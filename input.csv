full_name,default_branch,stars,forks,created_at,size,open_issues_count,description,topics,readme
ityouknow/spring-boot-examples,master,29903,12333,2016-11-05T05:32:33Z,1074,11,about learning Spring Boot via examples. Spring Boot 教程、技术栈示例代码，快速简单上手教程。 ,docker docker-composer fastdfs java mongodb mybatis rabbitmq scheduler spring spring-boot spring-boot-examples spring-boot-mail spring-boot-mongodb spring-boot-upload-file spring-cloud spring-data-jpa springboot springboot-shiro springcloud thymeleaf,"Spring Boot 学习示例
=========================

![Spring Boot 2.0](https://img.shields.io/badge/Spring%20Boot-2.0-brightgreen.svg)
![Mysql 5.6](https://img.shields.io/badge/Mysql-5.6-blue.svg)
![JDK 1.8](https://img.shields.io/badge/JDK-1.8-brightgreen.svg)
![Maven](https://img.shields.io/badge/Maven-3.5.0-yellowgreen.svg)
![license](https://img.shields.io/badge/license-MPL--2.0-blue.svg)
 
Spring Boot 使用的各种示例，以最简单、最实用为标准，此开源项目中的每个示例都以最小依赖，最简单为标准，帮助初学者快速掌握 Spring Boot 各组件的使用。

[Spring Boot 中文索引](https://github.com/ityouknow/awesome-spring-boot) &nbsp;| &nbsp; [Spring Cloud学习示例代码](https://github.com/ityouknow/spring-cloud-examples) &nbsp;| &nbsp; [Spring Boot 精品课程](https://github.com/ityouknow/spring-boot-leaning) 

 [Github地址](https://github.com/ityouknow/spring-boot-examples) &nbsp;| &nbsp; [码云地址](https://gitee.com/ityouknow/spring-boot-examples) &nbsp;| &nbsp;  [Spring Boot 1.X](https://github.com/ityouknow/spring-boot-examples/tree/master/1.x) | &nbsp;  [Spring Boot 2.X](https://github.com/ityouknow/spring-boot-examples/tree/master/2.x)

---


**本项目中所有示例均已经更新到 Spring Boot 3.0**

- Spring Boot 1.X  系列示例代码请看这里：[Spring Boot 1.X](https://github.com/ityouknow/spring-boot-examples/tree/master/1.x)   
- Spring Boot 2.X  系列示例代码请看这里：[Spring Boot 2.X](https://github.com/ityouknow/spring-boot-examples/tree/master/2.x) 



## 示例代码

- [spring-boot-hello](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-hello)：Spring Boot 3.0  Hello World 示例
- [spring-boot-banner](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-hello)：Spring Boot 3.0  定制 banner 示例
- [spring-boot-helloworld](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-helloWorld)：Spring Boot 3.0  Hello World Test 单元测试示例
- [spring-boot-scheduler](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-scheduler)：Spring Boot 3.0 定时任务 scheduler 使用示例
- [spring-boot-package](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-package)：Spring Boot 3.0 单元测试、集成测试、打 Jar/War 包、定制启动参数使用案例
- [spring-boot-commandLineRunner](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-commandLineRunner)：Spring Boot 3.0 目启动时初始化资源案例
- [spring-boot-web](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-web)：Spring Boot 3.0 web 示例
- [spring-boot-webflux](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-webflux)：Spring Boot 3.0  响应式编程 WebFlux 使用案例
- [spring-boot-file-upload](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-file-upload)：Spring Boot 3.0 上传文件使用案例
- [spring-boot-thymeleaf](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-thymeleaf)：Spring Boot 3.0 Thymeleaf 语法、布局使用示例
- [spring-boot-jpa](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-jpa)：Spring Boot 3.0 Jpa 操作、增删、改查多数据源使用示例
- [spring-boot-mybatis](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-mybatis)：Spring Boot 3.0 Mybatis 注解、xml 使用、增删改查、多数据源使用示例
- [spring-boot-web-thymeleaf](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-web-thymeleaf)：Spring Boot 3.0 thymeleaf 增删该查示例
- [spring-boot-jpa-thymeleaf-curd](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-jpa-thymeleaf-curd)：Spring Boot 3.0 Jpa thymeleaf 列表、增删改查使用案例
- [spring-boot-mail](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-mail)：Spring Boot 3.0 邮件发送使用示例
- [spring-boot-rabbitmq](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-rabbitmq)：Spring Boot 3.0 RabbitMQ 各种常见场景使用示例 
- [spring-boot-mongodb](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-mongodb)：Spring Boot 3.0 MongoDB 增删改查示例 多数据源使用案例
- [spring-boot-redis](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-redis)：Spring Boot 3.0 Redis 示例
- [spring-boot-memcache-spymemcached](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-memcache-spymemcached)：Spring Boot 3.0  集成 Memcached 使用案例
- [spring-boot-docker](https://github.com/ityouknow/spring-boot-examples/tree/master/spring-boot-docker)：Spring Boot 3.0 Docker 使用案例
- [dockercompose-springboot-mysql-nginx](https://github.com/ityouknow/spring-boot-examples/tree/master/dockercompose-springboot-mysql-nginx)：Spring Boot 3.0 Docker Compose + Spring Boot + Nginx + Mysql 使用案例


> 如果大家想了解关于 Spring Boot 的其它方面应用，也可以以[issues](https://github.com/ityouknow/spring-boot-examples/issues)的形式反馈给我，我后续来完善。

关注公众号：纯洁的微笑，回复""666""进群交流

![](http://www.ityouknow.com/assets/images/keeppuresmile_430.jpg)"
awsdocs/aws-doc-sdk-examples,main,8895,5455,2016-08-18T19:06:57Z,275099,262,"Welcome to the AWS Code Examples Repository.  This repo contains code examples used in the AWS documentation, AWS SDK Developer Guides, and more. For more information, see the Readme.md file below.",aws cpp documentation dotnet examples go java javascript php programming python ruby,"[![Build Status](https://github.com/aws/aws-sdk-ruby/workflows/CI/badge.svg)](https://github.com/awsdocs/aws-doc-sdk-examples/actions)
[![GitHub Super-Linter](https://github.com/awsdocs/aws-doc-sdk-examples/actions/workflows/super-linter.yml/badge.svg)](https://github.com/marketplace/actions/super-linter)
![[]](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue)

# AWS SDK Code Examples

This repository contains code examples that demonstrate how to use the [AWSK SDKs](https://aws.amazon.com/developer/tools/) to interact with [AWS services](https://aws.amazon.com/products).

Many examples are injected into the [AWS Documentation](https://docs.aws.amazon.com).

## How this repository is organized

Code examples for each language's SDK can be found within the following subdirectories. The examples here demonstrate the most common uses of the SDK for each language.

|     SDK    |       folder      | SDK version |
|:----------:|:-----------------:|:-----------:|
| .NET       | [dotnetv3/](dotnetv3)         | 3.5+        |
| .NET       | [dotnet/](.dotnet)           | <3.5        |
| C++        | [cpp/](cpp)              | 1           |
| Go         | [gov2/](gov2)            | 2           |
| Go         | [go/](go)               | 1           |
| Java       | [javav2/](javav2)           | 2           |
| Java       | [java/](java)             | 1           |
| JavaScript | [javascriptv3/](javascriptv3)     | 3           |
| JavaScript | [javascript/](javascriptv)       | 2           |
| Kotlin     | [kotlin/](kotlin)           | 1             |
| PHP        | [php/](php)              | 3           |
| Python     | [python/](python)           | 3           |
| Ruby       | [ruby/](ruby)             | 3           |
| Rust       | [rustv1/](rustv1) | 1             |
| Swift      | [swift/](swift)            | preview           |

Within each directory, you will find SDK-specific instructions for understanding and invoking example code.

### NOTE
In alignment with our SDKs and Tools Maintenance Policy, the AWS SDK for Java v1.x will enter maintenance mode on July 31, 2024, and reach end-of-support on December 31, 2025.

For more information, see [Announcing end-of-support for AWS SDK for Java v1.x](https://aws.amazon.com/blogs/developer/announcing-end-of-support-for-aws-sdk-for-java-v1-x-on-december-31-2025/).


### Additional directories

| directory                     | purpose                                                                                                                                                     | usage                                                                                                                                                                                  |
|-------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [/applications](applications) | Contains the non-language-specific components of example applications, which show how the SDKs can be used in the context of a production-like application. | To view the language-specific components for each example application, see the `cross-service` folder in the sub-directory for your desired language (such as `python/cross-service`). |
| [/test](test)                 | Contains all components supporting the custom test automation framework used to routinely test the code in this repository.                                 | Deploys to AWS as a polyglot container-based integration testing solution. WARNING: Still under active construction as of 2023.                                                        |
| [/resources](resources)       | Contains shared components used by many code examples across this repository.                                                                               | Deploys as frontend ([/clients](/resources/clients)) or backend ([/cdk](/resources/cdk) or [/cfn](/resources/cfn)) components.                                                         


## Invoke example code

To invoke this example code, you must have an AWS account. For more information about creating an account, see [AWS Free Tier](https://aws.amazon.com/free/).

You must also have AWS credentials configured. For steps on using the AWS Command Line Interface (AWS CLI) to configure credentials, see [CLI Configuration basics](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html)

## ⚠️ Usage disclaimer

These code examples interact with services that may incur charges to your AWS account. For more information, see [AWS Pricing](https://aws.amazon.com/pricing/).

Additionally, example code might theoretically modify or delete existing AWS resources. As a matter of due diligence, do the following:

- Be aware of the resources that these examples create or delete.
- Be aware of the costs that might be charged to your account as a result.
- Back up your important data.

# Contributing

This repository thrives on your contributions! ❤️ To get involved, see the [CONTRIBUTING.md](CONTRIBUTING.md). 🙏

# Copyright and license

All content in this repository, unless otherwise stated, is
Copyright © Amazon Web Services, Inc. or its affiliates. All rights reserved.

Except where otherwise noted, all examples in this collection are licensed under the [Apache
license, version 2.0](https://www.apache.org/licenses/LICENSE-2.0) (the ""License""). The full
license text is provided in the `LICENSE` file accompanying this repository.
"
spring-projects/spring-data-examples,main,5060,3354,2014-01-30T15:42:43Z,11619,18,Spring Data Example Projects,,
thombergs/code-examples,master,2585,2600,2017-07-30T14:12:24Z,121387,119,A collection of code examples from blog posts etc.,,"# Example Code Repository

[![CI](https://github.com/thombergs/code-examples/workflows/CI/badge.svg)](https://github.com/thombergs/code-examples/actions?query=workflow%3ACI)

This repo contains example projects which show how to use different (not only) Java technologies.
The examples are usually accompanied by a blog post on [https://reflectoring.io](https://reflectoring.io).

See the READMEs in each subdirectory of this repo for more information on each module."
vert-x3/vertx-examples,4.x,3510,2086,2015-02-24T17:42:44Z,51281,45,Vert.x examples,async examples http2 kotlin reactive vertx,
in28minutes/spring-boot-examples,master,1174,3328,2017-11-27T04:31:20Z,2128,50,Code Examples for everything thats written on www.springboottutorial.com,,"# Spring Boot Code Examples

All code examples for our website http://www.springboottutorial.com

## Keep Learning Every Day
- **1:** [FOLLOW](https://links.in28minutes.com/lin) Ranga on LinkedIn

## Check Out Our Amazing ROADMAPS
- **1:** [AWS Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#aws-roadmap)
- **2:** [Azure Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#azure-roadmap)
- **3:** [Google Cloud Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#google-cloud-roadmap)
- **4:** [Cloud Beginner Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#cloud-beginner-roadmap)
- **5:** [DevOps Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#devops-roadmap)
- **6:** [Java Full Stack Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#java-full-stack-roadmap)
- **7:** [Java Microservices Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#java-microservices-roadmap)

[![Image](https://www.springboottutorial.com/images/Course-clean-code.png ""Clean Code with Java: Learn Simple Design, Refactoring & TDD"")](https://www.udemy.com/course/java-clean-code-with-refactoring-and-tdd/?referralCode=201A00544D2D754A688F)


### Installing Eclipse & Embedded Maven
- Installation Video : https://www.youtube.com/playlist?list=PLBBog2r6uMCSmMVTW_QmDLyASBvovyAO3
- GIT Repository For Installation : https://github.com/in28minutes/getting-started-in-5-steps
- PDF : https://github.com/in28minutes/SpringIn28Minutes/blob/master/InstallationGuide-JavaEclipseAndMaven_v2.pdf

### Running Examples
- Download the zip or clone the Git repository.
- Unzip the zip file (if you downloaded one)
- Open Command Prompt and Change directory (cd) to folder containing pom.xml
- Open Eclipse 
   - File -> Import -> Existing Maven Project -> Navigate to the folder where you unzipped the zip
   - Select the right project
- Choose the Spring Boot Application file (search for @SpringBootApplication)
- Right Click on the file and Run as Java Application
- You are all Set

### Troubleshooting
- Refer our TroubleShooting Guide - http://www.in28minutes.com/spring-boot-maven-eclipse-troubleshooting-guide-and-faq

### Useful Links
- Find out more about in28Minutes and our approach to creating great learning experience - The in28Minutes Way - http://www.in28minutes.com/the-in28minutes-way
- Facebook  : https://www.facebook.com/in28Minutes​
- Twitter   : https://twitter.com/in28Minutes​
- YouTube   : https://www.youtube.com/rithustutorials​
- Instagram : https://www.instagram.com/in28minutes/

in28Minutes is creating amazing solutions for you to learn Spring Boot, Full Stack and the Cloud - Docker, Kubernetes, AWS, React, Angular etc. - [Check out all our courses here](https://github.com/in28minutes/learn)

## Youtube Playlists - 500+ Videos

[Click here - 30+ Playlists with 500+ Videos on Spring, Spring Boot, REST, Microservices and the Cloud](https://www.youtube.com/user/rithustutorials/playlists?view=1&sort=lad&flow=list)
"
nacos-group/nacos-examples,master,919,1457,2018-09-21T15:52:49Z,1151,70,Nacos Examples,,"# nacos-examples
Nacos Examples

# Nacos-examples [中文](./README_CN.md) #

This is examples of the nacos, you can use nacos-native-sdk/spring to opercate service/config.

## Start nacos
You can start nacos by standalone on your computer

https://nacos.io/en-us/docs/deployment.html

You can start server from aliyun

https://help.aliyun.com/document_detail/139460.html

https://www.aliyun.com/product/aliware/mse?spm=nacos-website.topbar.0.0.0

## Config your config 

### Spring
https://nacos.io/en-us/docs/quick-start-spring.html

### Spring-boot
https://nacos.io/en-us/docs/quick-start-spring-boot.html

### Spring-cloud
https://nacos.io/en-us/docs/quick-start-spring-cloud.html

### Dubbo
https://nacos.io/en-us/docs/use-nacos-with-dubbo.html

## Run Demo
Run Main
"
deeplearning4j/deeplearning4j-examples,master,2417,1806,2015-08-24T15:17:43Z,355459,81,"Deeplearning4j Examples (DL4J, DL4J Spark, DataVec)",artificial-intelligence deeplearning deeplearning4j dl4j intellij javafx python zeppelin-notebook,"<pre>
                                ########  ##       ##              ##
                                ##     ## ##       ##    ##        ##
                                ##     ## ##       ##    ##        ##
                       **$**    ##     ## ##       ##    ##        ##    **$**
                                ##     ## ##       ######### ##    ##
                                ##     ## ##             ##  ##    ##
                                ########  ########       ##   ######
              .   :::: :   :    :   :     : ::::  :     ::::    :::::  :::: ::::  :::::   .
              .   :    :   :   : :  ::   :: :   : :     :       :   :  :    :   : :   :   .
              .   :     : :   :   : : : : : :   : :     :       :   :  :    :   : :   :   .
              .   :::    :    :   : :  :  : ::::  :     :::     :::::  :::  ::::  :   :   .
              .   :     : :   ::::: :     : :     :     :       :  :   :    :     :   :   .
              .   :    :   :  :   : :     : :     :     :       :   :  :    :     :   :   .
              .   :::: :   :  :   : :     : :     ::::: ::::    :    : :::: :     :::::   .
</pre>

For support, please go over to:
https://community.konduit.ai

We do not monitor the github issues of this repository very often.

## Introduction
The **Eclipse Deeplearning4J** (DL4J) ecosystem is a set of projects intended to support all the needs of a JVM based deep learning application. This means starting with the raw data, loading and preprocessing it from wherever and whatever format it is in to building and tuning a wide variety of simple and complex deep learning networks.

The DL4J stack comprises of:
- **DL4J**: High level API to build MultiLayerNetworks and ComputationGraphs with a variety of layers, including custom ones. Supports importing Keras models from h5, including tf.keras models (as of 1.0.0-M2) and also supports distributed training on Apache Spark
- **ND4J**: General purpose linear algebra library with over 500 mathematical, linear algebra and deep learning operations. ND4J is based on the highly-optimized C++ codebase LibND4J that provides CPU (AVX2/512) and GPU (CUDA) support and acceleration by libraries such as OpenBLAS, OneDNN (MKL-DNN), cuDNN, cuBLAS, etc
- **SameDiff** : Part of the ND4J library, SameDiff is our automatic differentiation / deep learning framework. SameDiff uses a graph-based (define then run) approach, similar to TensorFlow graph mode. Eager graph (TensorFlow 2.x eager/PyTorch) graph execution is planned. SameDiff supports importing TensorFlow frozen model format .pb (protobuf) models. Import for ONNX, TensorFlow SavedModel and Keras models are planned. Deeplearning4j also has full SameDiff support for easily writing custom layers and loss functions.
- **DataVec**: ETL for machine learning data in a wide variety of formats and files (HDFS, Spark, Images, Video, Audio, CSV, Excel etc)
- **LibND4J** : C++ library that underpins everything. For more information on how the JVM accesses native arrays and operations refer to [JavaCPP](https://github.com/bytedeco/javacpp)

All projects in the DL4J ecosystem support Windows, Linux and macOS. Hardware support includes CUDA GPUs (10.0, 10.1, 10.2 except OSX), x86 CPU (x86_64, avx2, avx512), ARM CPU (arm, arm64, armhf) and PowerPC (ppc64le).

## Prerequisites
This example repo consists of several separate Maven Java projects, each with their own pom files. Maven is a popular build automation tool for Java Projects. The contents of a ""pom.xml"" file dictate the configurations. Read more about how to configure Maven [here](https://deeplearning4j.konduit.ai/config/maven).

Users can also refer to the [simple sample project provided](./mvn-project-template/pom.xml) to get started with a clean project from scratch.

Build tools are considered standard software engineering best practice. Besides this the complexities posed by the projects in the DL4J ecosystem make dependencies too difficult to manage manually. All the projects in the DL4J ecosystem can be used with other build tools like Gradle, SBT etc. More information on that can be found [here](https://deeplearning4j.konduit.ai/config/buildtools).

## Support

For help with the examples, please go to our [support forum](https://community.konduit.ai/)

Note for users of 1.0.0-beta7 and prior, some examples and modules have been removed to reflect
changes in the framework's direction. Please see and comment on our post [here](https://community.konduit.ai/t/upcoming-removal-of-modules-and-roadmap-changes/1240)

If you would like a workaround for something you may be missing,
please feel free to post on the forums, and we will do what we can to help you.


## Example Content
Projects are based on what functionality the included examples demonstrate to the user and not necessarily which library in the DL4J stack the functionality lives in.

Examples in a project are in general separated into ""quickstart"" and ""advanced"".

Each project README also lists all the examples it contains, with a recommended order to explore them in.

- [dl4j-examples](dl4j-examples/README.md)
This project contains a set of examples that demonstrate use of the high level DL4J API to build a variety of neural networks.
Some of  these examples are end to end, in the sense they start with raw data, process it and then build and train neural networks on it.

- [tensorflow-keras-import-examples](tensorflow-keras-import-examples/README.md)
This project contains a set of examples that demonstrate how to import Keras h5 models and TensorFlow frozen pb models into the DL4J ecosystem. Once imported into DL4J these models can be treated like any other DL4J model - meaning you can continue to run training on them or modify them with the transfer learning API or simply run inference on them.

- [dl4j-distributed-training-examples](dl4j-distributed-training-examples/README.md)
This project contains a set of examples that demonstrate how to do distributed training, inference and evaluation in DL4J on Apache Spark. DL4J distributed training employs a ""hybrid"" asynchronous SGD approach - further details can be found in the distributed deep learning documentation [here](https://deeplearning4j.konduit.ai/distributed-deep-learning/intro)

- [cuda-specific-examples](cuda-specific-examples/README.md)
This project contains a set of examples that demonstrate how to leverage multiple GPUs for data-parallel training of neural networks for increased performance.

- [samediff-examples](samediff-examples/README.md)
This project contains a set of examples that demonstrate the SameDiff API. SameDiff (which is part of the ND4J library) can be used to build lower level auto-differentiating computation graphs. An analogue to the SameDiff API vs the DL4J API is the low level TensorFlow API vs the higher level of abstraction Keras API.

- [data-pipeline-examples](data-pipeline-examples/README.md)
This project contains a set of examples that demonstrate how raw data in various formats can be loaded, split and preprocessed to build serializable (and hence reproducible) ETL pipelines.

- [nd4j-ndarray-examples](nd4j-ndarray-examples/README.md)
This project contains a set of examples that demonstrate how to manipulate NDArrays. The functionality of ND4J demonstrated here can be likened to NumPy.

- [rl4j-examples](rl4j-examples/README.md)
This project contains examples of using RL4J, the reinforcement learning library in DL4J.

- [android-examples](android-examples/README.md)
This project contains an Android example project, that shows DL4J being used in an Android application.

## Feedback & Contributions
While these set of examples don't cover all the features available in DL4J the intent is to cover functionality required for most users - beginners and advanced.  File an issue [here](https://github.com/eclipse/deeplearning4j-examples/issues) if you have feedback or feature requests that are not covered here. We are also available via our [community forum](https://community.konduit.ai/) for questions.
We welcome contributions from the community. More information can be found [here](CONTRIBUTORS.md)
We **love** hearing from you. Cheers!
"
confluentinc/kafka-streams-examples,master,2281,1135,2017-08-18T22:07:36Z,24753,26,Demo applications and code examples for Apache Kafka's Streams API.,,"# Kafka Streams Examples

This project contains code examples that demonstrate how to implement real-time applications and event-driven
microservices using the Streams API of [Apache Kafka](http://kafka.apache.org/) aka Kafka Streams.

For more information take a look at the
[**latest Confluent documentation on the Kafka Streams API**](http://docs.confluent.io/current/streams/), notably the
[**Developer Guide**](https://docs.confluent.io/platform/current/streams/developer-guide/index.html)


---
Table of Contents

* [Available examples](#available-examples)
    * [Examples: Runnable Applications](#examples-apps)
    * [Examples: Unit Tests](#examples-unit-tests)
    * [Examples: Integration Tests](#examples-integration-tests)
    * [Docker Example: Kafka Music demo application](#examples-docker)
    * [Examples: Event Streaming Platform](#examples-event-streaming-platform)
* [Requirements](#requirements)
    * [Apache Kafka](#requirements-kafka)
    * [Confluent Platform](#requirements-confluent-platform)
    * [Using IntelliJ or Eclipse](#requirements-ide)
    * [Java](#requirements-java)
    * [Scala](#requirements-scala)
* [Packaging and running the examples](#packaging-and-running)
* [Development](#development)
* [Version Compatibility Matrix](#version-compatibility)
* [Where to find help](#help)

---


<a name=""available-examples""/>

# Available examples

This repository has several branches to help you find the correct code examples for the version of Apache Kafka and/or
Confluent Platform that you are using.  See [Version Compatibility Matrix](#version-compatibility) below for details.

There are three kinds of examples:

* **Examples under [src/main/](src/main/)**: These examples are short and concise.  Also, you can interactively
  test-drive these examples, e.g. against a local Kafka cluster.  If you want to actually run these examples, then you
  must first install and run Apache Kafka and friends, which we describe in section
  [Packaging and running the examples](#packaging-and-running).  Each example also states its exact requirements and
  instructions at the very top.
* **Examples under [src/test/](src/test/)**: These examples should test applications under [src/main/](src/main/).
  Unit Tests with TopologyTestDriver test the stream logic without external system dependencies.
  The integration tests use an embedded Kafka
  clusters, feed input data to them (using the standard Kafka producer client), process the data using Kafka Streams,
  and finally read and verify the output results (using the standard Kafka consumer client).
  These examples are also a good starting point to learn how to implement your own end-to-end integration tests.
* **Ready-to-run Docker Examples**: These examples are already built and containerized.


<a name=""examples-apps""/>

## Examples: Runnable Applications

Additional examples may be found under [src/main/](src/main/java/io/confluent/examples/streams/).

| Application Name            | Concepts used                                            | Java 8+ | Java 7+ | Scala |
| --------------------------- | -------------------------------------------------------- | ------- | ------- | ----- |
| WordCount                   | DSL, aggregation, stateful                               | [Java 8+ example](src/main/java/io/confluent/examples/streams/WordCountLambdaExample.java) | | [Scala Example](src/main/scala/io/confluent/examples/streams/WordCountScalaExample.scala) |
| MapFunction                 | DSL, stateless transformations, `map()`                  | [Java 8+ example](src/main/java/io/confluent/examples/streams/MapFunctionLambdaExample.java) | | [Scala Example](src/main/scala/io/confluent/examples/streams/MapFunctionScalaExample.scala) |
| SessionWindows              | Sessionization of user events, user behavior analysis    | | [Java 7+ example](src/main/java/io/confluent/examples/streams/SessionWindowsExample.java)
| GlobalKTable                | `join()` between `KStream` and `GlobalKTable`            | [Java 8+ example](src/main/java/io/confluent/examples/streams/GlobalKTablesExample.java) | | |
| GlobalStore                 | ""join"" between `KStream` and `GlobalStore`               | [Java 8+ example](src/main/java/io/confluent/examples/streams/GlobalStoresExample.java) | | |
| PageViewRegion              | `join()` between `KStream` and `KTable`                  | [Java 8+ example](src/main/java/io/confluent/examples/streams/PageViewRegionLambdaExample.java) | [Java 7+ example](src/main/java/io/confluent/examples/streams/PageViewRegionExample.java) | |
| PageViewRegionGenericAvro   | Working with data in Generic Avro format                 | [Java 8+ example](src/main/java/io/confluent/examples/streams/PageViewRegionLambdaExample.java) | [Java 7+ example](src/main/java/io/confluent/examples/streams/PageViewRegionExample.java) | |
| WikipediaFeedSpecificAvro   | Working with data in Specific Avro format                | [Java 8+ example](src/main/java/io/confluent/examples/streams/WikipediaFeedAvroLambdaExample.java) | [Java 7+ example](src/main/java/io/confluent/examples/streams/WikipediaFeedAvroExample.java) | |
| SecureKafkaStreams          | Secure, encryption, client authentication                | | [Java 7+ example](src/main/java/io/confluent/examples/streams/SecureKafkaStreamsExample.java) | |
| Sum                         | DSL, stateful transformations, `reduce()`                | [Java 8+ example](src/main/java/io/confluent/examples/streams/SumLambdaExample.java) | | |
| WordCountInteractiveQueries | Interactive Queries, REST, RPC                           | [Java 8+ example](src/main/java/io/confluent/examples/streams/interactivequeries/WordCountInteractiveQueriesExample.java) | | |
| KafkaMusic                  | Interactive Queries, State Stores, REST API              | [Java 8+ example](src/main/java/io/confluent/examples/streams/interactivequeries/kafkamusic/KafkaMusicExample.java) | | |
| ApplicationReset            | Application Reset Tool `kafka-streams-application-reset` | [Java 8+ example](src/main/java/io/confluent/examples/streams/ApplicationResetExample.java) | | |
| Microservice                | Microservice ecosystem, state stores, dynamic routing, joins, filtering, branching, stateful operations | [Java 8+ example](src/main/java/io/confluent/examples/streams/microservices) | | |


<a name=""examples-unit-tests""/>

## Examples: Unit Tests

The stream processing of Kafka Streams can be **unit tested** with the `TopologyTestDriver` from the
`org.apache.kafka:kafka-streams-test-utils` artifact. The test driver allows you to write sample input into your
processing topology and validate its output.

See the documentation at [Testing Streams Code](https://docs.confluent.io/current/streams/developer-guide/test-streams.html).


<a name=""examples-integration-tests""/>

## Examples: Integration Tests

We also provide several **integration tests**, which demonstrate end-to-end data pipelines.  Here, we spawn embedded Kafka
clusters and the [Confluent Schema Registry](https://github.com/confluentinc/schema-registry), feed input data to them
(using the standard Kafka producer client), process the data using Kafka Streams, and finally read and verify the output
results (using the standard Kafka consumer client).

Additional examples may be found under [src/test/](src/test/java/io/confluent/examples/streams/).

> Tip: Run `mvn test` to launch the tests.

| Integration Test Name               | Concepts used                               | Java 8+ | Java 7+ | Scala |
| ----------------------------------- | ------------------------------------------- | ------- | ------- | ----- |
| WordCount                           | DSL, aggregation, stateful                  | [Java 8+ Example](src/test/java/io/confluent/examples/streams/WordCountLambdaIntegrationTest.java) | | [Scala Example](src/test/scala/io/confluent/examples/streams/WordCountScalaIntegrationTest.scala) |
| WordCountInteractiveQueries         | Interactive Queries, REST, RPC              | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/interactivequeries/WordCountInteractiveQueriesExampleTest.java) | |
| Aggregate                           | DSL, `groupBy()`, `aggregate()`             | [Java 8+ Example](src/test/java/io/confluent/examples/streams/AggregateTest.java) | | [Scala Example](src/test/scala/io/confluent/examples/streams/AggregateScalaTest.scala) |
| CustomStreamTableJoin               | DSL, Processor API, Transformers            | [Java 8+ Example](src/test/java/io/confluent/examples/streams/CustomStreamTableJoinIntegrationTest.java) | | |
| EventDeduplication                  | DSL, Processor API, Transformers            | [Java 8+ Example](src/test/java/io/confluent/examples/streams/EventDeduplicationLambdaIntegrationTest.java) | | |
| GlobalKTable                        | DSL, global state                           | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/GlobalKTablesExampleTest.java) | |
| GlobalStore                         | DSL, global state, Transformers             | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/GlobalStoresExampleTest.java) | |
| HandlingCorruptedInputRecords       | DSL, `flatMap()`                            | [Java 8+ Example](src/test/java/io/confluent/examples/streams/HandlingCorruptedInputRecordsIntegrationTest.java) | | |
| KafkaMusic (Interactive Queries)    | Interactive Queries, State Stores, REST API | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/interactivequeries/kafkamusic/KafkaMusicExampleTest.java) | |
| MapFunction                         | DSL, stateless transformations, `map()`     | [Java 8+ Example](src/test/java/io/confluent/examples/streams/MapFunctionLambdaIntegrationTest.java) | | |
| MixAndMatch DSL + Processor API     | Integrating DSL and Processor API           | [Java 8+ Example](src/test/java/io/confluent/examples/streams/MixAndMatchLambdaIntegrationTest.java) | | |
| PassThrough                         | DSL, `stream()`, `to()`                     | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/PassThroughIntegrationTest.java) | |
| PoisonPill                          | DSL, `flatMap()`                            | [Java 8+ Example](src/test/java/io/confluent/examples/streams/HandlingCorruptedInputRecordsIntegrationTest.java) | | |
| ProbabilisticCounting\*\*\*         | DSL, Processor API, custom state stores     | | | [Scala Example](src/test/scala/io/confluent/examples/streams/ProbabilisticCountingScalaIntegrationTest.scala) |
| Reduce (Concatenate)                | DSL, `groupByKey()`, `reduce()`             | [Java 8+ Example](src/test/java/io/confluent/examples/streams/ReduceTest.java) | | [Scala Example](src/test/scala/io/confluent/examples/streams/ReduceScalaTest.scala) |
| SessionWindows                      | DSL, windowed aggregation, sessionization   | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/SessionWindowsExampleTest.java) | |
| StatesStoresDSL                     | DSL, Processor API, Transformers            | [Java 8+ Example](src/test/java/io/confluent/examples/streams/StateStoresInTheDSLIntegrationTest.java) | | |
| StreamToStreamJoin                  | DSL, `join()` between KStream and KStream   | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/StreamToStreamJoinIntegrationTest.java) | |
| StreamToTableJoin                   | DSL, `join()` between KStream and KTable    | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/StreamToTableJoinIntegrationTest.java) | [Scala Example](src/test/scala/io/confluent/examples/streams/StreamToTableJoinScalaIntegrationTest.scala) |
| Sum                                 | DSL, aggregation, stateful, `reduce()`      | [Java 8+ Example](src/test/java/io/confluent/examples/streams/SumLambdaIntegrationTest.java) | | |
| TableToTableJoin                    | DSL, `join()` between KTable and KTable     | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/TableToTableJoinIntegrationTest.java) | |
| UserCountsPerRegion                 | DSL, aggregation, stateful, `count()`       | [Java 8+ Example](src/test/java/io/confluent/examples/streams/UserCountsPerRegionLambdaIntegrationTest.java) | | |
| ValidateStateWithInteractiveQueries | Interactive Queries for validating state    | | [Java 8+ Example](src/test/java/io/confluent/examples/streams/ValidateStateWithInteractiveQueriesLambdaIntegrationTest.java) | | |
| GenericAvro                         | Working with data in Generic Avro format    | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/GenericAvroIntegrationTest.java) |  [Scala Example](src/test/scala/io/confluent/examples/streams/GenericAvroScalaIntegrationTest.scala) |
| SpecificAvro                        | Working with data in Specific Avro format   | | [Java 7+ Example](src/test/java/io/confluent/examples/streams/SpecificAvroIntegrationTest.java) | [Scala Example](src/test/scala/io/confluent/examples/streams/SpecificAvroScalaIntegrationTest.scala) |

\*\*\*demonstrates how to probabilistically count items in an input stream by implementing a custom state store
([CMSStore](src/main/scala/io/confluent/examples/streams/algebird/CMSStore.scala)) that is backed by a
[Count-Min Sketch](https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch) data structure (with the CMS implementation
of [Twitter Algebird](https://github.com/twitter/algebird))


<a name=""examples-docker""/>

# Docker Example: Kafka Music demo application

This containerized example launches:

* Confluent's Kafka Music demo application for the Kafka Streams API, which makes use of
  [Interactive Queries](http://docs.confluent.io/current/streams/developer-guide.html)
* a single-node Apache Kafka cluster with a single-node ZooKeeper ensemble
* a [Confluent Schema Registry](https://github.com/confluentinc/schema-registry) instance

The Kafka Music application demonstrates how to build of a simple music charts application that continuously computes,
in real-time, the latest charts such as latest Top 5 songs per music genre.  It exposes its latest processing results
-- the latest charts -- via Kafka’s [Interactive Queries](http://docs.confluent.io/current/streams/developer-guide.html#interactive-queries)
feature via a REST API.  The application's input data is in Avro format, hence the use of Confluent Schema Registry,
and comes from two sources: a stream of play events (think: ""song X was played"") and a stream of song metadata (""song X
was written by artist Y"").

You can find detailed documentation at
https://docs.confluent.io/current/streams/kafka-streams-examples/docs/index.html.


<a name=""event-streaming-platform""/>

# Examples: Event Streaming Platform

For additional examples that showcase Kafka Streams applications within an event streaming platform, please refer to the [examples GitHub repository](https://github.com/confluentinc/examples).


<a name=""requirements""/>

# Requirements

<a name=""requirements-kafka""/>

## Apache Kafka

The code in this repository requires Apache Kafka 0.10+ because from this point onwards Kafka includes its
[Kafka Streams](https://github.com/apache/kafka/tree/trunk/streams) library.
See [Version Compatibility Matrix](#version-compatibility) for further details, as different branches of this
repository may have different Kafka requirements.

> **For the `master` branch:** To build a development version, you typically need the latest `trunk` version of Apache Kafka
> (cf. `kafka.version` in [pom.xml](pom.xml) for details).  The following instructions will build and locally install
> the latest `trunk` Kafka version:
>
> ```shell
> $ git clone git@github.com:apache/kafka.git
> $ cd kafka
> $ git checkout trunk
>
> # Now build and install Kafka locally
> $ ./gradlew clean && ./gradlewAll install
> ```


<a name=""requirements-confluent-platform""/>

## Confluent Platform

The code in this repository requires [Confluent Schema Registry](https://github.com/confluentinc/schema-registry).
See [Version Compatibility Matrix](#version-compatibility) for further details, as different branches of this
repository have different Confluent Platform requirements.

* [Confluent Platform Quickstart](http://docs.confluent.io/current/quickstart.html) (how to download and install)
* [Confluent Platform documentation](http://docs.confluent.io/current/)

> **For the `master` branch:** To build a development version, you typically need the latest `master` version of Confluent Platform's
> Schema Registry (cf. `confluent.version` in [pom.xml](pom.xml), which is set by the upstream
> [Confluent Common](https://github.com/confluentinc/common) project).
> The following instructions will build and locally install the latest `master` Schema Registry version, which includes
> building its dependencies such as [Confluent Common](https://github.com/confluentinc/common) and
> [Confluent Rest Utils](https://github.com/confluentinc/rest-utils).
> Please read the [Schema Registry README](https://github.com/confluentinc/schema-registry) for details.
>
> ```shell
> $ git clone https://github.com/confluentinc/common.git
> $ cd common
> $ git checkout master
>
> # Build and install common locally
> $ mvn -DskipTests=true clean install
>
> $ git clone https://github.com/confluentinc/rest-utils.git
> $ cd rest-utils
> $ git checkout master
>
> # Build and install rest-utils locally
> $ mvn -DskipTests=true clean install
>
> $ git clone https://github.com/confluentinc/schema-registry.git
> $ cd schema-registry
> $ git checkout master
>
> # Now build and install schema-registry locally
> $ mvn -DskipTests=true clean install
> ```

Also, each example states its exact requirements at the very top.


<a name=""requirements-ide""/>

## Using IntelliJ or Eclipse

If you are using an IDE and import the project you might end up with a ""missing import / class not found"" error.
Some Avro classes are generated from schema files and IDEs sometimes do not generate these classes automatically.
To resolve this error, manually run:

```shell
$ mvn -Dskip.tests=true compile
```

If you are using Eclipse, you can also right-click on `pom.xml` file and choose _Run As > Maven generate-sources_.


<a name=""requirements-java""/>

## Java 8+

Some code examples require Java 8+, primarily because of the usage of
[lambda expressions](https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html).

IntelliJ IDEA users:

* Open _File > Project structure_
* Select ""Project"" on the left.
    * Set ""Project SDK"" to Java 1.8.
    * Set ""Project language level"" to ""8 - Lambdas, type annotations, etc.""


<a name=""requirements-scala""/>

## Scala

> Scala is required only for the Scala examples in this repository.  If you are a Java developer you can safely ignore
> this section.

If you want to experiment with the Scala examples in this repository, you need a version of Scala that supports Java 8
and SAM / Java lambda (e.g. Scala 2.11 with `-Xexperimental` compiler flag, or 2.12).

If you are compiling with Java 9+, you'll need to have Scala version 2.12+ to be compatible with the Java version.


<a name=""packaging-and-running""/>

# Packaging and running the Application Examples

The instructions in this section are only needed if you want to interactively test-drive the
[application examples](#examples-apps) under [src/main/](src/main/).

> **Tip:** If you only want to run the integration tests (`mvn test`), then you do not need to package or install
> anything -- just run `mvn test`. These tests launch embedded Kafka clusters.

The first step is to install and run a Kafka cluster, which must consist of at least one Kafka broker as well as
at least one ZooKeeper instance.  Some examples may also require a running instance of Confluent schema registry.
The [Confluent Platform Quickstart](http://docs.confluent.io/current/quickstart.html) guide provides the full
details.

In a nutshell:

```shell
# Ensure you have downloaded and installed Confluent Platform as per the Quickstart instructions above.

# Start ZooKeeper
$ ./bin/zookeeper-server-start ./etc/kafka/zookeeper.properties

# In a separate terminal, start Kafka broker
$ ./bin/kafka-server-start ./etc/kafka/server.properties

# In a separate terminal, start Confluent Schema Registry
$ ./bin/schema-registry-start ./etc/schema-registry/schema-registry.properties

# Again, please refer to the Confluent Platform Quickstart for details such as
# how to download Confluent Platform, how to stop the above three services, etc.
```

The next step is to create a standalone jar (""fat jar"") of the [application examples](#examples-apps):

```shell
# Create a standalone jar (""fat jar"")
$ mvn clean package

# >>> Creates target/kafka-streams-examples-7.8.0-0-standalone.jar
```

> Tip: If needed, you can disable the test suite during packaging, for example to speed up the packaging or to lower
> JVM memory usage:
>
> ```shell
> $ mvn -DskipTests=true clean package
> ```

You can now run the application examples as follows:

```shell
# Run an example application from the standalone jar. Here: `WordCountLambdaExample`
$ java -cp target/kafka-streams-examples-7.8.0-0-standalone.jar \
  io.confluent.examples.streams.WordCountLambdaExample
```

The application will try to read from the specified input topic (in the above example it is ``streams-plaintext-input``),
execute the processing logic, and then try to write back to the specified output topic (in the above example it is ``streams-wordcount-output``).
In order to observe the expected output stream, you will need to start a console producer to send messages into the input topic
and start a console consumer to continuously read from the output topic. More details in how to run the examples can be found
in the [java docs](src/main/java/io/confluent/examples/streams/WordCountLambdaExample.java#L31) of each example code.

If you want to turn on log4j while running your example application, you can edit the
[log4j.properties](src/main/resources/log4j.properties) file and then execute as follows:

```shell
# Run an example application from the standalone jar. Here: `WordCountLambdaExample`
$ java -cp target/kafka-streams-examples-7.8.0-0-standalone.jar \
  -Dlog4j.configuration=file:src/main/resources/log4j.properties \
  io.confluent.examples.streams.WordCountLambdaExample
```

Keep in mind that the machine on which you run the command above must have access to the Kafka/ZooKeeper clusters you
configured in the code examples.  By default, the code examples assume the Kafka cluster is accessible via
`localhost:9092` (aka Kafka's ``bootstrap.servers`` parameter) and the ZooKeeper ensemble via `localhost:2181`.
You can override the default ``bootstrap.servers`` parameter through a command line argument.


<a name=""development""/>

# Development

This project uses the standard maven lifecycle and commands such as:

```shell
$ mvn compile # This also generates Java classes from the Avro schemas
$ mvn test    # Runs unit and integration tests
$ mvn package # Packages the application examples into a standalone jar
```


<a name=""version-compatibility""/>

# Version Compatibility Matrix

| Branch (this repo)                      | Confluent Platform | Apache Kafka      |
| ----------------------------------------|--------------------|-------------------|
| [5.4.x](../../../tree/5.4.x/)\*         | 5.4.0-SNAPSHOT     | 2.4.0-SNAPSHOT    |
| [5.3.0-post](../../../tree/5.3.0-post/) | 5.3.0              | 2.3.0             |
| [5.2.2-post](../../../tree/5.2.2-post/) | 5.2.2              | 2.2.1             |
| [5.2.1-post](../../../tree/5.2.1-post/) | 5.2.1              | 2.2.1             |
| [5.1.0-post](../../../tree/5.1.0-post/) | 5.1.0              | 2.1.0             |
| [5.0.0-post](../../../tree/5.0.0-post/) | 5.0.0              | 2.0.0             |
| [4.1.0-post](../../../tree/4.1.0-post/) | 4.1.0              | 1.1.0             |
| [4.0.0-post](../../../tree/4.4.0-post/) | 4.0.0              | 1.0.0             |
| [3.3.0-post](../../../tree/3.3.0-post/) | 3.3.0              | 0.11.0            |

\*You must manually build the `2.3` version of Apache Kafka and the `5.3.x` version of Confluent Platform.  See instructions above.

The `master` branch of this repository represents active development, and may require additional steps on your side to
make it compile.  Check this README as well as [pom.xml](pom.xml) for any such information.


<a name=""help""/>

# Where to find help

* Looking for documentation on Apache Kafka's Streams API?
    * We recommend to read the [Kafka Streams chapter](https://docs.confluent.io/current/streams/) in the
      [Confluent Platform documentation](https://docs.confluent.io/current/).
    * Watch our talk
      [Rethinking Stream Processing with Apache Kafka](https://www.youtube.com/watch?v=ACwnrnVJXuE)
* Running into problems to use the demos and examples in this project?
    * First, you should check our [FAQ wiki](https://github.com/confluentinc/kafka-streams-examples/wiki/FAQ) for an answer first.
    * If the FAQ doesn't help you, [create a new GitHub issue](https://github.com/confluentinc/kafka-streams-examples/issues).
* Want to ask a question, report a bug in Kafka or its Kafka Streams API, request a new Kafka feature?
    * For general questions about Apache Kafka and Confluent Platform, please head over to the
      [Confluent mailing list](https://groups.google.com/forum/?pli=1#!forum/confluent-platform)
      or to the [Apache Kafka mailing lists](http://kafka.apache.org/contact).

# License

Usage of this image is subject to the license terms of the software contained within. Please refer to Confluent's Docker images documentation [reference](https://docs.confluent.io/platform/current/installation/docker/image-reference.html) for further information. The software to extend and build the custom Docker images is available under the Apache 2.0 License.
"
BruceEckel/OnJava8-Examples,master,2993,1119,2015-04-20T22:34:50Z,10935,17,"Code Examples for the book On Java 8""""",,"# Examples for *On Java 8* by Bruce Eckel

If you want to experiment with the code examples from the book [On Java
8](https://www.onjava8.com/), you're in the right place.

These examples are automatically extracted directly from the book. This repository
includes tests to verify that the code in the book is correct.

> NOTE: Do not attempt to use JDK 16 or greater with gradle. 
> This produces a `BUG!` message from Gradle, which is broken for those versions.

## Contents

- [Building From the Command Line: Quick Version](#building-from-the-command-line-quick-version)
- [Building From the Command Line: Detailed Instructions](#building-from-the-command-line-detailed-instructions)
  * [Install Java](#install-java)
    + [Windows](#windows)
    + [Macintosh](#macintosh)
    + [Linux](#linux)
  * [Verify Your Installation](#verify-your-installation)
  * [Installing and Running the Book Examples](#installing-and-running-the-book-examples)
- [Appendix A: Command-Line Basics](#appendix-a-command-line-basics)
  * [Editors](#editors)
  * [The Shell](#the-shell)
    + [Starting a Shell](#starting-a-shell)
    + [Directories](#directories)
    + [Basic Shell Operations](#basic-shell-operations)
    + [Unpacking a Zip Archive](#unpacking-a-zip-archive)
- [Appendix B: Testing](#appendix-b-testing)
- [Appendix C: Troubleshooting](#appendix-c-troubleshooting)

# Building From the Command Line: Quick Version

Before you can run the examples from this repository, you must install
[JDK8](http://www.oracle.com/technetwork/java/javase/downloads/index.html), the
*Java Development Kit* for version 8 of the language.

If you just want to download and check the code, [Download
Here](https://github.com/BruceEckel/OnJava8-Examples/archive/refs/heads/master.zip)
and [unzip it](#unpacking-a-zip-archive) into your destination directory. Open
a [shell/command window](#appendix-a-command-line-basics) and move into the
root of that directory. You'll know you are in the right directory if you see
the files `gradlew` and `gradlew.bat`.

You'll need an Internet connection the first time you compile the code,
because Gradle needs to first install itself, then all the support libraries.
Once these are installed you can perform additional compiling and running
offline.

On Mac/Linux, enter:

```
./gradlew test
```

(If you get a *Permission denied* error, run `chmod +x ./gradlew`)

On Windows, enter

```
gradlew test
```

If all goes well, the tests will run. Everything should complete without errors.

All the book examples are in the subdirectory `Examples` in subdirectories
corresponding to the atom names.

# Building From the Command Line: Detailed Instructions

If you are not familiar with the command line, first read [Command-Line
Basics](#appendix-a-command-line-basics).

## Install Java

You must first install the *Java Development Kit* (JDK).

### Windows

1. Follow the instructions to [install Chocolatey](https://chocolatey.org/).

2. At a [shell prompt](#appendix-a-command-line-basics), type: `choco install
jdk8` (you may also select a more recent version, like `jdk11`). The
installation process takes some time, but when it's finished Java is installed
and the necessary environment variables are set.

### Macintosh

The Mac comes with a much older version of Java that won't work for the
examples in this book, so you'll need to update it to (at least) Java 8.

  1.  Follow the instructions at this link to [Install HomeBrew](http://brew.sh/)

  2.  At a [shell prompt](#appendix-a-command-line-basics), first type
      `brew update`. When that completes, enter `brew cask install java`.

**NOTE:** Sometimes the default version of Java that you get with the above
installation will be too recent and not validated by the Mac's security
system. If this happens you'll either need to turn off the security by hand
or install an earlier version of Java. For either choice, you'll need to Google
for answers on how to solve the problem (often the easiest approach is to just
search for the error message produced by the Mac).

### Linux

Use the standard package installer with the following [shell commands](#appendix-a-command-line-basics):

*Ubuntu/Debian*:

  1. `sudo apt-get update`

  2. `sudo apt-get install default-jdk`

*Fedora/Redhat*:

```
su -c ""yum install java-1.8.0-openjdk""
```

## Verify Your Installation

[Open a new shell](#appendix-a-command-line-basics) and type:

```
java -version
```

You should see something like the following (Version numbers and actual text
will vary):

```
openjdk version ""11"" 2018-09-25
OpenJDK Runtime Environment 18.9 (build 11+28)
OpenJDK 64-Bit Server VM 18.9 (build 11+28, mixed mode)
```

If you see a message that the command is not found or not recognized, review
the installation instructions. If you still can't get it to work, check
[StackOverflow](http://stackoverflow.com/search?q=installing+java).

## Installing and Running the Book Examples

Once you have Java installed, the process to install and run the book examples
is the same for all platforms:

1. Download the book examples from the
[GitHub Repository](https://github.com/BruceEckel/OnJava8-Examples/archive/refs/heads/master.zip).

2. [Unzip](#unpacking-a-zip-archive) the downloaded file into the directory of your choice.

3. Use the Windows Explorer, the Mac Finder, or Nautilus or equivalent on Linux
to browse to the directory where you uzipped `OnJava8-Examples`, and
[open a shell](#appendix-a-command-line-basics) there.

4. If you're in the right directory, you should see files named `gradlew` and
`gradlew.bat` in that directory, along with numerous other files and
directories. The directories correspond to the chapters in the book.

5. At the shell prompt, type `gradlew test` (Windows) or `./gradlew test`
(Mac/Linux).

The first time you do this, Gradle will install itself and numerous other
packages, so it will take some time. After everything is installed, subsequent
builds and runs will be much faster.

Note that you must be connected to the Internet the first time you run `gradlew`
so that Gradle can download the necessary packages.

# Appendix A: Command-Line Basics

Because it is possible for a ""dedicated beginner"" to learn programming from
this book, you may not have previously used your computer's command-line shell.
If you have, you can go directly to the
[installation instructions](#building-from-the-command-line-detailed-instructions).

## Editors

To create and modify Java program files&mdash;the code listings shown in this
book&mdash;you need a program called an *editor*. You'll also need the editor to
make changes to your system configuration files, which is sometimes required
during installation.

Programming editors vary from heavyweight *Integrated Development Environments*
(IDEs, like Eclipse, NetBeans and IntelliJ IDEA) to more basic text
manipulation applications. If you already have an IDE and are comfortable with
it, feel free to use that for this book.

Numerous explanations in this book are specific to IntelliJ IDEA so if you
don't already have an IDE you might as well start with IDEA. There are many
other editors; these are a subculture unto themselves and people sometimes get
into heated arguments about their merits. If you find one you like better, it's
not too hard to change. The important thing is to choose one and get
comfortable with it.

## The Shell

If you haven't programmed before, you might be unfamiliar with your operating
system *shell* (also called the *command prompt* in Windows). The shell harkens
back to the early days of computing when everything happened by typing commands
and the computer responded by displaying responses&mdash;everything was text-based.

Although it can seem primitive in the age of graphical user interfaces, a shell
provides a surprising number of valuable features.

To learn more about your shell than we cover here, see
[Bash Shell](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) for Mac/Linux
or [Windows Shell](https://en.wikipedia.org/wiki/Windows_shell).

### Starting a Shell

**Mac**: Click on the *Spotlight* (the magnifying-glass icon in the upper-right
corner of the screen) and type ""terminal."" Click on the application that looks
like a little TV screen (you might also be able to hit ""Return""). This starts a
shell in your home directory.

**Windows**: First, start the Windows Explorer to navigate through your
directories:

- *Windows 7*: click the ""Start"" button in the lower left corner of the screen.
In the Start Menu search box area type ""explorer"" and then press the ""Enter""
key.

- *Windows 8*: click Windows+Q, type ""explorer"" and then press the ""Enter"" key.

- *Windows 10*: click Windows+E.

Once the Windows Explorer is running, move through the folders on your computer
by double-clicking on them with the mouse. Navigate to the desired folder. Now
click the file tab at the top left of the Explorer window and select ""Open
Windows Powershell."" This opens a shell in the destination directory.

**Linux**: To open a shell in your home directory:

- *Debian*: Press Alt+F2. In the dialog that pops up, type 'gnome-terminal'

- *Ubuntu*: Either right-click on the desktop and select 'Open Terminal', or
  press Ctrl+Alt+T

- *Redhat*: Right-click on the desktop and select 'Open Terminal'

- *Fedora*: Press Alt+F2. In the dialog that pops up, type 'gnome-terminal'


### Directories

*Directories* are one of the fundamental elements of a shell. Directories hold
files, as well as other directories. Think of a directory as a tree with
branches. If `books` is a directory on your system and it has two other
directories as branches, for example `math` and `art`, we say that you have a
directory `books` with two *subdirectories* `math` and `art`. We refer to them
as `books/math` and `books/art` since `books` is their *parent* directory.
Note that Windows uses backslashes rather than forward slashes to separate the
parts of a directory.

### Basic Shell Operations

The shell operations shown here are approximately identical across operating
systems. For the purposes of this book, here are the essential operations in a
shell:

-   **Change directory**: Use `cd` followed by the name of the
    directory where you want to move, or `cd ..` if you want to move
    up a directory. If you want to move to a different directory while
    remembering where you came from, use `pushd` followed by the different
    directory name. Then, to return to the previous directory, just say
    `popd`.

-   **Directory listing**: `ls` (`dir` in Windows) displays all the files and
    subdirectory names in the current directory. Use the wildcard `*` (asterisk) to
    narrow your search. For example, if you want to list all the files ending in
    "".kt,"" you say `ls *.kt` (Windows: `dir *.kt`). If you want to list the
    files starting with ""F"" and ending in "".kt,"" you say `ls F*.kt` (Windows:
    `dir F*.kt`).

-   **Create a directory**: use the `mkdir` (""make directory"") command
    (Windows: `md`), followed by the name of the directory you want to create.
    For example, `mkdir books` (Windows: `md books`).

-   **Remove a file**: Use `rm` (""remove"") followed by the name of the file
    you wish to remove (Windows: `del`). For example, `rm somefile.kt` (Windows:
    `del somefile.kt`).

-   **Remove a directory**: use the `rm -r` command to remove the files in
    the directory and the directory itself (Windows: `deltree`). For example,
    `rm -r books` (Windows: `deltree books`).

-   **Repeat a command**: The ""up arrow"" on all three operating
    systems moves through previous commands so you can edit and
    repeat them. On Mac/Linux, `!!` repeats the last command and
    `!n` repeats the nth command.

-   **Command history**: Use `history` in Mac/Linux or press the F7 key in Windows.
    This gives you a list of all the commands you've entered. Mac/Linux provides
    numbers to refer to when you want to repeat a command.

### Unpacking a Zip Archive

A file name ending with `.zip` is an archive containing other files in a
compressed format. Both Linux and Mac have command-line `unzip` utilities, and
it's possible to install a command-line `unzip` for Windows via the Internet.

However, in all three systems the graphical file browser (Windows Explorer, the
Mac Finder, or Nautilus or equivalent on Linux) will browse to the directory
containing your zip file. Then right-mouse-click on the file and select ""Open""
on the Mac, ""Extract Here"" on Linux, or ""Extract all ..."" on Windows.

# Appendix B: Testing

The test system is built in so that we (the authors) can verify the correctness
of what goes into the book.

You don't need to run the tests, but if you want to, you can just run `gradlew
test` (on Windows) or `./gradlew test` (Mac/Linux).

To compile and run everything, the command is:

`gradlew run`

If you are on a Unix/Linux based system, you must select the local directory for all commands, for example:

`./gradlew run`

To only compile everything, the command is:

`gradlew compileJava`

To compile only a single chapter (including dependencies), use for example:

`gradlew :strings:compileJava`

To run only a single chapter, say:

`gradlew :strings:run`

Gradle can also be used to run a single program. Here, we run the **ReplacingStringTokenizer.java**
program in the **strings** chapter subdirectory:

`gradlew  :strings:ReplacingStringTokenizer`

However, if the file name is unique throughout the book (the majority are), you
can just give the program name, like this:

`gradlew  ReplacingStringTokenizer`

Note that all commands are run from the base directory where the example code is
installed, and where you find the `gradlew` script.

You can learn about other options by just typing `gradlew` with no arguments.

# Appendix C: Troubleshooting

If any terminology or processes described here remain unclear to you, you can
usually find explanations or answers through [Google](https://www.google.com/).
For more specific issues or problems, try
[StackOverflow](http://stackoverflow.com/). Sometimes you can find installation
instructions on [YouTube](https://www.youtube.com/).

Sometimes a Gradle build will be unable to connect to the internet and download
the necessary components, producing an error message containing:

```
javax.net.ssl.SSLException: java.lang.RuntimeException: Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty
```

Normally this means you have multiple Java installations on your machine
(applications built with Java ordinarily install their own version of Java), and
somehow the `cacerts` security file is interfering with the `cacerts` file for
the Java you have installed. It can be difficult to know which `cacerts` file is
interfering with yours. The brute-force approach is to search for all the
`cacerts` files on your machine and begin uninstalling the associated
applications---or in some cases, simply removing the directory containing the
`cacerts` file---until the Gradle build begins to work. You might also need to
adjust some environment variables and/or your path. Once you get the Gradle
build working successfully, you should be able to reinstall any applications you
removed in the process.
"
camunda/camunda-bpm-examples,master,1020,1178,2013-04-04T15:39:07Z,22984,4,A collection of usage examples for Camunda Platform intended to get you started quickly,,"Camunda Platform examples
====================

> Looking for the ""invoice"" example contained in the distribution?  You can find it here: https://github.com/camunda/camunda-bpm-platform/tree/master/examples/invoice

Camunda Platform examples is a collection of focused usage examples for the [Camunda Platform](https://github.com/camunda/camunda-bpm-platform), intended to get you started quickly. The sources on the master branch work with the current Camunda release. Follow the links below to browse the examples for the Camunda version you use:

| Camunda Version | Link                                                                  | Checkout command      |
|-----------------|-----------------------------------------------------------------------|-----------------------|
| Latest          | [Master branch](https://github.com/camunda/camunda-bpm-examples)      | `git checkout master` |
| 7.21            | [7.21 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.21) | `git checkout 7.21`   |
| 7.20            | [7.20 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.20) | `git checkout 7.20`   |
| 7.19            | [7.19 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.19) | `git checkout 7.19`   |
| 7.18            | [7.18 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.18) | `git checkout 7.18`   |
| 7.17            | [7.17 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.17) | `git checkout 7.17`   |
| 7.16            | [7.16 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.16) | `git checkout 7.16`   |
| 7.15            | [7.15 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.15) | `git checkout 7.15`   |
| 7.14            | [7.14 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.14) | `git checkout 7.14`   |
| 7.13            | [7.13 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.13) | `git checkout 7.13`   |
| 7.12            | [7.12 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.12) | `git checkout 7.12`   |
| 7.11            | [7.11 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.11) | `git checkout 7.11`   |
| 7.10            | [7.10 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.10) | `git checkout 7.10`   |
| 7.9             | [7.9 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.9)   | `git checkout 7.9`    |
| 7.8             | [7.8 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.8)   | `git checkout 7.8`    |
| 7.7             | [7.7 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.7)   | `git checkout 7.7`    |
| 7.6             | [7.6 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.6)   | `git checkout 7.6`    |
| 7.5             | [7.5 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.5)   | `git checkout 7.5`    |
| 7.4             | [7.4 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.4)   | `git checkout 7.4`    |
| 7.3             | [7.3 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.3)   | `git checkout 7.3`    |
| 7.2             | [7.2 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.2)   | `git checkout 7.2`    |
| 7.1             | [7.1 tag](https://github.com/camunda/camunda-bpm-examples/tree/7.1)   | `git checkout 7.1`    |

If you clone this repository, use the checkout commands to access the sources for the desired version.

## Overview

* [Getting Started with Camunda Platform](#getting-started-with-camunda-platform)
* [BPMN 2.0 & Process Implementation](#bpmn-20--process-implementation-examples)
* [Deployment & Project Setup](#deployment--project-setup-examples)
* [Process Engine Plugin](#process-engine-plugin-examples)
* [Bpmn 2.0 Model API](#bpmn-20-model-api-examples)
* [Cmmn 1.1 Model API Examples](#cmmn-11-model-api-examples)
* [Cockpit](#cockpit-examples)
* [Tasklist](#tasklist-examples)
* [Multi-Tenancy](#multi-tenancy-examples)
* [Spin](#spin-examples)
* [DMN](#dmn-examples)
* [Process Instance Migration](#process-instance-migration-examples)
* [SDK-JS Examples](#sdk-js-examples)
* [Authentication](#authentication)
* [Spring Boot Starter examples](#spring-boot-starter-examples)
* [Quarkus Extension Examples](#quarkus-extension-examples)
* [External Task Client](#external-task-client)
* [External Task Client Spring](#external-task-client-spring)
* [External Task Client Spring Boot](#external-task-client-spring-boot)
* [Testing](#testing)

### Getting Started with Camunda Platform

| Name                                                                                           | Container          |
|------------------------------------------------------------------------------------------------|--------------------|
| [Simple Process Applications](https://docs.camunda.org/get-started/bpmn20/)                    | All                |
| [Camunda Platform and the Spring Framework](https://docs.camunda.org/get-started/spring/) [^1] | Tomcat             |
| [Process Applications with JavaEE 6](https://docs.camunda.org/get-started/javaee6/) [^1]       | JavaEE Containers  |

### BPMN 2.0 & Process Implementation Examples

| Name                                                                                                             | Container         | Keywords                  |
|------------------------------------------------------------------------------------------------------------------|-------------------|---------------------------|
| [Service Task REST HTTP](/servicetask/rest-service)                                                              | Unit Test         | Rest Scripting, classless |
| [Service Task SOAP HTTP](/servicetask/soap-service) [^1]                                                         | Unit Test         | SOAP Scripting, classless |
| [Service Task SOAP CXF HTTP](/servicetask/soap-cxf-service) [^1]                                                 | Unit Test         | SOAP, CXF, Spring, Spin   |
| [Service Invocation Synchronous](/servicetask/service-invocation-synchronous)                                    | Unit Test         | Java Delegate, Sync       |
| [Service Invocation Asynchronous](/servicetask/service-invocation-asynchronous)                                  | Unit Test         | Signal, Async             |
| [User Task Assignment Email](/usertask/task-assignment-email) [^1][^2]                                           | All               | Email, Usertask           |
| [User Task Form Embedded](/usertask/task-form-embedded) [^2]                                                     | All               | Html, Form, Usertask      |
| [User Task Form Embedded - Serialized Java Object](/usertask/task-form-embedded-serialized-java-object) [^1][^2] | All               | Html, Form, Usertask      |
| [User Task Form Embedded - JSON](/usertask/task-form-embedded-json-variables) [^2]                               | All               | Html, Form, Usertask      |
| [User Task Form Embedded - Bpmn Elements](/usertask/task-form-embedded-bpmn-events) [^2]                         | All               | Html, Form, Usertask      |
| [User Task Form Embedded - React](/usertask/task-form-embedded-react) [^2]                                       | All               | Html, Form, Usertask      |
| [User Task Form - Camunda Forms](/usertask/task-camunda-forms) [^2]                                              | All               | Html, Form, Usertask      |
| [User Task Form Generated](/usertask/task-form-generated) [^1][^2]                                               | All               | Html, Form, Usertask      |
| [User Task Form JSF](/usertask/task-form-external-jsf) [^1][^2]                                                  | JavaEE Containers | JSF, Form, Usertask       |
| [Script Task XSLT](/scripttask/xslt-scripttask)                                                                  | Unit Test         | XSLT Scripttask           |
| [Script Task XQuery](/scripttask/xquery-scripttask) [^1]                                                         | Unit Test         | XQuery Scripttask         |
| [Start Event - Message](/startevent/message-start)                                                               | Unit Test         | Message Start Event       |
| [Start Process - SOAP CXF](/startevent/soap-cxf-server-start) [^1]                                               | War               | SOAP, CXF, Spring         |

### Deployment & Project Setup Examples

| Name                                                                                            | Container             |  Keywords                 |
|-------------------------------------------------------------------------------------------------|-----------------------|---------------------------|
| [Process Application - Servlet](deployment/servlet-pa)                                          | All                   | War, Servlet              |
| [Process Application - EJB](deployment/ejb-pa)                                                  | JavaEE Containers     | Ejb, War                  |
| [Process Application - Jakarta EJB](deployment/ejb-pa-jakarta)                                  | Jakarta EE Containers | Ejb, War                  |
| [Process Application - Spring 5 Servlet - WildFly](deployment/spring-servlet-pa-wildfly)        | WildFly               | Spring, Servlet, War      |
| [Process Application - Spring 5 Servlet - Embedded Tomcat](deployment/spring-servlet-pa-tomcat) | Tomcat                | Spring, Servlet, War      |
| [Embedded Spring 5 with embedded REST](deployment/embedded-spring-rest)                         | vanilla Apache Tomcat | Spring, Rest, Embedded    |
| [Plain Spring 5 Web application - WildFly](deployment/spring-wildfly-non-pa)                    | WildFly               | Spring, Jndi, War         |
| [Process Application - Spring Boot](deployment/spring-boot) [^1]                                | Spring Boot           | Spring                    |

### Process Engine Plugin Examples

| Name                                                                                            | Container            |  Keywords                                   |
|-------------------------------------------------------------------------------------------------|----------------------|---------------------------------------------|
| [BPMN Parse Listener](process-engine-plugin/bpmn-parse-listener)                                | Unit Test            | Process Engine Plugin, Bpmn Parse Listener  |
| [BPMN Parse Listener on User Task](process-engine-plugin/bpmn-parse-listener-on-user-task) [^1] | Unit Test            | Process Engine Plugin, Bpmn Parse Listener  |
| [Command Interceptor - Blocking](process-engine-plugin/command-interceptor-blocking)            | Unit Test            | Maintenance, Interceptor, Configuration     |
| [Custom History Level](process-engine-plugin/custom-history-level)                              | Unit Test            | Process Engine Plugin, Custom History Level |
| [Failed Job Retry Profile](process-engine-plugin/failed-job-retry-profile)                      | Unit Test            | Process Engine Plugin, Failed Job Retry     |

### Bpmn 2.0 Model API Examples

| Name                                                                 | Container            | Keywords                  |
|----------------------------------------------------------------------|----------------------|---------------------------|
| [Generate JSF forms](/bpmn-model-api/generate-jsf-form) [^1]         | JavaEE Containers    | JSF, Usertask             |
| [Generate BPMN process](/bpmn-model-api/generate-process-fluent-api) | Unit Test            | Fluent API                |
| [Parse BPMN model](/bpmn-model-api/parse-bpmn)                       | Unit Test            | BPMN                      |

### Cmmn 1.1 Model API Examples

| Name                                                                                             | Container            | Keywords                  |
|--------------------------------------------------------------------------------------------------|----------------------|---------------------------|
| [Strongly-typed Access to Custom Extension Elements](/cmmn-model-api/typed-custom-elements) [^1] | Unit Test            | CMMN, TransformListener   |

### Cockpit Examples

| Name                                                                                                           | Keywords                                  |
|----------------------------------------------------------------------------------------------------------------|-------------------------------------------|
| [Fullstack (ReactJS 16.x & Java) ""Count Processes"" Cockpit Plugin](/cockpit/cockpit-fullstack-count-processes) | Plugin, Custom Script, Fullstack, ReactJS |
| [Angular ""Open Usertasks"" Cockpit Tab](/cockpit/cockpit-angular-open-usertasks) [^1]                           | Plugin, Custom Script, Angular            |
| [AngularJS 1.x ""Search Processes"" Cockpit Plugin](/cockpit/cockpit-angularjs-search-processes) [^1]            | Plugin, Custom Script, AngularJS          |
| [ReactJS ""Involved Users"" Cockpit Plugin](/cockpit/cockpit-react-involved-users)                               | Plugin, Custom Script, ReactJS            |
| [""Cats"" Cockpit Plugin](/cockpit/cockpit-cats) [^1]                                                            | Plugin, Custom Script                     |
| [""Diagram interactions"" Cockpit Plugin](/cockpit/cockpit-diagram-interactions)                                 | Plugin, Custom Script                     |
| [""Open Incidents"" Cockpit Plugin](/cockpit/cockpit-open-incidents) [^1]                                        | Plugin, Custom Script                     |
| [""Request Interceptor"" Cockpit Script](/cockpit/cockpit-request-interceptor) [^1]                              | Plugin, Custom Script                     |
| [bpmn-js Cockpit module](/cockpit/cockpit-bpmn-js-module) [^1]                                                 | Plugin, Custom Script, bpmn-js            |
| [bpmn-js Cockpit module - bundled](/cockpit/cockpit-bpmn-js-module-bundled)                                    | Plugin, Custom Script, bpmn-js, rollup    |

### Tasklist Examples

| Name                                                                                                                                                                    | Keywords                  |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------|
| [Create Standalone Task - client side](https://github.com/camunda/camunda-bpm-platform/tree/master/webapps/frontend/ui/tasklist/plugins/standaloneTask/app)             | Plugin                    |
| [Create Standalone Task - server side](https://github.com/camunda/camunda-bpm-platform/blob/master/webapps/assembly/src/main/java/org/camunda/bpm/tasklist/impl/plugin) | Plugin                    |
| [Javascript Only Plugin](/tasklist/cats-plugin)                                                                                                                         | Plugin, Custom Script     |
| [JQuery 3.4 Behavior Patch](/tasklist/jquery-34-behavior) [^1]                                                                                                          | Plugin, Custom Script     |


### SDK-JS Examples

| Name                                           | Environment | Keywords                    |
|------------------------------------------------|-------------|-----------------------------|
| [SDK JS forms](/sdk-js/browser-forms) [^1][^2] | Browser     | HTML, task, form, SDK       |

### Multi-Tenancy Examples

| Name                                                                                                                       | Container | Keywords      |
|----------------------------------------------------------------------------------------------------------------------------|-----------|---------------|
| [Multi-Tenancy with Database Schema Isolation](multi-tenancy/schema-isolation)                                             | Wildfly   | Multi-Tenancy |
| [Multi-Tenancy with Tenant Identifiers for Embedded Process Engine](multi-tenancy/tenant-identifier-embedded)              | Unit Test | Multi-Tenancy |
| [Multi-Tenancy with Tenant Identifiers for Shared Process Engine](multi-tenancy/tenant-identifier-shared)                  | All       | Multi-Tenancy |
| [Multi-Tenancy with Tenant Identifiers and Shared Process Definitions](multi-tenancy/tenant-identifier-shared-definitions) | Unit Test | Multi-Tenancy |

### Spin Examples

| Name                                                                                                                                           | Container          | Keywords                           |
|------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|------------------------------------|
| [Global Data Format Configuration to Customize JSON serialization](spin/dataformat-configuration-global)                                       | Unit Test          | Spin, Configuration                |
| [Process-Application-Specific Data Format Configuration to Customize JSON serialization](spin/dataformat-configuration-in-process-application) | Application Server | Spin, Configuration, Shared Engine |

### DMN Examples

| Name                                                                                  | Container | Keywords        |
|---------------------------------------------------------------------------------------|-----------|-----------------|
| [Embed Decision Engine - Dish Decision Maker](dmn-engine/dmn-engine-java-main-method) | Jar       | DMN, Embed      |
| [Decision Requirements Graph(DRG) Example](dmn-engine/dmn-engine-drg)                 | Jar       | DMN, DRG, Embed |

### Process Instance Migration Examples

| Name                                                                              | Container                             | Keywords        |
|-----------------------------------------------------------------------------------|---------------------------------------|-----------------|
| [Migration on Deployment of New Process Version](migration/migrate-on-deployment) | Application Server with Shared Engine | BPMN, Migration |

### Authentication

| Name                                              | Container                                                                  | Keywords                |
|---------------------------------------------------|----------------------------------------------------------------------------|-------------------------|
| [Basic Authentication](authentication/basic) [^1] | Spring boot with embedded engine, REST API and Basic Authentication filter |  Authentication         |

### Spring Boot Starter examples

| Name                                                              | Container                                              | Keywords                              |
|-------------------------------------------------------------------|--------------------------------------------------------|---------------------------------------|
| [Plain Camunda Engine](spring-boot-starter/example-simple)        | Jar                                                    | Spring Boot Starter                   |
| [Webapps](spring-boot-starter/example-webapp)                     | Spring boot with embedded engine and Webapps           | Spring Boot Starter, Webapps          |
| [Webapps EE](spring-boot-starter/example-webapp-ee)               | Spring boot with embedded engine and Webapps           | Spring Boot Starter, Webapps          |
| [REST API](spring-boot-starter/example-web)                       | Spring boot with embedded engine and Webapps           | Spring Boot Starter, REST API         |
| [Twitter](spring-boot-starter/example-twitter)                    | Spring boot with embedded engine and Webapps           | Spring Boot Starter, Webapps, Twitter |
| [Camunda Invoice Example](spring-boot-starter/example-invoice)    | Spring boot with embedded engine, Webapps and Rest API | Spring Boot Starter, REST API         |
| [Autodeployment](spring-boot-starter/example-autodeployment) [^1] | Spring boot with embedded engine and Webapps           | Spring Boot Starter                   |
| [REST API DMN](spring-boot-starter/example-dmn-rest) [^1]         | Spring boot with embedded engine and Webapps           | Spring Boot Starter, REST API         |

### Quarkus Extension Examples

| Name                                                              | Container                                                                  | Keywords                |
|-------------------------------------------------------------------|----------------------------------------------------------------------------|-------------------------|
| [Datasource Example](quarkus-extension/datasource-example)        | Uber-Jar                                                                   |  Quarkus Extension      |
| [Spin Plugin Example](quarkus-extension/spin-plugin-example)      | Uber-Jar                                                                   |  Quarkus Extension      |
| [Simple REST Example](quarkus-extension/simple-rest-example) [^1] | Uber-Jar                                                                   |  Quarkus Extension      |

### External Task Client

| Name                                                                                                                         | Environment                         | Keywords                          |
|------------------------------------------------------------------------------------------------------------------------------|-------------------------------------|-----------------------------------|
| [Order Handling - Java](./clients/java/order-handling)                                                                       | Java External Task Client           | External Task Client, Servicetask |
| [Loan Granting - Java](./clients/java/loan-granting) [^1]                                                                    | Java External Task Client           | External Task Client, Servicetask |
| [Dataformat - Java](./clients/java/dataformat) [^1]                                                                          | Java External Task Client           | External Task Client, Servicetask |
| [Loan Granting - JavaScript](https://github.com/camunda/camunda-external-task-client-js/tree/master/examples/granting-loans) | JavaScript External Task Client     | External Task Client, Servicetask |
| [Order Handling - JavaScript](https://github.com/camunda/camunda-external-task-client-js/tree/master/examples/order)         | JavaScript External Task Client     | External Task Client, Servicetask |
 
### External Task Client Spring

| Name                                                                                     | Keywords                          |
|------------------------------------------------------------------------------------------|-----------------------------------|
| [Loan Granting Example](./spring-boot-starter/external-task-client/loan-granting-spring) | External Task Client, Servicetask |

### External Task Client Spring Boot

| Name                                                                                                                      | Container                                           | Keywords                                               |
|---------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------|--------------------------------------------------------|
| [Loan Granting w/ REST API & Webapp Example](./spring-boot-starter/external-task-client/loan-granting-spring-boot-webapp) | Spring Boot with embedded Client, REST API & Webapp | External Task Client, Servicetask, Spring Boot Starter |
| [Order Handling Example](./spring-boot-starter/external-task-client/order-handling-spring-boot) [^1]                      | Spring Boot with embedded Client                    | External Task Client, Servicetask, Spring Boot Starter |
| [Request Interceptor Example](./spring-boot-starter/external-task-client/request-interceptor-spring-boot) [^1]            | Spring Boot with embedded Client                    | External Task Client, Servicetask, Spring Boot Starter |

### Container Specifics

| Name                                                                  | Container | Keywords     |
|-----------------------------------------------------------------------|-----------|--------------|
| [Jackson Annotation Example for WildFly](wildfly/jackson-annotations) | Wildfly   | War, Servlet |

### Testing

| Name                                                                                                 | Keywords                 |
|------------------------------------------------------------------------------------------------------|--------------------------|
| [Assert](testing/assert/job-announcement-publication-process)                                        | Testing, Junit 4, Assert |
| [Assert and JUnit 5](testing/junit5/camunda-bpm-junit-assert/)                                       | Testing, Junit 5, Assert |
| [Assert and Junit 5: configure a custom process engine](testing/junit5/camunda-bpm-junit-use-engine) | Testing, Junit 5, Assert |

## Contributing

Have a look at our [contribution guide](https://github.com/camunda/camunda-bpm-platform/blob/master/CONTRIBUTING.md) for how to contribute to this repository.

## License
The source files in this repository are made available under the [Apache License Version 2.0](./LICENSE).

[^1]: _This example is not actively maintained anymore._

[^2]: _Complete demo applications_
"
oracle-samples/oracle-db-examples,main,1264,813,2017-02-27T18:53:21Z,55575,17,Examples of applications and tool usage for Oracle Database,database java oracle oracle-11g oracle-12c oracle-19c oracle-autonomous-database oracle-database oracle-db sql,"# oracle-db-examples
This repository stores a variety of examples demonstrating how to use the Oracle Database. 

| Repo/Folder name  | Description |
| ------------- | ------------- |
| [C](./C) | C examples |
| [apex](./apex) | APEX examples |
| [db-sample-schemas](https://github.com/oracle/db-sample-schemas) | Git submodule of the Oracle Database Sample Schemas |
| [dotnet](https://github.com/oracle/dotnet-db-samples) | .NET based examples |
| [exadata](./exadata) | Exadata examples |
| [java](./java)  | Java examples |
| [javascript](./javascript) | JavaScript examples |
| [machine-learning](./machine-learning) | Oracle Machine Learning examples |
| [optimizer](./optimizer) | Oracle Optmizer and Optimizer Stats examples |
| [plsql](./plsql) | PL/SQL examples |
| [python](./python) | Python examples |
| [ruby](./ruby) | Ruby examples |
| [sagas](./sagas) | Saga examples |
| [security](./security) | Security features examples |
| [spatial](./spatial) | Spatial features examples |
| [sql](./sql) | SQL examples |
| [sqldeveloper](./sqldeveloper) | [SQL Developer](http://www.oracle.com/technetwork/developer-tools/sql-developer/) examples |
| [txeventq](./txeventq) | TxEventQ examples |

## Documentation
You can find the online documentation of the Oracle Database under [docs.oracle.com/en/database/](http://docs.oracle.com/en/database/)

## LiveSQL
Some of the examples that you see within this repository can be executed in the free web-based tool: [LiveSQL.oracle.com](https://livesql.oracle.com).

LiveSQL is also an excellent resource for getting started with Oracle Database.

## Dev Gym
If you would like to challenge yourself, you can take quizzes, workouts and classes at [DevGym.oracle.com](https://devgym.oracle.com).

## Contributing

This project welcomes contributions from the community. Before submitting a pull request, please [review our contribution guide](./CONTRIBUTING.md)

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process

## License

You may not use the identified files except in compliance with the
Apache License, Version 2.0 (the ""License."")

You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0.  A copy of the license is
also reproduced in [LICENSE.md](./LICENSE.md)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied.

See the License for the specific language governing permissions and
limitations under the License.
"
anarsultanov/examples,master,109,130,2019-06-11T18:09:02Z,156,9,Examples for my blog posts.,,"# examples
![CodeQL](https://github.com/anarsultanov/examples/workflows/CodeQL/badge.svg)

This project is a collection of examples for articles on **[my blog](https://sultanov.dev/)**.

"
java9-modularity/examples,master,160,104,2017-07-10T19:41:50Z,19321,0,"Contains all code examples from the Java 9 Modularity book, organized by chapter.",,"![Java 9 Modularity cover](java9modularity-flat-cover.png)

This repository contains all the example code from the [Java 9 Modularity book](http://shop.oreilly.com/product/0636920049494.do).
The examples are grouped by chapter in the book:

2. Modules and Modular JDK
3. Working with Modules
4. Services
5. Modularity Patterns
6. Advanced Modularity Patterns
7. Migration Without Modules
8. Migration to Modules
9. Migration Case Study: Spring and Hibernate
10. Library Migration
11. Build Tools and IDEs
12. Testing Modules

Most examples contain a `run.sh` file to compile and run the example.
The scripts are tested on Mac OS and Linux. Windows users can use the Linux Subsystem for Windows, or use Cygwin to run the scripts.
Some examples demonstrate errors, which means that compiling or running them may fail on purpose.
A README is available in each example directory to explain the example.
"
mapstruct/mapstruct-examples,main,1233,506,2013-07-07T15:38:42Z,827,31,Examples for using MapStruct,,"# MapStruct Examples

This repository contains examples showing how to use [MapStruct](http://mapstruct.org/), a Java annotation processor for the generation of type-safe bean mapping classes.

Currently, the following examples exist:

* [_mapstruct-on-ant_](mapstruct-on-ant): Shows how to use MapStruct in Ant-based projects; to build this example, run `ant build` on the command line
* [_mapstruct-on-gradle_](mapstruct-on-gradle): Shows how to use MapStruct in Gradle-based projects; to build the example project, run `./gradlew clean build` on the command line
* [_mapstruct-on-bazel_](mapstruct-on-bazel): Shows how to use MapStruct in Bazel-based projects; to build the example project, run `bazel build //...` on the command line, to test the project, run `bazel test //...`.
* [_mapstruct-lombok_](mapstruct-lombok): Shows how to use MapStruct together with Lombok (with both a Maven `pom.xml` and a Gradle `build.gradle`); to build the example project, run either `mvn clean install` or `./gradlew clean build` on the command line
* [_mapstruct-iterable-non-iterable_](mapstruct-iterable-to-non-iterable): Shows how by means of a mapper util class conversions can be made from an iterable- to its non-iterable element
* [_mapstruct-mapping-from-map_](mapstruct-mapping-from-map): Shows how by means of a mapper util class and qualifiers extracting value can be carried out on Maps. Watch [mapstruct/mapstruct#1075](https://github.com/mapstruct/mapstruct/issues/1075) for native support.
* [_mapstruct-rounding_](mapstruct-rounding): Shows how by means of a mapper util class and qualifiers roundings can be carried out on Numbers
* [_mapstruct-updatemethods_](mapstruct-updatemethods-1): Shows how to update an existing target object
* [_mapstruct-field-mapping_](mapstruct-field-mapping): Shows how MapStruct can be used with ""struct"" like objects with public fields
* [_mapstruct-nested-bean-mappings_](mapstruct-nested-bean-mappings): Shows how to map object graphs via a main root method
* [_mapstruct-mapping-with-cycles_](mapstruct-nested-bean-mappings): Shows how to map object graphs that can contain cycles
* [_mapstruct-spi-accessor-naming_](mapstruct-spi-accessor-naming): Example on how to use the Service Provider Interface (SPI) for a custom accessor naming strategy.
* [_mapstruct-protobuf3_](mapstruct-protobuf3): Example on how to use protobuf3 with MapStruct
* [_mapstruct-kotlin_](mapstruct-kotlin): Example on how to use MapStruct with Kotlin using KAPT (Kotlin Annotation Processing Tool)
* [_mapstruct-kotlin-gradle_](mapstruct-kotlin-gradle): Example on how to use MapStruct with Kotlin and Gradle Kotlin DSL using KAPT
* [_mapstruct-jpa-child-parent_](mapstruct-jpa-child-parent): Example on how to use @Context in relation to parent / child relations in JPA)
* [_mapstruct-suppress-unmapped_](mapstruct-suppress-unmapped): Shows how mapping to target properties can be ignored without warning by default in a mixed scenario. However bean property mappings that have the same name will still be applied.
* [_mapstruct-lookup-entity-with-id_](mapstruct-lookup-entity-with-id): Shows how an object with composite key can be read from the database in a mapping method.
* [_mapstruct-clone_](mapstruct-clone): Shows how an object can be deeply cloned by defining all mapping methods.
* [_mapstruct-metadata-annotations_](mapstruct-metadata-with-annotations): Demonstrates how to read annotations and use them as mapping instruction.
* [_mapstruct-mappers-repo_](mapstruct-mapper-repo): Demonstrates how one can build a repo of mappers by means of code generation.

## License

The examples in this project are licensed under the Apache License, Version 2.0.
"
nanchen2251/RxJava2Examples,master,2845,611,2017-06-19T05:38:45Z,9598,5,:fire:RxJava2 Examples —— 这可能是从 RxJava1 跳到 RxJava2（学习 RxJava2 ）最好的例子 Demo：https://github.com/nanchen2251/RxJava2Examples,,"# RxJava2Examples
### RxJava2 Examples——它可能是从RxJava1跳到RxJava2（学习RxJava2）最好的例子Demo

> RxJava 1.x 到 RxJava 2.x 的无缝对接  
无需学习 RxJava 1.x, 直接学习 RxJava 2.x  
完备齐全的操作符示例  
支持与 Retrofit 交互处理示例  
Activity 基类封装处理 

### 文章链接：
[这可能是最好的 RxJava 2.x 入门教程（完结版）](http://www.jianshu.com/p/0cd258eecf60)<br>
[这可能是最好的 RxJava 2.x 入门教程（一）](http://www.jianshu.com/p/a93c79e9f689)<br>
[这可能是最好的 RxJava 2.x 入门教程（二）](http://www.jianshu.com/p/b39afa92807e)<br>
[这可能是最好的 RxJava 2.x 入门教程（三）](http://www.jianshu.com/p/e9c79eacc8e3)<br>
[这可能是最好的 RxJava 2.x 入门教程（四）](http://www.jianshu.com/p/c08bfc58f4b6)<br>
[这可能是最好的 RxJava 2.x 入门教程（五）](http://www.jianshu.com/p/81fac37430dd)<br>


### 关于作者
    南尘<br>
    四川成都<br>
    [其它开源](https://github.com/nanchen2251/)<br>
    [个人博客](https://nanchen2251.github.io/)<br>
    [简书](http://www.jianshu.com/u/f690947ed5a6)<br>
    [博客园](http://www.cnblogs.com/liushilin/)<br>
    交流群：118116509 <a target=""_blank"" href=""//shang.qq.com/wpa/qunwpa?idkey=e6ad4af66393684e1d0c9441403b049d2d5670ec0ce9f72150e694cbb7c16b0a""><img border=""0"" src=""http://pub.idqqimg.com/wpa/images/group.png"" alt=""Android神技侧漏交流群"" title=""Android神技侧漏交流群""></a>( 点击图标即可加入 )<br>
    欢迎投稿(关注)我的唯一公众号，公众号搜索 nanchen 或者扫描下方二维码：<br>
    ![](https://github.com/nanchen2251/Blogs/blob/master/images/nanchen12.jpg)
    

### Just a gif
![](https://github.com/nanchen2251/RxJava2Examples/blob/master/GIF.gif)

### RxJava 1.x 到 RxJava 2.x 变化一览

RxJava 1.x -> RxJava 2.x

* `onCompleted` -> `onComplete` - without the trailing d
* `Func1` -> `Function`
* `Func2` -> `BiFunction`
* `CompositeSubscription` -> `CompositeDisposable`
* `limit` operator has been removed - Use `take` in RxJava2
* and much more.

### 一些操作符的解释

* `Map` -> transform the items emitted by an Observable by applying a function to each item
* `Zip` -> combine the emissions of multiple Observables together via a specified function and emit single items for each combination based on the results of this function
* `Filter` -> emit only those items from an Observable that pass a predicate test
* `FlatMap` -> transform the items emitted by an Observable into Observables, then flatten the emissions from those into a single Observable
* `Take` -> emit only the first n items emitted by an Observable
* `Reduce` -> apply a function to each item emitted by an Observable, sequentially, and emit the final value
* `Skip` -> suppress the first n items emitted by an Observable
* `Buffer` -> periodically gather items emitted by an Observable into bundles and emit these bundles rather than emitting the items one at a time
* `Concat` -> emit the emissions from two or more Observables without interleaving them
* `Replay` -> ensure that all observers see the same sequence of emitted items, even if they subscribe after the Observable has begun emitting items
* `Merge` -> combine multiple Observables into one by merging their emissions

### 尽情地下载运行，开始感受RxJava 2.x 的强大魅力吧~

### 为这个例子pull你的伟大代码，加入分享这个大家庭，Just to do!


### 该例子借鉴了以下项目：
 * [https://github.com/amitshekhariitbhu/RxJava2-Android-Samples](https://github.com/amitshekhariitbhu/RxJava2-Android-Samples) 

    
#### 有码走遍天下 无码寸步难行（引自网络）

> 1024 - 梦想，永不止步!  
爱编程 不爱Bug  
爱加班 不爱黑眼圈  
固执 但不偏执  
疯狂 但不疯癫  
生活里的菜鸟  
工作中的大神  
身怀宝藏，一心憧憬星辰大海  
追求极致，目标始于高山之巅  
一群怀揣好奇，梦想改变世界的孩子  
一群追日逐浪，正在改变世界的极客  
你们用最美的语言，诠释着科技的力量  
你们用极速的创新，引领着时代的变迁  
  
------至所有正在努力奋斗的程序猿们！加油！！  
    
## Licenses
```
 Copyright 2017 nanchen(刘世麟)

 Licensed under the Apache License, Version 2.0 (the ""License"");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an ""AS IS"" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
```


"
lokeshgupta1981/SpringExamples,master,293,648,2018-05-05T07:17:17Z,213,1,Initial Commit,,"# Spring Boot Examples by HowToDoInJava.com

This repository hosts the projects and their source codes written for various tutorials written in [howtodoinjava.com](https://howtodoinjava.com/)."
apache/struts-examples,master,420,551,2014-03-11T07:00:06Z,4033,8,Mirror of Apache Struts,java struts web-framework,"# Struts Examples

[![Build Status @ ASF](https://ci-builds.apache.org/buildStatus/icon?job=Struts%2FStruts-examples-master)](https://ci-builds.apache.org/job/Struts/job/Struts-examples-master/)
[![Build Status @ GH Actions](https://github.com/apache/struts-examples/actions/workflows/maven.yml/badge.svg)](https://github.com/apache/struts-examples/actions/workflows/maven.yml)
[![License](http://img.shields.io/:license-apache-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

This Maven multi-module project contains all the Struts 2 example applications that are part of the Getting Started Struts 2 tutorials at http://struts.apache.org.

To build all the example applications run the Maven command:

```
mvn -e clean package
```

In the project's root folder, Maven will build each module and create a `.war` file in the target sub-folder of each module.

You can then copy the `.war` files to your Servlet container (e.g. Tomcat, Jetty, GlassFish, etc).

There is a README file in each module with instructions and the URL to view that application.
"
camunda-consulting/camunda-7-code-examples,main,594,999,2013-04-04T15:31:22Z,126720,527,Examples and demo applications built by the camunda consulting team,,"Camunda Consulting Examples
===========================

This repository contains examples, code snippets and demo applications build by the Camunda Consulting Team
or contributors. Note: All examples are only tested manually and there is no guarantee that they are actively maintained. If you search for officially maintained examples go to <a href=""https://github.com/camunda/camunda-bpm-examples"">https://github.com/camunda/camunda-bpm-examples</a>.

<table>
  <tr>
    <th>Type of Example</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><a href=""https://github.com/camunda/camunda-consulting/tree/master/snippets"">Snippets</a></td>
    <td>Code snippets for particular technical issues. <b>The code is not maintained and might be out-of-date.</b></td>
  </tr>
  <tr>
    <td><a href=""https://github.com/camunda/camunda-consulting/tree/master/one-time-examples"">One-time Examples</a></td>
    <td>Examples created once for a specific event (like a conference or a magazine article). <b>The code is not maintained and might be out-of-date.</b></td>
  </tr>
</table>

<b>Please add a README.md with a short project description and how to use it whenever you add a new snippet or example.</b>
"
rhwayfun/spring-boot-learning-examples,develop,1561,569,2017-03-28T00:50:20Z,372,7,Spring Boot工程实践，快速上手Spring Boot开发必备。最全的Spring Boot使用案例！,springboot,"# 最全的Spring Boot实践指南
![travis](https://travis-ci.org/rhwayfun/spring-boot-learning-examples.svg?branch=develop)
[![codecov](https://codecov.io/gh/rhwayfun/spring-boot-learning-examples/branch/develop/graph/badge.svg)](https://codecov.io/gh/rhwayfun/spring-boot-learning-examples)
[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/spring-boot-learning-examples/chat)
[![license](https://img.shields.io/badge/license-EPL%201.0-green.svg)](https://choosealicense.com/licenses/epl-1.0/)

Spring Boot知识点整理、工程实践，并结合工作案例进行深入

* 使用travis-ci持续集成
* 使用codecov进行代码覆盖率检查
* 学习案例以模块方式划分，每隔模块都是独立可执行项目，直接运行Application即可

## 分享平台

> 博客：http://blog.csdn.net/u011116672

> Github：https://github.com/rhwayfun

## 项目模块
```
└── 基础入门
└── Web开发
    └── Weex
    └── Bootstrap
    └── thymeleaf
└── 缓存使用
    └── Ehcache
    └── Caffeine
    └── Guava Cache
└── 数据库
    └── Mybatis
    └── MySQL
└── Spring其他功能
    └── Spring Task
    └── Spring Retry
    └── Spring AOP
└── 企业开发进阶
    └── Dubbo（阿里开源的分布式服务治理框架）
    └── Kafka
    └── RocketMQ
    └── Sharding-JDBC
    └── Disconf
    └── Elsaticsearch
    └── Elsatic-job
    └── Redis
    └── MongoDB
    └── Mockito
    └── InfluxDB
    └── Ignite
    └── Geode
    └── ...
```

### 基础入门

* spring-boot-quickstart（Spring Boot快速入门案例）
* spring-boot-configuration（了解下Spring Boot配置管理）

### web开发

* spring-boot-web-jsp（使用JSP作为开发）
* spring-boot-web-thymeleaf（使用模板引擎thymeleaf开发）
* spring-boot-web-bootstrap（bootstrap入门demo）
* spring-boot-security（权限控制项目实战）
    
    [spring security实战](http://blog.csdn.net/u011116672/article/details/77428049)
    
* spring-boot-security-cas（集成CAS搭建自己的认证中心）
    

### 缓存使用
* spring-boot-cache-caffeine（高性能本地缓存框架caffeine实践）
* spring-boot-cache-ehcache（Java应用最多的本地缓存Ehcache实践）
* spring-boot-redis（分布式KV缓存redis实践）

### 数据库
* spring-boot-mybatis（mybatis使用快速入门）
* spring-boot-mybatis-annotation（mybatis全注解使用示例）
* spring-boot-mybatis-multidatasource（mybatis多数据库解决方案）
* spring-boot-mybatis-sharding-jdbc（使用sharding-jdbc对数据库进行分库分表）
    
    [Sharding-JDBC分库分表使用实例](http://blog.csdn.net/u011116672/article/details/78374724)
    
* spring-boot-mybatis-sharding-jdbc-masterslave（使用sharding-jdbc完成分库分表+读写分离）
    
    [Sharding-JDBC读写分离探秘](http://blog.csdn.net/u011116672/article/details/78576117)

### Spring其他功能
* spring-boot-task（定时任务）

    [Spring定时任务源码分析](http://blog.csdn.net/u011116672/article/details/77132205)
    
    [深入浅出Spring task定时任务](http://blog.csdn.net/u011116672/article/details/52517247)
    
* spring-boot-retry（重试和熔断）

    [重试框架Spring retry实践](http://blog.csdn.net/u011116672/article/details/77823867)
    
* spring-boot-aspect（aop相关，静态织入、动态织入）
    
    [AspectJ切面执行两次原因分析](http://blog.csdn.net/u011116672/article/details/63685340)


### 企业开发进阶
* spring-boot-dubbo（服务治理框架dubbo使用案例）
* spring-boot-dubbo-annotation（服务治理框架dubbo案例，基于注解实现）

    [dubbo-spring-boot-project](https://github.com/apache/incubator-dubbo-spring-boot-project)

* spring-boot-dubbo-extension（基于duboo扩展点实现自定义扩展）
* spring-boot-disconf（分布式配置管理disconf使用案例）
* spring-boot-elasticsearch（全文搜索引擎elasticsearch实践）
* spring-boot-mongodb（NoSQL数据库mongodb实战）
* spring-boot-kafka（消息中间件kafka实践）
* spring-boot-rocketmq（阿里开源消息中间件RocketMQ实践）

    spring-boot-rocketmq-starter使用案例

* spring-boot-rocketmq-starter（阿里开源消息中间件RocketMQ Spring Boot Starter）
    
    [spring-boot-rocketmq-starter 使用指南](apache-rocketmq-starter-guide.md)
    
    [spring-boot-rocketmq-starter](https://github.com/rhwayfun/spring-boot-rocketmq-starter)
    
* spring-boot-mockito（Java社区最火的测试框架Mockito使用实战）
* spring-boot-hibernate-validation（Hibernate出品的校验框架使用实战）
* spring-boot-geode（内存数据库geode实战，目前应用与内部地址位置距离的计算）
* spring-boot-ignite（内存数据库ignite实战）
* spring-boot-elastic-job（分布式任务调度框架elastic-job实战）
* spring-boot-starter（自定义spring boot starter）
* spring-boot-starter-rest（自定义spring boot starter）
* spring-boot-logging-log4j2（使用log4j2）
* spring-boot-influxdb（时序数据库influxDB实践）
* spring-boot-mybatis-sharding-jdbc（分库分表Sharding-JDBC实践）

## 准备工作

> [数据库脚本](docs/sql/springboot/spring-boot-mybatis.sql)

### 安装MySQL

### 添加用户`travis`

 ```
 create user travis@localhost;
 ```
### 授权

```
grant all privileges on *.* to travis@localhost;/* mac系统下localhost要改成127.0.0.1 */      
```

### 查看权限

```
/*      查看MySQL所有用户      */
SELECT DISTINCT CONCAT('User: ''',user,'''@''',host,''';') AS query FROM mysql.user;
/*      查看travis用户的权限      */
show grants for travis@localhost; 
```

### 编译运行

```
mvn clean compile
mvn clean package
```


## 未完待续
更多案例不断补充中。。。如果您觉得对你有用，就给我点个赞吧\(^o^)/~


"
pkainulainen/spring-data-jpa-examples,master,657,733,2013-05-25T19:30:21Z,587,7,,,"# Test With Spring Course

If you are struggling to write good automated tests for Spring web applications, you are not alone! [I have launched a video course](https://www.testwithspring.com/?utm_source=github&utm_medium=social&utm_content=spring-data-jpa&utm_campaign=test-with-spring-course-presales) that describes how you can write automated tests which embrace change and help you to save your time (and nerves).

# Spring Data JPA Tutorial

This repository contains the example applications of my [Spring Data JPA tutorial](http://www.petrikainulainen.net/spring-data-jpa-tutorial/). The READMEs of the examples provide more information about the application in question.
"
springframeworkguru/spring5webapp,master,705,17935,2017-05-16T00:00:24Z,137,118,Example Spring 5 Web Application,,"# Spring Framework 5: Beginner to Guru

This repository is for an example application built in my [Spring Framework 5 - Beginner to Guru](https://www.udemy.com/testing-spring-boot-beginner-to-guru/?couponCode=GITHUB_REPO) online course

The application is a simple Spring Boot 2 / Spring Framework 5 web application. It is used to help students learn how
to use the Spring Framework. Step by step instructions and detailed explanations can be found within the course.

As you work through the course, please feel free to fork this repository to your out GitHub repo. Most links contain links 
to source code changes. If you encounter a problem you can compare your code to the lesson code. [See this link for help with compares](https://github.com/springframeworkguru/spring5webapp/wiki#getting-an-error-but-cannot-find-what-is-different-from-lesson-source-code)

## Spring Framework 5: Beginner to Guru Course Wiki
Got a question about your Spring Framework 5 course? [Checkout these FAQs!](https://github.com/springframeworkguru/spring5webapp/wiki)

## Getting Your Development Environment Setup
### Recommended Versions
 | Recommended | Reference | Notes |
| ----------- | --------- | ----- |
| Oracle Java 11 JDK | [Download]([https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html](https://www.oracle.com/java/technologies/javase/jdk11-archive-downloads.html)) | Java 8 or Java 17 may also be used. |
| IntelliJ 2018 or Higher | [Download](https://www.jetbrains.com/idea/download/) | Ultimate Edition recommended. Students can get a free 120 trial license [here](https://github.com/springframeworkguru/spring5webapp/wiki/Which-IDE-to-Use%3F#how-do-i-get-the-free-120-day-trial-to-intellij-ultimate) |
| Maven 3.6.0 or higher | [Download](https://maven.apache.org/download.cgi) | [Installation Instructions](https://maven.apache.org/install.html)|
| Gradle 4.8 or higher | [Download](https://gradle.org/install/) | **Note:** Use Version 5 or higher if using Java 11 |
| Git 2.15 or higher | [Download](https://git-scm.com/downloads) | | 
| Git GUI Clients | [Downloads](https://git-scm.com/downloads/guis) | Not required. But can be helpful if new to Git. SourceTree is a good option for Mac and Windows users. |
| Spring Boot 2.1 or higher | [What's new](https://content.pivotal.io/springone-platform-2017/whats-new-in-spring-boot-2-0-phillip-webb-madhura-bhave) | | 

## All Spring Framework Guru Courses
### Spring Framework 5
* [Spring Framework 5: Beginner to Guru](https://www.udemy.com/testing-spring-boot-beginner-to-guru/?couponCode=GITHUB_REPO) - Get the most modern and comprehensive course available for the Spring Framework! Join over 17,200 over Guru's in an Slack community exclusive to this course! More than 5,700 students have given this 53 hour course a 5 star review!
* [Spring Boot Microservices with Spring Cloud Beginner to Guru](https://www.udemy.com/course/spring-boot-microservices-with-spring-cloud-beginner-to-guru/?referralCode=6142D427AE53031FEF38) - Master Microservice Architectures Using Spring Boot 2 and Cloud Based Deployments with Spring Cloud and Docker
* [Reactive Programming with Spring Framework 5](https://www.udemy.com/reactive-programming-with-spring-framework-5/?couponCode=GITHUB_REPO_SF5B2G) - Keep your skills razor sharp and take a deep dive into Reactive Programming!
* [Testing Spring Boot: Beginner to Guru](https://www.udemy.com/testing-spring-boot-beginner-to-guru/?couponCode=GITHUB_REPO_SF5B2G) - ** Best Selling Course** Become an expert in testing Java and Spring Applications with JUnit 5, Mockito and much more!

### SQL
* [SQL Beginner to Guru: MySQL Edition](https://www.udemy.com/sql-beginner-to-guru-mysql-edition/?couponCode=GITHUB_REPO_SF5B2G) - SQL is a fundamental must have skill, which employers are looking for. Learn to master SQL on MySQL, the worlds most popular database!

### DevOps
* [Apache Maven: Beginner to Guru](https://www.udemy.com/apache-maven-beginner-to-guru/?couponCode=GITHUB_REPO_SF5B2G) - **Best Selling Course** Take the mystery out of Apache Maven. Learn how to use Maven to build your Java and Spring Boot projects!
* [OpenAPI: Beginner to Guru](https://www.udemy.com/course/openapi-beginner-to-guru/?referralCode=0E7F511C749013CA6AAD) - Master OpenAPI (formerly Swagger) to Create Specifications for Your APIs
* [Docker for Java Developers](https://www.udemy.com/docker-for-java-developers/?couponCode=GITHUB_REPO_SF5B2G) - Best Selling Course on Udemy! Learn how you can supercharge your development by leveraging Docker. Collaborate with other students in a Slack community exclusive to the course!
* [Spring Framework DevOps on AWS](https://www.udemy.com/spring-core-devops-on-aws/?couponCode=GITHUB_REPO_SF5B2G) - Learn how to build and deploy Spring applications on Amazon AWS!
* [Ready for Production with Spring Boot Actuator](https://www.udemy.com/ready-for-production-with-spring-boot-actuator/?couponCode=GITHUB_REPO_SF5B2G) - Learn how to leverage Spring Boot Actuator to monitor your applications running in production.

### Web Development with Spring Framework
* [Mastering Thymeleaf with Spring Boot](https://www.udemy.com/mastering-thymeleaf-with-spring/?couponCode=GITHUB_REPO_SF5B2G) - Once you learn Thymeleaf, you'll never want to go back to using JSPs for web development!


## Connect with Spring Framework Guru
* Spring Framework Guru [Blog](https://springframework.guru/)
* Subscribe to Spring Framework Guru on [YouTube](https://www.youtube.com/channel/UCrXb8NaMPQCQkT8yMP_hSkw)
* Like Spring Framework Guru on [Facebook](https://www.facebook.com/springframeworkguru/)
* Follow Spring Framework Guru on [Twitter](https://twitter.com/spring_guru)
* Connect with John Thompson on [LinkedIn](http://www.linkedin.com/in/springguru)
"
marhan/effective-java-examples,master,579,464,2011-02-25T20:23:49Z,459,1,"Source code to the book Effective Java Second Edition"" created by Joshua Bloch""",,"# Effective Java Examples

This are the souces from the book ""Effective Java Second Edition"", written by Joshua Bloch.

They are unmodifed, except the package names.

The original source are downloaded from http://java.sun.com/docs/books/effective/index.html, but are no longer provided.

"
maxliaops/Java_Web_Examples,master,609,436,2014-04-24T09:36:13Z,105216,0,《实战突击：Java Web项目整合开发》源码,,"Java_Web_Examples
=================

《实战突击：Java Web项目整合开发》源码

01 - 都市供求信息网
02 - 物流配货网
03 - 编程爱好者博客地带
04 - 明日知道
05 - 天下陶网络商城
06 - 网络在线考试
07 - 物资管理系统
08 - 企业办公自动化系统
09 - 校园管理系统
10 - 高校学生选课系统
11 - MR网络购物中心
12 - 图书馆管理系统
13 - 讯友网络相册
14 - 企业门户网站
15 - 芝麻开门博客网
16 - 进销存管理系统
17 - 网上淘书吧
18 - 新奥家电连锁网络系统
19 - 大学生求职就业网
20 - 华奥汽车销售集团网
21 - 科研成果申报管理系统
"
apache/camel-examples,main,377,357,2020-02-05T08:44:11Z,11126,0,Apache Camel Examples,camel integration java,
nicolasgramlich/AndEngineExamples,GLES2,375,333,2011-11-22T22:46:31Z,90062,26,AndEngine - Examples,,
healthnlp/examples,master,86,53,2015-06-18T15:11:25Z,151328,6,Health NLP Examples,,
oktadev/java-microservices-examples,main,519,303,2019-05-17T01:19:39Z,3169,0,"Java Microservices: Spring Boot, Spring Cloud, JHipster, Spring Cloud Config, and Spring Cloud Gateway",java jhipster jhipster-microservices kubernetes microservices microservices-architecture netflix-zuul oauth2 reactive-microservices spring-boot spring-cloud spring-cloud-config spring-cloud-gateway,"# Java Microservices with Spring Boot & Spring Cloud 🍃☁️
 
This repository contains examples of how to build a Java microservices architecture with Spring Boot, Spring Cloud, and Netflix Eureka.

This repository has five examples in it:

1. A bare-bones microservices architecture with Spring Boot, Spring Cloud, Eureka Server, and Zuul. 
2. A microservices architecture that's generated with JHipster and configured centrally with Spring Cloud Config. 
3. A microservices architecture that uses Spring Cloud Gateway and Spring WebFlux to show reactive microservices.
4. A JHipster-generated reactive microservices architecture with Spring Cloud Gateway and Spring WebFlux.
5. A JHipster 7 + Kubernetes example that deploys to Google Cloud with sealed secrets. 

We think you'll enjoy them all!

1. See [Java Microservices with Spring Boot and Spring Cloud][blog-spring-boot-spring-cloud] for an overview of the first example.
2. Read [Java Microservices with Spring Cloud Config and JHipster][blog-spring-cloud-config] to learn about microservices with JHipster.
3. Refer to [Secure Reactive Microservices with Spring Cloud Gateway][blog-spring-cloud-gateway] to learn about Spring Cloud Gateway and reactive microservices.
4. Refer to [Reactive Java Microservices with Spring Boot and JHipster][blog-reactive-jhipster] to see how JHipster makes reactive microservices a breeze.
5. Peruse [Kubernetes to the Cloud with Spring Boot and JHipster][blog-k8s] to see how JHipster simplifies Kubernetes deployments.

**Prerequisites:** [Java 11](https://sdkman.io/sdks#java) and an internet connection.

* [Spring Boot + Spring Cloud Example](#spring-boot--spring-cloud-example)
* [JHipster + Spring Cloud Config Example](#jhipster--spring-cloud-config-example)
* [Spring Cloud Gateway Example](#spring-cloud-gateway-example)
* [Reactive Microservices with JHipster Example](#reactive-microservices-with-jhipster-example)
* [Kubernetes to the Cloud Example](#kubernetes--reactive-java-with-jhipster-example)
* [Links](#links)
* [Help](#help)
* [License](#license)

## Spring Boot + Spring Cloud Example

To install this example, run the following commands:

```bash
git clone https://github.com/oktadev/java-microservices-examples.git
cd java-microservices-examples/spring-boot+cloud
```

The `api-gateway` and `car-service` projects are already pre-configured to be locked down with OAuth 2.0 and Okta. That means if you try to run them, you won't be able to login until you create an account, and an application in it.

### Create a Web Application in Okta

Log in to your Okta Developer account (or [sign up](https://developer.okta.com/signup/) if you don't have an account).

1. From the **Applications** page, choose **Add Application**.
2. On the Create New Application page, select **Web**.
3. Give your app a memorable name, add `http://localhost:8080/login/oauth2/code/okta` as a Login redirect URI, select **Refresh Token** (in addition to **Authorization Code**), and click **Done**.

Copy the issuer (found under **API** > **Authorization Servers**), client ID, and client secret into the `application.properties` of the `api-gateway` and `car-service` projects.

```properties
okta.oauth2.issuer=https://{yourOktaDomain}/oauth2/default
okta.oauth2.client-id=$clientId
okta.oauth2.client-secret=$clientSecret
```

Then, run all the projects with `./mvnw` in separate terminal windows. You should be able to navigate to `http://localhost:8761` and see the apps have been registered with Eureka.

Then, navigate to `http://localhost:8080/cool-cars` in your browser, log in with Okta, and see the resulting JSON.

## JHipster + Spring Cloud Config Example

To install this example, run the following commands:

```bash
git clone https://github.com/oktadev/java-microservices-examples.git
cd java-microservices-examples/jhipster
```

Create Docker containers for all gateway and microservice applications:

```bash
mvn -Pprod verify com.google.cloud.tools:jib-maven-plugin:dockerBuild
```

### Create a Web Application in Okta

Log in to your Okta Developer account (or [sign up](https://developer.okta.com/signup/) if you don't have an account).

1. From the **Applications** page, choose **Add Application**.
2. On the Create New Application page, select **Web**.
3. Give your app a memorable name, add `http://localhost:8080/login/oauth2/code/okta` as a Login redirect URI, select **Refresh Token** (in addition to **Authorization Code**), and click **Done**.
4. To configure Logout to work in JHipster, **Edit** your app, add `http://localhost:8080` as a Logout redirect URI, then click **Save**.

Rather than modifying each of your apps for Okta, you can use Spring Cloud Config in JHipster Registry to do it. Open `docker-compose/central-server-config/application.yml` and add your Okta settings.

The client ID and secret are available on your app settings page. You can find the issuer under **API** > **Authorization Servers**.

```yaml
spring:
  security:
    oauth2:
      client:
        provider:
          oidc:
            issuer-uri: https://{yourOktaDomain}/oauth2/default
        registration:
          oidc:
            client-id: {yourClientId}
            client-secret: {yourClientSecret}
```

The registry, gateway, blog, and store applications are all configured to read this configuration on startup.

Start all your containers from the `docker-compose` directory:

```bash
docker-compose up -d
```

Before you can log in to the registry, you'll need to add redirect URIs for JHipster Registry, ensure your user is in a `ROLE_ADMIN` group and that groups are included in the ID token.

Log in to your Okta dashboard, edit your OIDC app, and add the following Login redirect URI:

* `http://localhost:8761/login/oauth2/code/oidc`

You'll also need to add a Logout redirect URI:

* `http://localhost:8761`

Then, click **Save**.

### Create Groups and Add Them as Claims to the ID Token

JHipster is configured by default to work with two types of users: administrators and users. Keycloak is configured with users and groups automatically, but you need to do some one-time configuration for your Okta organization.

Create a `ROLE_ADMIN` group (**Users** > **Groups** > **Add Group**) and add your user to it. Navigate to **API** > **Authorization Servers**, and click on the the `default` server. Click the **Claims** tab and **Add Claim**. Name it `groups`, and include it in the ID Token. Set the value type to `Groups` and set the filter to be a Regex of `.*`. Click **Create**.

Now when you hit `http://localhost:8761` or `http://localhost:8080`, you should be able to log in with Okta!

## Spring Cloud Gateway Example

To install this example, run the following commands:

```bash
git clone https://github.com/oktadev/java-microservices-examples.git
cd java-microservices-examples/spring-cloud-gateway
```

The `api-gateway` and `car-service` projects are already pre-configured to be locked down with OAuth 2.0 and Okta. That means if you try to run them, you won't be able to login until you create an account, and an application in it.

If you already have an Okta account, see the **Create a Web Application in Okta** section below. Otherwise, we created a Maven plugin that configures a free Okta developer account + an OIDC app (in under a minute!).

To use it, run `./mvnw com.okta:okta-maven-plugin:setup` to create an account and configure the gateway to work with Okta.

Copy the `okta.*` properties from the gateway's `src/main/resources/application.properties` to the same file in the `car-service` project.

Then, run all the projects with `./mvnw` in separate terminal windows. You should be able to navigate to `http://localhost:8761` and see the apps have been registered with Eureka.

Then, navigate to `http://localhost:8080/cars` in your browser, log in with Okta, and see the resulting JSON.

### Create a Web Application in Okta

Log in to your Okta Developer account (or [sign up](https://developer.okta.com/signup/) if you don't have an account).

1. From the **Applications** page, choose **Add Application**.
2. On the Create New Application page, select **Web**.
3. Give your app a memorable name, add `http://localhost:8080/login/oauth2/code/okta` as a Login redirect URI and click **Done**.

Copy the issuer (found under **API** > **Authorization Servers**), client ID, and client secret into the `application.properties` of the `api-gateway` and `car-service` projects.

```properties
okta.oauth2.issuer=https://{yourOktaDomain}/oauth2/default
okta.oauth2.client-id=$clientId
okta.oauth2.client-secret=$clientSecret
```

## Reactive Microservices with JHipster Example

To install this example, run the following commands:

```bash
git clone https://github.com/oktadev/java-microservices-examples.git
cd java-microservices-examples/reactive-jhipster
```

The JHipster Registry and Spring Cloud Config are pre-configured to use Okta. That means if you try to run them, you won't be able to login until you create an account, and an application in it.

Install the Okta CLI using the instructions on [cli.okta.com](https://cli.okta.com) and come back here when you're done. If you don't have an Okta developer account, run `okta register`.

**NOTE**: You can also use your browser and Okta's developer console to register an app. See [JHipster's security documentation](https://www.jhipster.tech/security/#okta) for those instructions.

From the gateway project's directory, run `okta apps create jhipster`. Accept the default redirect URIs.

This process does several things:

1. Registers an OIDC app in Okta with JHipster's configured redirect URIs.
2. Creates `ROLE_ADMIN` and `ROLE_USER` groups and adds your user to both.
3. Creates a `groups` claim and adds it to ID tokens.
4. Creates a `.okta.env` file with the values you'll need to talk to Okta.

Spring Cloud Config allows you to distribute Spring's configuration between apps. Update `gateway/src/main/docker/central-server-config/localhost-config/application.yml` to use your Okta app settings. You can find the values for each property in the `.okta.env` file.

```yaml
spring:
  security:
    oauth2:
      client:
        provider:
          oidc:
            issuer-uri: https://<your-okta-domain>/oauth2/default
        registration:
          oidc:
            client-id: <client-id>
            client-secret: <client-secret>
```

Save your changes. These values will be distributed to the JHipster Registry, gateway, blog, and store apps. Start all the services and apps using the following commands:

```shell
cd gateway
docker-compose -f src/main/docker/keycloak.yml up -d #jhkeycloakup
docker-compose -f src/main/docker/postgresql.yml up -d #jhpostgresqlup
docker-compose -f src/main/docker/jhipster-registery up -d #jhregistryup
./gradlew
```

Open a new terminal window, start the blog app's Neo4j database, and then the app itself.

```shell
cd ../blog
docker-compose -f src/main/docker/neo4j.yml up -d #jhneo4jup
./gradlew
```

Then, open another terminal window, start the store app's MongoDB database, and the microservice.

```shell
cd ../store
docker-compose -f src/main/docker/mongodb.yml up -d #jhmongoup
./gradlew
```

Now, open a new incognito browser window, go to `http://localhost:8080`, and sign in. Rejoice that using Okta for authentication works!

**TIP**: You can also run everything using Docker Compose. See the [blog post](https://developer.okta.com/blog/2021/01/20/reactive-java-microservices#run-your-microservices-stack-with-docker-compose) for how to do that.

## Kubernetes + Reactive Java with JHipster Example

To install this example, run the following commands:

```bash
git clone https://github.com/oktadev/java-microservices-examples.git
cd java-microservices-examples/jhipster-k8s/k8s
```

If you don't have JHipster installed, install it.

```shell
npm i -g generator-jhipster@7
```

Run JHipster's [Kubernetes sub-generator](https://www.jhipster.tech/kubernetes/).

```shell
jhipster k8s
```

You will be prompted with several questions. The answers will be pre-populated from choices I made when creating this app. Answer as follows, changing the Docker repository name to yours, or leaving it blank if you don't have one.

- Type of application: **Microservice application**
- Root directory: **../**
- Which applications? `<select all>`
- Set up monitoring? **No**
- Which applications with clustered databases? select **store**
- Admin password for JHipster Registry: `<generate one>`
- Kubernetes namespace: **demo**
- Docker repository name: `<your docker hub username>`
- Command to push Docker image: `docker push`
- Enable Istio? **No**
- Kubernetes service type? **LoadBalancer**
- Use dynamic storage provisioning? **Yes**
- Use a specific storage class? `<leave empty>`

### Install Minikube to Run Kubernetes Locally

If you have Docker installed, you can run Kubernetes locally with Minikube. Run `minikube start` to begin.

```shell
minikube --memory 8g --cpus 8 start
```

Build Docker images for each app. In the {`gateway`, `blog`, `store` } directories, run the following Gradle command (where `<image-name>` is `gateway`, `store`, or `blog`).

```shell
./gradlew bootJar -Pprod jib -Djib.to.image=<docker-repo-name>/<image-name>
```

> You can also build your images locally and publish them to your Docker daemon. This is the default if you didn't specify a base Docker repository name.
>
> ```shell
> # this command exposes Docker images to minikube
> eval $(minikube docker-env)
> ./gradlew -Pprod bootJar jibDockerBuild
> ```
>
> Because this publishes your images locally to Docker, you'll need to make modifications to your Kubernetes deployment files to use `imagePullPolicy: IfNotPresent`.
>
> ```yaml
> - name: gateway-app
>   image: gateway
>   imagePullPolicy: IfNotPresent
> ```
>
> Make sure to add this `imagePullPolicy` to the following files:
>
> - `k8s/gateway-k8s/gateway-deployment.yml`
> - `k8s/blog-k8s/blog-deployment.yml`
> - `k8s/store-k8s/store-deployment.yml`

### Register an OIDC App for Auth

Install the Okta CLI using the instructions on [cli.okta.com](https://cli.okta.com) and come back here when you're done. If you don't have an Okta developer account, run `okta register`.

**NOTE**: You can also use your browser and Okta's developer console to register an app. See [JHipster's security documentation](https://www.jhipster.tech/security/#okta) for those instructions.

From the gateway project's directory, run `okta apps create jhipster`. Accept the default redirect URIs.

This process does several things:

1. Registers an OIDC app in Okta with JHipster's configured redirect URIs.
2. Creates `ROLE_ADMIN` and `ROLE_USER` groups and adds your user to both.
3. Creates a `groups` claim and adds it to ID tokens.
4. Creates a `.okta.env` file with the values you'll need to talk to Okta.

Update `k8s/registry-k8s/application-configmap.yml` to contain your OIDC settings from the `.okta.env` file the Okta CLI just created. The Spring Cloud Config server reads from this file and shares the values with the gateway and microservices.

```yaml
data:
  application.yml: |-
    ...
    spring:
      security:
        oauth2:
          client:
            provider:
              oidc:
                issuer-uri: https://<your-okta-domain>/oauth2/default
            registration:
              oidc:
                client-id: <client-id>
                client-secret: <client-secret>
```

To configure the JHipster Registry to use OIDC for authentication, modify `k8s/registry-k8s/jhipster-registry.yml` to enable the `oauth2` profile.

```yaml
- name: SPRING_PROFILES_ACTIVE
  value: prod,k8s,oauth2
```

Then, in the `k8s` directory, start your engines!

```shell
./kubectl-apply.sh -f
```

You can see if everything starts up using the following command.

```shell
kubectl get pods -n default
```

You can use the name of a pod with `kubectl logs` to tail its logs.

```shell
kubectl logs <pod-name> --tail=-1 -n default
```

You can use port-forwarding to see the JHipster Registry.

```shell
kubectl port-forward svc/jhipster-registry -n default 8761
```

Open a browser and navigate to `http://localhost:8761`. You'll need to sign in with your Okta credentials.

Once all is green, use port-forwarding to see the gateway app.

```shell
kubectl port-forward svc/gateway -n default 8080
```

Then, go to `http://localhost:8080`, and you should be able to add blogs, posts, tags, and products.

Please read the [Kubernetes to the Cloud with Spring Boot and JHipster][blog-k8s] for more information.

## Links

These examples use the following open source libraries:

* [Okta Spring Boot Starter](https://github.com/okta/okta-spring-boot) 
* [Spring Boot](https://spring.io/projects/spring-boot)
* [Spring Cloud](https://spring.io/projects/spring-cloud)
* [Spring Cloud Gateway](https://spring.io/projects/spring-cloud-gateway)
* [Spring Security](https://spring.io/projects/spring-security)
* [JHipster](https://www.jhipster.tech)
* [OpenJDK](https://openjdk.java.net/)
* [K9s](https://k9scli.io/)

## Help

Please post any questions as comments on the example's blog post, or on the [Okta Developer Forums](https://devforum.okta.com/).

## License

Apache 2.0, see [LICENSE](LICENSE).

[blog-spring-boot-spring-cloud]: https://developer.okta.com/blog/2019/05/22/java-microservices-spring-boot-spring-cloud
[blog-spring-cloud-config]: https://developer.okta.com/blog/2019/05/23/java-microservices-spring-cloud-config
[blog-spring-cloud-gateway]: https://developer.okta.com/blog/2019/08/28/reactive-microservices-spring-cloud-gateway
[blog-reactive-jhipster]: https://developer.okta.com/blog/2021/01/20/reactive-java-microservices
[blog-k8s]: https://developer.okta.com/blog/2021/06/01/kubernetes-spring-boot-jhipster
"
osate/examples,master,54,65,2013-02-21T20:41:59Z,35681,2,Examples and case-study that use OSATE,,
pkainulainen/Examples,master,61,60,2011-12-11T15:43:57Z,694,18,A repository for the code examples of my blog,,
attacomsian/code-examples,master,152,345,2019-01-28T11:20:51Z,384,14,Example projects for my personal blog. ,java javascript mongodb mongoose nodejs nodejs-tutorials rest-api spring-boot spring-boot-tutorial spring-data-jpa thymeleaf,"# Example Projects

Example projects for https://attacomsian.com/blog/ website.

All codes are released under [MIT](https://github.com/attacomsian/code-examples/blob/master/LICENSE) license unless otherwise specified.
"
pkainulainen/spring-mvc-test-examples,master,363,467,2013-05-16T14:01:24Z,609,105,,,"# Test With Spring Course

If you are struggling to write good automated tests for Spring web applications, you are not alone! [I have launched a video course](https://www.testwithspring.com/?utm_source=github&utm_medium=social&utm_content=spring-mvc-test&utm_campaign=test-with-spring-course-presales) that describes how you can write automated tests which embrace change and help you to save your time (and nerves).

# Spring MVC Test Tutorial

This repository contains the example applications of my [Spring MVC Test tutorial](http://www.petrikainulainen.net/spring-mvc-test-tutorial/).

"
structurizr/examples,main,68,54,2022-02-23T14:34:48Z,993,3,Structurizr examples,,"# Examples

This repo contains some Structurizr examples in the following formats:

- [Structurizr DSL](https://github.com/structurizr/examples/tree/main/dsl)
- [Structurizr for Java](https://github.com/structurizr/examples/tree/main/java)

There are also some examples of how to use Structurizr for enterprise-wide modelling:

- [Example 1: Enterprise modelling with the Structurizr DSL, with on-premises installation](https://github.com/structurizr/examples/tree/main/enterprise#example-1)
- [Example 2: Enterprise modelling with the Structurizr DSL, without on-premises installation](https://github.com/structurizr/examples/tree/main/enterprise#example-2)
- [Example 3: Backstage as a system catalog + system modelling with the Structurizr DSL](https://github.com/structurizr/examples/tree/main/enterprise#example-3)
- [Example 4: Import Backstage to Structurizr](https://github.com/structurizr/examples/tree/main/enterprise#example-4)"
fyhertz/libstreaming-examples,master,281,231,2013-05-20T04:42:04Z,1687,36,Some examples of how to use libstreaming,,"# Some examples of how to use libstreaming

This repository contains three simple examples of how to use libstreaming.

### Libstreaming ?

You can find out more about libstreaming [here](https://github.com/fyhertz/libstreaming).

### Example 1

Shows how to use the RTSP server.

### Example 2

Shows how to start a stream and obtain a SDP that you will then want to hand to the receiver.

### Example 3

**This example shows how you can use libstreaming with a Wowza Media Server.**

[Read this tutorial to find out of to use it](https://github.com/fyhertz/libstreaming/wiki/Using-libstreaming-with-Wowza-Media-Server)

### Build instructions

1. Clone the repository

2. libstreaming is referenced as git submodule in this repo, so you will need to run the two following commands:
```sh
git submodule init
git submodule update
```

3. Run the **android project update** command in the libstreaming directory and in the directory of the example you wish to compile:
```sh
cd libstreaming
android update project --path . --target android-21
cd ../example3/app
android update project --path . --target android-21
```

4. Run ant
```sh
ant debug
```

**Note: you will need to run 'ant clean' before compiling another example!**
"
mjpt777/examples,master,110,40,2012-10-31T10:28:04Z,120,0,Code Examples,,"examples
========

Code Examples"
aws-samples/aws-dynamodb-examples,master,518,210,2013-06-26T17:23:19Z,727,9,DynamoDB Examples,,"# Various Examples and AWS SDK code examples for Amazon DynamoDB

An Amazon Web Services and DynamoDB community-led repository containing code and examples for developing with and using [Amazon DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.html).

We have [IAM policies for DynamoDB](https://github.com/aws-samples/aws-dynamodb-examples/tree/master/DynamoDBIAMPolicies), [a script to load an existing table](https://github.com/aws-samples/aws-dynamodb-examples/tree/master/nosqlworkbenchscript) into NoSQL Workbench, [CloudFormation examples](https://github.com/aws-samples/aws-dynamodb-examples/tree/master/cloudformation), and [a CDK to track table size and item count histories to CloudWatch](https://github.com/aws-samples/aws-dynamodb-examples/tree/master/DynamoDBCustomMetrics). 

We also have AWS SDK [code examples for DynamoDB in various languages](https://github.com/aws-samples/aws-dynamodb-examples/tree/master/DynamoDB-SDK-Examples). You can find each language examples here:

* [Node.js](./DynamoDB-SDK-Examples/node.js)
* [Java](./DynamoDB-SDK-Examples/java)
* [Python](./DynamoDB-SDK-Examples/python)
* [.Net](./DynamoDB-SDK-Examples/dotnet)
* [Golang](./DynamoDB-SDK-Examples/golang)
* [Rust](./DynamoDB-SDK-Examples/rust)
* [Ruby](./DynamoDB-SDK-Examples/ruby)

PS. If you are up for contributing, we welcome community pull requests.


All code in this repository is provided as is, where is. There are no guarantees, either expressed or implied. It is up to you to check what they do and utilize the code responsibly.

Special thanks to other contributors to this repo before it was moved over to this current location. Here are their GitHub users:
* @jprivillaso
* @tywalch
* @normj
* @jasonwadsworth
* @johanrin
* @DejanBelic
* @TLaue
"
assertj/assertj-examples,main,366,185,2013-03-14T23:16:41Z,7058,7,Examples illustrating AssertJ assertions,assertj assertj-assertions java,"## AssertJ examples

AssertJ examples is divided in two : assertions-examples (core, guava and joda assertions) and AssertJ swing modules.

The **main** branch contains examples with the latest released version of AssertJ modules (for Java 8).

There are several branches that contain examples for the ongoing development versions of AssertJ modules. That means you have to build the according AssertJ modules by your own before new features compile. The following table contains these special branches that are merged into the main each time the module is released.

| Branch                        | Modules                                    |
| ----------------------------- | ------------------------------------------ |
| with-latest-snapshot-versions | Core 3.x for Java 8 |
| with-latest-swing-snapshot    | Swing                                      |


### AssertJ assertions examples

**assertj-examples/assertions-examples** contains executable AssertJ assertions examples that you can run as JUnit tests.
Please have a look at **[assertions examples sources](assertions-examples/src/test/java/org/assertj/examples)**.

The **main** branch contains examples with the latest released version of AssertJ modules for Java 8, similarly the **java-7** branch contains examples of AssertJ modules for Java 7.
You should be able to build those two branches with `mvn clean install` command.

In your IDE, add `src/test/generated-assertions` to the project java test sources otherwise you will have errors/missing classes.
This is the folder where custom assertions classes are generated by default by the maven assertions generator plugin. 
Note that Intellij Idea wrongly adds `src/test/generated-assertions` to the production sources when it should be added the **test sources**, you will have to fix that in your module/project settings. 

Building **with-latest-snapshot-versions** is a little more complicated :
- you need to build the needed SNAPSHOT dependencies before - most probably assertj-core and maybe other modules. 
- run `mvn clean install` in `assertj-examples/assertions-examples`.
- In your IDE, add `src/test/generated-assertions` to the project java sources if you IDE shows errors/missing classes.  

### AssertJ-Swing examples

The **main** branch contains examples with the latest released version of AssertJ modules => you should be able to build it with mvn clean install command.

**assertj-swing-aut** contains the AUT (application under test) that is tested by the examples.

**assertj-swing-junit-examples** contains executable AssertJ-Swing examples that you can inspect and run as JUnit tests.
Please have a look at **[swing-junit-examples sources](assertj-swing-junit-examples/src/test/java/org/assertj/swing/junit/examples)**.

**assertj-swing-testng-examples** contains executable AssertJ-Swing examples that you can inspect and run as TestNG tests.
Please have a look at **[swing-testng-examples sources](assertj-swing-testng-examples/src/test/java/org/assertj/swing/testng/examples)**.


## Contributing

Contributing is easy, only two rules to follow : 
* Checkout the snapshot branch corresponding to your examples, it should be `with-latest-snapshot-versions` most of the time (not main!) 
* Use **[AssertJ code Eclipse formatting preferences](https://github.com/joel-costigliola/assertj-core/blob/main/src/ide-support/assertj-eclipse-formatter.xml)** (for Idea users, it is possible to import it)
* Add FUN examples ! ;-)

Thanks !
"
holdenk/learning-spark-examples,master,334,271,2014-03-06T19:33:53Z,1615,0,Examples for learning spark,,"[![buildstatus](https://travis-ci.org/holdenk/learning-spark-examples.svg?branch=master)](https://travis-ci.org/holdenk/learning-spark-examples)
Examples for Learning Spark
===============
Examples for the Learning Spark book. These examples require a number of libraries and as such have long build files. We have also added a stand alone example with minimal dependencies and a small build file
in the mini-complete-example directory.


These examples have been updated to run against Spark 1.3 so they may
be slightly different than the versions in your copy of ""Learning Spark"".

Requirements
==
* JDK 1.7 or higher
* Scala 2.10.3
- scala-lang.org
* Spark 1.3
* Protobuf compiler
- On debian you can install with sudo apt-get install protobuf-compiler
* R & the CRAN package Imap are required for the ChapterSixExample
* The Python examples require urllib3

Python examples
===

From spark just run ./bin/pyspark ./src/python/[example]

Spark Submit
===

You can also create an assembly jar with all of the dependencies for running either the java or scala
versions of the code and run the job with the spark-submit script

`./sbt/sbt assembly` OR `mvn package`

`cd $SPARK_HOME; ./bin/spark-submit   --class com.oreilly.learningsparkexamples.[lang].[example] ../learning-spark-examples/target/scala-2.10/learning-spark-examples-assembly-0.0.1.jar`

[![Learning Spark](http://akamaicovers.oreilly.com/images/0636920028512/cat.gif)](http://www.jdoqocy.com/click-7645222-11260198?url=http%3A%2F%2Fshop.oreilly.com%2Fproduct%2F0636920028512.do%3Fcmp%3Daf-strata-books-videos-product_cj_9781449358600_%2525zp&cjsku=0636920028512)
"
flowable/flowable-examples,master,221,231,2016-12-20T08:21:56Z,3385,42,Repository with example Flowable projects,,
amehlhase316/ser321examples,master,28,767,2020-09-25T21:27:30Z,96161,3,,,"# ser321examples

All examples in this repository are for you to play with and to learn about the different concepts in this class. This repo is still a ""living"" thing. As we progress we might add more examples or make changes. 

You can use these samples to develop your solutions but you need to reference things if you copy parts of the repo into your solution and it is NOT ok to use any of the examples here and submit them as your own. Each assignment that you submit has to have a significant own contribution to show you understand the concepts and can develop a solution on your own. 

## Advise
It is advised that you fork this repository so that you have your own version and can also make changes to your own repo to test different scenarios. Then clone that repo to your main machine and your second machine. 

If we make changes to the repository we will notify you in the Slack #example_repo channel. See here about forking and keeping your version up to date <https://docs.github.com/en/free-pro-team@latest/github/getting-started-with-github/fork-a-repo?>

## Development
All examples are developed by the teaching team:

Many examples are used and adapted from Dr. Lindquist and Dr. Gary.

Others were developed by Dr. Mehlhase, David Clements and Aman Kaushik.


## Running the examples
The examples should all have Gradle files. The separate folders have a Gradle project but the ""inner"" folders also have separate Gradle files. Please check the comments and files so you know how to run the examples. 

## Suggestions
If you find any issues or have suggestions on how to improve the repo, the Gradle files etc. feel free to let us know. We are happy to accept Pull Requests if you think you come up with something good. 

## Have fun

Feel free to play with these examples, the better you understand these small examples the easier your coding assignments will be. 

Best

Dr. Mehlhase

"
SonarSource/sonar-custom-rules-examples,master,226,424,2016-10-24T13:34:34Z,216,5,"Shows how to bootstrap a project to write custom rules for PHP, Python, Cobol, RPG",language-team,"Sonar Custom Rules Examples [![Build Status](https://travis-ci.org/SonarSource/sonar-custom-rules-examples.svg?branch=master)](https://travis-ci.org/SonarSource/sonar-custom-rules-examples)
==========

This repository contains project examples you can directly clone to bootstrap your own project to write custom rules for COBOL, PHP, Python, and RPG.

Related documentation is there: https://docs.sonarqube.org/latest/extend/adding-coding-rules/

Sonar's [Clean Code solutions](https://www.sonarsource.com/solutions/clean-code/?utm_medium=referral&utm_source=github&utm_campaign=clean-code&utm_content=sonar-custom-rules-examples) help developers deliver high-quality, efficient code standards that benefit the entire team or organization.

Have questions or feedback?
---------------------------

Note that GitHub issues have been disabled.
To provide feedback or ask for help, please use the [Sonar Community Forum](https://community.sonarsource.com/).

### License

Copyright 2016-2022 SonarSource.

Licensed under the [GNU Lesser General Public License, Version 3.0](http://www.gnu.org/licenses/lgpl.txt)
"
j256/ormlite-examples,master,182,231,2013-03-08T21:56:44Z,32510,3,Various example programs,,
Vedenin/useful-java-links,master,5752,1188,2016-02-13T13:14:52Z,2410,20,"A list of useful Java frameworks, libraries, software and hello worlds examples",awesome awesome-list java-api java-applications java-frameworks java-libraries java-links lists machine-learning resources,
apache/incubator-kie-kogito-examples,stable,253,365,2019-03-07T09:33:22Z,47081,46,Kogito examples - Kogito is a cloud-native business automation technology for building cloud-ready business applications.,bpm bpmn cloud-native cmmn dmn hacktoberfest java knative kogito quarkus rules-engine serverless-workflow spring-boot workflow workflow-engine,"# Kogito Examples

This module contains a number of examples that you can take a look at and try out yourself.  Please take a look at the readme of each individual example for more details on how the example works and how to run it yourself (either locally or on Kubernetes).

Since Kogito aims at supporting both Quarkus and Spring Boot each example usually provides both type of projects.

- Default branch is `stable`, pointing to the latest released version.
- **[You can also check all versions by looking at releases.](https://github.com/kiegroup/kogito-examples/releases/latest)**

## Use alternative Quarkus platforms

The Quarkus quickstarts by default currently use the Quarkus core BOM.

If you want to use an alternative BOM when building the Quarkus quickstarts you can override the `quarkus.platform.*` properties. The following example shows how to set `quarkus.platform.artifact-id` to use the quarkus-universe-bom.

```
mvn -Dquarkus.platform.artifact-id=quarkus-universe-bom clean install
```

Because the Kogito project is part of the Quarkus Platform, the same applies also to Kogito BOM being used.

By default `org.kie.kogito:kogito-bom` is used, but, when needed, this can be overridden using Maven properties:
* `kogito.bom.*` for Kogito BOM overrides

The properties defined in each of the modules and can be overridden as follows:
* Kogito BOM
  ```
  mvn -Dkogito.bom.group-id=io.quarkus.platform -Dkogito.bom.artifact-id=quarkus-kogito-bom -Dkogito.bom.version=2.2.3.Final
  ```
> Note: It's important to keep BOM versions aligned when overriding. In case of Quarkus Platform this means using a single
> version value for all two (`quarkus.platform.version`, `kogito.bom.version`) properties.

## Contribution

Everyone is encouraged to contribute to these examples by

* trying it out and providing feedback and ideas for improvement
* create new examples -- **in this case, make sure your PR is against the `main` branch!**
* blogging about it
* using it on conferences and workshops


## Process hello world with scripts

shows most basic use of processes to build up a hello world example

* [on Quarkus](kogito-quarkus-examples/process-scripts-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-scripts-springboot)


## Process with business rules

shows integration between processes and rules.

* [on Quarkus](kogito-quarkus-examples/process-business-rules-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-business-rules-springboot)


## Process with Kafka

shows how message start and end events can be easily used to integrate with Apache Kafka to consume where
message name is the Kafka topic and the payload is mapped to process variable. Uses custom types
that are serialized into JSON.

* [on Quarkus](kogito-quarkus-examples/process-kafka-quickstart-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-kafka-quickstart-springboot)

## Process with Infinispan persistence

shows long running processes with Infinispan persistence so the state of process instances can
be preserved across service restarts.

* [on Quarkus](kogito-quarkus-examples/process-infinispan-persistence-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-infinispan-persistence-springboot)

## Process with service invocation

shows how easy it is to use local services to be invoked from within process. Allows easy and readable
service invocation use cases to be covered.

* [on Quarkus](kogito-quarkus-examples/process-service-calls-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-service-calls-springboot)

## Process with REST call

shows REST service invocation and parsing data back to an object instance used as process variable.

* [on Quarkus](kogito-quarkus-examples/process-rest-service-call-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-rest-service-call-springboot)

## Process with user tasks

shows user task interactions with four eye principle applied

* [on Quarkus](kogito-quarkus-examples/process-usertasks-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-usertasks-springboot)

## Process with user tasks based on custom life cycle

shows user task interactions with four eye principle applied that supports custom life cycle that allows to
add additional phases to user tasks to indicate other states.

* [on Quarkus](kogito-quarkus-examples/process-usertasks-custom-lifecycle-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-usertasks-custom-lifecycle-springboot)

## Process with user tasks with security on REST api

shows user task interactions with four eye principle applied with security restrictions on REST api.

* [on Quarkus](kogito-quarkus-examples/process-usertasks-with-security-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-usertasks-with-security-springboot)

## Process with timers

shows timers (intermediate and boundary) that allows to introduce delays in process execution

* [on Quarkus](kogito-quarkus-examples/process-timer-quarkus)
* [on Spring Boot](kogito-springboot-examples/process-timer-springboot)

## Serverless Workflow Getting Started

A Serverless Workflow greeting service with both JSON and YAML workflow definitions

* [on Quarkus](serverless-workflow-examples/serverless-workflow-greeting-quarkus)

## Serverless Workflow with events

A Serverless Workflow service for processing job applicant approvals and that showcases event-driven services.

* [on Quarkus](serverless-workflow-examples/serverless-workflow-events-quarkus)

## Serverless Workflow with service calls

A Serverless Workflow service for returning country information

* [on Quarkus](serverless-workflow-examples/serverless-workflow-service-calls-quarkus)

## Serverless Workflow GitHub showcase

A Serverless Workflow service that works as a Github bot application, which reacts upon a new PR being opened in a given GitHub project.

* [on Quarkus](serverless-workflow-examples/serverless-workflow-github-showcase)

## Other Misc Examples

- Onboarding example combining 1 process and two decision services: see [README.md](kogito-quarkus-examples/onboarding-example/README.md)
- Rules on Quarkus: see [README.md](kogito-quarkus-examples/rules-quarkus-helloworld/README.md)
- Rules on Quarkus with Unit: see [README.md](kogito-quarkus-examples/ruleunit-quarkus-example/README.md)
- Process on Quarkus: see [README.md](kogito-quarkus-examples/process-quarkus-example/README.md)
- Process on Spring Boot: see [README.md](kogito-springboot-examples/process-springboot-example/README.md)
- Trusty on Quarkus: see [README.md](kogito-quarkus-examples/trusty-demonstration/README.md)
- Trusty on Quarkus (DevUI integration): see [README.md](kogito-quarkus-examples/trusty-tracing-devservices/README.md)

## Trying the examples with the Kogito Operator

Most examples have a directory named `operator` including the YAML files to deploy it using the Kogito Operator in an OpenShift cluster.
Please refer to the [Kogito Documentation](https://docs.jboss.org/kogito/release/latest/html_single/#chap_kogito-deploying-on-openshift)
of how to install the operator to your environment in order to try it there.

## Getting Help
### Issues
- Do you have a [minimal, reproducible example](https://stackoverflow.com/help/minimal-reproducible-example) for your issue?
  - If so, please open a Jira for it in the [Kogito project](https://issues.redhat.com/projects/KOGITO/summary) with the details of your issue and example.
- Are you encountering an issue but unsure of what is going on?
  - Start a new conversation in the Kogito [Google Group](https://groups.google.com/g/kogito-development), or open a new thread in the [Kogito stream](https://kie.zulipchat.com/#narrow/stream/232676-kogito) of the KIE Zulip chat.
  - Please provide as much relevant information as you can as to what could be causing the issue, and our developers will help you figure out what's going wrong.

### Requests
- Do you have a feature/enhancement request?
  - Please open a new thread in the [Kogito stream](https://kie.zulipchat.com/#narrow/stream/232676-kogito) of the KIE Zulip chat to start a discussion there.
"
kaiwaehner/kafka-streams-machine-learning-examples,master,822,302,2017-08-16T11:47:33Z,54028,10,"This project contains examples which demonstrate how to deploy analytic models to mission-critical, scalable production environments leveraging Apache Kafka and its Streams API. Models are built with Python, H2O, TensorFlow, Keras, DeepLearning4 and other technologies.",deep-learning deeplearning4j dl4j h2o h2oai java kafka kafka-client kafka-streams keras keras-tensorflow ksql machine-learning open-source python tensorflow,
pkainulainen/spring-batch-examples,master,193,285,2016-01-27T20:20:34Z,173,3,,,"# Test With Spring Course

If you are struggling to write good automated tests for Spring web applications, you are not alone! [I have launched a video course](https://www.testwithspring.com/?utm_source=github&utm_medium=social&utm_content=spring-batch&utm_campaign=test-with-spring-course-presales) that describes how you can write automated tests which embrace change and help you to save your time (and nerves).

# Spring Batch Tutorial

This repository contains the example ammplications of my Spring Batch tutorial. This repository contains two examples that are described in the following:

* The _spring_ directory contains an example application that uses Spring Framework.
* The _spring-boot_ directory contains an example application that uses Spring Boot.

"
pajikos/java-examples,master,81,296,2017-04-24T19:57:06Z,181,14,"For more info, check my blog:",,"# Java examples

Working project examples
"
arquillian/arquillian-examples,master,160,213,2010-08-01T20:29:17Z,350,19,This repository hosts the example projects that are covered in the Arquillian Guides as well as several additional examples.,,"# Arquillian Examples

This repository hosts the example projects that are covered in the [Arquillian Guides](http://arquillian.org/guides/). These projects can be identified by the word ""tutorial"" in the name. There are several additional examples that demonstrate other functionality in Arquillian. All the projects in this repository are self-contained (they do not use parent projects).

To see an even more comprehensive set of example tests, browse the [Arquillian Showcase](https://github.com/arquillian/arquillian-showcase) repository.

## What is Arquillian?

Arquillian is an innovative and highly extensible testing platform for the JVM that enables developers to easily create automated integration, functional and acceptance tests for Java middleware.
                                 
Find at more at http://arquillian.org

## Project Index

Below is an index of the projects in this repository paired with a brief description.

### [arquillian-tutorial](https://github.com/arquillian/arquillian-examples/tree/master/arquillian-tutorial)

This project is a starting point for using Arquillian. It has a simple CDI test case that runs against Weld EE Embedded (default), Embedded GlassFish 3.1 (default) and Managed JBoss AS 7.1.

### [arquillian-tutorial-rinse-repeat](https://github.com/arquillian/arquillian-examples/tree/master/arquillian-tutorial-rinse-repeat)

This project is a follow-up to the arquillian-tutorial project. It demonstrates the integration of CDI and EJB with a test case that runs against GlassFish Embedded 3.1 (default), Remote JBoss AS 7.1, Remote GlassFish 3.1 and Managed JBoss AS 7.1.

### [arquillian-persistence-tutorial](https://github.com/arquillian/arquillian-examples/tree/master/arquillian-persistence-tutorial)

This project contains a JPA 2 integration test that runs against Embedded GlassFish 3.1 (default), Remote GlassFish 3.1, Managed JBoss AS 7.1 and Remote JBoss AS 7.1.

### [arquillian-drone-tutorial](https://github.com/arquillian/arquillian-examples/tree/master/arquillian-drone-tutorial)

This project demonstrates the use of Arquillian Drone to drive a Selenium test. It runs against Embedded GlassFish 3.1 (default), Managed JBoss AS 7.1 and Remote JBoss AS 7.1.

### ejb31-gfembedded

This project contains EJB3.1 integration test and runs against Glassfish Embedded 3 container. The projects target is to provide simplest possible setup for this test combination.

### ejb31-jbembedded

This project contains EJB3.1 integration test and runs against JBoss AS 6 Embedded container. The projects target is to provide simplest possible setup for this test combination.
 
### ejb3-openejb

This project contains EJB3 integration test and runs against Apache OpenEJB 3.1 Embedded container. The projects target is to provide simplest possible setup for this test combination.

### quickstart

This is a simple startup project with contains both tests for POJO and EJB running against a variety of containers.
 
### jpalab

This project is a JPA 1.x lab that experiments with functionality and boundaries of transaction-scoped and extended persistence contexts. It can be run on the OpenEJB 3.1 Embedded container with either OpenJPA, Hibernate or EclipseLink as the JPA provider.

### jsfunit-servlet

This project demonstrates how to use JSFUnit with a Servlet container.

### xa

This project demonstrates the use of XA DataSources that enlist in a distributed transaction within an Arquillian test.
"
apache/camel-spring-boot-examples,main,279,324,2020-05-14T06:31:29Z,4552,0,Apache Camel Spring Boot Examples,camel integration java spring-boot,
pkainulainen/spring-social-examples,master,157,285,2013-08-22T14:31:20Z,804,5,,,"# Test With Spring Course

If you are struggling to write good automated tests for Spring web applications, you are not alone! [I have launched a video course](https://www.testwithspring.com/?utm_source=github&utm_medium=social&utm_content=spring-social&utm_campaign=test-with-spring-course-presales) that describes how you can write automated tests which embrace change and help you to save your time (and nerves).

# Spring Social Tutorial

This repository contains the example applications of my [Spring Social tutorial](http://www.petrikainulainen.net/spring-social-tutorial/).
"
FabricMC/fabric-example-mod,1.20,1491,886,2018-11-03T20:32:07Z,453,4,Example Fabric mod,fabric,"# Fabric Example Mod

## Setup

For setup instructions please see the [fabric wiki page](https://fabricmc.net/wiki/tutorial:setup) that relates to the IDE that you are using.

## License

This template is available under the CC0 license. Feel free to learn from it and incorporate it in your own projects.
"
spring-framework-guru/sfg-blog-posts,master,322,571,2019-05-09T15:45:23Z,787,49,Source code examples for blog posts,java spring springframework,"[![CircleCI](https://circleci.com/gh/spring-framework-guru/sfg-blog-posts.svg?style=svg)](https://circleci.com/gh/spring-framework-guru/sfg-blog-posts)
# SFG Blog Posts

This repository contains source code examples from various blog posts from [Spring Framework Guru](https://springframework.guru) 

Are you interested in writing for Spring Framework Guru? Checkout the [wiki](https://github.com/spring-framework-guru/sfg-blog-posts/wiki) for how to get started!

The blog posts for the examples in this repo are:  
- [Service Locator Pattern in Spring](https://springframework.guru/service-locator-pattern-in-spring/)
- [Using GraphQL in a Spring Boot Application](https://springframework.guru/using-graphql-in-a-spring-boot-application/)
- [Spring JdbcTemplate CRUD Operations](https://springframework.guru/spring-jdbctemplate-crud-operations/)
- [Using Spring Aware Interfaces](https://springframework.guru/using-spring-aware-interfaces/)
- [Working with Resources in Spring](https://springframework.guru/working-with-resources-in-spring/)
- [Using RestTemplate in Spring](https://springframework.guru/using-resttemplate-in-spring/)
- [Using RestTemplate with Apaches HttpClient](https://springframework.guru/using-resttemplate-with-apaches-httpclient/)
- [How to Configure Multiple Data Sources in a Spring Boot Application](https://springframework.guru/how-to-configure-multiple-data-sources-in-a-spring-boot-application/)
- [Why you should be using Spring Boot Docker Layers](https://springframework.guru/why-you-should-be-using-spring-boot-docker-layers/)
- [Autowiring In Spring](https://springframework.guru/autowiring-in-spring/)
- [Spring Bean Definition Inheritance](https://springframework.guru/spring-bean-definition-inheritance/)
- [Best Practices for Dependency Injection with Spring](https://springframework.guru/best-practices-for-dependency-injection-with-spring/)
- [Using Project Lombok with Gradle](https://springframework.guru/using-project-lombok-with-gradle/)
- [Spring JdbcTemplate CRUD Operations](https://springframework.guru/spring-jdbctemplate-crud-operations/)
- [How to Configure Multiple Data Sources in a Spring Boot Application](https://springframework.guru/how-to-configure-multiple-data-sources-in-a-spring-boot-application/)
- [Working with Resources in Spring](https://springframework.guru/working-with-resources-in-spring/)
- [Spring Bean Scopes](https://springframework.guru/spring-bean-scopes/)
- [Using Ehcache 3 in Spring Boot](https://springframework.guru/using-ehcache-3-in-spring-boot/)
- [Spring Profiles](https://springframework.guru/spring-profiles/)
- [Using Spring Aware Interfaces](https://springframework.guru/using-spring-aware-interfaces/)
- [Spring Bean Lifecycle](https://springframework.guru/spring-bean-lifecycle/)
- [Spring Boot with Lombok: Part 1](https://springframework.guru/spring-boot-with-lombok-part-1/)
- [Consul Miniseries: Spring Boot Application and Consul Integration Part 1](https://springframework.guru/consul-miniseries-spring-boot-application-and-consul-integration-part-1/)
- [Consul Miniseries: Spring Boot Application and Consul Integration Part 2](https://springframework.guru/consul-miniseries-spring-boot-application-and-consul-integration-part-2/)
- [Consul Miniseries: Spring Boot Application and Consul Integration Part 3](https://springframework.guru/consul-miniseries-spring-boot-application-and-consul-integration-part-3/)
- [Debug your Code in IntelliJ IDEA](https://springframework.guru/debug-your-code-in-intellij-idea/)
- [Java 14 records](https://springframework.guru/java-14-records/)
- [Run Spring Boot on Docker](https://springframework.guru/run-spring-boot-on-docker/)
- [Manage Docker Containers with Docker Compose](https://springframework.guru/manage-docker-containers-with-docker-compose/)
- [Feign REST Client for Spring Application](https://springframework.guru/feign-rest-client-for-spring-application/)
- [Using MapStruct with Project Lombok](https://springframework.guru/using-mapstruct-with-project-lombok/)
- [Writing Parametrized Tests]()
- [Spring REST Docs]()
- [Calling Stored Procedure from Spring Data JPA Repository]()
- [Spring Boot Pagination]()
- [Convert OffsetDateTime to SQLTimeStamp]()
- [Error Handling in Spring REST]()
- [Spring State Machine]()
- [Java Bean Validation]()
- [Stored Procedures with Spring Boot]()
- [BeanFactory vs ApplicationContext]()
- [Multi Module Spring Boot Project]()
- [One to One Association]()
- [One to Many Association]()
- [Actuator in Spring Boot]()
- [Spring Boot CLI]()
- [Spring Boot Internationalization]()
- [Spring Retry]()
- [EnumSet in Java]()
- [Scheduling in Spring Boot]()
- [Spring Boot Kafka]()
- [Bootstrapping Data in Spring Boot]()
- [Using Eureka Service Registry]()
"
asciidoctor/asciidoctor-maven-examples,main,193,245,2013-12-23T01:55:33Z,1676,11,A collection of example projects that demonstrates how to use the Asciidoctor Maven plugin.,,
bintray/bintray-examples,master,333,137,2013-03-25T07:45:57Z,9520,11,Examples of resolving and deploying to Bintray.com,,"bintray-examples
================

Examples of resolving and deploying to Bintray.com

For comments, issues and questions please use the feeback form on Bintray.com
"
spring-projects/spring-hateoas-examples,main,370,182,2017-05-25T18:33:41Z,295,15,Collection of examples on how (and why) to build hypermedia-driven apps with Spring HATEOAS,hateoas rest spring,
GoogleCloudPlatform/cloud-bigtable-examples,main,228,226,2014-12-05T12:59:52Z,1406,10,Examples of how to use Cloud Bigtable both with GCE map/reduce as well as stand alone applications.,samples,"# Google Cloud Bigtable examples

[![Travis CI status][travis-shield]][travis-link]
[![Stack Overflow][stackoverflow-shield]][stackoverflow-link]

Bigger than a data warehouse, fast enough for real-time access, and less expensive than running virtual machines. The world-renowned database that powers Google is now available to you worldwide.

## Overview

[Google Cloud Bigtable](https://cloud.google.com/bigtable/) offers you a fast, fully managed, almost infinitely scalable NoSQL database service that's ideal for web, mobile, and IoT applications requiring terabytes to petabytes of data. Unlike comparable market offerings, Cloud Bigtable doesn't require you to sacrifice speed, scale, or cost efficiency when your applications grow. The Bigtable service that Cloud Bigtable relies upon has been battle-tested at Google for more than 10 years—it's the database driving major applications such as Search, Analytics, Maps and Gmail.

## Quickstart
[Quickstart/HBase](quickstart) - Create a Cloud Bigtable Cluster and the hbase shell from within a docker container on your local machine

## Java
* [Hello World](java/hello-world) - This sample has been migrated to: https://github.com/GoogleCloudPlatform/java-docs-samples/blob/main/bigtable/hbase/snippets/src/main/java/com/example/bigtable/HelloWorld.java
* [Import HBase Sequence files](java/dataflow-import-examples) Import HBase sequence files directly to Cloud Bigtable using Dataflow.
* [Dataproc Wordcount using Map/Reduce](java/dataproc-wordcount) - How to load data to Cloud Bigtable using Dataproc on GCE
* [GAE J8 Std-Hello World](https://github.com/googlecloudplatform/java-docs-samples/tree/master/appengine-java8/bigtable) - Accessing Cloud Bigtable from App Engine standard

## Dataflow
* [Connector-Examples](java/dataflow-connector-examples) - Using the cloud dataflow connector for Bigtable, do write Hello World to two rows, Use Cloud Pub / Sub to count Shakespeare, count the number of rows in a Table, and copy records from BigQuery to BigTable.
* [Pardo-HelloWorld](java/dataflow-pardo-helloworld) - example of using Cloud Dataflow without the connector.

## Go
* [cbt](https://github.com/GoogleCloudPlatform/gcloud-golang/tree/master/bigtable/cmd/cbt) [doc](https://godoc.org/google.golang.org/cloud/bigtable/cmd/cbt) Basic command line interactions with Cloud Bigtable - A really great place to start learning the Go Client.
* [helloworld](https://github.com/GoogleCloudPlatform/golang-samples/tree/master/bigtable/helloworld) - Basic Hello world example application demonstrating how to read and write to a Cloud Bigtable instance. 
* [usercounter](https://github.com/GoogleCloudPlatform/golang-samples/tree/master/bigtable/usercounter) - Accessing Cloud Bigtable from App Engine Flexible
* [search](https://github.com/GoogleCloudPlatform/golang-samples/tree/master/bigtable/search) - Create and search a Cloud Bigtable.


## Python
* [Hello
  World](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/bigtable/hello)
  A minimal application that demonstrates using the Googe Cloud Client
  libraries to create a temporary table, write some rows, read them back and
  clean up.
* [Hello World
  (Happybase)](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/bigtable/hello_happybase)
  A minimal application that demonstrates using the Happybase API create a
  temporary table, write some rows, read them back and clean up.

## Questions and discussions

If you have questions or run into issues with Google Cloud Bigtable or the
client libraries, you can use any of the following forums:

* Stack Overflow: tag questions with [`google-cloud-bigtable`][stackoverflow-link]
* Mailing list: [google-cloud-bigtable-discuss@][google-cloud-bigtable-discuss]

You can also subscribe to
[google-cloud-bigtable-announce@][google-cloud-bigtable-announce] list to receive
infrequent product and client library announcements.

## Contributing changes

See [CONTRIBUTING.md](CONTRIBUTING.md) for more information on how to contribute
to this project.

## More examples

More Google Cloud Bigtable examples are available in the following languages:

* [Java](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/bigtable)
* [Python](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/bigtable)
* [Node](https://github.com/googleapis/nodejs-bigtable/tree/master/samples)
* [Go](https://github.com/GoogleCloudPlatform/golang-samples/tree/master/bigtable)
* [Dotnet](https://github.com/GoogleCloudPlatform/dotnet-docs-samples/tree/master/bigtable/api)
* [C++](https://github.com/googleapis/google-cloud-cpp/tree/master/google/cloud/bigtable/examples)
* [Ruby](https://github.com/GoogleCloudPlatform/ruby-docs-samples/tree/master/bigtable)
* [PHP](https://github.com/GoogleCloudPlatform/php-docs-samples/tree/master/bigtable)


## License

Apache 2.0; see [LICENSE](LICENSE) for details.

<!-- references -->

[travis-shield]: https://travis-ci.org/GoogleCloudPlatform/cloud-bigtable-examples.svg
[travis-link]: https://travis-ci.org/GoogleCloudPlatform/cloud-bigtable-examples/builds
[stackoverflow-shield]: https://img.shields.io/badge/stackoverflow-google--cloud--bigtable-blue.svg
[nodejs-bigtable]: https://github.com/googleapis/nodejs-bigtable
[stackoverflow-link]: http://stackoverflow.com/search?q=[google-cloud-bigtable]
[google-cloud-bigtable-discuss]: https://groups.google.com/group/google-cloud-bigtable-discuss
[google-cloud-bigtable-announce]: https://groups.google.com/group/google-cloud-bigtable-announce
"
zpng/spring-cloud-microservice-examples,master,364,240,2016-10-28T04:31:24Z,162,7,spring-cloud-microservice-examples,angularjs cloud eureka-server finagle hystrix java spring-cloud-microservice springboot thrift zipkin,"# spring-cloud-microservice-examples
spring-cloud-microservice-examples

## 说明
  目前该项目实现了 zuul(路由模块), config-server(配置管理), eureka server（服务注册和发现）, zipkin（服务调用追踪）,hystrix, turbine stream (熔断分析)
  simple-service,simple-serviceB两个待发现的服务
  simple-ui (一个用angular写的前端页面)
  
  路由功能实现在 cloud-api-gateway 模块，注册到eureka server上面，所有的请求访问 http://localhost:5555, 然后根据路由规则
  ```
zuul.routes.api-a.path: /cloud-simple-service/**
zuul.routes.api-a.serviceId: cloud-simple-service

zuul.routes.api-b.path: /cloud-simple-serviceB/**
zuul.routes.api-b.serviceId: cloud-simple-serviceB

zuul.routes.api-ui.path: /cloud-simple-ui/**
zuul.routes.api-ui.serviceId: cloud-simple-ui
 ```
 分别请求到  注册到eureka server的cloud-simple-service 和 cloud-simple-serviceB服务。
 服务的架构图:
 ![流程图](https://docs.google.com/drawings/d/1kb_2cLW-KcwhWfmu-iburNTCKKuH7HGUEdQCKCZMgZE/pub?w=960&h=720)

---
## 使用指南
  * 先决条件
  本机安装rabbitmq,并启动
  ```
  rabbitmq-server
  ```
  本机安装mysql,并启动且创建dev和test数据库,并分别创建表
  ```
  mysql.server start
  mysql -uroot
    CREATE TABLE `user` (
  `id` int(11) NOT NULL,
  `username` varchar(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8
   dev数据库的user表中插入数据
   INSERT INTO `user` VALUES (1,'dev1'),(2,'dev2'),(3,'dev3');
   test数据库的user表中插入数据
   INSERT INTO `user` VALUES (1,'test1'),(2,'test2'),(3,'test3');
  ```

 * 运行各模块
  ```
  cd cloud-api-gateway
  mvn spring-boot:run  #端口5555
  cd cloud-config-server
  mvn spring-boot:run  #端口8888
  cd cloud-eureka-server
  mvn spring-boot:run  #端口8761
  cd cloud-simple-service
  mvn spring-boot:run  #端口8081
  cd cloud-simple-service
  mvn spring-boot:run --server.port=8082  # cloud-simple-service 以8082端口再次启动服务
  cd cloud-simple-ui
  mvn spring-boot:run #端口8090
  cd cloud-zipkin
  mvn spring-boot:run #端口9966
  ```
 * 打开浏览器输入网址并浏览效果
 ```
  查看Eureka Server
  http://localhost:8761 #查看eureka
 ```
  ![Eureka Server](https://drive.google.com/uc?id=0BxyRSlBgU-ShX1dEdG5YSi10OEE)

  ---
  ```
  请求simple service, simple service2, simple serviceB
  http://localhost:8081/user  #simple service
  结果:
  [
    {
        id: 1,
        username: ""dev1""
    },
    {
        id: 2,
        username: ""dev2""
    },
    {
        id: 3,
        username: ""dev3""
    }
  ]
  http://localhost:8082/user  #simple service2
  结果:
  [
    {
        id: 1,
        username: ""dev1""
    },
    {
        id: 2,
        username: ""dev1""
    },
    {
        id: 3,
        username: ""dev1""
    }
  ]
  http://localhost:8091/user  #simple serviceB
  结果:
  Result from simpleserviceB
  ```
  本项目实现了通过spring-cloud-bus, 传播config-server中config的变化.下面动手验证之.
  1. 下载配置git repository
    ```
    git clone git@github.com:zpng/spring-cloud-config-demo.git
    ```
    根目录下有个cloud-config-repo目录,该目录下有两个文件:
    cloud-simple-service-dev.properties
    cloud-simple-service-test.properties
    分别是cloud-simple-service在 dev和test环境下的配置信息
    cloud-simple-service-dev.properties内容:
    ```
    mysqldb.datasource.url=jdbc\:mysql\://localhost\:3306/dev?useUnicode\=true&characterEncoding\=utf-8

    mysqldb.datasource.username=root

    mysqldb.datasource.password=

    logging.level.org.springframework.web:DEBUG

    ```
    cloud-simple-service-test.properties内容:
    ```
    mysqldb.datasource.url=jdbc\:mysql\://localhost\:3306/test?useUnicode\=true&characterEncoding\=utf-8

    mysqldb.datasource.username=root

    mysqldb.datasource.password=

    logging.level.org.springframework.web:DEBUG
    ```
  1. 修改 cloud-simple-service-dev.properties 内容,
   ```
    mysql url中使用的dev数据库变为test数据库
     mysqldb.datasource.url=jdbc\:mysql\://localhost\:3306/dev?useUnicode\=true&characterEncoding\=utf-8
     ->
     mysqldb.datasource.url=jdbc\:mysql\://localhost\:3306/test?useUnicode\=true&characterEncoding\=utf-8

     git add -A
     git commit -m ""MOD: update config""
     git push origin master  #将修改push到git repositoy
   ```
  1. 此时并需要重启config-server或者simple-service,只需要发送一个POST请求到config-server,并通过bus传播到使用该配置文件的服务中.
    ```
    curl -X POST http://localhost:8888/bus/refresh  #(config-server启动在8888端口)
    ```
    此时刷新前端页面
    ```
    http://localhost:8081/user  #simple service
    http://localhost:8082/user  #simple service2
    ```
    发现数据都已变成:
    ```
    [
        {
            id: 1,
            username: ""test1""
        },
        {
            id: 2,
            username: ""test2""
        },
        {
            id: 3,
            username: ""test3""
        }
    ]
    ```
    ---
    1. 验证路由逻辑
    cloud-api-gateway服务使用了zuul进行请求转发,转发规则如下:
    ```
    # routes to serviceId
    zuul.routes.api-a.path: /cloud-simple-service/**
    zuul.routes.api-a.serviceId: cloud-simple-service

    zuul.routes.api-b.path: /cloud-simple-serviceB/**
    zuul.routes.api-b.serviceId: cloud-simple-serviceB

    zuul.routes.api-ui.path: /cloud-simple-ui/**
    zuul.routes.api-ui.serviceId: cloud-simple-ui
    ```
    并且zuul服务中进行了token验证,需要请求参数中包含accessToken,accessToken可以为任意值,如果不包含该参数则请求不能
    转发过去.
    ```
    http://localhost:5555/cloud-simple-ui/users?accessToken=test
    结果:
    [
        {
            id: 1,
            username: ""test1""
        },
        {
            id: 2,
            username: ""test2""
        },
        {
            id: 3,
            username: ""test3""
        }
    ]

    http://localhost:5555/cloud-simple-serviceB/user?accessToken=tbbsxxxxd
    结果: Result from simpleserviceB
    http://localhost:5555/cloud-simple-service/user?accessToken=xxxdaew
    结果:
    [
        {
            id: 1,
            username: ""test1""
        },
        {
            id: 2,
            username: ""test2""
        },
        {
            id: 3,
            username: ""test3""
        }
    ]
    ```
    可见zuul已经完全发挥了它的路由作用.

   1. Hystrix
    Hystrix是熔断器, Hystrx Dashboard实现了监控单个Hystrix stream的功能.
    ```
    http://localhost:8022/hystrix/
    ```
    打开后页面如下:
    ![hystrix stream页面](https://drive.google.com/uc?id=0BxyRSlBgU-ShTG1QZUpSc1hCV2c)
    在其中输入
    ```
    http://localhost:8090/hystrix.stream
    ```
    (cloud-simple-ui服务),即可监控该服务的stream,如下图
    ![simple-ui-hystrix-stream](https://drive.google.com/uc?id=0BxyRSlBgU-ShUmRwNzluRWhxNmM)
    注意需要请求几次cloud-simple-ui服务,该图上才会有结果.
   1. Turbine
    本示例使用了turbine-amqp, 然后各个需要统计hystrix stream的微服务,包含依赖
    ```
            <!--for turbine stream-->
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-netflix-hystrix-stream</artifactId>
            </dependency>
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-starter-stream-rabbit</artifactId>
            </dependency>
    ```
    即可将stream 发送到rabbitmq队列,然后turbine stream项目获取这些stream, 然后显示在图示上,这样跟之前的区别是可以监控所有
    的微服务,而不是单个主机的stream.
    同样打开
    ```
    http://localhost:8022/hystrix/
    ```
    在其中输入
    ```
    http://localhost:8989/turbine.stream
    ```
    则可以看到如下图所示
    ![turbine stream](https://drive.google.com/uc?id=0BxyRSlBgU-ShSmFsdzY1ZWIxdGc)
    如图所示可以看到 cloud-simple-service, cloud-simple-serviceB, cloud-simple-ui 共3个服务的Hystrix Stream.

   1. Zipkin
    zipkin可以跟踪微服务的调用以及,各个路径上面的时间,进而分析瓶颈.
    打开
    ```
    http://localhost:9966
    ```

  trace如下图:
    ![zipkin-simple-ui-trace](https://drive.google.com/uc?id=0BxyRSlBgU-Shb3Bab2sxN1lUSE0)
    dependencies如下图:
    ![zipkin-dependencies](https://drive.google.com/uc?id=0BxyRSlBgU-ShLWJDRGd1VUhMWHc)


  
"
joshlong-attic/boot-examples,master,225,152,2013-12-16T10:39:28Z,587,14,a repository for convenient Spring Boot examples,,"boot-examples
=============

a repository for convenient Spring Boot examples
"
RefactoringGuru/design-patterns-java,main,850,253,2017-09-15T12:26:36Z,278,2,Design Pattern Examples in Java,design-patterns java,"# Design Patterns in Java

This repository is part of the [Refactoring.Guru](https://refactoring.guru/design-patterns) project.

It contains Java examples for all classic GoF design patterns.


## Requirements

The examples were written in Java 8, but also tested in Java 9.

For the best experience, we recommend working with examples in IntelliJ IDEA. The Community Edition of IDE is available for free (https://www.jetbrains.com/idea/download/).

After downloading or cloning this repository to your computer, import its root directory into a New project:

- Either through start dialog: Select ""Import Project"" option and skip through the rest of the steps.

- Or via the main menu: File > New > Project from Existing Sources...

After importing the project, you will be able to run examples by right-clicking ""Demo"" files inside every example and selecting the ""Run"" command from the context menu.


## Roadmap

- [ ] Add detailed comments all classes.
- [ ] Add structure-only examples.


## Contributor's Guide

We appreciate any help, whether it's a simple fix of a typo or a whole new example. Just [make a fork](https://help.github.com/articles/fork-a-repo/), do your change and submit a [pull request](https://help.github.com/articles/creating-a-pull-request-from-a-fork/).

Here's a style guide which might help you to keep your changes consistent with our code:

1. All code should meet the [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html)

2. Try to hard wrap the code at 80th's character. It helps to list the code on the website without scrollbars.

3. Examples should match following package convention: refactoring_guru.{pattern}.{example_name}. Example:

    ```java
    package refactoring_guru.factory_method.ui_example.buttons;

    class Button {
    ...
    ```

4. Places classes into separate files.

5. Group classes into sub-packages. It helps people to understand dependencies of a class by glancing over its imports. Example:

    ```java
    package refactoring_guru.factory_method.example.buttons;

    class Button {
    ...
    ```

    ```java
    package refactoring_guru.factory_method.example.factories;

    import Button;

    class Factory {
    ...
    ```

6. Comments may or may not have language tags in them, such as this:

    ```java
    /**
     * EN: All products families have the same varieties (MacOS/Windows).
     *
     * This is a MacOS variant of a button.
     *
     * RU: Все семейства продуктов имеют одни и те же вариации (MacOS/Windows).
     *
     * Это вариант кнопки под MacOS.
     */
    ```

    Don't be scared and ignore the non-English part of such comments. If you want to change something in a comment like this, then do it. Even if you do it wrong, we'll tell you how to fix it during the Pull Request.


## License

This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.

<a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-nd/4.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png"" /></a>


## Credits

Authors: Bohdan Herashchenko ([@b1ger](https://github.com/b1ger)) and Alexander Shvets ([@neochief](https://github.com/neochief))
"
RameshMF/spring-boot-tutorial,master,1648,1718,2018-09-17T07:25:55Z,2064,5,"100+ Spring Boot Articles, Tutorials, Video tutorials,  Projects, Guides, Source code examples etc",annotations spring-application spring-boot spring-data spring-security tutorial xml-configuration,"<h1>YouTube Channel - Spring Boot Tutorial</h1>
<p>Subscribe for future video and updates</p>

<a href=""https://www.youtube.com/playlist?list=PLGRDMO4rOGcNSBOJOlrgQqGpIgo6_VZgR"" target=""_blank"">Spring Boot Tutorial on YouTube
</a>

# Newly published spring boot tutorials (2020)
<ul style=""text-align: left;"">
<li><a href=""https://www.javaguides.net/2021/07/react-js-react-hooks-spring-boot.html"" target=""_blank"">React JS ( React Hooks) + Spring Boot Tutorial</a><br></li><li><a href=""https://www.javaguides.net/2021/07/spring-boot-tutorial-for-beginners.html"" target=""_blank"">Spring Boot Tutorial for Beginners Step by Step</a><br></li><li><a href=""https://www.javaguides.net/2021/07/spring-boot-tutorial-build-employee-management-project.html"" target=""_blank"">Spring Boot Tutorial - Build Employee Management Project from Scratch using Spring Boot + Spring Security + Thymeleaf and MySQL Database</a><br></li><li><a href=""https://www.javaguides.net/2021/06/configure-jwt-with-spring-boot-and-swagger.html"" target=""_blank"">Configure JWT with Spring Boot and Swagger UI</a><br></li><li><a href=""https://www.javaguides.net/2021/06/spring-boot-rest-api-documentation-with-swagger.html"" target=""_blank"">Spring Boot REST API Documentation with Swagger</a><br></li><li><a href=""https://www.javaguides.net/2021/05/spring-boot-crud-tutorial.html"" target=""_blank"">Spring Boot CRUD Tutorial with Spring MVC, Spring Data JPA, Thymeleaf, Hibernate, MySQL</a><br></li><li><a href=""https://www.javaguides.net/2021/04/spring-boot-project-employee-management.html"" target=""_blank"">Spring Boot Project - Employee Management System | Project for Final Year Students</a><br></li><li><a href=""https://www.javaguides.net/2021/04/deploy-spring-boot-mysql-crud-rest-api-Application-on-aws.html"" target=""_blank"">Deploy Spring Boot MySQL CRUD REST API Application on AWS | Elastic Beanstalk | AWS RDS</a><br></li><li><a href=""https://www.javaguides.net/2021/04/spring-boot-dto-validation-example.html"" target=""_blank"">Spring Boot DTO Validation Example</a><br></li><li><a href=""https://www.javaguides.net/2021/04/deploy-spring-boot-application-on-aws.html"" target=""_blank"">Deploy a Spring Boot Application on AWS | Elastic Beanstalk</a><br></li><li><a href=""https://www.javaguides.net/2021/04/deploy-spring-boot-mvc-application-on-aws.html"" target=""_blank"">Deploy Spring Boot MVC Application on AWS | Elastic Beanstalk</a><br></li><li><a href=""https://www.javaguides.net/2021/04/deploy-spring-boot-war-file-on-tomcat-in-aws.html"" target=""_blank"">Deploy Spring Boot WAR file on Tomcat in AWS | Elastic Beanstalk</a></li><li><a href=""https://www.javaguides.net/2021/03/validation-in-spring-boot-rest-api-with-hibernate-validator.html"" target=""_blank"">Validation in Spring Boot REST API with Hibernate Validator (Java Bean Validation Annotations)</a><br></li><li><a href=""Spring Boot DTO Example - Entity To DTO Conversion"" target=""_blank"">Spring Boot DTO Example - Entity To DTO Conversion</a><br></li><li><a href=""https://www.javaguides.net/2021/01/prerequisites-to-learn-spring-boot.html"" target=""_blank"">Prerequisites to Learn Spring Boot</a><br></li><li><a href=""https://www.javaguides.net/2021/01/angular-spring-boot-rest-api-example.html"" target=""_blank"">Angular + Spring Boot REST API Example Tutorial</a><br></li><li><a href=""https://www.javaguides.net/2020/11/jsp-vs-thymeleaf-support-in-spring-boot.html"" target=""_blank"">JSP vs Thymeleaf Support in Spring Boot</a><br></li><li><a href=""https://www.javaguides.net/2020/11/spring-professional-certification-topics-and-questions.html"" target=""_blank"">Spring Professional Certification Topics and Questions</a><br></li><li><a href=""https://www.javaguides.net/2020/07/spring-boot-react-js-crud-example-tutorial.html"" target=""_blank"">Spring Boot + React JS CRUD Example Tutorial</a></li>
<li><a href=""https://www.javaguides.net/2020/07/spring-boot-angular-10-crud-example-tutorial.html"" target=""_blank"">Spring Boot + Angular 10 CRUD Example Tutorial</a></li>
<li><a href=""https://www.javaguides.net/2020/07/react-js-spring-boot-rest-api-example-tutorial.html"" target=""_blank"">React JS + Spring Boot REST API Example Tutorial</a></li>
<li><a href=""https://www.javaguides.net/2020/07/spring-boot-project-architecture.html"" target=""_blank"">Spring Boot Project Architecture</a></li>
<li><a href=""https://www.javaguides.net/2020/07/how-spring-mvc-works-internally.html"" target=""_blank"">How Spring MVC Works Internally</a></li>
<li><a href=""https://www.javaguides.net/2020/07/three-tier-three-layer-architecture-in-spring-mvc-web-application.html"" target=""_blank"">Three Tier (Three Layer) Architecture in Spring MVC Web Application</a></li>
<li><a href=""https://www.javaguides.net/2020/06/best-practice-to-develop-persistence-or-dao-layer.html"" target=""_blank"">Best Practice to Develop Persistence or DAO Layer</a></li>
<li><a href=""https://www.javaguides.net/2020/06/best-youtube-channels-to-learn-spring-boot.html"" target=""_blank"">Best YouTube Channels to learn Spring Boot</a></li>
<li><a href=""https://www.javaguides.net/2020/06/pagination-and-sorting-with-spring-boot-thymeleaf-spring-data-jpa-hibernate-mysql.html"" target=""_blank"">Pagination and Sorting with Spring Boot, ThymeLeaf, Spring Data JPA, Hibernate, MySQL</a></li>
<li><a href=""https://www.javaguides.net/2020/06/free-spring-boot-microservices-open-source-projects-github.html"" target=""_blank"">Free Spring Boot Microservices Open Source Projects | GitHub | Download</a></li>
<li><a href=""https://www.javaguides.net/2020/06/spring-security-tutorial-with-spring-boot-spring-data-jpa-thymeleaf-and-mysql-database.html"" target=""_blank"">Spring Security Tutorial with Spring Boot, Spring Data JPA, Thymeleaf and MySQL Database</a></li>
<li><a href=""https://www.javaguides.net/2020/06/free-spring-boot-angular-open-source-projects-github.html"" target=""_blank"">Free Spring Boot Angular Open Source Projects | GitHub</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-crud-web-application-with-thymeleaf.html"" target=""_blank"">Spring Boot CRUD Web Application with Thymeleaf, Spring MVC, Spring Data JPA, Hibernate, MySQL</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part1.html"" target=""_blank""></a><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part1.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 1</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part2.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 2</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part3.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 3</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part4.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 4</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part5.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 5</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part6.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 6</a>&nbsp;</li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-crud-database-real-time-project-part7.html"" target=""_blank"">Spring Boot Thymeleaf CRUD Database Real-Time Project - PART 7</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-jsp-example-tutorial.html"" target=""_blank"">Spring Boot JSP Example Tutorial</a></li>
<li><a href=""https://www.javaguides.net/2020/05/spring-boot-thymeleaf-example-tutorial.html"" target=""_blank"">Spring Boot Thymeleaf Example Tutorial</a></li>
<li><a href=""https://www.javaguides.net/2020/04/jpa-hibernate-one-to-many-mapping-example-with-spring-boot.html"" target=""_blank"">JPA, Hibernate One to Many Mapping Example with Spring Boot and MySQL Database</a></li>
<li><a href=""https://www.javaguides.net/2020/04/deploying-spring-boot-war-file-with-jsp-to-tomcat.html"" target=""_blank"">Deploying Spring Boot WAR file with JSP to Tomcat</a></li>
<li><a href=""https://www.javaguides.net/2020/04/jpa-and-hibernate-many-to-many-mapping-spring-boot.html"" target=""_blank"">JPA and Hibernate Many to Many Mapping with Spring Boot - @ManyToMany and @JoinTable</a></li>
<li><a href=""https://www.javaguides.net/2020/04/spring-boot-file-upload-download-rest-api-example.html"" target=""_blank"">Spring Boot File Upload / Download Rest API Example</a></li>
<li><a href=""https://www.javaguides.net/2020/04/spring-boot-mysql-jpa-hibernate-restful-crud-api-tutorial.html"" target=""_blank"">Spring Boot, MySQL, JPA, Hibernate Restful CRUD API Tutorial</a></li>
<li><a href=""https://www.javaguides.net/2020/04/spring-boot-h2-jpa-hibernate-restful-crud-api-tutorial.html"" target=""_blank"">Spring Boot, H2, JPA, Hibernate Restful CRUD API Tutorial</a></li>
</ul>

<h1> Spring Boot Tutorials/Articles/Guides </h1>
<div dir=""ltr"" style=""text-align: left;"" trbidi=""on"">
<h2 style=""text-align: left;"">
Spring Boot Basics</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/getting-started-with-spring-boot.html"">Getting Started with Spring Boot</a></li>
<li><a href=""http://www.javaguides.net/2018/09/installing-spring-boot-with-maven-and-gradle.html"">Installing Spring Boot with Maven and Gradle</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-building-restful-web-service.html"">Spring Boot 2 Hello World Application</a></li>
<li><a href=""http://www.javaguides.net/2018/09/overview-of-spring-boot-starter-parent.html"">Overview of Spring Boot Starter Parent</a></li>
<li><a href=""http://www.javaguides.net/2018/09/important-spring-boot-starters-with-examples.html"">Important Spring Boot Starters with Examples</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-how-to-change-port-and-context-path.html"">Spring Boot How to Change Port and Context Path</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-deploy-war-file-to-external-tomcat.html"">Spring Boot 2 Deploy WAR file to External Tomcat</a></li>
<li><a href=""http://www.javaguides.net/2018/09/different-ways-of-running-spring-boot-appilcation.html"">Different Ways of Running Spring Boot Application</a></li>
<li><a href=""https://www.baeldung.com/spring-boot-migration"">Migrating from Spring to Spring Boot</a></li>
<li><a href=""http://www.javaguides.net/2018/10/spring-boot-annotations.html"">Spring Boot Annotations</a></li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot REST API Development</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-hibernate-5-mysql-crud-rest-api-tutorial.html"">Spring Boot 2 Hibernate 5 MySQL CRUD REST API Tutorial</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-jpa-mysql-crud-example.html"">Spring Boot 2 JPA MySQL CRUD Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-building-restful-web-service.html"">Spring Boot 2 Hello World Application</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-crud-rest-apis-validation-example.html"">Spring Boot 2 CRUD REST APIs Validation Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-data-jpa-auditing-with-spring-boot2-and-mysql-example.html"">Spring Data JPA Auditing with Spring Boot 2 and MySQL Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-exception-handling-for-rest-apis.html"">Spring Boot 2 Exception Handling for REST APIs</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-logging-slf4j-logback-and-log4j-example.html"">Spring Boot 2 Logging SLF4j Logback and LOG4j2 Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-jersey-rest-jpa-hibernate-5-crud-rest-apis-example.html"">Spring Boot 2 + Jersey REST + JPA + Hibernate 5 CRUD REST APIs Example</a></li>
<li><a href=""http://www.javaguides.net/2018/10/spring-boot-2-scheduling-tasks.html"">Spring Boot 2 - Scheduling Tasks</a></li>
<li><a href=""http://www.javaguides.net/2018/10/spring-boot-2-restful-api-documentation-with-swagger2-tutorial.html"">Spring Boot 2 RESTful API Documentation with Swagger 2 Tutorial</a></li>
<li><a href=""http://www.javaguides.net/2018/11/spring-boot-2-file-upload-and-download-rest-api-tutorial.html"">Spring Boot 2 - File Upload and Download Rest API Tutorial</a> // LATEST</li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot Web Application Development</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-mvc-using-spring-boot2-jsp-jpa-hibernate5-mysql-example.html"">Spring MVC + Spring Boot2 + JSP + JPA + Hibernate 5 + MySQL Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot2-mvc-web-application-thymeleaf-jpa-mysql-example.html"">Spring Boot 2 MVC Web Application Thymeleaf JPA MySQL Example</a></li>
<li><a href=""http://www.javaguides.net/2018/10/spring-boot-spring-mvc-validating-form.html"">Spring Boot 2 - Spring MVC + Thymeleaf Input Form Validation</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-jpa-multiple-data-sources-example.html"">Spring Boot JPA Multiple Data Sources Example</a></li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot with Spring Security</h2>
<div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-spring-mvc-role-based-spring-security-jpa-thymeleaf-mysql-tutorial.html"">Spring Boot 2 + Spring MVC + Role Based Spring Security + JPA + Thymeleaf + MySQL Tutorial</a></li>
<li><a href=""https://spring.io/guides/gs/authenticating-ldap/"">Authenticating a User with LDAP using Spring Boot and Spring Security</a></li>
<li><a href=""http://www.javaguides.net/2018/10/user-registration-module-using-springboot-springmvc-springsecurity-hibernate5-thymeleaf-mysql.html"">User Registration Module using Spring Boot 2 + Spring MVC + Spring Security + Hibernate 5 + Thymeleaf + MySQL</a></li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot Configuration</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-java-based-configuration-example.html"">Spring Boot 2 Java Based Configuration Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-xml-configuration-example.html"">Spring Boot 2 XML Configuration Example</a></li>
<li><a href=""https://www.baeldung.com/spring-boot-migration"">Migrating from Spring to Spring Boot</a></li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot Testing</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-data-jpa-repository-testing-using-spring-boot-datajpatest.html"">Spring Data JPA Repository Testing using Spring Boot @DataJpaTest</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-rest-apis-integration-testing.html"">Spring Boot 2 REST APIs Integration Testing</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-with-junit-5-testing.html"">Spring Boot 2 with JUnit 5 Testing Example</a></li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot Annotations</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-enableautoconfiguration-annotation-with-example.html"">Spring Boot @EnableAutoConfiguration Annotation with Example</a></li>
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-springbootapplication-annotation-with-example.html"">Spring Boot @SpringBootApplication Annotation with Example</a></li>
<li><a href=""http://www.javaguides.net/2018/10/spring-boot-annotations.html"">Spring Boot Annotations</a></li>
<li><a href=""http://www.javaguides.net/2018/10/spring-boot-creating-asynchronous-methods-using-async-annotation.html"">Spring Boot - Creating Asynchronous Methods using @Async Annotation</a></li>
</ul>
<h2 style=""text-align: left;"">
Configure Spring Boot with PostgreSQL</h2>
</div>
<div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2019/01/springboot-postgresql-jpa-hibernate-crud-restful-api-tutorial.html"">Spring Boot + PostgreSQL + JPA/Hibernate CRUD Restful API Tutorial</a></li>
</ul>
<h2 style=""text-align: left;"">
Spring Boot Mini Projects</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/mini-todo-management-project-using-spring-boot-springmvc-springsecurity-jsp-hibernate-mysql.html"">Mini Todo Management Project using Spring Boot + Spring MVC + Spring Security + JSP + Hibernate + MySQL</a></li>
<li><a href=""http://www.javaguides.net/2018/10/user-registration-module-using-springboot-springmvc-springsecurity-hibernate5-thymeleaf-mysql.html"">User Registration Module using Spring Boot + Spring MVC + Spring Security + Hibernate 5 + Thymeleaf + MySQL</a></li>
</ul>
</div>
</div>
<h1>Spring Boot + Angular 9 Tutorials // Latest </h1>
<ul style=""text-align: left;""><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-example-tutorial.html""></a>
<li><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-example-tutorial.html""></a><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-example-tutorial.html"">Spring Boot + Angular 9 CRUD Example Tutorial</a> - Main Tutorial</li>
<li><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-part-1-develop-springboot-crud-rest-apis.html"">Spring Boot + Angular 9 CRUD Tutorial - Part 1 - Develop Spring Boot CRUD Rest APIs</a></li>
<li><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-part-2-create-angular-9-app.html"">Spring Boot + Angular 9 CRUD - Part 2 - Create an Angular 9 App</a></li>
<li><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-part-3-develop-angular-9-crud-operations.html"">Spring Boot + Angular 9 CRUD - Part 3 - Develop Angular 9 CRUD Operations</a></li>
<li><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-9-crud-part-4-angular-9-crud-app-configuration.html"">Spring Boot + Angular 9 CRUD, Part 4 - Angular 9 CRUD App Configuration</a></li>
<li><a href=""https://www.javaguides.net/2020/01/spring-boot-angular-8-crud-part-5-running-angular-9-crud-app.html"">Spring Boot 2 + Angular 9 CRUD, Part 5 - Running Angular 9 CRUD App</a></li>
</ul>

<h1> Spring Boot + MongoDB </h1>
<ul style=""text-align: left;""><b><a href=""https://www.javaguides.net/2019/12/spring-boot-angular-mongodb-crud-example-tutorial.html""></a>
<li><a href=""https://www.javaguides.net/2019/12/spring-boot-angular-mongodb-crud-example-tutorial.html""><b></b></a><b><a href=""https://www.javaguides.net/2019/12/spring-boot-angular-mongodb-crud-example-tutorial.html"">Spring Boot + Angular + MongoDB CRUD Example Tutorial</a></b></li>
<li><b><a href=""https://www.javaguides.net/2019/12/spring-boot-mongodb-crud-example-tutorial.html"">Spring Boot + MongoDB CRUD Tutorial</a></b></li>
</b></ul>
"
payara/Payara-Examples,master,143,177,2015-06-20T15:38:47Z,12142,39,Repository for Example Code to demonstrate Payara specific features,,"//
// Copyright (c) 2016-2022 Payara Foundation and/or its affiliates.
//

# Payara Platform Examples
Repository for Example Code to demonstrate Payara specific features

### [Administration Samples](administration-examples)
This module contains some example asadmin scripts for managing Payara

### [Java EE](javaee)
Some simple Java EE example applications  
Payara Clustered Singleton example application

### [MicroProfile](microprofile)
Some simple MicroProfile example applications  

### [Payara Micro](payara-micro)
Example applications showing features of Payara Micro

### [Payara Services Examples](payara-services)
Some examples of additional Payara services, including:

* Request Tracing Service
* Notification Service
* EclipseLink Cache Coordination / Invalidation MDB examples

### [OSGi Examples](osgi)

Some simple examples of OSGi bundles that can be deployed on Payara Server

### [Ecosystem](ecosystem)

Examples of using development and integration tools and plugins like Maven and Gradle plugins.

### [Cloud Providers Examples](cloud-providers)

Some examples specific for cloud providers like AWS, Google, Azure, ...

### [Polyglot](polyglot)

Some examples using other JVM languages with Payara, including examples with GraalVM.
"
CamelCookbook/camel-cookbook-examples,master,260,187,2013-01-13T21:06:57Z,6908,62,Example source code for Apache Camel Developer's Cookbook,apache-camel examples integration packtpub,"Apache Camel Developer's Cookbook, 2nd Edition Samples
======================================================

[![Build Status](https://travis-ci.org/CamelCookbook/camel-cookbook-examples.png?branch=master)](https://travis-ci.org/CamelCookbook/camel-cookbook-examples)
[![Stories in Ready](https://badge.waffle.io/CamelCookbook/camel-cookbook-examples.png?label=ready&title=Ready)](https://waffle.io/CamelCookbook/camel-cookbook-examples?utm_source=badge)

This project contains the sample code for the [_Apache Camel Developer's Cookbook, 2nd Edition_](http://www.packtpub.com/apache-camel-developers-cookbook/book)
(Packt Publishing, TBD 2017) by [Scott Cranton](https://github.com/scranton), [Jakub Korab](https://github.com/jkorab), and [Christian Posta](https://github.com/christian-posta).
The latest version of this code is available on [GitHub](http://github.com/CamelCookbook/camel-cookbook-examples).

*This project is up to date with [Apache Camel 2.20.0](http://camel.apache.org/camel-2200-release.html).*

All of the examples are driven through JUnit tests, and are collectively structured as a set
of Apache Maven projects. To execute them, you will need a copy of the [Java 8 JDK](http://openjdk.java.net/install/)
and an [Apache Maven 3](http://maven.apache.org/) installation. 
Maven will download all of the appropriate project dependencies.

In order to execute all the tests, all you need to do is run:

    $ mvn clean install
"
databricks/learning-spark,master,3868,2424,2014-06-16T04:47:54Z,370,30,Example code from Learning Spark book,,"[![buildstatus](https://travis-ci.org/holdenk/learning-spark-examples.svg?branch=master)](https://travis-ci.org/holdenk/learning-spark-examples)
Examples for Learning Spark
===============
Examples for the Learning Spark book. These examples require a number of libraries and as such have long build files. We have also added a stand alone example with minimal dependencies and a small build file
in the mini-complete-example directory.


These examples have been updated to run against Spark 1.3 so they may
be slightly different than the versions in your copy of ""Learning Spark"".

Requirements
==
* JDK 1.7 or higher
* Scala 2.10.3
- scala-lang.org
* Spark 1.3
* Protobuf compiler
- On debian you can install with sudo apt-get install protobuf-compiler
* R & the CRAN package Imap are required for the ChapterSixExample
* The Python examples require urllib3

Python examples
===

From spark just run ./bin/pyspark ./src/python/[example]

Spark Submit
===

You can also create an assembly jar with all of the dependencies for running either the java or scala
versions of the code and run the job with the spark-submit script

./sbt/sbt assembly OR mvn package
cd $SPARK_HOME; ./bin/spark-submit   --class com.oreilly.learningsparkexamples.[lang].[example] ../learning-spark-examples/target/scala-2.10/learning-spark-examples-assembly-0.0.1.jar

[![Learning Spark](http://akamaicovers.oreilly.com/images/0636920028512/cat.gif)](http://www.jdoqocy.com/click-7645222-11260198?url=http%3A%2F%2Fshop.oreilly.com%2Fproduct%2F0636920028512.do%3Fcmp%3Daf-strata-books-videos-product_cj_9781449358600_%2525zp&cjsku=0636920028512)"
castagna/jena-examples,master,280,128,2011-10-10T13:02:42Z,110,8,"A collection of ready to use, small and self contained examples on how to use Apache Jena",,
zhangjun0x01/bigdata-examples,master,257,132,2020-05-30T09:11:48Z,31775,8,分享一些在工作中的大数据实战案例，包括flink、kafka、hadoop、presto等等。欢迎大家关注我的公众号【大数据技术与应用实战】，一起成长。,,"分享自己平时工作和学习中遇到的一些大数据相关的知识点，如hadoop、flink、presto、hive、iceberg等等，更多精彩内容欢迎大家关注我的微信公众号：

![欢迎关注我的公众号：大数据技术与应用实战](https://img-blog.csdnimg.cn/20200727095900191.png)
"
haoxiaoyong1014/springboot-examples,master,188,139,2018-05-28T03:03:07Z,7570,11,spring boot 集成各技术案例,spring-boot springboot-netty springboot-oauth2 springboot-redis,"# springboot-examples
spring boot 集成各技术案例 <img src=""https://camo.githubusercontent.com/95c3d7ef0b5da8445087e462514063675f79321d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4372656174697665253230436f6d6d6f6e732d4443334432342e737667"" alt=""知识共享协议（CC协议）"" data-canonical-src=""https://img.shields.io/badge/License-Creative%20Commons-DC3D24.svg"" style=""max-width:100%;"">


[![Stargazers over time](https://starchart.cc/haoxiaoyong1014/springboot-examples.svg)](https://starchart.cc/haoxiaoyong1014/springboot-examples)

2018/5/24 添加 springboot-rabbitMQ(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-rabbitmq"">消息队列</a>)

2018/6/12 添加  springboot-redis-docker(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-redis-docker"">Docker 部署 SpringBoot 项目整合 Redis 镜像做访问计数Demo</a>)

2018/6/13 添加 springboot-web-thymeleaf (<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-web-thymeleaf"">springboot整合thymeleaf</a>)

2018/6/20 添加 springboot2-oauth2(springBoot版本:2.0.1.RELEASE)

 **springboot2-oauth2 包括:** 
* springboot-oauth2-authorization-server(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-oauth2-authorization-server"">springboot整合OAuth2.0认证服务</a>),

* springboot-oauth2-resource-server(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-oauth2-resource-server"">资源服务</a>)

2018/6/30 添加 springboot-mybatis-ehcache (<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-mybatis-myehcache"">使用EhcacheCache做二级缓存,使用pageHelper做分页插件</a>)

2018/7/14 添加 springboot-websocket (<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-websocket"">在线人数统计,消息发送,一对一,一对多发送消息<a>)
  
2018/8/10 添加 springboot-shrio(<a href=""https://github.com/haoxiaoyong1014/springboot-shiro"">基础版<a>) 

2018/8/13 添加 springboot-shiro-v1.2.0(<a href=""https://github.com/haoxiaoyong1014/springboot-shiro-v1.2.0"">加强版<a>)

2018/9/28 添加 springboot-quartz(<a href=""https://github.com/haoxiaoyong1014/springboot-quartz"">任务调度,持久化任务<a>)

2018/10/15 添加 springboot-SpringDataJpa(<a href=""https://github.com/haoxiaoyong1014/springboot-SpringDataJpa"">Spring Data JPA 使用<a>)

2018/10/20 添加 springboot-netty(<a href=""https://github.com/haoxiaoyong1014/springboot-netty"">springboot整合netty做心跳检测<a>)

2018/11/29 添加 springboot2-redis(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot2-redis"">springboot2x系列整合Redis(Lettuce版)<a>)

2019/2/20 添加 springboot-fastDFS(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-fastDFS"">springboot-fastDFS</a>)

2019/3/12 添加 global-exception(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/global-exception"">global-exception(Spring全局异常处理)</a>)

2019/5/11 添加 springboot-mongodb(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-mongodb"">springboot-mongodb(springboot整合mongodb)</a>)

2019/5/31 添加 springboot-login-Interceptor(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-login-Interceptor"">springboot拦截器整合JWT做验证token,以及token过期解决方案</a>)

2019/6/24 添加 springboot-druid(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-druid"">使用阿里巴巴提供的springboot整合druid包管理连接池</a>)

2019/7/30 添加 springboot-easyexcel-encapsulation(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-easyexcel-encapsulation"">对阿里巴巴easyexcel导入导出excel文件进行封装</a>)

2019/9/08 添加 strategy-aop(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/strategy-aop"">AOP+自定义注解+策略模式 记录操作日志，避免过多的 if else</a>)

2019/10/15 添加 chat-software(<a href=""https://github.com/haoxiaoyong1014/chat-software""> 基于Netty Spring Boot仿微信聊天项目</a>)

2020/1/11 添加 distributed-job(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/distributed-job"">spring-boot整合xxl-job,手动触发定时任务</a>)

2020/2/29 添加 mybatis-plus-example(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/mybatis-plus-example"">springboot整合mybatis-plus</a>)

2020/3/20 添加 okay-spring-boot-starter(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/okay-spring-boot-starter"">从SpringBoot源码到自己封装一个Starter</a>)

2020/5/08 添加 springboot-threadpool(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-threadpool"">SpringBoot 使用线程池-线程池隔离</a>)

2020/5/14 添加 springboot-swagger-enhance(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-swagger-enhance"">SpringBoot集成第三方swagger美化文档样式</a>)

2020/8/14 添加 springboot-admin-monitor(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-admin-monitor"">springBoot-admin 日志,系统监控</a>)

2020/9/10 添加 springboot-elk(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-elk"">springboot集成ELK,包含安装步骤</a>)

# springboot-redis-example(<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples"">redis系列</a>)

2018/6/12 添加  springboot-redis-docker(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-redis-docker"">Docker 部署 SpringBoot 项目整合 Redis 镜像做访问计数(PV)Demo</a>)

2018/07/27  添加springboot-redis-ranking (<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-redis-ranking"">基于Redis实现商品排行榜</a>)

2018/08/01 添加 springboot-redis-fridends (<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-redis-friends"">基于Redis实现查询共同好友</a>,
结合前端vue.js,前端项目地址: <a href=""https://github.com/haoxiaoyong1014/common-friends"">common-friends</a>)

2018/11/16 添加 redis-manage(<a href=""https://github.com/haoxiaoyong1014/redis-manage"">Redis的后台管理</a>,结合前端项目<a href=""https://github.com/haoxiaoyong1014/redis-manage-view"">redis-manage-view</a>)

2019/8/16 添加 springboot-idempotent(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-idempotent"">springboot + redis + 注解 + 拦截器 实现接口幂等性校验</a>)

2019/9/14 添加 springboot-mybatis-redis-cache(<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-mybatis-redis-cache"">使用redis做二级缓存</a>)

2019/10/29添加 [Redis专题(七)--基于Sentinel（哨兵）搭建实现Redis高可用集群](https://haoxiaoyong.cn/2019/10/29/2019/2019-12-03-redis-master-slave/)

2020/09/18添加 springboot-redis-range( [SpringBoot 使用 Redis Geo 实现查找附近的位置](https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-redis-range))

持续更新中....


"
leeowenowen/rxjava-examples,master,433,94,2016-04-16T03:04:32Z,23335,0,全面，完整，图文并茂的RxJavaAPI使用示例。,,"#RxJava 示例工程

#理解RxJava API的一个关键是明白API需要Observable的Case是异步使用场景，而返回普通对象类型的是同步使用场景， 比如flatmap与map, buffer中的多个重载等。

讲解ＲxJava如何使用的示例工程，你可以将它安装在android手机上，然后就可以随手学习ＲxJava的api了．
点击API名称，可以看到源码，源码输出以及对应的marble-diagram.
>API描述目前支持中文和英文两种语言, 如果你的Android设备使用的是中文,那么你看到的API描述会跟我如下的截图有所不同.

# rxjava-examples
rxjava-example android project

Show how to use RxJava API, you can install the [Demo APK](https://raw.githubusercontent.com/wiki/leeowenowen/rxjava-examples/apk/app-debug.apk) on your android phone, and then you
can learn RxJava API everywhere!

click the api name, and you can see the source code, output and relevant marble diagram at the same time.
all the source codes show on the sample gui are generated from my project source, and all the marble diagram is loaded from 
load.

[Download APK](https://raw.githubusercontent.com/wiki/leeowenowen/rxjava-examples/apk/app-debug.apk)


![Barcode/二维码](https://raw.githubusercontent.com/wiki/leeowenowen/rxjava-examples/res/barcode.png)

![Demo Screenshot1](https://raw.githubusercontent.com/wiki/leeowenowen/rxjava-examples/res/rxjava-1.png)


![Demo Screenshot2](https://raw.githubusercontent.com/wiki/leeowenowen/rxjava-examples/res/rxjava-2.png)
"
mattdesl/lwjgl-basics,master,1853,185,2012-11-05T01:42:27Z,18293,10,:wrench: LibGDX/LWJGL tutorials and examples,,
spring-projects/spring-integration-samples,main,2272,2544,2011-08-10T04:40:02Z,14030,21,"You are looking for examples, code snippets, sample applications for Spring Integration? This is the place.",,"Spring Integration Samples
==========================

[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.spring.io/scans?search.rootProjectNames=spring-integration-samples)

Welcome to the **Spring Integration Samples** repository which provides **50+ samples** to help you learn [Spring Integration][]. To simplify your experience, the *Spring Integration* samples are split into 4 distinct categories:

* Basic
* Intermediate
* Advanced
* Applications
* DSL

Inside of each category you'll find a **README.md** file, which will contain a more detailed description of that category. Each sample also comes with its own **README.md** file explaining further details, e.g. how to run the respective sample.

| For additional samples, please also checkout the [Spring Integration Extensions][] project as it also provides numerous samples.

*Happy Integration!*

# Note

This (main) branch requires Spring Integration 6.0 or above. 
For samples running against earlier versions of Spring Integration, use the __5.5.x__ and other branches.

The project requires now Java 17 or above.
To open the project in the IDE, use its `import` option against a `build.gradle` file from the root project directory.

## Related GitHub projects

* [Spring Integration][]
* [Spring Integration Extensions][]

## Community Sample Projects

* [Xavier Padró][]

# Categories

Below is a short description of each category.

## DSL

This directory holds demos/samples for Spring Integration 4.0 Java Configuration as well as the Java DSL Extension.

## Basic

This is a good place to get started. The samples here are technically motivated and demonstrate the bare minimum with regard to configuration and code to help you to get introduced to the basic concepts, API and configuration of Spring Integration. For example, if you are looking for an answer on how to wire a **Service Activator**  to a **Channel** or how to apply a **Gateway** to your message exchange or how to get started with using the **MAIL** or **XML** module, this would be the right place to find a relevant sample. The bottom line is that this is a good starting point.

* **amqp** - Demonstrates the functionality of the various **AMQP Adapters**
* **barrier** - Shows how to suspend a thread until some asynchronous event occurs
* **control-bus** - Demonstrates the functionality of the **Control Bus**
* **enricher** - This sample demonstrates how the Enricher components can be used
* **feed** - Demonstrates the functionality of the **Feed Adapter** (RSS/ATOM)
* **file** - Demonstrates aspects of the various File Adapters (e.g. **File Inbound/Outbound Channel Adapters**, file **polling**)
* **ftp** - Demonstrates the **FTP support** available with Spring Integration
* **helloworld** - Very simple starting example illustrating a basic message flow (using **Channel**, **ServiceActivator**, **QueueChannel**)
* **http** - Demonstrates request/reply communication when using a pair of **HTTP Inbound/Outbound gateways**
* **jdbc** - Illustrates the usage of the Jdbc Adapters, including object persistence and retrieval
* **jms** - Demonstrates **JMS** support available with Spring Integration
* **jmx** - Demonstrates **JMX** support using a **JMX Attribute Polling Channel** and **JMX Operation Invoking Channel Adapter**
* **jpa** - Shows the usage of the JPA Components
* **mail** - Example showing **IMAP** and **POP3** support
* **mqtt** - Demonstrates the functionality of inbound and outbound **MQTT Adapters**
* **mongodb** - Shows how to persist a Message payload to a **MongoDb** document store and how to read documents from **MongoDb**
* **oddeven** - Example combining the functionality of **Inbound Channel Adapter**, **Filter**, **Router** and **Poller**
* **quote** - Example demoing core EIP support using **Channel Adapter (Inbound and Stdout)**, **Poller** with Interval Triggers, **Service Activator**
* **sftp** - Demonstrating SFTP support using **SFTP Inbound / Outbound Channel Adapters**
* **tcp-amqp** - Demonstrates basic functionality of bridging the **Spring Integration TCP Adapters** with **Spring Integration AMQP Adapters**
* **tcp-broadcast** - Demonstrates broadcasting a message to multiple connected TCP clients.
* **tcp-client-server** - Demonstrates socket communication using **TcpOutboundGateway**, **TcpInboundGateway** and also uses a **Gateway** and a **Service Activator**
* **tcp-with-headers** - Demonstrates sending headers along with the payload over TCP using JSON.
* **testing-examples** - A series of test cases that show techniques to **test** Spring Integration applications.
* **twitter** - Illustrates Twitter support using the **Twitter Inbound Channel Adapter**, **Twitter Inbound Search Channel Adapter**, **Twitter Outbound Channel Adapter**
* **ws-inbound-gateway** - Example showing basic functionality of the **Web Service Gateway**
* **ws-outbound-gateway** - Shows outbound web services support using the **Web Service Outbound Gateway**, **Content Enricher**, Composed Message Processor (**Chain**)
* **xml** - Example demonstrates various aspects of the **Xml** support using an **XPath Splitter**, **XPath Router**, **XSLT Transformer** as well as **XPath Expression** support
* **xmpp** - Show the support for [**XMPP**](https://en.wikipedia.org/wiki/Extensible_Messaging_and_Presence_Protocol) (formerly known as Jabber) using e.g. GoogleTalk

## Intermediate

This category targets developers who are already more familiar with the Spring Integration framework (past getting started), but need some more guidance while resolving more advanced technical problems that you have to deal with when switching to a Messaging architecture. For example, if you are looking for an answer on how to handle errors in various scenarios, or how to properly configure an **Aggregator** for the situations where some messages might not ever arrive for aggregation, or any other issue that goes beyond a basic understanding and configuration of a particular component to address ""what else you can do?"" types of problems, this would be the right place to find relevant examples.

* **async-gateway** - Usage example of an asynchronous **Gateway**
* **dynamic-poller** - Example shows usage of a **Poller** with a custom **Trigger** to change polling periods at runtime
* **async-gateway** - Example shows usage of an **Asynchronous Gateway**
* **errorhandling** - Demonstrates basic **Error Handling** capabilities of Spring Integration
* **file-processing** - Sample demonstrates how to wire a message flow to process files either sequentially (maintain the order) or concurrently (no order).
* **mail-attachments** - Demonstrates the processing of email attachments
* **monitoring** The project used in the *[Spring Integration Management and Monitoring Webinar](https://www.springsource.org/node/3598)* Also available on the *[SpringSourceDev YouTube Channel](https://www.youtube.com/SpringSourceDev)*
* **multipart-http** - Demonstrates the sending of HTTP multipart requests using Spring's **RestTemplate** and a Spring Integration **Http Outbound Gateway**
* **rest-http** - This sample demonstrates how to send an HTTP request to a Spring Integration's HTTP service while utilizing Spring Integration's new HTTP Path usage. This sample also uses Spring Security for HTTP Basic authentication. With HTTP Path facility, the client program can send requests with URL Variables.
* **retry-and-more** Provides samples showing the application of MessageHandler Advice Chains to endpoints - retry, circuit breaker, expression evaluating
* **splitter-aggregator-reaper** A demonstration of implementing the Splitter and Aggregator *Enterprise Integration Patterns* (EIP) together. This sample also provides a concrete example of a [message store reaper][] in action.
* **stored-procedures-derby**  Provides an example of the stored procedure Outbound Gateway using *[Apache Derby](https://db.apache.org/derby/)*
* **stored-procedures-ms** Provides an example of the stored procedure Outbound Gateway using *Microsoft SQL Server*
* **stored-procedures-oracle** Provides an example of the stored procedure Outbound Gateway using *ORACLE XE*
* **stored-procedures-postgresql** Provides an example of the stored procedure Outbound Gateway using *[PostgreSQL](https://www.postgresql.org/)*
* **tcp-async-bi-directional** - Demonstrates the use of *Collaborating Channel Adapters* for arbitrary async messaging (not request/reply) between peers.
* **tcp-client-server-multiplex** - Demonstrates the use of *Collaborating Channel Adapters* with multiple in-flight requests/responses over a single connection.
* **travel** - More sophisticated example showing the retrieval of weather (SOAP Web Service) and traffic (HTTP Service) reports using real services
* **tx-synch** Provides a sample demonstrating the use of transaction synchronization, renaming an input file to a different filename, depending on whether the transaction commits, or rolls back.

## Advanced

This category targets advanced developers who are quite familiar with Spring Integration but are looking to address a specific custom need by extending the Spring Integration public API. For example, if you are looking for samples showing how to implement a custom **Channel** or **Consumer** (event-based or polling-based), or you are trying to figure out what is the most appropriate way to implement a custom **BeanParser** on top of the Spring Integration BeanParser hierarchy when implementing a custom namespace, this would be the right place to look. Here you can also find samples that will help you with adapter development. Spring Integration comes with an extensive library of adapters that allow you to connect remote systems with the Spring Integration messaging framework. However you might have a need to integrate with a system for which the core framework does not provide an adapter, so you have to implement your own. This category would include samples showing you how to implement various adapters.

* **advanced-testing-examples** - Example test cases that show advanced techniques to test Spring Integration applications
* **dynamic-ftp** - Demonstrates one technique for sending files to dynamic destinations.
* **dynamic-tcp-client** - Demonstrates a technique for dynamically creating TCP clients.

## Applications

This category targets developers and architects who have a good understanding of Message-Driven architecture and Enterprise Integration Patterns, and have an above average understanding of Spring and Spring integration and who are looking for samples that address a particular business problem. In other words, the emphasis of samples in this category is '**business use cases**' and how they can be solved via a Messaging architecture and Spring Integration in particular. For example, if you are interested to see how a Loan Broker process or Travel Agent process could be implemented and automated via Spring Integration, this would be the right place to find these types of samples.

* **cafe** - Emulates a simple operation of a coffee shop combining various Spring Integration adapters (Including **Router** and **Splitter**) see [Appendix A of the reference documentation](https://docs.spring.io/spring-integration/docs/current/reference/html/#samples) for more details. Implementations are provided for:
  - AMQP
  - JMS
  - In memory channels
* **cafe-scripted** - Scripted implementation of the classic **cafe** sample application. Supports **JavaScript**, **Groovy**, **Ruby**, and **Python**.
* **loan-broker** - Simulates a simple banking application (Uses **Gateway**, **Chain**, **Header Enricher**, **Recipient List Router**, **Aggregator**) see [Appendix A of the reference documentation](https://docs.spring.io/spring-integration/docs/current/reference/html/#samples) for more details
* **loanshark** This extension to the loan broker sample shows how to exchange messages between Spring Integration applications (and other technologies) using **UDP**.
  **file-split-ftp** - Reads a file; splits into 3 based on contents; sends files over ftp; sends email with results.

# Contributing

See the [Spring Integration Contributor Guidelines](https://github.com/spring-projects/spring-integration/blob/master/CONTRIBUTING.adoc) for information about how to contribute to this repository.

# Resources

For more information, please visit the Spring Integration website at: [https://projects.spring.io/spring-integration/](https://projects.spring.io/spring-integration/)

[Spring Integration]: https://github.com/spring-projects/spring-integration
[Spring Integration Extensions]: https://github.com/spring-projects/spring-integration-extensions

[message store reaper]: https://docs.spring.io/spring-integration/api/org/springframework/integration/store/MessageGroupStoreReaper.html

[Xavier Padró]: https://github.com/xpadro/spring-integration
"
eventuate-tram/eventuate-tram-examples-customers-and-orders,master,593,285,2018-03-19T17:29:16Z,1355,35,An example of Choreography-based sagas in Spring Boot/JPA microservices,eventual-consistency java microservice-architecture microservices sagas spring-boot,
jjenkov/javafx-examples,main,421,91,2020-10-21T10:37:31Z,3367,5,A large collection of JavaFX examples demonstrating basic + advanced features of JavaFX. ,,"# JavaFX Examples
This repository contains a growing collection of JavaFX examples. So far this GitHub repository contains 76 examples.
I have plans to add lots more examples in the future, so make sure you star this repository for future reference ;-)


The lists of examples is found here: 

- [JavaFX Basic Examples](#javafx-basic-examples)
- [JavaFX Advanced Examples](#javafx-advanced-examples)

## JavaFX Tutorial
The examples come from my JavaFX tutorial series: [JavaFX Tutorial](http://tutorials.jenkov.com).

## Java + JavaFX Version Used
In general the examples in this repository will attempt to use the latest version of Java and JavaFX. 
For now the examples are tested with Java 14 and JavaFX 14 (yes, 15 + 15 are latest - will update soon!).

## Running the Examples
There are 3 options to run the examples.

- Using your IDE (IntelliJ IDEA / Eclipse / Netbeans)
- Using Maven - passing main class to run on the command line
- Using gradle - passing main class to run on the command line
- Using Maven - configuring the main class inside the pom.xml

Some of these are covered in more detail below.

### Run the Examples in IntelliJ Idea(needs pre-downloaded javafx modules)
To run the examples from within IntelliJ IDEA you must first create a new project in IntelliJ, and set the root
directory to the directory into which you have cloned this Git repository. 

Second, you must download JavaFX and unzip the distribution to some directory.

Third, you must add all the JAR files found in the ""lib"" directory to your project's classpath.

Fourth, you must create a run configuration for the example class you want to run. Add the following
JVM args to that run configuration:

--module-path C:\data\downloads\javafx\javafx-sdk-14\lib --add-modules javafx.base,javafx.controls,javafx.fxml,javafx.graphics,javafx.media,javafx.swing,javafx.web

Make sure that the --module-path points to the directory you unzipped your downloaded JavaFX distribution to (meaning the ""lib"" dir within that JavaFX distribution dir - as shown above).

### Run in IDE - alternative
Instead of creating run configuration for each example class you can create a run configuration for the ExampleRunner class(based on maven or gradle nature. Both are supported using wrappers so you don't need to have any of them on you system and you can choose to use the one you prefer), and then from inside the
ExampleRunner class, call the example class you want to run - by changing the main() method inside the ExampleRunner class. For instance,
add the following line to the ExampleRunner class main() method and then run ExampleRunner main

	ButtonExample.main(args);


### Run via Maven - Passing Main Class as Argument to Maven
You can use maven and pass the example class you want to add. for example to run WebViewExample you can run

./mvnw compile exec:java -Dexec.args=""com.jenkov.javafx.webview.WebViewExample""

### Run via Gradle - Passing Main Class as Argument to Gradle
You can use gradle and pass the example class you want to add. for example to run WebViewExample you can run

./gradlew run --args=""com.jenkov.javafx.webview.WebViewExample""

### Run via Maven
You can use Maven and edit the pom.xml file and change ""mainClass"" of openjfx plugin configuration and select the example you want then run

./mvnw clean javafx:run


## Suggestions
If you have any suggestions for missing examples, create a GitHub issue in this repo, and / or ping me on 
Twitter (@jjenkov) or LinkedIn (Jakob Jenkov).

<a name=""javafx-basic-examples""></a>
# JavaFX Basic Examples

 - [Accordion Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/accordion/AccordionExample.java)
 - [Animation Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/animation/AnimationExample.java)
 - Button Examples
   - [Button Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/button/ButtonExample.java)
   - [Button Font Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/button/ButtonFontExample.java)
   - [Disabled Button Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/button/DisabledButtonExample.java)
   - [Normal, Default and Cancel Mode Button Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/button/ButtonDefaultAndCancelModesExample.java)
   - [Button FXML Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/button/ButtonFXMLExample.java)
   - [Button Transformation Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/button/ButtonTransformationExample.java)
 - [Canvas Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/canvas/CanvasExample.java)
 - [ChoiceBox Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/choicebox/ChoiceBoxExample.java)
 - [Color Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/color/ColorExample.java)
 - [ColorPicker Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/colorpicker/ColorPickerExample.java)
 - [ComboBox Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/combobox/ComboBoxExample.java)
 - [Concurrency Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/concurrency/ConcurrencyExample.java)
 - [ContextMenu Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/contextmenu/ContextMenuExample.java)
 - [DirectoryChooser Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/directorychooser/DirectoryChooserExample.java)
 - [FileChooser Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/filechooser/FileChooserExample.java)
 - [Font Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/font/FontExample.java)
 - [FXML Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/fxml/FXMLExample.java)
 - [HTMLEditor Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/htmleditor/HtmlEditorExample.java)
   Hyperlink Examples
   - [Hyperlink Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/hyperlink/HyperlinkExample.java)
   - [Hyperlink Font Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/hyperlink/HyperlinkFontExample.java)
   - [Hyperlink Change Text Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/hyperlink/HyperlinkChangeTextExample.java)
 - [ImageView Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/imageview/ImageViewExample.java)
 - Label Examples
   - [Label Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/label/LabelExample.java)
   - [Label Font Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/label/LabelFontExample.java)
   - [Label Change Text Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/label/LabelChangeTextExample.java)
 - [Media Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/media/MediaExample.java)
 - MenuButton Examples
   - [MenuButton Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/menubutton/MenuButtonExample.java)
   - [MenuButton Font Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/menubutton/MenuButtonFontExample.java)
   - [MenuButton Icon Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/menubutton/MenuButtonIconExample.java)
 - [Pagination Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/pagination/PaginationExample.java)
 - [ProgressBar Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/progressbar/ProgressBarExample.java)
 - [Properties Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/properties/PropertyExample.java)
 - [Scene Cursor Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/scene/SceneCursorExample.java)
 - [ScrollPane Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/scrollpane/ScrollPaneExample.java)
 - [Separator Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/separator/SeparatorExample.java)
 - [Slider Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/slider/SliderExample.java)
 - [SplitMenuButton Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/splitmenubutton/SplitMenuButtonExample.java)
 - [SplitPane Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/splitpane/SplitPaneExample.java)
 - Stage Examples
   - [Stage Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/StageExample.java)
   - [Stage Decoration Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/StageDecorationExample.java)
   - [Multiple Stages Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/MultipleStagesExample.java)
   - [Multiple Stages Modal Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/MultipleStagesModalExample.java)
   - [Full Screen Stage Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/FullScreenStageExample.java)
   - [Auto Shutdown Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/AutoShutDownExample.java)
   - [Keyboard Events Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/stage/StageKeyboardEventsExample.java)
 - [TabPane Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tabpane/TabPaneExample.java)
 - TableView Examples
   - [TableView Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tableview/TableViewExample.java)
   - [TableView Editable Column Cells Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tableview/TableViewEditableExample.java)
   - [TableView Nested Columns Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tableview/TableViewNestedColumnsExample.java)
   - [TableView Selection Model Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tableview/TableViewSelectionModelExample.java)
   - [TableView Custom Rendering Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tableview/TableViewCustomRenderingExample.java)
   - [TableView Map as Data Items Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tableview/TableViewMapDataItemsExample.java)
 - [Text Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/text/TextExample.java)
 - [TextArea Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/textarea/TextAreaExample.java)
 - [TextField Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/textfield/TextFieldExample.java)
 - [TitledPane Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/titledpane/TitledPaneExample.java)
 - ToggleButton Examples
   - [ToggleButton Example](https://github.com/jjenkov/javafx-example/blob/main/src/main/java/com/jenkov/javafx/togglebutton/ToggleButtonExample.java)
   - [ToggleButton Font Example](https://github.com/jjenkov/javafx-example/blob/main/src/main/java/com/jenkov/javafx/togglebutton/ToggleButtonFontExample.java)
 - [ToolBar Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/toolbar/ToolBarExample.java)
 - [ToolTip Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/tooltip/ToolTipExample.java)
 - [TreeTableView Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/treetableview/TreeTableViewExample.java)
 - [TreeView Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/treeview/TreeViewExample.java)
 - [VBox Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/vbox/VBoxExample.java)
 - WebView Examples
   - [WebView Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/webview/WebViewExample.java)
   - [WebView JavaScript Integration Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/webview/WebViewJavaScriptIntegrationExample.java)
   - [WebView Mouse Wheel Zoom Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/webview/WebViewMouseWheelZoomExample.java) 
     (Mouse wheel zoom code provided by Friedhold Matz (@FriedholdMatz on Twitter))
 - 2D Examples
   - [2D Basics Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/gfx2d/Gfx2DExample.java)
 - 3D Examples
   - [3D Basics Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/gfx3d/Gfx3DExample.java)
 - Transformations Examples
   - [Transformations Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/transformations/TransformationsExample.java)
   - [Translate Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/transformations/TranslateTransformationsExample.java)
   - [Rotate Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/transformations/RotateTransformationsExample.java)
   - [Scale Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/transformations/ScaleTransformationsExample.java)
 - Drag and Drop Examples
   - [Drag and Drop Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/draganddrop/DragAndDropExample.java)


<a name=""javafx-advanced-examples""></a>
# JavaFX Advanced Examples
- [Auto-responsive Layout Example](https://github.com/jjenkov/javafx-examples/blob/main/src/main/java/com/jenkov/javafx/layout/AutoResponsiveLayoutExample.java)


"
mscharhag/blog-examples,master,125,147,2013-11-17T16:07:41Z,12055,13,,,"blog-examples
=============

This repository contains example code for various blog posts on [https://www.mscharhag.com/][1]

[1]:https://www.mscharhag.com/"
mswiderski/jbpm-examples,master,76,185,2012-07-30T14:11:59Z,226,9,Various examples of jBPM 5 ,,"jbpm-examples
=============

Various examples of jBPM 5 and 6:
- use of jbpm as a framwork
- use of jbpm service
- use of jbpm services with spring to build execution server
"
m0ver/tinystruct-examples,master,64,200,2013-02-19T01:10:41Z,64709,3,"The framework is quite easy to be used, but in order to help you to understand deeply, we prepared some code examples for your reference. It might be helpful for you to hand it easily.",,"<img src=""https://avatars.githubusercontent.com/u/3723144?s=400&u=6c4b365e7feb0aab20383785d77ba27abf9f5bb8&v=4"" title=""tinystruct2.0"" /> 

tinystruct framework
=========
[![Build Status](https://travis-ci.org/m0ver/tinystruct-examples.svg?branch=master)](https://travis-ci.org/m0ver/tinystruct2.0)

This is an example project based on tinystruct framework, it supports both C/S application and B/S web application development. 



To execute it in CLI mode
---
```tcsh
$ bin/dispatcher --version

  _/  '         _ _/  _     _ _/
  /  /  /) (/ _)  /  /  (/ (  /  1.2.3
           /
```
```tcsh
$ bin/dispatcher --help
Usage: bin/dispatcher COMMAND [OPTIONS]
Commands: 
        download                Download a resource from other servers
        exec                    To execute native command(s)
        generate                POJO object generator
        install                 Install a package
        open                    Start a default browser to open the specific URL
        say                     Output words
        set                     Set system property
        sql-execute             Executes the given SQL statement, which may be an INSERT, UPDATE, or DELETE statement or an SQL statement that returns nothing, such as an SQL DDL statement.
        sql-query               Executes the given SQL statement, which returns a single ResultSet object.
        update                  Update for latest version

Options: 
        --allow-remote-access   Allow to be accessed remotely
        --help                  Help command
        --host                  Host name / IP
        --import                Import application
        --logo                  Print logo
        --settings              Print settings
        --version               Print version

Run 'bin/dispatcher COMMAND --help' for more information on a command.

$ bin/dispatcher say/""Praise to the Lord""
Praise to the Lord
```

Run it in a servlet container
---
```tcsh
# bin/dispatcher start --import org.tinystruct.system.TomcatServer
```
Run it in docker container
---
```tcsh
# wget https://github.com/tinystruct/tinystruct2.0/archive/master.zip
# unzip master.zip
# mv tinystruct2.0-master/Dockerfile .
# docker build -t tinystruct-based:1.0 -f Dockerfile .
# docker run -d -p 777:777 tinystruct-based:1.0
```

You can access the below URLs after deployed the project in Tomcat 6.0+ :

* <a href=""http://localhost:777/?q=say/Praise%20to%20the%20Lord!"">http://localhost:777/?q=say/Praise%20to%20the%20Lord! </a><br />
* <a href=""http://localhost:777/?q=praise"">http://localhost:777/?q=praise </a><br />
* <a href=""http://localhost:777/?q=youhappy"">http://localhost:777/?q=youhappy</a><br />
* <a href=""http://localhost:777/?q=say/%E4%BD%A0%E7%9F%A5%E9%81%93%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%80%E7%95%85%E9%94%80%E7%9A%84%E4%B9%A6%E6%98%AF%E5%93%AA%E4%B8%80%E6%9C%AC%E4%B9%A6%E5%90%97%EF%BC%9F"">http://localhost:777/?q=say/%E4%BD%A0%E7%9F%A5%E9%81%93%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%80%E7%95%85%E9%94%80%E7%9A%84%E4%B9%A6%E6%98%AF%E5%93%AA%E4%B8%80%E6%9C%AC%E4%B9%A6%E5%90%97%EF%BC%9F</a>

A demonstration for comet technology, without any websocket and support any web browser:
* <a href=""https://tinystruct.herokuapp.com/?q=talk"">https://tinystruct.herokuapp.com/?q=talk</a><br />

<img src=""example.png"" title=""smalltalk - tinystruct2.0"" height=""300""/> <br />

Live Demo Site: 
* https://tinystruct.herokuapp.com/
* <a href=""https://tinystruct.herokuapp.com/?q=say/Praise%20to%20the%20Lord!"">https://tinystruct.herokuapp.com/?q=say/Praise%20to%20the%20Lord! </a><br />
* <a href=""https://tinystruct.herokuapp.com/?q=praise"">https://tinystruct.herokuapp.com/?q=praise</a><br />
* <a href=""https://tinystruct.herokuapp.com/?q=youhappy"">https://tinystruct.herokuapp.com/?q=youhappy</a><br />
* <a href=""https://tinystruct.herokuapp.com/?q=say/%E4%BD%A0%E7%9F%A5%E9%81%93%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%80%E7%95%85%E9%94%80%E7%9A%84%E4%B9%A6%E6%98%AF%E5%93%AA%E4%B8%80%E6%9C%AC%E4%B9%A6%E5%90%97%EF%BC%9F"">https://tinystruct.herokuapp.com/?q=say/%E4%BD%A0%E7%9F%A5%E9%81%93%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%80%E7%95%85%E9%94%80%E7%9A%84%E4%B9%A6%E6%98%AF%E5%93%AA%E4%B8%80%E6%9C%AC%E4%B9%A6%E5%90%97%EF%BC%9F</a>

Results in your browser should be:

<blockquote>
<h1>Praise to the Lord!</h1>
Praise to the Lord! 
<i>true</i>
<h1>你知道全世界最畅销的书是哪一本书吗？</h1>
</blockquote>

Explore it 
--
* Please read more example code in the project.
* Also please see this project: 
	https://github.com/m0ver/mobile1.0
	http://ingod.asia


License
--

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.


[![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/m0ver/tinystruct2.0/trend.png)](https://bitdeli.com/free ""Bitdeli Badge"")
"
streamnative/examples,master,51,32,2019-05-10T15:37:59Z,411,19,Apache Pulsar examples and demos,apache-pulsar schema,"<img src=""images/streamnative-logo.png"" width=""250"">

* [Overview](#overview)

# Overview

This is a curated list of demos that showcase Apache Pulsar® messaging and event streaming capabilities.

# Clients

- [PubSub Client Examples](clients/README.md)

# Cloud

- [SteamNative Cloud Examples](cloud/README.md)

# Flink

- [Pulsar Flink Connector](pulsar-flink/README.md)

# Spring for Apache Pulsar

- [Spring for Apache Pulsar Example](spring-pulsar/README.md)"
googleads/googleads-adsense-examples,main,135,191,2014-03-04T17:32:59Z,246,11,Samples for the AdSense Management API,,"Samples for the AdSense Management API
===========================
The AdSense Management API v2 is
[now availble](https://ads-developers.googleblog.com/2021/04/announcing-v2-of-adsense-management-api.html).
Updated examples can be found for each language in the top-level `v2`
directory.

These code samples are organized by language.

* *dotnet* is a command-line sample that shows how to make most calls against the API, written in C#.
* *java* is a command-line sample that shows how to make most calls against the API, written in Java.
* *php* is a set of samples that shows how to make most calls against the API, written in PHP.
* *python* is a command-line sample that shows how to make most calls against the API, written in Python.
* *ruby* is a set of command-line samples that show how to make most calls against the API, written in Ruby.


Please refer to the README.md file inside each directory for installation instructions.
"
in28minutes/MavenIn28Minutes,master,193,439,2015-09-05T14:10:50Z,872,13,Maven Tutorial for Beginners with Examples,,"# Maven Tutorial for Beginners - with Examples In28Minutes

[![Image](https://www.springboottutorial.com/images/Course-Maven-Tutorial-Manage-Java-Dependencies-in-20-Steps.png ""Maven Tutorial - Manage Java Dependencies in 20 Steps"")](https://www.udemy.com/course/learn-maven-java-dependency-management-in-20-steps/)

## Installing Eclipse and Java
https://github.com/in28minutes/SpringIn28Minutes/blob/master/InstallationGuide-JavaEclipseAndMaven_v2.pdf

## Course Overview
- We will use Handson Real World Examples to understand what Maven can do. 
- We will understand how Maven makes the life of an application developer easy. 
- We will learn how Maven helps us to automate things like compilation, running unit tests, creating a war, creating an ear, running a web application in tomcat. 
- We will learn how to use Maven effectively in combination of an IDE like Eclipse. 
- We will use 
  - Maven for dependency management, building and running the application in tomcat.
  - Eclipse IDE.

### Step List
Lets now look at the steps in this tutorial. 
- Step 1 to 4 we will learn about the basics of Maven : Project Object Model and Build LifeCycle
- Steps 5 and 6 we will learn about dependency management and transitive dependencies
- Step 7 we will learn about a maven project with multiple layers. Typical projects have a web layer, data layer, external interface layer. We will learn how to create such projects using maven. Multi Module Maven Project.
- Step 8 : We will learn how to create a war, deploy to tomcat.

### Running Examples
- If you are downloading the zip file, unzip the file
- Open Command Prompt and Change directory to folder containing pom.xml
- Run command ""mvn tomcat7:run""
- For help : user our installation guide - https://github.com/in28minutes/SpringIn28Minutes/blob/master/InstallationGuide-JavaEclipseAndMaven_v2.pdf

### Youtube Video
https://courses.in28minutes.com/p/maven-tutorial-for-beginners-in-5-steps

# 0. What is Maven?
Defining what Maven does is very difficult. 
##	Every Day Developer
		Manages Dependencies - Web Layer (Spring MVC), Data Layer (JPA - Hibernate) etc..                  
		Build a jar or a war or an ear
		Run the application locally - Tomcat or Jetty
		Deploy to a T environment
		Add new dependencies to a project
		Run Unit Tests
##	Maven helps us do all these and more...
		Generate Projects
		Create Eclipse Workspace

# 1. Beginner Maven Project
##	What is the power of Maven?
####	First Project : My aim is to create a Spring.jar. Think as if you are developing Spring. Some other developers want to use the framework you are developing. Steps in creating a JAr
- App.Java -> App.class
- AppTest.Java -> AppTest.class
- Run Unit Tests
- Package in a particular format
- Earlier this was done using long tedious ant scripts

#### Convention over Configuration
- Pre defined folder structure
- pom.xml
- mvn --version
- mvn compile (compiles source files)
- mvn test-compile (compiles test files) - one thing to observe is this also compiles source files
- mvn clean - deletes target directory
- mvn test - run unit tests

## You are ready for theory on Build Life Cycle

Pre-defined sequence of steps that are done when we run a maven command. Plugins can be attached to lifecycle stages. Default plugins are already defined in the super pom.

mvn install 
- package - creates the jar
- install - copies the created jar to local maven repository - a temp folder on my machine where maven stores the files.

###	Build LifeCycle 
		Validate
		Compile
		Test
		Package
		Integration Test
		Verify
		Install
		Deploy

## Lets understand pom.xml

###	Project Object Model (POM)
		Name (if another project want to refer to our project, how do they do it?)
		Version (Major Version, Minor Version, Incremental Version)
		Packaging 
		Dependencies
		Plugins


###  Maven repository stores all the versions of all dependencies. JUnit 4.2,4.3,4.4
###  Local Repository - all the dependencies that are downloaded for 1st time are stored.


# 2. Intermediate Maven Project

- Transtive Dependencies (add Hibernate dependency)
- Exclusions - Add an exclude
- Dependency Hierarchy - See how each dependency is coming in
- Versions [4.1,] [,4.1] [,4.1)
- Scope - Dependencies are needed only for tests. They are not part of the war or jar. we can use scope for that.
- Maven Compiler Plugin - Change source from 1.5 to 1.8.
- Effective Pom - Super Pom (Similar to Java Inheritance) - Check the build part of super pom (Convention over configuration - defaults are defined). We can change it - for example source directory. Recommended not to override defaults. Easy to move from one project to another project. Definitions of various plugins. mvn help:effective-pom

##	Dependency Management
		Scope
		Transitive Dependencies
		Excluding Dependency
		Dependency Versions
##	Sample Project Object Model
		Maven Plugins
		Convention over configuration
			Source Code
				${basedir}/src/main/java
				${basedir}/src/main/resources
			Test Code
				${basedir}/src/test
##	Hierarchy of POMS
		Super POM

# 3. Multi Module Maven Project
- Most projects have multiple layers. Each layer has its own dependencies. Also multiple layers may share same dependency. We will see the best practices in managing dependencies in a multi module maven project.
- Parent pom has type pom
- - Defines Modules
- Dependency Management Section
- Properties
- Pre-defined Variables ${project.version}
- Run from command prompt - mvn clean install

# 4. Maven Web Application
##	Packaging
		War
		Ear
##	Running application in Tomcat	

# 5. Tip and Tricks
##	Important Commands
		help:effective-settings
		help:effective-pom
		dependency:tree
		dependency:sources
		--debug
##	Maven Archetypes
		archetype:generate

# 6. Missing (To Discuss)
- Plugins : Show in super pom.xml
- Eclipse Integration
- Profiles


### Expectations
- You should know Java. 

### Running Examples
- Download the zip or clone the Git repository.
- Unzip the zip file (if you downloaded one)
- Open Command Prompt and Change directory (cd) to folder containing pom.xml
- Open Eclipse 
   - File -> Import -> Existing Maven Project -> Navigate to the folder where you unzipped the zip
   - Select the right project
- Choose the Spring Boot Application file (search for @SpringBootApplication)
- Right Click on the file and Run as Java Application
- You are all Set

### Troubleshooting
- Refer our TroubleShooting Guide - https://github.com/in28minutes/in28minutes-initiatives/tree/master/The-in28Minutes-TroubleshootingGuide-And-FAQ

## Youtube Playlists - 500+ Videos

[Click here - 30+ Playlists with 500+ Videos on Spring, Spring Boot, REST, Microservices and the Cloud](https://www.youtube.com/user/rithustutorials/playlists?view=1&sort=lad&flow=list)

## Keep Learning in28Minutes

in28Minutes is creating amazing solutions for you to learn Spring Boot, Full Stack and the Cloud - Docker, Kubernetes, AWS, React, Angular etc. - [Check out all our courses here](https://github.com/in28minutes/learn)
"
ttrelle/spring-data-examples,master,180,164,2011-12-23T10:11:17Z,272,5,"Examples for using Spring Data for JPA, MongoDB, Neo4j, Redis",java jpa mongodb neo4j redis spring-data,"# Spring Data Blog Series

This projects holds the Java source examples for my blog post series on the Spring Data project:

* [GridFS Support in Spring Data MongoDB](http://blog.codecentric.de/en/2012/07/gridfs-support-in-spring-data-mongodb/)
* [Part 6: Spring Data Redis](http://blog.codecentric.de/en/2012/04/spring-data-redis/)
* [Part 5: Spring Data Neo4j](http://blog.codecentric.de/en/2012/02/spring-data-neo4j/)
* [Part 4: Geospatial Queries with Spring Data MongoDB](http://blog.codecentric.de/en/2012/02/spring-data-mongodb-geospatial-queries/)
* [Part 3: Spring Data MongoDB](http://blog.codecentric.de/en/2012/02/spring-data-mongodb/)
* [Part 2: Spring Data JPA](http://blog.codecentric.de/en/2012/01/spring-data-jpa/)
* [Part 1: Spring Data Commons](http://blog.codecentric.de/en/2011/12/spring-data-commons/)

## Build Status @ Travis CI ##
[![Build Status](https://travis-ci.org/ttrelle/spring-data-examples.png?branch=master)](https://travis-ci.org/ttrelle/spring-data-examples)

## Usage

The projects are using a Maven based build. To run the tests on the command line use

	mvn clean test
   
If you want to use an IDE like Eclipse run

	mvn eclipse:eclipse
   
and set the Eclipse variable M2_REPO pointing to your local Maven repository. Or just import the project as an existing Maven project if you are using the m2 plugin.
 
"
resteasy/resteasy-examples,main,135,138,2016-05-24T08:09:29Z,1423,4,RESTEasy examples,,
aliyun/tablestore-examples,master,236,108,2019-03-13T07:29:58Z,2886,26,Example code for aliyun tablestore.,,"# Aliyun TableStore Examples

[![License Status](https://img.shields.io/badge/license-apache2-brightgreen.svg)](https://travis-ci.org/aliyun/aliyun-tablestore-nodejs-sdk)
## [Click here for the English README](README_EN.md)

**目录**
- [1、项目结构](#1%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84)
- [2、开通与配置](#2%E5%BC%80%E9%80%9A%E4%B8%8E%E9%85%8D%E7%BD%AE)
  - [开通服务、创建实例、获取AK](#%E5%BC%80%E9%80%9A%E6%9C%8D%E5%8A%A1%E5%88%9B%E5%BB%BA%E5%AE%9E%E4%BE%8B%E8%8E%B7%E5%8F%96ak)
  - [完成配置](#%E5%AE%8C%E6%88%90%E9%85%8D%E7%BD%AE)
- [3、样例统计](#3%E6%A0%B7%E4%BE%8B%E7%BB%9F%E8%AE%A1)
  - [demos(场景样例)](#demos%E5%9C%BA%E6%99%AF%E6%A0%B7%E4%BE%8B)
  - [tools(迁移、计算等工具)](#tools%E8%BF%81%E7%A7%BB%E8%AE%A1%E7%AE%97%E7%AD%89%E5%B7%A5%E5%85%B7)
  - [feature(SDK基础功能)](#featuresdk%E5%9F%BA%E7%A1%80%E5%8A%9F%E8%83%BD)
- [4、使用提醒](#4%E4%BD%BF%E7%94%A8%E6%8F%90%E9%86%92)
  - [资源释放](#%E8%B5%84%E6%BA%90%E9%87%8A%E6%94%BE)
- [5、咨询/答疑/反馈](#5%E5%92%A8%E8%AF%A2%E7%AD%94%E7%96%91%E5%8F%8D%E9%A6%88)
  - [联系方式：](#%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F)


# 1、项目结构
- 根据功能，分为3个模块(场景样例/迁移、计算等工具/SDK基础功能)，
- 每个项目名下对应独立的Example项目

```
├── README.md
├── demos                                   #场景样例
│   ├── IMChart                             #即时聊天系统
│   ├── SharingCarManagement                #共享汽车管理
│   ├── SportTrack                          #运动轨迹
│   ├── insurance-policy-management         #保险单管理系统
│   ├── TraceMedicine                       #药品监管（溯源）系统
│   ├── TableStore-Grid                     #气象格点数据解决方案
│   ├── MailManagement                      #基于Timestream的快递轨迹管理
│   ├── WifiMonitor                         #基于Timestream的Wifi监控系统
│   ├── Orders                              #基于 MySQL + Tablestore 分层存储的大规模订单系统系列测试代码
│   └── Canal-press                         #基于 MySQL + Tablestore 分层存储的大规模订单系统系列中canal部分压测代码
│
├── tools                                   #工具/产品
│   ├── Dts-MySQL2TableStore                #MySQL增量数据迁移表格存储
│   └── Datax-MySQL2TableStore              #MySQL数据迁移表格存储
│
└── feature                                 #SDK基础功能
    ├── TableCopy                           #数据复制（表级别）
    ├── FuzzySearch                         #模糊查询
    └── AggregationAndGroupBy               #统计聚合
```

# 2、开通与配置
## 开通服务、创建实例、获取AK
- [控制台](https://ots.console.aliyun.com): https://ots.console.aliyun.com
- [开通服务](https://help.aliyun.com/document_detail/27287.html): https://help.aliyun.com/document_detail/27287.html
- [创建实例](https://help.aliyun.com/document_detail/55211.html): https://help.aliyun.com/document_detail/55211.html
- [获取AK](https://usercenter.console.aliyun.com/#/manage/ak): https://usercenter.console.aliyun.com/#/manage/ak

## 完成配置
在home目录下创建tablestoreCong.json文件，填写相应参数，所有独立项目都会使用该配置
```
# mac 或 linux系统下：/home/userhome/tablestoreConf.json
# windows系统下: C:\Documents and Settings\%用户名%\tablestoreConf.json
{
  ""endpoint"": ""http://instanceName.cn-hangzhou.ots.aliyuncs.com"",
  ""accessId"": ""***********"",
  ""accessKey"": ""***********************"",
  ""instanceName"": ""instanceName""
}
```
- endpoint：实例的接入地址，控制台实例详情页获取；
- accessId：AK的ID，获取AK链接提供；
- accessKey：AK的密码，获取AK链接提供；
- instanceName：使用的实例名；

# 3、项目统计

## [demos(场景样例)](/demos)
样例 | 语言 | 项目名
--- | --- | ---
基于 MySQL + Tablestore 分层存储架构的大规模订单系统实践-架构篇 | java | [Orders](/demos/Orders)
基于 MySQL + Tablestore 分层存储架构的大规模订单系统实践-数据同步 Canal 篇 | java | [Canal-press](/demos/Canal-press)
[即时聊天系统](https://yq.aliyun.com/articles/710363) | java | [IMChart](/demos/ImChart)
[共享汽车管理](https://yq.aliyun.com/articles/703177) | java | [SharingCarManagement](/demos/SharingCarManagement)
[运动轨迹管理](https://yq.aliyun.com/articles/702482) | java | [SportTrack](/demos/SportTrack)
[保险单管理系统](https://yq.aliyun.com/articles/699669) | java | [insurance-policy-management](/demos/insurance-policy-management)
[药品监管（溯源）系统](https://yq.aliyun.com/articles/699636) | java | [TraceMedicine](/demos/TraceMedicine)
[气象格点数据解决方案](https://yq.aliyun.com/articles/698313) | java | [TableStore-Grid](/demos/TableStore-Grid)
[基于Timestream的Wifi监控系统](https://yq.aliyun.com/articles/698591) | java | [WifiMonitor](/demos/WifiMonitor)
[基于Timestream的快递轨迹管理](https://yq.aliyun.com/articles/698551) | java | [MailManagement](/demos/MailManagement)

## tools(迁移、计算等工具)
场景 | 工具 | 项目名
--- | --- | ---
[MySQL数据迁移表格存储](https://yq.aliyun.com/articles/698973) | datax | [Datax-MySQL2TableStore](/tools/Datax-MySQL2TableStore)
[MySQL增量数据导入表格存储](https://yq.aliyun.com/articles/708325) | DTS | [Dts-MySQL2TableStore](/tools/Dts-MySQL2TableStore)

## feature(Tablestore功能)
功能 | 语言(SDK) | 项目名
--- | --- | ---
[表级别数据复制](https://yq.aliyun.com/articles/706791) | java | [TableCopy](/feature/TableCopy)
[模糊查询](https://yq.aliyun.com/articles/703707) | java | [FuzzySearch](/feature/FuzzySearch)
统计聚合 | java | [AggregationAndGroupBy](/feature/AggregationAndGroupBy)
[Tablestore Spark Demo](/feature/TableStoreSparkDemo/README.md) | scala | [TableStoreSparkDemo](/feature/TableStoreSparkDemo)

## basic(SDK基础使用)
功能 | 语言(SDK) | 项目名
--- | --- | ---
基础使用 | java | [Java SDK 使用](/basic/Java)


# 4、使用提醒

## 资源释放
- 删除无用索引、无用数据、无用表格等
- 释放相应资源，避免持续收费


# 5、咨询/答疑/反馈
## 联系方式：
- 钉钉群: 表格存储技术交流群-2
- 群号: 23307953
- 二维码:

![二维码](image/QRcode.png)
"
swagger-api/swagger-core,master,7334,2150,2011-07-05T23:44:11Z,19282,783,"Examples and server integrations for generating the Swagger API Specification, which enables easy access to your REST API",java open-source openapi openapi-specification openapi3 rest rest-api swagger swagger-api swagger-oss,"# Swagger Core <img src=""https://raw.githubusercontent.com/swagger-api/swagger.io/wordpress/images/assets/SW-logo-clr.png"" height=""50"" align=""right"">

**NOTE:** If you're looking for Swagger Core 1.5.X and OpenAPI 2.0, please refer to [1.5 branch](https://github.com/swagger-api/swagger-core/tree/1.5).

**NOTE:** Since version 2.1.7, Swagger Core also supports the Jakarta namespace. There are a parallel set of artifacts with the `-jakarta` suffix, providing the same functionality as the unsuffixed (i.e.: `javax`) artifacts.
Please see the [Wiki](https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---Getting-started) for more details.

**NOTE:** Since version 2.2.0 Swagger Core supports OpenAPI 3.1; see [this page](https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---OpenAPI-3.1) for details

![Build Test Deploy](https://github.com/swagger-api/swagger-core/workflows/Build%20Test%20Deploy%20master/badge.svg?branch=master)
[![Maven Central](https://maven-badges.herokuapp.com/maven-central/io.swagger.core.v3/swagger-project/badge.svg?style=plastic)](https://maven-badges.herokuapp.com/maven-central/io.swagger.core.v3/swagger-project)

Swagger Core is a Java implementation of the OpenAPI Specification. Current version supports *JAX-RS2* (`javax` and `jakarta` namespaces).

## Get started with Swagger Core!
See the guide on [getting started with Swagger Core](https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---Getting-started) to get started with adding Swagger to your API.

## See the Wiki!
The [github wiki](https://github.com/swagger-api/swagger-core/wiki) contains documentation, samples, contributions, etc. Start there.

## Compatibility
The OpenAPI Specification has undergone several revisions since initial creation in 2010.  The Swagger Core project has the following compatibilities with the OpenAPI Specification:

Swagger core Version      | Release Date | OpenAPI Spec compatibility | Notes | Status
------------------------- | ------------ | -------------------------- | ----- | ----
2.2.21 (**current stable**)| 2024-03-20   | 3.x           | [tag v2.2.21](https://github.com/swagger-api/swagger-core/tree/v2.2.21) | Supported
2.2.20                     | 2023-12-19   | 3.x           | [tag v2.2.20](https://github.com/swagger-api/swagger-core/tree/v2.2.20) | Supported
2.2.19                     | 2023-11-10   | 3.x           | [tag v2.2.19](https://github.com/swagger-api/swagger-core/tree/v2.2.19) | Supported
2.2.18                     | 2023-10-25   | 3.x           | [tag v2.2.18](https://github.com/swagger-api/swagger-core/tree/v2.2.18) | Supported
2.2.17                     | 2023-10-12   | 3.x           | [tag v2.2.17](https://github.com/swagger-api/swagger-core/tree/v2.2.17) | Supported
2.2.16                     | 2023-09-18   | 3.x           | [tag v2.2.16](https://github.com/swagger-api/swagger-core/tree/v2.2.16) | Supported
2.2.15                     | 2023-07-08   | 3.x           | [tag v2.2.15](https://github.com/swagger-api/swagger-core/tree/v2.2.15) | Supported
2.2.14                     | 2023-06-26   | 3.x           | [tag v2.2.14](https://github.com/swagger-api/swagger-core/tree/v2.2.14) | Supported
2.2.13                     | 2023-06-24   | 3.x           | [tag v2.2.13](https://github.com/swagger-api/swagger-core/tree/v2.2.13) | Supported
2.2.12                     | 2023-06-13   | 3.x           | [tag v2.2.12](https://github.com/swagger-api/swagger-core/tree/v2.2.12) | Supported
2.2.11                     | 2023-06-01   | 3.x           | [tag v2.2.11](https://github.com/swagger-api/swagger-core/tree/v2.2.11) | Supported
2.2.10                     | 2023-05-15   | 3.x           | [tag v2.2.10](https://github.com/swagger-api/swagger-core/tree/v2.2.10) | Supported
2.2.9                     | 2023-03-20  | 3.x           | [tag v2.2.9](https://github.com/swagger-api/swagger-core/tree/v2.2.9)                                             | Supported
2.2.8                     | 2023-01-06  | 3.x           | [tag v2.2.8](https://github.com/swagger-api/swagger-core/tree/v2.2.8)                                             | Supported
2.2.7                     | 2022-11-15  | 3.0           | [tag v2.2.7](https://github.com/swagger-api/swagger-core/tree/v2.2.7)                                             | Supported
2.2.6                     | 2022-11-02  | 3.0           | [tag v2.2.6](https://github.com/swagger-api/swagger-core/tree/v2.2.6)                                             | Supported
2.2.5                     | 2022-11-02  | 3.0           | [tag v2.2.5](https://github.com/swagger-api/swagger-core/tree/v2.2.5)                                             | Supported
2.2.4                     | 2022-10-16  | 3.0           | [tag v2.2.4](https://github.com/swagger-api/swagger-core/tree/v2.2.4)                                             | Supported
2.2.3                     | 2022-09-27  | 3.0           | [tag v2.2.3](https://github.com/swagger-api/swagger-core/tree/v2.2.3)                                             | Supported
2.2.2                     | 2022-07-20  | 3.0           | [tag v2.2.2](https://github.com/swagger-api/swagger-core/tree/v2.2.2)                                             | Supported
2.2.1                     | 2022-06-15  | 3.0           | [tag v2.2.1](https://github.com/swagger-api/swagger-core/tree/v2.2.1)                                             | Supported
2.2.0                     | 2022-04-04  | 3.0           | [tag v2.2.0](https://github.com/swagger-api/swagger-core/tree/v2.2.0)                                             | Supported
2.1.13                     | 2022-02-07  | 3.0           | [tag v2.1.13](https://github.com/swagger-api/swagger-core/tree/v2.1.13)                                           | Supported
2.1.12                     | 2021-12-23  | 3.0           | [tag v2.1.12](https://github.com/swagger-api/swagger-core/tree/v2.1.12)                                           | Supported
2.1.11                     | 2021-09-29  | 3.0           | [tag v2.1.11](https://github.com/swagger-api/swagger-core/tree/v2.1.11)                                           | Supported
2.1.10                     | 2021-06-28  | 3.0           | [tag v2.1.10](https://github.com/swagger-api/swagger-core/tree/v2.1.10)                                           | Supported
2.1.9                     | 2021-04-20  | 3.0           | [tag v2.1.9](https://github.com/swagger-api/swagger-core/tree/v2.1.9)                                             | Supported
2.1.8                     | 2021-04-18  | 3.0           | [tag v2.1.8](https://github.com/swagger-api/swagger-core/tree/v2.1.8)                                             | Supported
2.1.7                     | 2021-02-18  | 3.0           | [tag v2.1.7](https://github.com/swagger-api/swagger-core/tree/v2.1.7)                                             | Supported
2.1.6                     | 2020-12-04  | 3.0           | [tag v2.1.6](https://github.com/swagger-api/swagger-core/tree/v2.1.6)                                             | Supported
2.1.5                     | 2020-10-01  | 3.0           | [tag v2.1.5](https://github.com/swagger-api/swagger-core/tree/v2.1.5)                                             | Supported
2.1.4                     | 2020-07-24  | 3.0           | [tag v2.1.4](https://github.com/swagger-api/swagger-core/tree/v2.1.4)                                             | Supported
2.1.3                     | 2020-06-27  | 3.0           | [tag v2.1.3](https://github.com/swagger-api/swagger-core/tree/v2.1.3)                                             | Supported
2.1.2                     | 2020-04-01  | 3.0           | [tag v2.1.2](https://github.com/swagger-api/swagger-core/tree/v2.1.2)                                             | Supported
2.1.1                     | 2020-01-02  | 3.0           | [tag v2.1.1](https://github.com/swagger-api/swagger-core/tree/v2.1.1)                                             | Supported
2.1.0                     | 2019-11-16  | 3.0           | [tag v2.1.0](https://github.com/swagger-api/swagger-core/tree/v2.1.0)                                             | Supported
2.0.10                    | 2019-10-11  | 3.0           | [tag v2.0.10](https://github.com/swagger-api/swagger-core/tree/v2.0.10)                                           | Supported
2.0.9                     | 2019-08-22  | 3.0           | [tag v2.0.9](https://github.com/swagger-api/swagger-core/tree/v2.0.9)                                             | Supported
2.0.8                     | 2019-04-24  | 3.0           | [tag v2.0.8](https://github.com/swagger-api/swagger-core/tree/v2.0.8)                                             | Supported
2.0.7                     | 2019-02-18  | 3.0           | [tag v2.0.7](https://github.com/swagger-api/swagger-core/tree/v2.0.7)                                             | Supported
2.0.6                     | 2018-11-27  | 3.0           | [tag v2.0.6](https://github.com/swagger-api/swagger-core/tree/v2.0.6)                                             | Supported
2.0.5                     | 2018-09-19  | 3.0           | [tag v2.0.5](https://github.com/swagger-api/swagger-core/tree/v2.0.5)                                             | Supported
2.0.4                     | 2018-09-05  | 3.0           | [tag v2.0.4](https://github.com/swagger-api/swagger-core/tree/v2.0.4)                                             | Supported
2.0.3                     | 2018-08-09  | 3.0           | [tag v2.0.3](https://github.com/swagger-api/swagger-core/tree/v2.0.3)                                             | Supported
1.6.14 (**current stable**)| 2024-03-19   | 2.0           | [tag v1.6.14](https://github.com/swagger-api/swagger-core/tree/v1.6.14)                                           | Supported
1.6.13                    | 2024-01-26   | 2.0           | [tag v1.6.13](https://github.com/swagger-api/swagger-core/tree/v1.6.13)                                           | Supported
1.6.12                    | 2023-10-14   | 2.0           | [tag v1.6.12](https://github.com/swagger-api/swagger-core/tree/v1.6.12)                                           | Supported
1.6.11                    | 2023-05-15  | 2.0           | [tag v1.6.11](https://github.com/swagger-api/swagger-core/tree/v1.6.11)                                           | Supported
1.6.10                    | 2023-03-21  | 2.0           | [tag v1.6.10](https://github.com/swagger-api/swagger-core/tree/v1.6.10)                                           | Supported
1.6.9                     | 2022-11-15  | 2.0           | [tag v1.6.9](https://github.com/swagger-api/swagger-core/tree/v1.6.9)                                             | Supported
1.6.8                     | 2022-10-16  | 2.0           | [tag v1.6.8](https://github.com/swagger-api/swagger-core/tree/v1.6.8)                                             | Supported
1.6.7                     | 2022-09-27  | 2.0           | [tag v1.6.7](https://github.com/swagger-api/swagger-core/tree/v1.6.7)                                             | Supported
1.6.6                     | 2022-04-04  | 2.0           | [tag v1.6.6](https://github.com/swagger-api/swagger-core/tree/v1.6.6)                                             | Supported
1.6.5                     | 2022-02-07  | 2.0           | [tag v1.6.5](https://github.com/swagger-api/swagger-core/tree/v1.6.5)                                             | Supported
1.6.4                     | 2021-12-23  | 2.0           | [tag v1.6.4](https://github.com/swagger-api/swagger-core/tree/v1.6.4)                                             | Supported
1.6.3                     | 2021-09-29  | 2.0           | [tag v1.6.3](https://github.com/swagger-api/swagger-core/tree/v1.6.3)                                             | Supported
1.6.2                     | 2020-07-01  | 2.0           | [tag v1.6.2](https://github.com/swagger-api/swagger-core/tree/v1.6.2)                                             | Supported
1.6.1                     | 2020-04-01  | 2.0           | [tag v1.6.1](https://github.com/swagger-api/swagger-core/tree/v1.6.1)                                             | Supported
1.6.0                     | 2019-11-16  | 2.0           | [tag v1.6.0](https://github.com/swagger-api/swagger-core/tree/v1.6.0)                                             | Supported
1.5.24                    | 2019-10-11  | 2.0           | [tag v1.5.24](https://github.com/swagger-api/swagger-core/tree/v1.5.24)                                           | Supported
1.5.23                    | 2019-08-22  | 2.0           | [tag v1.5.23](https://github.com/swagger-api/swagger-core/tree/v1.5.23)                                           | Supported
1.5.22                    | 2019-02-18  | 2.0           | [tag v1.5.22](https://github.com/swagger-api/swagger-core/tree/v1.5.22)                                           | Supported
1.5.21                    | 2018-08-09  | 2.0           | [tag v1.5.21](https://github.com/swagger-api/swagger-core/tree/v1.5.21)                                           | Supported
1.5.20                    | 2018-05-23  | 2.0           | [tag v1.5.20](https://github.com/swagger-api/swagger-core/tree/v1.5.20)                                           | Supported
2.0.2                     | 2018-05-23  | 3.0           | [tag v2.0.2](https://github.com/swagger-api/swagger-core/tree/v2.0.2)                                             | Supported
2.0.1                     | 2018-04-16  | 3.0           | [tag v2.0.1](https://github.com/swagger-api/swagger-core/tree/v2.0.1)                                             | Supported
1.5.19                    | 2018-04-16  | 2.0           | [tag v1.5.19](https://github.com/swagger-api/swagger-core/tree/v1.5.19)                                           | Supported
2.0.0                     | 2018-03-20  | 3.0           | [tag v2.0.0](https://github.com/swagger-api/swagger-core/tree/v2.0.0)                                             | Supported
2.0.0-rc4                 | 2018-01-22  | 3.0           | [tag v2.0.0-rc4](https://github.com/swagger-api/swagger-core/tree/v2.0.0-rc4)                                     | Supported
2.0.0-rc3                 | 2017-11-21  | 3.0           | [tag v2.0.0-rc3](https://github.com/swagger-api/swagger-core/tree/v2.0.0-rc3)                                     | Supported
2.0.0-rc2                 | 2017-09-29  | 3.0           | [tag v2.0.0-rc2](https://github.com/swagger-api/swagger-core/tree/v2.0.0-rc2)                                     | Supported
2.0.0-rc1                 | 2017-08-17  | 3.0           | [tag v2.0.0-rc1](https://github.com/swagger-api/swagger-core/tree/v2.0.0-rc1)                                     | Supported
1.5.18                    | 2018-01-22  | 2.0           | [tag v1.5.18](https://github.com/swagger-api/swagger-core/tree/v1.5.18)                                           | Supported
1.5.17                    | 2017-11-21  | 2.0           | [tag v1.5.17](https://github.com/swagger-api/swagger-core/tree/v1.5.17)                                           | Supported
1.5.16                    | 2017-07-15  | 2.0           | [tag v1.5.16](https://github.com/swagger-api/swagger-core/tree/v1.5.16)                                           | Supported
1.3.12                    | 2014-12-23  | 1.2           | [tag v1.3.12](https://github.com/swagger-api/swagger-core/tree/v1.3.12)                                           | Supported
1.2.4                     | 2013-06-19  | 1.1           | [tag swagger-project_2.10.0-1.2.4](https://github.com/swagger-api/swagger-core/tree/swagger-project_2.10.0-1.2.4) | Deprecated
1.0.0                     | 2011-10-16  | 1.0           | [tag v1.0](https://github.com/swagger-api/swagger-core/tree/v1.0)                                                 | Deprecated


### Change History
If you're interested in the change history of swagger and the Swagger Core framework, see [here](https://github.com/swagger-api/swagger-core/releases).

### Prerequisites
You need the following installed and available in your $PATH:

* Java 11
* Apache maven 3.0.4 or greater
* Jackson 2.4.5 or greater


### To build from source (currently 2.2.22-SNAPSHOT)
```
# first time building locally
mvn -N
```

Subsequent builds:
```
mvn install
```

This will build the modules.

Of course if you don't want to build locally you can grab artifacts from maven central:

`https://repo1.maven.org/maven2/io/swagger/core/`

## Sample Apps
The samples have moved to [a new repository](https://github.com/swagger-api/swagger-samples/tree/2.0) and contain various integrations and configurations.

## Security contact

Please disclose any security-related issues or vulnerabilities by emailing [security@swagger.io](mailto:security@swagger.io), instead of using the public issue tracker.
"
eazybytes/microservices-with-spring-sectionwise-code,master,256,469,2021-09-27T10:05:16Z,18453,1,"Microservices With Spring, Docker, Kubernetes  - Code Examples",docker docker-compose java kubernetes microservices spring spring-boot spring-cloud,"# This repo belongs to older version of the course. For the current version of the microservice course, please use below GitHub repo,
https://github.com/eazybytes/microservices


"
HaydiKodlayalim/spring-examples,master,240,100,2019-11-12T07:25:07Z,3198,10,SpringBoot Examples,aop elasticsearch graphql java jwt-token mongodb postgresql rabbitmq spring-aop spring-data spring-data-jpa spring-security springboot swagger2,
write2munish/Akka-Essentials,master,709,374,2012-03-02T04:32:13Z,465,16,Java/Scala Examples from the book - Akka Essentials,actors akka java remote-actors scala supervisor testkit,"Akka Essentials
(refer http://akka-essentials.blogspot.com/ for more details)

[![Build Status](https://api.travis-ci.org/write2munish/Akka-Essentials.png)](https://api.travis-ci.org/write2munish/Akka-Essentials)

You will find examples of Akka in Java & Scala, talking of one concept along with a problem solved

ClientServerExample : This example demonstrates how the remote actors works in a client / server mode. The client sends the message to the server and server replies back to the client. The example also demonstrates various methods of creating remote actor references on the client side.

LoadGeneratorExample : This example generates 10 million messages and calculates the time it takes to process them. The program demonstrated the Routing concept where a roundrobinrouter is used to distribute the load on to a set of workers

WordCountMapReduce : This examples implements the Word Count Map Reduce model. The client system reads a text file and sends each line of text as a message to the Server. The server reads the line, maps the words, reduces the words and finally does an inmemory aggregation of the result. The example also implemented a prioritymailbox, which is used to segregate the message requests between the mapreduce requests and getting the list of results from the aggregate actor

GridPatternExample : Grid Computing pattern is where a control node distributes the work to other nodes. Idea is to make use of the nodes on the network for their computing power. It is analogous to Master Slave Pattern with certain differences. The idea behind the Master Slave pattern is to partition the work into identical sub tasks which are then delegated to Slaves. The example demonstrates how an WorkerActor system sends a request for registration. The RegisterRemoteWorker recieves the request and forwards the same to JobController where the RoundRobinRouter is updated for the new worker information. The WorkScheduler sends a periodic request to JobController, who then sends packets to all the registered worker actors.

AkkaSerializableExample : Akka by default supports 2 serializer options - java and protobuf. In addition, Akka provides an API to write you owns serializable. In this example, i have used google gson library to convert your value object into json string representation which is then converted to bytes and transported across the wire

AkkaSupervisorExample : Akka provides two supervisor strategies - One-For-One or All-For-One that are used to monitor the actors and build the fault tolerance in the actor model. There are 3 examples that demonstrate the strategies and their usage. In addition, the java section has unit testing code also for testing your supervisor code

AkkaWithZeroMQ - Akka provides native support for ZeroMQ libraries and provide different connectors (Pub-Sub, Req-Rep,Router-Dealer and Pull-Push). There are four examples that demonstrated their usage

AkkaUnitTest : Unit testing toolkit is provided via TestKit in Akka. The scala side of unit testing is well covered. For java, TestKit provides limited constructs. The various examples implemented by Ray Roestenburg have ported to Java world, with couple of more scenario's added. This can be good starting point for Java programmers to start unit testing their actors

AkkaPersistentExample : Akka provides persistent model for stateful actors. The example uses a simple example of Integer (which carries the ) and operations (ADD, SUBTRACT, MULTIPLY, DIVIDE) along with operand acts on the state object
"
saturnism/grpc-by-example-java,master,865,339,2016-08-20T19:15:05Z,341,25,A collection of useful/essential gRPC Java Examples,containers distributed-tracing docker examples grpc grpc-java java java8 jpa kubernetes prometheus rxjava rxjava2 spring-boot stream zipkin,"gRPC Java Examples
==================

This is a collection of Java gRPC examples.

This is not official Google product.

[YouTube video](https://www.youtube.com/watch?v=xpmFhTMqWhc)
"
ebean-orm/examples,master,47,30,2014-11-13T06:47:57Z,262,3,"Example use Ebean with Maven, Gradle, Java and Kotlin ",,"# examples

Examples using Ebean with Maven, Gradle, Java and Kotlin 


<table>
<tr>
  <td>base-example</td>
  <td>A basic maven Java8 example</td>
</tr>
<tr>
  <td>basic-gradle-java</td>
  <td>Gradle5 Java8 example</td>
</tr>
<tr>
  <td>basic-gradle-kotlin</td>
  <td>Gradle5 Kotlin example. Includes Kotlin query bean generation.</td>
</tr>
</table>
"
hamvocke/spring-testing,master,985,408,2017-05-12T06:49:12Z,6801,0,A Spring Boot application with lots of test examples,microservices spring spring-boot spring-test tdd test-automation test-microservices test-pyramid testing,"# The Practical Test Pyramid: Spring Boot Edition

[![Build Status](https://circleci.com/gh/hamvocke/spring-testing/tree/master.svg?style=svg)](https://circleci.com/gh/hamvocke/spring-testing/tree/master)

This repository contains a *Spring Boot* application with lots of test examples on different levels of the [Test Pyramid](https://martinfowler.com/bliki/TestPyramid.html). It shows an opinionated way to thoroughly test your spring application by demonstrating different types and levels of testing. You will find that some of the tests are duplicated along the test pyramid -- concepts that have already been tested in lower-level tests will be tested in more high-level tests. This contradicts the premise of the test pyramid. In this case it helps demonstrating different kinds of tests which is the main goal of this repository.

## Read the Blog Post
This repository is part of a [blog posts](https://martinfowler.com/articles/practical-test-pyramid.html) I wrote about test automation and the test pyramid. I highly recommend you read it to get a better feeling for the purpose of the different kinds of tests in this repository and how you can implement a reliable test suite for a Spring Boot application.

## Get started

### 1. Set an API Key as Environment Variable
In order to run the service, you need to set the `WEATHER_API_KEY` environment variable to a valid API key retrieved from ~~darksky.net~~ [openweathermap.org](https://openweathermap.org/).

_Note: in a previous version this example used darksky.net as the weather API. Since they've shut down their API for public access, we've since switched over to openweathermap.org_

A simple way is to rename the `env.sample` file to `.env`, fill in your API key from _openweathermap.org_ and source it before running your application:

```bash
source .env
```

### 2. Start a PostgreSQL database
The easiest way is to use the provided `startDatabase.sh` script. This script starts a Docker container which contains a database with the following configuration:
    
  * port: `15432`
  * username: `testuser`
  * password: `password`
  * database name: `postgres`
  
If you don't want to use the script make sure to have a database with the same configuration or modify your `application.properties`.

### 3. Run the Application
Once you've provided the API key and started a PostgreSQL database you can run the application using

```bash
./gradlew bootRun
```

The application will start on port `8080` so you can send a sample request to `http://localhost:8080/hello` to see if you're up and running.


## Application Architecture

```
 ╭┄┄┄┄┄┄┄╮      ┌──────────┐      ┌──────────┐
 ┆   ☁   ┆  ←→  │    ☕     │  ←→  │    💾     │
 ┆  Web  ┆ HTTP │  Spring  │      │ Database │
 ╰┄┄┄┄┄┄┄╯      │  Service │      └──────────┘
                └──────────┘
                     ↑ JSON/HTTP
                     ↓
                ┌──────────┐
                │    ☁     │
                │ Weather  │
                │   API    │
                └──────────┘
```

The sample application is almost as easy as it gets. It stores `Person`s in an in-memory database (using _Spring Data_) and provides a _REST_ interface with three endpoints:

  * `GET /hello`: Returns _""Hello World!""_. Always.
  * `GET /hello/{lastname}`: Looks up the person with `lastname` as its last name and returns _""Hello {Firstname} {Lastname}""_ if that person is found.
  * `GET /weather`: Calls a downstream [weather API](https://openweathermap.org/current#name) via HTTP and returns a summary for the current weather conditions in Hamburg, Germany

### Internal Architecture
The **Spring Service** itself has a pretty common internal architecture:

  * `Controller` classes provide _REST_ endpoints and deal with _HTTP_ requests and responses
  * `Repository` classes interface with the _database_ and take care of writing and reading data to/from persistent storage
  * `Client` classes talk to other APIs, in our case it fetches _JSON_ via _HTTP_ from the openweathermap.org weather API


  ```
  Request  ┌────────── Spring Service ───────────┐
   ─────────→ ┌─────────────┐    ┌─────────────┐ │   ┌─────────────┐
   ←───────── │  Controller │ ←→ │  Repository │←──→ │  Database   │
  Response │  └─────────────┘    └─────────────┘ │   └─────────────┘
           │         ↓                           │
           │    ┌──────────┐                     │
           │    │  Client  │                     │
           │    └──────────┘                     │
           └─────────│───────────────────────────┘
                     │
                     ↓   
                ┌──────────┐
                │    ☁     │
                │ Weather  │
                │   API    │
                └──────────┘
  ```  

## Test Layers
The example applicationn shows different test layers according to the [Test Pyramid](https://martinfowler.com/bliki/TestPyramid.html).

```
      ╱╲
  End-to-End
    ╱────╲
   ╱ Inte-╲
  ╱ gration╲
 ╱──────────╲
╱   Unit     ╲
──────────────
```

The base of the pyramid is made up of unit tests. They should make the biggest part of your automated test suite.

The next layer, integration tests, test all places where your application serializes or deserializes data. Your service's REST API, Repositories or calling third-party services are good examples. This codebase contains example for all of these tests.

```
 ╭┄┄┄┄┄┄┄╮      ┌──────────┐      ┌──────────┐
 ┆   ☁   ┆  ←→  │    ☕     │  ←→  │    💾     │
 ┆  Web  ┆      │  Spring  │      │ Database │
 ╰┄┄┄┄┄┄┄╯      │  Service │      └──────────┘
                └──────────┘

  │    Controller     │      Repository      │
  └─── Integration ───┴──── Integration ─────┘

  │                                          │
  └────────────── Acceptance ────────────────┘               
```

```
 ┌─────────┐  ─┐
 │    ☁    │   │
 │ Weather │   │
 │   API   │   │
 │  Stub   │   │
 └─────────┘   │ Client
      ↑        │ Integration
      ↓        │ Test
 ┌──────────┐  │
 │    ☕     │  │
 │  Spring  │  │
 │  Service │  │
 └──────────┘ ─┘
```

## Tools
You can find lots of different tools, frameworks and libraries being used in the different examples:

  * **Spring Boot**: application framework
  * **JUnit**: test runner
  * **Hamcrest Matchers**: assertions
  * **Mockito**: test doubles (mocks, stubs)
  * **MockMVC**: testing Spring MVC controllers
  * **RestAssured**: testing the service end to end via HTTP
  * **Wiremock**: provide HTTP stubs for downstream services

"
rathboma/hadoop-framework-examples,master,149,154,2013-02-08T00:04:11Z,342,5,An implementation of a real-world map-reduce workflow in each major framework.,,"# Realistic Hadoop Data Processing Examples

This code is to accompany [my blog post on map reduce frameworks][1]

The point of the code in this repository is to provide an implementation for a business question (listed below) in each of the major Map Reduce frameworks.

Each implementation will get it's own subdirectory with it's own build and running instructions. Each framework will also get an accompanying test, and an in-depth walkthrough about implementation details.

The following implementations are complete:

* Java map reduce - [walkthrough](http://blog.matthewrathbone.com/2013/02/09/real-world-hadoop-implementing-a-left-outer-join-in-hadoop-map-reduce.html)
* Scoobi - [walkthrough](http://blog.matthewrathbone.com/2013/11/03/real-world-hadoop---implementing-a-left-outer-join-with-scoobi.html)
* Scalding - [walkthrough](http://blog.matthewrathbone.com/2015/10/20/2015-10-20-scalding-tutorial.html)
* Cascading - [walkthrough](http://blog.matthewrathbone.com/2015/06/25/real-world-hadoop---implementing-a-left-outer-join-in-java-with-cascading.html)
* Hive  - [walkthrough](http://blog.matthewrathbone.com/2013/02/20/real-world-hadoop---implementing-a-left-outer-join-in-hive.html)
* Pig - [walkthrough](http://blog.matthewrathbone.com/2013/04/07/real-world-hadoop---implementing-a-left-outer-join-in-pig.html)


## The problem


### The Data

We have two datasets: customers, and transactions.

Customer Fields:
* id (1)
* email (matthew@example.com)
* language (EN)
* location (US)

Transaction Fields:
* transaction-id (1)
* product-id (1)
* user-id (1)
* purchase-amount (19.99)
* product-description (a rubber chicken)

These two datasets are stored in tab-delimited files somewhere on HDFS.

### The Question

For each product, we want to know the number of locations in which that product was purchased.

That's it!

In the real world, we might have other questions, like the number of purchases per location for each product.



[1]: http://blog.matthewrathbone.com/post/39783477991/a-quick-guide-to-hadoop-map-reduce-frameworks
[2]: https://github.com/rathboma/hadoop-framework-examples/tree/master/java-mapreduce
"
chanjarster/spring-test-examples,master,294,115,2017-07-06T02:33:23Z,125,0,Spring、Spring Boot和TestNG测试指南,,"# Spring、Spring Boot和TestNG测试指南

Spring、Spring Boot都提供了非常便利的测试工具，但遗憾的是官方文档的大多数例子都是基于JUnit的。本人比较喜欢用TestNG做单元、集成测试，所以开启了本项目收集了在Spring、Spring Boot项目中利用TestNG测试的例子。

## 章节列表

1. [Chapter 0: 基本概念][chapter_0_concept]
1. Chapter 1: 基本用法
    1. [引言][chapter_1_intro]
    1. [认识TestNG][chapter_1_s1_testng]
    1. [使用Spring Testing工具][chapter_1_s2_spring_testing]
    1. [使用Spring Boot Testing工具][chapter_1_s3_spring_boot_testing]
1. Chapter 2: Annotations
    1. [引言][chapter_2_intro]
    1. [@TestPropertySource][chapter_2_s1_test_property_source]
    1. [@ActiveProfile][chapter_2_s2_active_profile]
    1. [@JsonTest][chapter_2_s3_json_test]
    1. [@OverrideAutoConfiguration][chapter_2_s4_override_auto_configuration]
    1. [@TestConfiguration][chapter_2_s5_test_configuration]
1. [Chapter 3: 使用Mockito][chapter_3_mockito]
1. Chapter 4: 测试关系型数据库
    1. [基本做法][chapter_4_s1_basic]
    1. [使用Docker创建临时数据库][chapter_4_s2_using_docker]
1. [Chapter 5: 测试Spring MVC][chapter_5_mvc]
1. [Chapter 6: 测试AOP][chapter_6_aop]
1. [Chapter 7: 测试@Configuration][chapter_7_configuration]
1. [Chapter 8: 共享测试配置][chapter_8_share_test_config]
1. [附录I Spring Mock Objects][appendix_i]
1. [附录II Spring Test Utils][appendix_ii]


[doc-spring-test-utils]: http://docs.spring.io/spring/docs/4.3.9.RELEASE/spring-framework-reference/htmlsingle/#unit-testing-support-classes
[chapter_0_concept]: chapter_0_concept.md

[chapter_1_intro]: chapter_1_intro.md
[chapter_1_s1_testng]: chapter_1_s1_testng.md
[chapter_1_s2_spring_testing]: chapter_1_s2_spring_testing.md
[chapter_1_s3_spring_boot_testing]: chapter_1_s3_spring_boot_testing.md

[chapter_2_intro]: chapter_2_intro.md
[chapter_2_s1_test_property_source]: chapter_2_s1_test_property_source.md
[chapter_2_s2_active_profile]: chapter_2_s2_active_profile.md
[chapter_2_s3_json_test]: chapter_2_s3_json_test.md
[chapter_2_s4_override_auto_configuration]: chapter_2_s4_override_auto_configuration.md
[chapter_2_s5_test_configuration]: chapter_2_s5_test_configuration.md

[chapter_3_mockito]: chapter_3_mockito.md

[chapter_4_s1_basic]: chapter_4_s1_basic.md
[chapter_4_s2_using_docker]: chapter_4_s2_using_docker.md

[chapter_5_mvc]: chapter_5_mvc.md
[chapter_6_aop]: chapter_6_aop.md
[chapter_7_configuration]: chapter_7_configuration.md
[chapter_8_share_test_config]: chapter_8_share_test_config.md
[appendix_i]: appendix_i.md
[appendix_ii]: appendix_ii.md
"
laolunsi/spring-boot-examples,master,268,119,2019-12-11T13:36:57Z,1000,3,:green_salad:​ Spring/SpringBoot/SpringCloud 实践学习案例，从入门到精通，持续更新中，欢迎交流学习:beer: ！ ,alibaba-cloud blog elasticsearch gateway java mail nacos rabbitmq redis spring spring-boot spring-cloud spring-cloud-alibaba spring-cloud-gateway,"# spring-boot-exmaples

:smile: 该仓库为Spring/SpringBoot/SpringCloud系列技术栈

目前还在持续更新中哦！我的公众号：猿生物语，ID: JavaApes, 欢迎大家与我一起学习、进步！

:tipping_hand_man: demo表示实战示例，study表示知识点的深入学习，请注意！因为工作较忙，可能部分已上传代码的子项目对应的文章还未发布，如有问题可以联系我！

如果您觉得该教程还算有所帮助，还请点个**star**支持一下！


---

## Spring Boot

- [x] spring-boot-ssm-demo: [Spring Boot SSM 简单整合示例](https://mp.weixin.qq.com/s/GO-LDQb4c2LERVpCT8xoVQ)
- [x] spring-boot-admin-demo: [Spring Boot 应用健康监控](https://mp.weixin.qq.com/s/4qCocrB-lhrNGtP1N4w4mQ)
- [x] spring-boot-config-study: [Spring Boot 配置详解](https://mp.weixin.qq.com/s/ctzf1Xo7850yBdBzv9vlmA)
- [x] spring-boot-swagger-demo: [Spring Boot 使用 Swagger 构建 RestAPI 接口文档](https://mp.weixin.qq.com/s/cATpnfphcbb1n8RW4YQXcA)
- [x] spring-boot-exception-demo: [Spring Boot 统一异常处理](https://mp.weixin.qq.com/s/KQGU1FaIvF-v9LmUa_-NGw)
- [x] spring-boot-logback-demo: [Spring Boot 日志处理之 Logback](https://mp.weixin.qq.com/s/Y_P-t_xy-BPtrHgJ0IZKlg)
- [x] spring-boot-redis-demo: [Spring Boot 整合 Redis](https://mp.weixin.qq.com/s/vxW3WNYixdKrHir7dlVzWQ)
- [x] spring-boot-mongo-demo: [Spring Boot 整合 MongoDB](https://mp.weixin.qq.com/s/5BAGDxengmOmT9m6iwq4dQ)
- [x] spring-boot-params-time-demo: [Spring Boot 时间参数处理问题](https://mp.weixin.qq.com/s/nEUIUCuyG1oz9JwJYhM8mA)
- [x] spring-boot-mail-demo: [Spring Boot 邮件发送](https://mp.weixin.qq.com/s/3wNjqD8db_vrn01WYv6ymg)
- [x] spring-boot-application-study: [Spring Boot Application 详解](https://mp.weixin.qq.com/s/AiDvv5wR4Av4yHxFOvLyDQ)
- [x] spring-boot-cache-demo: [Spring Boot 缓存技术实战](https://mp.weixin.qq.com/s/lcZfgOY-TOIcmUqFcBGBEA)
- [x] sso-oauth2-demo: [Spring Boot OAuth2 单点登录示例](https://mp.weixin.qq.com/s/2davYzHuGKRQD1m-Atjs3w)
- [x] spring-boot-rabbitmq-demo: [Spring Boot 整合 RabbitMQ](https://mp.weixin.qq.com/s/UjTWWIc68ncNYR6oxDUcBw)
- [x] spring-boot-elasticsearch-demo: [Spring Boot 整合 ElasticSearch](https://mp.weixin.qq.com/s/0_2u5v-ALMIGMaplr2AAfQ)
- [x] spring-boot-shardsphere-demo: Spring Boot + ShardShpere 实现分库分表
- [x] spring-boot-clickhouse-demo: [Spring Boot + ClickHouse](https://mp.weixin.qq.com/s/XQDWkmnXGrina_And9063w)

---

## Spring Cloud

- [x] spring-cloud-eureka-demo: [Spring Cloud 服务注册与发现之 Eureka](http://www.eknown.cn/index.php/springcloud/eureka.html)
- [x] spring-cloud-feign-demo: [Spring Cloud 服务调用之 Feign](http://www.eknown.cn/index.php/springcloud/feign.html)
- [x] spring-cloud-consul-demo: [Spring Cloud 服务注册中心之 Consul](http://www.eknown.cn/index.php/springcloud/consul.html)
- [x] spring-cloud-ribbon-demo: [Spring Cloud 服务调用之 Ribbon](http://www.eknown.cn/index.php/springcloud/ribbon.html)
- [x] spring-cloud-hystrix-demo: [Spring Cloud 熔断之 Hystrix](http://www.eknown.cn/index.php/springcloud/hystrix.html)
- [x] spring-cloud-ali-nacos-demo: [Spring Cloud 阿里服务注册中心 Nacos](https://mp.weixin.qq.com/s/XUt2GZbXHk9Mkg9in99ERQ)
- [x] spring-cloud-admin-demo: [Spring Cloud 应用健康监控](https://mp.weixin.qq.com/s/pInf-K-KaQAOxLM5sINQOw)
- [x] spring-cloud-config-demo:[ Spring Cloud 配置中心](https://mp.weixin.qq.com/s/QcIaGAYUvPBIqJM8oMbVvQ)
- [x] spring-cloud-nacos-config-demo: [Spring Cloud Nacos 配置中心](https://mp.weixin.qq.com/s/ESGR3aWgnkgJAw7Oc36xGw)
- [ ] spring-cloud-gateway: Spring Cloud Gateway
- [x] spring-cloud-gateway-nacos-routes: [Spring Cloud Gateway + Nacos 实现动态路由](https://mp.weixin.qq.com/s/B3sas24dVk0DSgeqDPBAng)
- [x] spring-cloud-gateway-dynamic-routes: [Spring Cloud Gateway + Mysql 实现动态路由及路由管理功能](https://mp.weixin.qq.com/s/uHgF7tAj1uSsBxKvLENBUw)
- [ ] spring-cloud-sentinel-demo: [Spring Cloud Alibaba Sentinel 流量管理](https://mp.weixin.qq.com/s/9BvAhUCvsW1GmwLXhB5btQ)

未完待续...

---

## 公众号

如果大家想要实时关注我的文章和分享动态的话，可以关注一下！

微信搜索 **猿生物语** or **JavaApes** ，或扫码。

![file](http://zfh-public-blog.oss-cn-beijing.aliyuncs.com/image-1578371742220.png)








"
CrossTheRoadElec/Phoenix5-Examples,master,117,171,2017-09-13T17:11:50Z,81429,13,"HERO C#, FRC C++/Java, future platforms.",,
devunwired/recyclerview-playground,master,1245,270,2014-08-25T04:32:09Z,266,12,Examples of RecyclerView use and custom LayoutManager implementations,,"Android RecyclerView Examples
-----------------------------

This repository contains examples for using the RecyclerView widget found in the Android Support Library.

Disclaimer
----------
This repository contains sample code intended to demonstrate the capabilities of the RecyclerView layout manager APIs. It is not intended to be used as-is in applications as a library dependency, and will not be maintained as such. Bug fix contributions are welcome, but issues and feature requests will not be addressed.

Example Contents
----------------
The following bits can be found in the main sample application:
- Implementation of `LinearLayoutManager` and `GridLayoutManager` for vertical and horizontal scrolling.
- Custom ItemDecorations
 - `InsetDecoration` - Create an inset margin on all child views.
 - `DividerDecoration` - Create an inset margin and draw dividers below vertical child views.
 - `GridDividerDecoration` - Create an inset margin an draw dividers along grid lines
- Custom LayoutManager
 - `FixedGridLayoutManager` - Similar to `StaticGridLayoutManager`, but with a controllable column count.
 
The following examples are incubating on the `experimental` branch (these mostly work, if you feel like living dangerously):
- Custom LayoutManagers
 - `StaticGridLayoutManager` - 2D scrolling grid with variable column count based on data set. Window of visible (non-recycled) views is determined statically.
 - `DynamicGridLayoutManager` - 2D scrolling grid where window of visible views is determined dynamically. Results in fewer views in memory, but scrolling performance is questionable.

License
-------

The code supplied here is covered under the MIT Open Source License:

Copyright (c) 2015 Wireless Designs, LLC

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
langchain4j/langchain4j-examples,main,350,143,2023-06-20T16:04:18Z,1154,1,,,"# [LangChain4j](https://github.com/langchain4j/langchain4j) Examples

This repository provides several examples using the LangChain4j library.

A good place to start includes:
- [Tutorials](https://github.com/langchain4j/langchain4j-examples/tree/main/tutorials/src/main/java)
- [More examples](https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java)
- [Examples of using advanced RAG techniques](https://github.com/langchain4j/langchain4j-examples/tree/main/rag-examples/src/main/java)
- [Example of an agent with memory, tools and RAG](https://github.com/langchain4j/langchain4j-examples/blob/5a19b723661530cf64846a256e2b01b060e7fb0b/customer-support-agent-example/src/main/java/dev/langchain4j/example/CustomerSupportAgentApplication.java#L39)

If you have any issues or feature requests, please submit them [here](https://github.com/langchain4j/langchain4j/issues/new/choose).
"
luoyan35714/OPC_Client,master,206,155,2014-12-03T08:26:08Z,71003,0,OPC client examples,,"## OPC_Client

OPC client examples include [utgard](http://openscada.org/projects/utgard/) and [jeasyopc](http://sourceforge.net/projects/jeasyopc/?source=navbar)

Also for the real produce environment, there's two example for <b>performance</b> test.

## 已完成
`Utgard`部分已经全部完成

## Next Step
+ JeasyOPC继续压力测试
+ 40W点下异步的时间
+ 异步下多少线程数是最好的

## 现在依然存在的问题
+ JeasyOPC发布订阅的实现
+ JeasyOPC异步的源码实现

## 资源
+ `OPC_Client_Jeasyopc` JeasyOPC的测试Example
+ `OPC_Client_Jeasyopc_Perfermance` JeasyOPC的压力测试Example
+ `OPC_Client_Utgard` Utgard的测试Example
+ `OPC_Client_Utgard_Perfermance` Utgard的压力测试Example
+ `书籍` OPC开发参考书籍
+ `学习笔记` 个人OPC学习笔记和一个测试结果文档`OPC压力测试结果统计`
+ `安装文件` 一个OPC Server 模拟器 ·Matrikon Simulation OPC Server·

## 学习笔记
+ [个人学习OPC学习笔记](http://www.hifreud.com/tag/#OPC-ref)
"
TNG/ArchUnit-Examples,main,534,87,2017-11-29T20:46:03Z,434,3,"Examples for ArchUnit (A Java architecture test library, to specify and assert architecture rules in plain Java)",,"# ArchUnit Examples

This module presents some examples on how to use the latest release of 
[ArchUnit](http://archunit.org).

The different subprojects demonstrate the type of test support: 
* `example-junit4` shows how to use the JUnit 4 test support including the `ArchUnitRunner`
* `example-junit5` shows how to use the JUnit 5 test support where test classes are simply being picked up by being annotated with `@AnalyzeClasses`
* `example-plain` shows how to use ArchUnit independently of any specific test framework, even though as a runtime environment these tests use JUnit 4 as well

All example rules you find within `src/test` refer to classes from `src/main`.
These tests are all designed to fail, to demonstrate how production code could violate
typical architectural constraints (like layer dependencies).

You can run them with Gradle

```
./gradlew build
```

Otherwise the tests can be run directly from any IDE.

## Regarding issues

If you have found any issues with the examples or have any question, please direct them to the [main repository](https://github.com/TNG/ArchUnit/issues) instead. This repository is an autogenerated version of the latest released version of https://github.com/TNG/ArchUnit/tree/main/archunit-example (with some simplified project setup for illustration)
"
gothinkster/spring-boot-realworld-example-app,master,1254,661,2017-08-28T17:43:55Z,759,4,"Example Spring codebase containing real world examples (CRUD, auth, advanced patterns, etc) that adheres to the RealWorld API spec.",mybatis realworld spring-boot,"# ![RealWorld Example App using Kotlin and Spring](example-logo.png)

[![Actions](https://github.com/gothinkster/spring-boot-realworld-example-app/workflows/Java%20CI/badge.svg)](https://github.com/gothinkster/spring-boot-realworld-example-app/actions)

> ### Spring boot + MyBatis codebase containing real world examples (CRUD, auth, advanced patterns, etc) that adheres to the [RealWorld](https://github.com/gothinkster/realworld-example-apps) spec and API.

This codebase was created to demonstrate a fully fledged full-stack application built with Spring boot + Mybatis including CRUD operations, authentication, routing, pagination, and more.

For more information on how to this works with other frontends/backends, head over to the [RealWorld](https://github.com/gothinkster/realworld) repo.

# *NEW* GraphQL Support  

Following some DDD principles. REST or GraphQL is just a kind of adapter. And the domain layer will be consistent all the time. So this repository implement GraphQL and REST at the same time.

The GraphQL schema is https://github.com/gothinkster/spring-boot-realworld-example-app/blob/master/src/main/resources/schema/schema.graphqls and the visualization looks like below.

![](graphql-schema.png)

And this implementation is using [dgs-framework](https://github.com/Netflix/dgs-framework) which is a quite new java graphql server framework.
# How it works

The application uses Spring Boot (Web, Mybatis).

* Use the idea of Domain Driven Design to separate the business term and infrastructure term.
* Use MyBatis to implement the [Data Mapper](https://martinfowler.com/eaaCatalog/dataMapper.html) pattern for persistence.
* Use [CQRS](https://martinfowler.com/bliki/CQRS.html) pattern to separate the read model and write model.

And the code is organized as this:

1. `api` is the web layer implemented by Spring MVC
2. `core` is the business model including entities and services
3. `application` is the high-level services for querying the data transfer objects
4. `infrastructure`  contains all the implementation classes as the technique details

# Security

Integration with Spring Security and add other filter for jwt token process.

The secret key is stored in `application.properties`.

# Database

It uses a ~~H2 in-memory database~~ sqlite database (for easy local test without losing test data after every restart), can be changed easily in the `application.properties` for any other database.

# Getting started

You'll need Java 11 installed.

    ./gradlew bootRun

To test that it works, open a browser tab at http://localhost:8080/tags .  
Alternatively, you can run

    curl http://localhost:8080/tags

# Try it out with [Docker](https://www.docker.com/)

You'll need Docker installed.
	
    ./gradlew bootBuildImage --imageName spring-boot-realworld-example-app
    docker run -p 8081:8080 spring-boot-realworld-example-app

# Try it out with a RealWorld frontend

The entry point address of the backend API is at http://localhost:8080, **not** http://localhost:8080/api as some of the frontend documentation suggests.

# Run test

The repository contains a lot of test cases to cover both api test and repository test.

    ./gradlew test

# Code format

Use spotless for code format.

    ./gradlew spotlessJavaApply

# Help

Please fork and PR to improve the project.
"
Udinic/SmallExamples,master,131,117,2011-08-17T22:21:55Z,230,7,A collection of small examples from my blog,,"Small Examples
==============

This project combines a collection of modules, each intended to show a certain feature discussed in my blog.
This project can be easily opened in IntelliJ IDEA, or imported into your favorite IDE.


Developed By
============

* Udi Cohen (udinic@gmail.com)



License
=======

Copyright 2012 Udi Cohen

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"
andreschaffer/event-sourcing-cqrs-examples,master,534,117,2017-06-02T19:30:49Z,409,3,Event Sourcing and CQRS in practice.,cqrs cqrs-es ddd domain-driven-design event-sourcing event-store events hexagonal-architecture java,"![Build](https://github.com/andreschaffer/event-sourcing-cqrs-examples/workflows/Build/badge.svg)
[![Test Coverage](https://api.codeclimate.com/v1/badges/299df5b2515003778612/test_coverage)](https://codeclimate.com/github/andreschaffer/event-sourcing-cqrs-examples/test_coverage)
[![Maintainability](https://api.codeclimate.com/v1/badges/299df5b2515003778612/maintainability)](https://codeclimate.com/github/andreschaffer/event-sourcing-cqrs-examples/maintainability)
[![Dependabot](https://img.shields.io/badge/Dependabot-enabled-blue?logo=dependabot)](https://docs.github.com/en/github/administering-a-repository/keeping-your-dependencies-updated-automatically)

# Event Sourcing and CQRS Examples
This project aims to provide examples of how to use Event Sourcing and CQRS applied to a minimalistic bank context.  

We assume the reader has basic knowledge of Event Sourcing and CQRS concepts.  
If you want to brush up on the subject we suggest reading:  
- [https://martinfowler.com/eaaDev/EventSourcing.html](https://martinfowler.com/eaaDev/EventSourcing.html)
- [https://martinfowler.com/bliki/CQRS.html](https://martinfowler.com/bliki/CQRS.html)

## Domain overview
In this minimalistic bank, a _client_ can _open_ one or more _accounts_.  
On each _account_, the _client_ can _deposit_ or _withdraw_ money.  
The history of an _account's transactions_ is available to the _client_ as well as a summary of the _client's accounts_.

## Design choices
### Architecture overview
      Event Store   Projections
        +----+        +----+
        |    |        |    |
        | DB |        | DB |
        +--+-+        +-+--+
          ^             ^
          |             |
    +------------+------------+
    |     |      |      |     |
    |     |    Events   |     |
    |     +------+----+ |     |
    |     |      |    | |     |
    |     +      |    v +     |
    |   Domain   |   Read     |
    |   Model    |   Model    |
    |            |            |
    +------------+------------+
    |                         |
    |           API           |
    |                         |
    +-------------------------+ 

#### Ports and Adapters
For the Domain Model, we chose the Ports and Adapters structure because we wanted to protect the domain logic from
all the technical concerns.

For more information about it read [here](http://www.dossier-andreas.net/software_architecture/ports_and_adapters.html).

#### Package by Feature
For the Read Models, we chose the Package by Feature structure because we would not benefit from isolating the layers
and instead we put all feature related parts close together. 

For more information about it read [here](http://www.javapractices.com/topic/TopicAction.do?Id=205).

### DDD and REST
There has been a myth of DDD and REST being incompatible due to DDD being all about behaviour
whereas REST is all about state.  
In this project we followed both techniques quite strictly and hope that the result shows that they can be well combined.  
Note: We did not include REST hypermedia controls as we believe it is a big subject in itself and didn't want to shift focus from Event Sourcing and CQRS.

### Event Sourcing and CQRS (finally!)
We have taken a pragmatic approach when combining Event Sourcing and CQRS. 
By the book, CQRS proposes a complete separation between the read/query and write/command sides,
but that's not what we have here.
The approach we've taken instead:
- The writes/commands are all on the domain model side and processed by aggregates;
- The reads/queries are both in the domain model side and in the read model side.
  - The queries in the domain model side are only allowed when the data we need is a single aggregate itself.
    The reason being that we can only query the event store by aggregate id
    and we can actually fulfill those queries by replaying that single aggregate events.
  - For any other kind of query, we don't want to compromise the domain model.
    Therefore, we create read models to fulfill those queries.
    They are basically projections, potentially built from different events and aggregates
    that can be queried by more appropriate fields. 
    
#### Events
Events are a thing from the past. It communicates a significant change that _happened_. 

##### Idempotency when replaying events
When replaying events, we don't want to execute any business logic because we can't change history. We only want to do assignments.  
A simple example is with a deposit event: instead of adding the deposited amount to the balance when replaying (business logic), we want 
the updated balance already available so that we can just assign it. This makes it possible to replay the event multiple times with the same outcome.

##### Ordering of events
In a distributed world, event timestamps are unreliable for ordering - machines have their own clocks.  
Instead we can make the ordering explicit with an event version.
In this project we use event versioning in two ways:
- In the write/command side, we use it for protecting ourselves from race conditions via optimistic locking;
- In the read/query side, we use it for commutative reasons, meaning events can come out of order and we can still handle them properly.

If you are interested in this topic, we also recommend reading about [Lamport timestamps](https://en.wikipedia.org/wiki/Lamport_timestamps) and [Vector clocks](https://en.wikipedia.org/wiki/Vector_clock) as alternatives.

## Trying it out
### Requirements
- Java 14
- Maven

### Building the application
` mvn clean verify `

### Starting the application
` java -jar target/bank-service-1.0-SNAPSHOT.jar server src/environments/development.yml `

### Examples of use
#### Create a client
` curl -v -X POST -H ""Content-Type: application/json"" -d '{""name"":""Jane Doe"", ""email"":""jane.doe@example.com""}' http://localhost:8080/clients `

Check the created client in the response's 'Location' header.

#### Create an account for the client
` curl -v -X POST -H ""Content-Type: application/json"" -d '{""clientId"":""{CLIENT_ID}""}' http://localhost:8080/accounts `

Check the created account in the response's 'Location' header.

#### Make a deposit to the account
` curl -v -X POST -H ""Content-Type: application/json"" -d '{""amount"":1000000}' http://localhost:8080/accounts/{ACCOUNT_ID}/deposits `

#### Check that you created a millionaire!
` curl -v http://localhost:8080/accounts/{ACCOUNT_ID} `

#### More operations
Go ahead and check the code! :)

# Contributing
If you would like to help making this project better, see the [CONTRIBUTING.md](CONTRIBUTING.md).  

# Maintainers
Send any other comments, flowers and suggestions to [André Schaffer](https://github.com/andreschaffer) and [Dan Eidmark](https://github.com/daneidmark).

# License
This project is distributed under the [MIT License](LICENSE).
"
centic9/jgit-cookbook,master,1725,499,2013-05-27T07:28:23Z,1076,2,Provides examples and code snippets for the JGit Java Git implementation,git java-git jgit jgit-cookbook,"jgit-cookbook
=============
[![Build Status](https://github.com/centic9/jgit-cookbook/actions/workflows/gradle-build.yml/badge.svg)](https://github.com/centic9/jgit-cookbook/actions)
[![Gradle Status](https://gradleupdate.appspot.com/centic9/jgit-cookbook/status.svg?branch=master)](https://gradleupdate.appspot.com/centic9/jgit-cookbook/status)
[![Tag](https://img.shields.io/github/tag/centic9/jgit-cookbook.svg)](https://github.com/centic9/jgit-cookbook/tags)

Provides examples and code snippets for the [JGit](https://eclipse.org/jgit/) Java Git implementation. 

The JGit framework is rich and diverse, it has two layers, a low-level _api_ and a higher-level set of _porcelain_ commands. This can be a bit intimidating at first as there are lots of classes, some of which are not relevant for most tasks.

This project tries to provide a collection of ready-to-run snippets which provide a quick start for building functionality using JGit. 

Please make sure to take a look at the nicely written [introduction](http://www.codeaffine.com/2015/12/15/getting-started-with-jgit/) and also use the existing [JavaDoc](http://download.eclipse.org/jgit/site/6.8.0.202311291450-r/apidocs/) and the [User Guide](http://wiki.eclipse.org/JGit/User_Guide) as well, as they are well done and provide detailed information and a general overview of JGit respectively.

*Note: Please use sites such as http://stackoverflow.com for general questions about JGit usage, not issues in this project. Issues should be used for problems with snippets and suggestions of missing snippets. Snippets from good answers on stackoverflow can then be included here, naturally.*

#### Getting started

##### Grab it

    git clone https://github.com/centic9/jgit-cookbook.git

##### Build it and create Eclipse project files

###### When using Maven

    mvn dependency:sources eclipse:eclipse package

###### When using Gradle

    ./gradlew eclipse check

#### Run it

    Each snippet is a small standalone Java application, so you can simply  
    import the project into your favourite IDE and execute the snippets there.

#### Currently the following snippets are available

##### General Repository handling

* [Open an existing repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/OpenRepository.java)
* [Create a new repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/CreateNewRepository.java)

##### Porcelain commands

* [Initialize a new repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/InitRepository.java)
* [Add a new file to the index](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/AddFile.java)
* [Commit a file to an existing repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CommitFile.java)
* [Commit all changes](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CommitAll.java)
* [List commits (i.e. Log)](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ShowLog.java)
* [List all tags in a repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListTags.java)
* [List all branches in a repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListBranches.java)
* [List all commits in a repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/WalkAllCommits.java)
* [List uncommitted changes of a repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListUncommittedChanges.java)
* [Create and delete branches](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CreateAndDeleteBranch.java)
* [Create and delete tags](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CreateAndDeleteTag.java)
* [List all tags applied on a branch](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListTagsOnBranch.java)
* [Revert a modified tracked file back to its original state in most recent commit](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/RevertChanges.java)
* [Return diff between two branches](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ShowBranchDiff.java)
* [Show diff of changes to a file between two revs](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ShowFileDiff.java)
* [Show diff of changes to all files between two commits](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ShowChangedFilesBetweenCommits.java)
* [Show diff of changes to a file between two commits when the file has been renamed](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/DiffRenamedFile.java)
* [Show Status](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ShowStatus.java)
* [Store contents of branch into a compressed file](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CreateArchive.java)
* [Write contents of branch into a compressed file using a custom archive format](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CreateCustomFormatArchive.java)
* [Blame, i.e. find out which commit changed specific lines in a file](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ShowBlame.java)
* [Add and list Notes attached to commits](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/AddAndListNoteOfCommit.java)
* [List available Notes](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListNotes.java)
* [Clean all untracked files](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CleanUntrackedFiles.java)
* [Create, list, apply and drop stashes](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CreateListApplyAndDropStash.java)
* [Run garbage collection](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CollectGarbage.java)
* [Blame, i.e. retrieve information who last changed which line in a file](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/BlameFile.java)
* [Merge changes from a branch](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/MergeChanges.java)
* [List changed files between two commits](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/DiffFilesInCommit.java)
* [List changed files in index](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/DiffIndexChanges.java)
* [List changed files in checkout](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/DiffLocalChanges.java)

##### Commands working with remote repositories

* [Clone a remote repository into a new local directory](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CloneRemoteRepository.java)
* [Clone a remote repository via Apache SSHD](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CloneRemoteRepositoryWithApacheSSHD.java)
* [Iterate remote references in a repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListRemotes.java)
* [List remote heads/tags without a local clone](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/ListRemoteRepository.java)
* [Fetch from remote repositories](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/FetchRemoteCommits.java)
* [Fetch from remote repositories and use 'prune' to remove outdated remote branches/tags](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/FetchRemoteCommitsWithPrune.java)
* [Fetch from remote repositories via SSH protocol](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/FetchRemoteCommitsWithSshAuth.java)
* [Clone a remote repository via SSH protocol and username/password credentials](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CloneRemoteRepositoryWithAuthentication.java)
* [Rebase onto an upstream branch](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/RebaseToOriginMaster.java)
* [Using InMemoryRepository to clone a Git repo in-memory and work from there](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CloneRemoteRepositoryIntoMemoryAndReadFile.java)
* [Checkout a PR from GitHub](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/CheckoutGitHubPullRequest.java)
* [Push to a remote repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/PushToRemoteRepository.java)
* [Set remote tracking branch](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/porcelain/TrackMaster.java)

##### Low-level API

* [Get the SHA-1 ref from a name, e.g. refs/heads/master](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/GetRefFromName.java)
* [Get the commit-object from a name or a SHA-1](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/GetRevCommitFromObjectId.java)
* [Get the commit-message](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/GetCommitMessage.java)
* [Get the tree-object from a commit-object, name or SHA-1](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/GetRevTreeFromObjectId.java)
* [Read the contents of a file/blob](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ReadBlobContents.java)
* [Get the tag-object from a name or a SHA-1](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ReadTagFromName.java)
* [Resolve complex references, e.g. HEAD^^ to a SHA-1](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ResolveRef.java)
* [Iterate over the commits on a branch](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/WalkRev.java)
* [Iterate over a range of commits](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/WalkFromToRev.java)
* [Read contents of a specific file from a specific commit](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ReadFileFromCommit.java)
* [List remotes configured for the current repository](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/PrintRemotes.java)
* [Print out user information from Git](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ReadUserConfig.java)
* [Read file attributes, e.g. executable state, file or directory, size, ...](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/GetFileAttributes.java)
* [Use class BranchTrackingStatus to retrieve number of commits ahead/behind compared to remote branches](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ShowBranchTrackingStatus.java)
* [Check if commits on other branches are merged into a given branch](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/CheckMergeStatusOfCommit.java)
* [List files in a directory as-of a specific commit or a tag](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/ListFilesOfCommitAndTag.java)
* [Iterate over files of a commit recursively](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/WalkTreeRecursive.java)
* [Iterate over files of a commit non-recursively](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/WalkTreeNonRecursive.java)
* [Find all commits that are reachable via tags, branches, remotes, HEADs, ...](https://github.com/centic9/jgit-cookbook/blob/master/src/main/java/org/dstadler/jgit/api/WalkAllCommits.java)

##### GitServlet

* There is a standalone sub-project in directory [httpserver](https://github.com/centic9/jgit-cookbook/blob/master/httpserver) which 
starts up a simple HTTP Git server based on the JGit GitServlet.

Just import the project in your IDE and start up the `Main` application, see the Comments in the code for more details.

Another simple way to start the sample-server is to run `./gradlew run` in the httpserver-directory.

#### Useful code elsewhere

##### cf-ops-automation-broker 

* Implementation of a simple git server serving anynymous `git:` protocol: https://github.com/orange-cloudfoundry/cf-ops-automation-broker/blob/8bcb286652fae2b8fe2ccc9f67c53cb0272bcbd0/cf-ops-automation-broker-core/src/main/java/com/orange/oss/cloudfoundry/broker/opsautomation/ondemandbroker/git/GitServer.java
* Usage in tests: https://github.com/orange-cloudfoundry/cf-ops-automation-broker/blob/8bcb286652fae2b8fe2ccc9f67c53cb0272bcbd0/cf-ops-automation-bosh-broker/src/test/java/com/orange/oss/cloudfoundry/broker/opsautomation/ondemandbroker/sample/BoshServiceProvisionningTest.java#L134

#### Missing snippets

* Iterate all commits of a repository: https://gerrit.googlesource.com/plugins/branch-network/+log/refs/heads/master/src/main/java/com/googlesource/gerrit/plugins/branchnetwork/data/JGitFacade.java
* Take some of the unit tests as example: https://github.com/eclipse/jgit/tree/master/org.eclipse.jgit.test/tst/org/eclipse/jgit/api
* SubModules: http://stackoverflow.com/questions/13426798/jgit-read-gitmodules http://www.codeaffine.com/2014/04/16/how-to-manage-git-submodules-with-jgit/ https://stackoverflow.com/questions/26090139/jgit-reading-commits-from-a-submodule https://download.eclipse.org/jgit/site/6.8.0.202311291450-r/apidocs/org/eclipse/jgit/submodule/package-frame.html
* Diffing: http://stackoverflow.com/questions/12987364/how-to-diff-with-two-files-by-jgit-without-creating-repo
* Amend a previous commit: http://stackoverflow.com/questions/4772142/jgit-unstaging-files-removing-files-from-the-index-and-ammending-a-commit
* Remove a file from the index: http://stackoverflow.com/questions/4803462/jgit-java-git-library-unstaging-files
* Git repo on Amazon S3: http://stackoverflow.com/questions/8744611/git-repository-on-s3-as-origin-not-as-backup http://stackoverflow.com/questions/7031729/publish-to-s3-using-git http://www.fancybeans.com/blog/2012/08/24/how-to-use-s3-as-a-private-git-repository/
* CherryPick: http://download.eclipse.org/jgit/site/6.8.0.202311291450-r/apidocs/org/eclipse/jgit/api/CherryPickCommand.html http://stackoverflow.com/questions/18300898/how-to-cherry-pick-a-commit-that-has-more-than-one-parent
* More authentication: http://www.lordofthejars.com/2016/09/authenticating-with-jgit.html
* How to do a shallow clone (i.e. --depth 1) as soon as https://bugs.eclipse.org/bugs/show_bug.cgi?id=475615 is implemented

#### Support this project

If you find these snippets useful and would like to support it, you can [Sponsor the author](https://github.com/sponsors/centic9)

#### Sources

The following sources were used to build the snippets:

* [JGit JavaDoc](http://download.eclipse.org/jgit/site/6.8.0.202311291450-r/apidocs/)
* [JGit User Guide](http://wiki.eclipse.org/JGit/User_Guide)
* [JGit related questions on stackoverflow](http://stackoverflow.com/questions/tagged/jgit)
* [AlBlue's Blog: Embedding JGit](http://alblue.bandlem.com/2013/11/embedding-jgit.html)
* [JGit main page](http://www.eclipse.org/jgit/)
* [What’s the Difference? Creating Diffs with JGit](https://www.codeaffine.com/2016/06/16/jgit-diff/)

#### Other applications using JGit

* EGit - Git plugin for Eclipse - https://www.eclipse.org/egit/
* Gerrit - A web-based team code collaboration tool - https://www.gerritcodereview.com
* Gitiles - A simple Git repository browser - http://code.google.com/p/gitiles/ and https://android.googlesource.com
* JGitFS - A userfs implementation which allows to browse branches, tags, committs as a directory structure - https://github.com/centic9/JGitFS
* jgitstats - displays repository stats - https://github.com/selesse/jgitstats
* git-to-solr - Index git history into a Solr repository - https://github.com/arafalov/git-to-solr
* Elegit - GUI client for people who want to learn Git - https://github.com/dmusican/Elegit
* Grgit - A wrapper over JGit that provides a fluent API for interacting with Git repositories in Groovy-based tooling - https://github.com/ajoberstar/grgit
* jgitver A library to calculate a project semver compatible version from a git repository and its content - https://github.com/jgitver/jgitver
* gitective - Investigate Git repositories via filters - https://github.com/kevinsawicki/gitective
* RJGit - A JRuby wrapper around the JGit library - https://github.com/repotag/rjgit
* KGit - A Kotlin Wrapper of JGit - https://github.com/sya-ri/KGit
* Jabylon - A web based translation tool - https://github.com/jutzig/jabylon/ - [GitTeamProvider.java](https://github.com/jutzig/jabylon/blob/master/org.jabylon.team.git/src/main/java/org/jabylon/team/git/GitTeamProvider.java)

Ruby Build

#### Contribute

Please note that the list of snippets is not yet complete, probably never will. If you are missing things or have suggestions how to improve or add snippets, please either send pull requests or create [issues](https://github.com/centic9/jgit-cookbook/issues).

#### Licensing

   Copyright 2013-2023 Dominik Stadler

   Licensed under the Apache License, Version 2.0 (the ""License"");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an ""AS IS"" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
"
cxyxiaokui/spring-boot-examples,master,192,130,2018-11-16T00:44:46Z,1507,10,个人学习 SpringBoot2.x 写的一些示例程序，目前正在持续更新中.....,devtools filter freemarker interceptor jsp jwt mybatis rabbitmq redis servlet spirng-data-jpa spring-boot spring-session springboot springboot2 swagger thymeleaf webflux websockets weixin,"SpringBoot2.x 个人学习示例程序
=========================

![Spring Boot 2.0](https://img.shields.io/badge/Spring%20Boot-2.0-brightgreen.svg)
![JDK 1.8](https://img.shields.io/badge/JDK-1.8-brightgreen.svg)
![Maven](https://img.shields.io/badge/Maven-3.5.0-yellowgreen.svg)
![license](https://img.shields.io/badge/license-apache%202.0-blue.svg)

个人学习 **SpringBoot2.x** 写的一些示例程序，每个文件夹模块存放对应的示例程序代码。

在学习前首先要确保一下你本地是否配置了 JDK 和 Maven 的基础环境。

- Maven 必须是3.2及以上版本，

- JDK 必须是1.8 或更高。

如下所示 基础应用篇，高级应用篇，原理应用篇 列表说明：

- 第一个是：示例教程博客教程

- 第二个是：示例教程具体代码 Mavne 模块 （可以单独部署）

**SpringBoot版本：** 2.1.0.RELEASE

---

## SpringBoot2.x 基础应用篇

- [玩转SpringBoot 2 快速搭建 | Spring Initializr 篇](https://mp.weixin.qq.com/s/spbtRZVYzDips437o9oYvA)  **spring-boot-2.x-start** 

- [玩转 SpringBoot 2 快速搭建 | IntellJ IDEA篇](https://mp.weixin.qq.com/s/Z5vebfI7dPP75-1bE_JVzA)  **spring-boot-2.x-start**  

- [玩转 SpringBoot 2 快速搭建 | SpringToolSuite 篇](https://mp.weixin.qq.com/s/OpBxjMgrOkOvccn718YStA)  **spring-boot-2.x-start** 

- [玩转 Springboot 2 | 不使用 parent 方式创建SpringBoot项目篇](https://zhuoqianmingyue.blog.csdn.net/article/details/88093042)

- [玩转SpringBoot 2 之项目启动篇](https://mp.weixin.qq.com/s/gVkdcWP8RpJaLkOQF23JzQ)  **spring-boot-2.x-start**  

- [玩转 SpringBoot 2 之热部署DevTools](https://mp.weixin.qq.com/s/hJeh_YDiqZjHVJoDBa2oYQ)  **spring-boot-2.x-start**  

- [玩转 SpringBoot 2 快速搭建 | RESTful Api 篇](https://mp.weixin.qq.com/s/d2aB7t0NyIDVlQb4VKZciQ)  **spring-boot-2.x-restful-api**  

- [玩转 SpringBoot 2 快速整合 | 丝袜哥(Swagger)](https://mp.weixin.qq.com/s/X6KaClQRZbFn5-UcgxbqGQ)  **spring-boot-2.x-swagger** 

- [玩转 SpringBoot 2 快速整合 Filter](https://mp.weixin.qq.com/s/WtZ63iDwXh2L5qxhGyWESg)  **spring-boot-2.x_filter** 

- [玩转 SpringBoot 2 快速整合 Filter 注解版](https://mp.weixin.qq.com/s/MiuKREMyboVzcBDAYr9XNg)  **spring-boot-2.x-annotation-filter** 

- [玩转 SpringBoot 2快速整合拦截器](https://mp.weixin.qq.com/s/IkNHvjRV7lMlShFYasC9yw)  **spring-boot-2.x-interceptor** 

- [玩转 SpringBoot 2 快速整合 | Hibernate Validator数据校验](https://mp.weixin.qq.com/s/MUzj_Yg7X6JqGsDHE2MaXQ)  **spring-boot-2.x-restful-api**

- [玩转 SpringBoot 2 快速整合 Servlet](https://mp.weixin.qq.com/s/3Pe4hiCbrmvBDG3kFcnX7A)  **spring-boot-2.x-servlet** 

- [玩转 SpringBoot 2 快速整合 Listener](https://mp.weixin.qq.com/s/8NSHNpyN1PfOWoZUFmTy6g)  **spring-boot-2.x-listener** 

- [玩转 SpringBoot 2 快速整合 | 统一异常处理](https://mp.weixin.qq.com/s/3cfb3djYRo15KlavkV7tpw)  **spring-boot-2.x-unified_anomaly**  

- [玩转 SpringBoot 2 快速整合 | FreeMarker篇](https://mp.weixin.qq.com/s/dAa_KZvVEV2wK40L7WdH4g)  **spring-boot-2.x-freemarker**   

- [玩转 SpringBoot 2 快速整合 | JSP 篇](https://mp.weixin.qq.com/s/EbysDIkDKZ9OzMN_b7_uNQ)  **spring-boot-2.x-jsp**  

-  [玩转 SpringBoot 2 快速整合 | Thymeleaf 篇](https://mp.weixin.qq.com/s/O53FKyrWTDPqFhHEvdDCoQ)  **spring-boot-2.x-thymeleaf**   

- [史上最详 Thymeleaf 使用教程](https://mp.weixin.qq.com/s/7FLO1ChRf18QU-w9ILzeAw)  **spring-boot-2.x-thymeleaf**   

- [玩转 SpringBoot 2 之整合 JWT 上篇](https://mp.weixin.qq.com/s/WlwkTtn3xD6izXkkk5MjCQ)  **spring-boot-2.x-jwt**   

- [玩转 SpringBoot 2 之整合 JWT 下篇](https://mp.weixin.qq.com/s/kUiZ1PcBCr1shoOg_-hmvA)  **spring-boot-2.x-jwt**  

- [玩转SpringBoot 2之整合WebSocket篇](https://mp.weixin.qq.com/s/ZzgUerD1KTkQ-MCpPy2hGA)  **spring-boot-2.x_websocket**    

- [玩转 SpringBoot 2 之发送邮件篇](https://mp.weixin.qq.com/s/BxExlZztSbnuPi0Tem-cPQ)  **spring-boot-2.x_mail**   

- [玩转 SpringBoot 2 之整合定时任务篇](https://mp.weixin.qq.com/s/KYxh1g8LMY0TVdof08BlmA)  **spring-boot-2.x_task**   

- [玩转 SpringBoot 2.x 之使用 SpringDataJpa 篇](https://mp.weixin.qq.com/s/MVSY8cryvXIpCV1NTqWuFw)  **spring-boot-2.x-spring-data-jpa**  

- [玩转 SpringBoot 2.x 整合 Mybatis](https://mp.weixin.qq.com/s/98Lcc5mSD4xIl3fm69mIpQ)  **spring-boot-2.x-mybaties**  

- [玩转SpringBoot2.x 整合Druid(Mybatis版)](https://mp.weixin.qq.com/s/2zSRQT2LWOCAI1zADFcHwQ)  **spring-boot-2.x-mybaties**  

- [玩转 SpringBoot 2.x 之自定义Starter依赖](https://mp.weixin.qq.com/s/C6nP__BZ6NZkGpEW3h4F1w) **spring-boot-start-httpclient** **springboot-2.x-httpclient-custom-starter** 

- [SpringBoot 2 使用异步调用@Async](https://zhuoqianmingyue.blog.csdn.net/article/details/87989647)

- [SpringBoot 2 使用SpringBoot Admin 监控](https://zhuoqianmingyue.blog.csdn.net/article/details/82785269) 

- [SpringBoot 2 多数据源操作 MyBatis + Durid版](https://mp.weixin.qq.com/s/KbeMwk65nWt-qYmlZ7vR_g) **spring-boot-2.x-mybaties-multipleDataSource** 



- 未完待续...
## SpringBoot2.x 高级应用篇
- [SpringBoot 2 使用Spring WebFlux之HelloWord教程](https://github.com/zhuoqianmingyue/springbootexamples/wiki/SpringBoot2.0%E4%BD%BF%E7%94%A8Spring-WebFlux%E4%B9%8BHelloWord%E6%95%99%E7%A8%8B)  **lesson16_spring_webflux**  
- [Spring Boot 2 快速教程：WebFlux 快速入门（二）转载自泥瓦匠BYSocket](https://github.com/zhuoqianmingyue/springbootexamples/blob/master/doc/webflux/Spring%20Boot%202%20%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B%EF%BC%9AWebFlux%20%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89.md)
- [Spring Boot 2 快速教程：WebFlux Restful CRUD 实践（三）转载自泥瓦匠BYSocket ](https://github.com/zhuoqianmingyue/springbootexamples/blob/master/doc/webflux/Spring%20Boot%202%20%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B%EF%BC%9AWebFlux%20Restful%20CRUD%20%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%B8%89%EF%BC%89.md)
- [Spring Boot 2 快速教程：WebFlux 集成 Mongodb（四）转载自泥瓦匠BYSocket ](https://github.com/zhuoqianmingyue/springbootexamples/blob/master/doc/webflux/Spring%20Boot%202%20%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B%EF%BC%9AWebFlux%20%E9%9B%86%E6%88%90%20Mongodb%EF%BC%88%E5%9B%9B%EF%BC%89.md)
- [Spring Boot 2 快速教程：WebFlux 集成 Thymeleaf（五）转载自泥瓦匠BYSocket ](https://github.com/zhuoqianmingyue/springbootexamples/blob/master/doc/webflux/Spring%20Boot%202%20%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B%EF%BC%9AWebFlux%20%E9%9B%86%E6%88%90%20Thymeleaf%EF%BC%88%E4%BA%94%EF%BC%89.md)
- [Spring Boot 2 快速教程：WebFlux 集成 Thymeleaf 、 Mongodb 实践（六）转载自泥瓦匠BYSocket ](https://github.com/zhuoqianmingyue/springbootexamples/blob/master/doc/webflux/Spring%20Boot%202%20%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B%EF%BC%9AWebFlux%20%E9%9B%86%E6%88%90%20Thymeleaf%20%E3%80%81%20Mongodb%20%E5%AE%9E%E8%B7%B5%EF%BC%88%E5%85%AD%EF%BC%89.md)
- [SpringBoot 2 快速集成 Jedis客户端 连接 redis 服务](https://zhuoqianmingyue.blog.csdn.net/article/details/93303627)  **spring-boot-2.x-redis** 
- [SpringBoot 2 整合 SpringSession 最简操作](https://blog.csdn.net/ljk126wy/article/details/93971421)  **spring-boot-2.x-spring-session-1** **spring-boot-2.x-spring-session-2**   
- [SpringBoot 2 快速整合 RabbitMQ](https://blog.csdn.net/ljk126wy/article/details/97543094)  **spring-boot-2.x-rabbit-mq**  

- [SpringBoot 2 集成微信扫码支付](https://zhuoqianmingyue.blog.csdn.net/article/details/99554766)  **spring-boot-2.x-wxpay** 

- [SpringBoot中获取微信用户信息竟然这么简单！](https://mp.weixin.qq.com/s/MFw9dWLAbEwO-giBu9rPVA)  **spring-boot-2.x-weixin** 

- [JS-SDK自定义微信分享（SpringBoot版）](https://zhuoqianmingyue.blog.csdn.net/article/details/100714362)  **spring-boot-2.x-weixin** 

- [通过Docker 启动SpringBoot 项目](https://blog.csdn.net/ljk126wy/article/details/104275624)  



- 未完待续...
## SpringBoot2.x 原理应用篇
- [不会部署并调试SpringBoot源码？一看必会IDEA操作](https://mp.weixin.qq.com/s/XY3p1kMrZ0UqdSqjXN4ytA)

- [SpringBoot 2之自定义 Banner 日志输出篇](https://zhuoqianmingyue.blog.csdn.net/article/details/83109152)

- [SpringBoot 2.x 解析BeanPostProcessor原理篇](https://blog.csdn.net/ljk126wy/article/details/83305455)

目前正在维护中... 尽请期待


<div align=center><img src=""https://img-blog.csdnimg.cn/20191005233835434.png""  /></div>
"
frandorado/spring-projects,master,143,130,2018-10-23T15:22:44Z,197,4,Spring examples,java spring spring-boot spring-mvc,"# Spring projects

* `Mar 20` **Spring Actuator (Micrometer) Undertow** Undertow metrics with Spring Actuator [Link to the project](https://github.com/frandorado/spring-projects/tree/master/spring-micrometer-undertow) and [Link to the blog](https://frandorado.github.io/spring/2020/03/31/spring-actuator-undertow.html) 

* `Feb 20` **Custom deserialization in Spring** Custom deserialization using Jackson [Link to the project](https://github.com/frandorado/spring-projects/tree/master/spring-custom-serializer-deserializer) and [Link to the blog](https://frandorado.github.io/spring/2020/02/14/spring-custom-json-transforms.html) 

* `Sep 19` **Spring Batch AWS Integration** Integration of Spring Batch with AWS SQS for remote chunking and partitioning. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/spring-batch-aws-integration) and [Link to the blog](https://frandorado.github.io/spring/2019/07/29/spring-batch-aws-series-introduction.html) 

* `Jun 19` **Reactive vs Non-Reactive Spring Performance** Comparation of performance between Spring MVC and Spring WebFlux. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/spring-reactive-nonreactive) and [Link to the blog](https://frandorado.github.io/spring/2019/06/26/spring-reactive-vs-non-reactive-performance.html)
 
* `Apr 19` **Spring Data Mongo using Mongo Cluster** Spring Data Mongo using a configured Cluster with Docker. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/spring-data-mongo-with-cluster) and [Link to the blog](https://frandorado.github.io/spring/2019/04/16/mongo-cluster-with-spring-data-mongo.html)

* `Jan 19` **Circuit Breaker with Resilience4j and Spring** Example of Circuit Breaker in Spring using Reslience4j library. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/resilience4j-spring) and [Link to the blog](https://frandorado.github.io/spring/2019/01/04/circuitbreaker-resilience4j-spring.html)

* `Dec 18` **AsyncRestTemplate returns 404 (Site Not Found) with Apache factory** Spring Boot Web Application where we change the default implementation of Spring's factory for AsyncRestTemplate with the Apache's factory and the error 404 found. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/async-rest-template-apache) and [Link to the blog](https://frandorado.github.io/spring/2018/12/17/asyncresttemplate-apache-404.html)

* `Nov 18` **Logging of Requests and Responses in Spring (including body)** Spring Boot Web Application where we trace in logs the request and the response including the body. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/log-request-response-with-body) and [Link to the blog](https://frandorado.github.io/spring/2018/11/15/log-request-response-with-body-spring.html)

* `Nov 18` **Logging of Requests and Responses in Spring with Undertow (no body)** Spring Boot Web Application where we configure Undertow as embedded server and enable RequestDumpingHandler to log requests and responses. [Link to the project](https://github.com/frandorado/spring-projects/tree/master/log-request-response-undertow) and [Link to the blog](https://frandorado.github.io/spring/2018/11/04/log-request-response-with-undertow-spring.html)
"
kylinsoong/drools-examples,master,151,99,2012-07-16T07:18:48Z,13504,1,Drools 中文文档,,
asciidoctor/asciidoctor-gradle-examples,master,146,136,2015-02-19T22:03:14Z,2221,21,A collection of example projects that demonstrates how to use the Asciidoctor Gradle plugin,,
vladmihalcea/high-performance-java-persistence,master,1248,479,2015-10-15T04:57:57Z,4248,5,The High-Performance Java Persistence book and video course code examples,,"# High-Performance Java Persistence

The [High-Performance Java Persistence](https://vladmihalcea.com/books/high-performance-java-persistence?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp) book and video course code examples. I wrote [this article](https://vladmihalcea.com/high-performance-java-persistence-github-repository/) about this repository since it's one of the best way to test JDBC, JPA, Hibernate or even jOOQ code. Or, if you prefer videos, you can watch [this presentation on YouTube](https://www.youtube.com/watch?v=U8MoOe8uMYA).

### Are you struggling with application performance issues?

<a href=""https://vladmihalcea.com/hypersistence-optimizer/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp"">
<img src=""https://vladmihalcea.com/wp-content/uploads/2019/03/Hypersistence-Optimizer-300x250.jpg"" alt=""Hypersistence Optimizer"">
</a>

Imagine having a tool that can automatically detect if you are using JPA and Hibernate properly. No more performance issues, no more having to spend countless hours trying to figure out why your application is barely crawling.

Imagine discovering early during the development cycle that you are using suboptimal mappings and entity relationships or that you are missing performance-related settings. 

More, with Hypersistence Optimizer, you can detect all such issues during testing and make sure you don't deploy to production a change that will affect data access layer performance.

[Hypersistence Optimizer](https://vladmihalcea.com/hypersistence-optimizer/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp) is the tool you've been long waiting for!

#### Training

If you are interested in on-site training, I can offer you my [High-Performance Java Persistence training](https://vladmihalcea.com/trainings/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp)
which can be adapted to one, two or three days of sessions. For more details, check out [my website](https://vladmihalcea.com/trainings/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp).

#### Consulting

If you want me to review your application and provide insight into how you can optimize it to run faster, 
then check out my [consulting page](https://vladmihalcea.com/consulting/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp).

#### High-Performance Java Persistence Video Courses

If you want the fastest way to learn how to speed up a Java database application, then you should definitely enroll in [my High-Performance Java Persistence video courses](https://vladmihalcea.com/courses/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp).

#### High-Performance Java Persistence Book

Or, if you prefer reading books, you are going to love my [High-Performance Java Persistence book](https://vladmihalcea.com/books/high-performance-java-persistence?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp) as well.

<a href=""https://vladmihalcea.com/books/high-performance-java-persistence?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp"">
<img src=""https://i0.wp.com/vladmihalcea.com/wp-content/uploads/2018/01/HPJP_h200.jpg"" alt=""High-Performance Java Persistence book"">
</a>

<a href=""https://vladmihalcea.com/courses?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp"">
<img src=""https://i0.wp.com/vladmihalcea.com/wp-content/uploads/2018/01/HPJP_Video_Vertical_h200.jpg"" alt=""High-Performance Java Persistence video course"">
</a>

## Java

All examples require at least Java 17 because of the awesome [Text Blocks](https://openjdk.java.net/jeps/355) feature, which makes JPQL and SQL queries so much readable.

## Maven

You need to use Maven 3.6.2 or newer to build the project.

## IntelliJ IDEA

On IntelliJ IDEA, the project runs just fine. You will have to make sure to select Java 17 or newer.

## Database setup

The project uses various database systems for integration testing, and you can configure the JDBC connection settings using the
`DatasourceProvider` instances (e.g., `PostgreSQLDataSourceProvider`).

By default, without configuring any database explicitly, HSQLDB is used for testing.

However, since some integration tests are designed to work on specific relational databases, we will need to have those databases started prior to running those tests.

Therefore, when running a DB-specific test, this GitHub repository will execute the following steps:

1. First, the test will try to find whether there's a local RDBMS it can use to run the test.
2. If no local database is found, the integration tests will use Testcontainers to bootstrap a Docker container
with the required *Oracle*, *SQL Server*, *PostgreSQL*, *MySQL*, *MariaDB*, *YugabyteDB*, or *CockroachDB* instance on demand.
   
> While you don't need to install any database manually on your local OS, this is recommended since your tests will run much faster than if they used Testcontainers.

### Manual Database configuration

- PostgreSQL

    You can install PostgreSQL, and the password for the `postgres` user should be `admin`.

    Now you need to create a `high_performance_java_persistence` database.
    
- Oracle

    You need to download and install Oracle XE

    Set the `sys` password to `admin`

    Connect to Oracle using the ""sys as sysdba"" user and create a new user:
    
        alter session set ""_ORACLE_SCRIPT""=true;

        create user oracle identified by admin default tablespace users;

        grant dba to oracle;

        alter system set processes=1000 scope=spfile;

        alter system set sessions=1000 scope=spfile;
        
        ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED;

    Open the `C:\app\${user.name}\product\21c\homes\OraDB21Home1\network\admin` folder where `${user.name}` is your current Windows username.
  
    Locate the `tnsnames.ora` and `listener.ora` files and change the port from `1522` to `1521` if that's the case. If you made these modifications,
    you need to restart the `OracleOraDB21Home1TNSListener` and `OracleServiceXE` Windows services.
  
- MySQL

    You should install MySQL 8, and the password for the `mysql` user should be `admin`.

    Now, you need to create a `high_performance_java_persistence` schema

    Besides having all privileges on this schema, the `mysql` user also requires select permission on `mysql.PROC`.
    
    If you don't have a `mysql` user created at database installation time, you can create one as follows:
    
    ````
    CREATE USER 'mysql'@'localhost';
    
    SET PASSWORD for 'mysql'@'localhost'='admin';
    
    GRANT ALL PRIVILEGES ON high_performance_java_persistence.* TO 'mysql'@'localhost';
    
    GRANT SELECT ON mysql.* TO 'mysql'@'localhost';
    
    FLUSH PRIVILEGES;
    ````

- SQL Server

    You can install SQL Server Express Edition with Tools. Choose mixed mode authentication and set the `sa` user password to `adm1n`.

    Open SQL Server Configuration Manager -> SQL Server Network Configuration and enable Named Pipes and TCP
    
    In the right pane of the TCP/IP option, choose Properties, then IP Addresses and make sure you Enable all listed IP addresses.
    You need to blank the dynamic TCP port value and configure the static TCP port 1433 for all IPs.
        
    Open SQL Server Management Studio and create the `high_performance_java_persistence` database
    
## Maven

> To build the project, don't use *install* or *package*. Instead, just compile test classes like this:
>
>    mvnw clean test-compile
    
Or you can just run the `build.bat` or `build.sh` scripts which run the above Maven command.
    
Afterward, just pick one test from the IDE and run it individually.

> Don't you run all tests at once (e.g. `mvn clean test`) because the test suite will take a very long time to complete.
>
> So, run the test you are interested in individually.

Enjoy learning more about Java Persistence, Hibernate, and database systems!
"
eventuate-examples/eventuate-examples-java-customers-and-orders,master,387,207,2016-06-23T22:35:10Z,409,18,Java version of the Customers and Orders event sourcing example from my presentations,,"This is the Java version of the customers and orders example that I've used in numerous presentations
on developing microservices with event sourcing and CQRS.
The code is built using the Eventuate platform.
It illustrates how to implement an eventually consistent credit limit check using event sourcing.
For more information, see this [presentation from Gluecon 2016](http://www.slideshare.net/chris.e.richardson/a-pattern-language-for-microservices-gluecon-2016/24)

# About Eventuate&trade;

![](http://eventuate.io/i/logo.gif)

The application is built using [Eventuate](http://eventuate.io/), which is an application platform for writing transactional microservices.
It provides a simple yet powerful event-driven programming model that is based on event sourcing and Command Query Responsibility Segregation (CQRS).
Eventuate solves the distributed data management problems inherent in a microservice architecture.
It consists of a scalable, distributed event store and client libraries for various languages and frameworks including Java, Scala, and the Spring framework.

# Building and running the application.

This is a Java 8, Gradle project. However, you do not need to install Gradle since it will be downloaded automatically. You just need to have Java 8 installed.


## Building and running using Eventuate Local

First, build the application:

```
./gradlew assemble
```

Next, you can launch the application using [Docker Compose](https://docs.docker.com/compose/)

Note:

If the containers aren't accessible via `localhost` - e.g. you are using Docker Toolbox, you will have to use `${DOCKER_HOST_IP}` instead of localhost.
See this http://eventuate.io/docs/usingdocker.html[guide to setting `DOCKER_HOST_IP`] for more information.

```
./gradlew <database-mode>ComposeBuild
./gradlew <database-mode>ComposeUp
```

Where `database-mode` is one of:

* `mysqlbinlog` - use MySQL with Binlog-based event publishing
* `postgreswal` - use Postgres with Postgres WAL-based event publishing
* `postgrespolling` - use Postgres with generic JDBC polling-based event publishing

Finally, you can use the Swagger UI provided by the services to create customers and orders, and view the order history:

* `http://localhost:8081/swagger-ui.html` - Create a customer
* `http://localhost:8083/swagger-ui.html` - Create an order
* `http://localhost:8082/swagger-ui.html` - View the customer and the order

(Hint: best to open these URLs in separate tabs)

The script `./show-urls.sh` will display the URLs.
"
mongodb/stitch-examples,master,138,95,2017-04-03T17:19:53Z,48443,12,MongoDB Stitch Examples,,"# MongoDB Stitch Examples

| Documentation                                                                                  |
| ---------------------------------------------------------------------------------------------- |
| [blog-comments-simple](https://docs.mongodb.com/stitch/getting-started/first-stitch-app/)      |
| [ToDo (Web)](https://docs.mongodb.com/stitch/getting-started/todo-web/)                        |
| [ToDo (Android)](https://docs.mongodb.com/stitch/getting-started/todo-android/)                |
| [ToDo (iOS)](https://docs.mongodb.com/stitch/getting-started/todo-ios/)                        |
| [Dashboard](https://docs.mongodb.com/stitch/getting-started/dashboard/)                        |
| [IoT Temperature Tracker](https://docs.mongodb.com/stitch/getting-started/temperature-tracker/)|

[![Join the chat at https://gitter.im/mongodb/stitch](https://badges.gitter.im/mongodb/stitch.svg)](https://gitter.im/mongodb/stitch?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)
"
ihuaylupo/manning-smia,master,308,391,2019-08-21T17:13:38Z,222,18,Spring Microservices in Action - Second Edition - Code Examples,,
eventuate-tram/eventuate-tram-sagas-examples-customers-and-orders,master,501,235,2017-11-29T05:01:56Z,1929,28,Spring Boot/JPA microservices that use an orchestration-based saga to maintain data consistency,,
jeffheaton/encog-java-examples,master,161,113,2011-06-23T17:45:10Z,23807,1,,,"[![Build Status](https://travis-ci.org/encog/encog-java-examples.svg)](https://travis-ci.org/encog/encog-java-examples)

Encog Examples 3.3

The following links will be helpful getting started with Encog.

Getting Started:

http://www.heatonresearch.com/wiki/Getting_Started

Important Links:

http://www.heatonresearch.com/encog
http://www.heatonresearch.com/wiki"
yidongnan/spring-cloud-netflix-example,master,805,374,2016-06-07T02:23:48Z,1097,5,spring-cloud-netflix-example is an example for microservices system,docker microservice rabbitmq spring-boot-admin spring-cloud-config spring-cloud-netflix spring-cloud-sleuth swagger zipkin,"# Spring Cloud Netflix Sample Application

<details>
<summary>Translations:</summary>

- [Chinese / 中文](README-zh.md)

</details>

spring-cloud-netflix-example is an example for microservices system.

It contains **configuration management, service discovery, circuit breakers, intelligent routing, distributed tracing, application monitor**.

The registry center uses the eureka, if you want to use consul, you can refer to https://github.com/yidongnan/spring-cloud-consul-example.

## Getting Started
```shell
./gradlew clean build -x test
./buildDockerImage.sh
docker-compose up -d
```

If you want to start more serve, you should use:
```shell
docker-compose scale service-a=2 service-b=3  
```

Start the basic service in the development environment:
```
docker-compose -f docker-compose-dev.yml up -d
```

## Technology List
* Spring Cloud Netflix
* Spring Cloud Sleuth
* Spring Cloud Config
* Spring Boot Admin
* Spring Boot
* ZipKin
* RabbitMQ
* Docker
* Swagger

## Architecture Overview
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Architecture.png"">

## Screenshots
### Api Route(Zuul)
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_001.png"">

### Eureka Dashboard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_002.png"">

### ZipKin Dashboard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_003.png"">

### ZipKin Trace Detail
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_004.png"">

### ZipKin Dependencies Overview
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_005.png"">

### Spring Boot Admin Dashboard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_006.png"">

### Spring Boot Admin Detail
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_007.png"">

### Spring Boot Admin Environment
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_008.png"">

### Spring Boot Admin Thread Dump
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_009.png"">

### Spring Boot Admin Trace
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_010.png"">

### Hystrix Dashboard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_011.png"">

### Hystrix Dashboard Detail
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-netflix-example/master/screenshots/Selection_012.png"">
"
jjohannes/understanding-gradle,main,243,35,2021-08-11T08:49:32Z,693,1,The Understanding Gradle video series introduces the concepts of the Gradle Build Tool one-by-one in short videos.,examples gradle tutorial,
knowledgefactory4u/KnowledgeFactory,master,157,97,2019-09-01T08:01:46Z,3371,2,Spring examples,actuator crud-application java jparepository kotlin mongodb mongodb-database mysql-database reactive-programming spring-boot springmvc-mybatis thymeleaf webflux,"# Spring Boot examples

# Local setup

Step 1: Download or clone the source code from GitHub to the local machine

Step 2:  ```mvn clean install```

Step 3:  ```mvn spring-boot:run``` or Run as Java Application


"
BruceEckel/AtomicKotlinExamples,master,300,79,2017-08-15T14:56:27Z,2550,7,"Examples auto-extracted from the book Atomic Kotlin.""""",kotlin kotlin-language kotlin-learning,"# Atomic Kotlin Examples

If you want to experiment with the code examples from the book [Atomic
Kotlin](https://www.AtomicKotlin.com), you're in the right place.

These examples are automatically extracted directly from the book. This repository
includes tests to verify that the code in the book is correct.

> **NOTE** If you are planning to solve the exercises after reading each atom
> (and you should), you can get the exercises AND all these examples together by
> installing [the educational course](https://www.atomickotlin.com/exercises/).
> If you're going to solve the exercises, you can just install the course and you
> don't need to install the examples from this repository.

## Contents
- [Introduction](#introduction)
- [Compiling and Running Programs in IntelliJ IDEA](#compiling-and-running-programs-in-intellij-idea)
- [Building From the Command Line: Quick Version](#building-from-the-command-line-quick-version)
- [Building From the Command Line: Detailed Instructions](#building-from-the-command-line-detailed-instructions)
  * [Install Java](#install-java)
    + [Windows](#windows)
    + [Macintosh](#macintosh)
    + [Linux](#linux)
  * [Verify Your Installation](#verify-your-installation)
  * [Installing and Running the Book Examples](#installing-and-running-the-book-examples)
- [Appendix A: Command-Line Basics](#appendix-a-command-line-basics)
  * [Editors](#editors)
  * [The Shell](#the-shell)
    + [Starting a Shell](#starting-a-shell)
    + [Directories](#directories)
    + [Basic Shell Operations](#basic-shell-operations)
    + [Unpacking a Zip Archive](#unpacking-a-zip-archive)
- [Appendix B: Command-Line Hello World](#appendix-b-command-line-hello-world)
  * [Packages](#packages)
- [Appendix C: The Kotlin REPL](#appendix-c-the-kotlin-repl)
  * [Install Kotlin](#install-kotlin)
  * [The REPL](#the-repl)
- [Appendix D: Testing](#appendix-d-testing)

# Introduction

The easiest way to access and experiment with the book examples is to
clone/download this repository and open it with IntelliJ IDEA. This is all that
most people need, and those people can ignore the rest of this README.

The remainder of this README shows you how to build and test the examples using
both IntelliJ IDEA and the command line.

Exercises and solutions for the book can be found at
[AtomicKotlin.com/exercises](https://www.atomickotlin.com/exercises).

**Note**: If any terminology or processes described here are still not clear to
you, you can usually find explanations or answers through
[Google](https://www.google.com/). For more specific issues or problems, try
[StackOverflow](http://stackoverflow.com/). Sometimes you can find installation
instructions on [YouTube](https://www.youtube.com/).

# Compiling and Running Programs in IntelliJ IDEA

The easiest and fastest way to start using the examples in this book is by
compiling and running them using IntelliJ IDEA:

1. Follow the instructions [here](https://www.jetbrains.com/help/idea/installation-guide.html)
to install IntelliJ IDEA.

2. Download the [zipped code
repository](https://github.com/BruceEckel/AtomicKotlinExamples/archive/master.zip)
and [unzip it](#unpacking-a-zip-archive).

3. Start IntelliJ IDEA and select the `File | Open` menu item. Navigate to
where you unzipped the repository and open the `build.gradle` file. You should
see a dialog box like this:

    ![](images/buildgradle.png)

    Select the `Open as Project` button.

4. If you don't see a `Project` window on the left side, go to the menu and select
`View | Tool Windows | Project` to turn it on.

5. You'll see an `Examples` folder. Click on it to open it, then navigate to
the `HelloWorld` folder and open that, then double-click on `HelloWorld.kt`.
You'll see something like this:

    ![](images/helloworld.png)

    Click on the green triangle in the gutter area to the left of `fun main() {`.
    It should look like this:

    ![](images/runhelloworld.png)

    Select the top one, the `Run` option, and IntelliJ IDEA will run your
    program and display the resulting output.

    **NOTE**: The first program you run will take awhile, because IntelliJ IDEA
    is building the entire project. Subsequent programs will start much more
    quickly.

6. If you don't already have a JDK (*Java Development Kit*) on your machine,
you will see error messages. A JDK is necessary to compile both Java and
Kotlin. You can [install one from within
IntelliJ](https://www.jetbrains.com/help/idea/sdk.html#jdk-from-ide). Once the
JDK is installed, IDEA will also be able to compile Kotlin.

# Building From the Command Line: Quick Version

Before you can run the examples from this repository, you must install the
current version of
[Java](http://www.oracle.com/technetwork/java/javase/downloads/index.html),
although some earlier versions should also work. (If you get any errors, try
upgrading to a more recent version of Java).

If you just want to download and check the code, [Download
Here](https://github.com/BruceEckel/AtomicKotlinExamples/archive/master.zip)
and [unzip it](#unpacking-a-zip-archive) into your destination directory. Open
a [shell/command window](#appendix-a-command-line-basics) and move into the
root of that directory. You'll know you are in the right directory if you see
the files `gradlew` and `gradlew.bat`.

You'll need an Internet connection the first time you compile the code,
because Gradle needs to first install itself, then all the support libraries.
Once these are installed you can perform additional compiling and running
offline.

On Mac/Linux, enter:

```
./gradlew test
```

(If you get a *Permission denied* error, run `chmod +x ./gradlew`)

On Windows, enter

```
gradlew test
```

If all goes well, the tests will run. Everything should complete without errors.

All the book examples are in the subdirectory `Examples` in subdirectories
corresponding to the atom names.

To compile and run examples using the Kotlin command-line tools, see
[Command-Line Hello World](#appendix-b-command-line-hello-world).

# Building From the Command Line: Detailed Instructions

If you are not familiar with the command line, first read [Command-Line
Basics](#appendix-a-command-line-basics).

## Install Java

Kotlin runs on top of Java, so you must first install the *Java Development Kit* (JDK).

### Windows

1. Follow the instructions to [install Chocolatey](https://chocolatey.org/).

2. At a [shell prompt](#appendix-a-command-line-basics), type: `choco install
jdk8` (you may also select a more recent version, like `jdk11`). The
installation process takes some time, but when it's finished Java is installed
and the necessary environment variables are set.

### Macintosh

The Mac comes with a much older version of Java that won't work for the
examples in this book, so you'll need to update it to (at least) Java 8.

  1.  Follow the instructions at this link to [Install HomeBrew](http://brew.sh/)

  2.  At a [shell prompt](#appendix-a-command-line-basics), first type
      `brew update`. When that completes, enter `brew cask install java`.

**NOTE:** Sometimes the default version of Java that you get with the above
installation will be too recent and not validated by the Mac's security
system. If this happens you'll either need to turn off the security by hand
or install an earlier version of Java. For either choice, you'll need to Google
for answers on how to solve the problem (often the easiest approach is to just
search for the error message produced by the Mac).

### Linux

Use the standard package installer with the following [shell commands](#appendix-a-command-line-basics):

*Ubuntu/Debian*:

  1. `sudo apt-get update`

  2. `sudo apt-get install default-jdk`

*Fedora/Redhat*:

```
su -c ""yum install java-1.8.0-openjdk""
```

## Verify Your Installation

[Open a new shell](#appendix-a-command-line-basics) and type:

```
java -version
```

You should see something like the following (Version numbers and actual text
will vary):

```
openjdk version ""11"" 2018-09-25
OpenJDK Runtime Environment 18.9 (build 11+28)
OpenJDK 64-Bit Server VM 18.9 (build 11+28, mixed mode)
```

If you see a message that the command is not found or not recognized, review
the installation instructions. If you still can't get it to work, check
[StackOverflow](http://stackoverflow.com/search?q=installing+java).

## Installing and Running the Book Examples

Once you have Java installed, the process to install and run the book examples
is the same for all platforms:

1. Download the book examples from the
[GitHub Repository](https://github.com/BruceEckel/AtomicKotlinExamples/archive/master.zip).

2. [Unzip](#unpacking-a-zip-archive) the downloaded file into the directory of your choice.

3. Use the Windows Explorer, the Mac Finder, or Nautilus or equivalent on Linux
to browse to the directory where you uzipped `AtomicKotlinExamples`, and
[open a shell](#appendix-a-command-line-basics) there.

4. If you're in the right directory, you should see files named `gradlew` and
`gradlew.bat` in that directory, along with numerous other files and
directories. The directories correspond to the chapters in the book.

5. At the shell prompt, type `gradlew test` (Windows) or `./gradlew test`
(Mac/Linux).

The first time you do this, Gradle will install itself and numerous other
packages, so it will take some time. After everything is installed, subsequent
builds and runs will be much faster.

Note that you must be connected to the Internet the first time you run `gradlew`
so that Gradle can download the necessary packages.

# Appendix A: Command-Line Basics

Because it is possible for a ""dedicated beginner"" to learn programming from
this book, you may not have previously used your computer's command-line shell.
If you have, you can go directly to the
[installation instructions](#building-from-the-command-line-detailed-instructions).

## Editors

To create and modify Kotlin program files&mdash;the code listings shown in this
book&mdash;you need a program called an *editor*. You'll also need the editor to
make changes to your system configuration files, which is sometimes required
during installation.

Programming editors vary from heavyweight *Integrated Development Environments*
(IDEs, like Eclipse, NetBeans and IntelliJ IDEA) to more basic text
manipulation applications. If you already have an IDE and are comfortable with
it, feel free to use that for this book.

Numerous explanations in this book are specific to IntelliJ IDEA so if you
don't already have an IDE you might as well start with IDEA. There are many
other editors; these are a subculture unto themselves and people sometimes get
into heated arguments about their merits. If you find one you like better, it's
not too hard to change. The important thing is to choose one and get
comfortable with it.

## The Shell

If you haven't programmed before, you might be unfamiliar with your operating
system *shell* (also called the *command prompt* in Windows). The shell harkens
back to the early days of computing when everything happened by typing commands
and the computer responded by displaying responses&mdash;everything was text-based.

Although it can seem primitive in the age of graphical user interfaces, a shell
provides a surprising number of valuable features.

To learn more about your shell than we cover here, see
[Bash Shell](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) for Mac/Linux
or [Windows Shell](https://en.wikipedia.org/wiki/Windows_shell).

### Starting a Shell

**Mac**: Click on the *Spotlight* (the magnifying-glass icon in the upper-right
corner of the screen) and type ""terminal."" Click on the application that looks
like a little TV screen (you might also be able to hit ""Return""). This starts a
shell in your home directory.

**Windows**: First, start the Windows Explorer to navigate through your
directories:

- *Windows 7*: click the ""Start"" button in the lower left corner of the screen.
In the Start Menu search box area type ""explorer"" and then press the ""Enter""
key.

- *Windows 8*: click Windows+Q, type ""explorer"" and then press the ""Enter"" key.

- *Windows 10*: click Windows+E.

Once the Windows Explorer is running, move through the folders on your computer
by double-clicking on them with the mouse. Navigate to the desired folder. Now
click the file tab at the top left of the Explorer window and select ""Open
Windows Powershell."" This opens a shell in the destination directory.

**Linux**: To open a shell in your home directory:

- *Debian*: Press Alt+F2. In the dialog that pops up, type 'gnome-terminal'

- *Ubuntu*: Either right-click on the desktop and select 'Open Terminal', or
  press Ctrl+Alt+T

- *Redhat*: Right-click on the desktop and select 'Open Terminal'

- *Fedora*: Press Alt+F2. In the dialog that pops up, type 'gnome-terminal'


### Directories

*Directories* are one of the fundamental elements of a shell. Directories hold
files, as well as other directories. Think of a directory as a tree with
branches. If `books` is a directory on your system and it has two other
directories as branches, for example `math` and `art`, we say that you have a
directory `books` with two *subdirectories* `math` and `art`. We refer to them
as `books/math` and `books/art` since `books` is their *parent* directory.
Note that Windows uses backslashes rather than forward slashes to separate the
parts of a directory.

### Basic Shell Operations

The shell operations shown here are approximately identical across operating
systems. For the purposes of this book, here are the essential operations in a
shell:

-   **Change directory**: Use `cd` followed by the name of the
    directory where you want to move, or `cd ..` if you want to move
    up a directory. If you want to move to a different directory while
    remembering where you came from, use `pushd` followed by the different
    directory name. Then, to return to the previous directory, just say
    `popd`.

-   **Directory listing**: `ls` (`dir` in Windows) displays all the files and
    subdirectory names in the current directory. Use the wildcard `*` (asterisk) to
    narrow your search. For example, if you want to list all the files ending in
    "".kt,"" you say `ls *.kt` (Windows: `dir *.kt`). If you want to list the
    files starting with ""F"" and ending in "".kt,"" you say `ls F*.kt` (Windows:
    `dir F*.kt`).

-   **Create a directory**: use the `mkdir` (""make directory"") command
    (Windows: `md`), followed by the name of the directory you want to create.
    For example, `mkdir books` (Windows: `md books`).

-   **Remove a file**: Use `rm` (""remove"") followed by the name of the file
    you wish to remove (Windows: `del`). For example, `rm somefile.kt` (Windows:
    `del somefile.kt`).

-   **Remove a directory**: use the `rm -r` command to remove the files in
    the directory and the directory itself (Windows: `deltree`). For example,
    `rm -r books` (Windows: `deltree books`).

-   **Repeat a command**: The ""up arrow"" on all three operating
    systems moves through previous commands so you can edit and
    repeat them. On Mac/Linux, `!!` repeats the last command and
    `!n` repeats the nth command.

-   **Command history**: Use `history` in Mac/Linux or press the F7 key in Windows.
    This gives you a list of all the commands you've entered. Mac/Linux provides
    numbers to refer to when you want to repeat a command.

### Unpacking a Zip Archive

A file name ending with `.zip` is an archive containing other files in a
compressed format. Both Linux and Mac have command-line `unzip` utilities, and
it's possible to install a command-line `unzip` for Windows via the Internet.

However, in all three systems the graphical file browser (Windows Explorer, the
Mac Finder, or Nautilus or equivalent on Linux) will browse to the directory
containing your zip file. Then right-mouse-click on the file and select ""Open""
on the Mac, ""Extract Here"" on Linux, or ""Extract all ..."" on Windows.

# Appendix B: Command-Line Hello World

This appendix explains how to compile and run the program shown in the ""Hello
World"" atom in the book, using the latest version (1.5 or higher) of the
[Kotlin command-line compiler](http://kotlinlang.org/docs/tutorials/command-line.html).

Open up a console window in the `HelloWorld` directory, where you'll see
`HelloWorld.kt`, and type:

```
kotlinc HelloWorld.kt
```

`kotlinc` means ""Kotlin compiler."" The compiler is the program that takes
your program and turns it into something that will run; this process is
called *compiling*.

Assuming you've typed the code correctly, you should get back the console
prompt, with no other messages. If you get error messages, try to discover
where you've mis-typed the code, correct it and try again. Once you are
successful, you're ready to run the program.

There's one more thing: When you run `kotlinc`, the resulting program doesn't
have the same name as the source program. Instead, the compiler appends a `Kt`
to the name. To see it, run `ls` or `dir` on the `helloworld` subdirectory.
You'll see that the directory contains `HelloWorldKt.class`. What's important
is the part before the `.class`. This is the actual name of the program:
`HelloWorldKt`.

Now we can run the program:

```
kotlin HelloWorldKt
```

And you'll see the output on the console:

```
Hello, world!
```

## Packages

If the program is in a package, the package name is also required to run the
program. That is, if `Foo.kt` contains a `package` statement:

```
package bar
```

then you cannot simply say:

```
kotlin Foo
```

You'll get a message starting with `error: could not find or load`...

If you were to compile this program, you'd see there's a new subdirectory
called `bar`. The name of the subdirectory that appears when you run `kotlinc`
corresponds to the `package` name in the program that was compiled.

If the program is packaged under `bar`, we give the package name followed by a
""dot,"" then the program's name:

```
kotlin bar.FooKt
```

# Appendix C: The Kotlin REPL

The Kotlin interpreter is also called the REPL (for *Read-Evaluate-Print-
Loop*). To use this you must first install the
latest version (1.5 or higher) of the [Kotlin command-line
compiler](http://kotlinlang.org/docs/tutorials/command-line.html).

> NOTE: You do not need to install command-line Kotlin for the operations
> described previously in this README.

## Install Kotlin

In this book, we use Kotlin version 1.5, the latest available at the time. The
detailed installation instructions for the command-line compiler are available
at [The Kotlin Site](https://kotlinlang.org/docs/tutorials/command-line.html).

To check your installation, open a new shell and type:

```
kotlin -version
```

at the shell prompt. You'll see the version information for your Kotlin
installation.

## The REPL

To start the REPL, type `kotlinc` by itself on the command line. You should see
something like the following:

```
Welcome to Kotlin version 1.5 (JRE 1.8.0_144-b01)
Type :help for help, :quit for quit
>>>
```

The exact version numbers will vary depending on the versions of Kotlin
and Java you've installed, but make sure that you're running Kotlin 1.5
or greater.

The REPL gives you immediate interactive feedback, which is helpful for
experimentation. For example, you can do arithmetic:

```
>>> 42 * 11.3
474.6
```

Find out more by typing `:help` at the Kotlin prompt. To exit the REPL, type:

```
>>> :quit
```

To compile and run examples using the Kotlin command-line tools, see
[Command-Line Hello World](#appendix-b-command-line-hello-world).

# Appendix D: Testing

The test system is built in so that we (the authors) can verify the correctness
of what goes into the book.

You don't need to run the tests, but if you want to, you can just run `gradlew
test` (on Windows) or `./gradlew test` (Mac/Linux).

There are two steps in creating and running the tests, which you can run
separately if you want (again, just running the Gradle `test` command will
validate the code, so you don't need to do the following steps):

1. `gradlew GenerateTests` generates tests from the sources in this repository.
   It creates (or recreates) the file `TestExamples.java`. You normally don't need to run this; the
   `TestExamples.java` in the repository should be up to date.

2. `gradlew TestExamples` runs the tests in `TestExamples.java`.

Alternatively, `TestExamples.java` can be called as a regular **JUnit** test class.
"
meddle0x53/learning-rxjava,master,275,120,2015-03-05T10:11:03Z,430,1,Examples of using RxJava,,"# Learning Reactive Programming With Java 8 Example Runner
This project contains the examples of the 'Learning Reactive Programming With Java 8' book.

## Installing and running this program.
 * Of course you'll need Git :).
 * To run these examples you need Java 8, if you don't have it, navigate to Oracle's site and download/install it.
 * Now you can clone this project by running :
 
   ```
   git clone https://github.com/meddle0x53/learning-rxjava.git
   ```
   
 * Navigate to the root of the project (`cd learning-rxjava`) and run :
 
   ```
     ./gradlew build
   ```
   
 * This will download and install all the dependencies needed by the project and will compile it.
 * You can open the project with Eclipse and run the examples. You'll need the Gradle plugin for Eclipse.
 
### Running example from console

 ```bashgra
 ./gradlew execute -Pchapter=1 -Pexample=ReactiveSumV1
 ```
 
## Examples
Here are the descriptions of all the examples in the book.

#### 01. Iterator VS Observable
This example is used in the book in the 'Comparing the Iterator pattern and the RxJava Observable' of the first chapter.
It demonstrates the difference between RxJava's Observables and the Iterators, by iterating over a list of strings.
The `Observable.from` method is introduced here for the first time, as well as subscribing.

The example can be found here [ObservableVSIterator](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter01/ObservableVSIterator.java)

#### 02. Reactive Sum, version 1
This is example demonstrates a reactive sum, which is updated on change of any of its collectors. It is demonstrates
many of the features of RxJava, like Observers, Schedulers Observable transformations, filtering and combining.

The example can be found here [ReactiveSumV1](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter01/ReactiveSumV1.java)

#### 03. Introduction to the new syntax and semantics
Demonstrates creating and using lambdas, passing them to methods, that receive Functional Interfaces as parameters and references
to existing methods.

The example can be found here [Java8LambdasSyntaxIntroduction](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter02/Java8LambdasSyntaxIntroduction.java)

#### 04. Reactive Sum, version 2 (with lambdas)
Another implementation of the 'Reactive Sum', similar to the on of the first chapter, but it uses the new Java 8 syntax with lambdas.

The example can be found here [ReactiveSumV2](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter02/ReactiveSumV2.java)
 
#### 05. Pure and higher functions
Demonstrates pure and higher order functions. Applies higher order functions to other functions.

The example can be found here [PureAndHigherOrderFunctions](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter02/PureAndHigherOrderFunctions.java)

#### 06. Introduction to monads
Shows implementation and uses of a monad. The Optional monad.

The example can be found here [Monads](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter02/Monads.java)
 
#### 07. Observables and monads
Shows that Observables are not true monads. They are monad-like structures though and benefit from that.

The example can be found here [ObservablesAndMonads](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter02/ObservablesAndMonads.java)
 
#### 08. Creating Observables with Observable.from
A set of examples of using the Observable.from method for creating Observables from collections, arrays and Iterables.

The example can be found here [CreatingObservablesWithFrom](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/CreatingObservablesWithFrom.java)

#### 09. Using Observable.from with Future
Demonstrates creating Observables using the Observable.from(Future) method.

The example can be found here [CreatingObservablesWithFromFuture](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/CreatingObservablesWithFromFuture.java)

#### 10. Using the Observable.just method to create Observables
Demonstrates creating Observables using the Observable.just method.

The example can be found here [CreatingObservablesUsingJust](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/CreatingObservablesUsingJust.java)

#### 11. A few factory methods for creating Observables (Chapter 3, pages 43-46)
Demonstrates using Observable.interval, Observable.timer, Observable.error,
Observable.never, Observable.empty and Observable.range for Obsevable creation.

The example can be found here [CreatingObservablesUsingVariousFactoryMethods](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/CreatingObservablesUsingVariousFactoryMethods.java)

#### 12. Demonstration of the Observable.create method (Chapter 3, pages 46-50)
Demonstrates using Observable.create for creating custom Observables.
Contains unsubscribing and implementing unsubscribing logic in Observable.create.

The example can be found here [ObservableCreateExample](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/ObservableCreateExample.java)

#### 13. A ConnectableObservable demonstration (Chapter 3, pages 51-53)
Demonstration of ConnectableObservables and the methods realted to them - publish, refCount, share.

The example can be found here [UsingConnectableObservables](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/UsingConnectableObservables.java)

#### 14. Subjects demonstration (Chapter 3, pages 53-54)
Demonstrates using a Subject to subscribe to an Observables, propagating its notifications to multiple Subscribers.

The example can be found here [SubjectsDemonstration](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/SubjectsDemonstration.java)

#### 15. Reactive Sum, version 3 (with Subjects) (Chapter 3, pages 55-57)
The 'Reactive Sum' is implemented through reactive properties, which are in fact BehaviorSubjects.

The example can be found here [ReactiveSumV3](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter03/ReactiveSumV3.java)

#### 16. Examples of using Observable transformations (Chapter 4, pages 59-66)
Demonstration of using map, flatMap, flatMapIterable and switchMap.

The example can be found here [MappingExamples](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter04/MappingExamples.java)

#### 17. Working with files using flatMap (Chapter 4, pages 60-62)
Demonstration of using flatMap with an Observable created by directory stream,
reading all the files from it, using Observables.

The example can be found here [FlatMapAndFiles](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter04/FlatMapAndFiles.java)

#### 18. Demonstration of using the Observable#groupBy operator (Chapter 4, pages 67-69)
Demonstrates how the groupBy operator can be used.

The example can be found here [UsingGroupBy](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter04/UsingGroupBy.java)

#### 19. Demonstration of various transforming operators (Chapter 4, pages 69-71)
Demonstration of working with the cast, materialize, timestamp and timeInterval operators.

The example can be found here [VariousTransformationsDemonstration](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter04/VariousTransformationsDemonstration.java)

#### 20. Various examples of using filtering operators (Chapter 4, pages 71-75)
Demonstrates the filter, takeLast, last, takeLastBuffer, lastOrDefault,
skipLast, skip, first, elementAt, distinct, distinctUntilChanged and ofType operators.

The example can be found here [FilteringExamples](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter04/FilteringExamples.java)

#### 21. Demonstration of using Observable#scan and more (Chapter 4, pages 76-78)
Demonstrates the scan operator and contains an example of working with data using the majority of the operators learned through the chapter.

The example can be found here [ScanAndUsingMultipleOperators](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter04/ScanAndUsingMultipleOperators.java)

#### 22. Examples of combining Observables (Chapter 5, pages 82-88)
Demonstrates combining Observables using Observable.zip, Observable.merge and Observable.concat.

The example can be found here [CombiningObservables](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter05/CombiningObservables.java)

#### 23. Some examples of using conditionals (Chapter 5, pages 88-91)
Demonstration of using the Observable.amb, Observable.takeWhile, Observable.takeUntil,
Observable.skipUntil and Observable.defaultIfEmpty.

The example can be found here [Conditionals](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter05/Conditionals.java)

#### 24. Examples of handling errors (Chapter 5, pages 92-95)
A demonstrates working with Observable.onErrorReturn, Observable.onErrorResumeNext and Observable.onExceptionResumeNext
as well as retrying with Observable.retry and Observable.retryWhen.

The example can be found here [HandlingErrors](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter05/HandlingErrors.java)

#### 25. Example of doing HTTP requests and handling responses with Observables (Chapter 5, pages 95-99)
Using multiple Observable operators in order to handle and augment an HTTP response from Github.

The example can be found here [HttpRequestsExample](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter05/HttpRequestsExample.java)

#### 26. Observable.interval and Schedulers (Chapter 6, pages 103-105)
More information of Observable.interval and its default Scheduler. Contains an example of debugging information of the emitted items and the current Thread.

The example can be found here [IntervalAndSchedulers](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter06/IntervalAndSchedulers.java)

#### 27. Demonstration of the different Schedulers types (Chapter 6, pages 106-114)
A collection of examples of using the different Schedulers.

The example can be found here [SchedulersTypes](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter06/SchedulersTypes.java)

#### 28. A few examples of observeOn and subscribeOn (Chapter 6, pages 115-119)
Demonstrates using subscribeOn and observeOn with Schedulers and Observables.

The example can be found here [SubscribeOnAndObserveOn](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter06/SubscribeOnAndObserveOn.java)

#### 29. Demonstraton of parallelism (Chapter 6, pages 121-122)
Demonstrates parallelism by executing a number of requests in parallel.

The example can be found here [ParallelRequestsExample](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter06/ParallelRequestsExample.java)

#### 30. Examples demonstrating backpressure and buffering operators (Chapter 6, pages 122-127)
Demonstrates using the Observable#sample, Observable#buffer, Observable#window
Observable#throttleLast, Observable#debounce, Observable#onBackpressureDrop and
Observable#onBackpressureBuffer operators

The example can be found here [BackpressureExamples](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter06/BackpressureExamples.java)

#### 31. A demonstration of using Blocking Observables (Chapter 7, pages 133-136)
Examples of using BlockingObservable and their operators -
BlockingObservable#forEach, BlockingObservable#first, BlockingObservable#next,
BlockingObservable#last and BlockingObservable#single.
Includes examples of Observable#count and Observable#toList combined with the Observable#toBlocking operator.

The example can be found here [BlockingObservablesAndOperators](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter07/BlockingObservablesAndOperators.java)

#### 32. Unit test demonstrating different ways of testing Observables (Chapter 7, pages 131-133, 136-138)
Includes simple subscription test, test with BlockingObservable and test with TestSubscriber.

The example can be found here [SortedObservableTest](https://github.com/meddle0x53/learning-rxjava/blob/master/src/test/java/com/packtpub/reactive/chapter07/SortedObservableTest.java)

#### 33. Example of testing asynchronous Observables (Chapter 7, pages 139-140)
A unit test testing the custom reateObservable#interval method.

The example can be found here [CreateObservableIntervalTest](https://github.com/meddle0x53/learning-rxjava/blob/master/src/test/java/com/packtpub/reactive/chapter07/CreateObservableIntervalTest.java)

#### 34. Resource management demonstration (Chapter 8, pages 142-148)
Demonstration of custom resource management with Observable#using.

The example can be found here [ResourceManagement](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter08/ResourceManagement.java)

#### 35. Example of using Observable#lift for executing custom operators (Chapter 8, pages 148-152)
Demonstrates implementing values with indices using lift and the custom operator Indexed.

The example can be found here [Lift](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter08/Lift.java)

#### 36. Unit test for the Indexed operator (Chapter 8, pages 152-153)

The example can be found here [IndexedTest](https://github.com/meddle0x53/learning-rxjava/blob/master/src/test/java/com/packtpub/reactive/chapter08/IndexedTest.java)

#### 37. Demonstration of the Observable.compose operator (Chapter 8, pages 153)
Example of implementing a Transformer and passing it to Observable#compose.

The example can be found here [Compose](https://github.com/meddle0x53/learning-rxjava/blob/master/src/main/java/com/packtpub/reactive/chapter08/Compose.java)

#### 38. Unit test for the OddFilter Transformer. (Chapter 8, pages 154)

The example can be found here [OddFilterTest](https://github.com/meddle0x53/learning-rxjava/blob/master/src/test/java/com/packtpub/reactive/chapter08/OddFilterTest.java)
"
bitstorm/Wicket-tutorial-examples,master,113,115,2012-09-18T20:27:19Z,123314,2,Code examples for the offcial Wicket user guide,apache-wicket java web web-framework wicket wicket-tutorial,"Wicket-tutorial-examples
========================

This repository contains the example projects used in the [Wicket user guide](http://wicket.apache.org/learn/#guide).

## Building the project

The project is a multi-module Maven project. To compile it run 'mvn compile' from the root directory. To run the examples locally follows these steps:

* run 'mvn install' from the root directory
* go into project StarterExamples and run 'mvn jetty:run' or 'mvn tomcat:run'

To run a single example project you have to install first project BootstrapCommon ('mvn install'). Then go into the folder of the project you want to run, type 'mvn jetty:run' or 'mvn tomcat:run' and then point your browser to http://localhost:8080

## See the examples on line

The examples can be explored on line at [http://wicket-tutorial-examples.it:8080/](http://wicket-tutorial-examples.it:8080/) (courtesy of [Host.it](https://host.it/)). 

NOTE: examples are hosted on a free account, so you might need to wait few seconds before server responds.

## Contributing to this guide

If you want to contribute to the guide with corrections or new contents, you can find how to do it [here](http://wicket.apache.org/contribute/userguide.html).

## The author
My name is Andrea Del Bene and I'm a passionate enterprise web developer and an advocate of Apache Wicket. I started programming in Java since version 1.2 and I'm a strong supporter of open source technologies.
If you like this project and want to support me, you can offer me a beer :-) :

<p> <a href=""https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=RGHPTV2QDK8VN"" rel=""nofollow""><img src=""https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif""></a>  </p>
"
rathboma/hive-extension-examples,master,90,129,2013-08-03T18:23:12Z,158,4,Examples for extending hive,,"# Hive UDF Examples

This code accompanies [this article which walks through creating UDFs in Apache Hive][blog-post].

## Compile

```
mvn compile
```

## Test

```
mvn test
```

## Build
```
mvn assembly:single
```

## Run

```
%> hive
hive> ADD JAR /path/to/assembled.jar;
hive> create temporary function hello as 'com.matthewrathbone.example.SimpleUDFExample';
hive> select hello(firstname) from people limit 10;

```

[blog-post]:http://blog.matthewrathbone.com/2013/08/10/guide-to-writing-hive-udfs.html"
Nirman-Rathod/Spring,master,171,146,2013-10-28T13:46:47Z,1200,0,Spring Tutorials and Examples,,
powermock/powermock-examples-maven,master,111,114,2016-12-02T06:37:15Z,176,30,Examples of specific uses of PowerMock.,,"# PowerMock Examples.

[![Build Status](https://travis-ci.org/powermock/powermock-examples-maven.svg?branch=master)](https://travis-ci.org/powermock/powermock-examples-maven)

This project contains different examples of specific uses of PowerMock.
"
microservices-patterns/ftgo-application,master,3309,1277,2017-10-23T04:30:04Z,1144,96,Example code for the book Microservice patterns,,
CodelyTV/java-ddd-example,main,393,200,2019-08-20T11:07:25Z,550,18,♨️ DDD in Java skeleton & examples. Course:,codely codelytv cqrs cucumber cucumber-java ddd ddd-architecture ddd-cqrs ddd-example gradle hexagon java java-skeleton junit rabbitmq,"# ☕🚀 Java DDD example: Save the boilerplate in your new projects

<img src=""http://codely.tv/wp-content/uploads/2016/05/cropped-logo-codelyTV.png"" align=""left"" width=""192px"" height=""192px""/>
<img align=""left"" width=""0"" height=""192px"" hspace=""10""/>

> ⚡ Start your Java projects as fast as possible

[![CodelyTV](https://img.shields.io/badge/codely-tv-green.svg?style=flat-square)](https://codely.tv)
[![CI pipeline status](https://github.com/CodelyTV/java-ddd-example/workflows/CI/badge.svg)](https://github.com/CodelyTV/java-ddd-example/actions)

## ℹ️ Introduction

This is a repository intended to serve as a starting point if you want to bootstrap a Java project with JUnit and Gradle.

Here you have the [course on CodelyTV Pro where we explain step by step all this](https://pro.codely.tv/library/ddd-en-java/about/?utm_source=github&utm_medium=social&utm_campaign=readme) (Spanish)

## 🏁 How To Start

1. Install Java 11: `brew cask install corretto`
2. Set it as your default JVM: `export JAVA_HOME='/Library/Java/JavaVirtualMachines/amazon-corretto-11.jdk/Contents/Home'`
3. Clone this repository: `git clone https://github.com/CodelyTV/java-ddd-example`.
4. Bring up the Docker environment: `make up`.
5. Execute some [Gradle lifecycle tasks](https://docs.gradle.org/current/userguide/java_plugin.html#lifecycle_tasks) in order to check everything is OK:
    1. Create [the project JAR](https://docs.gradle.org/current/userguide/java_plugin.html#sec:jar): `make build`
    2. Run the tests and plugins verification tasks: `make test`
6. Start developing!

## ☝️ How to update dependencies

* Gradle ([releases](https://gradle.org/releases/)): `./gradlew wrapper --gradle-version=WANTED_VERSION --distribution-type=bin`

## 💡 Related repositories

### ☕ Java

* 📂 [Java Basic example](https://github.com/CodelyTV/java-basic-example)
* ⚛ [Java OOP Examples](https://github.com/CodelyTV/java-oop-examples)
* 🧱 [Java SOLID Examples](https://github.com/CodelyTV/java-solid-examples)
* 🥦 [Java DDD Example](https://github.com/CodelyTV/java-ddd-example)

### 🐘 PHP

* 📂 [PHP Basic example](https://github.com/CodelyTV/php-basic-example)
* 🎩 [PHP DDD example](https://github.com/CodelyTV/php-ddd-example)
* 🥦 [PHP DDD Example](https://github.com/CodelyTV/php-ddd-example)

### 🧬 Scala

* 📂 [Scala Basic example](https://github.com/CodelyTV/scala-basic-example)
* ⚡ [Scala Basic example (g8 template)](https://github.com/CodelyTV/scala-basic-example.g8)
* ⚛ [Scala Examples](https://github.com/CodelyTV/scala-examples)
* 🥦 [Scala DDD Example](https://github.com/CodelyTV/scala-ddd-example)
"
eventuate-examples/eventuate-examples-restaurant-management,master,210,108,2016-05-08T01:30:25Z,133,3,Event-driven microservices version of restaurant management from POJOs in Action,,"
# Restaurant management application

Food to Go is a fictitious, on-demand logistics company that delivers takeout orders from restaurants to customers.
A key part of the application is the restaurant management service, which maintains a database of restaurants that can be queried for availability to deliver an order to a customer at a particular time.
This version of the restaurant management service has an architecture based on microservices, event sourcing and Command Query Responsibility Segregation (CQRS).
It is written in Java and uses the Eventuate Platform, Spring Boot, and Redis.

Don't forget to take a look at the other [Eventuate example applications](http://eventuate.io/exampleapps.html).

# Got questions?

Don't hesitate to create an issue or see

* [Website](http://eventuate.io)
* [Mailing list](https://groups.google.com/d/forum/eventuate-users)
* [Slack](https://eventuate-users.slack.com). [Get invite](https://eventuateusersslack.herokuapp.com/)
* [Contact us](http://eventuate.io/contact.html).

# Architecture

The following diagram shows the architecture of the application.

<img class=""img-responsive"" src=""http://eventuate.io/demos/eventuate-restaurant-management-architecture.png"">

The application is built using CQRS.
The command side service handles creates, updates and deletes.
It defines the following REST endpoints:

* POST /restaurant - create a restaurant
* PUT /restaurant/*id* - update a restaurant
* DELETE /restaurant/*id* - delete a restaurant

The command side service stores restaurants in the Eventuate event store.

The query side service handles GET requests.
It subscribes to Restaurant events and maintains a denormalized representation of the restaurants in Redis for fast querying.
The query side service defines the following REST endpoints:

* GET /restaurant/*id* - finds a restaurant
* GET /availablerestaurants?zipcode=xx&dayOfWeek=xx&hour=xx&minute=xx - finds restaurants that are available to deliver to the specified zip code at the specified time

# About Eventuate&trade;

![](http://eventuate.io/i/logo.gif)

The application is built using [Eventuate](http://eventuate.io/), which is an application platform for writing transactional microservices.
It provides a simple yet powerful event-driven programming model that is based on event sourcing and Command Query Responsibility Segregation (CQRS).
Eventuate solves the distributed data management problems inherent in a microservice architecture.
It consists of a scalable, distributed event store and client libraries for various languages and frameworks including Java, Scala, and the Spring framework.

There are two versions of Eventuate:

* [Eventuate SaaS server](http://eventuate.io/usingeventuate.html) - this is a full featured event store that is hosted on AWS
* [Eventuate Local](http://eventuate.io/usingeventuate.html) - an open-source event store that is built using MySQL and Kafka

# Building and running the application.

This is a Java 8, Gradle project. However, you do not need to install Gradle since it will be downloaded automatically. You just need to have Java 8 installed.

The details of how to build and run the services depend slightly on whether you are using Eventuate SaaS or Eventuate Local.

## Building and running using Eventuate SaaS

First, must [sign up to get your credentials](https://signup.eventuate.io/) in order to get free access to the SaaS version.

Next, build the application:

```
./gradlew assemble
```

Next, you can launch the application using [Docker Compose](https://docs.docker.com/compose/)

```
docker-compose up -d
```

## Building and running using Eventuate Local

First, build the application:

```
./gradlew assemble -P eventuateDriver=local
```

Next, you can launch the application using [Docker Compose](https://docs.docker.com/compose/)

```
export DOCKER_HOST_IP=...
docker-compose -f docker-compose-eventuate-local.yml up -d
```

Note: You need to set `DOCKER_HOST_IP` before running Docker Compose.
`DOCKER_HOST_IP` is the IP address of the machine running the Docker daemon.
It must be an IP address or resolvable hostname.
It cannot be `localhost`.
See this [guide to setting `DOCKER_HOST_IP`](http://eventuate.io/docs/usingdocker.html) for more information.


## Using the application

Finally, you can use the Swagger UI provided by the services to create, update, delete and view restaurants:

* `http://${DOCKER_HOST_IP?}:8081/swagger-ui.html` - Restaurant command-side service
* `http://${DOCKER_HOST_IP?}:8082/swagger-ui.html` - Restaurant query-side service

Note: DOCKER_HOST_IP is the IP address of the machine running the Docker daemon.

(Hint: best to open these URLs in separate tabs)

# Got questions?

Don't hesitate to create an issue or see

* [Website](http://eventuate.io)
* [Mailing list](https://groups.google.com/d/forum/eventuate-users)
* [Slack](https://eventuate-users.slack.com). [Get invite](https://eventuateusersslack.herokuapp.com/)
* [Contact us](http://eventuate.io/contact.html).
"
OWASP/wrongsecrets,master,1114,261,2020-08-19T05:59:51Z,84462,39,Vulnerable app with examples showing how to not use secrets,aws azure ctf devsecops docker gcp hashicorp-vault java keepass kubernetes owasp secrets secrets-management security terraform-aws terraform-azure terraform-gcp vault vulnerable-web-app,"<!-- CRE Link: [223-780](https://www.opencre.org/cre/223-780?register=true&type=tool&tool_type=training&tags=secrets,training&description=With%20this%20app%2C%20we%20have%20packed%20various%20ways%20of%20how%20to%20not%20store%20your%20secrets.%20These%20can%20help%20you%20to%20realize%20whether%20your%20secret%20management%20is%20ok.%20The%20challenge%20is%20to%20find%20all%20the%20different%20secrets%20by%20means%20of%20various%20tools%20and%20techniques.%20Can%20you%20solve%20all%20the%2015%20challenges%3F) -->

# OWASP WrongSecrets

[![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Want%20to%20dive%20into%20secrets%20management%20and%20do%20some%20hunting?%20try%20this&url=https://github.com/OWASP/wrongsecrets&hashtags=secretsmanagement,secrets,hunting,p0wnableapp,OWASP,WrongSecrets) [<img src=""https://img.shields.io/badge/-MASTODON-%232B90D9?style=for-the-badge&logo=mastodon&logoColor=white"" width=84>](https://tootpick.org/#text=Want%20to%20dive%20into%20secrets%20management%20and%20do%20some%20hunting?%20try%20this%0A%0Ahttps://github.com/OWASP/wrongsecrets%20%23secretsmanagement,%20%23secrets,%20%23hunting,%20%23p0wnableapp,%20%23OWASP,%20%23WrongSecrets) [<img src=""https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white"" width=80>](https://www.linkedin.com/shareArticle/?url=https://www.github.com/OWASP/wrongsecrets&title=OWASP%20WrongSecrets)

[![Java checkstyle and testing](https://github.com/OWASP/wrongsecrets/actions/workflows/main.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/main.yml) [![Pre-commit](https://github.com/OWASP/wrongsecrets/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/pre-commit.yml) [![Terraform FMT](https://github.com/OWASP/wrongsecrets/actions/workflows/terraform.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/terraform.yml) [![CodeQL](https://github.com/OWASP/wrongsecrets/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/codeql-analysis.yml) [![Dead Link Checker](https://github.com/OWASP/wrongsecrets/actions/workflows/link_checker.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/link_checker.yml)[![Javadoc and Swaggerdoc generator](https://github.com/OWASP/wrongsecrets/actions/workflows/java_swagger_doc.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/java_swagger_doc.yml) [![Test Heroku with cypress](https://github.com/OWASP/wrongsecrets/actions/workflows/heroku_tests.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/heroku_tests.yml)

[![Test minikube script (k8s)](https://github.com/OWASP/wrongsecrets/actions/workflows/minikube-k8s-test.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/minikube-k8s-test.yml) [![Test minikube script (k8s&vault)](https://github.com/OWASP/wrongsecrets/actions/workflows/minikube-vault-test.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/minikube-vault-test.yml) [![Docker container test](https://github.com/OWASP/wrongsecrets/actions/workflows/container_test.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/container_test.yml)[![Test container on podman and Colima](https://github.com/OWASP/wrongsecrets/actions/workflows/container-alts-test.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/container-alts-test.yml)
[![DAST with ZAP](https://github.com/OWASP/wrongsecrets/actions/workflows/dast-zap-test.yml/badge.svg)](https://github.com/OWASP/wrongsecrets/actions/workflows/dast-zap-test.yml)

[![OWASP Production Project](https://img.shields.io/badge/OWASP-production%20project-48A646.svg)](https://owasp.org/projects/)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7024/badge)](https://bestpractices.coreinfrastructure.org/projects/7024)
[![Discussions](https://img.shields.io/github/discussions/OWASP/wrongsecrets)](https://github.com/OWASP/wrongsecrets/discussions)

Welcome to the OWASP WrongSecrets game! The game is packed with real life examples of how to _not_ store secrets in your software. Each of these examples is captured in a challenge, which you need to solve using various tools and techniques. Solving these challenges will help you recognize common mistakes & can help you to reflect on your own secrets management strategy.

Can you solve all the 46 challenges?

Try some of them on [our Heroku demo environment](https://wrongsecrets.herokuapp.com/).

Want to play the other challenges? Read the instructions on how to set them up below.

![screenshotOfChallenge1](/images/screenshot.png)

<a href=""https://github.com/vshymanskyy/StandWithUkraine/blob/main/README.md""><img src=""https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner2-no-action.svg"" /></a>

## Table of contents

-   [Support](#support)
-   [Basic docker exercises](#basic-docker-exercises)
    -   [Running these on Heroku](#running-these-on-heroku)
    -   [Running these on Render.io](#running-these-on-renderio)
    -   [Running these on Railway](#running-these-on-railway)
-   [Basic K8s exercise](#basic-k8s-exercise)
    -   [Minikube based](#minikube-based)
    -   [k8s based](#k8s-based)
    -   [Vault exercises with minikube](#vault-exercises-with-minikube)
-   [Cloud Challenges](#cloud-challenges)
    -   [Running WrongSecrets in AWS](#running-wrongsecrets-in-aws)
    -   [Running WrongSecrets in GCP](#running-wrongsecrets-in-gcp)
    -   [Running WrongSecrets in Azure](#running-wrongsecrets-in-azure)
    -   [Running Challenge15 in your own cloud only](#running-challenge15-in-your-own-cloud-only)
-   [Do you want to play without guidance?](#do-you-want-to-play-without-guidance-or-spoils)
-   [Special thanks & Contributors](#special-thanks--contributors)
-   [Sponsorships](#sponsorships)
-   [Help Wanted](#help-wanted)
-   [Use OWASP WrongSecrets as a secret detection benchmark](#use-owasp-wrongsecrets-as-a-secret-detection-benchmark)
-   [CTF](#ctf)
    -   [CTFD Support](#ctfd-support)
    -   [FBCTF Support](#fbctf-support-experimental)
-   [Notes on development](#notes-on-development)
    -   [Dependency management](#dependency-management)
    -   [Get the project started in IntelliJ IDEA](#get-the-project-started-in-intellij-idea)
    -   [Automatic reload during development](#automatic-reload-during-development)
    -   [How to add a Challenge](#how-to-add-a-challenge)
    -   [Local testing](#local-testing)
    -   [Local Automated testing](#Local-automated-testing)
-   [Want to play, but are not allowed to install the tools?](#want-to-play-but-are-not-allowed-to-install-the-tools)
-   [Want to disable challenges in your own release?](#want-to-disable-challenges-in-your-own-release)
-   [Further reading on secrets management](#further-reading-on-secrets-management)

## Support

Need support? Contact us
via [OWASP Slack](https://owasp.slack.com/archives/C02KQ7D9XHR) for which you sign up [here](https://owasp.org/slack/invite)
, file a [PR](https://github.com/OWASP/wrongsecrets/pulls), file
an [issue](https://github.com/OWASP/wrongsecrets/issues) , or
use [discussions](https://github.com/OWASP/wrongsecrets/discussions). Please note that this is an OWASP volunteer
based project, so it might take a little while before we respond.

Copyright (c) 2020-2024 Jeroen Willemsen and WrongSecrets contributors.

## Basic docker exercises

_Can be used for challenges 1-4, 8, 12-32, 34, 35-43_

For the basic docker exercises you currently require:

-   Docker [Install from here](https://docs.docker.com/get-docker/)
-   Some Browser that can render HTML

You can install it by doing:

```bash
docker run -p 8080:8080 jeroenwillemsen/wrongsecrets:latest-no-vault
```

Now you can try to find the secrets by means of solving the challenge offered at:

-   [localhost:8080/challenge/challenge-1](http://localhost:8080/challenge/challenge-1)
-   [localhost:8080/challenge/challenge-2](http://localhost:8080/challenge/challenge-2)
-   [localhost:8080/challenge/challenge-3](http://localhost:8080/challenge/challenge-3)
-   [localhost:8080/challenge/challenge-4](http://localhost:8080/challenge/challenge-4)
-   [localhost:8080/challenge/challenge-8](http://localhost:8080/challenge/challenge-8)
-   [localhost:8080/challenge/challenge-12](http://localhost:8080/challenge/challenge-12)
-   [localhost:8080/challenge/challenge-13](http://localhost:8080/challenge/challenge-13)
-   [localhost:8080/challenge/challenge-14](http://localhost:8080/challenge/challenge-14)
-   [localhost:8080/challenge/challenge-15](http://localhost:8080/challenge/challenge-15)
-   [localhost:8080/challenge/challenge-16](http://localhost:8080/challenge/challenge-16)
-   [localhost:8080/challenge/challenge-17](http://localhost:8080/challenge/challenge-17)
-   [localhost:8080/challenge/challenge-18](http://localhost:8080/challenge/challenge-18)
-   [localhost:8080/challenge/challenge-19](http://localhost:8080/challenge/challenge-19)
-   [localhost:8080/challenge/challenge-20](http://localhost:8080/challenge/challenge-20)
-   [localhost:8080/challenge/challenge-21](http://localhost:8080/challenge/challenge-21)
-   [localhost:8080/challenge/challenge-22](http://localhost:8080/challenge/challenge-22)
-   [localhost:8080/challenge/challenge-23](http://localhost:8080/challenge/challenge-23)
-   [localhost:8080/challenge/challenge-24](http://localhost:8080/challenge/challenge-24)
-   [localhost:8080/challenge/challenge-25](http://localhost:8080/challenge/challenge-25)
-   [localhost:8080/challenge/challenge-26](http://localhost:8080/challenge/challenge-26)
-   [localhost:8080/challenge/challenge-27](http://localhost:8080/challenge/challenge-27)
-   [localhost:8080/challenge/challenge-28](http://localhost:8080/challenge/challenge-28)
-   [localhost:8080/challenge/challenge-29](http://localhost:8080/challenge/challenge-29)
-   [localhost:8080/challenge/challenge-30](http://localhost:8080/challenge/challenge-30)
-   [localhost:8080/challenge/challenge-31](http://localhost:8080/challenge/challenge-31)
-   [localhost:8080/challenge/challenge-32](http://localhost:8080/challenge/challenge-32)
-   [localhost:8080/challenge/challenge-34](http://localhost:8080/challenge/challenge-34)
-   [localhost:8080/challenge/challenge-35](http://localhost:8080/challenge/challenge-35)
-   [localhost:8080/challenge/challenge-36](http://localhost:8080/challenge/challenge-36)
-   [localhost:8080/challenge/challenge-37](http://localhost:8080/challenge/challenge-37)
-   [localhost:8080/challenge/challenge-38](http://localhost:8080/challenge/challenge-38)
-   [localhost:8080/challenge/challenge-39](http://localhost:8080/challenge/challenge-39)
-   [localhost:8080/challenge/challenge-40](http://localhost:8080/challenge/challenge-40)
-   [localhost:8080/challenge/challenge-41](http://localhost:8080/challenge/challenge-41)
-   [localhost:8080/challenge/challenge-42](http://localhost:8080/challenge/challenge-42)
-   [localhost:8080/challenge/challenge-43](http://localhost:8080/challenge/challenge-43)

Note that these challenges are still very basic, and so are their explanations. Feel free to file a PR to make them look
better ;-).

### Running these on Heroku

You can test them out at [https://wrongsecrets.herokuapp.com/](https://wrongsecrets.herokuapp.com/) as well! The folks at Heroku have given us an awesome open source support package, which allows us to run the app for free there, where it is almost always up. Still, please do not fuzz and/or try to bring it down: you would be spoiling it for others that want to testdrive it.
Use [this link](https://wrongsecrets.herokuapp.com/) to use our hosted version of the app. If you want to host it on Heroku yourself (e.g., for running a training), you can do so by clicking [this link](https://heroku.com/deploy?template=https://github.com/OWASP/wrongsecrets/tree/master). Please be aware that this will incur costs for which this project and/or its maintainers cannot be held responsible.

### Running these on Render.io
*status: experimental*

You can test them out at [https://wrongsecrets.onrender.com/](https://wrongsecrets.onrender.com/). Please understand that we run on a free-tier instance, we cannot give any guarantees. Please do not fuzz and/or try to bring it down: you would be spoiling it for others that want to testdrive it.
Want to deploy yourself with Render? Click the button below:

[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy?repo=https://github.com/OWASP/wrongsecrets)


### Running these on Railway
*status: maintained by [alphasec.io](https://github.com/alphasecio)*

If you want to host WrongSecrets on Railway, you can do so by deploying [this one-click template](https://railway.app/new/template/7pnwRj). Railway does not offer an always-free plan anymore, but the free trial is good enough to test-drive this before you decide to upgrade. If you need a step-by-step companion guide, see [this blog post](https://alphasec.io/test-your-secret-management-skills-with-owasp-wrongsecrets/).

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/new/template/7pnwRj)

## Basic K8s exercise

_Can be used for challenges 1-6, 8, 12-43_

### Minikube based

Make sure you have the following installed:

-   Docker [Install from here](https://docs.docker.com/get-docker/)
-   Minikube [Install from here](https://minikube.sigs.k8s.io/docs/start/)

The K8S setup currently is based on using Minikube for local fun. You can use the commands below from the root of the project:

```bash
    minikube start
    kubectl apply -f k8s/secrets-config.yml
    kubectl apply -f k8s/secrets-secret.yml
    kubectl apply -f k8s/challenge33.yml
    kubectl apply -f k8s/secret-challenge-deployment.yml
    while [[ $(kubectl get pods -l app=secret-challenge -o 'jsonpath={..status.conditions[?(@.type==""Ready"")].status}') != ""True"" ]]; do echo ""waiting for secret-challenge"" && sleep 2; done
    kubectl expose deployment secret-challenge --type=LoadBalancer --port=8080
    minikube service secret-challenge
```

Alternatively you can do :

```bash
    ./k8s-vault-minkube-start.sh
```

now you can use the provided IP address and port to further play with the K8s variant (instead of localhost).

-   [localhost:8080/challenge/challenge-5](http://localhost:8080/challenge/challenge-5)
-   [localhost:8080/challenge/challenge-6](http://localhost:8080/challenge/challenge-6)
-   [localhost:8080/challenge/challenge-33](http://localhost:8080/challenge/challenge-33)

### k8s based

Want to run vanilla on your own k8s? Use the commands below:

```bash
    kubectl apply -f k8s/secrets-config.yml
    kubectl apply -f k8s/secrets-secret.yml
    kubectl apply -f k8s/challenge33.yml
    kubectl apply -f k8s/secret-challenge-deployment.yml
    while [[ $(kubectl get pods -l app=secret-challenge -o 'jsonpath={..status.conditions[?(@.type==""Ready"")].status}') != ""True"" ]]; do echo ""waiting for secret-challenge"" && sleep 2; done
    kubectl port-forward \
        $(kubectl get pod -l app=secret-challenge -o jsonpath=""{.items[0].metadata.name}"") \
        8080:8080
```

now you can use the provided IP address and port to further play with the K8s variant (instead of localhost).

-   [localhost:8080/challenge/challenge-5](http://localhost:8080/challenge/challenge-5)
-   [localhost:8080/challenge/challenge-6](http://localhost:8080/challenge/challenge-6)
-   [localhost:8080/challenge/challenge-33](http://localhost:8080/challenge/challenge-33)

## Vault exercises with minikube

_Can be used for challenges 1-8, 12-46_
Make sure you have the following installed:

-   minikube with docker (or comment out line 8 and work at your own k8s setup),
-   docker,
-   helm [Install from here](https://helm.sh/docs/intro/install/),
-   kubectl [Install from here](https://kubernetes.io/docs/tasks/tools/),
-   jq [Install from here](https://stedolan.github.io/jq/download/),
-   vault [Install from here](https://www.vaultproject.io/downloads),
-   grep, Cat, and Sed

Run `./k8s-vault-minkube-start.sh`, when the script is done, then the challenges will wait for you at <http://localhost:8080> . This will allow you to run challenges 1-8, 12-46.

When you stopped the `k8s-vault-minikube-start.sh` script and want to resume the port forward run: `k8s-vault-minikube-resume.sh`.
This is because if you run the start script again it will replace the secret in the vault and not update the secret-challenge application with the new secret.

## Cloud Challenges

_Can be used for challenges 1-46_

**READ THIS**: Given that the exercises below contain IAM privilege escalation exercises,
never run this on an account which is related to your production environment or can influence your account-over-arching
resources.

### Running WrongSecrets in AWS

Follow the steps in [the README in the AWS subfolder](aws/README.md).

### Running WrongSecrets in GCP

Follow the steps in [the README in the GCP subfolder](gcp/README.md).

### Running WrongSecrets in Azure

Follow the steps in [the README in the Azure subfolder](azure/README.md).

### Running Challenge15 in your own cloud only

When you want to include your own Canarytokens for your cloud-deployment, do the following:

1. Fork the project.
2. Make sure you use the [GCP ingress](/gcp/k8s-vault-gcp-ingress-start.sh) or [AWS ingress](aws/k8s-aws-alb-script.sh) scripts to generate an ingress for your project.
3. Go to [canarytokens.org](https://canarytokens.org/generate) and select `AWS Keys`, in the webHook URL field add `<your-domain-created-at-step1>/canaries/tokencallback`.
4. Encrypt the received credentials so that [Challenge15](/src/main/java/org/owasp/wrongsecrets/challenges/docker/Challenge15.java) can decrypt them again.
5. Commit the unencrypted and encrypted materials to Git and then commit again without the decrypted materials.
6. Adapt the hints of Challenge 15 in your fork to point to your fork.
7. Create a container and push it to your registry
8. Override the K8s definition files for either [AWS](/aws/k8s/secret-challenge-vault-deployment.yml) or [GCP](/gcp/k8s/secret-challenge-vault-deployment.yml.tpl).

## Do you want to play without guidance or spoils?

Each challenge has a `Show hints` button and a `What's wrong?` button. These buttons help to simplify the challenges and give explanation to the reader. Though, the explanations can spoil the fun if you want to do this as a hacking exercise.
Therefore, you can manipulate them by overriding the following settings in your env:

-   `hints_enabled=false` will turn off the `Show hints` button.
-   `reason_enabled=false` will turn of the `What's wrong?` explanation button.
-   `spoiling_enabled=false` will turn off the `/spoil/challenge-x` endpoint (where `x` is the short-name of the challenge).

## Enabling Swaggerdocs and UI

You can enable Swagger documentation and the Swagger UI by overriding the `SPRINGDOC_UI` and `SPRINGDOC_DOC` when running the Docker container.

## Special thanks & Contributors

Leaders:

- [Ben de Haan @bendehaan](https://www.github.com/bendehaan)
- [Jeroen Willemsen @commjoen](https://www.github.com/commjoen)

Top contributors:

- [Jannik Hollenbach @J12934](https://www.github.com/J12934)
- [Puneeth Y @puneeth072003](https://www.github.com/puneeth072003)
- [Joss Sparkes @RemakingEden](https://www.github.com/RemakingEden)

Contributors:

- [Nanne Baars @nbaars](https://www.github.com/nbaars)
- [Marcin Nowak @drnow4u](https://www.github.com/drnow4u)
- [Rodolfo Cabral Neves @roddas](https://www.github.com/roddas)
- [Osama Magdy @osamamagdy](https://www.github.com/osamamagdy)
- [Divyanshu Dev @Novice-expert](https://www.github.com/Novice-expert)
- [Tibor Hercz @tiborhercz](https://www.github.com/tiborhercz)
- [za @za](https://www.github.com/za)
- [Chris Elbring Jr. @neatzsche](https://www.github.com/neatzsche)
- [Diamond Rivero @diamant3](https://www.github.com/diamant3)
- [Norbert Wolniak @nwolniak](https://www.github.com/nwolniak)
- [Adarsh A @adarsh-a-tw](https://www.github.com/adarsh-a-tw)
- [Shubham Patel @Shubham-Patel07](https://www.github.com/Shubham-Patel07)
- [Filip Chyla @fchyla](https://www.github.com/fchyla)
- [Turjo Chowdhury @turjoc120](https://www.github.com/turjoc120)
- [Vineeth Jagadeesh @djvinnie](https://www.github.com/djvinnie)
- [Dmitry Litosh @Dlitosh](https://www.github.com/Dlitosh)
- [Josh Grossman @tghosth](https://www.github.com/tghosth)
- [alphasec @alphasecio](https://www.github.com/alphasecio)
- [CaduRoriz @CaduRoriz](https://www.github.com/CaduRoriz)
- [Madhu Akula @madhuakula](https://www.github.com/madhuakula)
- [Mike Woudenberg @mikewoudenberg](https://www.github.com/mikewoudenberg)
- [Spyros @northdpole](https://www.github.com/northdpole)
- [RubenAtBinx @RubenAtBinx](https://www.github.com/RubenAtBinx)
- [Jeff Tong @Wind010](https://www.github.com/Wind010)
- [Fern @f3rn0s](https://www.github.com/f3rn0s)
- [Shlomo Zalman Heigh @szh](https://www.github.com/szh)
- [Rick M @kingthorin](https://www.github.com/kingthorin)
- [Nicolas Humblot @nhumblot](https://www.github.com/nhumblot)
- [Danny Lloyd @dannylloyd](https://www.github.com/dannylloyd)
- [Alex Bender @alex-bender](https://www.github.com/alex-bender)

Testers:

- [Dave van Stein @davevs](https://www.github.com/davevs)
- [Marcin Nowak @drnow4u](https://www.github.com/drnow4u)
- [Marc Chang Sing Pang @mchangsp](https://www.github.com/mchangsp)
- [Vineeth Jagadeesh @djvinnie](https://www.github.com/djvinnie)

Special thanks:

- [Madhu Akula @madhuakula @madhuakula](https://www.github.com/madhuakula)
- [Nanne Baars @nbaars @nbaars](https://www.github.com/nbaars)
- [Björn Kimminich @bkimminich](https://www.github.com/bkimminich)
- [Dan Gora @devsecops](https://www.github.com/devsecops)
- [Xiaolu Dai @saragluna](https://www.github.com/saragluna)
- [Jonathan Giles @jonathanGiles](https://www.github.com/jonathanGiles)


### Sponsorships

We would like to thank the following parties for helping us out:

[![gitguardian_logo.png](images/gitguardian_logo.jpeg)](https://blog.gitguardian.com/gitguardian-is-proud-sponsor-of-owasp/)

[GitGuardian](https://www.gitguardian.com/) for their sponsorship which allows us to pay the bills for our cloud-accounts.

[![jetbrains_logo.png](images/jetbrains_logo.png)](https://www.jetbrains.com/)

[Jetbrains](https://www.jetbrains.com/) for licensing an instance of Intellij IDEA Ultimate edition to the project leads. We could not have been this fast with the development without it!

[![1password_logo.png](images/1password_logo.png)](https://github.com/1Password/1password-teams-open-source/pull/552)

[1Password](https://1password.com/) for granting us an open source license to 1Password for the secret detection testbed.


[![AWS Open Source](images/aws-white_48x29.png)](https://aws.amazon.com/)

[AWS](https://aws.amazon.com/) for granting us AWS Open Source credits which we use to test our project and the [Wrongsecrets CTF Party](https://github.com/OWASP/wrongsecrets-ctf-party) setup on AWS.

## Help Wanted

You can help us by the following methods:

-   Star us
-   Share this app with others
-   Of course, we can always use your help [to get more flavors](https://github.com/OWASP/wrongsecrets/issues/37) of ""wrongly"" configured secrets in to spread awareness! We would love to get some help with other cloud providers, like Alibaba or Tencent cloud for instance. Do you miss something else than a cloud provider? File an issue or create a PR! See [our guide on contributing for more details](CONTRIBUTING.md). Contributors will be listed in releases, in the ""Special thanks & Contributors""-section, and the web-app.

## Use OWASP WrongSecrets as a secret detection benchmark

As tons of secret detection tools are coming up for both Docker and Git, we are creating a Benchmark testbed for it.
Want to know if your tool detects everything? We will keep track of the embedded secrets in [this issue](https://github.com/OWASP/wrongsecrets/issues/201) and have a [branch](https://github.com/OWASP/wrongsecrets/tree/experiment-bed) in which we put additional secrets for your tool to detect.
The branch will contain a Docker container generation script using which you can eventually test your container secret scanning.

## CTF

We have 3 ways of playing CTFs:

-   The quick ""let's play""-approach based on our own Heroku domain [https://wrongsecrets-ctf.herokuapp.com](https://wrongsecrets-ctf.herokuapp.com), which we documented for you here.
-   A more extended approach documented in [ctf-instructions.md](/ctf-instructions.md).
-   A fully customizable CTF setup where every player gets its own virtual instance of WrongSecrets and a virtual instance of the wrongsecrets-desktop, so they all can play hassle-free. For this you have to use [the WrongSecrets CTF Party setup](https://github.com/OWASP/wrongsecrets-ctf-party).

### CTFD Support

Want to use CTFD to play a CTF based on the free Heroku wrongsecrets-ctf instance together with CTFD? You can!

NOTE: CTFD support now works based on the [Juiceshop CTF CLI](https://github.com/juice-shop/juice-shop-ctf).

NOTE-II: [https://wrongsecrets-ctf.herokuapp.com](https://wrongsecrets-ctf.herokuapp.com) (temporary down based on lack of oss credits) is based on Heroku and has limited capacity.

Initial creation of the zip file for CTFD requires you to visit [https://wrongsecrets-ctf.herokuapp.com/api/Challenges](https://wrongsecrets-ctf.herokuapp.com/api/Challenges) once before executing the steps below.

Follow the following steps:

```shell
    npm install -g juice-shop-ctf-cli@9.1.0
    juice-shop-ctf #choose ctfd and https://wrongsecrets-ctf.herokuapp.com as domain. No trailing slash! The key is 'TRwzkRJnHOTckssAeyJbysWgP!Qc2T', feel free to enable hints. We do not support snippets or links/urls to code or hints.
    docker run -p 8001:8000 -it ctfd/ctfd:3.4.3
```

Now visit the CTFD instance at [http://localhost:8001](http://localhost:8001) and setup your CTF.
Then use the administrative backup function to import the zipfile you created with the juice-shop-ctf command.
Game on using [https://wrongsecrets-ctf.herokuapp.com](https://wrongsecrets-ctf.herokuapp.com)!
Want to setup your own? You can! Watch out for people finding your key though, so secure it properly: make sure the running container with the actual ctf-key is not exposed to the audience, similar to our heroku container.

## FBCTF Support (Experimental!)

NOTE: FBCTF support is experimental.

Follow the same step as with CTFD, only now choose fbctfd and as a url for the countrymapping choose `https://raw.githubusercontent.com/OWASP/wrongsecrets/79a982558016c8ce70948a8106f9a2ee5b5b9eea/config/fbctf.yml`.
Then follow [https://github.com/facebookarchive/fbctf/wiki/Quick-Setup-Guide](https://github.com/facebookarchive/fbctf/wiki/Quick-Setup-Guide) to run the FBCTF.

## Notes on development

For development on local machine use the `local` profile `./mvnw spring-boot:run -Dspring-boot.run.profiles=local,without-vault`

If you want to test against vault without K8s: start vault locally with

```shell
 export SPRING_CLOUD_VAULT_URI='http://127.0.0.1:8200'
 export VAULT_API_ADDR='http://127.0.0.1:8200'
 vault server -dev
```

and in your next terminal, do (with the token from the previous commands):

```shell
export SPRING_CLOUD_VAULT_URI='http://127.0.0.1:8200'
export SPRING_CLOUD_VAULT_TOKEN='<TOKENHERE>'
vault token create -id=""00000000-0000-0000-0000-000000000000"" -policy=""root""
vault kv put secret/secret-challenge vaultpassword.password=""$(openssl rand -base64 16)""
```

Now use the `local-vault` profile to do your development.

```shell
./mvnw spring-boot:run -Dspring-boot.run.profiles=local,local-vault
```

If you want to dev without a Vault instance, use additionally the `without-vault` profile to do your development:

```shell
./mvnw spring-boot:run -Dspring-boot.run.profiles=local,without-vault
```

Want to push a container? See `.github/scripts/docker-create-and-push.sh` for a script that generates and pushes all containers. Do not forget to rebuild the app before composing the container.

Want to check why something in vault is not working in kubernetes? Do `kubectl exec vault-0 -n vault -- vault audit enable file file_path=stdout`.

### Dependency management

We have CycloneDX and OWASP Dependency-check integrated to check dependencies for vulnerabilities.
You can use the OWASP Dependency-checker by calling `mvn dependency-check:aggregate` and `mvn cyclonedx:makeBom` to use CycloneDX to create an SBOM.

### Get the project started in IntelliJ IDEA

Requirements: make sure you have the following tools installed: [Docker](https://www.docker.com/products/docker-desktop/), [Java22 JDK](https://jdk.java.net/22/), [NodeJS 20](https://nodejs.org/en/download/current) and [IntelliJ IDEA](https://www.jetbrains.com/idea/download).

1. Fork and clone the project as described in the [documentation](https://github.com/OWASP/wrongsecrets/blob/master/CONTRIBUTING.md).
2. Import the project in IntelliJ (e.g. import as mvn project / local sources)
3. Go to the project settings and make sure it uses Java22 (And that the JDK can be found)
4. Go to the IDE settings>Language & Frameworks > Lombok and make sure Lombok processing is enabled
5. Open the Maven Tab in your IDEA and run ""Reload All Maven Projects"" to make the system sync and download everything. Next, in that same tab use the ""install"" option as part of the OWASP WrongSecrets Lifecycle to genereate the asciidoc and such.
6. Now run the `main` method in `org.owasp.wrongsecrets.WrongSecretsApplication.java`. This should fail with a stack trace.
7. Now go to the run configuration of the app and make sure you have the active profile `without-vault`. This is done by setting the VM options arguments to `--server.port=8080 --spring.profiles.active=local,without-vault`. Set `K8S_ENV=docker` as environment argument.
8. Repeat step 6: run the app again, you should have a properly running application which is visitable in your browser at http://localhost:8080.

**Pictorial Guide** on how to get the project started in IntelliJ IDEA is available at [_Contributing.md_](https://github.com/OWASP/wrongsecrets/blob/master/CONTRIBUTING.md#how-to-get-started-with-the-project-in-intellij-idea).

Feel free to edit and propose changes via pull requests. Be sure to follow our guidance in the [documentation](https://github.com/OWASP/wrongsecrets/blob/master/CONTRIBUTING.md) to get your work accepted.

Please note that we officially only support Linux and MacOS for development. If you want to develop using a Windows machine, use WSL2 or a virtual machine running Linux. We did include Windows detection & a bunch of `exe` files for a first experiment, but are looking for active maintainers of them. Want to make sure it runs on Windows? Create PRs ;-).

If, after reading this section, you still have no clue on the application code: Have a look [at some tutorials on Spring boot from Baeldung](https://www.baeldung.com/spring-boot).

### Automatic reload during development

To make changes made load faster we added `spring-dev-tools` to the Maven project.
To enable this in IntelliJ automatically, make sure:

-   Under Compiler -> Automatically build project is enabled, and
-   Under Advanced settings -> Allow auto-make to start even if developed application is currently running.

You can also manually invoke: Build -> Recompile the file you just changed, this will also force reloading of the application.

### How to add a Challenge

Follow the steps below on adding a challenge:

1. First make sure that you have an [Issue](https://github.com/OWASP/wrongsecrets/issues) reported for which a challenge is really wanted.
2. Add the new challenge in the `org.owasp.wrongsecrets.challenges` folder. Make sure you add an explanation in `src/main/resources/explanations` and refer to it from your new Challenge class.
3. Add unit, integration and UI tests as appropriate to show that your challenge is working.
4. Do not forget to configure the challenge in `src/main/resources/wrong-secrets-configuration.yaml`
5. Review the [CONTRIBUTING guide](CONTRIBUTING.md) for setting up your contributing environment and writing good commit messages.

For more details please refer [_Contributing.md_](https://github.com/OWASP/wrongsecrets/blob/master/CONTRIBUTING.md#how-to-add-a-challenge).

If you want to move existing cloud challenges to another cloud: extend Challenge classes in the `org.owasp.wrongsecrets.challenges.cloud` package and make sure you add the required Terraform in a folder with the separate cloud identified. Make sure that the environment is added to `org.owasp.wrongsecrets.RuntimeEnvironment`.
Collaborate with the others at the project to get your container running so you can test at the cloud account.

### Local testing

If you have made some changes to the codebase or added a new challenge and would like to see exactly how the container will look after merge for testing, we have a script that makes this very easy. Follow the steps below:

1. Ensure you have bash installed and open.
2. Navigate to .github/scripts.
3. Run the docker-create script `bash docker-create.sh`.
   - Note: Do you want to run this on your minikube? then first run `eval $(minikube docker-env)`.
4. Follow any instructions given, you made need to install/change packages.
5. Run the newly created container:
  - to running locally: `docker run -p 8080:8080 jeroenwillemsen/wrongsecrets:local-test-no-vault`
  - to run it on your minikube: use the container `jeroenwillemsen/wrongsecrets:local-test-k8s-vault` in your deployment definition.
  - to run it with Vault on your minikube: use the container `jeroenwillemsen/wrongsecrets:local-test-local-vault` in your deployment definition.

### Local Automated testing

We currently have 2 different test-suites, both fired with `./mvnw test`.
- A normal junit test suite of unit and integration tests, located at the [`test/java` folder](src/test/java) with output stored at the default target directory.
- A cypress test suite, integrated by means of a junit test, located at [`test/e2e` folder](src/test/e2e) with output stored at [`target/test-classes/e2e/cypress/reports/`](target/test-classes/e2e/cypress/reports/). See the [cypress readme](src/test/e2e/cypress/README.md) for more details.

Note: You can do a full roundtrip of cleaning, building, and testing with `./mvnw clean install`.

## Want to play, but are not allowed to install the tools?

If you want to play the challenges, but cannot install tools like keepass, Radare, etc. But are allowed to run Docker containers, try the following:

```shell
docker run -p 3000:3000 -v /var/run/docker.sock:/var/run/docker.sock jeroenwillemsen/wrongsecrets-desktop:latest
```

or use something more configurable:

```shell
docker run -d \
  --name=webtop \
  --security-opt seccomp=unconfined \
  -e PUID=1000 \
  -e PGID=1000 \
  -e TZ=Europe/London \
  -e SUBFOLDER=/ \
  -e KEYBOARD=en-us-qwerty \
  -p 3000:3000 \
  -v /var/run/docker.sock:/var/run/docker.sock \
  --shm-size=""2gb"" \
  --restart unless-stopped \
  jeroenwillemsen/wrongsecrets-desktop:latest
```

And then at [http://localhost:3000](http://localhost:3000).

Note: be careful with trying to deploy the `jeroenwillemsen/wrongsecrets-desktop` container to Heroku ;-).

## Docker on macOS with M1 and Colima (Experimental!)

NOTE: Colima support is experimental.

Using [Colima](https://github.com/abiosoft/colima) (version 0.5.2 when written) you your macOS with Apple Silicon M1
to run Docker image `jeroenwillemsen/wrongsecrets` you try one of:

- switch off Colima
- change Docker context
- run Colima with 1 CPU

### Switch off Colima

```shell
colima stop
```
and run natively Docker image `jeroenwillemsen/wrongsecrets` on ARM.

### Change Docker context

Running docker image on Colima container runtimes on macOS Ventura with M1 CPU can run very slowly or can hang at some point.
Wrong Secrets provide `arm64` Docker image and switching to `desktop-linux` context will use the native `arm64` image.
To do that in the terminal run:

```shell
docker context ls
```

you should see context default `colima *`:

```
NAME                TYPE                DESCRIPTION                               DOCKER ENDPOINT                                    KUBERNETES ENDPOINT                ORCHESTRATOR
colima *            moby                colima                                    unix:///Users/YOUR_USER_NAME/.colima/default/docker.sock
default             moby                Current DOCKER_HOST based configuration   unix:///var/run/docker.sock                        https://127.0.0.1:6443 (default)   swarm
desktop-linux       moby                                                          unix:///Users/YOUR_USER_NAME/.docker/run/docker.sock
```

Now run one of the above Docker commands together with `--context` switch e.g.:

```bash
docker --context desktop-linux run -p 8080:8080 jeroenwillemsen/wrongsecrets:latest-no-vault
```

### Run Colima with 1 CPU

Colima is using QEMU behind and for QEMU on Apple Silicon M1 is recommended to use 1 CPU core:

```shell
colima start -m 8 -c 1 --arch x86_64
```

and run with AMD x64 emulation e.g.:

```bash
docker run -p 8080:8080 jeroenwillemsen/wrongsecrets:latest-no-vault
```

## Want to disable challenges in your own release?

If you want to run WrongSecrets but without certain challenges you don't want to present to others: please read this section.

*_NOTE_* Please note that we do not deliver any support to your fork when you follow the process below. Please understand that license and copyright of the original application remain intact for your Fork.

Requirements:
- Have the JDK of Java 22 installed;
- Have an account at a registry to which you can push your variant of the WrongSecrets container;

Here are the steps you have to follow to create your own release of WrongSecrets with certain challenges disabled:
1. Fork the repository.
2. In `src/main/resources/wrong-secrets-configuration.yaml` remove the reference to the challenge you no longer want to have in your fork.
3. In the root of the project run `./mvnw clean install`
4. Now build the Docker image for your target of choice:

```sh
   docker buildx create --name mybuilder
   docker buildx use mybuilder
   docker buildx build --platform linux/amd64,linux/arm64 -t <registry/container-name>:<yourtag>-no-vault --build-arg ""argBasedPassword='this is on your command line'"" --build-arg ""PORT=8081"" --build-arg ""argBasedVersion=<yourtag>"" --build-arg ""spring_profile=without-vault"" --push
   docker buildx build --platform linux/amd64,linux/arm64 -t <registry/container-name>:<yourtag>-kubernetes-vault--build-arg ""argBasedPassword='this is on your command line'"" --build-arg ""PORT=8081"" --build-arg ""argBasedVersion=<yourtag>"" --build-arg ""spring_profile=kubernetes-vault"" --push
```


## Further reading on secrets management

Want to learn more? Checkout the sources below:

-   [Blog: 10 Pointers on Secrets Management](https://dev.to/commjoen/secure-deployment-10-pointers-on-secrets-management-187j)
-   [OWASP SAMM on Secret Management](https://owaspsamm.org/model/implementation/secure-deployment/stream-b/)
-   [The secret detection topic at Github](https://github.com/topics/secrets-detection)
-   [OWASP Secretsmanagement Cheatsheet](https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Secrets_Management_Cheat_Sheet.md)
-   [OpenCRE on secrets management](https://www.opencre.org/cre/223-780?register=true&type=tool&tool_type=training&tags=secrets,training&description=With%20this%20app%2C%20we%20have%20packed%20various%20ways%20of%20how%20to%20not%20store%20your%20secrets.%20These%20can%20help%20you%20to%20realize%20whether%20your%20secret%20management%20is%20ok.%20The%20challenge%20is%20to%20find%20all%20the%20different%20secrets%20by%20means%20of%20various%20tools%20and%20techniques.%20Can%20you%20solve%20all%20the%2014%20challenges%3F&trk=flagship-messaging-web&messageThreadUrn=urn:li:messagingThread:2-YmRkNjRkZTMtNjRlYS00OWNiLWI2YmUtMDYwNzY3ZjI1MDcyXzAxMg==&lipi=urn:li:page:d_flagship3_feed;J58Sgd80TdanpKWFMH6z+w==)
"
kakajika/FragmentAnimations,master,1143,157,2015-11-27T16:10:06Z,143,7,3D animation examples for support-v4 Fragment transition.,,"# FragmentAnimations

[![Platform](https://img.shields.io/badge/platform-android-green.svg)](http://developer.android.com/index.html)
<img src=""https://img.shields.io/badge/license-Apache 2.0-green.svg?style=flat"">
[![API](https://img.shields.io/badge/API-4%2B-yellow.svg?style=flat)](https://android-arsenal.com/api?level=4)
[![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-FragmentAnimations-green.svg?style=true)](https://android-arsenal.com/details/1/3526)

Animation examples for `support.v4.Fragment` transition.

These animations do not depends on any external libraries.

[<img src=""https://dply.me/h7azvd/button/large"" alt=""Try it on your device via DeployGate"">](https://dply.me/h7azvd)

## Usage Example

In your `Fragment`, just code like this.

```java
@Override
public Animation onCreateAnimation(int transit, boolean enter, int nextAnim) {
    return CubeAnimation.create(CubeAnimation.UP, enter, DURATION);
}
```

See more example in [ExampleFragment.java](https://github.com/kakajika/FragmentAnimations/blob/master/app/src/main/java/com/labo/kaji/fragmentanimations/example/ExampleFragment.java)

## Contents

### Cube Animation

[CubeAnimation.java](https://github.com/kakajika/FragmentAnimations/blob/master/fragmentanimations/src/main/java/com/labo/kaji/fragmentanimations/CubeAnimation.java)

![Cube](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/cube.gif)

### Flip Animation

[FlipAnimation.java](https://github.com/kakajika/FragmentAnimations/blob/master/fragmentanimations/src/main/java/com/labo/kaji/fragmentanimations/FlipAnimation.java)

![Flip](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/flip.gif)

### Push/Pull Animation

[PushPullAnimation.java](https://github.com/kakajika/FragmentAnimations/blob/master/fragmentanimations/src/main/java/com/labo/kaji/fragmentanimations/PushPullAnimation.java)

![Push/Pull](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/pushpull.gif)

### Sides Animation

[SidesAnimation.java](https://github.com/kakajika/FragmentAnimations/blob/master/fragmentanimations/src/main/java/com/labo/kaji/fragmentanimations/SidesAnimation.java)

### Move Animation

[MoveAnimation.java](https://github.com/kakajika/FragmentAnimations/blob/master/fragmentanimations/src/main/java/com/labo/kaji/fragmentanimations/MoveAnimation.java)

![Move](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/move.gif)

## Combination

You can use above Animations with another one.

```java
@Override
public Animation onCreateAnimation(int transit, boolean enter, int nextAnim) {
    if (enter) {
        return MoveAnimation.create(MoveAnimation.UP, enter, DURATION);
    } else {
        return CubeAnimation.create(CubeAnimation.UP, enter, DURATION);
    }
}
```

### Cube/Move Animation

![Cube/Move](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/cubemove.gif)

### Move/Cube Animation

![Move/Cube](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/movecube.gif)

### Push/Move Animation

![Push/Move](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/pushmove.gif)

### Move/Pull Animation

![Move/Pull](https://raw.githubusercontent.com/wiki/kakajika/FragmentAnimations/images/movepull.gif)

## Install

This library is available in jcenter.

```groovy
dependencies {
    compile 'com.labo.kaji:fragmentanimations:0.1.1'
}
```

## License

    Copyright 2015 kakajika

    Licensed under the Apache License, Version 2.0 (the ""License"");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an ""AS IS"" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
"
eazybytes/microservices,3.2.3,225,249,2023-07-10T06:44:23Z,1856,5,"Microservices With Spring, Docker, Kubernetes - Code Examples",docker docker-compose java kubernetes microservice spring spring-boot spring-cloud,"# Master Microservices with Spring Boot, Docker, Kubernetes

[![Image](https://github.com/eazybytes/microservices/blob/3.2.0/Microservice.png ""Master Microservices with Java, Spring, Docker, Kubernetes"")](https://www.udemy.com/course/master-microservices-with-spring-docker-kubernetes/?referralCode=9365DB9B7EE637F629A9)

Learn how to create enterprise and production ready Microservices with Spring, Spring Cloud, Docker and Kubernetes.

## Topics covered in the course
* Section 1 - Introduction to Microservices Architecture
* Section 2- Building microservices using Spring Boot
* Section 3 - How do we right size our microservices & identify boundaries
* Section 4 - Handle deployment, portability &  scalability of microservices using Docker
* Section 5 - Deep Dive on Cloud Native Apps & 15-Factor methodology
* Section 6 - Configurations Management in Microservices
* Section 7 - Using MySQL DBs inside microservices
* Section 8 - Service Discovery & Service Registration in microservices
* Section 9 - Gateway, Routing & Cross cutting concerns in Microservices
* Section 10 - Making Microservices Resilient
* Section 11 - Observability and monitoring of microservices
* Section 12 - Microservices Security
* Section 13 - Event Driven microservices using RabbitMQ,Spring Cloud Functions & Stream
* Section 14 - Event Driven microservices using Kafka,Spring Cloud Functions & Stream
* Section 15 - Container Orchestration using Kubernetes
* Section 16 - Deep dive on Helm
* Section 17 - Server-side service discovery and load balancing using Kubernetes
* Section 18 - Deploying microservices into cloud K8s cluster
* Section 19 - Introduction to K8s Ingress, Service Mesh (Istio) & mTLS
* Section 20 - Congratulations & Thank You

## Pre-requisite for the course
- Good understanding on Java and Spring concepts
- Basic understanding on SpringBoot & REST services is a bonus but not mandatory
- Interest to learn and explore about Microservices

# Important Links
- Spring Boot - https://spring.io/projects/spring-boot
- Create SpringBoot project - https://start.spring.io
- DTO pattern blog - https://martinfowler.com/eaaCatalog/dataTransferObject.html
- Model Mapper - http://modelmapper.org/
- Map Struct - https://mapstruct.org/
- Spring Doc - https://springdoc.org/
- Open API - https://www.openapis.org/
- Lucidchart Blog - https://www.lucidchart.com/blog/ddd-event-storming
- Docker website - https://www.docker.com
- Docker hub website - https://hub.docker.com
- Buildpacks website - https://buildpacks.io
- Google Jib website - https://github.com/GoogleContainerTools/jib
- Docker compose website - https://docs.docker.com/compose/
- Twelve-Factor methodology - https://12factor.net
- Beyond the Twelve-Factor App book - https://www.oreilly.com/library/view/beyond-the-twelve-factor/9781492042631/
- Spring Cloud website - https://spring.io/projects/spring-cloud
- Spring Cloud Config website - https://spring.io/projects/spring-cloud-config
- Spring Cloud Bus website - https://spring.io/projects/spring-cloud-bus
- RabbitMQ website - https://www.rabbitmq.com
- Hookdeck website- https://hookdeck.com
- Spring Cloud Netflix website - https://spring.io/projects/spring-cloud-netflix
- Spring Cloud OpenFeign - https://spring.io/projects/spring-cloud-openfeign
- Netflix Blog - https://netflixtechblog.com/netflix-oss-and-spring-boot-coming-full-circle-4855947713a0
- Resilience4j website - https://resilience4j.readme.io
- Spring Cloud Gateway website - https://spring.io/projects/spring-cloud-gateway
- Stripe RateLimitter pattern blog - https://stripe.com/blog/rate-limiters
- Apache Benchmark website - https://httpd.apache.org
- Grafana website - https://grafana.com
- Grafana Loki setup - https://grafana.com/docs/loki/latest/getting-started/
- Micrometer website - https://micrometer.io
- Prometheus website - https://prometheus.io/
- Grafana Dashboards - https://grafana.com/grafana/dashboards/
- OpenTelemetry website - https://opentelemetry.io/
- OpenTelemetry automatic instrumentation - https://opentelemetry.io/docs/instrumentation/java/automatic/
- Keycloak website - https://www.keycloak.org/
- Apache Kafka website - https://kafka.apache.org
- Docker compose file for Kafka - https://github.com/bitnami/containers/blob/main/bitnami/kafka/docker-compose.yml
- Local Kubernetes Cluster with Docker Desktop - https://docs.docker.com/desktop/kubernetes/
- Kubernetes Dashboard - https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/
- Helm website - https://helm.sh
- Chocolatey website - https://chocolatey.org/
- Bitnami Helm charts GitHub repo - https://github.com/bitnami/charts
- Spring Cloud Kubernetes website - https://spring.io/projects/spring-cloud-kubernetes
- Spring Cloud Kubernetes Blog - https://spring.io/blog/2021/10/26/new-features-for-spring-cloud-kubernetes-in-spring-cloud-2021-0-0-m3
- GCP website - https://cloud.google.com
- GCP SDK installation - https://cloud.google.com/sdk/docs/install
- Kubernetes Ingress - https://kubernetes.io/docs/concepts/services-networking/ingress/
- Ingress Controllers - https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/
- Istio (Service mesh) - https://istio.io


## Maven Commands used in the course

|     Maven Command       |     Description          |
| ------------- | ------------- |
| ""mvn clean install -Dmaven.test.skip=true"" | To generate a jar inside target folder |
| ""mvn spring-boot:run"" | To start a springboot maven project |
| ""mvn spring-boot:build-image"" | To generate a docker image using Buildpacks. No need of Dockerfile |
| ""mvn compile jib:dockerBuild"" | To generate a docker image using Google Jib. No need of Dockerfile |

## Docker Commands used in the course

|     Docker Command       |     Description          |
| ------------- | ------------- |
| ""docker build . -t eazybytes/accounts:s4"" | To generate a docker image based on a Dockerfile |
| ""docker run  -p 8080:8080 eazybytes/accounts:s4"" | To start a docker container based on a given image |
| ""docker images"" | To list all the docker images present in the Docker server |
| ""docker image inspect image-id"" | To display detailed image information for a given image id |
| ""docker image rm image-id"" | To remove one or more images for a given image ids |
| ""docker image push docker.io/eazybytes/accounts:s4"" | To push an image or a repository to a registry |
| ""docker image pull docker.io/eazybytes/accounts:s4"" | To pull an image or a repository from a registry |
| ""docker ps"" | To show all running containers |
| ""docker ps -a"" | To show all containers including running and stopped |
| ""docker container start container-id"" | To start one or more stopped containers |
| ""docker container pause container-id"" | To pause all processes within one or more containers |
| ""docker container unpause container-id"" | To unpause all processes within one or more containers |
| ""docker container stop container-id"" | To stop one or more running containers |
| ""docker container kill container-id"" | To kill one or more running containers instantly |
| ""docker container restart container-id"" | To restart one or more containers |
| ""docker container inspect container-id"" | To inspect all the details for a given container id |
| ""docker container logs container-id"" | To fetch the logs of a given container id |
| ""docker container logs -f container-id"" | To follow log output of a given container id |
| ""docker container rm container-id"" | To remove one or more containers based on container ids |
| ""docker container prune"" | To remove all stopped containers |
| ""docker compose up"" | To create and start containers based on given docker compose file |
| ""docker compose down"" | To stop and remove containers |
| ""docker compose start"" | To start containers based on given docker compose file |
| ""docker compose down"" | To stop the running containers |
| ""docker run -p 3306:3306 --name accountsdb -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=accountsdb -d mysql"" | To create a MySQL DB container |
| ""docker run -p 6379:6379 --name eazyredis -d redis"" | To create a Redis Container |
| ""docker run -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:22.0.3 start-dev"" | To create Keycloak Container|


## Apache Benchmark command used in the course

|     Apache Benchmark command      |     Description          |
| ------------- | ------------- |
| ""ab -n 10 -c 2 -v 3 http://localhost:8072/eazybank/cards/api/contact-info"" | To perform load testing on API by sending 10 requests |

## Kubernetes Commands used in the course

|     Kubernetes Command       |     Description          |
| ------------- | ------------- |
| ""kubectl apply -f filename"" | To create a deployment/service/configmap based on a given YAML file |
| ""kubectl get all"" | To get all the components inside your cluster |
| ""kubectl get pods"" | To get all the pods details inside your cluster |
| ""kubectl get pod pod-id"" | To get the details of a given pod id |
| ""kubectl describe pod pod-id"" | To get more details of a given pod id |
| ""kubectl delete pod pod-id"" | To delete a given pod from cluster |
| ""kubectl get services"" | To get all the services details inside your cluster |
| ""kubectl get service service-id"" | To get the details of a given service id |
| ""kubectl describe service service-id"" | To get more details of a given service id |
| ""kubectl get nodes"" | To get all the node details inside your cluster |
| ""kubectl get node node-id"" | To get the details of a given node |
| ""kubectl get replicasets"" | To get all the replica sets details inside your cluster |
| ""kubectl get replicaset replicaset-id"" | To get the details of a given replicaset |
| ""kubectl get deployments"" | To get all the deployments details inside your cluster |
| ""kubectl get deployment deployment-id"" | To get the details of a given deployment |
| ""kubectl get configmaps"" | To get all the configmap details inside your cluster |
| ""kubectl get configmap configmap-id"" | To get the details of a given configmap |
| ""kubectl get events --sort-by=.metadata.creationTimestamp"" | To get all the events occured inside your cluster |
| ""kubectl scale deployment accounts-deployment --replicas=1"" | To set the number of replicas for a deployment inside your cluster |
| ""kubectl set image deployment gatewayserver-deployment gatewayserver=eazybytes/gatewayserver:s11 --record"" | To set a new image for a deployment inside your cluster |
| ""kubectl rollout history deployment gatewayserver-deployment"" | To know the rollout history for a deployment inside your cluster |
| ""kubectl rollout undo deployment gatewayserver-deployment --to-revision=1"" | To rollback to a given revision for a deployment inside your cluster |
| ""kubectl get pvc"" | To list the pvcs inside your cluster |
| ""kubectl delete pvc data-happy-panda-mariadb-0"" | To delete a pvc inside your cluster |

## Helm Commands used in the course

|     Helm Command       |     Description          |
| ------------- | ------------- |
| ""helm create [NAME]"" | Create a default chart with the given name |
| ""helm dependencies build"" | To recompile the given helm chart |
| ""helm install [NAME] [CHART]"" | Install the given helm chart into K8s cluster |
| ""helm upgrade [NAME] [CHART]"" | Upgrades a specified release to a new version of a chart |
| ""helm history [NAME]"" | Display historical revisions for a given release |
| ""helm rollback [NAME] [REVISION]"" | Roll back a release to a previous revision |
| ""helm uninstall [NAME]"" | Uninstall all of the resources associated with a given release |
| ""helm template [NAME] [CHART]"" | Render chart templates locally along with the values |
| ""helm list"" | Lists all of the helm releases inside a K8s cluster |
"
ouya/ouya-sdk-examples,master,104,108,2013-06-03T23:57:09Z,194351,0,Examples for ouya sdk engines,,"ouya-sdk-examples
=================

This repository holds the code for various engines for interacting with the OUYA ODK.

Refer to the <a target=_blank href=""https://devs.ouya.tv/developers/docs"">[OUYA Docs]</a> for a table of content and guides for these examples.

Contributions to the OUYA Docs are submitted <a target=_blank href=""https://github.com/ouya/docs"">[here]</a>.
"
afrunt/examples,master,42,20,2018-01-03T02:45:54Z,5508,0,,,"# examples
## Spring Boot / Spring Cloud
* [Clustered Spring Boot Admin with Kubernetes Service Discovery](https://github.com/afrunt/examples/tree/master/spring-boot/spring-boot-admin-k8s)
* [Spring Boot and Elastic APM. SQL, JMS and custom spans](https://github.com/afrunt/examples/tree/master/spring-boot/spring-boot-elastic-apm)
## Java EE 8 
* [Java EE 8. How to integrate Java EE 8 application with NEO4j graph database](https://github.com/afrunt/examples/tree/master/java-ee-8-examples/neo4j-integration)
* [Java EE 8. How to implement custom scheduling with CDI and Concurrency Utilities](https://github.com/afrunt/examples/tree/master/java-ee-8-examples/cdi-managed-scheduling)
"
eventuate-examples/eventuate-examples-java-spring-todo-list,master,303,154,2015-12-19T19:24:23Z,495,20,A Java and Spring Boot Todo list application built using Eventuate,,"# An Eventuate project

<img class=""img-responsive"" src=""https://eventuate.io/i/logo.gif"">

This project is part of [Eventuate](http://eventuate.io), which is a microservices collaboration platform.

# Todo List example application

The Todo List application is the hello world application for the [Eventuate&trade; event sourcing](http://eventuate.io).
It illustrates how you can use the platform to write an application with a [microservices architecture](http://microservices.io/patterns/microservices.html) that uses [Event Sourcing](http://microservices.io/patterns/data/event-sourcing.html) and [Command Query Responsibility Segregation (CQRS)](http://microservices.io/patterns/data/cqrs.html).
The Todo List application lets users maintain a todo list.

The Todo List application is a Java and Spring Boot application built using Eventuate&trade;'s Event Sourcing based programming model.
Todos are implemented by an Event Sourcing-based `TodoAggregate`.
The aggregate's events are persisted in the Eventuate event store.
The application also maintains a materialized view of the data in MySQL.

Don't forget to take a look at the other [Eventuate example applications](http://eventuate.io/exampleapps.html).

# Got questions?

Don't hesitate to create an issue or see

* [Website](http://eventuate.io)
* [Mailing list](https://groups.google.com/d/forum/eventuate-users)
* [Slack](https://eventuate-users.slack.com). [Get invite](https://eventuateusersslack.herokuapp.com/)
* [Contact us](http://eventuate.io/contact.html).

# Architecture

The Todo application has a microservice architecture.
It is written using the [Eventuate Client Framework for Java](http://eventuate.io/docs/java/eventuate-client-framework-for-java.html), which provides an [event sourcing based programming model](http://eventuate.io/whyeventsourcing.html).
The following diagram shows the Todo List application architecture:

<img class=""img-responsive"" src=""i/eventuate-todo-architecture.png"">

The application consists of the following:

* Todo service - a Java and Spring Boot-based service that has a HATEOAS-style REST API for creating, updating and querying todo list items.
It uses Eventuate to persist aggregates using event sourcing.
* Todo view service - a Java and Spring Boot-based service that provides a REST API for querying todos.
It implements a [Command Query Responsibility Segregation (CQRS)](http://microservices.io/patterns/data/cqrs.html) view of todos using MySQL.
MySQL is kept up to date by subscribing to events produced by the Todo service.
* MySQL database - stores the CQRS view of todo list items.

Note: for simplicity, the Todo list application can be deployed as a monolithic application.


# Building and running the application

First, build the application

```
./gradlew assemble
```

Next, launch the services using [Docker Compose](https://docs.docker.com/compose/):

```
export DOCKER_HOST_IP=...
./gradlew <database-mode>ComposeBuild
./gradlew <database-mode>ComposeUp
```

Where `database-mode` is one of:

* `mysqlbinlog` - use MySQL with Binlog-based event publishing
* `postgreswal` - use Postgres with Postgres WAL-based event publishing
* `postgrespolling` - use Postgres with generic JDBC polling-based event publishing

Note: You need to set `DOCKER_HOST_IP` before running Docker Compose.
This must be an IP address or resolvable hostname.
It cannot be `localhost`.
See this [guide to setting `DOCKER_HOST_IP`](http://eventuate.io/docs/usingdocker.html) for more information.

# Using the application

Once the application has started, you can use the application via the Swagger UI.

* `http://${DOCKER_HOST_IP}:8081/swagger-ui.html` - the command-side service
* `http://${DOCKER_HOST_IP}:8082/swagger-ui.html` - the query-side service

# Got questions?

Don't hesitate to create an issue or see

* [Website](http://eventuate.io)
* [Mailing list](https://groups.google.com/d/forum/eventuate-users)
* [Slack](https://eventuate-users.slack.com). [Get invite](https://eventuateusersslack.herokuapp.com/)
* [Contact us](http://eventuate.io/contact.html).
"
inductiveautomation/ignition-sdk-examples,master,150,86,2014-12-13T19:42:19Z,8487,5,Ignition SDK Example Projects,,
vaadin/addressbook,master,90,1035,2013-01-22T15:14:29Z,609,10,Simple Addressbook example application,,"Addressbook Tutorial
====================

This tutorial teaches you some of the basic concepts in [Vaadin Framework](https://vaadin.com). It is meant to be
a fast read for learning how to get started - not an example on how application should be
designed. Please note this example uses and requires Java 8 to work.

![Addressbook Screenshot](addressbook_screenshot.png ""Addressbook Screenshot"")


Running the example from the command line
-------------------
```
$ mvn jetty:run
```

Open [http://localhost:8080/](http://localhost:8080/)


Importing in IntelliJ IDEA 14
--------------------
These instructions were tested on IntelliJ IDEA 14 CE. You can get it from https://www.jetbrains.com/idea/

To get the project up and running in IDEA, do:
- File -> New -> Project from Version Control -> Git
- The URL to use is https://github.com/vaadin/addressbook.git
- If you get a message about ""Non-managed pom.xml file found"". Choose ""Add as Maven Project""
- If you get a message about no JDK or SDK being selected. Choose ""Configure"" and select your installed JDK. You can also set the JDK using File -> Project Structure
- To start the project, find the ""Maven Projects"" tab on the right hand side of the screen and navigate to
  - Vaadin Web Application -> Plugins -> jetty -> jetty:run
  - Click the play button or right click and select Run (Select Debug instead to run in debug mode)

You should now have a Jetty server running on localhost:8080. Navigate to http://localhost:8080 to play with the application

Importing in NetBeans 8
--------------------
These instructions were tested on NetBeans 8.0.2. You can get it from https://www.netbeans.org

To checkout and run the project in NetBeans, do:
- Team -> Git -> Clone
- Set repository URL to https://github.com/vaadin/addressbook.git
- Finish
- Right click the imported project (Vaadin Addressbook Application) and select Run
- Select GlassFish Server 4.1 -> Remember in Current IDE Session -> OK

You should now have a GlassFish server running on localhost:8080 and a browser tab should also be automatically opened with this location

Importing in Eclipse
--------------------
These instructions were tested on Eclipse IDE for Java EE Developers Luna SR2. You can get it from http://eclipse.org/downloads/

To checkout and run the project in Eclipse, do:
- File -> Import...
- Check out Maven Projects from SCM
- Choose Git from SCM menu
  - If you do not see ""Git"" in the SCM menu, click ""Find more SCM connectors in the m2e Marketplace"" and install ""m2e-egit"". Restart Eclipse and start over.
- Set the repository URL to https://github.com/vaadin/addressbook.git
- Right click the imported ""addressbook"" and choose Run As -> Maven Build...
  - Set the goal to ""jetty:run"" and click ""Run""

You should now have a Jetty server running on localhost:8080. Navigate to [http://localhost:8080/](http://localhost:8080/) to play with the application

To use the built in server adapters of Eclipse, instead of doing ""Run As -> Maven Build..."" you can do
- Run As -> Run on Server
- Select the server you want to run on, e.g. Apache Tomcat 8 and click ok
- *Do not use the suggested J2EE Preview server* as it is outdated, deprecated and does not support Servlet 3, which is required for this application
"
apache/camel-quarkus-examples,main,70,111,2020-09-09T11:16:22Z,1360,1,Apache Camel Quarkus Examples,camel integration java quarkus,
JVerstry/Web-Related-Examples,master,79,105,2012-08-12T10:05:31Z,501,1,,,"Web-Related-Examples
====================

A set of web related examples from http://tshikatshikaaa.blogspot.com"
kite-sdk/kite-examples,master,99,70,2013-12-09T15:46:58Z,3621,7,Kite SDK Examples,,"# Kite SDK Examples

The Kite Examples project provides examples of how to use the Kite SDK.

Each example is a standalone Maven module with associated documentation.

## Basic Examples

* `dataset` is the closest to a HelloWorld example of Kite. It shows how to create datasets and perform streaming writes and reads over them.
* `dataset-hbase` shows how to store entities in HBase using the `RandomAccessDataset` API.
* `dataset-staging` shows how to use two datasets to manage Parquet-formatted data
* `logging` is an example of logging events from a command-line programs to Hadoop via Flume, using log4j as the logging API.
* `logging-webapp` is like `logging`, but the logging source is a webapp.

## Advanced Examples

* `demo` is a full end-to-end example of a webapp that logs events using Flume and performs session analysis using Crunch and Hive.

## Getting Started

The easiest way to run the examples is on the
[Cloudera QuickStart VM](http://www.cloudera.com/content/support/en/downloads/quickstart_vms.html),
which has all the necessary Hadoop services pre-installed, configured, and
running locally. See the notes below for any initial setup steps you should take.

The current examples run on version 5.1.0 of the QuickStart VM.

Checkout the latest [branch](https://github.com/kite-sdk/kite-examples/branches) of this repository in the VM:

```bash
git clone git://github.com/kite-sdk/kite-examples.git
cd kite-examples
```

Then choose the example you want to try and refer to the README in the relevant subdirectory.

### Setting up the QuickStart VM

There are two ways to run the examples with the QuickStart VM:

1. Logged in to the VM guest (username and password are both `cloudera`).
2. From your host computer.

The advantage of the first approach is that you don't need to install anything extra on
your host computer, such as Java or Maven, so there are no fewer set up steps.

For either approach, you need to make the following changes while logged into the VM:

* __Sync the system clock__ For some of the examples it's important that the host and
guest times are in sync. To synchronize the guest, login and type
`sudo ntpdate pool.ntp.org`.
* __Configure the NameNode to listen on all interfaces__ In order to access the cluster from
the host computer, the NameNode must be configured to listen on all network interfaces. This
is done by setting the `dfs.namenode.rpc-bind-host` property in `/etc/hadoop/conf/hdfs-site.xml`:
```xml
  <property>
    <name>dfs.namenode.rpc-bind-host</name>
    <value>0.0.0.0</value>
  </property>
```
* __Configure the History Server to listen on all interfaces__ In order to access the
cluster from the host computer, the History Server must be configured to listen on all
network interfaces. This is done by setting the `mapreduce.jobhistory.address` property
in `/etc/hadoop/conf/mapred-site.xml`:
```xml
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value>0.0.0.0:10020</value>
  </property>
```
* __Configure HBase to listen on all interfaces__ In order to access the cluster from
the host computer, HBase must be configured to listen on all network interfaces. This
is done by setting the `hbase.master.ipc.address` and `hbase.regionserver.ipc.address`
properties in `/etc/hbase/conf/hbase-site.xml`:
```xml
  <property>
    <name>hbase.master.ipc.address</name>
    <value>0.0.0.0</value>
  </property>

  <property>
    <name>hbase.regionserver.ipc.address</name>
    <value>0.0.0.0</value>
  </property>
```
* __Restart the vm__ Restart the VM with `sudo shutdown -r now`

The second approach is preferable when you want to use tools from your own development
environment (browser, IDE, command line). However, there are a few extra steps you
need to take to configure the QuickStart VM, listed below:

* __Add a host entry for quickstart.cloudera__ Add or edit a line like the following
in `/etc/hosts` on the host machine
```
127.0.0.1       localhost.localdomain   localhost       quickstart.cloudera
```
* __Enable port forwarding__ Most of the ports that need to be forward are pre-configured
on the QuickStart VM, but there are few that we need to add. For VirtualBox, open
the Settings dialog for the VM, select the Network tab, and click the Port Forwarding
button. Map the following ports - in each case the host port and the guest port
should be the same. Also, your VM should not be running when you are making these changes.
  * 8032 (YARN ResourceManager)
  * 10020 (MapReduce JobHistoryServer)

If you have VBoxManage installed on your host machine, you can do this via
command line as well. In bash, this would look something like:

```bash
# Set VM_NAME to the name of your VM as it appears in VirtualBox
VM_NAME=""QuickStart VM""
PORTS=""8032 10020""
for port in $PORTS; do
  VBoxManage modifyvm ""$VM_NAME"" --natpf1 ""Rule $port,tcp,,$port,,$port""
done
```

## Running integration tests

Some of the examples include integration tests. You can run them all with the following
command:
 
```bash
for module in $(ls -d -- */); do
  (cd $module; mvn clean verify; if [ $? -ne 0 ]; then break; fi)
done
```

# Troubleshooting

## Working with the VM

* __What are the usernames/passwords for the VM?__
  * Cloudera manager: cloudera/cloudera
  * HUE: cloudera/cloudera
  * Login: cloudera/cloudera

* __I can't find the file in VirtualBox (or VMWare)!__
  * You probably need to unpack it: In Windows, install 7zip, and _extract_ the
    VM files from the `.7z` file. In linux or mac, `cd` to where you copied the
    file and run `7zr e cloudera-quickstart-vm-4.3.0-kite-vbox-4.4.0.7z`
  * You should be able to import the extracted files to VirtualBox or VMWare

* __How do I open a `.ovf` file?__
  * Install and open [VirtualBox][vbox] on your computer
  * Under the menu ""File"", select ""Import...""
  * Navigate to where you unpacked the `.ovf` file and select it

* __What is a `.vmdk` file?__
  * The `.vmdk` file is the virtual machine disk image that accompanies a
    `.ovf` file, which is a portable VM description.

* __How do I open a `.vbox` file?__
  * Install and open [VirtualBox][vbox] on your computer
  * Under the menu ""Machine"", select ""Add...""
  * Navigate to where you unpacked the `.vbox` file and select it

* __How do I fix ""VTx"" errors?__
  * Reboot your computer and enter BIOS
  * Find the ""Virtualization"" settings, usually under ""Security"" and _enable_
    all of the virtualization options

* __How do I get my mouse back?__
  * If your mouse/keyboard is stuck in the VM (captured), you can usually
    release it by pressing the right `CTRL` key. If you don't have one (or that
    didn't work), then the release key will be in the __lower-right__ of the
    VirtualBox window

* __Other problems__
  * Using VirtualBox? Try using VMWare.
  * Using VMWare? Try using VirtualBox.

[vbox]: https://www.virtualbox.org/wiki/Downloads

"
aspose-words/Aspose.Words-for-Java,master,384,202,2011-11-25T13:43:55Z,70755,15,"Aspose.Words for Java examples, plugins and showcases",,"![GitHub all releases](https://img.shields.io/github/downloads/aspose-words/Aspose.Words-for-Java/total) ![GitHub](https://img.shields.io/github/license/aspose-words/Aspose.Words-for-java)
# Java API for Various Document Formats

[Aspose.Words for Java](https://products.aspose.com/words/java) is an advanced Java Word processing API that enables you to perform a great range of document processing tasks directly within your Java applications. Aspose.Words for Java API supports processing word (DOC, DOCX, OOXML, RTF) HTML, OpenDocument, PDF, EPUB, XPS, SWF and all image formats. With Aspose.Words you can generate, modify, and convert documents without using Microsoft Word.

Directory | Description
--------- | -----------
[Examples](Examples) | A collection of Java examples that help you learn the product features.
[Plugins](Plugins) | Plugins that will demonstrate one or more features of Aspose.Words for Java.

<p align=""center"">
  <a title=""Download Examples ZIP"" href=""https://github.com/aspose-words/Aspose.words-for-Java/archive/master.zip"">
	<img src=""https://raw.github.com/AsposeExamples/java-examples-dashboard/master/images/downloadZip-Button-Large.png"" />
  </a>
</p>

## Word API Features

### Rendering and Printing

- Layout document into pages with high fidelity (exactly like Microsoft Word® would do that) to all the formats below.
- Render individual pages or complete documents to `PDF`, `XPS`, or `SWF`.
- Render document pages to raster images (Multipage `TIFF`, `PNG`, `JPEG`, `BMP`).
- Render pages to a Java Graphics object to a specific size.
- Print document pages using the Java printing infrastructure.
- Update TOC, page numbers, and other fields before rendering or printing.
- 3D Effects Rendering through the `OpenGL`.

### Document Content Features

- Access, create, and modify various document elements.
- Access and modify all document elements using `XmlDocument` -like classes and methods.
- Copy and move document elements between documents.
- Join and split documents.
- Specify document protection, open protected, and encrypted documents.
- Find and replace text, enumerate over document content.
- Preserve or extract OLE objects and ActiveX controls from the document.
- Preserve or remove VBA macros from the document. Preserve VBA macros digital signature.

### Reporting Features

- Support of C# syntax and LINQ extension methods directly in templates (even for `ADO.NET` data sources).
- Support of repeatable and conditional document blocks (loops and conditions) for tables, lists, and common content.
- Support of dynamically generated charts and images.
- Support of insertion of outer documents and `HTML` blocks into a document.
- Support of multiple data sources (including of different types) for the generation of a single document.
- Built-in support of data relations (master-detail).
- Comprehensive support of various data manipulations such as grouping, sorting, filtering, and others directly in templates.

For a more comprehensive list of features, please visit [Feature Overview](https://docs.aspose.com/words/java/feature-overview/).

## Read & Write Document Formats

**Microsoft Word:** DOC, DOCX, RTF, DOT, DOTX, DOTM, DOCM FlatOPC, FlatOpcMacroEnabled, FlatOpcTemplate, FlatOpcTemplateMacroEnabled\
**OpenOffice:** ODT, OTT\
**WordprocessingML:** WordML\
**Web:** HTML, MHTML\
**Fixed Layout:** PDF\
**Text:** TXT
**Other:** MD

## Save Word Files As

**Fixed Layout:** XPS, OpenXPS, PostScript (PS)\
**Images:** TIFF, JPEG, PNG, BMP, SVG, EMF, GIF\
**Web:** HtmlFixed\
**Others:** PCL, EPUB, XamlFixed, XamlFlow, XamlFlowPack

## Read File Formats

**MS Office:** DocPreWord60
**eBook:** MOBI

## Supported Environments

- **Microsoft Windows:** Windows Desktop & Server (x86, x64)
- **macOS:** Mac OS X
- **Linux:** Ubuntu, OpenSUSE, CentOS, and others
- **Java Versions:** `J2SE 7.0 (1.7)`, `J2SE 8.0 (1.8)` or above.

## Get Started with Aspose.Words for Java

Aspose hosts all Java APIs at the [Aspose Repository](https://repository.aspose.com/webapp/#/artifacts/browse/tree/General/repo/com/aspose/aspose-words). You can easily use Aspose.Words for Java API directly in your Maven projects with simple configurations. For the detailed instructions please visit [Installing Aspose.Words for Java from Maven Repository](https://docs.aspose.com/words/java/installation/) documentation page.

## Printing Multiple Pages on One Sheet using Java

```java
// Open the document.
Document doc = new Document(dataDir + ""TestFile.doc"");

// Create a print job to print our document with.
PrinterJob pj = PrinterJob.getPrinterJob();

// Initialize an attribute set with the number of pages in the document.
PrintRequestAttributeSet attributes = new HashPrintRequestAttributeSet();
attributes.add(new PageRanges(1, doc.getPageCount()));

// Pass the printer settings along with the other parameters to the print document.
MultipagePrintDocument awPrintDoc = new MultipagePrintDocument(doc, 4, true, attributes);

// Pass the document to be printed using the print job.
pj.setPrintable(awPrintDoc);

pj.print();
```

[Product Page](https://products.aspose.com/words/java) | [Docs](https://docs.aspose.com/words/java/) | [Demos](https://products.aspose.app/words/family) | [API Reference](https://apireference.aspose.com/words/java) | [Examples](https://github.com/aspose-words/Aspose.Words-for-Java/tree/master/Examples) | [Blog](https://blog.aspose.com/category/words/) | [Search](https://search.aspose.com/) | [Free Support](https://forum.aspose.com/c/words) | [Temporary License](https://purchase.aspose.com/temporary-license)
"
apache/geode-examples,develop,67,80,2016-12-30T08:00:06Z,1432,1,Apache Geode Examples,geode,"<!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the ""License""); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

[<img src=""https://geode.apache.org/img/Apache_Geode_logo.png"" align=""center""/>](http://geode.apache.org)

[![Build Status](https://api.travis-ci.org/apache/geode-examples.svg?branch=develop)](https://travis-ci.org.apache.geode_examples) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

# Apache Geode examples

This is the home of Apache Geode examples that are bundled with the project.
Contributions<sup>[2]</sup> and corrections are welcome. Please talk to us
about your suggestions at [dev@geode.apache.org](mailto:dev@geode.apache.org)
or submit a [pull request](https://github.com/apache/geode/pull/new/develop).

# Apache Geode Version

Geode client code must link against the _same or older_ version of Geode as the Geode server it will connect to.

Add `-PgeodeRepositoryUrl= -PgeodeVersion=1.12.0` to your `./gradlew` command to specify which Geode client libraries to link, otherwise the default may be too new.

If the latest examples don't compile with your preferred version of Geode, use `git tag` to list the available versions, then check out a suitable tag e.g. `git checkout rel/v1.12.0`.

## Running an example

The gradle build will automatically download and install a Geode release in the
`build` directory. You can run an example with the following gradle targets:

* `build` - compiles the example and runs unit tests
* `start` - initializes the Geode cluster
* `run` - runs the example Application
* `stop` - shuts down the cluster
* `runAll` - invokes start, run, stop

The commands you need to invoke will be given in the `README.md` file. Sample
usage:

    $ ./gradlew :replicated:start
    $ ./gradlew :replicated:run
    $ ./gradlew :replicated:stop
    $ ./gradlew runAll
    $ ./gradlew runAll -PgeodeRepositoryUrl= -PgeodeVersion=1.12.0

## Catalog of examples

The following sections call out ready-made examples or new examples that could
be built. You may want to start your journey with the [Apache Geode in 15
minutes or
Less](https://geode.apache.org/docs/guide/13/getting_started/15_minute_quickstart_gfsh.html)
tutorial.

### Basics

*  [Replicated Region](replicated/README.md)
*  [Partitioned Region](partitioned/README.md)
*  [Put Multiple Values at Once](putall/README.md)
*  [Functions](functions/README.md)
*  [Persistence](persistence/README.md)
*  [OQL (Querying)](queries/README.md)

### Intermediate

*  [Serialization](serialization/README.md)
*  [Lucene Indexing](lucene/README.md)
*  [OQL Indexing](indexes/README.md)
*  [Cache Loader](loader/README.md)
*  [Cache Writer](writer/README.md)
*  [Cache Listeners](listener/README.md)
*  [Async Event Queues & Async Event Listeners](async/README.md)
*  [Continuous Querying](cq/README.md)
*  [Transaction](transaction/README.md)
*  [Eviction](eviction/README.md)
*  [Expiration](expiration/README.md)
*  [Overflow](overflow/README.md)
*  [Security & SSL](clientSecurity/README.md)
*  [Colocation](colocation/README.md)
*  Off-heap
*  [Rest](rest/README.md)

### Advanced

*  [Lucene Spatial Indexing](luceneSpatial/README.md)
*  [WAN Gateway](wan/README.md)
*  [Durable Messaging for Subscriptions](durableMessaging/README.md)
*  [Micrometer Metrics](micrometerMetrics/README.md)
*  Delta propagation
*  Network partition detection
*  D-lock
*  [Compression](compression/README.md)
*  Resource manager
*  PDX Advanced

### Use cases, integrations and external examples

This section has self-contained little projects that illustrate a use case or
an integration with other projects.

*  SpringBoot Application
*  HTTP Session replication
*  Memcached
*  Spark Connector

## Adding a new example

Follow this approach to add a new example:

* Create a subdirectory with a descriptive name like `cacheWriter`
* Create a `README.md` file in the example subproject to walk the user through the tutorial
* Create a Java class with a main method in the `org.apache.geode_examples.$name.Example` class
* Create a cluster initialization script in `scripts/start.gfsh`
* Create a cluster shutdown script in `scripts/stop.gfsh`
* Modify the top-level `settings.gradle` file to include subproject
* Modify this `README.md` file to include the new example in the catalog of examples

The scripts should contain `gfsh` commands for starting locators, servers, and
creating regions--everything that the example program will need to use. Where
appropriate you should also add unit tests. To customize the build you can add
a `build.gradle` file.

Verify that the examples build by executing `./gradlew runAll` from the root directory.
Note that the build may fail if you do not add ASF license headers or use the
correct formatting. You can fix formatting with `./gradlew spotlessApply`.

## References

- [1]  [https://cwiki.apache.org/confluence/display/GEODE/Criteria+for+Code+Submissions](https://cwiki.apache.org/confluence/display/GEODE/Criteria+for+Code+Submissions)
- [2]  [https://cwiki.apache.org/confluence/display/GEODE/How+to+Contribute](https://cwiki.apache.org/confluence/display/GEODE/How+to+Contribute)
- [3]  [https://www.apache.org/licenses/#clas](http://www.apache.org/licenses/#clas)

## Export Control

This distribution includes cryptographic software.
The country in which you currently reside may have restrictions
on the import, possession, use, and/or re-export to another country,
of encryption software. BEFORE using any encryption software,
please check your country's laws, regulations and policies
concerning the import, possession, or use, and re-export of
encryption software, to see if this is permitted.
See <https://www.wassenaar.org/> for more information.

The U.S. Government Department of Commerce, Bureau of Industry and Security (BIS),
has classified this software as Export Commodity Control Number (ECCN) 5D002.C.1,
which includes information security software using or performing
cryptographic functions with asymmetric algorithms.
The form and manner of this Apache Software Foundation distribution makes
it eligible for export under the License Exception
ENC Technology Software Unrestricted (TSU) exception
(see the BIS Export Administration Regulations, Section 740.13)
for both object code and source code.

The following provides more details on the included cryptographic software:

* Apache Geode is designed to be used with
  [Java Secure Socket Extension](https://docs.oracle.com/javase/8/docs/technotes/guides/security/jsse/JSSERefGuide.html) (JSSE) and
  [Java Cryptography Extension](https://docs.oracle.com/javase/8/docs/technotes/guides/security/crypto/CryptoSpec.html) (JCE).
  The [JCE Unlimited Strength Jurisdiction Policy](https://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html)
  may need to be installed separately to use keystore passwords with 7 or more characters.
* Apache Geode links to and uses [OpenSSL](https://www.openssl.org/) ciphers.
"
ScottOaks/JavaPerformanceTuning,master,664,318,2014-03-14T02:32:44Z,2852,2,Examples for O'Reilly & Associates Java Performance Tuning: The Definitive Guide,,
sryza/spark-ts-examples,master,122,79,2015-10-07T00:45:41Z,2131,11,Spark TS Examples,,"# spark-ts-examples

Description
-----------

Examples showing how to use the `spark-ts` time series library for Apache Spark.

Minimum Requirements
--------------------

* Java 1.8
* Maven 3.0
* Apache Spark 1.6.0

Using this Repo
---------------

### Building

We use [Maven](https://maven.apache.org/) for building Java / Scala. To compile and build
the example jar, navigate to the `jvm` directory and run:

    mvn package

### Running

To submit one of the Java or Scala examples to a local Spark cluster, run the following command
from the `jvm` directory:

    spark-submit --class com.cloudera.tsexamples.Stocks target/spark-ts-examples-0.0.1-SNAPSHOT-jar-with-dependencies.jar

You can substitute any of the Scala or Java example classes as the value for the `--class`
parameter.

To submit a Python example, run the following command from the `python` directory:

    spark-submit --driver-class-path PATH/TO/sparkts-0.3.0-jar-with-dependencies.jar Stocks.py

The `--driver-class-path` parameter value must point to the Spark-TS JAR file, which can be
downloaded from the spark-timeseries [Github repo](https://github.com/sryza/spark-timeseries).
"
Chainfire/libsuperuser,master,1569,640,2012-10-29T18:01:25Z,551,26,"Example code for How-To SU""""",,"# libsuperuser

[![ci][1]][2] [![](https://jitpack.io/v/eu.chainfire/libsuperuser.svg)](https://jitpack.io/#eu.chainfire/libsuperuser)

Example code for ""How-To SU""

For some outdated background details, see:

[http://su.chainfire.eu/](http://su.chainfire.eu/)

Even though its outdated with regards to usage of this library,
if you're unfamiliar with writing code for root usage, it is not
a bad idea to read it.

## License

Copyright &copy; 2012-2019 Jorrit *Chainfire* Jongma

This code is released under the [Apache License version 2.0](https://www.apache.org/licenses/LICENSE-2.0).

## Deprecated

This library is not under active development right now, as I've mostly
moved away from the Android world. While I believe it still works great,
if it breaks due to changes on new Android versions or root solutions,
fixes may be slow to appear.

If you're writing a new app, you might consider using
[TopJohnWu's libsu](https://github.com/topjohnwu/libsu) instead. Barring
some edge-cases (that I personally seem to be the biggest user of) the
capabilities should be similar, but it's likely to be better maintained.

## v1.1.0 update

It is now 2019, 7 years since the initial release of
*libsuperuser*, and I have *finally* gotten around to releasing v1.1.0,
and writing an updated how-to. See, I don't need reminding every 6
months.

This update brings support for commands returning an `InputStream` for
STDOUT, as well as adding per-line and buffered STDERR support to
various methods.

As `Shell.Interactive` can be a bit tricky to use and understand
callback and threading wise, especially when used from a background
thread, the `Shell.Threaded` subclass has been added. This class
maintains its own dedicated background thread, upon which all the
callbacks are executed.

`Shell.Interactive` (and `Shell.Threaded`) have gained synchronous
methods, that may be easier to handle than the asynchronous ones, when
used from a background thread. Obviously one cannot use them from the
main UI thread, as this would block the UI.

Last but not least, `Shell.Pool` has been added, which maintains a
pool of `Shell.Threaded` instances for your app to use; created, cached,
and closed on-demand. For new users, `Shell.Pool` is the place to start.

If you're looking at the source of the library, `Shell.java` has
become way too large and would look better broken up. This is
intentionally not done to maintain better backward compatibility
with old code, of which there is quite a bit.

## Upgrading from v1.0.0 to v1.1.0

No functionality has been removed, but some of the method signatures
have subtly changed, and a lot of methods have been deprecated
(though they will not be removed). The compiler will certainly tell
you about these. Some interface have been renamed, and some methods
were added to existing interfaces. All `Exception` based classes have
moved to inner classes of `Shell`.

`Shell.run(...)`, and all `Shell.SH.xxx` and `Shell.SU.xxx` methods
automatically redirect to their `Shell.Pool.xxx` counterparts. This
is a free speed-up for code using these methods. The redirection
can be turned off by calling `Shell.setRedirectDeprecated(false)`
from something like `Application::onCreate()`.

While most code should run the same without issue, you should
definitely double check, especially for complicated scripts or
commands that set specific environment variables.

`Shell.Interactive` should work exactly as it always has, but
since some threading-related code has changed internally, it is
always wise to check if everything still works as expected.

There is no need to migrate existing `Shell.Interactive` code to
`Shell.Threaded`, unless you want to use the functionality
provided by `Shell.Pool`. Be sure to read about the usage difference
between them below.

Last but not least, `minSdkVersion` was updated from 4 to 5, so
we're losing compatibility with Android 1.6 Donut users, sorry.

## Example project

The example project is very old, and does not follow current best
practises. While `PooledActivity` has been added demonstrating
some calls using `Shell.Threaded` and `Shell.Pool`, they aren't
particularly good. The old code demonstrating both legacy and
interactive modes remains present. Use the mode button at the bottom
to switch between activities.

## Basics

This page is not intended as a full reference, just to get you
started off. There are many methods and classes in the library
not explained here. For more advanced usages, consult the source
code - over 1/3rd of the lines belong to comments.

Some of the below may seem out-of-order, you might want to read
this entire section twice.

#### Blocking, threads, and ShellOnMainThreadException

Running subprocesses is expensive and timings cannot be predicted.
For something like running ""su"" even more so, as it can launch
a dialog waiting for user interaction. Many methods in this library
may be *blocking* (taking unpredictable time to return). When you
attempt to call any of these methods from the main UI thread, the
library will throw a `Shell.ShellOnMainThreadException` at you, if
your app is compiled in debug mode. (Note that this behavior can
be disabled through the `Debug.setSanityChecksEnabled(false)` call).

Methods that may throw this exception include any of the `run(...)`,
`waitFor...()`, and `close...()` methods, with the exception of
`closeWhenIdle()`.

The `Shell.Builder`, `Shell.Interactive` and `Shell.Threaded` classes
provide `addCommand(...)` methods, which run asynchronously and provide
completion callbacks. `addCommand(...)` can safely be called from
the main UI thread.

`Shell.Interactive` (and its `Shell.Threaded` subclass) is a class
wrapping a running instance of a shell (such as ""sh"" or ""su""),
providing methods to run commands in that shell and return the output
of each individual command and its exit code. As opening a shell
itself can be very expensive (especially so with ""su""), it is
preferred to use few interactive shells to run many commands rather
than executing a single shell for each individual command.

`Shell.Interactive` (and its `Shell.Threaded` subclass) uses two
background threads to continuously gobble the input from STDOUT and
STDERR. This is an (unfortunate) requirement to prevent the underlying
shell from possibly deadlocking if it produces large amounts of output.

When an instance of `Shell.Interactive` is created, it determines if
the calling thread has an Android `Looper` attached, if it does, it
creates an Android `Handler`, to which all callbacks (such as the
interfaces passed to `addCommand(...)`) are passed. The callbacks
are then executed on the original calling thread. If a `Looper` is
not available, callbacks are usually executed on the gobbler threads
(which increases the risk of deadlocks, and should be avoided), but
may also be executed on the calling thread (which can cause deadlocks
in your own threading code).

(Didn't make sense? Don't worry about it, and just follow the
advice and examples below)

#### `Shell.Interactive` vs `Shell.Threaded`

`Shell.Interactive`'s threading/callback model *can* be fine when it's
used from the main UI thread. As the main UI thread most certainly has
a `Looper`, there is no problem creating a `Handler`, and the callbacks
are run directly on the main UI thread. While this does allow you to
directly manipulate UI elements from the callbacks, it also causes
jank if your callbacks take too long to execute.

However, when `Shell.Interactive` is used from a background thread,
unless you manually create and manage a special secondary thread for
it (a `HandlerThread`), callbacks run on the gobbler threads, which is
potentially bad.

The `Shell.Threaded` subclass specifically creates and manages this
secondary `HandlerThread` for you, and guarantees all callbacks are
executed on that thread. This prevents most deadlock situations from
happening, and is consistent in its behavior across the board.

The drawback there is that you cannot directly manipulate UI elements
from the callbacks passed to `addCommand(...)` (or any other methods),
but that is probably not what you end up wanting to do in any
real-world app anyway. When the need arises, you can use something
like `Activity::runOnUiThread(...)` to call code that adjusts the UI.

Additionally, `Shell.Threaded` is easier to setup and supports pooling
via `Shell.Pool` (explained further below). The choice which to use
should be easy at this point, unless you have some very specific needs.

If you are porting from `Shell.Interactive` to `Shell.Threaded`, please
note that the behavior of the `close()` method is different between
the two. In `Shell.Interactive` it redirects to `closeImmediately()`,
which waits for all commands to complete and then closes the shell.
In `Shell.Threaded` it returns the shell to the pool if it is
part of one, and otherwise redirects to `closeWhenIdle()`, which
schedules the actual close when all commands have completed, but
returns immediately. This discrepancy is unfortunate but required
to maintain both good backwards compatibility and support pooling
with try-with-resources.

#### Common methods

Examples follow further below, which make use of pooling. But before
pooling can be explained, the common methods you will use with
different classes need a quick walk-through.

#### Common methods: `addCommand(...)`

The `Shell.Builder` (used to manually construct `Shell.Interactive`
and `Shell.Threaded` instances), `Shell.Interactive` and
`Shell.Threaded` classes provide `addCommand(...)` methods. These
run asynchronously and are safe to call from the main UI thread: they
return before the commands complete, and an optionally provided
callback is executed when the command does complete:

- `addCommand(Object commands)`

- `addCommand(Object commands, int code, OnResult onResultListener)`

`commands` accepts a `String`, a `List<String>`, or a `String[]`.

`onResultListener` is one of:

- `OnCommandResultListener2`, which buffers STDOUT and STDERR and
returns them to the callback all in one go

- `OnCommandLineListener`, which is unbuffered and is called once
for each line read from STDOUT or STDERR

- `OnCommandInputStreamListener`, which is called with an
`InputStream` you can use to read raw data from the shell. You
should continue reading the `InputStream` until *-1* is returned
(*not 0* as is sometimes done), or further commands on this shell
will not execute. You can call `InputStream::close()` to do this
for you. Additionally, if the shell is closed during reading, then
(and only then) an `IOException` will be thrown.

All of these provide an `onCommandResult` method that is called
with the `code` you passed in, and the exit code of the (last) of the
commands passed in. Note that the exit code will be < 0 if an error
occurs, such as the shell being closed.

The `addCommand(...)` calls will *not* be further explained in this
document, consult the example project (`InteractiveActivity.java`)
and the library source for further details.

#### Common methods: `run(...)`

The `Shell.Interactive`, `Shell.Threaded`, and `Shell.PoolWrapper`
classes provide `run(...)` methods. These run synchronously and are
*not* safe to call from the main UI thread: they return when the
command is completed:

- `int run(Object commands)`

- `int run(Object commands, List<String> STDOUT, List<String> STDERR, boolean clear)`

- `int run(Object commands, OnSyncCommandLineListener onSyncCommandLineListener)`

- `int run(Object commands, OnSyncCommandInputStreamListener onSyncCommandInputStreamListener)`

As before, `commands` accepts a `String`, a `List<String>`, or a `String[]`.

It should be obvious that these are simply the synchronous counterparts
of the asynchronous `addCommand(...)` methods.

Instead of calling a callback interface with the exit code, it is
returned directly, and instead of returning a negative exit code on
error, `Shell.ShellDiedException` is thrown.

#### Pooling

The `Shell.Pool` class provides shell pooling. It will create new
shell instances on-demand, and keep a set number of them around for
reuse later (4 by default for ""su"" instances, 1 for non-""su"" instances).

`Shell.Pool.SH` and `Shell.Pool.SU` are pre-created instances of
`Shell.PoolWrapper` for ""sh"" and ""su"", providing `get()` and the
earlier mentions `run(...)` methods for the pool.

The `get()` method can be used to retrieve a `Shell.Threaded` instance
from the pool, which you should later return to the pool by calling
it's `close()` method.

The `run(...)` methods, instead of operating on a specific
`Shell.Threaded` instance you manage, retrieve an instance from the
pool, proxies the call to that instance's `run(...)` method, and
then immediately returns the instance to the pool.

Sound complex? Maybe, but it all comes together so you can sprinkle
`Shell.Pool.SU.run(...)` calls throughout as many threads as you wish
(barring of course the main UI thread), running simultaneously or not,
with instances being created, reused, and closed automatically. All of
this without you ever having to worry about managing the instances,
and only having to catch a single `Shell.ShellDiedException`.

#### Examples

It is assumed all the code following is run from a background thread,
such as `Thread`, `AsyncTask`, or `(Job)IntentService`.

Running some basic commands:

```
try {
    List<String> STDOUT = new ArrayList<String>();
    List<String> STDERR = new ArrayList<String>();
    int exitCode;

    exitCode = Shell.Pool.SU.run(""echo nobody will ever see this"");
    // we have only an exit code

    exitCode = Shell.Pool.SU.run(""ls -l /"", STDOUT, STDERR, true);
    // exit code, and STDOUT/STDERR output

    exitCode = Shell.Pool.SU.run(""cat /init.rc"", new Shell.OnSyncCommandInputStreamListener() {
        @Override
        public void onInputStream(InputStream inputStream) {
            try {
                byte[] buf = new byte[16384];
                int r;
                while ((r = inputStream.read(buf)) >= 0) {
                    // do something with buf

                    // if we decide to abort before r == -1, call inputStream.close()
                }
            } catch (IOException e) {
                // shell died during read
            }
        }

        @Override
        public void onSTDERR(String line) {
            // hey, some output on STDERR!
        }
    });

    Shell.Pool.SU.run(""logcat -d"", new Shell.OnSyncCommandLineListener() {
        @Override
        public void onSTDOUT(String line) {
            // hey, some output on STDOUT!
        }

        @Override
        public void onSTDERR(String line) {
            // hey, some output on STDERR!
        }
    });

} catch (Shell.ShellDiedException e) {
    // su isn't present, access was denied, or the shell terminated while 'run'ing
}
```

When running multiple commands in quick succession, it is slightly
cheaper to `get()` an instance and `close()` it when done, and using
the returned instance. But keep in mind if there is a longer period
between your calls, and another thread wants to call su, the shell you
have not `close()`'d yet cannot be reused by that thread:

```
try {

    // get an instance from the pool
    Shell.Threaded shell = Shell.Pool.SU.get();
    try {

        // this is very useful
        for (int i = 0; i < 100; i++) {
            shell.run(""echo nobody will ever see this"");
        }

    } finally {
        // return the instance to the pool
        shell.close();
    }

} catch (Shell.ShellDiedException e) {
    // su isn't present, access was denied, or the shell terminated while 'run'ing
}
```

If you're targeting API >= 19 and Java 1.8, you can use
try-with-resources with `Shell.Threaded::ac()`, which casts the
instance to a `Shell.ThreadedAutoCloseable`:

```
try {

    // get an instance from the pool, automatically returning it at the end of the try block
    try (Shell.ThreadedAutoCloseable shell = Shell.Pool.SU.get().ac()) {

        // this is very useful
        for (int i = 0; i < 100; i++) {
            shell.run(""echo nobody will ever see this"");
        }

    }

} catch (Shell.ShellDiedException e) {
    // su isn't present, access was denied, or the shell terminated while 'run'ing
}
```

## libRootJava

For more advanced usages of root, such as running Java/Kotlin code as
root directly, please see my [libRootJava](https://github.com/Chainfire/librootjava)
library.

## Annotations

Nullity and thread annotations have recently been added.

Please note that *all* methods that *may* be problematic on the UI
thread have been marked as `@WorkerThread`. Some of these methods
can be called from the UI thread without issue in specific conditions.
If so, those conditions should be noted in the method's javadoc.

## Gradle

Root `build.gradle`:

```
allprojects {
    repositories {
        ...
        maven { url 'https://jitpack.io' }
    }
}
```

Module `build.gradle`:

```
dependencies {
    implementation 'eu.chainfire:libsuperuser:1.1.1'
}
```

[1]: https://github.com/Chainfire/libsuperuser/workflows/ci/badge.svg
[2]: https://github.com/Chainfire/libsuperuser/actions
"
royrusso/akka-java-examples,master,125,79,2014-03-01T21:12:02Z,208,1,Example implementation of various akka patterns in Java,,"Akka examples in Java
==============

A few examples using Akka with Java. These examples have basic structures in common:

* Coded in Java.
* Clustered Akka setup.
* Logback / SL4J Logger. Log file is under the root path: ``/logs``
* Akka configuration has most logging options turned on. (chatty)

All examples are runnable from within your IDE, by executing the ``Main`` method in the corresponding ``org.royrusso.app.System`` class.

Simple Akka Example
------------------

``/simple`` :: The simplest of Akka examples. Creates an Actor that processes a command.

Akka Parent-Child Actors
------------------

``/parent-child`` :: This example illustrates how you can configure an Akka cluster for hierarchical Actor relationships.
This cluster contains Parent Actors that, given a Command, send an Event to a Child Actor for processing.

Akka Persistence with EventSourcing
------------------

``/eventsourcing-persistence`` :: Usage of the new Akka Persistence module with Event Sourcing. An Akka Processor is responsible for processing non-persistent Commands
that generate Events. The Events are persisted, and then allowed to modify the state of the processor. Additionally, the events are broadcast over the eventstream.

During recovery, the system then loads the persisted Events and replays them to the processor.

On restart, the system will load its last known state from the latest Snapshot (``snapshot`` dir), and replay all Journaled (``journal`` dir) Events after that point.

Notes:

* LevelDB is used for persistence in this example.
* ``/snapshots`` contains the snapshot of the processor states.
* ``/journal`` contains the running journal of events.

Akka Persistent Channels
-----------------------

``persistent-channel`` :: Illustrates how to send/receive payloads between actors listening on a channel. Messages are persisted until there is a valid confirmation
of it being received by the destination Actor, and then deleted. This example also illustrates how the destination Actor may respond with an ack.


Akka Event-Bus
------------------

``/event-bus`` :: Here we show how the Akka EventStream can be used by Actors that are subscribed to listen for certain event types that are emitted by another actor.
"
geowarin/hibernate-examples,master,56,79,2013-01-19T16:57:46Z,199,1,Hibernate examples from my blog http://geowarin.wordpress.com,,"Hibernate examples
==================

Hibernate examples from my blog http://geowarin.wordpress.com/tag/hibernate"
jsflive/jsf22-examples,master,105,84,2013-03-21T20:52:37Z,402,4,JSFlive JSF 2.2 Examples,,"JSFlive JSF 2.2 Examples
========================

This is a collection of examples for the [JSFlive JSF 2.2 series](http://jsflive.wordpress.com/category/jsf-2-2/ ""JSFlive series on new features of JSF 2.2"").

Included examples:

* CollectionDataModel ([JSFlive post on JSF 2.2 CollectionDataModel](http://jsflive.wordpress.com/2013/03/30/jsf22-collectiondatamodel/ ""JSFlive JSF 2.2: CollectionDataModel""))
* Composite components in taglibs ([JSFlive post on JSF 2.2 Composite components in taglibs](http://jsflive.wordpress.com/2013/04/06/jsf22-cc-taglib/ ""JSFlive JSF 2.2: Composite components in taglibs""))
* Configurable resource directory ([JSFlive post on JSF 2.2 Configurable resource directory](http://jsflive.wordpress.com/2013/04/01/jsf22-config-resource-dir/ ""JSFlive JSF 2.2: Configurable resource directory""))
* Empty composite component attributes ([JSFlive post on JSF 2.2 Empty composite component attributes](http://jsflive.wordpress.com/2013/04/08/jsf22-empty-cc-attrs/ ""JSFlive JSF 2.2: Empty composite component attributes""))
* File upload with h:inputFile ([JSFlive post on JSF 2.2 File upload with h:inputFile](http://jsflive.wordpress.com/2013/04/23/jsf22-file-upload/ ""JSFlive JSF 2.2: File upload with h:inputFile""))
* HTML5 friendly markup ([JSFlive post on JSF 2.2 HTML5 friendly markup](http://jsflive.wordpress.com/2013/08/08/jsf22-html5/ ""JSFlive JSF 2.2: HTML5 friendly markup""))
* Reset input fields ([JSFlive post on JSF 2.2 Reset input fields](http://jsflive.wordpress.com/2013/06/20/jsf-22-reset-values/ ""JSFlive JSF 2.2: Reset input fields""))
* View actions ([JSFlive post on JSF 2.2 view actions](http://jsflive.wordpress.com/2013/03/22/jsf22-view-actions/ ""JSFlive JSF 2.2: View actions""))
* View scope for CDI ([JSFlive post on JSF 2.2 View scope for CDI](http://jsflive.wordpress.com/2013/07/17/jsf22-cdi-view-scope/ ""JSFlive JSF 2.2: View scope for CDI""))
"
tfnico/guava-examples,master,81,69,2010-06-15T15:00:04Z,131,0,Examples of Google Guava usage,,
PacktPublishing/Mastering-Distributed-Tracing,master,264,92,2018-08-10T11:10:46Z,239,1,"Mastering Distributed Tracing"" by Yuri Shkuro"," published by Packt""","


# Mastering Distributed Tracing

by [Yuri Shkuro](https://www.shkuro.com). Illustrations by [Lev Polyakov](https://polyakovproductions.com/).

Published by: Packt Publishing (2019)

This is the code repository for the book _[Mastering Distributed Tracing](https://www.packtpub.com/networking-and-servers/mastering-distributed-tracing?utm_source=github&utm_medium=repository&utm_campaign=9781788628464)_. It contains all the supporting project files necessary to work through the book from start to finish.

## About the book

_Mastering Distributed Tracing_ provides comprehensive coverage of the tracing field. Solve problems through code instrumentation with open standards, and learn how to profile complex systems. The book will also prepare you to operate and enhance your own tracing infrastructure.

## Navigation

* [Chapter 4: Instrumentation Basics with OpenTracing](./Chapter04)
* [Chapter 5: Instrumentation of Asynchronous Applications](./Chapter05)
* [Chapter 7: Tracing with Service Mesh](./Chapter07)
* [Chapter 11: Integration with Metrics and Logs](./Chapter11)
* [Chapter 12: Gathering Insights Through Data Mining](./Chapter12)
### Download a free PDF

 <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>
<p align=""center""> <a href=""https://packt.link/free-ebook/9781788628464"">https://packt.link/free-ebook/9781788628464 </a> </p>"
quarkus-for-spring-developers/examples,main,39,17,2021-01-29T14:44:20Z,1673,0,Example code for the Quarkus for Spring Developers eBook,event-driven examples java kubernetes kubernetes-native quarkus spring spring-boot,"Example code for the [Quarkus for Spring Developers](https://red.ht/quarkus-spring-devs) eBook. Code is organized by chapter. Each project is self-contained, meaning there is no parent/child structure amongst projects.

# Versions
Whenever possible, versions of Quarkus and Spring used in these examples are kept up-to-date as much as possible. The frameworks may have evolved since the book's writing and perhaps there is a better/different way to do something than what is shown in the book's code excerpts. The code in this repository will be kept in sync with what is shown in the book so that those examples may be replicated successfully. As new editions of the book are published, examples may be changed to reflect new patterns.

Here is a summary of some of the new features which may affect the examples in the book. The examples in this repo won't be updated to take advantage of these capabilities until a new revision of the book is released.

## Quarkus
- [RESTEasy Reactive - to block or not to block](https://quarkus.io/blog/resteasy-reactive-smart-dispatch/)
    - New features in RESTEasy Reactive allow Quarkus to automatically detect whether a method is blocking or non blocking
    - Starting with Quarkus 2.2, this means that the `@Blocking` annotation used in many of the Quarkus examples is no longer needed. Quarkus will ""figure it out"" on its own.
- Panache Reactive with Hibernate Reactive
    - The Quarkus reactive examples in chapter 4 using Panache Reactive currently use a custom built class for implementing transaction rollback within tests.
    - Quarkus now includes an `@TestReactiveTransaction` annotation that can automatically rollback transactions within tests, similar to how the `@TestTransaction` annotation works in the Hibernate ORM examples in chapter 4.
- `quarkus.hibernate-orm.database.generation` will default to `drop-and-create` when Dev Services is in use.
- `@NativeImageTest` has been deprecated in favor of `@QuarkusIntegrationTest`
- The `maven-failsafe-plugin` has been moved out of the `native` Maven profile and into the main profile.

## Spring
- The implementation of [`chapter-5`s Spring Kafka test example](chapter-5/chapter-5-spring-kafka-streams/src/test/java/org/acme/DockerComposeBase.java) had to be modified to use [`KafkaContainer`](https://www.testcontainers.org/modules/kafka/) instead of [`DockerComposeContainer`](https://www.testcontainers.org/modules/docker_compose/) due to docker compose ""flakiness"" that was happening within the GitHub Actions CI/CD process. The Spring Kafka tests were continually failing within the CI/CD process.
- Spring Boot 3/Spring 6/Spring Cloud 2022.0 has shipped but would have an impact on the examples in the book, plus would require Java 17, therefore the examples will not yet be updated to those versions.

# Book Chapter Text
The table below describes the versions of the example snippets used in the book's chapter text:

| Framework | Version |
| --------- | ------- |
| Quarkus   | `2.1.4.Final` |
| Spring Boot | `2.5.4` |

# Examples Repo
The table below describes the versions of the examples in this repo:

| Framework | Version       |
| --------- |---------------|
| Quarkus   | `2.16.12.Final` |
| Spring Boot | `2.7.16`       |

# Chapter List
- Chapter 1 - Introducing Quarkus (No example code)
- [Chapter 2 - Getting Started with Quarkus](chapter-2/README.md)
- [Chapter 3 - Building RESTful Applications](chapter-3/)
- [Chapter 4 - Persistence](chapter-4/)
- [Chapter 5 - Event Driven Services](chapter-5/)
- [Chapter 6 - Building Applications for the Cloud](chapter-6/)
"
udacity/nd035-c1-spring-boot-basics-examples,master,103,319,2020-06-17T22:38:42Z,554,0,,,
nurkiewicz/rxjava-book-examples,master,171,65,2016-11-12T17:03:04Z,129,1,Source code of all examples from Reactive Programming with RxJava book,,"# Source code of examples from _Reactive Programming with RxJava_

Book is available on [O'Reilly](http://shop.oreilly.com/product/0636920042228.do) and [Amazon](http://amzn.to/2gJ6Vhx).

If you find any example incomplete or broken, please [submit a PR](https://github.com/nurkiewicz/rxjava-book-examples/pulls) or [create an issue](https://github.com/nurkiewicz/rxjava-book-examples/issues/new).

* [Chapter 1](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch1)
* [Chapter 2](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch2)
* [Chapter 3](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch3)
* [Chapter 4](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch4)
* [Chapter 5](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch5)
* [Chapter 6](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch6)
* [Chapter 7](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch7)
* [Chapter 8](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch8)
* [Chapter 9](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/ch9)
* [Appendix 1](https://github.com/nurkiewicz/rxjava-book-examples/tree/master/src/test/java/com/oreilly/rxjava/appendix1)

# Remarks

1. Some examples were slightly modified to support newer versions of dependent libraries
2. Java projects can't simply import Android `.aar` libraries. Therefore parts of [RxAndroid](https://github.com/ReactiveX/RxAndroid) and [RxBinding](https://github.com/JakeWharton/RxBinding) source code were copied directly.
"
bonigarcia/webdrivermanager-examples,master,112,58,2016-11-16T08:05:09Z,777,0,JUnit tests with Selenium WebDriver and WebDriverManager,java junit junit5 selenium selenium-webdriver webdrivermanager,"[![Maven Central](https://img.shields.io/maven-central/v/io.github.bonigarcia/webdrivermanager.svg)](https://search.maven.org/#search%7Cga%7C1%7Cg%3Aio.github.bonigarcia%20a%3Awebdrivermanager)
[![Build Status](https://github.com/bonigarcia/webdrivermanager-examples/workflows/build/badge.svg)](https://github.com/bonigarcia/webdrivermanager-examples/actions)
[![badge-jdk](https://img.shields.io/badge/jdk-11-green.svg)](https://www.oracle.com/java/technologies/downloads/)
[![License badge](https://img.shields.io/badge/license-Apache2-green.svg)](https://www.apache.org/licenses/LICENSE-2.0)
[![Backers on Open Collective](https://opencollective.com/webdrivermanager/backers/badge.svg)](#backers)
[![Sponsors on Open Collective](https://opencollective.com/webdrivermanager/sponsors/badge.svg)](#sponsors)
[![Support badge](https://img.shields.io/badge/stackoverflow-webdrivermanager_java-green.svg?logo=stackoverflow)](https://stackoverflow.com/questions/tagged/webdrivermanager-java)
[![Twitter Follow](https://img.shields.io/twitter/follow/boni_gg.svg?style=social)](https://twitter.com/boni_gg)

# WebDriverManager Examples [![][Logo]][GitHub Repository]

This repository contains JUnit examples to automate the [Selenium WebDriver] driver management using [WebDriverManager]. These examples are open-source, released under the terms of [Apache 2.0 License].

## Usage

In order to use WebDriverManager from tests in a Maven project, you need to add the following dependency in your `pom.xml`:

```xml
<dependency>
    <groupId>io.github.bonigarcia</groupId>
    <artifactId>webdrivermanager</artifactId>
    <version>${wdm.version}</version>
    <scope>test</scope>
</dependency>
```

... or in a Gradle project:

```
dependencies {
    testImplementation(""io.github.bonigarcia:webdrivermanager:${wdm.version}"")
}
```

Then you can let WebDriverManager to manage the drivers required by Selenium WebDriver (e.g., chromedriver, geckodriver). For example, as a JUnit test using Chrome browser:

```java
class ChromeTest {

    WebDriver driver;

    @BeforeAll
    static void setupClass() {
        WebDriverManager.chromedriver().setup();
    }

    @BeforeEach
    void setupTest() {
        driver = new ChromeDriver();
    }

    @AfterEach
    void teardown() {
        driver.quit();
    }

    @Test
    void test() {
        // Your test code here
    }

}
```

... or using Firefox:

```java
class FirefoxTest {

    WebDriver driver;

    @BeforeAll
    static void setupClass() {
        WebDriverManager.firefoxdriver().setup();
    }

    @BeforeEach
    void setupTest() {
        driver = new FirefoxDriver();
    }

    @AfterEach
    void teardown() {
        driver.quit();
    }

    @Test
    void test() {
        // Your test code here
    }

}
```

## Help

If you have questions on how to use WebDriverManager properly with a special configuration or suchlike, please consider asking a question on [Stack Overflow] and tag it with  *webdrivermanager-java*.

## Support

WebDriverManager is part of [OpenCollective], an online funding platform for open and transparent communities. You can support the project by contributing as a backer (i.e., a personal [donation] or [recurring contribution]) or as a [sponsor] (i.e., a recurring contribution by a company).

### Backers

<a href=""https://opencollective.com/webdrivermanager"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/backers.svg?width=890""></a>

### Sponsors

<a href=""https://opencollective.com/webdrivermanager/sponsor/0/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/0/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/1/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/1/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/2/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/2/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/3/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/3/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/4/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/4/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/5/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/5/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/6/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/6/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/7/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/7/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/8/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/8/avatar.svg""></a>
<a href=""https://opencollective.com/webdrivermanager/sponsor/9/website"" target=""_blank""><img src=""https://opencollective.com/webdrivermanager/sponsor/9/avatar.svg""></a>

## About

WebDriverManager (Copyright &copy; 2015-2023) is a personal project of [Boni Garcia] licensed under [Apache 2.0 License].

[Apache 2.0 License]: https://www.apache.org/licenses/LICENSE-2.0
[Boni Garcia]: https://bonigarcia.github.io/
[Selenium WebDriver]: https://docs.seleniumhq.org/projects/webdriver/
[WebDriverManager]:https://github.com/bonigarcia/webdrivermanager/
[Logo]: https://bonigarcia.github.io/img/webdrivermanager.png
[GitHub Repository]: https://github.com/bonigarcia/webdrivermanager-examples
[Stack Overflow]: https://stackoverflow.com/questions/tagged/webdrivermanager-java
[OpenCollective]: https://opencollective.com/webdrivermanager
[donation]: https://opencollective.com/webdrivermanager/donate
[recurring contribution]: https://opencollective.com/webdrivermanager/contribute/backer-8132/checkout
[sponsor]: https://opencollective.com/webdrivermanager/contribute/sponsor-8133/checkout
"
roskenet/spring-javafx-examples,master,156,66,2017-03-16T16:24:26Z,100,4,Example apps for springboot-javafx-support. See,examples fxml javafx spring springboot,"# Examples how to use springboot-javafx-support

See: https://www.felixroske.de/page/programmierung/index.html

"
mfaisalkhatri/rest-assured-examples,master,157,65,2021-11-19T19:26:29Z,4505,1,Learn API testing using rest-assured framework.,api-automation apitesting automation-test hacktoberfest learning-by-doing rest-assured test-automation testing testing-framework tutorial,"[![Java CI with Maven](https://github.com/mfaisalkhatri/rest-assured-examples/actions/workflows/maven.yml/badge.svg)](https://github.com/mfaisalkhatri/rest-assured-examples/actions/workflows/maven.yml)
![Open Source Love](https://badges.frapsoft.com/os/v1/open-source.svg?v=103)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

## Don't forget to give a :star: to make the project popular.

## :question: What is this Repository about?

This project is the outcome of my self-learning about the API Testing Automation framework - Rest-assured.
I heard a lot about Rest-Assured and how it made the QA's life easier by helping them to run all the tedious API tests
in an efficient way.
Hence, I started learning about the framework and have documented all my learnings in this repository with all
example code from writing basic tests to running end to end API automation tests.

## :briefcase: What does this repo contain?

- This repo contains example codes of API Tests using Rest-Assured.
- `Hamcrest Matchers` are used for assertions.
- [TestNG](https://testng.org) Listeners are used to capture the events in logs.
- `Log4j` is used to capture logs.
- [Lombok](https://projectlombok.org/) is used to generate Getter and Setters automatically for post body
  requests.
- FAKE Rest APIs on [Reqres.in](https://reqres.in/) is used for testing.
- End to End scenarios have been added for
  the [restful booker APIs](https://restful-booker.herokuapp.com/apidoc/index.html).

## :hammer_and_wrench: Talking more about the Scenarios Covered in this project:

You will get the answers to the following questions and its respective working code example with rest-assured
framework in this repository:

- How to write tests for `Get` requests?
- How to write tests for `POST` requests?
- How to write tests for `PUT` requests?
- How to write tests for `PATCH` requests?
- How to write tests for `DELETE` requests?
- How to handle the `authentication` requests?
- How to write tests for `SOAP API` requests?
- How to verify the Response Body?
- How to verify the Response Status Code?
- How to verify the Response headers?
- How to extract value from Response Body?
- How to perform assertions using `Hamcrest Matchers`?
- How to create `POJO` for passing values to request body?
- How to use `Lombok` to generate `Getters` and `Setters`?
- How to use `Lombok` for writing the builder pattern code?
- How to use Builder Pattern for test data generation using [Data Faker](https://github.com/datafaker-net/datafaker)?
- How to write end-to-end api tests?
- How to perform `JSON Schema Validation`?

## :writing_hand: Blog Links

- [What is API Testing?](https://mfaisalkhatri.github.io/2020/08/08/apitesting/)
- [End to End API testing using rest-assured](https://medium.com/@iamfaisalkhatri/end-to-end-api-testing-using-rest-assured-a58c4ea80255)
- [How to perform JSON Schema Validation using Rest-Assured?](https://medium.com/@iamfaisalkhatri/how-to-perform-json-schema-validation-using-rest-assured-64c3b6616a91)
- [API Testing using RestAssured and OkHttp](https://mfaisalkhatri.github.io/2020/05/29/restassuredokhttp/)

## :movie_camera: Tutorial Video

[![Watch the video](https://img.youtube.com/vi/xLKpdQE0oKY/hqdefault.jpg)](https://www.youtube.com/watch?v=xLKpdQE0oKY&t=1s)
[![Watch the video](https://img.youtube.com/vi/AFQSolEeu74/hqdefault.jpg)](https://www.youtube.com/live/AFQSolEeu74?si=8WROMbunjUuzqqQj&t=1)


## :question: Need Assistance?

- Discuss your queries by writing to me @ `mohammadfaisalkhatri@gmail.com`
  OR ping me on any of the social media sites using the below link:
    - [Linktree](https://linktr.ee/faisalkhatri)

## :computer: Paid Trainings

- Contact me for Paid trainings related to Test Automation and Software Testing,
  mail me @ `mohammadfaisalkhatri@gmail.com` or ping me on [LinkedIn](https://www.linkedin.com/in/faisalkhatri/)

## :thought_balloon: Checkout the blogs related to Testing written by me on the following links:

- [Medium Blogs](https://medium.com/@iamfaisalkhatri)
- [LambdaTest Blogs](https://www.lambdatest.com/blog/author/mfaisalkhatri/)
- [My Website](https://mfaisalkhatri.github.io)
"
mattia-battiston/clean-architecture-example,master,1624,379,2016-03-10T15:34:36Z,897,5,Clean Architecture Example (Java): Example of what clean architecture would look like (in Java),,"# clean-architecture-example
This is an example project to show what Clean Architecture would look like (in Java).

It was originally created to go together with [this presentation](http://www.slideshare.net/mattiabattiston/real-life-clean-architecture-61242830)

**Table of Contents**
* [Why Clean Architecture?](#why-clean-architecture)
* [Application Structure](#application-structure)
* [Testing Strategy](#testing-strategy)
* [Building and Running the application](#building-and-running-the-application)
* [The example domain](#the-example-domain)
* [Resources](#resources)
* [Contacts](#contacts)

***

## Why Clean Architecture?
> The center of your application is not the database. Nor is it one or more of the frameworks you may be using. **The center of your application is the use cases of your application**  -  _Unclebob_ ([source](https://blog.8thlight.com/uncle-bob/2012/05/15/NODB.html ""NODB""))

Clean architecture helps us solve, or at least mitigate, these common problems with architecture:
* **Decisions are taken too early**, often at the beginning of a project, when we know the least about the problem that we have to solve
* **It's hard to change**, so when we discover new requirements we have to decide if we want to hack them in or go through an expensive and painful re-design. We all know which one usually wins. _The best architectures are the ones that allow us to defer commitment to a particular solution and let us change our mind_
* **It's centered around frameworks**. Frameworks are tools to be used, not architectures to be conformed to. Frameworks often require commitments from you, but they don’t commit to you. They can evolve in different directions, and then you’ll be stuck following their rules and quirks
* **It's centered around the database**. We often think about the database first, and then create a CRUD system around it. We end up using the database objects everywhere and treat everything in terms of tables, rows and columns
* **We focus on technical aspects** and when asked about our architecture we say things like “it’s servlets running in tomcat with an oracle db using spring”
* **It's hard to find things** which makes every change longer and more painful
* **Business logic is spread everywhere**, scattered across many layers, so when checking how something works our only option is to debug the whole codebase. Even worse, often it's duplicated in multiple places
* **Forces/Encourages slow, heavy tests**. Often our only choice for tests is to go through the GUI, either because the GUI has a lot of logic, or because the architecture doesn't allow us to do otherwise. This makes tests slow to run, heavy and brittle. It results in people not running them and the build beind broken often
* **Infrequent deploys** because it's hard to make changes without breaking existing functionalities. People resort to long-lived feature branches that only get integrated at the end and result in big releases, rather than small incremental ones

Clean architecture gives us all these benefits:
* **Effective testing strategy** that follows the [testing pyramid](http://martinfowler.com/bliki/TestPyramid.html) and gives us a fast and reliable build
* **Frameworks are isolated** in individual modules so that when (not if) we change our mind we only have to change one place, with the rest of the app not even knowing about it
* **Independent from Database**, which is treated just like any other data provider. Our app has real use cases rather than being a CRUD system
* **Screaming architecture** a.k.a. it screams its intended usage. When you look at the package structure you get a feel for what the application does rather than seeing technical details
* **All business logic is in a use case** so it's easy to find and it's not duplicated anywhere else
* **Hard to do the wrong thing** because modules enforce compilation dependencies. If you try to use something that you're not meant to, the app doesn't compile
* **We're always ready to deploy** by leaving the wiring up of the object for last or by using feature flags, so we get all the benefits of continuous integration (no need for feature branches)
* **Swarming on stories** so that different pairs can easily work on the same story at the same time to complete it quicker
* **Good monolith** with clear use cases that you can split in microservices later one, once you've learnt more about them

Of course, it comes at a cost:
* **Perceived duplication of code**. Entities might be represented differently when used in business logic, when dealing with the database and when presenting them in a json format. You might feel like you're duplicating code, but you're actually favouring _decoupling over DRY_
* **You need interesting business logic** to ""justify"" the structure. If all you do in your use case is a one-line method to read or save from a database, then maybe you can get away with something simpler

***

## Application Structure

<img src=""docs/images/clean-architecture-diagram-1.png"" alt=""clean-architecture-diagram-1.png"" width=""700"">
<img src=""docs/images/clean-architecture-diagram-2.png"" alt=""clean-architecture-diagram-2.png"" width=""700"">

##### Core: Entities
* Represent your domain object
* Apply only logic that is applicable in general to the whole entity (e.g. validating the format of an hostname)
* Plain java objects: no frameworks, no annotations

##### Core: Use Cases
* Represent your business actions, it’s what you can do with the application. Expect one use case for each business action
* Pure business logic, plain java (expect maybe some utils libraries like StringUtils)
* Define interfaces for the data that they need in order to apply some logic. One or more dataproviders will implement the interface, but the use case doesn’t know where the data is coming from
* The use case doesn't know who triggered it and how the results are going to be presented (e.g. could be on a web page, or returned as json, or simply logged, etc.)
* Throws business exceptions

##### Dataproviders
* Retrieve and store data from and to a number of sources (database, network devices, file system, 3rd parties, etc.)
* Implement the interfaces defined by the use case
* Use whatever framework is most appropriate (they are going to be isolated here anyway)
* Note: if using an ORM for database access, here you'd have another set of objects in order to represent the mapping to the tables (don't use the core entities as they might be very different)

##### Entrypoints
* Are ways to interact with the application, and typically involve a delivery mechanism (e.g. REST APIs, scheduled jobs, GUI, other systems)
* Trigger a use case and convert the result to the appropriate format for the delivery mechanism
* A GUI would use MVC (or MVP) in here; the controller would trigger a use case

##### Configuration
* Wires everything together
* Frameworks (e.g. for dependency injection) are isolated here
* Has the ""dirty details"" like Main class, web server configuration, datasource configuration, etc.

##### _Examples_
<img src=""docs/images/example-1.png"" alt=""clean-architecture-diagram-1.png"" width=""700"">
<img src=""docs/images/example-2.png"" alt=""clean-architecture-diagram-1.png"" width=""700"">


***

## Testing Strategy
<img src=""docs/images/testing-strategy.png"" alt=""testing-strategy.png"" width=""700"">

##### Unit Tests
* for TDD (a.k.a. Tests first, to drive design)
* Cover every little detail, aim for 100% coverage
* “Dev to dev” documentation: What should this class do?
* Test individual classes in isolation, very fast

##### Acceptance Tests
* for BDD (a.k.a. Conversations with the stakeholders)
* Demonstrate and document business requirements
* “Business” documentation: What does the system do?
* Test a use case in isolation, very fast (no GUI, no DB, etc.)
* Use your favourite BDD framework (we use [Yatspec](https://github.com/bodar/yatspec))

##### Integration Tests
* Test integration with slow parts (http, database, etc.)
* “Dev” documentation: Does this work as expected?
* Test one layer in isolation (e.g. only rest endpoint, or only data provider). Slow
* Use whatever library makes it easy (e.g. Spring MockMVC; in-memory db)

##### End-to-end Tests
* Test only the critical journeys (e.g. most common happy path)
* Demonstrate “business” end-to-end requirement
* Start the whole app, very slow. Keep these to a minimum

***

## Building and Running the application
* building the application:
```
./gradlew clean build
```
* running the application (from the jar, after having built it):
```
java -jar application/build/clean-architecture-example.jar
```
* running the application (on the fly):
```
./gradlew bootRun
```
* running the application (in the IDE): open and run the main class
```
com.clean.example.configuration.Application
```
* more info on available tasks:
```
./gradlew tasks
```

Once the application is running, you can:
* open <http://localhost:8080/broadbandaccessdevice/device1.exlon.com/> and you should see some json
* look at the log and you should see a scheduled job running every 5 seconds (it prints something like _""Job Starting: ReconcileBroadbandAccessDeviceJob...""_)

##### Importing the project in IntelliJ
* Simply open the _build.gradle_ file and IntelliJ should load everything

##### Importing the project in Eclipse
* Make sure you've installed the Gradle plugin
* ""Import existing project"", choose Gradle, select the main folder and follow the instructions

***

## The example domain
<img src=""docs/images/example-domain.png"" alt=""example-domain.png"" width=""700"">

This example application is a simplified version of a real production application that we develop at Sky. The domain is a telecommunication domain. It's a Network Inventory software that has the fulfill the following use cases:
* Capacity of an exchange: how much available space have we got in a particular exchange? can we take on more customers in that area?
* Reconcile devices: has anything changed in reality that we don't know of?
* Get details of a particular device, by hostname

***

## Resources

##### Presentation
* Real Life Clean Architecture http://www.slideshare.net/mattiabattiston/real-life-clean-architecture-61242830

##### Blogs & Articles
* The Clean Architecture https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html
* Screaming Architecture http://blog.8thlight.com/uncle-bob/2011/09/30/Screaming-Architecture.html
* NODB https://blog.8thlight.com/uncle-bob/2012/05/15/NODB.html
* Hexagonal Architecture http://alistair.cockburn.us/Hexagonal+architecture

##### Videos & Presentations
* Clean Coders ep. 7: Architecture, Use Cases, and High Level Design https://cleancoders.com/episode/clean-code-episode-7/show
* Robert C. Martin - Clean Architecture https://vimeo.com/43612849
* Robert C. Martin - Clean Architecture and Design https://www.youtube.com/watch?v=Nsjsiz2A9mg

***

## Contacts
For any question or feedback (really appreciated!) feel free to contact me:
* Email: mattia _(dot)_ battiston _(at)_ gmail.com
* Twitter: [@BattistonMattia](https://twitter.com/BattistonMattia)
* Linkedin: [Mattia Battiston](https://uk.linkedin.com/in/mattiabattiston)
"
jsvitak/jbpm-6-examples,master,32,127,2013-05-27T10:18:05Z,740,4,Examples how to use jBPM 6.,,"jbpm-6-examples
===============

Web examples for jBPM 6.2. Distributed under Apache Software License 2.0. Steps to try them can be found in their folders.

- rewards-basic
 - demonstrates jBPM EJB services in combination with servlets and JSP

- rewards-cdi-jsf
 - demonstrates jBPM CDI services in combination with CDI beans and JSF

"
OmarElgabry/DesignPatterns,master,295,117,2015-07-20T21:16:38Z,1645,2,Examples of Design Patterns in Java,design-patterns java,"![Screenshot](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/logo.png)

# Design Patterns

Design Patterns are solutions to common software design problems that occur over and over in software development.

## Index
+ [Structural](#structural)
+ [Behavioral](#behavioral)
+ [Creational](#creational)
+ [Support](#support)
+ [Contribute](#contribute)
+ [License](#license)


## Structural<a name=""structural""></a>

### Adapter
An adapter helps to join two incompatible interfaces to work together. So, if you have an interface with implementing classes. If you were asked later to add additional sub class(es), but they have incompatible Interface, then, adapter pattern could be useful. There are two structures:
#### Object
The Adapter has a reference to the incompatible object.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/adapter.object.png)

#### Interface
The Adapter has a reference to the incompatible interface.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/adapter.interface.png)

### Decorator
The decorator pattern extends the functionality of an object dynamically.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/decorator.png)

### Bridge
Decouples an abstraction from its implementation so that the two can vary independently. As an example, If you have a class called Rectangle. This class could have two different implementations, Red Rectangle and Blue one. Instead of Inheriting from Rectangle class, one for blue rectangle and another for red, We could instead pull out these implementations and use Composition over Inheritance.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/bridge.png)

### Composite
It's used to create a tree structure of group of objects. So, an Object can be collection of other objects, where objects share a common interface that defines the common operations.

An object can have a collection of objects called _Composite_ Or _Node_, while objects that can't have other objects(at the lowest level) called _Leaf_. _Composite_ object can have leafs or other composites.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/composite.png)

## Behavioral<a name=""behavioral""></a>
### Strategy
Strategy is used when you want to extend the behavior of an Object, where this behavior could vary during the run time. If multiple objects need to use the same behavior(algorithm), we get the benefit of code reuse too.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/startegy.png)
### Dependency injection
Dependency is used when you want to separate the dependencies of an Object, and pass them to dependent object during run time. The dependent object does not need to know how to construct the dependencies nor which actual dependencies it is using.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/dependency.png)

### Iterator
This pattern is used to get a way to access the elements of a collection object in sequential manner without exposing its underlying representation. In this snippet, I am using Java's built-in Iterable & Iterator classes.

#### Separate Class
![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/iterator.separate.png)

#### Single Class 
![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/iterator.single.png)

### Observer
Observer pattern is used such that if an object is changed, its dependents objects get notified of that change, Thus, there is 1:M Relationship. As an example, having a Publisher that publish news to the Subscribers, Whenever any new updates or data added, the Subscribers get notified. In this snippet, I am using Java's Observer and Observable classes.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/observer.png)

### State
A class behavior may change based on set of states either made by user, or internally by the system. In this pattern, We encapsulate each state. The user doesn't need to know about each state, the user only performs some actions which in turn may change the state of the object.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/state.png)

## Creational<a name=""creational""></a>

### Factory 
This pattern defines a way for creating object(s) during run time.

#### Factory Method
Factory Method is a method used to create object(s) of a certain type(interface) during run time.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/factory.method.png)

#### Abstract Factory
Factory Method is an object used to create a set of related objects during run time.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/factory.abstract.png)

### Singleton
 The Singleton Pattern is a pattern that ensures that there is only ever one single instance of a class, And it provides a global way to get to that instance.

#### Classic
This is the basic implementation

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/singleton.classic.png)

#### Eager Instantiation
If you are concerned about synchronization, eager intantiation could be useful as long as you know you'll always need to instantiate the object, and the object doesn't take a lot of time to load.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/singleton.eager.png)

#### Synchronized 
Another solution for synchronization using ```synchronized``` method. But, you will pay for it's pitfall; Synchronized code takes a lot longer to run.

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/singleton.synchronized.png)

### Prototype
The Portotype Pattern used when you want to hide the complexity of creating new instance same as in Factory Pattern, and Creating an object is an expensive operation. Thus, copy an existing object is much efficient. It uses Java's Cloneable Interface for cloning objects.
 
#### Abstract Class
Using abstract class

![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/prototype.abstract.png)

#### Interface
Using Interface
 
![Class Diagram](https://raw.githubusercontent.com/OmarElGabry/JavaDesignPatterns/master/diagrams/prototype.interface.png)

## Support
I've written these snippets in my free time during my studies. If you find it useful, please support the project by spreading the word.

## Contribute <a name=""contribute""></a>

Contribute by creating new issues, sending pull requests on Github or you can send an email at: omar.elgabry.93@gmail.com

## License
Built under [MIT](http://www.opensource.org/licenses/mit-license.php) license.
"
vlingo/xoom-examples,master,185,45,2018-08-12T03:46:35Z,18628,5,The VLINGO XOOM examples demonstrating features and functionality available in the reactive components. See each of the submodules for specific examples.,actor-framework actor-model actors example-code example-project examples java jvm,"# xoom-examples

[![Gitter chat](https://badges.gitter.im/gitterHQ/gitter.png)](https://gitter.im/vlingo-platform-java/examples)
[![Build](https://github.com/vlingo/xoom-examples/workflows/Build/badge.svg)](https://github.com/vlingo/xoom-examples/actions?query=workflow%3ABuild)

The VLINGO XOOM examples demonstrating features and functionality available in the reactive components. See each of the submodules for specific examples.

Docs: https://docs.vlingo.io
"
line/armeria-examples,main,139,52,2018-07-26T02:59:21Z,869,2,Armeria examples,,"# Armeria examples

- `annotated-http-service` <a href=""https://gitpod.io/#project=annotated-http-service/https://github.com/line/armeria-examples/tree/main/annotated-http-service/src/main/java/example/armeria/server/annotated/Main.java"">
                             <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                           </a> 
  - Learn how to write an HTTP service using annotations.
  - See [Annotated services](https://armeria.dev/docs/server-annotated-service).

- `annotated-http-service-kotlin` <a href=""https://gitpod.io/#project=annotated-http-service-kotlin/https://github.com/line/armeria-examples/tree/main/annotated-http-service-kotlin/src/main/kotlin/example/armeria/server/annotated/kotlin/Main.kt"">
                                    <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                                  </a>
  - Learn how to write an HTTP service using annotations with Kotlin Coroutines.
  - See [Kotlin coroutines support](https://armeria.dev/docs/server-annotated-service#kotlin-coroutines-support).

- `context-propagation`
  - Learn how to propagate Armeria's `RequestContext` for use in scenarios like tracing.
  - [`dagger`](https://dagger.dev/producers) provides an example using the Dagger asynchronous framework for
  automatic propagation.
  - `manual` provides an example manually propagating the context with Java's standard `CompletableFuture`.
  - [`reactor`](https://github.com/reactor/reactor-core/tree/3.3.x) provides an example using the Reactor
  asynchronous framework for automatic propagation.
  - [`rxjava`](https://github.com/ReactiveX/RxJava/tree/3.x) provides an example using the RxJava3 asynchronous
  framework for automatic propagation.

- `grpc` <a href=""https://gitpod.io/#project=grpc/https://github.com/line/armeria-examples/tree/main/grpc/src/main/java/example/armeria/grpc/Main.java"">
           <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
         </a> 
  - Learn how to write a gRPC service with Armeria gRPC module.
  - See [Running a gRPC service](https://armeria.dev/docs/server-grpc) and
    [Calling a gRPC service](https://armeria.dev/docs/client-grpc).
    
- `grpc-kotlin`
  - Learn how to write a gRPC service with Armeria gRPC module (Kotlin).
  - See [Running a gRPC service](https://armeria.dev/docs/server-grpc) and
    [Calling a gRPC service](https://armeria.dev/docs/client-grpc).

- `grpc-reactor` <a href=""https://gitpod.io/#project=grpc-reactor/https://github.com/line/armeria-examples/tree/main/grpc-reactor/src/main/java/example/armeria/grpc/reactor/Main.java"">
                   <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                 </a> 
  - Learn how to write a gRPC service with Armeria gRPC module,
    [`reactive-grpc`](https://github.com/salesforce/reactive-grpc) and
    [Project Reactor](https://projectreactor.io/) libraries for asynchronous processing
    with non-blocking back pressure.
  - See [Running a gRPC service](https://armeria.dev/docs/server-grpc) and
    [Calling a gRPC service](https://armeria.dev/docs/client-grpc).

- `proxy-server` <a href=""https://gitpod.io/#project=proxy-server/https://github.com/line/armeria-examples/tree/main/proxy-server/src/main/java/example/armeria/proxy/Main.java"">
                   <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                 </a> 
  - Learn how to make a proxy server which leverages client side load balancing.
  - See [Client-side load balancing](https://armeria.dev/docs/client-service-discovery)

- `resilience4j-spring` <a href=""https://gitpod.io/#project=resilience4j-spring/https://github.com/line/armeria-examples/tree/main/resilience4j-spring/src/main/java/example/armeria/resilience4j/spring/Main.java"">
  <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
  </a>
    - Learn how to use Armeria with Resilience4j and Spring.

- `saml-service-provider` <a href=""https://gitpod.io/#project=sam-service-provider/https://github.com/line/armeria-examples/tree/main/saml-service-provider/src/main/java/example/armeria/server/saml/sp/Main.java"">
                            <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                          </a> 
  - Learn how to authenticate users using SAML.
  - See [SAML Single Sign-on](https://armeria.dev/docs/advanced-saml).

- `server-sent-events` <a href=""https://gitpod.io/#project=server-sent-events/https://github.com/line/armeria-examples/tree/main/server-sent-events/src/main/java/example/armeria/server/sse/Main.java"">
                         <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                       </a> 
  - Learn how to serve Server-Sent Events.
  - See [Serving Server-Sent Events](https://armeria.dev/docs/server-sse).
  
- `spring-boot-minimal` <a href=""https://gitpod.io/#project=spring-boot-minimal/https://github.com/line/armeria-examples/tree/main/spring-boot-minimal/src/main/java/example/springframework/boot/minimal/Main.java"">
                          <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                        </a> 
  - Learn how to use Armeria with the minimal Spring Boot dependencies.

- `spring-boot-minimal-kotlin`
  - Learn how to use Armeria with the minimal Spring Boot dependencies (Kotlin).

- `spring-boot-tomcat` <a href=""https://gitpod.io/#project=spring-boot-tomcat/https://github.com/line/armeria-examples/tree/main/spring-boot-tomcat/src/main/java/example/springframework/boot/tomcat/Main.java"">
                         <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                       </a> 
  - Learn how to make Armeria serve your Spring Boot web application.

- `spring-boot-webflux` <a href=""https://gitpod.io/#project=spring-boot-webflux/https://github.com/line/armeria-examples/tree/main/spring-boot-webflux/src/main/java/example/springframework/boot/webflux/Main.java"">
                          <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                        </a> 
  - Learn how to make Armeria serve your Spring Boot reactive web application.
  - See [Using Armeria with Spring WebFlux](https://armeria.dev/docs/advanced-spring-webflux-integration).

- `dropwizard` <a href=""https://gitpod.io/#project=dropwizard/https://github.com/line/armeria-examples/tree/main/dropwizard/src/main/java/example/dropwizard/DropwizardArmeriaApplication.java"">
                 <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
               </a> 
  - Learn how to make Armeria serve your Dropwizard web application.
  - See [Using Armeria with Dropwizard](https://armeria.dev/docs/advanced-dropwizard-integration).

- `static-files` <a href=""https://gitpod.io/#project=static-files/https://github.com/line/armeria-examples/tree/main/static-files/src/main/java/example/armeria/server/files/Main.java"">
                   <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
                 </a> 
  - Learn how to serve static files.
  - See [Serving static files](https://armeria.dev/docs/server-http-file).
  
- `thrift` <a href=""https://gitpod.io/#project=grpc/https://github.com/line/armeria-examples/tree/main/thrift/src/main/java/example/armeria/thrift/Main.java"">
             <img align=""absmiddle"" height=""20"" src=""https://gitpod.io/button/open-in-gitpod.svg""/>
           </a> 
  - Learn how to write a Thrift service with Armeria Thrift module.
  - See [Running a Thrift service](https://armeria.dev/docs/server-thrift) and
    [Calling a Thrift service](https://armeria.dev/docs/client-thrift).
  - Install Thrift compiler locally before generating Thrift services.
    - Use `brew install thrift` for macOS.

## Configure `-parameters` javac option 

You can omit the value of `@Param` if you compiled your code with `-parameters` javac option.
Please refer to [Configure `-parameters` javac option](https://armeria.dev/docs/setup#configure--parameters-javac-option) for more information.

## How to run

- Use `run` or `bootRun` task to run an example from Gradle.
- See [Open an existing Gradle project](https://www.jetbrains.com/help/idea/gradle.html#gradle_import_project_start) to import an example into IntelliJ IDEA.
- See [Configure `-parameters` javac option](https://armeria.dev/docs/setup#configure--parameters-javac-option) to configure IntelliJ IDEA.
- See [Build and run the application](https://www.jetbrains.com/help/idea/creating-and-running-your-first-java-application.html#run_app) to run an example from IntelliJ IDEA.

## License

All files under this directory (`examples`) belong to
[the public domain](https://en.wikipedia.org/wiki/Public_domain).
Please feel free to copy-and-paste and start your awesome project with Armeria!
"
gauravrmazra/gauravbytes,master,58,143,2017-01-01T07:04:53Z,10944,32,Examples for gauravbytes.com,apache-avro bigdata docker elasticsearch elk-stack imdg java java-8 jupyter-notebook mongodb pandas-dataframe spring spring-boot spring-cloud spring-mvc,"# gauravbytes
examples for gauravbytes.com
"
RameshMF/Hibernate-ORM-Tutorials,master,232,310,2018-11-22T13:15:38Z,14672,6,40+ source code Examples/Tutorials/Guides of Hibernate ORM Framework,hibernate hibernate-configurations hibernate-framework hibernate-orm-framework jpa jpa-persistence-applications,"# Hibernate-ORM-Tutorials
Tutorials/guides/examples of Hibernate ORM Framework


<div dir=""ltr"" style=""text-align: left;"" trbidi=""on"">

<div class=""font-family-page"">
<div class=""separator"" style=""clear: both; text-align: center;"">
<a href=""https://3.bp.blogspot.com/-LZZRjsO24YI/W_qbPQkNsTI/AAAAAAAAE9o/Urok6r0IKbkPtRU6V7r5ty5eMOcaKiKAgCLcBGAs/s1600/hibernate-logo.jpg"" imageanchor=""1"" style=""margin-left: 1em; margin-right: 1em;""><img border=""0"" data-original-height=""139"" data-original-width=""491"" src=""https://3.bp.blogspot.com/-LZZRjsO24YI/W_qbPQkNsTI/AAAAAAAAE9o/Urok6r0IKbkPtRU6V7r5ty5eMOcaKiKAgCLcBGAs/s1600/hibernate-logo.jpg""></a></div>
<div class=""separator"" style=""clear: both; text-align: center;"">
</div>
<div class=""separator"" style=""clear: both; text-align: center;"">
</div>
<div>
This tutorial is designed for all those Java programmers who would like to understand the Hibernate framework and its API. All the examples in this tutorial&nbsp;have been developed using Hibernate 5.3 +.</div>
<h2 style=""text-align: left;"">
1. Hibernate Getting Started</h2>
<div>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-framework-overview-architecture-bascis.html"" target=""_blank"">Hibernate Framework Overview - Architecture and Basics</a>&nbsp;- In this article, b<span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">efore getting started with Hibernate framework, let's familiar with a few basic concepts of the hibernate framework, it's architecture, it's benefits and advantages over JDBC etc.</span></li>
</ul>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-hello-world-tutorial.html"">Hibernate 5 - Hello World Tutorial</a>&nbsp;- In this Hibernate hello world tutorial, we will show you how to create a Hibernate Application to connect MySQL database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/12/hibernate-transaction-management-tutorial.html"" target=""_blank"">Hibernate Transaction Management Tutorial</a>&nbsp;- In this tutorial, we will learn how to manage transactions in Hibernate applications.</li>
</ul>
</div>
<h2 style=""text-align: left;"">
2. Bootstrap</h2>
<h3 style=""text-align: left;"">
2.1 Native Bootstrapping</h3>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-xml-configuration-example.html"" style=""font-family: inherit;"">Hibernate 5 XML Configuration Example</a><span style=""font-family: inherit;""> - In this article, we will show you how to create a Hibernate Application using hibernate.cfg.xml configuration to connect MySQL database.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-java-configuration-example.html"" style=""font-family: inherit;"">Hibernate 5 Java Configuration Example</a><span style=""font-family: inherit;""> - In this article, we will show you how to create a Hibernate Application using Java configuration without using hibernate.cfg.xml to connect MySQL database.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-configurations-quick-references.html"" style=""font-family: inherit; font-size: 16px;"" target=""_blank"">Hibernate Configurations Quick References [Snippets]</a><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;"">&nbsp;-&nbsp;</span><span style=""color: #24292e; font-family: inherit; font-size: 16px;"">This post is&nbsp;a quick</span><span style=""color: #24292e; font-family: inherit; font-size: 16px;"">&nbsp;reference to Hibernate XML or Java-based configuration.</span></li>
</ul>
</div>
<h3 style=""text-align: left;"">
2.2 JPA Bootstrapping</h3>
<div class=""font-family-page"">
<div>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/jpa-with-hibernate-5-bootstrapping-example.html"" target=""_blank"">JPA 2 with Hibernate 5 Bootstrapping Example</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">In this post, we will show you how to create or configure a simple JPA application with Hibernate.</span></li>
</ul>
<h2 style=""text-align: left;"">
3. Domain Model</h2>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/guide-to-jpa-and-hibernate-cascade-types.html"" target=""_blank"">Guide to JPA and Hibernate Cascade Types</a>&nbsp;- J</span><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;"">PA allows you to propagate the state transition from a parent entity to a child. This article describes all cascade types with an example.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;""><a href=""http://www.javaguides.net/2018/12/hibernatejpa-primary-key-generation-stratergies.html"" target=""_blank"">Hibernate/JPA - Primary Key Generation Strategies</a>&nbsp;- Let's discuss&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;"">4 different primary key generation strategies which generate the primary key values programmatically or use database features, like auto-incremented columns or sequences.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-enum-type-mapping-example.html"">Hibernate 5 - Enum Type Mapping Example</a>&nbsp;- In this article, we will show you how a Java enum type is persisted into a database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-component-mapping-using-embeddable-embedded-annotation.html"" target=""_blank"">Hibernate Component Mapping Using @Embeddable and @Embedded Annotation</a>&nbsp;-&nbsp;<span style=""background-color: white; color: #24292e; font-size: 16px;"">With Hibernate we can use the&nbsp;</span><span style=""background-color: rgba(27 , 31 , 35 , 0.05); color: #d73a49; font-family: &quot;consolas&quot; , &quot;liberation mono&quot; , &quot;courier&quot; , monospace; font-size: 14.4px; padding: 0.2em 0.4em;"">@Embeddable</span><span style=""background-color: white; color: #24292e; font-size: 16px;"">&nbsp;annotation to mark a class to be eligible as an embeddable class.</span></li>
</ul>
<span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""></span></div>
<h2 style=""text-align: left;"">
4. Hibernate Database Operations (Session Methods)</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-save-an-entity-example.html"">Hibernate 5 - Save an Entity Example</a> - In this article, we will create a simple Hibernate application to demonstrate how to save an entity into a database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-persist-entity-example.html"">Hibernate 5 - Persist an Entity Example</a> - In this article, we will create a simple Hibernate application to demonstrate how to persist an entity into a database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-saveorupdate-method-example.html"">Hibernate 5 - saveOrUpdate() Method Example</a> - In this article, we will create a simple Hibernate application to demonstrate how to save or update an entity in the database using the saveOrUpdate() method.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-get-load-and-byid-method-examples.html"">Hibernate 5 - get(), load() and byId() Method Examples</a> - In this article, we will show you how to use Session.get(), Session.load() and Session.byId() methods to retrieve an entity from database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-merge-example.html"">Hibernate 5 - merge() Example</a> - In this article, we will show you how to use Session.merge() method to merge an entity in Hibernate Application.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-delete-or-remove-entity.html"">Hibernate 5 - Delete or Remove an Entity Example</a> - In Hibernate, an entity can be removed from a database by calling the Session.delete() or Session.remove(). Using these methods, we can remove a transient or persistent object from datastore.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-load-method-example.html"">Hibernate 5 - load() Method Example</a> - In this article, we will create a simple Hibernate application using Java configuration without using hibernate.cfg.xml to demonstrates the usage of Session.load() method.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-c3p0-connection-pool-example.html"">Hibernate 5 c3p0 Connection Pool Example</a> - In this article, we will show how to use c3p0 connection pooling in hibernate applications.</li>
</ul>
<h2 style=""text-align: left;"">
5. Inheritance Mapping</h2>
<div style=""text-align: left;"">
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-inheritance-mapping.html"" target=""_blank"">Hibernate 5 - Inheritance Mapping</a>&nbsp;- In this article, we will learn 4 inheritance<span style=""background-color: white; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">&nbsp;strategies with examples.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/hibernate-jpa-mappedsuperclass-inheritance-example.html"" target=""_blank"">Hibernate/JPA MappedSuperclass Inheritance Example</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">The JPA standard specification defines the&nbsp;</span><a href=""https://docs.oracle.com/javaee/7/api/javax/persistence/MappedSuperclass.html"" style=""color: #3d85c6; font-size: 16px;"" target=""_blank"">@MappedSuperclass</a><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">&nbsp;annotation to allow an entity to inherit properties from a base class.</span></li>
</ul>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/hibernatejpa-single-table-inheritance.html"" target=""_blank"">Hibernate/JPA Single Table Inheritance Example</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">In this article, we will discuss The single table strategy which maps all entities of the inheritance structure to the same database table.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/hibernate-jpa-joined-table-inheritance-example.html"" target=""_blank"">Hibernate JPA Joined Table Inheritance Example</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">In this article, we will discuss The Joined table strategy or table-per-subclass mapping strategy.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/hibernatejpa-table-per-class-inheritance-example.html"" target=""_blank"">Hibernate/JPA Table Per Class Inheritance Example</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;"">In this article, we’ll look into Hibernate/JPA table per class inheritance.</span></li>
</ul>
</div>
<span style=""background-color: white; color: #24292e; font-family: , &quot;blinkmacsystemfont&quot; , &quot;segoe ui&quot; , &quot;helvetica&quot; , &quot;arial&quot; , sans-serif , &quot;apple color emoji&quot; , &quot;segoe ui emoji&quot; , &quot;segoe ui symbol&quot;; font-size: 16px;""></span></div>
<div class=""font-family-page"">
<h2 style=""text-align: left;"">
6. Hibernate Query Language</h2>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-query-language-basics.html"">Hibernate Query Language Basics</a> - This article describes the basics of HQL.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-query-language-insert-update.html"">Hibernate Query Language INSERT, UPDATE, SELECT and DELETE Example</a> - In this article, we will discuss how to create simple Hibernate Query Language INSERT, UPDATE, SELECT and DELETE Example.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-hql-crud-example-snippets.html"">Hibernate 5 - HQL CRUD Example [Snippets]</a> - In this article, we will see quick snippets or examples of Hibernate 5 HQL CRUD Example.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-named-query-tutorial-with-examples.html"">Hibernate 5 Named Query Tutorial with Examples</a> - This tutorial shows you how to use the named queries annotations in hibernation application.</li>
</ul>
<div class=""font-family-page"">
<h2 style=""text-align: left;"">
7. Hibernate 5 with Java 8</h2>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-5-persist-java-8-localdate-localdatetime-and-duration-example.html"">Hibernate 5 - Persist Java 8 LocalDate, LocalDateTime and Duration Example</a>&nbsp;- In this article, we will learn how to persist Java 8 LocalDate, LocalDateTime, and Duration with&nbsp;<a href=""http://www.javaguides.net/p/hibernate-tutorial.html"">Hibernate 5</a>.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""https://thoughts-on-java.org/use-java-8-optional-hibernate/"" target=""_blank"">How to use Java 8’s Optional with Hibernate</a>&nbsp;- This article show you how to use Java 8 Optional Class to handle&nbsp;<i>NullPointerException</i>.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""https://thoughts-on-java.org/get-query-results-stream-hibernate-5/"">How to get query results as a Stream with Hibernate 5.2</a>&nbsp;- This post shows you how to use stream() method that allows you to process the query results as a Java 8 Stream.</li>
</ul>
</div>
<div class=""font-family-page"">
<h2 style=""text-align: left;"">
8. Database</h2>
<div>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/guide-to-hibernate-5-schema-generation.html"" target=""_blank"">Guide to Hibernate 5 Schema Generation</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;"">In this guide, You will learn how does Hibernate allows you to generate the database from the entity mappings. In this guide, we will following&nbsp;points.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/guide-to-hibernate-native-sql-queries.html"" target=""_blank"">Guide to Hibernate Native SQL Queries</a>&nbsp;-&nbsp;</span><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;"">Let's learn more about Hibernate native SQL queries with examples snippets.</span></li>
</ul>
<ul style=""text-align: left;"">
<li><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;""><a href=""http://www.javaguides.net/2018/11/hibernate-5-using-stored-procedures-for.html"" target=""_blank"">Hibernate 5 - Using Stored Procedures for Querying</a>&nbsp;-&nbsp;&nbsp;</span><span style=""font-family: inherit;"">Hibernate</span><span style=""background-color: white; color: #24292e; font-family: inherit; font-size: 16px;"">&nbsp;provides support for queries via stored procedures and functions</span></li>
</ul>
<h2 style=""text-align: left;"">
<span style=""color: #24292e;"">Hibernate Annotations</span></h2>
</div>
<div>
<div style=""text-align: left;"">
</div>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/12/all-hibernate-mapping-annotations.html"" target=""_blank"">All Hibernate Annotations: Mapping Annotations</a>&nbsp;- A quick reference to all Hibernate mapping annotations.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/all-jpa-annotations-mapping-annotations.html"" target=""_blank"">All JPA Annotations: Mapping Annotations</a>&nbsp;- A quick reference to all JPA mapping annotations.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/hibernate-component-mapping-using-embeddable-embedded-annotation.html"" target=""_blank"">Hibernate Component Mapping Using @Embeddable and @Embedded Annotation</a>&nbsp;-&nbsp;<span style=""background-color: white; color: #24292e; font-size: 16px;"">With Hibernate we can use the&nbsp;</span><span style=""background-color: rgba(27 , 31 , 35 , 0.05); color: #d73a49; font-family: &quot;consolas&quot; , &quot;liberation mono&quot; , &quot;courier&quot; , monospace; font-size: 14.4px; padding: 0.2em 0.4em;"">@Embeddable</span><span style=""background-color: white; color: #24292e; font-size: 16px;"">&nbsp;annotation to mark a class to be eligible as an embeddable class.</span></li>
</ul>
<br>
<div>
<br></div>
</div>
</div>
<div class=""separator"" style=""clear: both; text-align: center;"">
<a href=""https://3.bp.blogspot.com/-sZpG0bMK5xQ/W_qZl9AuksI/AAAAAAAAE9U/2aimw3DF5pUZzeAOmN7xiLc59GTqRaNIQCEwYBhgL/s1600/spring-hibernate.jpg"" imageanchor=""1"" style=""margin-left: 1em; margin-right: 1em;""><img border=""0"" data-original-height=""282"" data-original-width=""600"" src=""https://3.bp.blogspot.com/-sZpG0bMK5xQ/W_qZl9AuksI/AAAAAAAAE9U/2aimw3DF5pUZzeAOmN7xiLc59GTqRaNIQCEwYBhgL/s1600/spring-hibernate.jpg""></a></div>
<br>
<h2 style=""text-align: left;"">
9. Spring Boot 2 + Hibernate 5 Tutorials</h2>
<div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-boot-2-hibernate-5-mysql-crud-rest-api-tutorial.html"">Spring Boot 2 Hibernate 5 MySQL CRUD REST API Tutorial</a> - In this tutorial, we will learn how to develop CRUD RESTFul API using Spring boot 2, Hibernate 5, JPA, Maven, and MySQL database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/09/spring-mvc-using-spring-boot2-jsp-jpa-hibernate5-mysql-example.html"">Spring MVC + Spring Boot2 + JSP + JPA + Hibernate 5 + MySQL Example</a> - In this article, we will learn how to develop a Spring MVC web application using Spring MVC, Spring boot 2, JSP, Hibernate 5, JPA, Maven, and MySQL database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/spring-boot-spring-mvc-spring-security-hibernate-mysql-tutorial.html"">Spring Boot + Spring MVC + Spring Security + Hibernate + MySQL Tutorial</a> - In this article, we discuss how to create a user registration form with Spring Boot, Spring Security, Hibernate and Thymeleaf. We will develop a simple User Registration Module using Role-based Spring security which can use in any spring MVC based projects.</li>
</ul>
</div>
<h2 style=""text-align: left;"">
10. Spring MVC 5 + Hibernate 5 Tutorials</h2>
<div>
<div style=""text-align: left;"">
</div>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/spring-mvc-5-hibernate-5-jsp-mysql-crud-tutorial.html"">Spring MVC 5 + Hibernate 5 + JSP + MySQL CRUD Tutorial</a> - In this spring hibernate integration tutorial, we will learn how to create <a href=""http://www.javaguides.net/p/spring-mvc-tutorial.html"">Spring MVC </a>5 web application, handle form submission, integrate hibernate 5 to connect to the backend database. In this tutorial, we will integrate <a href=""http://www.javaguides.net/p/spring-mvc-tutorial.html"">Spring MVC 5+</a> with Hibernate ORM framework using Java-based configuration without any XML configuration.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/spring-mvc-5-spring-data-jpa-hibernate-jsp-mysql-tutorial.html"">Spring MVC 5 + Spring Data JPA + Hibernate 5 + JSP + MySQL Tutorial</a> - In this tutorial, we will discuss the integration of <a href=""http://www.javaguides.net/p/spring-mvc-tutorial.html"">Spring MVC 5</a>, <a href=""http://www.javaguides.net/p/spring-data-jpa-tutorial.html"">Spring Data JPA</a>, Hibernate 5 and MySQL CRUD example. We will demonstrate CRUD(Create, Retrieve, Update, Delete) operations on a Customer entity as well as display list of customers from the MySQL database.</li>
</ul>
<ul style=""text-align: left;"">
<li><a href=""http://www.javaguides.net/2018/11/spring-mvc-5-hibernate-5-xml-based-configuration-example.html"">Spring MVC 5 + Hibernate 5 XML Based Configuration Example</a> - In this tutorial, we will integrate <a href=""http://www.javaguides.net/p/spring-mvc-tutorial.html"">Spring MVC </a>with Hibernate ORM framework using XML-based configuration.</li>
</ul>
</div>
</div>
</div>
"
jetty-project/embedded-jetty-websocket-examples,10.0.x,185,76,2013-12-01T14:42:54Z,502,10,Embedded Jetty WebSocket Examples,java11 jetty websocket websocket-client websocket-server,"# WebSockets on Embedded Jetty

This project contains examples on using WebSockets with Embedded Jetty.

Note: If you want to use CDI + websockets with Jetty, check out the example project at

https://github.com/jetty-project/embedded-jetty-weld

There are 2 APIs you can use with Jetty, the native WebSocket API and the javax.websocket API.

# Project: javax.websocket-example

Demonstration of how to create a WebSocket Client or a WebSocket Server using `javax.websocket` APIs. 


# Project: native-jetty-websocket-example

Demonstration of how to create a WebSocket Client or WebSocket Server using `org.eclipse.jetty.websocket` APIs.

"
lokeshgupta1981/Spring-Boot-Examples,master,63,93,2022-06-17T06:51:38Z,19446,5,,,"# Spring-Boot-Examples
"
strimzi/client-examples,main,72,64,2018-07-30T08:56:37Z,264,0,Example clients for use with Strimzi,,"[![Build Status](https://dev.azure.com/cncf/strimzi/_apis/build/status/client-examples?branchName=main)](https://dev.azure.com/cncf/strimzi/_build/latest?definitionId=33&branchName=main)
[![License](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0)
[![Twitter Follow](https://img.shields.io/twitter/follow/strimziio?style=social)](https://twitter.com/strimziio)


# Client examples

This repository contains examples of [Apache Kafka®](https://kafka.apache.org) client applications written using the Apache Kafka Java APIs:
* Message Producer which periodically produces messages into a topic
* Streams application which reads messages from a topic, transforms them (reverses the message payload) and sends them to another topic
* Consumer which is consuming messages from a topic

All examples are assembled into Docker images which allows them to be deployed on Kubernetes or OpenShift.
This may serve as a basic usage example for the [Strimzi project](https://strimzi.io).

This repository contains `Deployments` for the clients as well as `KafkaTopic` and `KafkaUsers` for use by Strimzi operators.
Logging configuration can be found in the `log4j2.properties` file for the producer and consumer separately.

## Build

The pre-built images are available on our Docker Hub.
But if you want to do any modifications to the examples, you will need to build your own versions.

To build these examples you need some basic requirements.
Make sure you have `make`, `docker`, `JDK 1.8` and `mvn` installed. 
After cloning this repository to your folder Hello World example is fully ready to be build.
By one single command Java sources are compiled into JAR files, Docker images are created and pushed to repository.
By default the Docker organization to which images are pushed is the one defined by the `USER` environment variable which is assigned to the `DOCKER_ORG` one.
The organization can be changed exporting a different value for the `DOCKER_ORG` and it can also be the internal registry of an OpenShift running cluster.

The command for building the examples is:

```
make all
```

## Usage

Basic requirement to run this example is a Kubernetes cluster with Strimzi managed Apache Kafka cluster deployed.
Examples how to deploy Apache Kafka using Strimzi can be found on the [Strimzi website](https://strimzi.io/quickstarts/minikube/).

After successfully building the images (which will cause the images to be pushed to the specified Docker repository) you are ready to deploy the producer and consumer containers along with Kafka and Zookeper.

You can deploy the examples individually by applying [`java-kafka-producer.yaml`](./java/kafka/java-kafka-producer.yaml), [`java-kafka-consumer.yaml`](./java/kafka/java-kafka-consumer.yaml) and [`java-kafka-streams.yaml`](./java/kafka/java-kafka-streams.yaml) files.
This will create Kubernetes `Deployments` with the example image.
The second option is to apply `deployment.yaml` file.
This deploys the producer, consumer and streams and also creates the topics they are using.

If you built your own version of these examples, remember to update the `image` field with the path where the image was pushed during the build and it's available (i.e. `<my-docker-org>/java-kafka-consumer:latest`).

When using [`deployment.yaml`](./java/kafka/deployment.yaml) file for deployment you can start observing the sending messages in producer container's log and the receiving of messages in consumer container's log.
It's also available as a [`deployment-ssl.yaml`](./java/kafka/deployment-ssl.yaml) which deploys the same producer and consumer applications but using a TLS encryption and [`deployment-ssl-auth.yaml`](./java/kafka/deployment-ssl-auth.yaml) which uses TLS client authentication and ACLs.

You can also use these example clients with OAuth authentication. See the example [`deployment-oauth.yaml`](./java/kafka/deployment-oauth.yaml) for more details.
To run the OAuth example, you will need to have your Kafka cluster configured with OAuth and change the configuration in [`deployment-oauth.yaml`](./java/kafka/deployment-oauth.yaml) to point to your OAuth server.

## Configuration

Below are listed and described the available environment variables that can be used for configuration.

Producer  
* `STRIMZI_TOPIC` - the topic the producer will send to  
* `STRIMZI_DELAY_MS` - the delay, in ms, between messages  
* `STRIMZI_MESSAGE_COUNT` - the number of messages the producer should send
* `STRIMZI_MESSAGE` - the message the producer will send
* `STRIMZI_LOG_LEVEL` - logging level  
* `STRIMZI_HEADERS` - custom headers list separated by commas of `key1=value1, key2=value2`
* `STRIMZI_TRACING_SYSTEM` - if it's set to or `opentelemetry`, this will enable tracing. 

Consumer  
* `STRIMZI_TOPIC` - name of topic which consumer subscribes  
* `STRIMZI_MESSAGE_COUNT` - the number of messages the consumer should receive
* `STRIMZI_LOG_LEVEL` - logging level  
* `STRIMZI_TRACING_SYSTEM` - if it's set to `opentelemetry`, this will enable tracing.

Streams  
* `STRIMZI_SOURCE_TOPIC` - name of topic which will be used as the source of messages
* `STRIMZI_TARGET_TOPIC` - name of topic where the transformed messages are sent
* `STRIMZI_LOG_LEVEL` - logging level
* `STRIMZI_TRACING_SYSTEM` - if it's set to `opentelemetry`, this will enable tracing.

Additionally, any Kafka Consumer API, Kafka Producer API or Kafka Streams API configuration option can be passed as an environment variable.
It should be prefixed with `KAFKA_` and use `_` instead of `.`.
For example environment variable `KAFKA_BOOTSTRAP_SERVERS` will be used as the `bootstrap.servers` configuration option in the Kafka Consumer API.

### Tracing

The examples support tracing using the [OpenTelemetry Java Instrumentation](https://github.com/open-telemetry/opentelemetry-java-instrumentation).
To enable tracing, configure the Tracer using [environment variables](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/configuration/sdk-environment-variables.md).

To run Opentelemetry Tracing, you can also use the provided example in [`deployment-tracing-opentelemetry.yaml`](./java/kafka/deployment-tracing-opentelemetry.yaml).

CAUTION: Strimzi no longer supports OpenTracing.
If you were previously using OpenTracing with these examples, we encourage you to transition to using OpenTelemetry instead.

## Container signatures

From the 0.38.0 release, Strimzi containers are signed using the [`cosign` tool](https://github.com/sigstore/cosign).
Strimzi currently does not use the keyless signing and the transparency log.
To verify the container, you can copy the following public key into a file:

```
-----BEGIN PUBLIC KEY-----
MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC
TRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==
-----END PUBLIC KEY-----
```

And use it to verify the signature:

```
cosign verify --key strimzi.pub quay.io/strimzi-examples/java-kafka-consumer:latest --insecure-ignore-tlog=true
```"
Iteratr-Learning/Real-World-Software-Development,master,265,178,2019-11-11T11:30:10Z,348,8,Examples for our book: Real-World Software Development,,"This is the sample code for the book ""Real World Software Development""
written by Richard Warburton and Raoul-Gabriel Urma and published by
O'Reilly Media.

Full details can be found online at http://shop.oreilly.com/product/0636920053996.do

"
langmi/spring-batch-examples,master,87,76,2011-07-19T18:31:38Z,3294,0,Collection of Spring Batch Examples,,"# Spring Batch Examples

Collection of Spring Batch Examples, covering the basics, [readers][readers], [writers][writers], [listeners][listeners] and complex usecases.

## Why?

Spring Batch Examples exist, because i needed a central place to store the source code of my own examples collection. Instead of the usual private Subversion repository i wanted to give Github a try.

## What?

The Examples are described in each of the submodule README.

## How?

This repository uses [git submodules][git-submodules] to link to the individual example repositories on github. Right after the check-out you need to run: `git submodule --init` to get the submodule sources.

To get the latest commits for the submodules:

* [update submodules from with git command][git-update-submodules]: `git submodule -q foreach git pull -q origin master`
* [sourcetree][sourcetree]: just fetch/pull from the current repository, sourcetree will update the submodules too

## General Informations

All Spring Batch Examples:

* are individual github repositories and maven projects, the pom.xml in this root directory is only for a convenient _build all_ feature
* are tested with:
  * Spring Batch 2.1.8.RELEASE
  * Spring Framework 3.1.0.RELEASE
* are provided ""as is"", no guarantees :-)
* work with [in-memory database][database], but not with in-memory jobrepository, since the [MapJobRepository is threadsafe][maprepo-threadsafe] i could use it, but why break a standard configuration ?

Overview for the project setup.

### Maven Configuration

The pom.xml in this root directory contains just a simple parent pom wrapper project to provide a convenient ""build all"" feature, see [Maven Pom project aggregation][project-aggregation].
Each individual project stands on its own and can be used as such, e.g. there are no maven configurations made in the parent pom.

The examples modules are:

* spring batch examples parent, the mentioned ""build all"" parent module
    * complex, contains examples which use more than one of the core aspects of spring batch
    * listeners
    * playground, mostly for incubating new examples
    * readers
    * writers

#### Usable Systemproperties

* -DreuseForks
    * run tests with individual and fresh JVM per test class or reuse JVM between tests
    * default is `false`
    * use `true`, if you want to run the tests with shared JVMs

#### Specific Build Configurations

For each project i added specific build configurations for the following build plugins:

* [maven-compiler-plugin][maven-compiler-plugin]
    * JDK set to 1.6
    * compiler.debug=true
    * compiler.optimize=false
* [maven-enforcer-plugin][maven-enforcer-plugin]
    * enforce minimum Java version 1.6
    * enforce minimum Maven version 3.0
* [maven-resources-plugin][maven-resources-plugin]
    * forced UTF-8 encoding
* [maven-surefire-plugin][maven-surefire-plugin]
    * set log4j properties file location
    * Java memory configuration to prevent OutOfMemory problems during tests, see [Java -X options][java-x-options]
    * [forkCount][forkCount]=1C to run one test class per cpu core
    * [reuseForks][reuseForks]=false to run each test class isolated
        * can be overridden by using systemproperty `-DreuseForks=true`

##### Why isolated tests?

I use the [reuseForks=false][reuseForks] for the maven test configuration to get a new JVM for each test class. This configuration lowers the test run time by a signifikant amount. Why is that necessary?

While using the HSQLDB in-memory database i see sometimes thread problems.

#### Dependencies

Each project contains only the needed dependencies and i check regularly for version updates and the [dependencies licenses][license].

### Directory Structure

The project follows the [maven standard directory layout][standard-dir-layout], only difference so far is a README.md (md for markdown format) and a LICENSE file instead of both files ending with .txt.

### Important /resources Directories and Files

Overview:

    # log4j configuration
    src/main/resources/log4j/log4.properties
    # the job configurations    
    src/main/resources/spring/batch/job/
    # spring batch setup
    src/main/resources/spring/batch/setup/job-context.xml
    src/main/resources/spring/batch/setup/job-database.xml
    # the used input files    
    src/test/resources/input/ 
    # test setup
    src/test/resources/spring/batch/setup/test/job-test-context.xml

For each project:

* the log4j.properties is under `src/main/resources/log4j/log4j.properties`
    * logging level is WARN for all and DEBUG for the source package of the project
    * location might be changed soon to src/test...
* the Spring Batch infrastructure setup is under `src/main/resources/spring/batch/setup/...`
    * `job-context.xml` contains JobRepository, StepScope etc. beans
    * `job-database.xml` contains the datasource and transactionmanager beans
        * [HSQLDB in-memory][hsqldb-in-memory] variant is used
        * Spring Batch Schema is loaded at Application Context startup with [jdbc:initialize-database][jdbc-init-db]
* the Spring Batch test infrastructure setup is under `src/test/resources/spring/batch/setup/test/...`
    * `job-test-context.xml` contains just the [JobLauncherTestUtils][JobLauncherTestUtils] bean


### Code Structure

* each example has its own package (test package has the same name), e.g. `simplelist`
    * not all examples have java source, some have only a job.xml and some tests
* each example has its own job.xml, e.g. `simple-list-job.xml`
* each example has a large test coverage, well what can i say, i am addicted to tests :-)

## License

To simplify it, all work is under [Apache 2.0 license][apache-license], fork it, use it, bend it and if you find a bug or improvement, do not hesitate to push a patch.

### Licenses of used Java libraries

**last check: 29.04.2013**

* AOP Alliance - [Public Domain][aop-dependency]
* Apache commons-collections, -dbcp, -io, -logging, -pool - all licensed under Apache 2.0
* bcprov - [MIT][bcprov-dependency]
* harmcrest-core - [new BSD][hamcrest-dependency]
* HSQLDB - [based on BSD][hsqldb-dependency]
* Jettison - [Apache 2.0 license][jettison-dependency]
* log4j - [Apache 2.0 license][log4j-dependency]
* Maven - [Apache 2.0 license][maven-dependency]
* slf4j - [identical to MIT License][slf4j-dependency]
* Spring Batch - [Apache 2.0 license][spring-batch-dependency]
* Spring Framework - all licensed under [Apache 2.0][spring-framework-dependency]
* xpp3 - XMLPullParser - [Public Domain][xpp3-dependency]
* xstream - [BSD][xstream-dependency]

#### Problematic Dependencies

* JUnit - [Common Public License - v 1.0][junit-dependency] (look for license.txt in the github repository)
    * just do not distribute your project with junit, should be easy
* Truezip - [Eclipse Public License, Version 1.0][truezip-dependency]
    * if you distribute a project with truezip you need to include the license and a statement basically saying you did not change anything
    * if you change the source, ... well if you run a commercial product you are screwed :-)


[hsqldb-in-memory]: http://hsqldb.org/doc/2.0/guide/running-chapt.html#running_inprocess-sect
[jdbc-init-db]: http://static.springsource.org/spring/docs/current/spring-framework-reference/html/jdbc.html#d0e24263
[JobLauncherTestUtils]: http://static.springsource.org/spring-batch/apidocs/org/springframework/batch/test/JobLauncherTestUtils.html
[maven-enforcer-plugin]: http://maven.apache.org/enforcer/maven-enforcer-plugin/
[maven-compiler-plugin]:http://maven.apache.org/plugins/maven-compiler-plugin/
[maven-resources-plugin]:http://maven.apache.org/plugins/maven-resources-plugin/
[standard-dir-layout]: http://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html
[maven-surefire-plugin]:http://maven.apache.org/plugins/maven-surefire-plugin/
[project-aggregation]:http://maven.apache.org/guides/introduction/introduction-to-the-pom.html#Project_Aggregation

[aop-dependency]: http://aopalliance.sourceforge.net/
[bcprov-dependency]: http://www.bouncycastle.org/licence.html
[hamcrest-dependency]: https://github.com/hamcrest/JavaHamcrest
[hsqldb-dependency]: http://hsqldb.org/web/hsqlLicense.html
[jettison-dependency]: http://jettison.codehaus.org/License
[junit-dependency]: https://github.com/junit-team/junit
[log4j-dependency]: http://logging.apache.org/log4j/1.2/license.html
[maven-dependency]: http://maven.apache.org/license.html
[slf4j-dependency]: http://www.slf4j.org/license.html
[spring-batch-dependency]: http://static.springsource.org/spring-batch/license.html
[spring-framework-dependency]: http://www.springsource.org/about
[truezip-dependency]: http://truezip.java.net/license.html
[xpp3-dependency]: http://www.xmlpull.org/
[xstream-dependency]: http://xstream.codehaus.org/license.html


[git-update-submodules]: http://stackoverflow.com/a/9103113/62201
[apache-license]: http://www.apache.org/licenses/LICENSE-2.0.html
[database]:http://hsqldb.org/doc/2.0/guide/running-chapt.html#running_inprocess-sect
[git-submodules]: http://git-scm.com/book/de/Git-Tools-Submodules
[java-x-options]: http://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/jrdocs/refman/optionX.html
[listeners]: http://static.springsource.org/spring-batch/reference/html/configureStep.html#interceptingStepExecution
[maprepo-threadsafe]: https://jira.springsource.org/browse/BATCH-1541
[readers]: http://static.springsource.org/spring-batch/reference/html/domain.html#domainItemReader
[reuseForks]: http://maven.apache.org/surefire/maven-surefire-plugin/test-mojo.html#reuseForks
[forkCount]: http://maven.apache.org/surefire/maven-surefire-plugin/test-mojo.html#forkCount
[sourcetree]: http://sourcetreeapp.com/
[writers]: http://static.springsource.org/spring-batch/reference/html/domain.html#domainItemWriter
"
skprasadu/spring-security-examples,master,43,101,2013-02-10T23:27:30Z,350,1,spring-security-examples,,"Spring Security
===============

[Spring Test MVC](https://github.com/SpringSource/spring-test-mvc) is a good framework for testing Spring MVC application.

In this sample, we demonstrated a simple Calendar application, where a regular user can create a Event and can see others event but cannot modify them. Admin user can modify other user's event as well.

We will demonstrate the Spring Security capability for Inmemory authorization provider, JDBC authorization provider, LDAP authorization provider, CAS Single sign on authorization provider.

Refer to this [blog](http://krishnasblog.com/2013/02/10/spring-test-mvc-junit-testing-spring-security-layer-with-inmemorydaoimpl-2/) for more details.
"
YogenRaii/spring-examples,master,36,81,2016-06-04T00:01:33Z,23903,29,"Starter projects with Spring using Java and Kotlin. Contains modules that covers Security with JWT, Spring with Kotlin, Dependency injection simplified etc.",custom-bean-validation dependency-injection jwt-authentication kotlin spring-mvc spring-security,"# spring-examples
Consists of examples that I've done in spring.
"
hibernate/hibernate-test-case-templates,main,59,320,2015-06-26T20:21:25Z,270,25,Templates and examples to report issues to Hibernate,,"# Hibernate Test Case Templates

When creating a bug report for any project within the Hibernate family, it's extremely helpful (and, frankly, required)
to have an adequate test case available.  This is obviously important to make reproducing the issue as easy as
possible.  But it's also vital longer-term.  Nearly every bug fix should include a regression test, which frequently is based
on the original reproducer (sometimes, it's the reproducer, verbatim).

To help create useful test cases, we're opening up this repo with various templates.  Please see the READMEs in each
project's subdir for more info.

As always, this is open source for a reason!  If these templates can be improved in any way, please let us know (either
through our JIRA instance or through GitHub Issues).  Better yet, send us a pull request!"
itext/itext-publications-examples-java,develop,99,88,2016-11-23T15:55:45Z,213825,19,,,
jveverka/spring-examples,java-17,106,49,2020-05-29T17:31:04Z,1375,2,Java 17  and Spring-Boot examples and demo projects.,arm64 docker java java-11 java-17 reactive-programming spring spring-boot spring-data spring-security springframework testcontainers testcontainers-junit-jupiter webflux x86-64,"[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Java17](https://img.shields.io/badge/java-17-blue)](https://img.shields.io/badge/java-17-blue)
[![Gradle](https://img.shields.io/badge/gradle-v7.3-blue)](https://img.shields.io/badge/gradle-v7.3-blue)
![Build and Test](https://github.com/jveverka/spring-examples/workflows/Build%20and%20Test/badge.svg)

# Spring-Boot examples
This project contains various simple or not-so simple [Spring Boot](https://spring.io/projects/spring-boot) examples.

### Environment setup
Minimal requirements: Please make sure following software is installed on your PC.
* [OpenJDK 17](https://adoptium.net/releases.html?variant=openjdk17&jvmVariant=hotspot)
* [Gradle 7.5](https://gradle.org/install/) or later

Please check [full system requirements](docs/system-requirements.md) for more details. 

### Compile and Run
```
gradle clean build test
gradle --build-file spring-api-first/build.gradle clean openApiGenerate build test
```

### Examples
* [__spring native__](spring-native) - Spring native & AOT demo.
* [__spring data__](spring-data) - JPA / Hibernate / spring data and Flyway demo.
* [__spring websocket__](spring-websockets) - simple websocket demo.
* [__spring demo__](spring-demo) - basic springboot application, actuator, buildinfo, swagger.
* [__spring proxy__](spring-proxy) - simple springboot http proxy demo.
* [__spring API first__](spring-api-first) - OpenAPI 3.0 API first application design.
* [__spring webflux__](spring-webflux) - Spring Webflux example.
* [__spring dependency injection__](spring-di) - simple dependency injection demo.
* [__spring jcasbin__](spring-jcasbin) - simple integration example of jcasbin in spring app.
* [__spring security__](spring-security) - cookie session tracking and web security.
* [__spring security-jwt__](spring-security-jwt) - JWT based web security.
* [__spring fileserver__](spring-fileserver) - simple file server ove REST APIs 
* [__spring_mockwebserver__](spring-mockwebserver) - simple http proxy service calling another service.  
* [__spring bank__](spring-bank) - simple transactional web application.
* [__spring_mongo__](spring-mongo) - simple springboot + mongodb with testcontainers example.

### Topics
* [__Spring Native__](https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/) - [Spring native case study.](spring-native)
* [__Reactive Spring__](https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html) - [Reactive Spring case study.](spring-webflux)
* [__JUnit5__](https://github.com/junit-team/junit5/) - [all projects]()
* __Security__ - [__spring security__](spring-security), [__spring jcasbin__](spring-jcasbin), [__spring security-jwt__](spring-security-jwt), [__spring-webflux__](spring-webflux)
* __Web/Http__ - [__spring proxy__](spring-proxy), [__spring fileserver__](spring-fileserver), [__spring websocket__](spring-websockets), [__spring API first__](spring-api-first), [__spring-webflux__](spring-webflux)
* [__Spring Data__](https://spring.io/projects/spring-data) - [__spring data__](spring-data), [__spring bank__](spring-bank)
* __Integrations__ - [__spring proxy__](spring-proxy), [__spring API first__](spring-api-first)

_Enjoy !_
"
mikailsheikh/cogitolearning-examples,master,52,65,2013-11-06T10:55:55Z,1460,2,All the examples for the tutorials on the Cogito Learning website.,,"cogitolearning-examples
=======================

All the examples for the tutorials on the Cogito Learning website.
"
andreaiacono/MapReduce,master,96,76,2014-02-15T21:44:13Z,35109,0,MapReduce by examples,mapreduce tutorial,"MapReduce
=========

Sample code of MapReduce talk for JUG Milano, available at https://www.slideshare.net/andreaiacono/mapreduce-by-examples

It contains the code for:
* a basic [WordCount](https://github.com/andreaiacono/MapReduce/tree/master/src/main/java/samples/wordcount) example 
* finding the [top-n used words in a text file with combiner](https://github.com/andreaiacono/MapReduce/tree/master/src/main/java/samples/topn)
* finding the [top-n used words in a text file with optimization](https://github.com/andreaiacono/MapReduce/tree/master/src/main/java/samples/topn_enhanced)
* [Computing the mean](https://github.com/andreaiacono/MapReduce/tree/master/src/main/java/samples/mean) of a set of numbers
* [Executing a join](https://github.com/andreaiacono/MapReduce/tree/master/src/main/java/samples/join) between two data files
* executing [K-means](https://github.com/andreaiacono/MapReduce/tree/master/src/main/java/samples/kmeans) clustering on a dataset


"
jboss-openshift/openshift-examples,master,27,86,2015-05-06T09:09:06Z,11250,4,,,"# openshift-examples
"
aws-samples/amazon-kinesis-data-analytics-examples,master,134,88,2019-04-22T16:39:36Z,54157,14,"Example applications in Java, Python and SQL for Kinesis Data Analytics, demonstrating sources, sinks, and operators.",,"## Amazon Managed Service for Apache Flink examples

--------

>  #### 🚨 August 30, 2023: Amazon Kinesis Data Analytics has been renamed to [Amazon Managed Service for Apache Flink](https://aws.amazon.com/managed-service-apache-flink).
--------

Example applications in Java, Python and SQL for Kinesis Data Analytics, demonstrating sources, sinks, and operators.

> #### ⚠️ We are updating and reorganising the Amazon Managed Service for Apache Flink code examples. <br/> Please, refer to the new repository [aws-samples/amazon-managed-service-for-apache-flink-examples](https://github.com/aws-samples/amazon-managed-service-for-apache-flink-examples/) with updated examples.

## License Summary

This sample code is made available under the MIT-0 license. See the LICENSE file.
"
mploed/ddd-with-spring,master,723,190,2018-03-28T15:27:17Z,581,3,Code examples for my conference talk on implementing ddd with spring,domain-driven-design spring-boot springframework,"# ddd-with-spring

<div align=""center"">

[![Build Status](https://travis-ci.org/mploed/ddd-with-spring.svg?branch=master)](https://travis-ci.org/mploed/ddd-with-spring)

</div>

This repository aims at showcasing a way how you could implement various aspects from Domain-driven Design with the
Spring ecosystem. It is also the demo project for my conference talk ""Implementing Domain-driven Design with the Spring 
ecosystem"".

## Which DDD aspects are covered?
The focus of the demo project are Aggregates, event-based communication and bounded contexts. The complete list is:

- Aggregates
- Event-based communication with
    - a message broker (RabbitMQ)
    - HTTP Feeds
    - Spring Application Events
- Architectural styles
    - Hexagonal Architecture
    - CRUD
    - Query-driven (not yet implemented properly)
    
## Which Spring Technologies are being used?

The project uses the following Spring technologies:

- Spring Framework Core
- Spring MVC
- Spring Boot
- Spring Cloud Stream 
- Spring Data JPA

## Prerequisites and getting started

In order to run the application you need to have Docker and docker-compose installed on your machine.

When you have docker up and running you need to perform the following steps on the command line:

1. ./mvnw clean package
2. docker-compose up --build
3. After everything has started you can open http://localhost:8080 in a browser of your choice
"
prowide/prowide-core-examples,master,76,69,2014-06-02T11:29:35Z,20604,0,"Source code examples for Prowide Core"""," open source SWIFT Java library""","# prowide-core-examples

Requirements
============
* Java 11+

## Source code examples for ""Prowide Core"" open source SWIFT Java library.

The examples are provided as simple main classes to clarified API frequently asked questions.
Comprehensive test cases can be found in the actual https://github.com/prowide/prowide-core project

For additional resources and documentation please check: http://dev.prowidesoftware.com/

run ""./gradlew eclipse"" or ""./gradlew idea"" to generate your local IDE setup

Then use your IDE run option on any example class to see its output

**Important Note on Library Versions**

Prowide regularly releases new versions of its libraries. As such, the versions of the libraries you use may need to be updated over time.
To check the latest versions and relevant changes, please visit the [Prowide Release Notes](https://dev.prowidesoftware.com/SRU2023-10/release-notes/changelog-consolidated/). It is recommended to regularly review this page and update your project's library versions accordingly to ensure compatibility and access to the latest features and fixes.


### Issues

For Prowide Core API issues please use https://github.com/prowide/prowide-core/issues
"
eazybytes/microservices-with-spring,main,108,171,2021-03-25T09:32:22Z,177,2,"Microservices With Spring, Docker, Kubernetes  - Code Examples",docker docker-compose java kubernetes microservices spring spring-boot spring-cloud,"# Master Microservices with Java, Spring, Docker, Kubernetes

[![Image](https://udemy-image-web-upload.s3.amazonaws.com:443/redactor/raw/article_lecture/2022-08-02_02-27-57-b721336be301d3848be7ec92142e646c.png ""Master Microservices with Java, Spring, Docker, Kubernetes"")](https://www.udemy.com/course/master-microservices-with-spring-docker-kubernetes/?referralCode=9365DB9B7EE637F629A9)

Learn how to create enterprise and production ready Microservices with Spring, Spring Cloud, Docker and Kubernetes.

## Topics covered in the course
* Section 1 - Introduction to Microservices Architecture
* Section 2 - Microservices & Spring Cloud (Match Made in Heaven)
* Section 3 - How do we right size our Microservices & Identifying boundaries(Challenge 1)
* Section 4 - Getting started with creation of accounts, loans & cards microservices
* Section 5 - How do we build, deploy, scale our microservices using Docker (Challenge 2)
* Section 6 - Introduction to Cloud Native Apps & 12factors
* Section 7 - Configurations Management in Microservices (Challenge 3)
* Section 8 - Service Discovery & Registration(Challenge 4)
* Section 9 - Making Microservices Resilient (Challenge 5)
* Section 10 - Handling Routing & Cross cutting concerns (Challenge 6)
* Section 11 - Distributed tracing & Log aggregation (Challenge 7)
* Section 12 - Monitoring Microservices Metrics & Health (Challenge 8)
* Section 13 - Automatic self-heal, autoscale, deployments (Challenge 9)
* Section 14 - Deploying all microservices into K8s cluster
* Section 15 - Deep Dive on Helm
* Section 16 - Securing Microservices using K8s Service
* Section 17 - Securing Microservices using OAuth2 client credentials grant flow
* Section 18 - Securing Microservices using OAuth2 Authorization code grant flow
* Section 19 - Introduction to K8s Ingress & Service Mesh (Istio)

## Pre-requisite for the course
- Good understanding on Java and Spring concepts
- Basic understanding on SpringBoot & REST services is a bonus but not mandatory
- Interest to learn and explore about Microservices

# Important Links
- Spring Cloud Project - https://spring.io/projects/spring-cloud
- Spring Cloud Config - https://spring.io/projects/spring-cloud-config
- Spring Cloud Gateway - https://spring.io/projects/spring-cloud-gateway
- Spring Cloud Netflix - https://spring.io/projects/spring-cloud-netflix
- Spring Cloud Sleuth - https://spring.io/projects/spring-cloud-sleuth
- The 12-factor App - https://12factor.net/
- Docker - https://www.docker.com/
- DockerHub - https://hub.docker.com/u/eazybytes
- Cloud Native Buildpacks - https://buildpacks.io/
- Resilience4j - https://resilience4j.readme.io/docs/getting-started
- Zipkin - https://zipkin.io/
- RabbitMQ - https://www.rabbitmq.com/
- Micrometer - https://micrometer.io/
- Prometheus - https://prometheus.io/
- Grafana - https://grafana.com/
- Kubernetes - https://kubernetes.io/
- GCP - https://console.cloud.google.com/
- GConsole -  https://cloud.google.com/sdk
- Helm -  https://helm.sh/
- Keycloak  -  https://www.keycloak.org/
- Istio -  https://istio.io/

## Maven Commands used in the course

|     Maven Command       |     Description          |
| ------------- | ------------- |
| ""mvn clean install -Dmaven.test.skip=true"" | To generate a jar inside target folder |
| ""mvn spring-boot:run"" | To start a springboot maven project |
| ""mvn spring-boot:build-image -Dmaven.test.skip=true"" | To generate a docker image using Buildpacks. No need of Dockerfile |

## Docker Commands used in the course

|     Docker Command       |     Description          |
| ------------- | ------------- |
| ""docker build . -t eazybytes/accounts"" | To generate a docker image based on a Dockerfile |
| ""docker run  -p 8081:8080 eazybytes/accounts"" | To start a docker container based on a given image |
| ""docker images"" | To list all the docker images present in the Docker server |
| ""docker image inspect image-id"" | To display detailed image information for a given image id |
| ""docker image rm image-id"" | To remove one or more images for a given image ids |
| ""docker image push docker.io/eazybytes/accounts"" | To push an image or a repository to a registry |
| ""docker image pull docker.io/eazybytes/accounts"" | To pull an image or a repository from a registry |
| ""docker ps"" | To show all running containers |
| ""docker ps -a"" | To show all containers including running and stopped |
| ""docker container start container-id"" | To start one or more stopped containers |
| ""docker container pause container-id"" | To pause all processes within one or more containers |
| ""docker container unpause container-id"" | To unpause all processes within one or more containers |
| ""docker container stop container-id"" | To stop one or more running containers |
| ""docker container kill container-id"" | To kill one or more running containers instantly |
| ""docker container restart container-id"" | To restart one or more containers |
| ""docker container inspect container-id"" | To inspect all the details for a given container id |
| ""docker container logs container-id"" | To fetch the logs of a given container id |
| ""docker container logs -f container-id"" | To follow log output of a given container id |
| ""docker container rm container-id"" | To remove one or more containers based on container ids |
| ""docker container prune"" | To remove all stopped containers |
| ""docker compose up"" | To create and start containers based on given docker compose file |
| ""docker compose stop"" | To stop services |

## Kubernetes Commands used in the course

|     Kubernetes Command       |     Description          |
| ------------- | ------------- |
| ""kubectl apply -f filename"" | To create a deployment/service/configmap based on a given YAML file |
| ""kubectl get all"" | To get all the components inside your cluster |
| ""kubectl get pods"" | To get all the pods details inside your cluster |
| ""kubectl get pod pod-id"" | To get the details of a given pod id |
| ""kubectl describe pod pod-id"" | To get more details of a given pod id |
| ""kubectl delete pod pod-id"" | To delete a given pod from cluster |
| ""kubectl get services"" | To get all the services details inside your cluster |
| ""kubectl get service service-id"" | To get the details of a given service id |
| ""kubectl describe service service-id"" | To get more details of a given service id |
| ""kubectl get nodes"" | To get all the node details inside your cluster |
| ""kubectl get node node-id"" | To get the details of a given node |
| ""kubectl get replicasets"" | To get all the replica sets details inside your cluster |
| ""kubectl get replicaset replicaset-id"" | To get the details of a given replicaset |
| ""kubectl get deployments"" | To get all the deployments details inside your cluster |
| ""kubectl get deployment deployment-id"" | To get the details of a given deployment |
| ""kubectl get configmaps"" | To get all the configmap details inside your cluster |
| ""kubectl get configmap configmap-id"" | To get the details of a given configmap |
| ""kubectl get events --sort-by=.metadata.creationTimestamp"" | To get all the events occured inside your cluster |
| ""kubectl scale deployment accounts-deployment --replicas=3"" | To increase the number of replicas for a deployment inside your cluster |
| ""kubectl set image deployment accounts-deployment accounts=eazybytes/accounts:k8s"" | To set a new image for a deployment inside your cluster |
| ""kubectl rollout history deployment accounts-deployment"" | To know the rollout history for a deployment inside your cluster |
| ""kubectl rollout undo deployment accounts-deployment --to-revision=1"" | To rollback to a given revision for a deployment inside your cluster |
| ""kubectl autoscale deployment accounts-deployment --min=3 --max=10 --cpu-percent=70"" | To create automatic scaling using HPA for a deployment inside your cluster |
| ""kubectl logs node-id"" | To get a logs of a given node inside your cluster |

## Helm Commands used in the course

|     Helm Command       |     Description          |
| ------------- | ------------- |
| ""helm create [NAME]"" | Create a default chart with the given name |
| ""helm dependencies build"" | To recompile the given helm chart |
| ""helm install [NAME] [CHART]"" | Install the given helm chart into K8s cluster |
| ""helm upgrade [NAME] [CHART]"" | Upgrades a specified release to a new version of a chart |
| ""helm history [NAME]"" | Display historical revisions for a given release |
| ""helm rollback [NAME] [REVISION]"" | Roll back a release to a previous revision |
| ""helm uninstall [NAME]"" | Uninstall all of the resources associated with a given release |
| ""helm template [NAME] [CHART]"" | Render chart templates locally along with the values |
| ""helm list"" | Lists all of the helm releases inside a K8s cluster |
"
mkyong/spring-embedded-database,master,61,109,2015-06-26T05:17:31Z,127,0,Spring Embedded Database Examples,,"Spring Embedded Database
===============================
Template for a Spring 4 MVC + Embedded Database examples, using HSQLDB, H2 and Derby.

###1. Technologies used
* Maven 3.0
* Spring 4.1.6.RELEASE
* HSQLDB 2.3.2
* H2 1.4.187
* Derby 10.11.1.1

###2. To Run this project locally
```shell
$ git clone https://github.com/mkyong/spring-embedded-database
$ mvn jetty:run
```
Access ```http://localhost:8080/spring-mvc-db/```

###3. To import this project into Eclipse IDE
1. ```$ mvn eclipse:eclipse```
2. Import into Eclipse via **existing projects into workspace** option.
3. Done.

###4. Project Demo
Please refer to this article [Spring Embedded Database  examples](http://www.mkyong.com/spring/spring-embedded-database-examples/)
"
heervisscher/htl-examples,master,95,47,2016-10-05T07:41:54Z,1148,1,AEM HTL examples,,"# htl-examples

### AEM compatibility
The package is only compatible with AEM6.4 SP2 and later.
It uses OSGi r7 annotations and HTL 1.4 syntax.  
Uses aem core components: https://github.com/adobe/aem-core-wcm-components/  
aem acs commoms: https://github.com/Adobe-Consulting-Services/acs-aem-commons/

## Included examples

### [OSGi R7](/core/src/main/java/com/adobe/examples/htl/core/service/impl/MySimpleServiceImpl.java)
Example use of OSGi r7 annotations

### [HTL 1.4](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/components/htl1_4/htl1_4.html)
Some example usages of HTL 1.4 syntax

### [CustomBindingProvider](/core/src/main/java/com/adobe/examples/htl/core/bindings/CustomBindingProvider.java)
Provides an example of a CustomBindingProvider, this if you want generic objects available in HTL

### [HashMapExample](/core/src/main/java/com/adobe/examples/htl/core/hashmap/HashMapExample.java)
Example on using a Map<> together with HTL

### [LinkedList](/core/src/main/java/com/adobe/examples/htl/core/linkedlist/MiniNav.java)
Code sample on using a LinkedList with HTL

### [Exporter](/core/src/main/java/com/adobe/examples/htl/core/models/PageExporterImpl.java)
Example on using Exporter-annotation with Sling-Models

### [Request parameter](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/samplecode/request-parameter.html)
How to get a request parameter in HTL

### [htl-maven-plugin](/ui.apps/pom.xml#L98-L99)
Validating HTL-files during build process

### [AutoCloseable](/core/src/main/java/com/adobe/examples/htl/core/service/AutoCloseableService.java)
Example on using AutoCloseable functionality, no need to close ResourceResolvers in code

### [Date-formatting](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/components/aem6.3/formatting/formatting.html)
Formatting your date-objects in HTL

### [Number-formatting](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/components/aem6.3/formatting/formatting.html)
Formatting numbers in HTL

### [Resource resolution in data-sly-use](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/components/aem6.3/button/button.html)
Example that shows the resolution of resources directly in HTL

### [RequestAttributes](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/components/aem6.3/product/product.html)
Passing in request-attributes to data-sly-resource and data-sly-include

### [OSGi annotations](/core/src/main/java/com/adobe/examples/htl/core/service/impl/MySimpleServiceImpl.java)
Example of the OSGi annotations, easy way to define OSGi properties.
Properties defined in [MyServiceConfiguration.java](/core/src/main/java/com/adobe/examples/htl/core/service/impl/MyServiceConfiguration.java), default config [here](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/config/com.adobe.examples.htl.core.service.impl.MySimpleServiceImpl.xml)


### [Java8 Iterator](/core/src/main/java/com/adobe/examples/htl/core/java8iterator/Java8Iterator.java)
Use of a lambda expression that is supported in Java8

### [Custom Sling-Model for the Title-component](/core/src/main/java/com/adobe/examples/htl/core/models/TitleImpl.java)
Example of a custom Sling-Model implementation, that is picked up from the core components.

### [CompositeValueMap](/core/src/main/java/com/adobe/examples/htl/core/models/CompositeValueMapModel.java)
Example of using the CompositeValueMap to merge properties of two ValueMaps

### [HealthCheck](/core/src/main/java/com/adobe/examples/htl/core/hc/HealthCheckExample.java)
Example of a basic healthcheck, that can be executed from the OSGi-console

### [HealthCheck card example](/ui.apps/src/main/content/jcr_root/apps/settings/granite/operations/hc/.content.xml)
Shows how to display a healthcheck card in the operations dashboard. To extend the default collection of healthchecks you need to use sling:configCollectionInherit on the /apps/settings/granite/operations/hc node

### [Custom Polling](/core/src/main/java/com/adobe/examples/htl/core/polling/CustomPolling.java)
Example of a custom poller that gets executed based on the information in the cq:PollConfig node. 

### [Datalayer mover](/core/src/main/java/com/adobe/examples/htl/core/datalayer/DatalayerFilter.java)
Common problem when defining a datalayer is that the JS-fragments are in the body,
while some of those need to be in the head. This filter is moving JS-fragments from the body into the head.

### [Flexible adapters](/ui.apps/src/main/content/jcr_root/apps/aemhtlexamples/components/aem6.3/flexibleadaptable/example.html)
Shows how to have a flexible way of using adapters, instead of always the same resource. Available since 6.3.1.1
"
Clever-Wang/spring-boot-examples,master,90,63,2018-05-13T05:00:41Z,232,3,springboot整合Shiro系列,,
arafalov/solr-indexing-book,master,43,21,2013-02-18T13:38:28Z,194,0,"Example code for the book Indexing Data in Apache Solr""""",examples solr,"Apache Solr for Indexing Data (Instant How-to)
==================

<div style=""float: left"">
    <img src=""https://github.com/arafalov/solr-indexing-book/raw/master/solr_book.jpg""/>
</div>


This repository contains examples and extra material for the  book [Instant Apache Solr for Indexing Data How-to](https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781782164845/1) by Alexandre Rafalovitch. The directory **published** contains the support files and collections as described in the book.
"
cloudbees/cloudbees-examples,master,35,71,2019-01-31T05:13:42Z,419,4,Public repository - Examples for documentation,,"# Welcome
Welcome to the CloudBees examples repository. This repository is a place for storing tutorials, examples, and other learning materials to complement mentions in product documentation.
Of note:

* It is owned and managed by the docs team.
* This repo contains assets that complement mentions in product documentation.  As such, it is not standalone.
* It is pre-populated with top-level product folders. Organize content in sub-folders appropriate to your files or projects.

## Managing asset links
* When providing a link in product documentation to a repo asset, consider using the raw link where appropriate. This gives the reader a cut/paste-ready version of the asset.
* Choose prudent filenames to minimize future renames. Simply moving a file to a new name breaks exiting links out in the wild. It is recommended to leverage symbolic links to effect ""redirects"". The following shows how to rename `origfile.yaml` and then create a hard link to this original name. As a result, links to the old name will automatically ""redirect"" to the new name.

  ```shell
  // move old file to new name
  git mv origfile.yaml newfile.yaml
  git commit -m ""commit message""
  git push

  // create link to old file
  ln  newfile.yaml origfile.yaml

  // add, commit, and push the symlink
  git add origfile.yaml
  git commit -m ""created symlink to the original file""
  git push
  ```

## In this repo
The following table is a brief summary of each of the example projects.

|Directory|Description  |
|:---|:---|
|cloudbees-build-test-automation|Example files referenced by CloudBees Build and Test Automation documentation.|
|cloudbees-cd|Example files referenced by CloudBees CD documentation.|
|cloudbees-ci|Example files referenced by CloudBees CI documentation.|
|cloudbees-feature-flags|Example files referenced by CloudBees Feature Flags documentation.|
|cloudbees-sdm|Example files for CloudBees SDM.|
|pipeline-template-examples|This repository includes a sample Pipeline Template Catalog. The demos folder includes examples of how to customize a template.yaml file.|
|helm-custom-value-file-examples|Custom Property Value Files for the CloudBees Core for Modern Platforms Helm installation.|
|flow-on-kubernetes|Sample property value files for CloudBees Flow on Kubernetes Helm installation.|
"
grundid/nfctools-examples,master,67,54,2012-03-29T13:17:30Z,205,8,Examples for the nfctools library,,
eclipse-ee4j/jakartaee-examples,main,110,43,2019-07-24T13:32:26Z,2867,9,Jakarta EE Examples,,"# Jakarta EE 10 Examples


This repository contains code examples for Jakarta EE 10.

A selection of these examples have an elaborate explanation in the Jakarta EE Tutorial. The tutorial content is located in the 
https://github.com/jakartaee/jakartaee-tutorial/ repository.

Note that this project, as the tutorial, is currently very much a work in progress.

### Types of examples

We use various different types of examples, as detailed below.

### Focused

[Focused](focused/README.md) examples demonstrate a single Jakarta technology and/or a single Jakarta API in a coherent and consistent way. 
Such focused examples are a little like an [SSCCE](http://sscce.org) (Short, Self Contained, Correct Example), 
but with a slightly different goal. Where the main purpose of an SSCCE is to be able to reproduce a bug, the purpose
of the focused example is to demonstrate a technology.

Each focused example is its own Maven module, and (typically) its own war. Such war can be deployed standalone to a server of choice, where it can be manually run, debugged, modified, etc.

To assure focused examples actually work, and as implicit documentation of how the example is run (what requests need to be done), most examples are accompanied by a test (in the future all examples should have a test). All tests follow the same pattern:

* A server/runtime is started (if needed)
* The actually build output of the Maven module (typically a war) is deployed to said server/runtime
* The test, which runs on the client, issues HTTP requests to the server/runtime
* The test assures the response of the server/runtime is expected
* The application is undeployed
* The server/runtime is stopped (if needed)

Focused examples use Maven for building and starting the tests and JUnit for defining and executing the tests. Arquillian is used, but only to start/stop a server, and to deploy/undeploy the test application for a given server/runtime.


### Tutorial

[Tutorial](tutorial/README.md) examples are examples that happen to be used in the current version of the tutorial. They are a mix of focused examples, and more elaborate examples. They are currently specifically a work in progress and may be moved to various other locations within this repo.

### Eleborate (future)

Eleborate examples are more complex and demonstrate multiple technologies and APIs to work together towards some practical goal.

### Applications (future)

Actual applications that are an example of how to use Jakarta EE for a specific sector, industry, or type of application. E.g. an example application for a pet store, a cargo tracker, etc.

See [Java EE Kickoff](https://github.com/javaeekickoff) for an idea of what example applications could be included here.
"
aterai/java-swing-tips,master,522,155,2014-09-09T10:51:59Z,62417,1,Java Swing example.,java swing,"java-swing-tips
===============
[日本語](https://ateraimemo.com/Swing.html): `Java Swing`の`GUI`プログラムを、 **小さなソースコード付きサンプル** を使って紹介しています。  
[English](https://java-swing-tips.blogspot.com/): Introduce the `GUI` program of `Java Swing` using **small source code examples**.

<img src=""https://lh3.ggpht.com/_9Z4BYR88imo/TQslJy3MxYI/AAAAAAAAAts/xrxOCvbp-0A/s800/screenshots.png"" />

Swingとは
---------------
[About the JFC and Swing (The Java™ Tutorials)][0]

`Swing`は、`GUI`(グラフィカル・ユーザ・インタフェース)を作成するための、`Java`標準のコンポーネントセット(ライブラリ、`UI`ツールキット)です。

Licence
---------------
- ソースコードはMITライセンスで公開しています。
    - https://github.com/aterai/java-swing-tips/blob/master/LICENSE.txt

編集方針
---------------
- **最も欲しいものはサンプル** [あるチュートリアルの思い出 - Backnumbers: Steps to Phantasien][1]
- **`SSCCE`** [Short, Self Contained, Correct Example][2]
- **`MCVE`** [How to create a Minimal, Complete, and Verifiable example - Help Center - Stack Overflow][3]

[0]: https://docs.oracle.com/javase/tutorial/uiswing/start/about.html
[1]: http://steps.dodgson.org/bn/2007/07/06/
[2]: http://sscce.org/
[3]: https://stackoverflow.com/help/mcve
"
erlieStar/rabbitmq-examples,master,91,47,2019-12-21T11:52:24Z,8271,7,rabbitmq各种用法示例,,"# RabbitMQ入门教程

## 模块

rabbitmq-api：原生api的使用

springboot-rabbitmq-annotation: springboot整合rabbitmq注解版本

springboot-rabbitmq-javaconfig: springboot整合rabbitmq javaconfig版本

springboot-rabbitmq-ack: 消息可靠投递的demo

## 教程

[RabbitMQ系列教程一：消息中间件的诸侯征战史](https://github.com/erlieStar/rabbitmq-examples/blob/master/docs/RabbitMQ%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E4%B8%80%EF%BC%9A%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E8%AF%B8%E4%BE%AF%E5%BE%81%E6%88%98%E5%8F%B2.md)

[RabbitMQ系列教程二：RabbitMQ的安装及图形界面的使用](https://github.com/erlieStar/rabbitmq-examples/blob/master/docs/RabbitMQ%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E4%BA%8C%EF%BC%9ARabbitMQ%E7%9A%84%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E7%9A%84%E4%BD%BF%E7%94%A8.md)

[RabbitMQ系列教程三：RabbitMQ最全特性一览及Java Api的使用](https://github.com/erlieStar/rabbitmq-examples/blob/master/docs/RabbitMQ%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E4%B8%89%EF%BC%9ARabbitMQ%E6%9C%80%E5%85%A8%E7%89%B9%E6%80%A7%E4%B8%80%E8%A7%88%E5%8F%8AJava%20Api%E7%9A%84%E4%BD%BF%E7%94%A8.md)

[RabbitMQ系列教程四：RabbitMQ整合Spring Boot](https://github.com/erlieStar/rabbitmq-examples/blob/master/docs/RabbitMQ%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E5%9B%9B%EF%BC%9ARabbitMQ%E6%95%B4%E5%90%88Spring%20Boot.md)

[RabbitMQ系列教程五：RabbitMQ如何保证消息的可靠投递](https://github.com/erlieStar/rabbitmq-examples/blob/master/docs/RabbitMQ%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E4%BA%94%EF%BC%9ARabbitMQ%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%8A%95%E9%80%92.md)

[RabbitMQ系列教程六：如何处理消费过程中的重复消息?](https://github.com/erlieStar/rabbitmq-examples/blob/master/docs/RabbitMQ%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E5%85%AD%EF%BC%9A%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E6%B6%88%E6%81%AF.md)

## 注意

有人向小编反映，看教程时图片会裂，因此导出了一个pdf版本，放在docs目录下（小编常年开vpn，一次也没遇到过）

因为加了一个pdf文件，可能git clone命令有点慢，多等一下就行了

## 联系我

email: erlie139@gmail.com

欢迎大家和我交流，关注公众号**Java识堂**获取我的联系方式
 
![欢迎fork和star](https://img-blog.csdnimg.cn/20200102100200903.jpg)
"
kpbird/NotificationListenerService-Example,master,255,131,2013-07-31T07:23:06Z,1592,9,NotificationListenerService Example,,"NotificationListenerService-Example
===================================

##Introduction
NotificationListenerService is introduced in Android 4.3 (API 18). It allows an application to receive information about notifications as it creates or removes. NotificationListenerService class is derived from the Service class. It has two abstract methods namely 1. onNotificationPosted 2. onNotificationRemoved.  
To use NotificationListenerService, we need to create a java file which extends NotificationListenerService and implement two callback methods. Both methods have a parameter named ""sbn"", which is an object of StatusBarNotification class. StatusBarNotification provides necessary information about Notifications.
NotificationListenerService provides facility to fetch active notifications using getActiveNotifications and also provides a feature to remove notifications using cancelAllNotifications.

##Useful Methods
1. NotificationListenerService
	* onNotificationPosted
	* onNotificationRemoved
2. StatusBarNotification
	* getId
	* getNotification
	* getPackageName
	* getPostTime
	* isClearable
	* isOngoing

##Note
User require to enable notification permission from ""Settings > Security > Notification access"".

![Mou icon](http://1.bp.blogspot.com/-7Q9G72-ZLCw/UfirCZP-H_I/AAAAAAAAEOk/aqX_YHs6s6Q/s400/device-2013-07-31-113010.png)
![Mou icon](http://1.bp.blogspot.com/-h_bFIcDWWp8/UfirCzDrC_I/AAAAAAAAEO0/9_aMH5EM6Dg/s400/device-2013-07-31-113539.png)
![Mou icon](http://2.bp.blogspot.com/-thl_wNKzILI/UfirDX6NR2I/AAAAAAAAEO4/_o5FWLmkJ2o/s400/device-2013-07-31-113701.png)
![Mou icon](http://1.bp.blogspot.com/-5KyUJQVOVzE/UfirDhqpFzI/AAAAAAAAEPA/RiZoI9dF--Q/s400/device-2013-07-31-113720.png)"
spdx/spdx-examples,master,108,42,2020-07-17T22:49:19Z,47728,11,Examples of SPDX files for software combinations,,"# SPDX Usage Examples

This repository includes demonstrations of [SPDX](https://spdx.dev) for various scenarios and use cases.

The repository is organized by profiles which represents a set of scenarios and use cases for a particular domain (e.g. security, license compliance).
Each directory contains a README.md file describing the profile and the examples contained within that directory.

The presentations directory contains examples included in various SPDX presentations.

Please note that this repository does not contain all of the supported fields nor all of the supported serialization formats in the latest version of the spec.  Please see the [SPDX Specification Examples](https://github.com/spdx/spdx-spec/tree/development/v2.3.1/examples) for the latest and examples that contain all of the supported fields and formats.

## Licenses

Copyright Contributors to the spdx-examples project.

Unless otherwise specified, source code in this repository is licensed under the GNU General Public License, Version 3 or later (GPL-3.0-or-later). A copy is included in the COPYING file.

Other licenses may be specified as well for certain files for purposes of illustration or where third-party components are used.

Documentation in this repository is licensed under the Creative Commons Attribution 4.0 International license (CC-BY-4.0), available at https://creativecommons.org/licenses/by/4.0/.

SPDX documents in this repository are provided under CC0 1.0 Universal (CC0-1.0), available at https://creativecommons.org/publicdomain/zero/1.0/.
"
weld/core,master,374,283,2010-08-05T19:41:31Z,57059,1,"Weld, including integrations for Servlet containers and Java SE, examples and documentation",,"Weld
====

[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/weld/user)
![GH Actions Build Status](https://github.com/weld/core/actions/workflows/ci-actions.yml/badge.svg)
[![Maven Central](http://img.shields.io/maven-central/v/org.jboss.weld.se/weld-se-shaded.svg)](http://search.maven.org/#search%7Cga%7C1%7Ca%3A%22weld-core-impl%22)
[![License](https://img.shields.io/badge/license-Apache%20License%202.0-yellow.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

Weld is the reference implementation of CDI: Contexts and Dependency Injection for the Java EE Platform which is the Java standard for dependency injection and contextual lifecycle management and one of the most important and popular parts of the Java EE platform.

Weld is integrated into many Java EE application servers such as WildFly, JBoss Enterprise Application Platform, GlassFish, Oracle WebLogic and others. Weld can also be used in a Servlet-only environment (Tomcat, Jetty) or plain Java SE environment.

See http://weld.cdi-spec.org for more details.

Building Weld
-------------

To build Weld simply run

> $ mvn clean install

Upgrading Weld in WildFly
-------------------------

Firstly, set the `JBOSS_HOME` environment property to point to your WildFly installation which already contains Weld 3 in older version:

> $ export JBOSS_HOME=/opt/wildfly

Then, run the upgrade script:

> $ mvn package -Pupdate-jboss-as -f jboss-as/pom.xml -Dweld.update.version=${weld.version}

In the above snippet, `${weld.version}` is the version of Weld you want to use.
Now you should have patched WildFly in `JBOSS_HOME`.

Running integration tests and the TCK on WildFly
----------------------------------------------------

Follow the steps above to set the JBOSS_HOME environment property and to upgrade Weld
within WildFly. Then, run:

> $ mvn clean verify -Dincontainer -f tests-arquillian/pom.xml

> $ mvn clean verify -Dincontainer -f jboss-tck-runner/pom.xml

If you want to run a specific test you can use the `-Dtest=<test_name>` flag. For example 

> $ mvn clean verify -Dincontainer -f jboss-tck-runner/pom.xml -Dtest=FireEventTest

Will run all the tests defined in `FireEventTest`.

> $ mvn clean verify -Dincontainer -f jboss-tck-runner/pom.xml -Dtest=FireEventTest#testInjectedEventAcceptsEventObject

Will only run the `FireEventTest.testInjectedEventAcceptsEventObject()` test method.
"
graphql-java/graphql-java-examples,master,101,56,2018-09-12T22:35:36Z,994,18,,,
bbejeck/kafka-streams,master,248,106,2016-03-01T02:14:08Z,6873,2,Code examples for working with Kafka Streams ,,"# kafka-streams
This is the repository for the examples of using Kafka streams covered in the blog posts: 

 *   [Kafka Streams - The Processor API](http://codingjunkie.net/kafka-processor-part1/)
 *   [Kafka Streams - The KStreams API](http://codingjunkie.net/kafka-streams-part2/)
 *   [Machine Learning with Kafka Streams](http://codingjunkie.net/kafka-streams-machine-learning/)


## Requirements to build this project

1.    Java 8
2.    Gradle

## Requirements to run the examples

1.    [kafka](https://github.com/apache/kafka) version kafka_2.11-0.10.1.0 see the section marked ""Running a task on a particular version of Scala""
2.    The [json-data-generator](https://github.com/acesinc/json-data-generator) from [ACES,Inc](http://acesinc.net/) 


## Setup Instructions

#### Extact the kafka_2.11-0.10.1.0.tgz file ####
    tar -xvzf kafka_2.11-0.10.1.0.tgz


#### Start zookeeper and kafka
```
      kafka-install-dir/bin/zookeeper-server-start.sh kafka-install-dir/conf/zookeeper.properties
      kafka-install-dir/bin/kafka-server-start.sh kafka-install-dir/conf/server.properties
```

#### Install the Json-Data-Generator  
Download the latest [json-data-generator release](https://github.com/acesinc/json-data-generator/releases) and follow the install instructions [here](http://acesinc.net/introducing-a-streaming-json-data-generator/)

#### Setup the kafka-streams repo
Clone or fork the repo
```
     git clone git@github.com:bbejeck/kafka-streams    
     cd kafka-streams
```     
Then copy the json config files to json generator conf directory
```
    cp streaming-workflows/* <dir>/json-data-generator-1.2.0/conf
```    
    
Create all the topics required by the examples
```
     ./bin/create-topics.sh /usr/local/kafka_2.11-0.10.1.0 localhost 2181
     args are kafka home, zookeeper host and zookeeper port adjust accordingly
```     

### Running the Purchase Processor API KStreams API Examples ###
     cd <dir>/json-data-generator-1.2.0/
     java -jar json-data-generator-1.2.0 purchases-config.json
     cd kafka-streams
     ./gradlew runPurchaseProcessor | runPurchaseStreams
     

### Running the Stock Trades Processor API or KStreams API Examples ###
     cd <dir>/json-data-generator-1.2.0/
     java -jar json-data-generator-1.2.0 stock-transactions-config.json
     cd kafka-streams
     ./gradlew runStockProcessor | runStockStreams
     
### Running the Twitter KStreams Language Classification Example ###
    rename src/main/resources/twitter-app.properties.template to twitter-app.properties 
    fill out the properties file with all the required values
    
    cd kafka-streams
    ./gradlew runTwitterKstreamNLP 

### Viewing the results of the purchase streaming examples ###
    cd kafka_install-dir/bin
    ./kafka-console-consumer --topic [patterns|rewards|purchases] --zookeeper localhost:2181
     
### Viewing the results of the stock-trading streaming examples ###
    cd kafka_install-dir/bin
    ./kafka-console-consumer --topic [stocks-out|transaction-summary] --zookeeper localhost:2181
    
### Viewing the results of the Twitter KStreams Language Classification Example ###
    cd kafka_install-dir/bin
    ./kafka-console-consumer --topic [english|french|spanish] --zookeeper localhost:2181    
          
"
newrelic/newrelic-opentelemetry-examples,main,85,58,2021-04-16T21:08:25Z,4118,7,Examples for sending OpenTelemetry sourced data to New Relic.,,"<a href=""https://opensource.newrelic.com/oss-category/#example-code""><picture><source media=""(prefers-color-scheme: dark)"" srcset=""https://github.com/newrelic/opensource-website/raw/main/src/images/categories/dark/Example_Code.png""><source media=""(prefers-color-scheme: light)"" srcset=""https://github.com/newrelic/opensource-website/raw/main/src/images/categories/Example_Code.png""><img alt=""New Relic Open Source example project banner."" src=""https://github.com/newrelic/opensource-website/raw/main/src/images/categories/Example_Code.png""></picture></a>

# New Relic OpenTelemetry Examples

This project contains examples illustrating usage of OpenTelemetry with New Relic. The examples aim to demonstrate the most common configurations we expect users to encounter, but isn't an exhaustive set of the ways you can use OpenTelemetry with New Relic. See [getting started guides](#getting-started-guides) and [other examples](#other-examples) for an index of available examples.

## Getting Started Guides

The [Getting Started Guides](./getting-started-guides/README.md) demonstrate how to get started with OpenTelemetry and New Relic. Each of the languages listed illustrates how to add OpenTelemetry instrumentation to a simple web application, and configure OpenTelemetry to export data to New Relic.

* .NET ([uninstrumented](./getting-started-guides/dotnet/Uninstrumented) / [instrumented](./getting-started-guides/dotnet/Instrumented))
* Go ([uninstrumented](./getting-started-guides/go/uninstrumented) / [instrumented](./getting-started-guides/go/instrumented))
* Java ([uninstrumented](./getting-started-guides/java/uninstrumented) / [instrumented](./getting-started-guides/java/instrumented))
* Javascript ([uninstrumented](./getting-started-guides/javascript/uninstrumented) / [instrumented](./getting-started-guides/javascript/instrumented))
* Python ([uninstrumented](./getting-started-guides/python/Uninstrumented) / [instrumented](./getting-started-guides/python/Instrumented))
* Ruby ([uninstrumented](./getting-started-guides/ruby/uninstrumented) / [instrumented](./getting-started-guides/ruby/instrumented))

## Other Examples

OpenTelemetry is a big ecosystem and everything doesn't fit into the goals of the [getting started guides](#getting-started-guides). These ""other examples"" demonstrate how other areas of OpenTelemetry fit in with New Relic. 

* Collector
  * [OpenTelemetry Collector with OTLP and New Relic](./other-examples/collector/nr-config)
  * [OpenTelemetry Collector with Host Monitoring and New Relic](./other-examples/collector/host-monitoring)
  * [OpenTelemetry Collector with Confluent Cloud and New Relic](./other-examples/collector/confluentcloud)
  * [OpenTelemetry Collector with Singlstore and New Relic](./other-examples/collector/singlestore)
  * [OpenTelemetry Collector with HCP Consul and New Relic](./other-examples/collector/hcp-consul)
* Java
  * [OpenTelemetry Agent New Relic Config](./other-examples/java/agent-nr-config)
  * [Micrometer Shim with OTLP Export](./other-examples/java/micrometer-shim)
  * [Logs In Context with Log4j2 and Log Forwarding](./other-examples/java/logs-in-context-log4j2)
* .NET
  * [OpenTelemetry Agent With New Relic Config](./other-examples/dotnet/agent-nr-config)
* Serverless
  * AWS Lambda
    * [OpenTelemetry Lambda .NET New Relic Config](./other-examples/serverless/aws-lambda/dotnet)
    * [OpenTelemetry Lambda Java New Relic Config](./other-examples/serverless/aws-lambda/java)
  * Azure Functions
    * [OpenTelemetry Azure Functions Node New Relic Config](./other-examples/serverless/azure-functions/node/http-trigger-app)

## How To Use

1. Clone this repo.
2. Follow the directions in the README of the example that you are interested in.

## Contribute

We encourage your contributions to improve `newrelic-opentelemetry-examples`! Keep in mind that when you submit your pull request, you'll need to sign the CLA via the click-through using CLA-Assistant. You only have to sign the CLA one time per project.

Generally, we want to focus on the [getting started guides](#getting-started-guides). We're open to additional examples being added which are aligned with the [demo app specification](./getting-started-guides/demo-app-specification.md) and which have a volunteer [codeowner](#codeowners).

We're more selective about additions to [other examples](#other-examples). We use the following criteria to evaluate additions:

* Does the example demonstrate a very popular use case or recurring pain point?
* Has someone has volunteered to be a [codeowner](#codeowners)?
* Is there documentation - either in the readme or [docs.newrelic.com](https://docs.newrelic.com/) - which describes how to use the data produced by the example in New Relic?
* Is there continuous integration (i.e. [github action](.github/workflows/pull_request.yml)) ensuring that the example code functions?

If the answer is yes to all those questions, we'll likely accept the contribution.

If you have any questions, or to execute our corporate CLA (which is required if your contribution is on behalf of a company), drop us an email at opensource@newrelic.com.

### Codeowners

Codeowners for each example are defined in [codeowner](.github/CODEOWNERS). Each codeowner is responsible for:

* Keeping dependencies (relatively) up to date.
* Responding to issues related to the example.

Codeowners are added as collaborators individually and given ""write"" permissions to the repository.

Examples without a codeowner may be deleted.

## Vulnerabilities

As noted in our [security policy](https://github.com/newrelic/newrelic-opentelemetry-examples/security/policy), New Relic is committed to the privacy and security of our customers and their data. We believe that providing coordinated disclosure by security researchers and engaging with the security community are important means to achieve our security goals.

If you believe you have found a security vulnerability in this project or any of New Relic's products or websites, we welcome and greatly appreciate you reporting it to New Relic through [HackerOne](https://hackerone.com/newrelic).

If you would like to contribute to this project, review [these guidelines](./CONTRIBUTING.md).

To all contributors, we thank you!  Without your contribution, this project would not be what it is today.

## License
`newrelic-opentelemetry-examples` is licensed under the [Apache 2.0](http://apache.org/licenses/LICENSE-2.0.txt) License.

`newrelic-opentelemetry-examples` also uses source code from third-party libraries. You can find full details on which libraries are used and the terms under which they are licensed in the third-party notices document.
"
howtoprogram/junit5-examples,master,74,62,2016-08-12T16:26:06Z,201,4,"JUnit 5 examples, tutorials",,"#JUnit 5 Examples

Contains all JUnit 5 Examples and Tutorial

Go to each sub project.

## 1. Import source code into Eclipse
### Maven

Menu **File –> Import –> Maven –> Existing Maven Projects**

Browse to your source code location

Click **Finish** button to finish the importing

### Gradle
Menu **File –> Import –> Gradle Project –> Select Project --> Next until finish**
## 2. Sub Modules
[JUnit 5 Assertions Example](http://howtoprogram.xyz/2016/08/12/junit-5-assertions-example/)
### junit5-assertions-examples

[JUnit 5 Disable or Ignore A Test](http://howtoprogram.xyz/2016/08/14/junit-5-disable-ignore-tests/)
### junit5-disable-test-example

[JUnit 5 Exception Testing](http://howtoprogram.xyz/2016/08/15/junit-5-exception-testing/)
### junit5-exception-testing-example

[JUnit 5 Test Suite ](http://howtoprogram.xyz/2016/08/16/junit-5-test-suite/)
### junit-5-test-suite-example

[JUnit 5 Assumptions With Assume](http://howtoprogram.xyz/2016/08/17/junit-5-assumptions-assume/)
### junit-5-assumptions

[JUnit 5 Nested Tests Examples](http://howtoprogram.xyz/2016/08/19/junit-5-nested-tests-examples/)
### junit5-nested-test-example

[JUnit 5 Dynamic Tests - Generate Tests at Run-time](http://howtoprogram.xyz/2016/08/21/junit-5-dynamic-tests/)
### junit5-dynamic-test-example

[JUnit 5 Maven Example](http://howtoprogram.xyz/2016/09/09/junit-5-maven-example/)
### junit5-maven-example

## 3. Related Posts
## [JUnit 5 Tutorial](http://howtoprogram.xyz/java-technologies/junit-5-tutorial/)
## [JUnit 5 vs JUnit 4](http://howtoprogram.xyz/2016/08/10/junit-5-vs-junit-4/)
## [JUnit 5 Basic Introduction](http://howtoprogram.xyz/2016/08/07/junit-5-basic-introduction/)
## [JUnit 5 and Spring Boot Example](https://howtoprogram.xyz/2017/09/12/junit-5-spring-boot-example/)
"
eclipse-ditto/ditto-examples,master,89,43,2017-10-30T17:47:24Z,10683,9,Eclipse Ditto™: Digital Twin framework - Examples,eclipse-ditto examples hacktoberfest java,"# Eclipse Ditto :: Examples

[![Join the chat at https://gitter.im/eclipse/ditto](https://badges.gitter.im/eclipse/ditto.svg)](https://gitter.im/eclipse/ditto?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

This repository contains examples and demonstrations of how to use [Eclipse Ditto](https://github.com/eclipse/ditto).

# Projects

## [grove control](grove-ctrl/)

The grove control project shows the different communication possibilities
using Eclipse Ditto on your local machine and a Rasperry Pi with GrovePi+ board
as IoT device. This project uses Python for the Raspberry Pi code and jQuery for the Web UI.

## [Rest to WebSocket demo](rest-to-websocket/)

This example shows how to combine the REST and WebSocket API of Eclipse Ditto.
This is demonstrated using a Frontend that sends REST requests and
a Thing that has a WebSocket connection to Ditto and uses it to receive
and respond to Messages. This project requires a running Eclipse Ditto
instance and a modern web browser.

## [Octopus via Hono to Ditto](octopus-via-hono/)

Arduino based example on a ESP8266 board publishing read out sensor values in Ditto Protocol via
the MQTT endpoint of [Eclipse Hono](https://www.eclipse.org/hono/) to a digital twin in Ditto:

- BME680 sensor
  - temperature
  - humidity
  - barometer
- BNO055 sensor
  - temperature
  - linear acceleration
  - angular velocity
  - gravity
  - absolute orientation
  - accelerometer
  - magnetometer
- power voltage

## [IoT-Device connected directly to Ditto via MQTT - controlled by a custom solution](mqtt-bidirectional/)

This example demonstrates how to connect an Arduino based device to Eclipse Ditto and how
payload mapping can be utilized to transform its telemetry data into a valid digital twin representation.
Furthermore a simple front-end allows manipulating the digital twin and receives twin updates
via SSE (Server Sent Events).

### Parts of this example

- Arduino
  - How to establish a network connection
  - How to establish a MQTT connection
  - How to receive and publish valid JSON data
- Front-end
  - How to use Ditto's HTTP API for
    - Create policy and things
    - Create a connection (MQTT)
    - Send live messages to device
    - Listen to server sent events
- Eclipse Ditto
  - How to set up Eclipse Ditto with Docker (alternatively use Ditto's Sandbox)
  - How to apply payload mapping on incoming messages from a connection

## [Quick introduction to MQTT in Ditto](mqtt-quick-introduction/)

This example demonstrates how to setup step by step MQTT connection in Ditto.
It presents how to updates things in Ditto and how to receive notifications that something was changed.

## [Samples for Microsoft Azure users](azure/)

Samples to leverage Eclipse Ditto capabilities with Microsoft Azure services.

## [kata](kata/)

A code kata is a way of learning new things and consolidating what has been learned. The presented katas serve to 
understand specific features of ditto better.
"
nitinsurana/Struts2-Examples,master,44,70,2013-07-13T05:11:21Z,11071,24,Struts2 Examples,,"Struts2
=======

Struts2 Examples
"
apache/camel-k-examples,main,74,60,2020-04-17T09:58:05Z,743,7,Apache Camel K Examples,camel integration java,"# Camel K Examples

This repository contains a collection of Camel K examples useful to understand how it works, common use cases and the idiomatic programming model.

You can find more information about Apache Camel and Apache Camel K on the [official Camel website](https://camel.apache.org).

## Before you begin

### Open the examples in the IDE

To better work on all examples, make sure you have all them locally by checking out the git repository:

```
git clone git@github.com:apache/camel-k-examples.git
```

We suggest you to open the examples with [VSCode](https://code.visualstudio.com/) because it provides useful extensions for working with Camel K files.
If you've already installed it on your machine, after cloning the repository, you can open the examples on the IDE executing:

```
code camel-k-examples
```

We suggest you to install the following extensions for VSCode (The IDE should automatically prompt to ask you to install them):
- [Extension Pack for Apache Camel](https://marketplace.visualstudio.com/items?itemName=redhat.apache-camel-extension-pack): provides auto-completion, error handling as well as integrated IDE tools to manage the lifecycle of Camel K integrations
- [Didact](https://marketplace.visualstudio.com/items?itemName=redhat.vscode-didact): Provides a better getting started experience when following readme files in the various examples

### Have your Kubernetes cluster ready

All examples require that you are connected to a Kubernetes/OpenShift cluster, even a local instance such as [Minikube](https://github.com/kubernetes/minikube) or [CRC](https://github.com/code-ready/crc). Some advanced examples may have additional requirements.

Ensure that you've followed the [Camel K installation guide](https://camel.apache.org/camel-k/latest/installation/installation.html) for your specific cluster before looking at the examples.

### Install the CLI tools

All examples need at least the following CLI tools installed on your system:

- `kubectl`: the Kubernetes default CLI tool that can be downloaded from the [Kubernetes releases page](https://github.com/kubernetes/kubernetes/releases).
- `kamel`: the Apache Camel K CLI that can be downloaded from the [Camel K release page](https://github.com/apache/camel-k/releases).

## Generic Examples

We are providing also a folder containing multiple generic examples in [Generic Examples](./generic-examples) folder.

## Kamelets

In the [Kamelets](./kamelets) folder, you'll get a set of examples based on Kamelets.

## Custom Examples

Examples are contained in directories ordered by level of difficulty.

Most examples provide a `readme.didact.md` file instead of the standard readme file. For those, if you're using VSCode with Didact installed, you can **right click on the `readme.didact.md` file and hit ""Didact: Start Didact Tutorial from File""**.

This is the current list of examples:

- [01 Basic](./01-basic): Getting started with Camel K by learning the most important features that you should know before trying to develop more complex examples.
- [02 Serverless API](./02-serverless-api): Learn how to design an API that manages files in a remote storage location and leverages *Knative* Serving to scale automatically (even to zero instances) based on the current load.
- [03 Knative Source Basic](./03-knative-source-basic): Getting started with Knative Camel Source by learning the most important concepts you should know before trying to develop more complex examples.
- [04 AWS Kinesis Source Basic](./04-aws-kinesis-source-basic): Learn how to consume AWS Kinesis events using Knative Camel Source.
- [10 Knative Source Salesforce](./10-knative-source-salesforce): Learn how to create a Knative Camel Source for Salesforce.
- [11 Knative Source Slack](./11-knative-source-slack): Getting started with Slack integration using Knative Camel Source.
- [90 AWS Kinesis Source With a Custom Configuration](./90-aws-kinesis-customized-event-source): Learn how to use a custom AWS Kinesis configuration when consuming AWS Kinesis events using Knative Camel Source.
"
kevinsawicki/github-maven-example,master,137,937,2011-09-02T01:11:54Z,141,21,Example project using GitHub Maven Plugins,java,"This is an example project that uses the [GitHub Maven Plugins](https://github.com/github/maven-plugins).

See the [POM file](https://github.com/kevinsawicki/github-maven-example/blob/master/example/pom.xml)
for how the downloads plugin and site plugin are configured.

# Getting started

* Fork this project
* Update the `pom.xml` file `<url>` element to be the address of your fork
* Optionally update `<scm>` and `<developers>` section as well to have the information for your fork
* Add the following to your Maven `settings.xml` file updated with your GitHub login name and password:

```xml
<servers>
  <server>
    <id>github</id>
    <username>user</username>
    <password>password</password>
  </server>  
</servers>
```

# Using the downloads plugin

```
$ cd github-maven-example/example
$ mvn clean install
```

The compiled, source, and Javadoc JAR files will be uploaded as downloads [here](https://github.com/kevinsawicki/github-maven-example/downloads).

# Using the site plugin

```
$ cd github-maven-example/example
$ mvn site
```

The generated site will be committed to the [gh-pages branch](https://github.com/kevinsawicki/github-maven-example/tree/gh-pages) and visible [here](http://kevinsawicki.github.com/github-maven-example/).
"
Red5/red5-examples,master,49,71,2014-05-01T03:58:15Z,22858,5,Example code for use with Red5 projects,java,"red5-examples
=============

Example code for use with Red5 projects
"
shiffman/Box2D-for-Processing,master,284,75,2011-03-04T02:46:53Z,5663,14,Processing JBox2D helper library and examples,,"# Box2D for Processing

A Processing library wrapping JBox2D (http://www.jbox2d.org/).

Download library: http://shiffman-archive.netlify.app/p5/libraries/box2d_processing/box2d_processing.zip

Tutorial and further examples for this library are available in The Nature of Code book: http://natureofcode.com.
"
SpoonLabs/spoon-examples,master,80,44,2015-01-16T13:23:46Z,5718,0,Examples on how to use the  Spoon Java source code transformation library ,,"# Spoon Examples

## Introduction

spoon-examples gives analysis and transformation processors showing the usage of the open-source library [Spoon](https://github.com/INRIA/spoon).

You can see these processors in:

- [`src/main/java/fr/inria/gforge/spoon/analysis`](https://github.com/SpoonLabs/spoon-examples/tree/master/src/main/java/fr/inria/gforge/spoon/analysis) for analysis.
- [`src/main/java/fr/inria/gforge/spoon/transformation`](https://github.com/SpoonLabs/spoon-examples/tree/master/src/main/java/fr/inria/gforge/spoon/transformation) for transformation.
  - [notnullcheck](https://github.com/SpoonLabs/spoon-examples/tree/master/src/main/java/fr/inria/gforge/spoon/transformation/notnullcheck) improves reliability
  - [bound](https://github.com/SpoonLabs/spoon-examples/tree/master/src/main/java/fr/inria/gforge/spoon/transformation/bound) is a transformation based on annotations
  - [mutation](https://github.com/SpoonLabs/spoon-examples/tree/master/src/main/java/fr/inria/gforge/spoon/transformation/mutation) is a simple mutation testing engine
  - [spoonerism](https://github.com/SpoonLabs/spoon-examples/tree/master/src/main/java/fr/inria/gforge/spoon/transformation/spoonerism) a basic example of transforming classes to extend a common parent class.  Accompanied by the [spoonerism.fodp](https://github.com/SpoonLabs/spoon-examples/blob/master/docs/spoonerism.fodp) presentation.


## Usage

You can run the tests of the project with a `mvn test` command on the root of the project to execute all examples (all test classes).

```console
git clone https://github.com/SpoonLabs/spoon-examples.git
cd spoon-examples
mvn test
```

"
fusioninsight/fusioninsight_hd_examples,master,67,61,2018-10-09T13:03:43Z,31689,48,,,Hello Fusioninsight_HD_Examples
mark-watson/Java-AI-Book-Code,master,244,119,2012-02-11T17:44:19Z,121984,0,Code examples for my Java artificial intelligence book,,"# Code for the 2020 edition of ""Practical Artificial Intelligence With Java""

The previous edition was released in 2013. The new 2020 edition is largely a rewrite of older material with the addition of new material. The 2020 edition was published July 28, 2020 and this repository was updated to remove all old code and add new and modified examples. See below for information on getting the old code and the PDF for the 2013 edition.

[Leanpub Link for latest edition](https://leanpub.com/javaai)

This book is a combination of

- new coverage of deep learning
- new material: creating and using knowledge graphs
- examples from my discontinued book ""Power Java"": anomaly detection, linked data, using DBPedia, OpenNLP, and web scraping
- examples from the original editions of this book: genetic algorithms and search algorithms 
- a few examples updated from my discontinued book ""Practical Semantic Web and Linked Data Applications, Java Edition""

You can find the older code for the 2013 4th edition here: [https://github.com/mark-watson/Java-AI-Book-Code_4th_edition](https://github.com/mark-watson/Java-AI-Book-Code_4th_edition)

"
skadistats/clarity-examples,master,106,37,2014-03-08T18:21:42Z,385,4,Example code for clarity,,"# Clarity-examples

This project contains example code for the [clarity replay parser](https://github.com/skadistats/clarity).

## Introduction

Clarity 2 uses an event based approach to replay analysis. To use it, you have to supply one or more
processors to clarity. A processor is a simple POJO, that you enrich with annotations, which tell
clarity what kind of data you want to receive.
 
This simple yet fully working example prints all messages from all chat (Source 2):

```java
public class AllChatProcessor {
    @OnMessage(S2UserMessages.CUserMessageSayText2.class)
    public void onMessage(Context ctx, S2UserMessages.CUserMessageSayText2 message) {
        System.out.format(""%s: %s\n"", message.getParam1(), message.getParam2());
    }
    public static void main(String[] args) throws Exception {
        // 1) create an input source from the replay
        Source source = new MappedFileSource(""replay.dem"");
        // 2) create a simple runner that will read the replay once
        SimpleRunner runner = new SimpleRunner(source);
        // 3) create an instance of your processor
        AllChatProcessor processor = new AllChatProcessor();
        // 4) and hand it over to the runner
        runner.runWith(processor);
    }
}
```

The main method does the following:

1. Creates a source from the replay file. In this case, a MappedFileSource is used, which needs a locally available file
   to work. This is the fastest implementation, but there is also an InputStreamSource, which lets you create a source 
   from any InputStream you can come up with.
2. Create a runner with your source. The runner is what drives the replay analysis. The SimpleRunner we use in this case
   will simply run over the whole replay once. There is also a more sophisticated ControllableRunner, which uses a separate
   thread for doing the work, and which allows seeking back and forth in the replay. 
3. Create an instance of your processor. Please note that you are not limited to only using one processor, and clarity itself
   contains a lot of processors that might take part in the run if what you requested requires it.
4. This starts the processing run. Your annotated method onMessage() will be called back whenever clarity finds an 
   allchat-message in the replay.

### Building / running the examples

All provided examples can be build with Gradle. The build process yields an ""uno-jar"", that is a jar 
containing all the dependencies, which can be called from the command line easily without having to 
set a correct classpath. Alternatively, you can use Gradle to run an example directly.

All following commands have to be issued in the root of the project.


#### Building

Windows:

    gradlew.bat <exampleName>Package 
    
Linux / Mac:

    ./gradlew <exampleName>Package

#### Running the built uno-jar

Windows:

    java -jar build\libs\<exampleName>.jar replay.dem 

Linux / Mac:

    java -jar build/libs/<exampleName>.jar replay.dem

#### Running from Gradle

Windows:

    gradlew.bat <exampleName>Run --args ""path\to\replay.dem"" 

Linux / Mac:

    ./gradlew <exampleName>Run  --args ""path/to/replay.dem""


### Logging

Clarity uses the logback-library for logging. You can enable logging for certain packages by changing 
`src/main/resources/logback.xml`.  

## Examples

### AllChat


You can find an executable example of the example above under [skadistats.clarity.examples.allchat.Main.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/allchat/Main.java).
Follow the instructions above to build and run it with

    <exampleName> = allchat

### Watching the data in real time

[Clarity Analyzer](https://github.com/spheenik/clarity-analyzer) is nifty little JavaFX Application 
that lets you see all the entity data in the replay in real time.
 
![Clarity Analyzer](https://raw.githubusercontent.com/spheenik/clarity-analyzer/master/screenshot.png)

### Showing the combat log

This example *almost* replicates what is shown on the combat log from the game.
It has problems with finding out if some modifier applied to a unit is a buff or a debuff, 
and it doesn't know how to convert the technical hero names to plain english... but otherwise it has it all :)

You can find it under [skadistats.clarity.examples.combatlog.Main.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/combatlog/Main.java).
Follow the instructions above to build and run it with

    <exampleName> = combatlog

### Show stats at the end of the game

This example shows how to use the PlayerResource entity as well as the ControllableRunner.
It outputs the score table at the end of the match. For getting to the result as fast as possible, it does not 
run the complete replay, but instead uses the ControllableRunner to directly seek to the last tick in the replay.

You can find it under [skadistats.clarity.examples.matchend.Main.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/matchend/Main.java).
Follow the instructions above to build and run it with

    <exampleName> = matchend

### Tracking spawns / deaths

This example shows how to write a processor that provides events related to the lifestate of an entity.
The processor provides 3 new events (`@OnEntitySpawned`, `@OnEntityDying` and `@OnEntityDied`) and an associated
main class that uses them.

You can find the processor under [skadistats.clarity.examples.lifestate.SpawnsAndDeaths.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/lifestate/SpawnsAndDeaths.java),
and the class that uses it under [skadistats.clarity.examples.lifestate.Main.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/lifestate/Main.java). 

Follow the instructions above to build and run it with

    <exampleName> = lifestate

### Retrieving basic game info

For retrieving the basic game information (players, picks, bans, who won), 
you do not need to iterate the replay. You can retrieve that info with the following code

```Java
public class Main {
    public static void main(String[] args) throws Exception {
        CDemoFileInfo info = Clarity.infoForFile(args[0]);
        System.out.println(info);
    }
}
```

You can find this example under [skadistats.clarity.examples.info.Main.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/info/Main.java).
Follow the instructions above to build and run it with

    <exampleName> = info


### Send table inspection (Source 1)

Dota 2 is a game made with the Source engine from Valve. Source manages a set of networked entities
which exist on the server and are propagated to the client. A lot of stuff you see in a dota match is a networked entity,
for example the heros, creeps and buildings, but also statistical information about the game, like
the current game time, scoreboard, etc. You can find some information about networked entities in the 
[Valve Developer Community Wiki](https://developer.valvesoftware.com/wiki/Networking_Entities).

Since the Dota client is constantly changing and improving, there is no fixed format for what data (properties) these
entities contain. To be able to replay a replay recorded on an old client on a newer version, the replay 
contains definitions of exactly what entities with what properties it contains. These definitions are
called send tables.

This example shows the format of the entity data in a certain replay.

You can find it under [skadistats.clarity.examples.dtinspector.Main.java](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/dtinspector/Main.java).
Follow the instructions above to build and run it with

    <exampleName> = dtinspector
	
and it will open a window which lets you explore the send tables in an interactive manner.


## Under the hood

### Events / Providers

Clarity is driven by a small annotation driven event system. Clarity provides basic events, like @OnMessage, 
which is used to get a callback whenever a message of a certain type is found in the replay.

If you want, you can subscribe to those events directly, for example to create a dump of the replay.

But those events can also be used to listen for certain data in the replay and refine the raw data into more
sophisticated events. One example from Clarity is the GameEvents processor, which listens for raw messages of type
CSVCMsg_GameEventList and CSVCMsg_GameEvent and transforms their content into an easier to use form:

```java
@Provides(OnGameEvent.class) // 1. register as a provider for @OnGameEvent
public class GameEvents {
    @OnMessage(NetMessages.CSVCMsg_GameEventList.class)
    public void onGameEventList(Context ctx, NetMessages.CSVCMsg_GameEventList message) {
        // 2. process the incoming message, and create GameEventDescriptors from it  
    }
    @OnMessage(NetworkBaseTypes.CSVCMsg_GameEvent.class)
    public void onGameEvent(Context ctx, NetworkBaseTypes.CSVCMsg_GameEvent message) {
        // 3. use the GameEventDescriptors from 2, to create a single GameEvent
        GameEvent e = new GameEvent(descriptor);
        // 4. raise @OnGameEvent
        ctx.createEvent(OnGameEvent.class, GameEvent.class).raise(e);
    }
```

1. the @Provides-annotation tells clarity that this processor is able to supply @OnGameEvent events.
   So whenever some processor gets added to the run that listens for this event, Clarity will make sure an instance
   of GameEvents is also part of the run to supply those events.
2. The exact structure of GameEvents in this replay is encoded in a CSVCMsg_GameEventList message. 
3. Create a single GameEvent, by using the descriptors created in 2.
4. fire the @OnGameEvent event, passing the created GameEvent as parameter.

Another example for creating your own event provider is [a provider for spawn / death events](https://github.com/skadistats/clarity-examples/blob/master/src/main/java/skadistats/clarity/examples/lifestate/SpawnsAndDeaths.java).

### Context

The first parameter on any event listener called by Clarity is a Context object.
You can use it to do useful stuff:

```java
public class Context {
    // 1. get a reference to another processor also taking part in the run
    public <T> T getProcessor(Class<T> processorClass) {}
    // 2. query the current tick
    public int getTick() {}
    // 3. query the engine type the replay was recorded with
    public EngineType getEngineType() {}
    // 4. query the build number the replay was recorded with (Source 2 only)
    public int getBuildNumber() {}
    // 5. raise an event yourself
    public <A extends Annotation> Event<A> createEvent(Class<A> eventType, Class... parameterTypes) {}
}
```

1. Often times you need a reference to another processor. You could get a reference to the mentioned GameEvents processor
   by calling `ctx.getProcessor(GameEvents.class)`.
2. returns the current tick
3. returns the type of engine (Source 1 or 2) the replay was recorded with.
4. if the replay was recorded with Source 2, this will give you the build number of the server that recorded the replay
5. this function can be used to create events yourself. 

"
eomjinyoung/JavaWebProgramming,master,62,102,2013-07-22T12:49:23Z,8373,1,Examples for Java web programming book ,,
allure-examples/allure-examples,master,62,45,2020-07-11T06:39:04Z,333,0,allure-examples core,,"# Allure Examples

Allure Report links auto redirect to the last build

## allure-java-commons
[![allure-java-commons](https://github.com/allure-examples/allure-examples/workflows/allure-java-commons/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-java-commons)

[![allure-java-commons](https://github.com/allure-examples/allure-java-commons/workflows/allure-java-commons/badge.svg)](https://github.com/allure-examples/allure-java-commons)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-java-commons/)

## allure-junit5
[![allure-junit5](https://github.com/allure-examples/allure-examples/workflows/allure-junit5/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-junit5)

[![allure-junit5-gradle](https://github.com/allure-examples/allure-junit5-gradle/workflows/allure-junit5-gradle/badge.svg)](https://github.com/allure-examples/allure-junit5-gradle)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-junit5-gradle/)

[![allure-junit5-gradle-kts](https://github.com/allure-examples/allure-junit5-gradle-kts/workflows/allure-junit5-gradle-kts/badge.svg)](https://github.com/allure-examples/allure-junit5-gradle-kts)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-junit5-gradle-kts/)

[![allure-junit5-maven](https://github.com/allure-examples/allure-junit5-maven/workflows/allure-junit5-maven/badge.svg)](https://github.com/allure-examples/allure-junit5-maven)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-junit5-maven/)

## allure-junit4
[![allure-junit4](https://github.com/allure-examples/allure-examples/workflows/allure-junit4/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-junit4)

[![allure-junit4-gradle](https://github.com/allure-examples/allure-junit4-gradle/workflows/allure-junit4-gradle/badge.svg)](https://github.com/allure-examples/allure-junit4-gradle)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-junit4-gradle/)

[![allure-junit4-gradle-kts](https://github.com/allure-examples/allure-junit4-gradle-kts/workflows/allure-junit4-gradle-kts/badge.svg)](https://github.com/allure-examples/allure-junit4-gradle-kts)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-junit4-gradle-kts/)

[![allure-junit4-maven](https://github.com/allure-examples/allure-junit4-maven/workflows/allure-junit4-maven/badge.svg)](https://github.com/allure-examples/allure-junit4-maven)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-junit4-maven/)

## allure-testng
[![allure-testng](https://github.com/allure-examples/allure-examples/workflows/allure-testng/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-testng)

[![allure-testng-gradle](https://github.com/allure-examples/allure-testng-gradle/workflows/allure-testng-gradle/badge.svg)](https://github.com/allure-examples/allure-testng-gradle)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-testng-gradle/)

[![allure-testng-gradle-kts](https://github.com/allure-examples/allure-testng-gradle-kts/workflows/allure-testng-gradle-kts/badge.svg)](https://github.com/allure-examples/allure-testng-gradle-kts)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-testng-gradle-kts/)

[![allure-testng-maven](https://github.com/allure-examples/allure-testng-maven/workflows/allure-testng-maven/badge.svg)](https://github.com/allure-examples/allure-testng-maven)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-testng-maven/)

## allure-cucumber5-junit4
[![allure-cucumber5-junit4](https://github.com/allure-examples/allure-examples/workflows/allure-cucumber5-junit4/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-cucumber5-junit4)

[![allure-cucumber5-junit4-gradle](https://github.com/allure-examples/allure-cucumber5-junit4-gradle/workflows/allure-cucumber5-junit4-gradle/badge.svg)](https://github.com/allure-examples/allure-cucumber5-junit4-gradle)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-cucumber5-junit4-gradle/)

[![allure-cucumber5-junit4-gradle-kts](https://github.com/allure-examples/allure-cucumber5-junit4-gradle-kts/workflows/allure-cucumber5-junit4-gradle-kts/badge.svg)](https://github.com/allure-examples/allure-cucumber5-junit4-gradle-kts)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-cucumber5-junit4-gradle-kts/)

[![allure-cucumber5-junit4-maven](https://github.com/allure-examples/allure-cucumber5-junit4-maven/workflows/allure-cucumber5-junit4-maven/badge.svg)](https://github.com/allure-examples/allure-cucumber5-junit4-maven)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-cucumber5-junit4-maven/)

## allure-cucumber5-testng
[![allure-cucumber5-testng](https://github.com/allure-examples/allure-examples/workflows/allure-cucumber5-testng/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-cucumber5-testng)

[![allure-cucumber5-testng-gradle](https://github.com/allure-examples/allure-cucumber5-testng-gradle/workflows/allure-cucumber5-testng-gradle/badge.svg)](https://github.com/allure-examples/allure-cucumber5-testng-gradle)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-cucumber5-testng-gradle/)

[![allure-cucumber5-testng-gradle-kts](https://github.com/allure-examples/allure-cucumber5-testng-gradle-kts/workflows/allure-cucumber5-testng-gradle-kts/badge.svg)](https://github.com/allure-examples/allure-cucumber5-testng-gradle-kts)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-cucumber5-testng-gradle-kts/)

[![allure-cucumber5-testng-maven](https://github.com/allure-examples/allure-cucumber5-testng-maven/workflows/allure-cucumber5-testng-maven/badge.svg)](https://github.com/allure-examples/allure-cucumber5-testng-maven)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-cucumber5-testng-maven/)

## allure-python
[![allure-python](https://github.com/allure-examples/allure-examples/workflows/allure-python/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-python)

[![allure-python-pytest](https://github.com/allure-examples/allure-python-pytest/workflows/allure-python-pytest/badge.svg)](https://github.com/allure-examples/allure-python-pytest)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-python-pytest/)

[![allure-python-behave](https://github.com/allure-examples/allure-python-behave/workflows/allure-python-behave/badge.svg)](https://github.com/allure-examples/allure-python-behave)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-python-behave/)

[![allure-python-robotframework](https://github.com/allure-examples/allure-python-robotframework/workflows/allure-python-robotframework/badge.svg)](https://github.com/allure-examples/allure-python-robotframework)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-python-robotframework/)

## allure-javascript
[![allure-javascript](https://github.com/allure-examples/allure-examples/workflows/allure-javascript/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-javascript)

[![allure-javascript-codeceptjs](https://github.com/allure-examples/allure-javascript-codeceptjs/workflows/allure-javascript-codeceptjs/badge.svg)](https://github.com/allure-examples/allure-javascript-codeceptjs)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-javascript-codeceptjs/)

[![allure-javascript-cucumberjs](https://github.com/allure-examples/allure-javascript-cucumberjs/workflows/allure-javascript-cucumberjs/badge.svg)](https://github.com/allure-examples/allure-javascript-cucumberjs)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-javascript-cucumberjs/)

[![allure-javascript-jest](https://github.com/allure-examples/allure-javascript-jest/workflows/allure-javascript-jest/badge.svg)](https://github.com/allure-examples/allure-javascript-jest)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-javascript-jest/)

## allure-kotlin-junit5
[![allure-kotlin-junit5](https://github.com/allure-examples/allure-examples/workflows/allure-kotlin-junit5/badge.svg)](https://github.com/allure-examples/allure-examples/actions?query=workflow%3Aallure-kotlin-junit5)

[![allure-kotlin-junit5-gradle-kts](https://github.com/allure-examples/allure-kotlin-junit5-gradle-kts/workflows/allure-kotlin-junit5-gradle-kts/badge.svg)](https://github.com/allure-examples/allure-kotlin-junit5-gradle-kts)
[![Allure Report](https://img.shields.io/badge/Allure%20Report-deployed-yellowgreen)](https://allure-examples.github.io/allure-kotlin-junit5-gradle-kts/)"
biemond/soa11g_examples,master,35,98,2011-09-28T16:27:04Z,13905,0,Oracle SOA Suite 11g Examples,,
kiegroup/jbpm-playground,master,43,98,2013-10-18T14:41:22Z,691,3,Repository containing jBPM examples,,
howtoprogram/Java-Examples,master,35,59,2016-07-01T12:27:24Z,273,0,"Some Java examples about using frameworks, libraries",,"# Java Examples 

## 1.Java JsonPojo Example
This small project contains examples how to convert Java object, Hashmap, List to JSON and vice versa. It also contains examples about how to work with files.  
### [Convert Java Objects To JSON And Vice Versa](http://howtoprogram.xyz/2016/07/01/convert-java-objects-json-vice-versa/)
## 2.Book RESTful Service Examples
This RESTful ws provides API for all below sub projects
## 3.Simple Java REST Client Example

### [Simple Java REST Client Using java.net.URL package](http://howtoprogram.xyz/2016/07/02/simple-java-rest-client-using-java-net-url-package)

### [Java REST Client Using Spring RestTemplate](http://howtoprogram.xyz/2016/07/03/java-rest-client-using-spring-resttemplate/)

### [Java REST Client Using Apache Httpcomponents](http://howtoprogram.xyz/2016/07/04/java-rest-client-using-apache-httpcomponents/)

### [Java REST Client Using Jersey Client](http://howtoprogram.xyz/2016/07/05/java-rest-client-using-jersey-client/)

### [Java REST Client Using Resteasy Client](http://howtoprogram.xyz/2016/07/12/java-rest-client-using-resteasy-client/)

### [Java REST Client Using Resteasy Client Proxy Framework](http://howtoprogram.xyz/2016/07/13/java-rest-client-using-resteasy-client-proxy-framework/)

### [Java REST Client Using Apache CXF Proxy based API](http://howtoprogram.xyz/2016/07/15/java-rest-client-using-apache-cxf-proxy-based-api/)

### [Java REST Client Using Netflix Feign](http://howtoprogram.xyz/2016/07/18/java-rest-client-using-netflix-feign/)

### [Java REST Client Using Unirest Java API](http://howtoprogram.xyz/2016/07/27/java-rest-client-using-unirest-java-api/)

### [Java REST Client Examples Using OkHttp](howtoprogram.xyz/2016/10/31/java-rest-client-examples-using-okhttp/)

### [How to Post with Retrofit 2](http://howtoprogram.xyz/2017/02/17/how-to-post-with-retrofit-2/)

### [Ignore Unknown Properties or New Fields in Jackson](http://howtoprogram.xyz/2017/02/18/ignore-exclude-new-fields-deserializing-jackson/)


## 4. Java 8
### [Java 8 – Format Date, LocalDate, LocalDateTime and ZonedDateTime](https://howtoprogram.xyz/2017/08/20/java-8-format-date-localdate-localdatetime/)"
gradescope/autograder_samples,master,74,149,2016-02-25T19:59:10Z,4098,6,Examples of autograders for running on Gradescope,autograder autograding computer-science course-management gradescope,docs/README.md
jponge/vertx-in-action,master,269,133,2018-05-28T08:20:11Z,19482,2,"Examples for the Manning Vert.x in Action"" book""",book distributed-systems examples manning reactive resilience scalability vertx,"[![Build Status](https://travis-ci.com/jponge/vertx-in-action.svg?branch=master)](https://travis-ci.com/jponge/vertx-in-action)

# Vert.x in Action book examples

👋 Welcome!

These are the working examples for [Vert.x in Action](https://www.manning.com/books/vertx-in-action) (ISBN 9781617295621) from [Manning Publications Co](https://www.manning.com/) and written by [Julien Ponge](https://julien.ponge.org/).

## How to open and run the examples?

Readers of the book should directly open projects from subfolders: they are all independent.

You will find both Gradle and Maven build descriptors for each project, so you can load the projects with text editors or integrated development environments such as IntelliJ IDEA, Eclipse IDE or Microsoft Visual Studio Code.

As an example if you want to build the chapter 1 with Gradle, open a terminal and run:

    $ cd chapter1
    $ ./gradlew build

or with Maven run:

    $ cd chapter1
    $ mvn package

The book examples work best using some Unix environment: Linux, macOS or the Windows Subsystem for Linux from Microsoft.

## What is the structure of the repository?

The following folders are available:

- `chapter1`
- `chapter2`
- `chapter3`
- `chapter4`
- `chapter5`
- `chapter6`
- `part2-steps-challenge` (covers chapters 7 to 12)
- `chapter13`

The `master` branch is where you must look for working examples.

Chapter 12 provides variants of the same code which you can get from the following branches:

- `chapter12/public-api-with-timeouts`
- `chapter12/public-api-with-circuit-breaker`
- `chapter12/public-api-with-circuit-breaker-and-timeouts`

## Will there be updates?

The book went to production with Manning in August 2020.

This repository contains samples against Eclipse Vert.x 4.0.3 (see tag `vertx-4.0.3`) that was released in March 2021.

At my own discretion I _may_ update to newer versions of Vert.x when they are published.

Note that the Vert.x core team has made a goal of ensuring that Vert.x 4.0.3 will work against all examples in this repository.

## Can I contribute?

Due to the nature of this project I will not accept any contribution to this repository.

## What if I have a question / issue?

If you are a Manning customer then you have access to forums.
Please refer to [Vert.x in Action on the Manning website](https://www.manning.com/books/vertx-in-action) where a link to the forum is provided.

If you have a question on Vert.x then please get in touch with the [Eclipse Vert.x community](https://vertx.io).
There are several channels that you can use including public mailing-lists and chat.

If you have a problem with your book order or any special request, then please contact Manning.

## Errata

### November 2020

Due to a peculiarities in how _TestContainers_ supports _Docker Compose_ it may be necessary to explicitly await for containers to be exposed, or test executions can sometimes fail because a container port hasn't been exposed yet.

This can be done by calling the `withExposedService` method on a `DockerComposeContainer` instance, as in:

```java
@Container
private static final DockerComposeContainer CONTAINERS = new DockerComposeContainer(new File(""../docker-compose.yml""))
  .withExposedService(""mongo_1"", 27017);
```

This fix has been applied to the tests in `part2-steps-challenge`.
"
g00glen00b/spring-samples,master,188,241,2015-11-15T18:48:53Z,278,0,A series of examples used to demonstrate certain features of Spring.,spring spring-boot spring-cloud spring-cloud-netflix spring-security,"# Example applications using Spring boot

This is a collection of small applications demonstrating certain features of Spring boot. Most of these are covered as well in [my blog posts](https://dimitri.codes/tag/spring-boot/).

## Contents

| Blog post                                                    | GitHub                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [Writing your first Spring webapp with Spring Boot](https://dimitri.codes/spring-webapp/) | [spring-boot-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-webapp) |
| [JPA made easy with Spring data's repositories](https://dimitri.codes/spring-data-jpa/) | [spring-boot-jpa-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-jpa-webapp) |
| [Handling errors with Spring MVC](https://dimitri.codes/handling-errors-with-spring-mvc/) | [spring-boot-jpa-error-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-jpa-error-webapp) |
| [Using Docker containers for your Spring boot applications](https://dimitri.codes/docker-spring-boot/) | [spring-boot-jpa-docker-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-jpa-docker-webapp) |
| [Take your Spring apps to the cloud with Bluemix and Docker](https://dimitri.codes/docker-containers-on-bluemix/) | [sping-boot-jpa-docker-bluemix-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-jpa-docker-bluemix-webapp) |
| [Internationalization (i18n) with Spring](https://dimitri.codes/spring-internationalization-i18n/) | [spring-boot-i18n-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-i18n-webapp) |
| [Handling forms with Spring Web and JSR-303](https://dimitri.codes/spring-form-validation/) | [spring-boot-form](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-form) |
| [Producing REST API's with Spring](https://dimitri.codes/producing-rest-apis-with-spring/) | [spring-boot-rest](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-rest) |
| [Consuming REST API's with Spring](https://dimitri.codes/consuming-rest-apis-with-spring/) | [spring-boot-rest](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-rest) |
| [Documenting your REST API with Swagger and Springfox](https://dimitri.codes/documenting-rest-api-swagger-springfox/) | [spring-boot-swagger](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-swagger) |
| [Exploring contract first options with Swagger](https://dimitri.codes/exploring-contract-first-options-swagger/) | [spring-boot-swagger](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-swagger) |
| [Using Ehcache 3 with Spring boot](https://dimitri.codes/spring-boot-cache-ehcache/) | [spring-boot-ehcache](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-ehcache) |
| [Using the Netflix stack with Spring boot: Eureka](https://dimitri.codes/using-the-netflix-stack-with-spring-boot-eureka/) | [spring-boot-eureka](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-eureka) |
| [Using the Netflix stack with Spring boot: Ribbon](https://dimitri.codes/using-netflix-stack-spring-boot-ribbon/) | [spring-boot-eureka](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-eureka) |
| [Using the Netflix stack with Spring boot: Hystrix](https://dimitri.codes/spring-boot-netflix-hystrix/) | [spring-boot-hystrix](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-hystrix) |
| [Mapping with Dozer](https://dimitri.codes/mapping-with-dozer/)  | [spring-boot-jpa-dozer-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-jpa-dozer-webapp) |
| [Mapping beans with MapStruct](https://dimitri.codes/mapstruct/) | [spring-boot-jpa-mapstruct-webapp](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-jpa-mapstruct-webapp) |
| [Getting started with Spring boot 2.0](https://dimitri.codes/getting-started-spring-boot-2/) | [spring-boot-2-web-crawler](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-2-web-crawler) |
| [Validating the input of your REST API with Spring](https://dimitri.codes/validating-the-input-of-your-rest-api-with-spring) | [spring-boot-validation](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-validation) |
| [Working with Spring boot and GraphQL](https://dimitri.codes/graphql-spring-boot) | [spring-boot-graphql](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-graphql) |
| [Indexing documents with Spring batch](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-solr-batch) | [spring-boot-solr-batch](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-solr-batch) |
| [Generating documentation for your REST API with Spring REST Docs](https://dimitri.codes/spring-rest-docs) | [spring-boot-restdocs](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-restdocs) |
| [Generating documentation for your REST API with Spring and Swagger](https://dimitri.codes/generating-static-documentation-swagger) | [spring-boot-swagger-static-docs](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-swagger-static-docs) |
| [Reactive relational databases with R2DBC and Spring](https://dimitri.codes/reactive-relational-databases-r2dbc-spring) | [spring-boot-r2dbc](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-r2dbc) |
| [Reactive streams over the network with RSocket](https://dimitri.codes/reactive-streams-rsocket) | [spring-boot-rsocket](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-rsocket) |
| [Battle of the Spring REST clients: RestTemplate, WebClient or RestClient?](https://dimitri.codes/resttemplate-or-webclient) | [spring-boot-restclient](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-restclient)
| [Getting started with htmx and Spring Boot](https://dimitri.codes/spring-boot-htmx-intro) | [spring-boot-htmx](https://github.com/g00glen00b/spring-samples/tree/master/spring-boot-htmx)
"
JavaMoney/javamoney-examples,main,85,38,2013-01-23T20:30:59Z,2332,20,JavaMoney - Examples,demo examples java money,"JSR 354 JavaMoney Examples
==========================

The current project structure is as follows:

- [Console examples](console)
  - [Simple Console Examples](console/javamoney-console-simple)
  - [Java 8 Console Examples](console/javamoney-console-java8)
  - [Java 11 Console Examples](console/javamoney-console-java11)
  - [Java Functional Examples](console/functional-examples): examples using Java 8+ with streams, lambda and money-api
  - [Money Machine](console/moneymachine): Adopt JSR API Testing project for getting feedback on the API
- [JavaFX examples](javafx)
 - [JavaFX Demo application](javafx/money-fxdemo)
 - [JavaFX binding examples](javafx/money-javafx-binding)
- [Swing RCP examples](swing)
  - [An improved successor to EZ Money.](swing/javamoney-ez) 
- [Web examples](web)
  - [Demo for CDI Events with the Money and Currency API](web/javamoney-payment-cdi-event)
  - [Spring Trading App](web/javamoney-tradingapp)  currently **unstable**/disabled
  - [Java EE with JAX-RS](web/jax-rs-money) currently **unstable/broken**/disabled
  - [Example using JSF with MoneyAPI](web/jsf-money)

[![CircleCI](https://dl.circleci.com/status-badge/img/gh/JavaMoney/javamoney-examples/tree/main.svg?style=svg)](https://dl.circleci.com/status-badge/redirect/gh/JavaMoney/javamoney-examples/tree/main) [![License](http://img.shields.io/badge/license-Apache2-red.svg)](http://opensource.org/licenses/apache-2.0) 

[![Built with Maven](http://maven.apache.org/images/logos/maven-feather.png)](http://maven.org/)
"
eventuate-tram/eventuate-tram-examples-java-spring-todo-list,master,185,95,2017-11-20T22:29:33Z,261,5,A todo list application implemented using Spring Boot-based microservices and the Eventuate Tram framework,,"# Todo List example application


This example demonstrates how to develop microservices with Spring Boot, JPA, Apache Kafka, ElasticSearch and the Eventuate Tram framework.

## The problem: atomically updating data and publishing events/messages

It's challenging to atomically update a data (e.g. a Domain-Driven design aggregate) and publish a message, such as a domain event.
The traditional approach of using 2PC/JTA isn't a good fit for modern applications.

The [Eventuate&trade; Tram framework](https://github.com/eventuate-tram/eventuate-tram-core) implements an alternative mechanism based on the [Application Events](http://microservices.io/patterns/data/application-events.html) pattern.
When an application creates or updates data, as part of that ACID transaction, it inserts an event into an `EVENTS` or `MESSAGES` table.
A separate CDC process publishes those events to a message broker, such as Apache Kafka.


## About the Todo list application

The Todo List application, which lets users maintain a todo list, is the hello world application for the [Eventuate&trade; Tram framework](https://github.com/eventuate-tram/eventuate-tram-core).
It shows how use Eventuate Tram to

* reliably publish domain events as part of a database transaction that updates an aggregate.
* consume domain events to update a [CQRS view](http://microservices.io/patterns/data/cqrs.html) view

When a user creates or updates a todo, the application publishes a domain event.
An event handler, subscribes to those events and updates an ElasticSearch-based CQRS view.

## Todo list architecture

The Todo List application is built using

* Java
* JPA
* Eventuate Tram
* Spring Boot
* MySQL
* ElasticSearch
* Apache Kafka

The following diagram shows the application's architecture.

![TODO architecture](./images/Architecture.png)

The application consists of two services:

* `Todo Service` - implements the REST endpoints for creating, updating and deleting todos.
The service persists the Todo JPA entity in MySQL.
Using `Eventuate Tram`, it publishes Todo domain events that are consumed by the `Todo View Service`.

* `Todo View Service` - implements a REST endpoint for querying the todos.
It maintains a CQRS view of the todos in ElasticSearch.

The `Todo Service` publishes events using Eventuate Tram.
Eventuate Tram inserts events into the `MESSAGE` table as part of the ACID transaction that updates the TODO table.
The Eventuate Tram CDC service tracks inserts into the `MESSAGE` table using the MySQL binlog and publishes messages to Apache Kafka.
The `Todo View Service` subscribes to the events and updates ElasticSearch.

## Two flavors of the application: monolithic and microservices

There are two versions of the application:

* `single-module` - a single module Gradle project for a monolithic version of the application.
It is the easiest to get started with.
* `multi-module` - a multi-module Gradle project for the microservices-based version of the application.
It consists of a `todo-service`, which creates and updates Todos, and `todo-view-service`, which maintains a [CQRS view](http://microservices.io/patterns/data/cqrs.html) view in ElasticSearch

# How it works

The Todo application uses the [Eventuate Tram framework](https://github.com/eventuate-tram/eventuate-tram-core) to publish and consume domain events.


## Domain event publisher

The `TodoCommandService` publishes an event when it creates, updates, or deletes a `Todo`.
It uses the `DomainEventPublisher`, which is implemented by the [Eventuate Tram framework](https://github.com/eventuate-tram/eventuate-tram-core).
`DomainEventPublisher` publishes the event as part of the transaction that updates the database.
If the transactions commits the event will be published.
Conversely, if the transaction is rolled back, then the event is not published.

```java
@Service
@Transactional
public class TodoCommandService {

  @Autowired
  private TodoRepository todoRepository;

  @Autowired
  private DomainEventPublisher domainEventPublisher;

  public Todo create(CreateTodoRequest createTodoRequest) {
    Todo todo = new Todo(createTodoRequest.getTitle(), createTodoRequest.isCompleted(), createTodoRequest.getOrder());
    todo = todoRepository.save(todo);

    publishTodoEvent(todo, new TodoCreated(todo.getTitle(), todo.isCompleted(), todo.getExecutionOrder()));

    return todo;
  }

  private void publishTodoEvent(Todo todo, DomainEvent... domainEvents) {
    domainEventPublisher.publish(Todo.class, todo.getId(), asList(domainEvents));
  }

  ...
```

## Domain event consumer

The CQRS view code subscribes to domain events published by the `TodoCommandService`.
It defines `DomainEventDispatcher` @Bean to invoke the event handlers defined by `TodoEventConsumer`.
The `DomainEventDispatcher` class is provided by the [Eventuate Tram framework](https://github.com/eventuate-tram/eventuate-tram-core).
It handles message de-duplication to ensure that the event handlers are idempotent.

```java
@Configuration
public class TodoViewConfiguration {

  @Bean
  public DomainEventDispatcher domainEventDispatcher(TodoEventConsumer todoEventConsumer, MessageConsumer messageConsumer) {
    return new DomainEventDispatcher(""todoServiceEvents"", todoEventConsumer.domainEventHandlers(), messageConsumer);
  }

```

The `TodoEventConsumer` defines the event handlers, which update Elasticsearch.

```java
public class TodoEventConsumer {

  @Autowired
  private TodoViewService todoViewService;

  public DomainEventHandlers domainEventHandlers() {
    return DomainEventHandlersBuilder
            .forAggregateType(Todo.class.getName())
            .onEvent(TodoCreated.class, dee -> {
              TodoCreated todoCreated = dee.getEvent();
              todoViewService.index(new TodoView(dee.getAggregateId(),
                  todoCreated.getTitle(), todoCreated.isCompleted(), todoCreated.getExecutionOrder()));
            })

```

# Got questions?

Don't hesitate to create an issue or see

* [Mailing list](https://groups.google.com/d/forum/eventuate-users)
* [Slack](https://eventuate-users.slack.com). [Get invite](https://eventuateusersslack.herokuapp.com/)
* [Contact us](http://eventuate.io/contact.html).


Don't forget to take a look at the other [Eventuate Tram examples](http://eventuate.io/exampleapps.html):

* [Customers and Orders](https://github.com/eventuate-tram/eventuate-tram-sagas-examples-customers-and-orders)
* [FTGO Example application for Microservice Patterns book](https://github.com/microservice-patterns/ftgo-application)


# Building and running

Note: you do not need to install Gradle since it will be downloaded automatically.
You just need to have Java 8 installed.

First, build the application

```
./gradlew assemble
```

Next, launch the services using [Docker Compose](https://docs.docker.com/compose/):

```
export DOCKER_HOST_IP=...
docker-compose -f docker-compose-eventuate-mysql.yml build
docker-compose -f docker-compose-eventuate-mysql.yml up -d
```

Note:

1. You can also run the Postgres version using `docker-compose-eventuate-postgres.yml`
2. You need to set `DOCKER_HOST_IP` before running Docker Compose.
This must be an IP address or resolvable hostname.
It cannot be `localhost`.
See this [guide to setting `DOCKER_HOST_IP`](http://eventuate.io/docs/usingdocker.html) for more information.

# Using the application

Once the application has started, you can use the application via the Swagger UI.

If you are running the `multi-module` version:

* `http://${DOCKER_HOST_IP}:8081/swagger-ui.html` - the command-side service
* `http://${DOCKER_HOST_IP}:8082/swagger-ui.html` - the query-side service

If you are running the `single-module` version:

* `http://${DOCKER_HOST_IP}:8080/swagger-ui.html` - the monolithic application

# Got questions?

Don't hesitate to create an issue or see

* [Mailing list](https://groups.google.com/d/forum/eventuate-users)
* [Slack](https://eventuate-users.slack.com). [Get invite](https://eventuateusersslack.herokuapp.com/)
* [Contact us](http://eventuate.io/contact.html).
"
jitpack/gradle-simple,master,65,428,2015-01-27T17:18:46Z,143,8,Simple gradle example project,,"# gradle-simple

[![](https://jitpack.io/v/jitpack/gradle-simple.svg?label=Release)](https://jitpack.io/#jitpack/gradle-simple) [![](https://jitci.com/gh/jitpack/gradle-simple/svg)](https://jitci.com/gh/jitpack/gradle-simple)

Example Gradle project producing a single jar. Uses the `maven` plugin to publish the jar to the local repository.

[https://jitpack.io/#jitpack/gradle-simple](https://jitpack.io/#jitpack/gradle-simple)

To install the library add: 
 
   ```gradle
   repositories { 
        jcenter()
        maven { url ""https://jitpack.io"" }
   }
   dependencies {
         implementation 'com.github.jitpack:gradle-simple:1.1'
   }
   ```  

"
Azure-Samples/java-on-azure-examples,main,83,63,2021-01-27T21:55:42Z,20558,8,Java on Azure examples,aca aks appservice asa azure containerapps functions java jboss spring springapps tomcat,"# Java on Azure Examples

This GitHub repository contains a set of Azure examples specifically for Java developers to quickly get started with Azure.
Please use the issue tracker to leave feedback, file issues or to propose other examples.

## Getting started

To work with these examples it is assumed you have the Azure CLI installed, and you have logged in and set your default subscription.
If you haven't done so follow the steps below.

_Note: Logging in and setting your default subscription needs to be done once per terminal session._

### Install Azure CLI

To setup the Azure CLI, please visit [Install the Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli).
And once you are done come back to this README.

### Login into Azure

<!-- workflow.skip() -->
````shell
  az login
````

### Set your default subscription

Get a list of your subscriptions (notice the `refresh` parameter that retrieves up-to-date subscriptions from the server) :

<!-- workflow.skip() -->
````shell
  az account list --output table --refresh
````

Set your default subscription for this session using the subscription id from the previous output:

<!-- workflow.skip() -->
````shell
  az account set --subscription ""subscription-id""
````

<!-- workflow.run() 

  exit 0

  -->

## Our alphabetical list of examples

1. [Azure App Configuration examples](appconfig/)
1. [Azure App Service examples](appservice/)      
1. [Azure Cache for Redis examples](redis/)            <!-- workflows run Sunday    / 2 examples  -->
1. [Azure Cognitive Services examples](cognitiveservices/)
1. [Azure Container Apps examples](containerapp/)
1. [Azure Container Instances examples](container/)
1. [Azure Container Registry examples](acr/)
1. [Azure Cosmos DB examples](cosmosdb/)
1. [Azure Front Door examples](afd/)
1. [Azure Data Explorer examples](kusto/)              <!-- workflows run Sunday    / 4 examples  -->
1. [Azure Database for MySQL examples](mysql/)         <!-- workflows run Tuesday   / 4 examples  -->
1. [Azure Database for PostgreSQL examples](postgres/) <!-- workflows run Monday    / 4 examples  -->
1. [Azure Event Hubs examples](eventhubs/)             <!-- workflows run Saturday  / 4 examples  -->
1. [Azure Functions examples](functionapp/)            <!-- workflows run Thursday  / 3 examples  -->
1. [Azure Key Vault examples](keyvault/)               <!-- workflows run Tuesday   / 6 examples  -->
1. [Azure Kubernetes Service examples](aks/)           
1. [Azure Monitor examples](monitor/)                  <!-- workflows run Thursday  / 1 example   -->
1. [Azure Networking examples](network/)               <!-- workflows run Wednesday / 1 example   -->
1. [Azure Red Hat OpenShift examples](aro/)
1. [Azure Resource Group examples](group/)             <!-- workflows run Saturday  / 2 examples  -->
1. [Azure Service Bus examples](servicebus/)           <!-- workflows run Friday    / 9 examples  -->
1. [Azure Spring Apps examples](spring/)               <!-- workflows run Wednesday / 3 examples  -->
1. [Azure SQL Database examples](sql/)                 <!-- workflows run Wednesday / 4 examples  -->
1. [Azure Storage examples](storage/)                  <!-- workflows run Monday    / 3 examples  -->

## Contributing

How do I contribute? See [Contributing](CONTRIBUTING.md)

<!-- 

  See https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure?tabs=azure-portal%2Clinux#create-a-service-principal 
  to associate use service principal with the GitHub actions mentioned below.

  Azure Container Registry examples

   1. acr/create/README.md                                                  - 0  0 * * 1 - westus
   2. acr/create-acrpull-service-principal/README.md                        - 0  1 * * 1 - westus
   3. acr/create-settings-xml/README.md                                     - 0  2 * * 1 - westus
   4. acr/dropwizard/README.md                                              - 0  3 * * 1 - westus
   5. acr/glassfish/README.md                                               - 0  4 * * 1 - westus
   6. acr/graalvm/README.md                                                 - 0  5 * * 1 - westus
   7. acr/helidon/README.md                                                 - 0  6 * * 1 - westus
   8. acr/helloworldjob/README.md                                           - 0  7 * * 1 - westus
   9. acr/jetty/README.md                                                   - 0  8 * * 1 - westus
  10. acr/micronaut/README.md                                               - 0  9 * * 1 - westus
  11. acr/payara/READNE.md                                                  - 0 10 * * 1 - westus
  12. acr/piranha/README.md                                                 - 0 11 * * 1 - westus
  13. acr/quarkus/README.md                                                 - 0 12 * * 1 - westus
  14. acr/springboot/README.md                                              - 0 13 * * 1 - westus
  15. acr/tomcat/README.md                                                  - 0 14 * * 1 - westus
  16. acr/wildfly/README.md                                                 - 0 15 * * 1 - westus

Azure Front Door examples

  1. afd/add-origins-to-origin-group/README.md                              - 0 16 * * 1 - westus
  2. afd/add-route/README.md                                                - 0 17 * * 1 - westus
  3. afd/create-endpoint/README.md                                          - 0 18 * * 1 - westus
  4. afd/create-origin-group/README.md                                      - 0 19 * * 1 - westus
  5. afd/create-profile/README.md                                           - 0 20 * * 1 - westus

Azure Kubernetes Service examples

  1. aks/create/README.md                                                   - 0 21 * * 1 - westus
  2. aks/create-kube-config/README.md                                       - 0 22 * * 1 - westus
  3. aks/graalvm/README.md                                                  - 0 23 * * 1 - westus
  4. aks/springboot/README.md                                               - 0  0 * * 2 - westus
  5. aks/tomcat/README.md                                                   - 0  1 * * 2 - westus
  6. aks/use-your-acr/README.md                                             - 0  2 * * 2 - westus
  7. aks/wildfly/README.md                                                  - 0  3 * * 2 - westus

Azure App Configuration examples

  1. appconfig/add-key-value/README.md                                      - 0  4 * * 2 - westus
  2. appconfig/create/README.md                                             - 0  5 * * 2 - westus

Azure App Service examples

  1. appservice/container-glassfish/README.md                               - 0  6 * * 2 - westus
  2. appservice/container-graalvm/README.md                                 - 0  7 * * 2 - westus
  3. appservice/container-jetty/README.md                                   - 0  8 * * 2 - westus
  4. appservice/container-payara/README.md                                  - 0  9 * * 2 - westus
  5. appservice/create-deployment-slot/README.md                            - 0 10 * * 2 - westus
  6. appservice/create-plan/README.md                                       - 0 11 * * 2 - westus
  7. appservice/delete-plan/README.md                                       - 0 12 * * 2 - westus
  8. appservice/delete-webapp/README.md                                     - 0 13 * * 2 - westus
  9. appservice/deploy-to-deployment-slot/README.md                         - 0 14 * * 2 - westus
 10. appservice/docker-tomcat/README.md                                     - 0 15 * * 2 - westus
 11. appservice/docker-wildfly/README.md                                    - 0 16 * * 2 - westus
 12. appservice/javase-quarkus/README.md                                    - 0 17 * * 2 - westus
 13. appservice/javase-springboot/README.md                                 - 0 18 * * 2 - westus
 14. appservice/jboss-eap-helloworld/README.md                              - 0 19 * * 2 - westus
 15. appservice/list-webapp/README.md                                       - 0 20 * * 2 - westus
 16. appservice/scale-manually/README.md                                    - 0 21 * * 2 - westus
 17. appservice/swap-deployment-slot/README.md                              - 0 22 * * 2 - westus
 18. appservice/tomcat-helloworld/README.md                                 - 0 23 * * 2 - westus

Azure Container Instances examples

  1. container/quarkus/README.md                                            - 0  0 * * 3 - westus
  2. container/tomcat/README.md                                             - 0  1 * * 3 - westus
  3. container/wildfly/README.md                                            - 0  2 * * 3 - westus

Azure Container Apps examples

  1. containerapp/create-environment/README.md                              - 0  3 * * 3 - westus
  2. containerapp/create-manual-job/README.md                               - 0  4 * * 3 - westus
  3. containerapp/dropwizard/README.md                                      - 0  5 * * 3 - westus
  4. containerapp/execute-manual-job/README.md                              - 0  6 * * 3 - westus
  5. containerapp/get-job-execution-log/README.md                           - 0  7 * * 3 - westus
  6. containerapp/glassfish/README.md                                       - 0  8 * * 3 - westus
  7. containerapp/helidon/README.md                                         - 0  9 * * 3 - westus
  8. containerapp/list-job-executions/README.md                             - 0 10 * * 3 - westus
  9. containerapp/micronaut/README.md                                       - 0 11 * * 3 - westus
 10. containerapp/piranha/README.md                                         - 0 12 * * 3 - westus
 11. containerapp/quarkus/README.md                                         - 0 13 * * 3 - westus
 12. containerapp/springboot/README.md                                      - 0 14 * * 3 - westus
 13. containerapp/tomcat/README.md                                          - 0 15 * * 3 - westus
 14. containerapp/wildfly/README.md                                         - 0 16 * * 3 - westus

Azure Cosmos DB examples

  1. cosmosdb/create/README.md                                              - 0 17 * * 3 - westus
  2. cosmosdb/create-sql-container/README.md                                - 0 18 * * 3 - westus
  3. cosmosdb/create-sql-database/README.md                                 - 0 19 * * 3 - westus
  4. cosmosdb/create-sql-leases-container/README.md                         - 0 20 * * 3 - westus
  5. cosmosdb/insert-item-into-sql-container/README.md                      - 0 21 * * 3 - westus
  6. cosmosdb/sql-change-feed-processor/README.md                           - 0 22 * * 3 - westus

Azure Event Hubs examples

  1. eventhubs/create-eventhub/README.md                                    - 0 23 * * 3 - westus
  2. eventhubs/create-namespace/README.md                                   - 0  0 * * 4 - westus
  3. eventhubs/receive-event/README.md                                      - 0  1 * * 4 - westus
  4. eventhubs/send-event/README.md                                         - 0  2 * * 4 - westus

Azure Functions examples

  1. functionapp/cosmosdb-output/README.md                                  - 0  3 * * 4 - westus3
  2. functionapp/helloworld/README.md                                       - 0  4 * * 4 - westus3
  3. functionapp/install-tools/README.md                                    - 0  5 * * 4 - westus3

Azure Resource Group examples

  1. group/create/README.md                                                 - 0  6 * * 4 - westus
  2. group/delete/README.md                                                 - 0  7 * * 4 - westus

Azure Key Vault examples

  1. keyvault/add-secret/README.md                                          - 0  8 * * 4 - westus
  2. keyvault/create/README.md                                              - 0  9 * * 4 - westus
  3. keyvault/create-self-signed-certificate/README.md                      - 0 10 * * 4 - westus

Azure Data Explorer examples

  1. kusto/create/README.md                                                 - 0 11 * * 4 - westus
  2. kusto/create-database/README.md                                        - 0 12 * * 4 - westus

Azure Monitor examples

  1. monitor/create-log-analytics-workspace/README.md                       - 0 13 * * 4 - westus

Azure Database for MySQL examples

  1. mysql/create/README.md                                                 - 0 14 * * 4 - westus
  2. mysql/get-country/README.md                                            - 0 15 * * 4 - westus
  3. mysql/load-your-mysql-database-with-data/README.md                     - 0 16 * * 4 - westus

Azure Cognitive Services examples

  1. cognitiveservices/create-openai-account/README.md                      - 0 17 * * 4 - eastus
  2. cognitiveservices/create-gpt35-model/README.md                         - 0 18 * * 4 - eastus
  3. cognitiveservices/chat-with-semantic-kernel-and-gpt35/README.md        - 0 19 * * 4 - eastus

Azure SQL Database examples

  1. sql/create/README.md                                                   - 0 20 * * 4 - westus2
  2. sql/get-country/README.md                                              - 0 21 * * 4 - westus2
  3. sql/load-your-mssql-database-with-data/README.md                       - 0 22 * * 4 - westus2
  4. sql/open-firewall-to-your-ip/README.md                                 - 0 23 * * 4 - westus2

 -->
"
mttkay/signpost-examples,master,82,38,2010-03-12T17:16:01Z,795,3,example code for how to access various OAuth service providers using Signpost,,
oracle/nosql-examples,master,49,47,2014-06-10T01:31:38Z,53774,0,This is a top level repository for code examples related to the use of Oracle NoSQL Database.,api awesome cloud database examples functions java node-js nosql nosql-database oci on-premise oracle oracle-cloud oracle-nosql-database python spring spring-data stream terraform,"# Oracle NoSQL Database

![Oracle NoSQL](./demo-livelab/NoSQL-Database.png)

**Oracle NoSQL Database** is designed for today’s most demanding applications that 
require low latency responses, flexible data models, and elastic scaling for dynamic workloads. 
It supports JSON, Table and Key-Value datatypes running on-premise, or as a cloud 
service with on-demand throughput and storage based provisioning.

**Oracle NoSQL Database Cloud Service** is now a fully managed database service running 
on Gen 2 Oracle Cloud Infrastructure hardware.

Oracle NoSQL Database Cloud Service makes it easy for developers to build applications, 
delivering predictable single digit millisecond response times with data replication for high availability. 
The service offers ACID transactions, serverless scaling, comprehensive security, and low pay-per-use pricing 
for both on-demand and provisioned capacity modes, including 100% compatibility with on-premises Oracle NoSQL Database. 

# Oracle Nosql Examples
This repository stores a variety of examples demonstrating how to use the Oracle NoSQL Database. 

| Repo/Folder name  | Description |
| ------------- | ------------- |
| [cluster_setup](./cluster_setup) | Deploying Oracle NoSQL Database on the Oracle Cloud Infrastructure `deploy-nosql` |
| [examples-nosql-cluster-deployment](./examples-nosql-cluster-deployment) | Examples allowing you to learn how to deploy a NoSQL cluster/NoSQL store - the most popular topologies |
| [examples-nosql-kvlocal](./examples-nosql-kvlocal) | example of Java Application embedding KVLocal  |
| [examples-nosql-java-direct-driver](./examples-nosql-java-direct-driver) | Examples using the `nosql-java-direct-driver` |
| [examples-nosql-java-sdk](./examples-nosql-java-sdk) | Examples using the `nosql-java-sdk` |
| [examples-nosql-node-sdk](./examples-nosql-node-sdk) | Examples using the `nosql-node-sdk` |
| [examples-nosql-spring-sdk](./examples-nosql-spring-sdk) | Examples using the `nosql-spring-sdk` |
| [demo-livelab](./demo-livelab) | you can find the code used in our NoSQL LiveLabs workshops in this directory and more information [here](#oracle-nosql-livelabs) |
| [demo-events](./demo-events) | The NoSQL team is delivering content in Webinars and Events around the world. You can also find the instructions for workshops showcased in NoSQL events and have more information [here](#oracle-nosql-livelabs)|
| [SQL for Oracle NoSQL Database tutorial](https://docs.oracle.com/en/database/other-databases/nosql-database/22.3/nsdev/getting-started-sql-oracle-nosql-database1.html) | Getting started with SQL for Oracle NoSQL Database `sql-for-nosql`|
| [terraform Provider for Oracle NoSQL Database tutorial](https://github.com/oracle/terraform-provider-oci/tree/master/examples/nosql)| This is a Terraform configuration that creates the NoSQL service on Oracle Cloud Infrastructure. `nosql-cloud-devops`|


We also collected in this repository exciting content about How to use the Oracle NoSQL database with other OCI services - more information  [here](#other-examples-and-resources). 
**Source:** `Architecture Center` **Source:** `GitHub`

---

NoSQL Developers 👨‍💻 👩‍💻

**Tags:** `enhancement` `help wanted` `question` `idea` `show-and-tell`

In the development world, practice makes the master. That is why you must find as many ways to practice as possible. Never stop learning. 

We’ve enabled [GitHub Discussions](https://github.com/oracle/nosql-examples/discussions) to provide a way for you to connect with other community members. We hope that you:

    Ask questions.
    Share ideas.
    Engage with other community members.
    Welcome others and are open-minded. Remember that this is a community we build together
# Oracle NoSQL LiveLabs



![NoSQL LiveLabs](./demo-livelab/LiveLabs.png)

**Oracle LiveLabs** gives you access to Oracle's tools and technologies to run 
a wide variety of labs and workshops.

In the development world, practice makes master. That is why you must find as many 
ways to practice as possible. Never stop learning. Follow our LiveLabs

* [Get started with tables in Oracle NoSQL Database Cloud Service](https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/view-workshop?wid=642) `sql-for-nosql` `nosql-java-sdk` `nosql-node-sdk` `nosql-dotnet-sdk` `nosql-go-sdk` `nosql-python-sdk`
* [Discover serverless apps using Oracle NoSQL Database Cloud Service — beginner level](https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/view-workshop?wid=879) `sql-for-nosql`  `nosql-node-sdk` 

> Those labs were specialled designed for Application Developers, Architects, Administrators
> and DevOps Engineers.

---

In the directory **demo-livelab** you can find the **code used in our NoSQL LiveLabs workshops**.
* [demo-lab-nosql](./demo-livelab/demo-lab-nosql) contains the code for Discover serverless apps using Oracle NoSQL Database Cloud Service — beginner level `sql-for-nosql`  `nosql-node-sdk` 


## Oracle LiveLabs 

Oracle LiveLabs gives you access to Oracle's tools and technologies to run a wide variety of labs and workshops.

Experience Oracle's best technology, live!

[https://developer.oracle.com/livelabs](https://developer.oracle.com/livelabs)

# Oracle NoSQL Workshops and Examples

![NoSQL Ideas](./demo-livelab/Ideas.png)

##  Oracle NoSQL Workshops

The NoSQL team is delivering content in Webinars and Events around the world.

**You can find the code of workshops showcased in NoSQL events** around the World (*LiveLabs coming soon*)
* [serverless-with-nosql-database](./demo-livelab/serverless-with-nosql-database) contains the code for Discover serverless apps using 
Oracle NoSQL Database Cloud Service — intermediate level. Intermediate level LiveLab will feature functions `sql-for-nosql`  `nosql-node-sdk` 
`nosql-python-sdk` `oci-functions` `nosql-cloud-devops`
* [demo-lab-baggage](./demo-livelab/demo-lab-baggage) contains the code for Discover serverless apps using Oracle NoSQL Database Cloud Service — expert level. 
Advanced level Livelab will feature Streaming and API gateway 
`sql-for-nosql`  `nosql-node-sdk` `nosql-python-sdk` `oci-functions` `nosql-cloud-devops` `oci-streaming` `oci-api-gateway` `oci-connector-hub`


**You can find also the instructions of workshops showcased in NoSQL events**

- [Discover Serverless Apps Using Oracle NoSQL Database Cloud Service - intermediate level](http://oracle.github.io/nosql-examples/demo-events/oug/serverless-with-nosql-database-and-functions/workshops/freetier/index.html) *demo-events > oug > serverless-with-nosql-database-and-functions*
`preview version` `sql-for-nosql` `nosql-node-sdk` `nosql-python-sdk` `oci-functions` `nosql-cloud-devops` 
- [Discover Oracle NoSQL Database](http://oracle.github.io/nosql-examples/demo-events/webinar/demo-nosql-lab-with-kvlite/workshops/livelabs/index.html) *demo-events > webinar > demo-nosql-lab-with-kvlite* `preview version` `sql-for-nosql` `nosql-node-sdk` 
- [Writing and optimizing NoSQL queries](http://oracle.github.io/nosql-examples/demo-events/webinar/tv-streaming-service-queries/workshops/livelabs/index.html) *demo-events > webinar > demo-nosql-lab-with-kvlite* `preview version` `sql-for-nosql` 

## Deploying Oracle NoSQL Database on the Oracle Cloud Infrastructure

**Tags:** `deploy-nosql` 

See this [script](./cluster_setup) that simplifies the installation of Oracle NoSQL Database on the Oracle Cloud Infrastructure (OCI). 
This script lets a user set up a small cluster (1-10 machines) quickly, for use in proof-of-concepts, small on premise installations, 
and cluster installations in cloud environments (OCI, AWS, Azure). It's easy to BYOL to the cloud environment of your choosing.

Read this [whitepaper](https://www.oracle.com/a/otn/docs/database/oracle-nosql-cluster-setup-oci.pdf) which explains how to easily install Oracle NoSQL Database on the Oracle Cloud Infrastructure (OCI).

## Getting started with SQL for Oracle NoSQL Database 

**Tags:** `sql-for-nosql` 

Welcome to [SQL for Oracle NoSQL Database tutorial](https://docs.oracle.com/en/database/other-databases/nosql-database/22.3/nsdev/getting-started-sql-oracle-nosql-database1.html). 


The SQL for Oracle NoSQL Database data model supports flat relational data, hierarchical typed (schema-full) data, and schema-less JSON data. 
SQL for Oracle NoSQL Database is designed to handle all such data seamlessly without any impedance mismatch among the different sub-models. 
Impedance mismatch is the problem that occurs due to differences between the database model and the programming language model.

You have two different schemas ( with real-time scenarios) for learning various SQL concepts. 
These two schemas will include various data types that can be used in the Oracle NoSQL database.

**Schema 1: BaggageInfo schema**
Using this schema you can handle a use case wherein passengers traveling on a flight can track the progress of their checked-in bags or 
luggage along the route to the final destination. This functionality can be made available as part of the airline's mobile application. 
Once the passenger logs into the mobile application, the ticket number or reservation code of the current flight is displayed on the screen. 
Passengers can use this information to search for their baggage information. The mobile application is using NoSQL Database to store all the data 
related to the baggage. In the backend, the mobile application logic performs SQL queries to retrieve the required data.

**Schema 2: Streaming Media Service - Persistent User Profile Store**
Consider a TV streaming application. It streams various shows that are watched by customers across the globe. 
Every show has a number of seasons and every season has multiple episodes. You need a persistent meta-data store that keeps track of the 
current activity of the customers using the TV streaming application. Using this schema you can provide useful information to the customer 
such as episodes they watched, the watch time per episode, the total number of seasons of the show they watched, etc. 
The data is stored in the NoSQL Database and the application performs SQL queries to retrieve the required data and make it available to the user.

The scripts allowing to run this tutorial are hosted in this Repository ( `AcctStreamSchema` and `BaggageSchema` ) but follow the instructions provided
in the [SQL for Oracle NoSQL Database tutorial](https://docs.oracle.com/en/database/other-databases/nosql-database/22.3/nsdev/getting-started-sql-oracle-nosql-database1.html)

## Terraform Provider for Oracle Cloud Infrastructure

**Tags:** `nosql-cloud-devops` 

The Oracle Cloud Infrastructure (OCI) provider allows you to use Terraform to interact with Oracle Cloud Infrastructure resources. 
Wherever you use a Terraform distribution you can use the OCI Terraform provider, including Terraform Cloud and the OCI Resource Manager.

[https://github.com/oracle/terraform-provider-oci](https://github.com/oracle/terraform-provider-oci)

This is a Terraform configuration that creates the NoSQL service on Oracle Cloud Infrastructure.

[https://github.com/oracle/terraform-provider-oci/tree/master/examples/nosql](https://github.com/oracle/terraform-provider-oci/tree/master/examples/nosql)

# Cloud Learning

NoSQL Developers 👨‍💻 👩‍💻

**Tags:** `nosql-java-sdk` `nosql-node-sdk` `nosql-dotnet-sdk` `nosql-go-sdk` `nosql-python-sdk`  `nosql-spring-sdk` `nosql-cloud-devops` `oci-functions` `oci-oke` and `more`

Learn how to Develop Applications Fast and Effortlessly using our resources and videos in the **Cloud Learning** page

[https://www.oracle.com/database/nosql/#rc30-cloud-learning](https://www.oracle.com/database/nosql/#rc30-cloud-learning)


# Other Examples and Resources

![NoSQL Ideas](./demo-livelab/Ideas.png)

## Process media by using serverless job management and ephemeral compute workers

**Source:** `Architecture Center`

**Tags:** `nosql-python-sdk` `oci-functions` 

Processing large media files can be a resource intensive operation requiring large compute shapes for timely and efficient processing. 
In scenarios where media processing requests might be ad-hoc and on-demand, leaving instances idle while waiting for new work is not cost effective.

By utilizing Oracle Cloud Infrastructure's (OCI) server-less capabilities, including OCI Functions and OCI NoSQL, 
we can quickly create a management system for processing media content using ephemeral OCI Compute workers.

[https://docs.oracle.com/en/solutions/process-media-using-oci-services/index.html](https://docs.oracle.com/en/solutions/process-media-using-oci-services/index.html)

Note: You can deploy this pattern using downloadable code or automated provisioning, as described in the Download or Deploy section in the link above.

## oci wearable health app

**Source:** `GitHub`

**Tags:** `nosql` `oci` 


The sample application is an IoT use-case, in which an application capturing health parameters running on a wearable device is sending health statistics to a device gateway (backend) 
hosted on OCI on regular intervals. The complete use-case can be split into 3 different parts:
- On-boarding and Administration
- Health data capturing & Real time Analytics
- Batch Analytics

[https://github.com/oracle-devrel/oci-wearable-health-app](https://github.com/oracle-devrel/oci-wearable-health-app)

## Oracle Cloud Infrastructure Data Flow Samples

**Source:** `GitHub`

**Tags:** `nosql-python-sdk` `oci-data flow` 


Oracle Cloud Infrastructure (OCI) Data Flow is a cloud-based serverless platform with a rich user interface. It allows Spark developers 
and data scientists to create, edit, and run Spark jobs at any scale without the need for clusters, an operations team, or highly specialized 
Spark knowledge. Being serverless means there is no infrastructure for you to deploy or manage. It is entirely driven by REST APIs, 
giving you easy integration with applications or workflows

Oracle NoSQL Database cloud service : This application shows how to interface with Oracle NoSQL Database cloud service.

[https://github.com/oracle-samples/oracle-dataflow-samples/](https://github.com/oracle-samples/oracle-dataflow-samples/)

## Train and deploy models from massive data sets: fraud detection use case

**Source:** `Architecture Center`

As your business goes through digital transformation and increasingly accepts online payment, effective methods to detect 
and eventually prevent credit card fraud are necessary to avoid losses. Since fraud is expected to account for a small 
fraction of all transactions, massive amounts of data are typically needed to build a robust and accurate model capable 
of alerting of fraud with minimal false positives.

[https://docs.oracle.com/en/solutions/models-credit-card-fraud-detection/index.html](https://docs.oracle.com/en/solutions/models-credit-card-fraud-detection/index.html)

## Employ anomaly detection for managing assets and predictive maintenance

**Source:** `Architecture Center`

Anomaly detection is the identification of rare items, events, or observations in data that greatly differ from expectations. This has uses in many industries for asset monitoring and maintenance.

Anomaly Detection Service helps you detect anomalies in time series data without the need for statisticians or machine learning experts. 
It provides prebuilt algorithms, and it addresses data issues automatically. It is a cloud-native service accessible over REST APIs and 
can connect to many data sources. The OCI Console, CLI, and SDK make it easy for use in end-to-end solutions.

[https://docs.oracle.com/en/solutions/anomaly-detection/index.html](https://docs.oracle.com/en/solutions/anomaly-detection/index.html)

##  Oracle Architecture Center

**Reference architectures and best practices**

Leverage knowledge from Oracle experts. Use our reference architectures, solution playbooks, and customer stories to build and deploy your cloud, 
hybrid, and on-premises workloads.

[Explore Oracle Architecture Center](https://docs.oracle.com/pls/topic/lookup?ctx=en/solutions&id=solutions-home)

## Contributing

This project welcomes contributions from the community. Before submitting a pull request, please [review our contribution guide](./CONTRIBUTING.md)

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process

## License

Copyright (c) 2018, 2023 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at
<https://oss.oracle.com/licenses/upl/>.

"
browserstack/testng-browserstack,master,68,143,2016-03-01T08:34:12Z,28685,19,Selenium examples for TestNG and BrowserStack Automate,,"# testng-browserstack

[TestNG](http://testng.org) Integration with BrowserStack.

![BrowserStack Logo](https://d98b8t1nnulk5.cloudfront.net/production/images/layout/logo-header.png?1469004780)

## Using Maven

### Run sample build

- Clone the repository
- Replace YOUR_USERNAME and YOUR_ACCESS_KEY with your BrowserStack access credentials in browserstack.yml.
- Install dependencies `mvn compile`
- To run the test suite having cross-platform with parallelization, run `mvn test -P sample-test`
- To run local tests, run `mvn test -P sample-local-test`

Understand how many parallel sessions you need by using our [Parallel Test Calculator](https://www.browserstack.com/automate/parallel-calculator?ref=github)

### Integrate your test suite

This repository uses the BrowserStack SDK to run tests on BrowserStack. Follow the steps below to install the SDK in your test suite and run tests on BrowserStack:

* Create sample browserstack.yml file with the browserstack related capabilities with your [BrowserStack Username and Access Key](https://www.browserstack.com/accounts/settings) and place it in your root folder.
* Add maven dependency of browserstack-java-sdk in your pom.xml file
```sh
<dependency>
    <groupId>com.browserstack</groupId>
    <artifactId>browserstack-java-sdk</artifactId>
    <version>LATEST</version>
    <scope>compile</scope>
</dependency>
```
* Modify your build plugin to run tests by adding argLine `-javaagent:${com.browserstack:browserstack-java-sdk:jar}` and `maven-dependency-plugin` for resolving dependencies in the profiles `sample-test` and `sample-local-test`.
```
            <plugin>
               <artifactId>maven-dependency-plugin</artifactId>
                 <executions>
                   <execution>
                     <id>getClasspathFilenames</id>
                       <goals>
                         <goal>properties</goal>
                       </goals>
                   </execution>
                 </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>3.0.0-M5</version>
                <configuration>
                    <suiteXmlFiles>
                        <suiteXmlFile>config/sample-local-test.testng.xml</suiteXmlFile>
                    </suiteXmlFiles>
                    <argLine>
                        -javaagent:${com.browserstack:browserstack-java-sdk:jar}
                    </argLine>
                </configuration>
            </plugin>
```
* Install dependencies `mvn compile`

## Using Gradle

### Prerequisites
- If using Gradle, Java v9+ is required.

### Run sample build

- Clone the repository
- Install dependencies `gradle build`
- To run the test suite having cross-platform with parallelization, run `gradle sampleTest`
- To run local tests, run `gradle sampleLocalTest`

Understand how many parallel sessions you need by using our [Parallel Test Calculator](https://www.browserstack.com/automate/parallel-calculator?ref=github)

### Integrate your test suite

This repository uses the BrowserStack SDK to run tests on BrowserStack. Follow the steps below to install the SDK in your test suite and run tests on BrowserStack:

* Following are the changes required in `gradle.build` -
    * Add `compileOnly 'com.browserstack:browserstack-java-sdk:latest.release'` in dependencies
    * Fetch Artifact Information and add `jvmArgs` property in tasks *SampleTest* and *SampleLocalTest* :
  ```
  def browserstackSDKArtifact = configurations.compileClasspath.resolvedConfiguration.resolvedArtifacts.find { it.name == 'browserstack-java-sdk' }
  
  task sampleTest(type: Test) {
    useTestNG() {
      dependsOn cleanTest
      useDefaultListeners = true
      suites ""config/sample-test.testng.xml""
      jvmArgs ""-javaagent:${browserstackSDKArtifact.file}""
    }
  }
  ```

* Install dependencies `gradle build`


## Notes
* You can view your test results on the [BrowserStack Automate dashboard](https://www.browserstack.com/automate)
"
habuma/spring-in-action-5-samples,main,1201,1048,2018-08-11T23:29:43Z,670,75,Home for example code from Spring in Action 5.,,
fescobar/allure-docker-service-examples,master,58,70,2020-08-21T14:56:36Z,3245,3,Repository to share examples about Allure Docker Service & Allure Docker Service UI,allure allure-docker-service allure-docker-service-ui automation docker kubernetes report reporting-tool testing testing-tools,"# ALLURE DOCKER SERVICE EXAMPLES
## OFFICIAL

- Kubernetes --> [allure-docker-kubernetes-example](allure-docker-kubernetes-example)

- MultiProject --> [allure-docker-multi-project-example](allure-docker-multi-project-example)

- TestNG  --> [allure-docker-java-testng-example](allure-docker-java-testng-example)
- JUnit4  --> [allure-docker-java-junit4-example](allure-docker-java-junit4-example)
- Cucumber JVM  --> [allure-docker-java-cucumber-jvm-example](allure-docker-java-cucumber-jvm-example)
- CucumberJS  --> [allure-docker-nodejs-cucumber-example](allure-docker-nodejs-cucumber-example)
- CucumberJS TypeScript --> [allure-docker-nodejs-typescript-cucumber-example](allure-docker-nodejs-typescript-cucumber-example)
- Mocha --> [allure-docker-nodejs-typescript-mocha-example](allure-docker-nodejs-typescript-mocha-example)
- Behave --> [allure-docker-python-behave-example](allure-docker-python-behave-example)
- PyTest --> [allure-docker-python-pytest-example](allure-docker-python-pytest-example)
- SpecFlow --> [AllureDockerCSharpExample](AllureDockerCSharpExample)
- SpecFlow3 --> [AllureDockerCSharpSpecFlow3Example](AllureDockerCSharpSpecFlow3Example)

See documentation here:
- https://github.com/fescobar/allure-docker-service
- https://github.com/fescobar/allure-docker-service-ui

## NO OFFICIAL
- Azure Container Instances --> https://github.com/khanzzirfan/jsonserver-mockend/blob/main/azure-aci-template.json
- AWS Terraform --> https://github.com/Idea-Pool/aws-allure
- GitHub Actions --> https://github.com/unickq/send-to-allure-docker-service-action
- Allure Operator --> https://github.com/mting806/allure-operator
"
aspose-pdf/Aspose.PDF-for-Java,master,121,133,2011-11-25T13:52:01Z,116431,20,"Aspose.PDF for Java examples, plugins and showcases",,"![GitHub all releases](https://img.shields.io/github/downloads/aspose-pdf/Aspose.pdf-for-Java/total) ![GitHub](https://img.shields.io/github/license/aspose-pdf/Aspose.pdf-for-java)
# Java API to Process & Manipulate PDF Files

[Aspose.PDF for Java](https://products.aspose.com/pdf/java) is a PDF document creation component that enables your Java applications to read, write and manipulate PDF documents without using Adobe Acrobat.

Directory | Description
--------- | -----------
[Examples](Examples) | A collection of Java examples that help you learn the product features.

<p align=""center"">
  <a title=""Download Examples ZIP"" href=""https://github.com/aspose-pdf/Aspose.pdf-for-Java/archive/master.zip"">
	<img src=""https://raw.github.com/AsposeExamples/java-examples-dashboard/master/images/downloadZip-Button-Large.png"" />
  </a>
</p>

## `aspose.pdf` Package Features

### PDF Document Featres

- Set basic information (e.g. author, creator) of the PDF document.
- Configure PDF Page properties (e.g. width, height, cropbox, bleedbox etc.).
- Set page numbering, bookmark level, page sizes etc.
- Apply document open action, open mode as well as appearance.
- Document can have different page transition effects such as dissolve or box.
- Create PDF documents via `XML`, `API` or `XML` and `API` combined.
- Ability to work with text, paragraphs, headings, hyperlinks, graphs, attachments etc.

### Security Features

- PDF documents can be encrypted up to 128 bits.
- Master and user passwords can be set for PDF encryption.
- Apply rescriptions on content modification, copying, printing and other operations.

### Conversion Features

- Convert an existing XML file (`.XML`) or `XmlDocument` to a new PDF document or a PDF file stream.
- Convert conventional Image formats into PDF file.
- Convert `PCL` files into PDF file.

For a more comprehensive list of features, please visit [Features of `aspose.pdf` Package](https://docs.aspose.com/pdf/java/features-of-aspose-pdf-package/).

## `com.aspose.pdf` Package Features

- Supports 14 core fonts.
- Support for `Type 1`, `TrueType`, `Type 3`, `CJK` fonts.
- `Unicode` support is available.
- Add, search, extract and replace text in PDF files.
- Add/delete, extract and replace images.
- Insert, delete, split PDF pages.
- Support for Linearization (optimization for the web).
- Set and get XMP metadata.
- Validate (`PDF/A-1a`, `PDF/A-1b`).
- Work with bookmarks, annotations, PDF forms, stamps, watermarks and more.

For a more comprehensive list of features, please visit [Features of `com.aspose.pdf` Package](https://docs.aspose.com/pdf/java/features-of-com-aspose-pdf-package/).

## `com.aspose.pdf.facades` Package Features

- Supports 14 core fonts.
- Support for `Type 1`, `TrueType`, `Type 3`, `CJK` fonts.
- `Unicode` support is available.
- Add, replace and extract text & images (from the entire PDF, a particular page, or a range of pages).
- Work with bookmarks, annotations, PDF forms, links, actions, signature and more.
- Print PDF to default, specified, physical, or virtual printer.
- Print PDF to `XPS` file or XPS printer.

For a more comprehensive list of features, please visit [Features of `com.aspose.pdf.facades` Package](https://docs.aspose.com/pdf/java/features-of-com-aspose-pdf-facades-package/).

## Read & Write PDF & Other Formats

**Fixed Layout:** PDF, XPS\
**Books:** EPUB\
**Web:** HTML
**Other:** TEX, XML, SVG

## Save PDF Documents As

**Microsoft Office:** DOC, DOCX, XLS, XLSX, PPTX\
**Images:** JPEG, PNG, BMP, TIFF, EMF\
**Other:** MobiXML, XML, TEXT

## Read Formats

CGM, MHT, PCL, PS, XSLFO, MD

## Supported Environments

- **Microsoft Windows:** Windows Desktop & Server (x86, x64)
- **macOS:** Mac OS X
- **Linux:** Ubuntu, OpenSUSE, CentOS, and others
- **Java Versions:** `J2SE 8.0 (1.8)` or above

## Get Started with Aspose.PDF for Java

Aspose hosts all Java APIs at the [Aspose Repository](https://repository.aspose.com/webapp/#/artifacts/browse/tree/General/repo/com/aspose/aspose-pdf). You can easily use Aspose.PDF for Java API directly in your Maven projects with simple configurations. For the detailed instructions please visit [Installing Aspose.PDF for Java from Aspose Repository](https://docs.aspose.com/pdf/java/installation/) documentation page.

## Extract text from a PDF file using Java

```java
// For complete examples and data files, please go to https://github.com/aspose-pdf/Aspose.Pdf-for-Java
// Open document
Document pdfDocument = new Document(""input.pdf"");

// Create TextAbsorber object to extract text
TextAbsorber textAbsorber = new TextAbsorber();

// Accept the absorber for all the pages
pdfDocument.getPages().accept(textAbsorber);

// Get the extracted text
String extractedText = textAbsorber.getText();

// Create a writer and open the file
java.io.FileWriter writer = new java.io.FileWriter(new java.io.File(""Extracted_text.txt""));
writer.write(extractedText);

// Write a line of text to the file tw.WriteLine(extractedText);
// Close the stream
writer.close();
```

[Product Page](https://products.aspose.com/pdf/java) | [Docs](https://docs.aspose.com/pdf/java/) | [Demos](https://products.aspose.app/pdf/family) | [API Reference](https://apireference.aspose.com/pdf/java) | [Examples](https://github.com/aspose-pdf/Aspose.PDF-for-Java/tree/master/Examples) | [Blog](https://blog.aspose.com/category/pdf/) | [Search](https://search.aspose.com/) | [Free Support](https://forum.aspose.com/c/pdf) | [Temporary License](https://purchase.aspose.com/temporary-license)
"
sequenceiq/sequenceiq-samples,master,116,45,2014-02-23T09:58:24Z,12979,0,SequenceIQ Hadoop examples,,"SequenceIQ Hadoop sample projects
============================

This repository is a collection of sample projects and code examples featured in our blog entries - for more details check  [SequenceIQ blog](http://blog.sequenceiq.com). 
This samples repository and the blog contains random thoughts and proof-of-concepts/interesting issues we have face during our product development stack.

Where the samples are not covered by a blog entry, we try to make them self explanatory or supply a short readme. Please feel free to collaborate, share, ask for help or report issues.


* **flume-sources** module: [Custom Apache Flume source](http://blog.sequenceiq.com/blog/2014/02/22/custom-flume-source/)
* **etl-samples** module: [ETL - producing better quality data](http://blog.sequenceiq.com/blog/2014/02/28/etl-and-data-quality/)
* **hdp-sandbox-access** module: [Accessing HDP2 sandbox from the host](http://blog.sequenceiq.com/blog/2014/03/05/access-hdp2-sandbox/)
* **lastfm-morphlines-etl** module: [How-to: Process Data using Morphlines (in Kite SDK)](http://blog.cloudera.com/blog/2014/04/how-to-process-data-using-morphlines-in-kite-sdk/)
* **hdp-sandbox-access** module: [HDFS and java.nio.channels](http://blog.sequenceiq.com/blog/2014/03/07/read-from-hdfs/)
* **mapreduce-morphline** module: [Data cleaning with MapReduce and Morphlines](http://blog.sequenceiq.com/blog/2014/03/11/data-cleaning-with-mapreduce-and-morphlines/)
* **yarn-queue-tests** module: [YARN Capacity Scheduler](http://blog.sequenceiq.com/blog/2014/03/14/yarn-capacity-scheduler/)
* **tez-dag-jobs** module: [Using Mahout with Tez](http://blog.sequenceiq.com/blog/2014/03/31/mahout-on-tez/)
* **yarn-monitoring-R** module: [Monitoring YARN with R]()
* **scalding-correlation** module: [Correlation example with Scalding](http://blog.sequenceiq.com/blog/2014/06/23/scalding-correlation-example/)
* **spark-clustering** module: [K-means clustering on Spark](http://blog.sequenceiq.com/blog/2014/07/31/spark-mllib/)

Thanks,
[SequenceIQ](http://sequenceiq.com)

"
SonarSource/sonar-training-examples,master,38,64,2018-09-21T15:11:19Z,43652,0,,,"# SonarQube Training Examples

Several examples of analysis that demonstrate different use cases

## Sub-directories

* [complexity](complexity/): Demonstrates difference between cyclomatic and cognitive complexity

* [coverage-metrics](coverage-metrics/): Demonstrates the calculations for line, condition and overall coverage

* [size-metrics](size-metrics/): Demonstrates the calculation of different size metrics (lines, loc, lines to cover, comment lines and comments %)

* [metrics-without-scm](metrics-without-scm/): Demonstrates the SonarQube 7.1+ ability to compute metrics on new code even without SCM

* [branches](branches/): Demonstrates the SonarQube 6.7+ new branch management system, and to compare results with 5.6- old branch management.

* [portfolios](portfolios/): Example of meaningful Portfolios hierarchy and Application

* [file-renaming](file-renaming/): Demonstrate the SonarQube 6.7+ issue tracking preservation (and new code preservation) in case of file renaming or file move.

* [security](security/): Example of (7.3+) Vulnerabilities and Security Hotspots.

* [external-issues](external-issues/): Example of (7.2+) external linter issues import.

* [pull-request](pull-request/): Example of (7.7+) support for GitHub pull request analysis
"
jveverka/java-11-examples,master,57,53,2018-07-09T17:54:00Z,3149,4,JDK 11 examples and demo projects.,akka avro blockchain clustering dagger dependency-injection google-guice grpc hazelcast hibernate java11 jetty jni kafka mongodb mongodb-database rxjava ssh ssh-server testcontainers,"[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Java11](https://img.shields.io/badge/java-11-blue)](https://img.shields.io/badge/java-11-blue)
[![Gradle](https://img.shields.io/badge/gradle-v6.5-blue)](https://img.shields.io/badge/gradle-v6.5-blue)
![Build and Test](https://github.com/jveverka/java-11-examples/workflows/Build%20and%20Test/badge.svg)

# Java 11 examples
This repository contains various simple java 11 examples.
Examples are demonstrating not only new java 11 language features, 
but also new JDK 11 possibilities. 

### Environment setup
Make sure following software is installed on your PC.
* [OpenJDK 11](https://adoptopenjdk.net/?variant=openjdk11&jvmVariant=hotspot)
* [Gradle 6.8](https://gradle.org/install/) or later
* [docker.io 19.x](https://www.docker.com/) or later 

Please check [system requirements](docs/system-requirements.md) before. 

### Compile & Test
Most examples are build by top-level gradle project.
```
gradle clean build test
```

### Examples
* [artefact publishing demo](artefact-publishing-demo) - publish artefact to ORSSH.
* [akka clustering demo](akka-cluster-sshsessions)
* [futures demo](futures-demo)
* [image processing demo](imageprocessing-demo)
* [jetty server demo](jetty-servlet4-http2)
* [kafka example](kafka-example)
* [RxJava demo](rxjava-demo)
* [simple JNI demo](simple-jni-demo)
* [JPMS demo](simple-module-example)
* [ssh server demo](ssh-server-demo)
* [com.fasterxml.jackson](jackson-fasterxml-demo)
* [weird java stuff](java-is-weird)
* __Security and Crypto__
  * [Diffie-Hellman demo](diffie-hellman-demo) 
  * [JCE demo](jce-demo)
  * [Blockchain demo](block-chain)
  * [JWT demo](jwt-demo)
  * [Entropy calculation demo](entropy-demo)
  * [Enigma demo](enigma-demo)
* __Databases__
  * [mongodb demo](mongodb-demo)
  * [hibernate demo](hibernate-demo)
  * [JDBC demo](jdbc-demo)
  * [R2DBC demo](r2dbc-demo)
  * [Elastic Search demo](elastic-demo)

### Other Java Examples
* [spring demos](https://github.com/jveverka/spring-examples) - java11 & docker & gradle examples
* [java-boot-camp](https://github.com/jveverka/java-boot-camp) - java11 tutorials & maven examples

### JDK9 - JDK11 New Features 
* JDK9  [Feature list](https://openjdk.java.net/projects/jdk9/)
* JDK10 [Feature list](https://openjdk.java.net/projects/jdk/10/)
* JDK11 [Feature list](https://openjdk.java.net/projects/jdk/11/) 

### References
* [JDK12 - JDK17 Features](https://github.com/jveverka/java-17-examples)

_Enjoy !_
"
atinfo/at.info-knowledge-base,master,209,159,2013-12-05T22:34:53Z,1394,13,http://automated-testing.info knowledge base on test automation examples,,"at.info knowledge base
======================

http://automated-testing.info knowledge base is basement to provide different examples on test automation topics for different tools. Please have a look to overview page http://atinfo.github.io/at.info-knowledge-base/

Feel free to add and share with test automation communite any examples you wanted. Create pull request and share it.
Keep it automated! :)


Contribution Guidelines
======================

1. **Fork**
2. **Implement** Something
3. Submit a **Pull Request**
4. <a href=""http://automated-testing.info/t/gotovye-reczepty-ili-aktivizacziya-soobshhestva-avtomatizatorov-na-atinfo/4441"">**Create code recipe** on http://automated-testing.info</a> For example, like this http://automated-testing.info/t/code-recipe-kak-ispolzovat-sikuli-c-webdriver-primer-dlya-http-automated-testing-info/4586
4. High Five!


Small requirements to pull requests
======================

1. **Workable code**
2. Folder's name and all other names should be **informative**
3. **README.md** with description in root is obligatory (<a href=""https://github.com/atinfo/at.info-knowledge-base/blob/master/functional%20test%20automation/webdriver/methods-interceptor-via-aspectj-on-java/README.md"">please have a look to already existed examples</a>)


Timeline on added examples
======================
Also you can see it on http://atinfo.github.io/at.info-knowledge-base/

<ul>
            <li> <label>java</label> <label>selenium</label> <label>webdriver</label> <label>select2</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/select2-wrapper"" target=""_blank"">how to create a Select2 wrapper for further interaction with WebDriver</a> </li>
            <li> <label>java</label> <label>selenium</label> <label>webdriver</label> <label>content-supplier</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/selenium-supplier-examples"" target=""_blank"">set of examples in regards to selenium content supplier project</a> </li>
            <li> <label>java</label> <label>selenium</label> <label>webdriver</label> <label>content-supplier</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/selenium-supplier"" target=""_blank"">how to supply selenium content to remote environment</a> </li>
            <li> <label>java8</label> <label>selenium</label> <label>webdriver</label> <label>interfaces</label> <label>framework-design</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/java8-interfaces-impact-on-framework-design"" target=""_blank"">java 8 interfaces impact on test automation framework design</a> </li>
            <li> <label>java</label> <label>selenium</label> <label>webdriver</label> <label>env-watcher</label> <label>jenkins</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/selenium-utils-env-watcher"" target=""_blank"">jenkins plugin for managing stucked environment using env-watcher service</a> </li>
            <li> <label>java</label> <label>selenium</label> <label>webdriver</label> <label>env-watcher</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/env-watcher"" target=""_blank"">how to manage stucked environment via standalone service</a> </li>
            <li> <label>java</label> <label>mysql</label> <label>hibernate</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/java/testng/mysql-data-provider"" target=""_blank"">how to use Hibernate ORM and Java 8 tricks for retrieving DB entities</a> </li>
            <li> <label>java</label> <label>Mustache</label> <label>testng</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/java/mustache/html-templates"" target=""_blank"">How to create custom reports based on TestNG results with Mustache template engine.</a> </li>
            <li> <label>java</label> <label>jenkins</label> <label>webdriver</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/selenium-utils-jenkins-plugin"" target=""_blank"">How to shutdown Selenium Grid hub / nodes on Jenkins plugin</a> </li>
            <li> <label>java</label> <label>junit</label> <label>maven</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/java/junit/run_methods_by_tag"" target=""_blank"">How to run the only test methods, which has a special tag from java junit</a> </li>
            <li> <label>mailcatcher</label> <label>java</label> <label>rest</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/mailcatcher%20rest%20client%20on%20java"" target=""_blank"">How to use MailCatcher REST API for emails testing</a> </li>
            <li> <label>webdriver</label> <label>java</label> <label>proxy</label>  <label>browsermob</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/remote%20proxy%20and%20har%20storage%20on%20java"" target=""_blank"">How to use remote proxy (BrowserMob) and save output HAR files into storage</a> </li>
            <li> <label>webdriver</label> <label>java</label> <label>proxy</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/setting%20proxy%20for%20webdriver%20on%20java"" target=""_blank"">How to initialise Webdriver and RemoteWebdriver with custom Proxy</a></li>
            <li> <label>javascript</label> <label>firepath</label> <label>xul</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/javascript/how%20to%20extend%20firepath"" target=""_blank"">How to modify FirePath extension to allow saving locators with custom names</a></li>
            <li> <label>teamcity</label> <label>junit</label> <label>java</label> <label>maven</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/java/junit/run_failed_tests"" target=""_blank"">How to rerun the only failed tests from TeamCity build</a></li>
            <li> <label>thucydides</label> <label>junit</label> <label>java</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/thucydides/simple%20example%20of%20test%20based%20on%20google.com"" target=""_blank"">How to create simplest webdriver bdd test using Java+JUnit+Thucydides</a> </li>
            <li> <label>webdriver</label> <label>python</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/typed%20webelements%20on%20python"" target=""_blank"">How to create typed webelements for your webdriver python tests</a> </li>
            <li> <label>robot framework</label> <label>python</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/robotframework/Simple%20Hybrid%20(Python%20%2B%20Robotframework)%20Page%20Object%20Example"" target=""_blank"">Simple Hybrid (Python + Robotframework) Page Object Example</a> </li>
            <li> <label>webdriver</label> <label>java</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/methods-interceptor-via-aspectj-on-java"">How to intercept methods calls for collecting test steps via aspectj</a> </li>
            <li> <label>webdriver</label> <label>java</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/custom-locators-on-java"">How to create custom locators dynamically</a> </li>
            <li> <label>webdriver</label> <label>java</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/methods-interceptor-on-java"">How to intercept methods calls for collecting test steps</a> </li>
            <li> <label>java</label> <label>sikuli</label> <label>webdriver</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/sikuli/Java%20Sikuli%20WebDriver%20Examples"">How to use sikulix with wrappers, interfaces, observers to automate web with webdriver </a> </li>
            <li> <label>webdriver</label> <label>java</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/capture%20video%20on%20java"">Example on implementation screen recorder for web tests on webdriver by means of java</a> </li>
            <li> <label>webdriver</label> <label>java</label> <label>python</label> <label>ruby</label> <label>C#</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/file%20upload""> How to make file upload with Selenium WebDriver</a> </li>
            <li> <label>python</label> <label>webdriver</label> <label>browsermob</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/functional%20test%20automation/webdriver/chromedriver%20with%20browsermob%20proxy%20on%20python""> How to set chrome webdriver to use browsermob proxy</a> </li>
            <li> <label>python</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/python/code%20recipes/implement%20general%20wait""> How to implement generic waiting mechanism that wait on closure passed</a> </li>
            <li> <label>python</label> <a href=""https://github.com/atinfo/at.info-knowledge-base/tree/master/programming/python/code%20recipes/generate%20nested%20dicts""> Hot to make autogenerated nested dictionary without any headaches on getting not existed key</a> </li>
          </ul>
"
esig/dss-demonstrations,master,87,63,2017-01-27T13:00:01Z,102343,6,Examples of DSS integration,,"## Demonstrations for DSS : Digital Signature Service

This is the demonstration repository for project DSS : https://ec.europa.eu/digital-building-blocks/wikis/display/DIGITAL/eSignature. 

# Issue Tracker

Please, use the new JIRA for project is on https://ec.europa.eu/digital-building-blocks/tracker/projects/DSS/issues. 

# Maven repository

The release of [DSS](https://github.com/esig/dss) is published on Maven Central repository : 

https://central.sonatype.com/search?q=eu.europa.ec.joinup.sd-dss

# Demonstration

The demonstration bundle is deployed at https://ec.europa.eu/digital-building-blocks/DSS/webapp-demo

# DSS Standalone Application

In order to build the standalone application, the following modules are required:

 * dss-standalone-app;
 * dss-standalone-package.
 
If the build is successful, you will be able to find out the following containers in the directory `/dss-standalone-app-package/target/`:

 * dss-standalone-app-package-minimal.zip - contains the application code. Requires JDK ad JavaFX installed on a target machine in order to run the application;
 * dss-standalone-app-package-complete.zip - contains the application code, as well as JDK and JavaFX library code. Can be run on a machine whithout pre-installed libraries.

In order to launch the application, you will need to extract the archive and run the file `dss-run.bat`.

# DSS Web Application

To build the DSS Web Application the following modules are required:

 * dss-demo-webapp;
 * dss-demo-bundle.
 
After a successful build, in the directory `/dss-demo-bundle/target/` you will be able to find out two containers: `dss-demo-bundle.zip` and `dss-demo-bundle.tar.gz`. Despite the container type, the content of both files is the same. After extracting the content, you will need to run the file `Webapp-Startup.bat` in order to launch the server and the file `Webapp-Shutdown.bat` to stop the server. After running the server, the web-application will be available at the address `http://localhost:8080/`.

# JavaDoc

The JavaDoc is available on https://ec.europa.eu/digital-building-blocks/DSS/webapp-demo/apidocs/index.html

# Ready-to-use bundles

Bundles which contain the above demonstration can be downloaded from the [Maven repository](https://ec.europa.eu/digital-building-blocks/artifact/service/rest/repository/browse/esignaturedss/eu/europa/ec/joinup/sd-dss/dss-demo-bundle/).

The code of the demonstration can be found on https://ec.europa.eu/digital-building-blocks/code/projects/ESIG/repos/dss-demos/browse

[![License (LGPL version 2.1)](https://img.shields.io/badge/license-GNU%20LGPL%20version%202.1-blue.svg?style=flat-square)](https://www.gnu.org/licenses/lgpl-2.1.html)"
restfb/restfb-examples,master,54,32,2016-01-10T16:21:41Z,476,6,Exmples how to use RestFB,examples java restfb,"# restfb-examples

First run:

```bash
$ mvn compile
```

You can run the examples afterwards like this:

```bash
$ mvn exec:java@run-reader-examples -Daccess_token=MY_ACCESS_TOKEN
$ mvn exec:java@run-publisher-examples -Daccess_token=MY_ACCESS_TOKEN
$ mvn exec:java@run-login-example -Dapp_id=APP_ID -Dapp_secret=APP_SECRET
```

Instructions for getting an OAuth access token are available on [RestFB](http://restfb.com).
Or simply take one from [Facebook Graph API Explorer]([https://developers.facebook.com/tools/explorer/]).
You need [maven](https://maven.apache.org/) (>3.3.1) to be installed on your system."
dremio-hub/arrow-flight-client-examples,main,64,64,2020-10-20T22:57:32Z,175,6,,,"# Arrow Flight Client Application Examples

This repository provides sample Arrow Flight client applications in several languages to help you get started with Dremio Arrow Flight server endpoint.
"
hellokaton/java-library-examples,master,216,29,2018-01-15T06:11:32Z,468,1,"💪 example of common used libraries and frameworks, programming required, don't fork man.",cache email examples java kafka logback okhttp3 orm qrcode yaml,"# Java Library Examples

Java 库、框架使用示例大全，持续更新，请勿 `fork`。

[![](https://img.shields.io/travis/biezhi/java-library-examples.svg)](https://travis-ci.org/biezhi/java-library-examples)
[![](https://img.shields.io/badge/license-MIT-FF0080.svg)](https://github.com/biezhi/java-library-examples/blob/master/LICENSE)
[![@biezhi on zhihu](https://img.shields.io/badge/zhihu-%40biezhi-red.svg)](https://www.zhihu.com/people/biezhi)
[![](https://img.shields.io/github/followers/biezhi.svg?style=social&label=Follow%20Me)](https://github.com/biezhi)

- [`cache-example`](https://github.com/biezhi/java-library-examples/tree/master/cache-example)
    - [`ehcache-example`](https://github.com/biezhi/java-library-examples/blob/master/cache-example/ehcache-example)
    - [`guava-cache-example`](https://github.com/biezhi/java-library-examples/blob/master/cache-example/guava-cache-example)
    - [`jedis-example`](https://github.com/biezhi/java-library-examples/blob/master/cache-example/jedis-example)
- [`compress-example`](https://github.com/biezhi/java-library-examples/tree/master/compress-example)
- [`crawler-example`](https://github.com/biezhi/java-library-examples/blob/master/crawler-example)
    - [`crawler4j-example`](https://github.com/biezhi/java-library-examples/blob/master/crawler-example/crawler4j-example)
    - [`elves-example`](https://github.com/biezhi/java-library-examples/blob/master/crawler-example/elves-example)
    - [`webmagic-example`](https://github.com/biezhi/java-library-examples/blob/master/crawler-example/webmagic-example)
- [`email-example`](https://github.com/biezhi/java-library-examples/tree/master/email-example)
    - [`commons-email-example`](https://github.com/biezhi/java-library-examples/tree/master/email-example/commons-email-example/src/main/java/io/github/biezhi/email)
    - [`ohmyemail-example`](https://github.com/biezhi/java-library-examples/blob/master/email-example/ohmyemail-example)
- [`embedded-example`](https://github.com/biezhi/java-library-examples/blob/master/embedded-example)
- [`encrypt-example`](https://github.com/biezhi/java-library-examples/blob/master/encrypt-example)
- [`excel-example`](https://github.com/biezhi/java-library-examples/blob/master/excel-example)
- [`gui-example`](https://github.com/biezhi/java-library-examples/blob/master/gui-example)
- [`http-example`](https://github.com/biezhi/java-library-examples/blob/master/http-example)
    - [`httpclient4-example`](https://github.com/biezhi/java-library-examples/tree/master/http-example/httpclient4-example/src/main/java/io/github/biezhi/httpclient4)
    - [`ohmyrequest-example`](https://github.com/biezhi/java-library-examples/blob/master/http-example/ohmyrequest-example)
    - [`okhttp3-example`](https://github.com/biezhi/java-library-examples/tree/master/http-example/okhttp3-example/src/main/java/io/github/biezhi/okhttp3)
    - [`unirest-example`](https://github.com/biezhi/java-library-examples/tree/master/http-example/unirest-example/src/main/java/io/github/biezhi/unirest)
- [`json-example`](https://github.com/biezhi/java-library-examples/blob/master/json-example)
    - [`fastjson-example`](https://github.com/biezhi/java-library-examples/tree/master/json-example/fastjson-example/src/main/java/io/github/biezhi/json/fastjson)
    - [`gson-example`](https://github.com/biezhi/java-library-examples/tree/master/json-example/gson-exmaple/src/main/java/io/github/biezhi/json/gson)
    - [`jackson-example`](https://github.com/biezhi/java-library-examples/tree/master/json-example/jackson-example/src/main/java/io/github/biezhi/json/jackson)
- [`log-example`](https://github.com/biezhi/java-library-examples/blob/master/log-example)
    - [`commons-logging-example`](https://github.com/biezhi/java-library-examples/tree/master/log-example/commons-logging-example/src/main/java/io/github/biezhi/commons/logging)
    - [`log4j-example`](https://github.com/biezhi/java-library-examples/blob/master/log-example/log4j-example/src/main/java/io/github/biezhi/log4j)
    - [`logback-example`](https://github.com/biezhi/java-library-examples/blob/master/log-example/logback-example/src/main/java/io/github/biezhi/logback)
    - [`slf4j-example`](https://github.com/biezhi/java-library-examples/blob/master/log-example/slf4j-example/src/main/java/io/github/biezhi/slf4j)
- [`metrics-example`](https://github.com/biezhi/java-library-examples/blob/master/metrics-example)
- [`mq-example`](https://github.com/biezhi/java-library-examples/blob/master/mq-example)
    - [`kafka-example`](https://github.com/biezhi/java-library-examples/blob/master/mq-example/kafka-example)
    - [`rabbitmq-example`](https://github.com/biezhi/java-library-examples/blob/master/mq-example/rabbitmq-example)
    - [`rocketmq-example`](https://github.com/biezhi/java-library-examples/blob/master/mq-example/rocketmq-example)
- [`network-example`](https://github.com/biezhi/java-library-examples/blob/master/network-example)
    - [`mina-example`](https://github.com/biezhi/java-library-examples/blob/master/network-example/mina-example)
    - [`netty-example`](https://github.com/biezhi/java-library-examples/blob/master/network-example/netty-example)
- [`orm-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example)
    - [`blade-jdbc-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example/blade-jdbc-example)
    - [`dbutils-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example/dbutils-example)
    - [`hibernate-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example/hibernate-example)
    - [`jooq-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example/jooq-example)
    - [`mybatis-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example/mybatis-example)
    - [`sql2o-example`](https://github.com/biezhi/java-library-examples/blob/master/orm-example/sql2o-example)
- [`qrcode-example`](https://github.com/biezhi/java-library-examples/blob/master/qrcode-example)
    - [`qrgen-example`](https://github.com/biezhi/java-library-examples/blob/master/qrcode-example/qrgen-example)
    - [`zxing-example`](https://github.com/biezhi/java-library-examples/blob/master/qrcode-example/zxing-example)
- [`rss-example`](https://github.com/biezhi/java-library-examples/blob/master/rss-example)
- [`task-example`](https://github.com/biezhi/java-library-examples/blob/master/task-example)
- [`template-example`](https://github.com/biezhi/java-library-examples/blob/master/template-example)
    - [`freemarker-example`](https://github.com/biezhi/java-library-examples/blob/master/template-example/freemarker-example)
    - [`jetbrick-example`](https://github.com/biezhi/java-library-examples/blob/master/template-example/jetbrick-example)
    - [`velocity-example`](https://github.com/biezhi/java-library-examples/blob/master/template-example/velocity-example)
- [`yaml-example`](https://github.com/biezhi/java-library-examples/tree/master/yaml-example/src/main/java/io/github/biezhi/yaml)

## 项目结构

如若在本地运行，请确保你的计算机已经安装如下环境

- Maven3
- Java8
- [lombok](https://projectlombok.org/) 插件

# 开源协议

[MIT](https://github.com/biezhi/java-library-examples/blob/master/LICENSE)"
daggerok/spring-5-examples,master,106,40,2017-09-02T23:49:23Z,653,12,This repository is contains spring-boot 2 / spring framework 5 project examples. Using reactive programming model / paradigm and Kotlin,flux functional-programming functional-reactive-programming kotlin mongodb mono reactive-programming reactor redis server-side-events spring-5 spring-boot spring-data spring-data-keyvalue spring-fu spring-reactive spring-security spring-webflux sse webclient,
ModeShape/modeshape-examples,master,32,51,2011-04-15T16:09:23Z,609,1,"A set of examples for ModeShape, which is a lightweight, fast, pluggable, open-source, federating JCR implementation that can unify content from multiple systems, including files systems, databases, data grids, other repositories, etc.",,"[![License](http://img.shields.io/:license-apache%202.0-brightgreen.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)
[![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.modeshape/modeshape-parent/badge.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.modeshape%22)
[![Build Status](https://travis-ci.org/ModeShape/modeshape-examples.svg?branch=master)](https://travis-ci.org/ModeShape/modeshape-examples)

# The ModeShape project

ModeShape is an open source implementation of the JCR 2.0 
([JSR-283](http://www.jcp.org/en/jsr/detail?id=283])) 
(aka, 'JCR') specification and standard API. To your applications, 
ModeShape looks and behaves like a regular JCR repository. Applications 
can search, query, navigate, change, version, listen for changes, etc. 
But ModeShape can store that content in a variety of back-end stores 
or it can access and update existing content from *other* kinds 
of systems (including file systems, SVN repositories, JDBC database 
metadata, and other JCR repositories). ModeShape's connector architecture 
means that you can write custom connectors to access any kind of system. 
And ModeShape can even federate multiple back-end systems into a single, 
unified virtual repository.

For more information on ModeShape, including getting started guides, 
reference guides, and downloadable binaries, visit the project's 
website at [http://www.modeshape.org]() or follow us on our 
[blog](http://modeshape.wordpress.org) or on 
[Twitter](http://twitter.com/modeshape). Or hop into our 
[IRC chat room](http://www.jboss.org/modeshape/chat)
and talk our community of contributors and users.

The official Git repository for the project is also on GitHub 
at [http://github.com/ModeShape/modeshape]().

# Examples

This Git repository contains examples showing how to use ModeShape 
within your applications. Each example is a self-contained Maven project
that is ready to use.

To run the examples, simply clone the repository:

    $ git clone git://github.com/ModeShape/modeshape-examples.git
    $ cd modeshape-examples

Then use Maven to build all of the examples (and run any unit tests):

    $ mvn clean install -s settings.xml

or you can build an individual example. For instance:

    $ cd modeshape-embedded-example
    $ mvn clean install -s settings.xml

See [this ModeShape community article](http://community.jboss.org/wiki/ModeShapeandMaven) 
for help on how to install Maven 3.

# Looking for ModeShape 4.x or 3.x examples?

The code on the 'master' branch works against the latest ModeShape 5.x 
release, but examples for ModeShape 4.x and 3.x are on different
branches. To get to those, use the Git `checkout` command to 
switch branches:

    $ git checkout 4.x
    
or

    $ git checkout 3.x

and then use the Maven command to build the examples (same as above).

# Need help?

ModeShape is open source software with a dedicated community. If you 
have any questions or problems, post a question in our 
[user forum](http://community.jboss.org/en/modeshape) or hop into our 
[IRC chat room](http://www.jboss.org/modeshape/chat) and talk our 
community of contributors and users.

# Contribute an example

We're always looking for good, easy to follow examples. If you've written 
one and would like to help, simply use GitHub's Fork and Pull-Request 
techniques.

1. Use the ""Fork"" button at the top of [this page](https://github.com/ModeShape/modeshape-examples) 
on GitHub to create your own fork.
2. Clone your fork:
<pre>
    $ git clone git@github.com:&lt;you>/modeshape-examples.git
    $ cd modeshape-examples
    $ git remote add upstream git://github.com/ModeShape/modeshape-examples.git
</pre>
3. Create a topic branch
<pre>
    $ git checkout -b &lt;branch-name>
</pre>
4. Make your changes
5. When all of the examples (including yours) build, commit to that branch
<pre>
    $ git commit .
</pre>
6. Push your commit(s) to your fork on GitHub
<pre>
    $ git push origin &lt;branch-name>
</pre>
7. On GitHub.com, go to your fork and switch branches to your topic branch, press the 'Pull Request' button, and fill out the form with the details.

We'll then review your submission and, if it works and builds, merge it into the examples repository."
jorgemoralespou/osev3-examples,master,27,71,2015-07-17T09:14:27Z,152,3,DEPRECATED!!!!! Use https://github.com/jorgemoralespou/s2i-java instead for building springboot,,
douglascraigschmidt/POSA-14,master,581,1690,2014-04-12T19:22:54Z,6268,28,This repository contains assignments and examples for the 2014 offering of the POSA MOOC (see www.coursera.org/course/posa for more information),,"POSA-14
=======

This repository contains assignments and examples for the 2014
offering of the POSA MOOC (see www.coursera.org/course/posa for more
information).
"
sjsdfg/OnJava8-Examples-Maven,master,80,72,2019-04-26T02:10:23Z,654,1,this is the maven version of OnJava8-Examples https://github.com/BruceEckel/OnJava8-Examples,on-java-8 onjava8,"# OnJava8-Examples-Maven

this is the maven version of OnJava8-Examples https://github.com/BruceEckel/OnJava8-Examples

more easier to import

no guarantee that this code is run ok.

because some code just show you the wrong way, like this:

```java
// generics/HijackedInterface.java
// (c)2017 MindView LLC: see Copyright.txt
// We make no guarantees that this code is fit for any purpose.
// Visit http://OnJava8.com for more book information.
// {WillNotCompile}

class Cat
        extends ComparablePet implements Comparable<Cat> {
    // error: Comparable cannot be inherited with
    // different arguments: <Cat> and <ComparablePet>
    // class Cat
    // ^
    // 1 error

    public int compareTo(Cat arg) {
        return 0;
    }
}

```
"
leveluplunch/levelup-java-examples,master,74,42,2013-11-15T01:23:45Z,703,16,Java examples,,"levelup-java-examples
=====================

[![Build Status](https://travis-ci.org/leveluplunch/levelup-java-exercises.png?branch=master)](https://travis-ci.org/leveluplunch/levelup-java-examples)


Levelup [Java examples](http://www.leveluplunch.com/java/examples/) is a series of java examples that attempt to cross cut libraries such as straight up java, java 8, [Google Guava](https://code.google.com/p/guava-libraries/), [Apache commons](http://commons.apache.org/), [Spring IO](http://spring.io/), [Joda Time](http://www.joda.org/joda-time/), [Hamcrest](https://code.google.com/p/hamcrest/), [Jackson JSON/XML processor](http://wiki.fasterxml.com/JacksonHome), [jsonpath](http://goessner.net/articles/JsonPath/), [Junit](http://junit.org/) and much more...


## Staying in touch

* [leveluplunch.com](http://www.leveluplunch.com)
* [Twitter](https://twitter.com/leveluplunch)
* [Google plus](https://plus.google.com/+Leveluplunch)
* [Facebook](https://www.facebook.com/leveluplunch)
* [Youtube channel](https://www.youtube.com/user/LevelUpLunch)
	
## License

Level up lunch is released under version 2.0 of the [Apache License](http://www.apache.org/licenses/LICENSE-2.0).
"
pkainulainen/jooq-with-spring-examples,master,78,57,2014-01-01T15:49:09Z,381,20,,,"jooq-with-spring-examples
=========================
"
datastax/graph-examples,master,52,41,2017-01-30T20:43:25Z,44111,9,,,"# graph-examples

This repo contains a collection of graph examples.  The intent is to provide more complete and extensive examples than what is reasonable to include in DataStax documentation or blogposts.  This will include DataStax Graph Loader mapping scripts, schemas, example traversals, things to try in DataStax Studio, and application code examples.  Feel free to use and modify any of these for your own purposes.  There is no warranty or implied official support, but hopefully the examples will be useful as a starting point to show various ways of loading and experimenting with graph data.  And if you see anything that could be improved or added, issue reports and pull requests are always welcome!

Download DSE (includes DSE Graph), DataStax Studio, and the DSE Graph Loader at https://academy.datastax.com/downloads.

## Graph Resources:

### Documentation
- Apache TinkerPop [documentation](http://tinkerpop.apache.org/docs/current/reference/), [getting started tutorial](http://tinkerpop.apache.org/docs/current/tutorials/getting-started/), and [common recipes](http://tinkerpop.apache.org/docs/current/recipes/)
- DataStax Enterprise Graph [documentation](http://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/graph/graphTOC.html)
- [sql2gremlin.com](http://sql2gremlin.com) - to help migrate from sql to graph, used in the [Northwind](/northwind) graph example

### Video tutorials

- DataStax Academy [DSA 330 course](https://academy.datastax.com/resources/ds330-datastax-enterprise-graph) on DSE Graph, a self-paced course covering both DSE Graph and Gremlin as a traversal language.
- DataStax Academy Gremlin Recipes
  - [Gremlin as a stream](https://vimeo.com/user35188327/review/215965720/22e5289c7e)
  - [SQL to Gremlin](https://vimeo.com/user35188327/review/215966324/84ecf9b4ee)
  - [Recommendation engine with Gremlin](https://vimeo.com/user35188327/review/216119433/0dcc2e6055)
  - [Recursive traversal](https://vimeo.com/user35188327/review/216179907/b40808f0a2)
  - [Path with Gremlin](https://vimeo.com/user35188327/review/216259582/8ae9955826)

### Blog posts

- [Getting started with the DataStax Graph Loader](http://www.datastax.com/dev/blog/dgl-basics)
- [Gremlin's Time Machine](https://www.datastax.com/dev/blog/gremlins-time-machine) - a post about how to use the TinkerPop SubgraphStrategy to traverse your graph at a specific version or time in its history.
- [graphoendodonticology](https://www.datastax.com/2017/03/graphoendodonticology) - a resource to troubleshoot your graph
- [Reducing Computational Complexity with Correlate Traversals](https://www.datastax.com/2017/04/reducing-computational-complexity-with-correlate-traversals) - a post about calculating network centrality in various manners and the associated cost.
- [Introducing DSE Graph Frames](http://www.datastax.com/dev/blog/dse-graph-frame) - how to use DSE Graph with Spark's GraphFrames with the associated [DseGraphFrames example](/dse-graph-frame)
- [Learn How to Build a Domain Specific Language with DSE Graph](https://www.datastax.com/dev/blog/gremlin-dsls-in-java-with-dse-graph)
- Large graph loading best practices, [part 1](http://www.datastax.com/dev/blog/large-graph-loading-best-practices-strategies-part-1) and [part 2](http://www.datastax.com/dev/blog/large-graph-loading-tactics-part-2)
- Blog series from [DuyHai Doan](https://twitter.com/doanduyhai)'s blog:
  1. [Gremlin as a Stream](http://www.doanduyhai.com/blog/?p=13224)
  2. [SQL to Gremlin](http://www.doanduyhai.com/blog/?p=13260)
  3. [Recommendation Engine Traversal](http://www.doanduyhai.com/blog/?p=13285)
  4. [Recursive Traversals](http://www.doanduyhai.com/blog/?p=13301)
  5. [Path Object](http://www.doanduyhai.com/blog/?p=13320)
  6. [Projection and Selection](http://www.doanduyhai.com/blog/?p=13352)
  7. [Variable Handling](http://www.doanduyhai.com/blog/?p=13374)
  8. [The `sack()` Operator](http://www.doanduyhai.com/blog/?p=13404)

### Presentations

- [The Gremlin Graph Traversal Language](https://www.slideshare.net/slidarko/the-gremlin-traversal-language), a presentation by Marko Rodriguez and Daniel Kuppitz
- Fighting Fraud with Graph Databases Webinar [recording](https://www.youtube.com/watch?v=H5MmSL1c9Zs) and [slides](https://www.slideshare.net/DataStax/webinar-fighting-fraud-with-graph-databases).  Presented by DataStax and Cambridge Intelligence.

### Help!

- [DataStax support portal](https://support.datastax.com) (for current DataStax customers)
- [DataStax Academy Slack](https://academy.datastax.com/slack) in the dse-graph channel
- [Gremlin-users google group](https://groups.google.com/forum/#!forum/gremlin-users)
- Stack overflow with the [datastax-enterprise/datastax-enterprise-graph](http://stackoverflow.com/questions/tagged/datastax-enterprise+datastax-enterprise-graph) tag

### Graph language drivers
- Apache TinkerPop [Gremlin Language Variants](http://tinkerpop.apache.org/docs/current/tutorials/gremlin-language-variants/) - describes TinkerPop's idiomatic language support in the form of a fluent API
- [Introduction to DataStax Driver Usage of Gremlin Language Variants](http://www.datastax.com/dev/blog/datastax-drivers-fluent-apis-for-dse-graph-are-out)
- [Java](http://docs.datastax.com/en/developer/java-driver-dse/1.4/) - includes both a String based and fluent API
- [Python](http://docs.datastax.com/en/developer/python-dse-driver/2.2/ - includes both a String based and fluent API 
- [Node.js](http://docs.datastax.com/en/developer/nodejs-driver-dse/1.3/)
- [C#](http://docs.datastax.com/en/developer/csharp-driver-dse/2.0/)
- [C/C++](http://docs.datastax.com/en/developer/cpp-driver-dse/1.2/)
- [Ruby](http://docs.datastax.com/en/developer/ruby-driver-dse/2.0/)
- [PHP](http://docs.datastax.com/en/developer/php-driver-dse/1.1/)
- Looking for Scala? Take a look at [this example](https://github.com/mpollmeier/gremlin-scala-examples/tree/master/dse-graph) of using Scala with the DataStax Java driver

### Additional datasets

For additional interesting datasets, you might consider the following resources:

- [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/) - a collection of connected data in various categories such as social data, web graphs, product co-purchasing networks, review data, etc.
- [Awesome Public Datasets](https://github.com/caesar0301/awesome-public-datasets) - a github repository with links to collections, large and small, of interesting public data.  These are further categorized by industry and data type such as energy, government, machine learning, time series, sports data, transportation, etc.
- [CRAWDAD](http://crawdad.org/) - the Community Resource for Archiving Wireless Data At Dartmouth.  This includes wireless network trace data from a variety of sources."
SAP-samples/cf-mta-examples,main,105,38,2019-11-28T19:31:47Z,9044,31,"The repository contains multitarget application (MTA) examples for SAP BTP, Cloud Foundry environment. Examples demonstrate how to achieve different goals using MTAs and show the capabilities of MTA deployment service in the Cloud Foundry environment.",cloud-foundry mta sample sample-code sap-btp sap-cloud-platform,
bybit-exchange/api-usage-examples,master,102,39,2021-11-24T17:01:10Z,219,0,,,"This repository maintains example API wrappers for using the bybit REST API and Websocket.
"
Vedenin/java_in_examples,master,63,47,2015-10-27T19:28:42Z,386,9,Moved to https://github.com/Vedenin/useful-java-links,,"### Moved to https://github.com/Vedenin/useful-java-links/tree/master/helloworlds


"
in28minutes/spring-boot-vuejs-fullstack-examples,master,57,82,2019-05-07T05:32:05Z,3944,84,All full stack examples with Spring Boot and Vue JS for articles on our website http://www.springboottutorial.com,,"# Spring Boot VueJS Full Stack Examples
All full stack examples with Spring Boot and VueJS for articles on our website http://www.springboottutorial.com

[![Image](https://www.springboottutorial.com/images/Course-Go-Full-Stack-With-SpringBoot-And-Angular.png ""Go Full Stack with Spring Boot and Angular"")](https://links.in28minutes.com/in28minutes-angular)

[![Image](https://www.springboottutorial.com/images/Course-Go-Full-Stack-With-Spring-Boot-and-React.png ""Go Full Stack with Spring Boot and React"")](https://links.in28minutes.com/in28minutes-React)

## Keep Learning Every Day
- **1:** [FOLLOW](https://links.in28minutes.com/lin) Ranga on LinkedIn

## Check Out Our Amazing ROADMAPS
- **1:** [AWS Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#aws-roadmap)
- **2:** [Azure Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#azure-roadmap)
- **3:** [Google Cloud Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#google-cloud-roadmap)
- **4:** [Cloud Beginner Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#cloud-beginner-roadmap)
- **5:** [DevOps Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#devops-roadmap)
- **6:** [Java Full Stack Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#java-full-stack-roadmap)
- **7:** [Java Microservices Roadmap](https://github.com/in28minutes/roadmaps/blob/main/README.md#java-microservices-roadmap)



### Installing Eclipse & Embedded Maven
- Installation Video : https://www.youtube.com/playlist?list=PLBBog2r6uMCSmMVTW_QmDLyASBvovyAO3
- GIT Repository For Installation : https://github.com/in28minutes/getting-started-in-5-steps
- PDF : https://github.com/in28minutes/SpringIn28Minutes/blob/master/InstallationGuide-JavaEclipseAndMaven_v2.pdf

### Running Examples
- Download the zip or clone the Git repository.
- Unzip the zip file (if you downloaded one)
- Open Command Prompt and Change directory (cd) to folder containing pom.xml
- Open Eclipse 
   - File -> Import -> Existing Maven Project -> Navigate to the folder where you unzipped the zip
   - Select the right project
- Choose the Spring Boot Application file (search for @SpringBootApplication)
- Right Click on the file and Run as Java Application
- You are all Set

### Troubleshooting
- Refer our TroubleShooting Guide - http://www.in28minutes.com/spring-boot-maven-eclipse-troubleshooting-guide-and-faq

### Useful Links
- Find out more about in28Minutes and our approach to creating great learning experience - The in28Minutes Way - http://www.in28minutes.com/the-in28minutes-way
- Facebook  : https://www.facebook.com/in28Minutes​
- Twitter   : https://twitter.com/in28Minutes​
- YouTube   : https://www.youtube.com/rithustutorials​
- Instagram : https://www.instagram.com/in28minutes/"
vireshmanagooli/hibernate,master,93,69,2014-08-13T02:34:17Z,348,3,Examples related to Hibernate framework,,"hibernate
=========

Examples related to Hibernate framework

For Hibernate tutorial, tricks and tips visit - http://supportmycode.com/
"
wildfly-security-incubator/elytron-examples,main,28,52,2017-08-23T11:29:16Z,421,40,,hacktoberfest,
pauldeck/springmvc-2ed,master,133,139,2016-03-26T00:41:40Z,13562,1,"Examples for Spring MVC: A Tutorial (Second Edition)"" book""",,"# springmvc-2ed
Examples for ""Spring MVC: A Tutorial (Second Edition)"" book (ISBN 9781771970310), Brainy Software (http://brainysoftware.com), April 2016

If you are not familiar with GIT, click the ""Download ZIP"" button above to download the apps as a zip file.

Each sample application comes in both Spring Tool Suite (STS) and Eclipse projects. STS uses Maven as its dependency manager. If you are comfortable with Maven, STS is probably your best bet. If not, you can still use your beloved Eclipse to test the apps.

To test a project, open Eclipse or STS and import the project (File > Import > Existing Projects into Workspace > browse to project directory)

"
andreschaffer/microservices-testing-examples,master,107,36,2016-11-03T17:27:07Z,584,0,Microservices Testing in practice.,consumer-driven-contract-testing contract-testing contract-tests java microservices microservices-testing pact pact-jvm testing,"![Build](https://github.com/andreschaffer/microservices-testing-examples/workflows/Build/badge.svg)
[![Test Coverage](https://api.codeclimate.com/v1/badges/77358dd72d38afa63fce/test_coverage)](https://codeclimate.com/github/andreschaffer/microservices-testing-examples/test_coverage)
[![Maintainability](https://api.codeclimate.com/v1/badges/77358dd72d38afa63fce/maintainability)](https://codeclimate.com/github/andreschaffer/microservices-testing-examples/maintainability)
[![Dependabot](https://img.shields.io/badge/Dependabot-enabled-blue?logo=dependabot)](https://docs.github.com/en/github/administering-a-repository/keeping-your-dependencies-updated-automatically)

# Microservices Testing Examples

# Strategy
When it comes to testing microservices, usually there are two alternatives:  
a) Deploy all of them and test them in an end-to-end fashion  
b) Mock external dependencies in unit / integration tests

The problem with alternative _a_ is that it doesn't scale. It gets only harder to maintain the tests as the system evolves and new microservices arise.  
The problem with alternative _b_ is that the mocks might not behave the same way as the real dependencies, 
and thus we might miss integration problems.

So, how to proceed? Glad you asked.  
This project will focus on [Consumer-Driven Contract Testing](http://martinfowler.com/articles/consumerDrivenContracts.html) to overcome those limitations. 
It is a technique based on mocks, so that we benefit from fast feedback and no scalability issues, and attacks
the problem of potential incompatible behavior by recording the interactions with the mocks 
and then allowing the real services to test that they behave the same way the mock did instead.

Some of the tools that support Consumer-Driven Contract Testing are:
[Pact](https://docs.pact.io/),
[Pacto](http://thoughtworks.github.io/pacto/)
and [Spring Cloud Contract](https://cloud.spring.io/spring-cloud-contract/spring-cloud-contract.html).
This project will use Pact.

# Microservices
The microservices involved in this project are:  
- The special-membership-service, that manages members of a special membership;  
- The credit-score-service, that holds information about individuals credit scores;  
- The welcome-member-email-service, that contacts new members with a welcome email.

The system flow is very simple: 
a special membership request comes at the special-membership-service that in turn 
looks up the individual credit score at the credit-score-service 
and then decides whether it should create the membership or not. 
As a result of a new membership, the special-membership-service publishes a corresponding event that is picked by
the welcome-member-email-service that then contacts the new member with a warm welcome.

# Pact Broker
While testing, the way we'll make the interactions records (called pacts from now on) available to the real services 
is through a pact broker. We can run it with [Docker Compose](https://docs.docker.com/compose/) and access it on a browser [(http://localhost:9292)](http://localhost:9292).

```bash
docker-compose -f pact-tools/pact-broker/docker-compose.yml up -d
```
  
We will also use the [pact-cli](https://hub.docker.com/r/pactfoundation/pact-cli) tool to interact with the broker.

# Running the tests
We can run all the flows with [Maven](https://maven.apache.org/) and the pact cli like this:

For the welcome-member-email-service, we build it, create its pacts, publish and tag them:
```bash
mvn clean verify -pl welcome-member-email-service
mvn verify -pl welcome-member-email-service -Pconsumer-pacts
docker run --rm --net host -v `pwd`/welcome-member-email-service/target/pacts:/target/pacts pactfoundation/pact-cli:0.12.3.0 publish /target/pacts --consumer-app-version `git rev-parse --short HEAD` --tag prod --broker-base-url localhost:9292 --broker-username=rw_user --broker-password=rw_pass
```
  
For the special-membership-service, we build it, verify consumers' pacts, create its own pacts, publish and tag both the verification and the pacts created:
```bash
mvn clean verify -pl special-membership-service
mvn verify -pl special-membership-service -Pprovider-pacts -Dpact.verifier.publishResults=true -Dpact.provider.version=`git rev-parse --short HEAD` -Dpactbroker.tags=prod -Dpactbroker.user=rw_user -Dpactbroker.pass=rw_pass
mvn verify -pl special-membership-service -Pconsumer-pacts
docker run --rm --net host -v `pwd`/special-membership-service/target/pacts:/target/pacts pactfoundation/pact-cli:0.12.3.0 publish /target/pacts --consumer-app-version `git rev-parse --short HEAD` --tag prod --broker-base-url localhost:9292 --broker-username=rw_user --broker-password=rw_pass
```
  
For the credit-score-service, we build it, verify consumers' pacts and tag the verification:
```bash
mvn clean verify -pl credit-score-service
mvn verify -pl credit-score-service -Pprovider-pacts -Dpact.verifier.publishResults=true -Dpact.provider.version=`git rev-parse --short HEAD` -Dpactbroker.tags=prod -Dpactbroker.user=rw_user -Dpactbroker.pass=rw_pass
docker run --rm --net host pactfoundation/pact-cli:0.12.3.0 broker create-version-tag --pacticipant credit-score-service --version `git rev-parse --short HEAD` --tag prod --broker-base-url localhost:9292 --broker-username=rw_user --broker-password=rw_pass
```

## Test separation
We created two auxiliary maven profiles to hold control of creating the pacts (consumer-pacts) 
and verifying the pacts (provider-pacts).  

We separate the pact tests from the other tests. Pact tests are focused on the contracts and shouldn't be abused, 
otherwise we'll give the providers a hard time verifying an explosion of interactions.  

We have many integration tests with regular mocks for the expected behavior of our services in different scenarios
and a few pact tests in their own package (\*.pacts). In each pact test we focus on one provider integration contract at a time, 
specifying only the properties that we need and using appropriate matchers. (Side note: since it's a point-to-point integration we are talking about, 
we could use pact with unit tests - important to make sure the client used is the same one the service uses. We opted for 
slim integration tests instead since the services are very small anyway).  

The pact verification tests also have their own package (\*.pacts.verifications). Here we need to be able to setup the different states the consumers specify in their interactions 
and it becomes more evident that we shouldn't abuse pact in order to avoid unnecessary verifications at this point. (Side note: the class names are following a different pattern (\*PactVerifications) 
that is aligned with the maven profile (provider-pacts) just so we get a better control of when to run them - similar control could be achieved with jUnit categories as well).  

Now it's time for you to go ahead and take a look at those tests! Try changing a contract and see the tests fail :)

## Dependencies graph
Visit the pact broker page again after running the tests and check the pacts are there together with a cool dependencies graph:  
![alt text](https://github.com/andreschaffer/microservices-testing-examples/blob/master/docs/images/pact_broker_dependencies_graph.png ""Pact broker dependencies graph"")

# Automating it all with pipelines
                                            (Project A pipeline)


    +-------+    +--------------+    +--------------+    +---------------+    +--------+    +-------------+
    |       |    |              |    |              |    |               |    |        |    |  Tag Pacts  |
    | Build | +> | Verify Pacts | +> | Create Pacts | +> | Can I Deploy? | +> | Deploy | +> |     as      |
    |       |    |              |    |              |    |               |    |        |    |    Prod     |
    +-------+    +--------------+    +--------------+    +---------------+    +--------+    +-------------+
                    |                   |                             |                                |
                    |                   |                             |                                |
                    |                   |                             |                                |
                    |                   |  2    +-------------+    5  |                                |
                    |                   +-------+             +-------+                                |
                    |  1                        | Pact Broker |                                     6  |
                    +---------------------------+             +----------------------------------------+
                                                +-------------+
                                                   |       |
                            +----------------------+       +---------------------+
                            |  3                                              4  |
                            |                                                    |
                            |        (Project B Consumers Support Pipeline)      |
                            |                                                    |
                            |                                                    |
                            |    +-----------------------+    +--------------+   |
                            |    |                       |    |              |   |
                            +----+ Checkout Prod Version | +> | Verify Pacts +---+
                                 |                       |    |              |
                                 +-----------------------+    +--------------+


When a change is pushed to Project A repo, its pipeline is triggered:
* **Build:** checkout, package and run the regular unit and integration tests.
* **Verify Pacts:** download its consumers' pacts (tagged as prod) from the pact broker, verify all of them and publish the results to the pact broker.
* **Create Pacts:** create its pacts and publish them to the pact broker.

The pact broker will trigger all provider pipelines that has a contract with Project A as consumer:

* **Checkout Prod Version:** checkout Project B code corresponding to its prod tag.
* **Verify Pacts:** download the pacts that Project A created with B, verify them and publish the results to the pact broker.

Meanwhile, the pipeline of Project A was hanging in the **Can I Deploy?** until the pacts it created were marked as verified in the pact broker and resumes:
* **Deploy:** with confidence that it can interact with its neighbours, we can deploy Project A to production.
* **Tag Pacts as Prod:** tag all its pacts and verifications as prod in the pact broker.

**Disclaimer**: You can see these building blocks in our github actions build file, but the flow there looks a little bit different whereas the support pipelines from the providers are simulated.


# Contributing
If you would like to help making this project better, see the [CONTRIBUTING.md](CONTRIBUTING.md).  

# Maintainers
Send any other comments, flowers and suggestions to [André Schaffer](https://github.com/andreschaffer) and [Dan Eidmark](https://github.com/daneidmark).

# License
This project is distributed under the [MIT License](LICENSE).
"
deftlabs/mongodb-examples,master,52,39,2011-10-18T20:37:42Z,3055,0,,,
ehcache/ehcache3-samples,master,137,89,2016-06-28T17:32:07Z,5681,2,Some examples / tutorials on using Ehcache 3.,,"# Ehcache 3 Samples

This repository contains examples of and tutorials about usage of Ehcache 3.

## Samples

- 'basic' - demonstrates basic configuration and usage of Ehcache 3

- 'clustered' - demonstrates using distributed caching features with Terracotta server

- 'jsr107' - demonstrates configuration through JSR-107 (JCache) 

- 'fullstack' - binding with Spring, Hibernate and Metrics using JSR-107 in a real application

- 'scale-continuum' - live benchmark with different caching options

- 'caching-still-matters' - code examples used for the ""Caching Still Matters"" conference
"
atduskgreg/Making-Things-See-Examples,master,124,43,2011-09-25T21:23:56Z,1147,7,Kinect SimpleOpenNI Processing Examples from Making Things See,,
antlr/examples-v3,master,59,47,2010-01-08T22:12:37Z,2918,0,,,
JosePaumard/jdk8-lambda-tour,master,121,76,2014-02-19T15:45:10Z,3455,1,"Examples of Java 8, lambdas, Streams and Collectors stuff I show as examples during my talks. ",,"This repository contains example files I use in my JDK8 / Lambdas / Streams / 
Collectors talks. 

The data files mcdonalds.csv, movies-mpaa.txt, ospd.txt and 
words.shakespeare.txt can be freely downloaded from Robert Sedgwick page
here: http://introcs.cs.princeton.edu/java/data/. By the way, there are other
very interesting data sets on this page. 

You can find 3 examples here : 
- the Scrabble example, or ""how good at Scrabble Shakespeare would have been?""
- the MacDonald example, or ""Houston, we've got a problem""
- the Movie database example. 

All files are provided under the GPL license. All data sets files are under the
copyright of their authors, and provided for convenience only.

More on ""how good at Scrabble Shakespeare would have been"". I realized that the 
best words are in fact not playable in Scrabble : not enough letters to 
place buzzards and whizzing on a Scrabble board. But there are two blanks 
letters in the Scrabble game. So let's take into account that in fact, buzzards
and whizzing are doable with blank letters, and let's change the computation
of the score to take into account that the blank letters score 0. 

Nice little problem, and it turns out that it is still solvable with a 
map / filter / reduce approach, thus fully lambda based. Great !

More on the Movie database example. 

A nice question I had on this example is : ""and how about the most seen duo
of actors"". This question is pretty straigthforward if your actors are in
a DB with a basic SQL engine. With the Stream API, it's a bit trickier, and
cant be solved using a brute force method, due to the number of cases to 
evaluate. There's no Collector for that, to we have to build our own. And
if we want to go parallel, we need to be careful about using concurrent
structures.   
"
bhdrkn/Java-Examples,master,50,39,2012-04-22T20:13:27Z,219,1,Contains all kind of Java Examples which explained in blog,,"## Java Examples
These are my example project to demonstrate some of the topic which are explained on my personal [blog](http://www.bahadirakin.com).

---

### Projects

* **RestClient**: This is an example project which demonstrates how to use Apache HttpClient to consume Restful web services...[read more](http://www.bahadirakin.com/restful-web-servislerine-baglanmak/)
* **XStreamAnnotation**: This is an example project which demonstrates how to use XStream annotations to achieve object to xml mapping...[read more](http://www.bahadirakin.com/annotation-kullanarak-xstream/)
* **camel-soap**: This is an example project which demonstrates how to use Camel's Soap component... [read more](http://www.bahadirakin.com/camel-soap-ve-nesneler/)
* **camel-xslt**: This is an example project which demonstrates how to use xslt transformation by using Camel...[read more](http://www.bahadirakin.com/apache-camel-ve-xslt/)
* **download-servlet**: This is an example project which demonstrates how to use servlets to download data from servers...[read more](http://www.bahadirakin.com/servlet-yerel-dosya-yayinlama/)
* **jce-encrypt**: This is an example project which demonstrates how to encrypt plain-texts using AES or DES... [read more](http://www.bahadirakin.com/jce-sifrelemeler-ve-hatalar/)
* **rest-tutorial**: This is an example project which demonstrates how to develop restful web services using Jersey and Hibernate...[read more](http://www.bahadirakin.com/restful-web-servisleri-hazirlik/)
* **simple-smpp-routing**: This is an example project which demonstrates how to use camel to route JPA entities to SMPP endpoint. This project can be also used as a template project to create a Bulk-SMS application...[read more](http://www.bahadirakin.com/java-smpp-ve-camel/)
* **spring-cxf**: This is an example project which demonstrates how to develop CXF application which uses Spring...[read more](http://www.bahadirakin.com/spring-ve-cxf-ile-soap-web-servisleri/)
* **spring-jpa**: This is an example project which demonstrates how to develop JPA application which uses Spring. In this application Spring also manages trasnactions which are used by JPA...[read more](http://www.bahadirakin.com/spring-ve-jpa/)
* **spring-prime**: This is an example project which demonstrates how to develop a JSF application which Spring...[read more](http://www.bahadirakin.com/spring-ve-primefaces/)
* **test-with-mockito**: This is an example project which demonstrates how to develop an application by using Mockito...[read more](http://www.bahadirakin.com/mockito-ilk-adimlar/)
* **user-application**: This is an example project which demonstrates how to develop an application which uses, SpringData, SpringMvc, Mockito, Fongo etc. and deploys Heroku...[read more](http://www.bahadirakin.com/sprinmvc-ve-mongodb-1-projenin-hazirlanmasi/)
* **aws-dynamodb-tutorial**: This is an example project wich demonstrates usage of High Level Java-API usage of DynamoDB

---

### Repository Structure
Although i know that this repository structure is not proper, I used this structure to make easier to find other Java Example projects. 
"
arhohuttunen/spring-boot-test-examples,main,111,44,2021-04-03T10:25:51Z,326,0,This is the repository containing examples for my Spring Boot testing tutorial.,junit5 spring-boot,"# Spring Boot Test Examples

![Gradle Build](https://github.com/arhohuttunen/spring-boot-test-examples/workflows/Gradle%20Build/badge.svg)

This is the repository containing examples for my [Spring Boot Testing Tutorial](https://www.arhohuttunen.com/spring-boot-testing-tutorial/).
"
Smerity/cc-warc-examples,master,55,46,2014-03-19T00:22:54Z,31775,4,CommonCrawl WARC/WET/WAT examples and processing code for Java + Hadoop,,"![Common Crawl Logo](http://commoncrawl.org/wp-content/uploads/2012/04/ccLogo.png)

# Common Crawl WARC Examples

This repository contains both wrappers for processing WARC files in Hadoop MapReduce jobs and also Hadoop examples to get you started.

There are three examples for Hadoop processing:

+ [WARC files] HTML tag frequency counter using raw HTTP responses
+ [WAT files] Server response analysis using response metadata
+ [WET files] Classic word count example using extracted text

All three assume initially that the files are stored locally but can be trivially modified to pull them down from Common Crawl's Amazon S3 bucket.
To acquire the files, you can use [S3Cmd](http://s3tools.org/s3cmd) or similar.

    s3cmd get s3://aws-publicdatasets/common-crawl/crawl-data/CC-MAIN-2013-48/segments/1386163035819/warc/CC-MAIN-20131204131715-00000-ip-10-33-133-15.ec2.internal.warc.gz

# License

MIT License, as per `LICENSE`
"
saturnism/istio-by-example-java,master,253,120,2017-06-18T02:38:18Z,175,1,A collection of examples of using Istio with Java applications.,istio java microservice service-mesh spring spring-boot,"This is the source code material for the Istio Codelab.

See [Istio Code Lab](http://bit.ly/istio-lab) for setup instructions.
"
thombergs/buckpal,master,2014,618,2019-05-08T21:29:43Z,528,20,An example approach for implementing a Clean/Hexagonal Architecture,,"# Get Your Hands Dirty on Clean Architecture

This repository implements a small web app in the Hexagonal Architecture style, as discussed in the book ""Get Your Hands Dirty on Clean Architecture"".

The code has been updated to the 2nd edition of the book.

## Get the print book

[![Get Your Hands Dirty on Clean Architecture cover](img/cover-packt-450.png)](https://www.amazon.com/Your-Hands-Dirty-Clean-Architecture/dp/180512837X?keywords=get+your+hands+dirty+on+clean+architecture&amp;qid=1689324075&amp;sprefix=Get+Your+Hands+Dirty+on+Clean+,aps,424&amp;sr=8-2&_encoding=UTF8&tag=reflectorin0c-20&linkCode=ur2&linkId=c04a12e6dd6d399747b0cdce328650a5&camp=1789&creative=9325)

## Get the e-book

This is the self-published version, which is only available electronically.

[![Get Your Hands Dirty on Clean Architecture cover](img/cover-430.png)](https://thombergs.gumroad.com/l/gyhdoca)

## Companion Articles

* [Hexagonal Architecture with Java and Spring](https://reflectoring.io/spring-hexagonal/)
* [Building a Multi-Module Spring Boot Application with Gradle](https://reflectoring.io/spring-boot-gradle-multi-module/)

## Prerequisites

* JDK 17
* this project uses Lombok, so enable annotation processing in your IDE

## About the book
### All About Hexagonal Architecture

* Learn the concepts behind ""Clean Architecture"" and ""Hexagonal Architecture"".
* Explore a hands-on approach of implementing a Hexagonal architecture with example code [on GitHub](https://github.com/thombergs/buckpal).
* Develop your domain code independent of database or web concerns.

![Hexagonal Architecture](img/hexagonal-architecture.png)

### Get a Grip on Your Layers

* Learn about potential problems of the common layered architecture style.
* Free your domain layer of oppressive dependencies using dependency inversion.
* Structure your code in an architecturally expressive way.
* Use different methods to enforce architectural boundaries.
* Learn the consequences of shortcuts and when to accept them.
* ... and [more](#table-of-contents).

![Dependencies](img/dependencies.png)

### What Readers Say

> Tom Hombergs has done a terrific job in explaining clean architecture - from concepts to code. Really wish more technical books would be as clear as that one!

Gernot Starke - Fellow at [INNOQ](https://www.innoq.com/en/staff/gernot-starke/), Founder of [arc42](https://arc42.org/), Author of Software Architecture Books, Coach, and Consultant

> Love your book. One of the most practical books on hexagonal architecture I have seen/read so far.

Marten Deinum - Spring Framework Contributor and Author of [""Spring 5 Recipes""](https://www.amazon.com/Spring-5-Recipes-Problem-Solution-Approach/dp/1484227891&tag=reflectorin0c-20) and [""Spring Boot 2 Recipes""](https://www.amazon.com/Spring-Boot-Recipes-Problem-Solution-Approach/dp/1484239628&tag=reflectorin0c-20)

> A book taken right out of the machine room of software development. Tom talks straight from his experience and guides you through the day-to-day trade-offs necessary to deliver clean architecture.

Sebastian Kempken - Software Architect at Adcubum

> Thank you for the great book, it helped me gain significant insight into how one would go about implementing hexagonal and DDD in a modern Spring project.

Spyros Vallianos - Java Developer at Konnekt-able

> After reading it I had one of these 'aha' moments when things finally click in your brain.

Manos Tzagkarakis - Java Developer at Datawise

### Table of Contents

1. Maintainability
2. What's Wrong with Layers?
3. Inverting Dependencies
4. Organizing Code
5. Implementing a Use Case
6. Implementing a Web Adapter
7. Implementing a Persistence Adapter
8. Testing Architecture Elements
9. Mapping Between Boundaries
10. Assembling the Application
11. Taking Shortcuts Consciously
12. Enforcing Architecture Boundaries
13. Managing Multiple Bounded Contexts
14. A Component-Based Approach to Software Architecture
15. Deciding on an Architecture Style
"
jjenkov/java-examples,main,103,27,2021-03-05T11:40:16Z,934,1,A set of Java examples - of Java SE features (core Java) and techniques.,,"# Java Examples
A set of Java examples - of Java SE features (core Java) and techniques. 

The Java examples are related to the Java tutorials at <a href=""https://jenkov.com"">jenkov.com</a> .
Many of these Java examples will be hard to understand without the corresponding tutorial explaining the topic and
the examples.

# Examples Use Latest Version of Java
Since part of the examples in this Git repository are using new Java language features - you should use the 
latest version of Java when trying to run them.


## Java Concurrency Examples

 - [Java Virtual Thread Example](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/virtualthreads/VirtualThreadExample.java)
 - [Java Deadlock](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/deadlock/DeadlockExample.java) 
 - [Java Deadlock Prevention - Timeout Backoff](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/deadlock/prevention/DeadlockTimeoutExample.java)
 - [Java False Sharing Example](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/falsesharing/FalseSharingExample.java)
 - [Java Thread Congestion - Shared BlockingQueue Example](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/threadcongestion/ThreadCongestionExample.java)
 - [Java Thread Congestion - Separate BlockingQueue Example](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/threadcongestion/ThreadCongestionExample2.java)
 - [Java Thread Signaling Example 1](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/threadsignaling/ThreadSignalingExample.java)
 - [Java Thread Signaling Example 2](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/threadsignaling/ThreadSignalingExample2.java)
 - [Java Thread Signaling Example 3](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/threadsignaling/ThreadSignalingExample3.java)
 - [Java Thread Signaling Example 4](https://github.com/jjenkov/java-examples/blob/main/src/main/java/com/jenkov/java/concurrency/threadsignaling/ThreadSignalingExample4.java)


"
ewolff/microservice-kubernetes,master,198,192,2017-03-23T09:25:11Z,134,0,Microservices example using Kubernetes,,"Microservice Kubernetes Sample
=====================

[Deutsche Anleitung zum Starten des Beispiels](WIE-LAUFEN.md)

This sample is like the sample for my Microservices Book
 ([English](http://microservices-book.com/) /
 [German](http://microservices-buch.de/)) that you can find at
 https://github.com/ewolff/microservice .

However, this demo uses [Kubernetes](https://kubernetes.io/) as Docker
environment. Kubernetes also support service discovery and load
balancing. An Apache httpd as a reverse proxy routes the calls to the
services.

This project creates a complete micro service demo system in Docker
containers. The services are implemented in Java using Spring and
Spring Cloud.



It uses three microservices:
- `Order` to process orders.
- `Customer` to handle customer data.
- `Catalog` to handle the items in the catalog.

How to run
---------

See [How to run](HOW-TO-RUN.md).


Apache HTTP Load Balancer
------------------------

Apache HTTP is used to provide the web page of the demo at
port 8080. It also forwards HTTP requests to the microservices. This
is not really necessary as each service has its own port on the
Minikube host but it provides a single point of entry for the whole system.
Apache HTTP is configured as a reverse proxy for this.
Load balancing is left to Kubernetes.

To configure this Apache HTTP needs to get all registered services from
Kubernetes. It just uses DNS for that.

Please refer to the subdirectory [microservice-kubernetes-demo/apache](microservice-kubernetes-demo/apache/) to see how this works.


Remarks on the Code
-------------------

The microservices are:

- [microservice-kubernetes-demo-catalog](microservice-kubernetes-demo/microservice-kubernetes-demo-catalog) is the application to take care of items.
- [microservice-kubernetes-demo-customer](microservice-kubernetes-demo/microservice-kubernetes-demo-customer) is responsible for customers.
- [microservice-kubernetes-demo-order](microservice-kubernetes-demo/microservice-kubernetes-demo-order) does order processing. It uses
  microservice-kubernetes-demo-catalog and microservice-kubernetes-demo-customer.

The microservices use REST to communicate to each other.
See e.g. [CatalogClient](microservice-kubernetes-demo/microservice-kubernetes-demo-order/src/main/java/com/ewolff/microservice/order/clients/CatalogClient.java) .
The hostname is configurable to allow tests with stubs.
The default is `catalog` which works with Kubernetes.
Other microservices are found using Kubernetes built-in DNS.
Kubernetes does the load balancing on the IP level.

The microservices have a Java main application in `src/test/java` to
run them stand alone. `microservice-demo-order` uses a stub for the
other services then. Also there are tests that use _consumer-driven
contracts_. That is why it is ensured that the services provide the
correct interface. These CDC tests are used in microservice-demo-order
to verify the stubs. In `microservice-kubernetes-demo-customer` and
`microserivce-kubernetes-demo-catalog` they are used to verify the implemented
REST services.

Note that the code has no dependencies on Kubernetes.
"
ftomassetti/analyze-java-code-examples,master,97,45,2016-02-09T09:21:58Z,612,4,Some examples of code extracting information from Java source files using JavaParser,,"# analyze-java-code-examples
Some examples of code extracting information from Java source files using JavaParser

Read an explanation in this article: [http://tomassetti.me/getting-started-with-javaparser-analyzing-java-code-programmatically/](http://tomassetti.me/getting-started-with-javaparser-analyzing-java-code-programmatically/)
"
aspose-cells/Aspose.Cells-for-Java,master,143,99,2011-11-25T13:16:33Z,187663,19,"Aspose.Cells for Java examples, plugins and showcases",,"![GitHub release (latest by date)](https://img.shields.io/github/v/release/aspose-cells-cloud/aspose-cells-cloud-java) ![GitHub all releases](https://img.shields.io/github/downloads/aspose-cells/Aspose.cells-for-Java/total) ![GitHub](https://img.shields.io/github/license/aspose-cells/Aspose.cells-for-java)
# Java API for Excel File Formats

[Aspose.Cells for Java](https://products.aspose.com/cells/java) is an award-winning Excel Spreadsheet Processing API that allows Java developers to embed the ability to read, write and manipulate Excel® spreadsheets (XLS, XLSX, XLSM, XLSB, XLTX, SpreadsheetML, CSV, ODS), HTML, MHTML, PDF, and image file formats into their own Java applications without needing to rely on Microsoft Excel®.

Directory | Description
--------- | -----------
[Examples](https://github.com/aspose-cells/Aspose.Cells-for-Java/tree/master/Examples) | A collection of Java examples that help you learn the product features.
[Examples.GridWeb](https://github.com/aspose-cells/Aspose.Cells-for-Java/tree/master/Examples.GridWeb) | A collection of Java examples that help you learn and explore Aspose.GridWeb features.
[Plugins](https://github.com/aspose-cells/Aspose.Cells-for-Java/tree/master/Plugins) | Plugins that will demonstrate one or more features of Aspose.Cells for Java.

<p align=""center"">
  <a title=""Download ZIP"" href=""https://github.com/aspose-cells/Aspose.Cells-for-Java/archive/master.zip"">
    <img src=""https://raw.githubusercontent.com/AsposeExamples/java-examples-dashboard/master/images/downloadZip-Button-Large.png"" alt=""Download Aspose.Cells for Java Examples, Plugins and Showcases"" />
  </a>
</p>

## Excel File Processing Features

### Document Features

- Open Plain or Encrypted Excel files (Excel97, Excel2007/2010/2013) from different sources.
- Save Excel files (Excel97- Excel2007/2010/2013) in various supported formats.
- Convert Excel files & spreadsheets to various supported formats.
- Convert to Tagged Image File Format (`TIFF`).
- Read and Write OpenDocument Spreadsheet (`ODS`) format.
- Modify the document properties of Excel files.

### Worksheet Features

- Make Worksheet visible or hidden.
- Ability to show or hide worksheet tabs, scroll bars, gridlines & headers.
- Apply worksheet zoom level.
- Keep the selected data visible while scrolling in freeze panes.
- Ability to preview worksheet page breaks.
- Protection support for worksheet content, objects as well as scenarios.
- Perform and apply page setup configuration to worksheets.
- Perform various actions on individual or group of rows and columns.

### Data Management Features

- Insert data in specific cells at runtime.
- Fetch data from various data soures and import into worksheets.
- Retrieve data from cells based on their datatype.
- Get data from worksheet cells and export to array.
- Apply conditional formatting.
- Perform numerous formatting actions on data, such as, font setting.

### Charting & Graphics Features

- Supports creating various kinds of charts.
- Add custom charts to the worksheet.
- Add pictures to worksheets at the runtime.
- Ability to print worksheets.

### Advanced Features

- Use robust Formula Calculation Engine to support formula calculation.
- Manipulate VBA code or Macros.
- Create pivot tables as well as change its source data at runtime.

## Read & Write Spreadsheet Formats

**Microsoft Excel:** XLS, XLSX, XLSB, XLT, XLTX, XLTM, XLSM, XML\
**OpenOffice:** ODS\
**Text:** CSV, TSV\
**Web:** HTML, MHTML\
**Numbers:** Apple's iWork office suite Numbers app documents

## Save Excel Files As

**Fixed Layout:** PDF, PDF/A, XPS\
**Data Interchange:** DIF\
**Images:** JPEG, PNG, BMP, SVG, TIFF, EMF, GIF

## Supported Environments

- **Microsoft Windows:** Windows Desktop & Server (x86, x64)
- **macOS:** Mac OS X
- **Linux:** Ubuntu, OpenSUSE, CentOS, and others
- **Java Versions:** `J2SE 7.0 (1.7)`, or above

## Get Started with Aspose.Cells for Java

Aspose hosts all Java APIs at the [Aspose Repository](https://repository.aspose.com/webapp/#/artifacts/browse/tree/General/repo/com/aspose/aspose-cells). You can easily use Aspose.Cells for Java API directly in your Maven projects with simple configurations. For the detailed instructions please visit [Installing Aspose.Cells for Java from Maven Repository](https://docs.aspose.com/cells/java/installation/) documentation page.

## Convert Table to Range with Options using Java

```java
// For complete examples and data files, please go to https://github.com/aspose-cells/Aspose.Cells-for-Java
// The path to the documents directory.
String dataDir = Utils.getSharedDataDir(ConvertTableToRangeWithOptions.class) + ""Tables/"";
// Open an existing file that contains a table/list object in it
Workbook workbook = new Workbook(dataDir + ""book1.xlsx"");

TableToRangeOptions options = new TableToRangeOptions();
options.setLastRow(5);

// Convert the first table/list object (from the first worksheet) to normal range
workbook.getWorksheets().get(0).getListObjects().get(0).convertToRange(options);

// Save the file
workbook.save(dataDir + ""ConvertTableToRangeWithOptions_out.xlsx"");
```

[Home](https://www.aspose.com/) | [Product Page](https://products.aspose.com/cells/java) | [Docs](https://docs.aspose.com/cells/java/) | [Demos](https://products.aspose.app/cells/family) | [API Reference](https://apireference.aspose.com/cells/java) | [Examples](https://github.com/aspose-cells/Aspose.Cells-for-Java) | [Blog](https://blog.aspose.com/category/cells/) | [Search](https://search.aspose.com/) | [Free Support](https://forum.aspose.com/c/cells) | [Temporary License](https://purchase.aspose.com/temporary-license)
"
Frameworkium/frameworkium-examples,master,51,36,2015-08-14T11:07:12Z,836,7,"Sample project which utilises frameworkium-core, a framework for writing maintainable Selenium and REST API tests and facilitates reporting and integration to JIRA.",allure frameworkium selenium selenium-webdriver,"# Frameworkium Examples 
![build](https://github.com/frameworkium/frameworkium-examples/workflows/frameworkium-examples%20build/badge.svg)

This is a *sample project* which utilises [frameworkium-core][frameworkium-core], 
a framework for writing maintainable Selenium and REST API tests that also makes 
integrating with other test things (e.g. JIRA) much easier.

Please see the [Frameworkium usage guide][guidance] for more details.

As a result:
* Please [raise issues][core-issues] against the [frameworkium-core][frameworkium-core] project, not this one
* See the [frameworkium-core releases page][core-releases] for information about changes and new features
* This example project is not updated as regularly as the [core project][frameworkium-core]
* To keep up to date with the latest releases of core, modify the following block in the `pom.xml`:
```xml
<dependencies>
  <dependency>
    <groupId>com.github.frameworkium</groupId>
    <artifactId>frameworkium-core</artifactId>
    <!-- Update this with the latest from the frameworkium-core releases page -->
    <version>3.0.0</version>
  </dependency>
</dependencies>
```

The Frameworkium project is based on Ardesco's [Selenium-Maven-Template][ardesco] and 
Joe VDW's [Bootstrapium][bootstrapium]. We have extended it with some handy extras
for getting started quickly with Selenium, Appium and [Rest Assured][rest-assured].

## Getting Started

After setting up [apache maven][mvn], open the `frameworkium-examples` directory in a 
terminal/command prompt and run `mvn clean verify` to run the example tests using Firefox.

You will need the [geckodriver][geckodriver] on your path if you are using 
Firefox version 48 or above.

### Browsers

You can provide the `-Dbrowser` argument to chose a browser to run the tests in.

#### Drivers

Each browser requires a ""driver"".

For chrome, [ChromeDriver][chromedriver] needs to be on your path or specified
as an argument:
```
mvn clean verify -Dbrowser=chrome -Dwebdriver.chrome.driver=c:\path\to\chromedriver.exe
```

For Firefox 48 and above, [geckodriver][geckodriver] needs to be on your path or specified
as an argument:
```
mvn clean verify -Dbrowser=firefox -Dwebdriver.gecko.driver=c:\path\to\geckodriver.exe
```

### Selenium Grid

Want to run tests using a grid and in parallel?
```
mvn clean verify -Dbrowser=chrome -DgridURL=http://localhost:4444/wd/hub -Dthreads=4
```

All you need to do is ensure the browser is installed in the default location
and that the driver is on the path.

### Sauce Labs

Running mobile web tests using Appium on Sauce Labs is only slightly more involved:

```bash
export SAUCE_USERNAME=username
export SAUCE_ACCESS_KEY=access_key
mvn clean verify -Dplatform=ios -Dbrowser=safari -Dsauce=true 
```

### BrowserStack

Running mobile web tests using Appium on BrowserStack:

```bash
export BROWSER_STACK_USERNAME=username
export BROWSER_STACK_ACCESS_KEY=access_key
mvn clean verify -Dplatform=ios -Dbrowser=safari -DbrowserStack=true 
```

A full list of arguments can be found on the [guidance page][guidance].

### Reporting

After running your tests, you can generate an [Allure][allure] test report by 
simply running:

```
mvn allure:report 
```

## Further Information

Frameworkium sets you up for other stuff too - check out the
[guidance page][guidance] for further info.

[status-svg]: https://travis-ci.org/Frameworkium/frameworkium-examples.svg?branch=master
[status]: https://travis-ci.org/Frameworkium/frameworkium-examples
[ardesco]: https://github.com/Ardesco/Selenium-Maven-Template
[bootstrapium]: https://github.com/jvanderwee/bootstrapium
[rest-assured]: http://rest-assured.io/
[frameworkium-core]: https://github.com/Frameworkium/frameworkium-core
[core-issues]: https://github.com/Frameworkium/frameworkium-core/issues
[core-releases]: https://github.com/Frameworkium/frameworkium-core/releases
[mvn]: https://maven.apache.org/download.cgi
[geckodriver]: https://github.com/mozilla/geckodriver/releases
[chromedriver]: https://sites.google.com/a/chromium.org/chromedriver/home
[guidance]: https://frameworkium.github.io
[allure]: https://docs.qameta.io/allure/
"
oracle/json-in-db,master,86,50,2014-06-10T01:37:36Z,83538,2,Oracle Database JSON Examples,json oracle-database,"
# Oracle Database JSON Examples

* [JdbcExamples](JdbcExamples) - a collection of small
  examples that show how to work with JSON type column values in JDBC
  21c+
  
* [MongoExamples](MongoExamples) - examples of using the Oracle API for 
  MongoDB from a Java program

* [SodaExamples](SodaExamples) - a collection of small
  examples that show how to work with JSON collections in the Autonomous Database (19c+).

* [MuShop](https://github.com/oracle-quickstart/oci-cloudnative/tree/master/src/carts) - a cloud-native microservice written in Java.  The service stores shopping cart data in the autonomous database using JSON collections (SODA).

* [MuSprint](MuSprint) - a web application designed to track sprint user stories on a story board. Stories are organized into 'To Do', 'In Progress' or 'Completed' category.  The application is built using the SERN stack (SODA, Express.js, React.js, Node.js).

* [WineDemo](WineDemo) - a web application written in
  JavaScript/Node.js that uses JSON collections (SODA) to store wine
  collection data.

* [SODA Lab](https://dmcghan.github.io/soda-hol/?page=README.md) - a
  lab on using SODA Node.js in the autonomous database.

* [Microservices With Node &
  SODA](https://blogs.oracle.com/developers/creating-a-microservice-with-node-soda-json-document-storage-in-autonomous-db) - Step-by-step instructions on creating a microservice using Node.js
  and SODA in the autonomous database.

* [Python and AJD](https://cool.devo.build/tutorials/lol-optimizer-using-oci-extraction-processing) - This article shows how to process JSON data from Riot Games API using python and the Autonomous JSON Database. 

## Contributing

This project welcomes contributions from the community. Before submitting a pull request, please [review our contribution guide](./CONTRIBUTING.md)

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process

## License

Copyright (c) 2014, 2023 Oracle and/or its affiliates.

Released under the MIT License
"
mercyblitz/thinking-in-spring-boot-samples,master,1895,794,2018-11-22T13:34:21Z,350,21,小马哥书籍《Spring Boot 编程思想》示例工程,book code-project examples java mercyblitz samples spring spring-boot thinking-in-spring-boot,"# 《Spring Boot 编程思想》

> 谨以此书纪念已故外婆 - 解厚群

本书全名为《Spring Boot 编程思想》，是以 Spring Boot 2.0 为讨论的主线，讨论的范围将涵盖 Spring Boot 1.x 的所有版本，以及所关联的 Spring Framework 版本，致力于：

- 场景分析：掌握技术选型
- 系统学习：拒绝浅尝辄止
- 重视规范：了解发展趋势
- 源码解读：理解设计思想
- 实战演练：巩固学习成果




## 自序

- [《核心篇》](https://mercyblitz.github.io/books/thinking-in-spring-boot/core/preface/)（[预售中…](https://item.jd.com/12570242.html)）
- 《运维篇》（即将完稿…)
- 《Web 篇》(编写中…)




## 扉页

- [内容总览](https://mercyblitz.github.io/books/thinking-in-spring-boot/overview/)
- [版本范围](https://mercyblitz.github.io/books/thinking-in-spring-boot/version/)
- [相关约定](https://mercyblitz.github.io/books/thinking-in-spring-boot/conventions/)
- [配套视频](https://mercyblitz.github.io/books/thinking-in-spring-boot/videos/)
- [示例工程](https://mercyblitz.github.io/books/thinking-in-spring-boot/samples/)
- [勘误汇总](https://mercyblitz.github.io/books/thinking-in-spring-boot/revision/)
- [公益资金流向](https://mercyblitz.github.io/books/thinking-in-spring-boot/donate/)




## [关于我](https://mercyblitz.github.io/books/thinking-in-spring-boot/about/)

“我是谁？”，是个不错的哲学问题。

在江湖上，大家亲切地称我 “小马哥“，我做公益，也做生意；在社区中，我又以 `mercyblitz` 的身份出没在众多开源项目，""mercy"" 符合我的性格，""blitz"" 说明我的风格。

承蒙错爱，不少的朋友对我过去的分享称赞有加，然而“千人之诺诺，不如一士之谔谔”，时常又让自己陷入一种迷思，到底是平台的帮衬，还是个人的确禁得起考验。于是我选择隐匿真名，希望能够听到更为真实的声音。尽管在互联网时代，只要稍作功课，个人信息几乎无处遁形。无可讳言，本人的所属公司以及职业头衔必然会形成“舞台效应”，如此一来，不但违背了写书的初衷，而且模糊了讨论的焦点。所以，本书即不会出现这些信息，又不会搞“个人崇拜”。它的价值应该体现在知识的传播，至于它的优劣则由诸君来评判。




## 交流社区

- 微信公众号：次灵均阁
  
![微信公众号二维码](https://mercyblitz.github.io/books/thinking-in-spring-boot/assets/my_mp_qrcode.jpg)

- [知识星球](https://t.zsxq.com/72rj2rr)：
  
![小马哥 Java 星球](https://mercyblitz.github.io/books/thinking-in-spring-boot/assets/my_java_planet.png)

- [Github](http://github.com/mercyblitz)：[http://github.com/mercyblitz](http://github.com/mercyblitz)

> 更多个人信息，请使用 [Google 搜索 `mercyblitz`](https://www.google.com/search?q=mercyblitz)
"
inazaruk/examples,master,36,9,2011-05-26T23:08:54Z,3520,0,Collection of examples for demo purposes,,
peterarsentev/games_oop_javafx,master,205,1224,2018-04-25T15:32:53Z,226,0,"This project demonstrates how to use Java Fx in OOP Style. All examples are popular games. (Chess, TicTacToe, SeeBattle and etc)",,"This project demonstrates how to use Java Fx in OOP Style. 
All examples are popular games. (Snake, Chess, TicTacToe, SeeBattle and etc)

If you have any suggestions about this project, please, creating a new GitHub issue https://github.com/peterarsentev/games_oop_javafx/issues


## Snake

![ScreenShot](images/Snake.png)

## TicTacToe

![ScreenShot](images/TicTacToe.png)

## Chess

![ScreenShot](images/Chess.png)

## TODO

- SeaBattle
- PackMan
- Tetris
"
FrontierPsychiatrist/spring-oauth-example,master,139,73,2014-06-28T12:32:50Z,272,3,Example Spring Boot examples for a separated OAuth authentication and resource server,,"Spring Boot OAuth Authorization & Resource server
=================================================
I present to you an example on how to use Spring Boot together with Spring Security OAuth2 to implement an authorization server and
a resource server.

Also included are some example client applications for the resource server.

It's a pretty modern application, using Spring Boot, gradle, thymeleaf and only JavaConfig. In my opinion it's also a good example of how Java applications
aren't big bloated ""enterprisy"" things anymore. The current sloccount is 519. 178 of that are just the SQLite dialect for hibernate which
I had to include because it's not in the official packages.

Just tell me how to run it
--------------------------
* Clone the repository
* If you have gradle installed, run

        gradle build
    
    in the main directory. Otherwise run

        ./gradlew build
        
    It will download a local gradle. On Windows use `gradlew.bat`.
* Start the authorization server with

        java -jar oauth-server/build/libs/oauth-server.jar
        
    And the resource server with
  
        java -jar resource-server/build/libs/resource-server.jar
        
    The authorization server runs under [http://localhost:8081](http://localhost:8081) and the resource server under
    [http://localhost:8080](http://localhost:8080).
* Additionally you can start a http server in example-clients/html, e.g. like this

        cd example-clients/html/read-only
        ruby -run -e httpd . -p 9090
        
    It will be reachable under [http://localhost:9090](http://localhost:9090).
  
Starting from within a IDE
--------------------------
If you want to play around with the java code it's more practicable to start from within your IDE. Just run either `OAuthServerMain` or
`ResourceServerMain`. The working directory to execute in should be the directory in which you cloned into because the database files are
expected there.

What to do when it is running?
------------------------------
The OAuth server is fairly self explanatory. Just open [http://localhost:8081](http://localhost:8081) in a browser. You can login as
* an OAuth admin to administrate clients
* an resource admin or normal user to see what clients you have granted access.
The login credentials should be displayed on the login page.

The URL to get a new access token for a client is

    http://localhost:8081/oauth/authorize?client_id=$client_id&return_type=token&redirect_uri=some_uri
    
If the call to this URL is valid and you are logged in it will redirect to `some_uri` with an access token attached to the location hash. If
you want to call this with cURL you have to set the cookie header to include the session id.

    curl .../oauth/authorize?... -H ""Cookie: JSESSIONID=...""
    
which you can find in your browser development console.

The resource server exposes a (very simple) REST API. You can use the example clients to access them or cURL after receiving an access token.

    curl -v localhost:8080/todos -H ""Authorization: Bearer $token""
    curl -v localhost:8080/todos/1 -H ""Authorization: Bearer $token""
    curl -v -X DELETE localhost:8080/todos/1 -H ""Authorization: Bearer $token""
    curl -v -X POST localhost:8080/tokens localhost:8080/todos/1 -H ""Authorization: Bearer $token"" -d ""{ \""message\"": \""Do stuff\"", \""done\"": false }""
    
Why?
----
I wrote this because I had to get into OAuth with Spring and found it actually quite hard to find good examples and documentation. I hope
others can learn from this.

Caveats & Disclaimer
--------------------
I am not a security expert, far from it. I implemented this with my best knowledge on OAuth and Spring Security but I take no guarantee
that it is usable in a productive application.

I used sqlite for the database because most people will have sqlite on their system and can easily look into the database like this.

It goes without saying that in any production environment all HTTP traffic must be HTTPS, otherwise your tokens and client secrets are sniffable.

License
-------
See LICENSE.txt
"
mp911de/CleanArchitecture,main,228,71,2013-08-01T07:49:59Z,160,3,CleanArchitecture Example,architecture cleanarchitecture hexagonal java onion-architecture,"Sampler for Clean Architecture/Onion-Architecture [![Build Status](https://snap-ci.com/mp911de/CleanArchitecture/branch/master/build_image)](https://snap-ci.com/mp911de/CleanArchitecture/branch/master)
========================
Author: Mark Paluch<br/>
Technologies: CDI, JSF, JPA, EJB, JPA, JAX-RS<br/>
Summary: Example Application built using an Onion-Architecture that incorporates multiple technologies<br/>
Source: <https://github.com/mp911de/CleanArchitecture><br/>

More Information: <br/>
* https://www.paluch.biz/blog/80-clean-your-architecture-databases-the-web-and-service-interfaces-are-just-plugins.html
* https://www.paluch.biz/blog/83-clean-architecture-code-examples-for-an-onion-architecture.html

What is it?
-----------
This simple application consists of a few use cases. The purpose of the application is to show how to
apply clean architecture patterns in a Multi-Module Maven/Java environment.

It all starts with the data structures/entities/application model. These models are independent of business logic and delivery mechanisms. The models are specific to your domain, but not necessary specific to your application. They live within the `application-model` module. Business rules and use cases, the specific things your application does, reside within the `use-cases` module. They depend on the `application-model` and perhaps on external things that are represented by boundaries, located in `contracts`. Those boundaries are an agreement between the use case and the other side that provides a specific implementation. The `contracts` depend only on the `application-model`. No ORM entities or external-specific API/entities.
ORM, caching implementations, clients to external services implement a contract that is located in `external` and its sub-modules.

All parts are tied together by the delivery mechanism that
integrates the externals and connects the use cases by supplying dependencies to come the system to life.

If you need a different implementation for any external, so you can easily change that specific part without
affecting other parts of the system.

These patterns are verified by real life projects.

A word on Clean Architecture
----------------------------

As soon as you dig into the code, you'll notice comments on the one or other class. Subject of these comments is to help
to understand the structure and the different styles, which are possible.

You'll notice soon, there are many different styles and ways to approach the Clean Architecture style. There are use cases
which are built much more simple, e. g. without input/output boundaries and direct usage of dependency injection and
there are use-cases which implement input boundaries and use output boundaries. 

In the end it's up to you, how much you're willing to invest in your architecture. This is, however, only a variety of
examples to give you an impression, how to express Clean Architecture with Java.


What does it?
---------
The use cases are:

* CreateOrUpdateItem
* CreateOrUpdateUser
* ListItems
* ListOrders
* PlaceOrder
* PlaceOrderValidator

and a few business entities:

* User
* OrderItem
* Order
* Item

These use cases can be accessed by REST or Web UI (JSF) and are persisted using JPA within an in-memory H2 Database
(everything you need is included).

Requirements to run the App
-------------------

All you need to build this project is Java 6.0 (Java SDK 1.6) or better, Maven 3.0 or better.

The application this project produces is designed to be run on JBoss AS7, WildFly 8 or better.
You could easily change the delivery mechanism to a console application with only providing a new delivery mechanism
and a different approach how to wire the dependencies.


Build and Deploy the Quickstart
-------------------------

_NOTE: The following build command assumes you have configured your Maven user settings. If you have not, you must include Maven setting arguments on the command line._

1. Open a command line and navigate to the root directory of this project.
2. Type this command to build and deploy the archive:

        mvn clean package wildfly:run

3. This will start a WildFly 10 instance and deploy `target/clean-architecture.war` to the newly started instance.
 

Access the application 
-------------------------

The application will be running at the following URL: <http://localhost:8080/clean-architecture/>.

"
halzhang/EverExample,master,80,110,2013-01-30T03:35:23Z,11691,0,example code,,"EverExample
===
Android开发一些代码示例，或许挺有用的！

##### GestureExample
手势操作示例

##### 

Author
===
[HalZhang](http://weibo.com/halzhang) 



"
jboss-developer/jboss-jdg-quickstarts,jdg-7.3.x,67,101,2011-11-24T09:55:32Z,6182,15,"Quickstarts (or examples, or samples) for Infinispan.",,"[![Build Status](https://travis-ci.org/jboss-developer/jboss-jdg-quickstarts.svg?branch=jdg-7.3.x)](https://travis-ci.org/jboss-developer/jboss-jdg-quickstarts)

Red Hat Data Grid Quickstarts
=============================

Red Hat Data Grid (RHDG) is an elastically scalable in-memory data store built on the open source Infinispan project.

## RHDG Modes
You can use Red Hat Data Grid in two modes:

* _Library Mode_ provides binaries to build and deploy custom runtime environments. RHDG runs alongside your application in the same JVM. Your application has local access to a single node in a distributed cluster.

* _Remote Client-Server Mode_ provides a self-contained process in a container based on JBoss EAP. RHDG runs remotely and provides access to data through `Hot Rod`, `REST`, or `Memcached` interfaces.

## About the Quickstarts
These quickstarts demonstrate Red Hat Data Grid features and capabilities with specific, working examples that you can reference in your own projects.

If you are using _Remote Client-Server Mode_, you should start with the **helloworld-jdg** quickstart to ensure that your server configuration is valid and you can start it successfully.

Quickstarts have **Beginner**, **Intermediate**, and **Advanced** levels. You should start with a level that is comfortable for you and move on to the next level as you gain expertise.

Some quickstarts are prerequisites for others that expand on certain capabilities or functionality. You should always deploy and run any prerequisite quickstarts first.

## Available Quickstarts
This distribution contains the following quickstarts:

| **Quickstart Name** | **Demonstrated Technologies** | **Shows you how to...** |
|:-----------|:-----------|:-----------|
| [carmart](carmart/README.md) | Data Grid, CDI | Use Data Grid instead of a relational database. |
| [carmart-tx](carmart-tx/README.md) | Data Grid, CDI, Transactions | Use Data Grid instead of a relational database with transactions enabled.|
| [eap-cluster-app](eap-cluster-app/README.md) | Data Grid, CDI, EJB | Access an Data Grid cache from a JBoss EAP application using JDG modules for EAP.|
| [helloworld-jdg](helloworld-jdg/README.md) | Data Grid, CDI | Use Data Grid in clustered mode with expiration.|
| [hotrod-endpoint](hotrod-endpoint/README.md) | Data Grid, Hot Rod | Access Data Grid remotely through the Hot Rod protocol. |
| [hotrod-secured](hotrod-secured/README.md) | Data Grid, Hot Rod | Securely access Data Grid remotely through the Hot Rod protocol. |
| [memcached-endpoint](memcached-endpoint/README.md) | Data Grid, Memcached | Access Data Grid remotely through the Memcached protocol. |
| [openshift](openshift/README.md) | Data Grid, OpenShift | Complete tutorials for Data Grid on OpenShift that range from simple ""Hello World"" demonstrations to more advanced use cases. |
| [rapid-stock-market](rapid-stock-market/README.md) | Data Grid, Hot Rod, REST | Use compatibility mode to access data with multiple protocols. |
| [spring 4](spring4/README.md) | Data Grid, Spring | Use Spring 4 integration modules. |
| [spring 5](spring5/README.md) | Data Grid, Spring | Use Spring 5 integration modules. |
| [spring 4 session](spring4-session/README.md) | Data Grid, Spring Boot, Spring Session | Use of Spring Boot and Spring Session with RHDG. |
| [spring 5 session](spring5-session/README.md) | Data Grid, Spring Boot, Spring Session | Use of Spring Boot and Spring Session with RHDG. |
| [remote-query](remote-query/README.md) | Data Grid, Hot Rod, Remote Query | Query Data Grid remotely through the Hot Rod protocol. |
| [rest-endpoint](rest-endpoint/README.md) | Data Grid, REST | Access Data Grid remotely through the REST protocol. |
| [secure-embedded-cache](secure-embedded-cache/README.md) | Data Grid, CDI, REST | Secure Data Grid in Library (embedded) mode. |
| [cdi](cdi-jdg/README.md) | Data Grid, CDI | Use Data Grid CDI and JCache extensions. |
| [camel-jbossdatagrid-fuse](camel-jbossdatagrid-fuse/README.md) | Camel, Data Grid, REST | Use the Camel component camel-jbossdatagrid in JBoss Fuse. |
| [spark](spark/README.md) | Data Grid, Apache Spark | Read and write data to Data Grid and use streaming to react to data changes in real time. |

## System Requirements
You need the following to build and run the quickstarts:

* Java 8.0 (Java SDK 1.8) or later.
* Maven 3.0 or later. See the [Maven Getting Started Guide](http://maven.apache.org/guides/getting-started/index.html).
* JBoss EAP server distribution. Available from the [Red Hat Customer Portal](https://access.redhat.com/downloads).
* RHDG server distribution for _Remote Client-Server Mode_. Available from the [Red Hat Customer Portal](https://access.redhat.com/downloads).

You can also run the quickstarts with [JBoss Developer Studio or Eclipse](https://github.com/jboss-developer/jboss-developer-shared-resources/blob/master/guides/USE_JBDS.md#use-jboss-developer-studio-or-eclipse-to-run-the-quickstarts).

### Configuring Maven

If you have not yet done so, you must [Configure Maven](https://github.com/jboss-developer/jboss-developer-shared-resources/blob/master/guides/CONFIGURE_MAVEN.md#configure-maven-to-build-and-deploy-the-quickstarts).

If you do not configure Maven, you must pass settings with every Maven command as follows: ` -s QUICKSTART_HOME/settings.xml`

### Setting Environment Variables
RHDG quickstarts use the following environment variables:

* `JBOSS_HOME` denotes the path to your RHDG server installation.
* `EAP_HOME` denotes the path to your JBoss EAP installation.

`EAP_HOME` is a *replaceable* value. When you encounter it in a RHDG quickstart, change the value as appropriate.

| Installation method | Installation directory |
|:-----------|:-----------|
| ZIP archive | Custom directory |
| RPM | `/var/lib/jbossas/` |
| Installer | `{USER_HOME}/EAP-6.3.0` |
| JBoss Developer Studio installer | `{USER_HOME}/jbdevstudio/runtimes/jboss-eap` |

Where `{USER_HOME}` is one of the following:

* Linux: `/home/USER_NAME/`
* Windows: `""C:\Users\USER_NAME\""`

## Running the Quickstarts
Refer to the `README` file in each quickstart directory for instructions on building and running the quickstart.

### Building Quickstart Archives
You can build archives without deploying the quickstarts to check for compilation errors and view the contents of the quickstart.

From the root directory of the quickstart, run `$ mvn clean install` to build the archive.

## Contributing the Quickstarts
Refer to [JBoss Developer Contributing Guide](https://github.com/jboss-developer/jboss-developer-shared-resources/blob/master/guides/CONTRIBUTING.md)
"
storm-book/examples-ch02-getting_started,master,67,62,2012-01-07T03:25:51Z,104,5,,,
apache/accumulo-examples,main,34,40,2016-12-06T08:00:06Z,551,6,Apache Accumulo Examples,accumulo big-data hacktoberfest,"<!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the ""License""); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
# Apache Accumulo Examples

[![Build Status][ti]][tl]

## Introduction

The Accumulo-Examples repository contains a collection of examples for Accumulo versions 2.0 and
greater. Examples within the `main` branch are designed to work with the version currently
under development. Additional branches exist for previous releases of the Accumulo 2.x line. For
example, the `2.0` branch contains examples specifically intended to work with that release version.

The [Accumulo Tour] also provides several simple introductory examples that may be of interest.

A collection of examples for Accumulo 1.10 can be found [here].

## Setup instructions

Follow the steps below to run the Accumulo examples:

1. Clone this repository

        git clone https://github.com/apache/accumulo-examples.git

2. Follow [Accumulo's quickstart][quickstart] to install and run an Accumulo instance.
   Accumulo has an [accumulo-client.properties] in `conf/` that must be configured as
   the examples will use this file to connect to your instance.

3. Review [env.sh.example] and [accumulo-env.sh] (within your accumulo installation) to see if you 
   need to customize them. If `ACCUMULO_HOME` & `HADOOP_HOME` are set in your shell, you may be 
   able skip this step. Make sure `ACCUMULO_CLIENT_PROPS` is set to the location of your 
   [accumulo-client.properties].

        cp conf/env.sh.example conf/env.sh
        vim conf/env.sh

4. Build the examples repo and copy the examples jar to Accumulo's `lib/` directory to get on its
   class path:

        ./bin/build
        cp target/accumulo-examples.jar /path/to/accumulo/lib/

5. Each Accumulo example has its own documentation and instructions for running the example which
   are linked to below.

When running the examples, remember the tips below:

* Examples are run using the `runex` or `runmr` commands which are located in the `bin/` directory
  of this repo. The `runex` command is a simple script that use the examples shaded jar to run a
  a class. The `runmr` starts a MapReduce job in YARN.
* Commands intended to be run in bash are prefixed by '$' and should be run from the root of this
  repository.
* Several examples use the `accumulo` and `accumulo-util` commands which are expected to be on your 
  `PATH`. These commands are found in the `bin/` directory of your Accumulo installation.
* Commands intended to be run in the Accumulo shell are prefixed by '>'.

## Available Examples

Each example below highlights a feature of Apache Accumulo.

| Example | Description |
|---------|-------------|
| [batch] | Using the batch writer and batch scanner |
| [bloom] | Creating a bloom filter enabled table to increase query performance |
| [bulkIngest] | Ingesting bulk data using map/reduce jobs on Hadoop |
| [classpath] | Using per-table classpaths |
| [client] | Using table operations, reading and writing data in Java. |
| [combiner] | Using example StatsCombiner to find min, max, sum, and count. |
| [compactionStrategy] | Configuring a compaction strategy |
| [constraints] | Using constraints with tables. Limit the mutation size to avoid running out of memory |
| [deleteKeyValuePair] | Deleting a key/value pair and verifying the deletion in RFile. |
| [dirlist] | Storing filesystem information. |
| [export] | Exporting and importing tables. |
| [filedata] | Storing file data. |
| [filter] | Using the AgeOffFilter to remove records more than 30 seconds old. |
| [helloworld] | Inserting records both inside map/reduce jobs and outside. And reading records between two rows. |
| [isolation] | Using the isolated scanner to ensure partial changes are not seen. |
| [regex] | Using MapReduce and Accumulo to find data using regular expressions. |
| [reservations] | Using conditional mutations to implement simple reservation system. |
| [rgbalancer] | Using a balancer to spread groups of tablets within a table evenly |
| [rowhash] | Using MapReduce to read a table and write to a new column in the same table. |
| [sample] | Building and using sample data in Accumulo. |
| [shard] | Using the intersecting iterator with a term index partitioned by document. |
| [spark] | Using Accumulo as input and output for Apache Spark jobs |
| [tabletofile] | Using MapReduce to read a table and write one of its columns to a file in HDFS. |
| [terasort] | Generating random data and sorting it using Accumulo. |
| [tracing] | Generating trace data in a client application and Accumulo. |
| [uniquecols] | Use MapReduce to count unique columns in Accumulo |
| [visibility] | Using visibilities (or combinations of authorizations). Also shows user permissions. |
| [wordcount] | Use MapReduce and Accumulo to do a word count on text files |

## Release Testing

This repository can be used to test Accumulo release candidates.  See
[docs/release-testing.md](docs/release-testing.md).

[quickstart]: https://accumulo.apache.org/docs/2.x/getting-started/quickstart
[accumulo-client.properties]: https://accumulo.apache.org/docs/2.x/configuration/files#accumulo-clientproperties
[accumulo-env.sh]: https://accumulo.apache.org/docs/2.x/configuration/files#accumulo-envsh
[env.sh.example]: conf/env.sh.example
[manual]: https://accumulo.apache.org/latest/accumulo_user_manual/
[batch]: docs/batch.md
[bloom]: docs/bloom.md
[bulkIngest]: docs/bulkIngest.md
[classpath]: docs/classpath.md
[client]: docs/client.md 
[combiner]: docs/combiner.md
[compactionStrategy]: docs/compactionStrategy.md
[constraints]: docs/constraints.md
[deleteKeyValuePair]: docs/deleteKeyValuePair.md
[dirlist]: docs/dirlist.md
[export]: docs/export.md
[filedata]: docs/filedata.md
[filter]: docs/filter.md
[helloworld]: docs/helloworld.md
[isolation]: docs/isolation.md
[maxmutation]: docs/maxmutation.md
[regex]: docs/regex.md
[reservations]: docs/reservations.md
[rgbalancer]: docs/rgbalancer.md
[rowhash]: docs/rowhash.md
[sample]: docs/sample.md
[shard]: docs/shard.md
[spark]: spark/README.md
[tabletofile]: docs/tabletofile.md
[terasort]: docs/terasort.md
[tracing]: docs/tracing.md
[uniquecols]: docs/uniquecols.md
[visibility]: docs/visibility.md
[wordcount]: docs/wordcount.md
[ti]: https://github.com/apache/accumulo-examples/workflows/QA/badge.svg
[tl]: https://github.com/apache/accumulo-examples/actions
[here]: https://accumulo.apache.org/1.10/examples
[Accumulo Tour]: https://accumulo.apache.org/tour/
"
Qkyrie/modern-java-tutorials,master,207,75,2016-03-11T12:54:11Z,114,0,Tutorials and code examples posted on diplr.org,crpytography java kotlin micronaut quarkus spring,
meteor1993/spring-boot-examples,master,58,40,2019-09-11T08:43:12Z,376,3,本仓库为《Spring Boot 系列文章》代码仓库，欢迎点赞、收藏。,actuator druid hikari jpa mail mybatis mybatis-plus querydsl rabbitmq redis scheduler spring-boot swagger thymeleaf webflux,"本仓库为《跟我学 Spring Cloud 系列文章》 姊妹篇 《Spring Boot 系列文章》代码仓库，欢迎点赞、收藏。更多文章可访问博客站 https://www.geekdigging.com/ 获取。

![](https://img.shields.io/badge/Spring%20Boot-2.1-brightgreen)
![](https://img.shields.io/badge/Mysql-5.7-blue)
![](https://img.shields.io/badge/JDK-1.8-brightgreen)
![](https://img.shields.io/badge/Maven-3.6.0-blue)
![](https://img.shields.io/badge/Spring%20Cloud-Greenwich.SR2-orange)
![](https://img.shields.io/badge/license-MPL--2.0-blue)

***

如果我的文章对你有帮助，请扫码关注我的公众号，所有的文章都会在公众号首推：

<center>
    <img src=""https://cdn.geekdigging.com/wechat_qrcode_344.jpg"">
</center>

# [Spring Boot 系列文章](https://www.geekdigging.com/categories/SpringBoot/)

* [Spring Boot （一）：快速开始](https://www.geekdigging.com/2019/09/11/2531363117/)

* [Spring Boot （二）：模版引擎 Thymeleaf 渲染 Web 页面](https://www.geekdigging.com/2019/09/16/2755709569/)

* [Spring Boot （三）： ORM 框架 JPA 与连接池 Hikari](https://www.geekdigging.com/2019/09/19/2405775053/)

* [Spring Boot （四）： Druid 连接池密码加密与监控](https://www.geekdigging.com/2019/09/22/1068168916/)

* [Spring Boot （五）： Redis缓存使用姿势盘点](https://www.geekdigging.com/2019/09/24/2171701522/)

* [Spring Boot （六）： 为 JPA 插上翅膀的 QueryDSL](https://www.geekdigging.com/2019/09/26/1814805575/)

* [Spring Boot （七）： Mybatis极简配置](https://www.geekdigging.com/2019/09/28/3684964092/)

* [Spring Boot （八）： Mybatis 增强工具 MyBatis-Plus](http://www.geekdigging.com/2019/09/29/2160851131/)

* [Spring Boot （九）： 微服务应用监控 Spring Boot Actuator 详解](http://www.geekdigging.com/2019/09/30/3362349187/)

* [Spring Boot （十）： Spring Boot Admin 监控 Spring Boot 应用](http://www.geekdigging.com/2019/10/01/3649490045/)

* [Spring Boot （十一）： Spring Boot 定时任务](http://www.geekdigging.com/2019/10/06/3308794317/)

* [Spring Boot （十二）： Spring Boot 邮件服务](http://www.geekdigging.com/2019/10/07/3113346683/)

* [Spring Boot （十三）： Spring Boot 整合 RabbitMQ](http://www.geekdigging.com/2019/10/08/3448388748/)

* [Spring Boot （十四）： 响应式编程以及 Spring Boot Webflux 快速入门](http://www.geekdigging.com/2019/10/09/2115479772/)

* [Spring Boot （十五）： 优雅的使用 API 文档工具 Swagger2](http://www.geekdigging.com/2019/10/10/2115479772/)

* [Spring Boot （十六）： Webflux 和 MVC 性能对比](http://www.geekdigging.com/2019/10/14/363459181/)

* 其余文章笔者努力更新中，欢迎大家持续关注：）

顺便打个广告：

## [Spring Cloud 系列文章](https://www.geekdigging.com/categories/SpringCloud)

## [Spring Cloud Alibaba 系列文章](https://www.geekdigging.com/categories/SpringCloudAlibaba/)

* [Github代码仓库](https://github.com/meteor1993/SpringCloudLearning)

* [Gitee代码仓库](https://gitee.com/inwsy/SpringCloudLearning)
"
lokeshgupta1981/Core-Java,master,67,95,2019-10-08T17:53:32Z,5206,2,Core Java examples posted on howtodoinjava.com,,"# Related Tutorials on [howtodoinjava.com](https://howtodoinjava.com/)

1. [Java 11 � Files readString() API](https://howtodoinjava.com/java11/files-readstring-read-file-to-string/)
2. [Java 11 � Files writeString() API](https://howtodoinjava.com/java11/write-string-to-file/)
3. [Java � Read File to String](https://howtodoinjava.com/java/io/java-read-file-to-string-examples/)
4. [Java � Write to File](https://howtodoinjava.com/java/io/java-write-to-file/)"
IanDarwin/javasrc,master,239,150,2013-10-11T14:50:06Z,51312,0,Ian's Collected code examples from the O'Reilly Java Cookbook & elsewhere,basics environment java,
sujitpal/hia-examples,master,39,36,2012-07-13T23:04:41Z,174,1,Hadoop In Action Examples,,"hia-examples
============

The project started as worked examples from the book ""Hadoop In Action"" (hence the name). Since then it has morphed to a container for multiple projects related to Hadoop (and Hadoop ecosystem).

java/hadoop
-----------
A selection of solutions to problems from the ""Hadoop in Action"" book.

java/cascading-newsclip
-----------------------
An automated newspaper clipping service using Cascading.

java/cascading-kevinbacon
-------------------------
Cascading implementation of the Degrees of Separation from Kevin Bacon problem.

scala/impatient
---------------
Scalding version of Parts 1-5 of Paco Nathan's [Cascading for the Impatient](http://www.cascading.org/category/impatient/).

scala/cms-preproc
-----------------
Data analysis with Scalding on Medicare Claims data from cms.gov to find code outliers, etc.

scala/cms-disease-graph
-----------------------
Data analysis with Apache Spark to compute a disease graph for diseases identified as comorbidities among members. Uses Medicare Claims data from cms.gov.

pig/scripts
------------
Pig script examples from HIA.

pig/udfs
---------
Associated Pig UDFs from HIA.

hive/scripts
------------
Hive script examples from HIA.

"
jmgomezh/tmweka,master,64,77,2013-04-08T13:28:24Z,18299,1,Examples of Text Mining in WEKA,,"tmweka
======

Examples of Text Mining in WEKA.

For more information, check <a href=""http://www.esp.uem.es/jmgomez/tmweka"">Text Mining in WEKA Cookbook</a>."
sleberknight/basic-hbase-examples,master,39,44,2012-04-27T22:02:57Z,172,0,Contains sample code for a lightning talk on HBase.,,
rubykv/code-examples,master,62,29,2021-06-01T00:13:37Z,4189,0,code-examples is a collection of Java/Spring based software projects implemented as POCs (Proof Of Concept),docker java kafka microservice mongodb spring-boot spring-cloud,"# code-examples
code-examples is a collection of software projects implemented as POCs (Proof Of Concept)

## Projects
All the projects that are part of this repository are listed below under the concept / framework it belongs to.
Few of the projects implement multiple concepts so they would be listed under multiple topics. 

### Spring Circuit Breaker
* Alibaba Sentinel
  * Project :: alibaba-sentinel
  * Guide :: https://levelup.gitconnected.com/how-to-implement-a-circuit-breaker-in-microservice-with-alibaba-sentinel-d645f69b20ef

* Resilience4j
  * Project :: student, subject
  * Guide :: https://blog.devgenius.io/implementing-spring-cloud-circuit-breaker-with-resilience4j-cea647235cd7

### Microservice Registry / Eureka / Spring Cloud Netflix
* Project :: eureka-server, demo-eureka
* Guide :: https://levelup.gitconnected.com/simple-implementation-of-eureka-server-with-springboot-780b64e19735

### Spring Cloud OpenFeign / Feign
* Project :: eureka-server, student, subject
* Guide :: https://medium.com/javarevisited/simple-implementation-of-spring-cloud-openfeign-7f022630d01d

### Spring Cloud Gateway / Microservice Gateway + Loadbalancer
* Project :: gateway
* Guide :: https://medium.com/javarevisited/how-to-use-spring-cloud-gateway-to-dynamically-discover-microservices-194c0c3869c6

### Spring Cloud Config / Microservice External Configuration
* Project :: config-server-app
* Guide :: https://medium.com/javarevisited/external-configuration-in-microservices-spring-cloud-config-9c925f64749f

### CQRS / Axon4
* Project :: axon
* Guide :: https://medium.com/javarevisited/simple-implementation-of-axon-4-with-springboot-and-mongo-db-6ee25008459d

### Hexagonal Architecture
* Project :: hexagonal-architecture
* Guide :: https://medium.com/javarevisited/hexagonal-architecture-implementation-in-java-48a89c018247

### Docker
* Project :: demo
* Guide :: https://medium.com/javarevisited/how-to-build-run-and-test-a-simple-springboot-app-in-docker-lab-test-style-e632b57265a8

### Kafka
* With Kafka Java Client
  * Project :: kafka-demo 
  * Guide :: No Guide

* With Spring Kafka
  * Project :: spring-kafka-demo
  * Guide :: https://medium.com/javarevisited/implementing-another-in-demand-spring-project-spring-kafka-85ee25ec14f8

### Java Instrumentation
* Project :: java-instrumentation
* Guide :: https://medium.com/javarevisited/java-instrumentation-a-simple-working-example-in-java-a2c549024d9c

### gRPC
* Project :: grpc
* Guide :: https://medium.com/javarevisited/what-is-grpc-is-it-better-than-rest-api-58a3b7aff13a 

### Reactive Programming RxJava
* Project :: reactive
* Guide :: https://medium.com/javarevisited/lets-explore-reactive-programming-through-rxjava-805b0137e5d

### GraphQL
* Project :: graphql
* Guide :: https://medium.com/javarevisited/what-is-graphql-will-it-replace-rest-api-da2618001655

### AOP + Spring Cloud Sleuth
* Project :: aspect
* Guide :: https://medium.com/javarevisited/how-to-build-an-effective-logging-system-using-aspect-and-spring-cloud-sleuth-8f7aed647545

### ArchUnit
* Project :: arch-unit-demo
* Guide :: https://medium.com/javarevisited/how-to-test-java-architecture-with-archunit-fe8c018b7b57

### Spring AI
* Project :: ai-sample
* Guide :: 
"
vaadin/flow-spring-examples,v24,53,39,2017-10-20T09:57:52Z,2682,3,Examples for Vaadin and Spring Boot,flow java open-source spring-application spring-boot tutorial vaadin-spring webapp,"Flow Spring examples
======================

This project contains the source code for the examples for using Vaadin and Spring together with the help of Spring Boot.

The tutorial can be found [here](https://vaadin.com/docs/v14/flow/spring/tutorial-spring-basic.html).

The topics that are covered in this example project:
* Getting Started with Vaadin Spring for Flow and Spring Boot: the initial `@SpringBootApplication` class.
* Injection and Scopes with Vaadin Spring
* Navigation with Vaadin Spring
* Register VaadinServiceInitListener via the Spring DI mechanism
* Flow template within Spring Boot application
* Use I18N in Spring application

## Running the project from command line

Run `mvn clean install spring-boot:run` in the project root directory. After the server has started point your browser to [http://localhost:8080](http://localhost:8080) to see the resulting application.

## Running the project from your IDE

Navigate to the `org.vaadin.spring.tutorial.TutorialApplication` class and run it as a Java application.
"
zznate/hector-examples,master,80,26,2010-06-18T00:07:19Z,1701,6,Various examples of using the Hector API to access Apache Cassandra,,
npryce/goos-code-examples,master,73,33,2010-01-03T18:33:36Z,9103,0,"Code examples from later chapters of Growing Object-Oriented Software, Guided by Tests",,
saucelabs-training/demo-java,main,98,116,2018-10-29T17:41:25Z,21481,32,A repository containing examples using Java with Sauce Labs,hacktoberfest,"# Java Demonstration Scripts

Welcome to Java Demo Scripts designed by Solution Architects to provide examples of how to use Sauce Labs technologies. This repository contains
everything that you need to get started with web, mobile, visual, functional and all other types of automation using Java.

[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)
[![Codacy Badge](https://api.codacy.com/project/badge/Grade/564ddfb012db40048781b7b6c954d099)](https://app.codacy.com/gh/saucelabs-training/demo-java?utm_source=github.com&utm_medium=referral&utm_content=saucelabs-training/demo-java&utm_campaign=Badge_Grade_Dashboard)
[![Best Practices Tests](https://github.com/saucelabs-training/demo-java/actions/workflows/best-practice.yml/badge.svg)](https://github.com/saucelabs-training/demo-java/actions/workflows/best-practice.yml)
[![Selenium JUnit 5 Tests](https://github.com/saucelabs-training/demo-java/actions/workflows/selenium-examples.yml/badge.svg)](https://github.com/saucelabs-training/demo-java/actions/workflows/selenium-examples.yml)
[![JUnit 4 Tests](https://github.com/saucelabs-training/demo-java/actions/workflows/junit4.yml/badge.svg)](https://github.com/saucelabs-training/demo-java/actions/workflows/junit4.yml)
[![TestNg Tests](https://github.com/saucelabs-training/demo-java/actions/workflows/testng.yml/badge.svg)](https://github.com/saucelabs-training/demo-java/actions/workflows/testng.yml)
[![Selenium Cucumber Examples](https://github.com/saucelabs-training/demo-java/actions/workflows/cucumber.yml/badge.svg)](https://github.com/saucelabs-training/demo-java/actions/workflows/cucumber.yml)
[![Real Devices](https://github.com/saucelabs-training/demo-java/actions/workflows/real-devices.yml/badge.svg)](https://github.com/saucelabs-training/demo-java/actions/workflows/real-devices.yml)

## 🥇Most Popular
*  [Web automation best practices framework with multiple testing strategies. Crafted by industry experts with decades of experience.](./best-practice/)
*  [Quick start test, Junit 5](./selenium-examples/src/test/java/com/saucedemo/selenium/demo/SeleniumTest.java)
*  [Quick start test, Junit 4](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/demo/SeleniumTest.java)
*  [Quick start test, TestNg](./selenium-testng-examples/src/test/java/com/saucedemo/selenium/testng/demo/SeleniumTest.java)
*  [iOS real device, native app, Junit4](./appium-examples/src/test/java/com/appium_app/simple_example/IOSNativeAppTest.java)
*  [Front-end performance testing](./selenium-examples/src/test/java/com/saucedemo/selenium/PerformanceTest.java)
*  [Visual E2E test](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/SimpleVisualE2ETest.java)
*  [Sauce Connect usage](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/SauceConnectTest.java)

## Best Practices
*  [Desktop](./best-practice/src/test/java/com/saucedemo/tests/DesktopTests.java) `junit4` `sauce-bindings`
*  [Emu/Sim Web](./best-practice/src/test/java/com/saucedemo/tests/EmuSimWebAppTests.java) `junit4` `sauce-bindings`
*  [Performance](./best-practice/src/test/java/com/saucedemo/tests/PerformanceTests.java) `junit4` `sauce-bindings`
*  [RealDevice](./best-practice/src/test/java/com/saucedemo/tests/RealDeviceWebTests.java) `junit4` `sauce-bindings`
*  [Visual E2E](./best-practice/src/test/java/com/saucedemo/tests/VisualCrossPlatformTests.java) `junit4` `sauce-bindings`

## 🖥Web automation

- Sauce Bindings With TestRunner Examples
  * [Junit 5](./selenium-examples/src/test/java/com/saucedemo/selenium/demo/SaucebindingsJunitTest.java) `junit5` `sauce-bindings`
  * [Junit 4](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/demo/SauceBindingsJunit4Test.java) `junit4` `sauce-bindings`
  * [TestNg](./selenium-testng-examples/src/test/java/com/saucedemo/selenium/testng/demo/SauceBindingsTestngTest.java) `testng` `sauce-bindings`

- Sauce Bindings Examples
  * [Junit 5](./selenium-examples/src/test/java/com/saucedemo/selenium/demo/SauceBindingsTest.java) `junit4` `sauce-bindings`
  * [Junit 4](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/demo/SauceBindingsTest.java) `junit4` `sauce-bindings`
  * [TestNg](./selenium-testng-examples/src/test/java/com/saucedemo/selenium/testng/demo/SauceBindingsTest.java) `junit4` `sauce-bindings`

- Selenium Examples
  * [Accessibility Test with Sauce Bindings](/selenium-examples/src/test/java/com/saucedemo/selenium/accessibility/SauceBindingsTest.java) `junit4` `sauce-bindings`
  * [Accessibility Test with Deque Axe](/selenium-examples/src/test/java/com/saucedemo/selenium/accessibility/DequeAxeTest.java) `junit4`
  * [Cucumber web test](./selenium-cucumber-examples/src/test/java/com/saucedemo/selenium/cucumber/RunTestsAT.java)
  * [Windows authentication](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/WindowsAuthentication.java) `junit4`
  * [Cross Browser/Platform in Parallel w/ TestNG](./selenium-testng-examples/src/test/java/com/saucedemo/selenium/testng/CrossBrowserPlatformTest.java) `testng`
  * [Performance, front-end with Sauce Bindings](/selenium-examples/src/test/java/com/saucedemo/selenium/PerformanceTest.java) `junit5` `sauce-bindings`
  * [Single Browser in Parallel w/ TestNG](./selenium-testng-examples/src/test/java/com/saucedemo/selenium/testng/ParallelSingleBrowserTest.java) `testng`
  * [Visual e2e test](./selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/SimpleVisualE2ETest.java) `visual` `junit4`
  * [Visual e2e test with branching strategy](./blob/54a4bfde9040d71f88f3b3aff79a047474d01be9/selenium-junit4-examples/src/test/java/com/saucedemo/selenium/junit4/SimpleVisualE2ETest.java#L115-L158) `visual` `junit4`

## 📱Mobile automation

[📚 Mobile Testing Training Tutorials](./TRAINING.md)

- Real Devices
  * [iOS native app](./appium-examples/src/test/java/com/appium_app/simple_example/IOSNativeAppTest.java)
  * [Android native app](./appium-examples/src/test/java/com/appium_app/simple_example/AndroidNativeAppTest.java)
  * [Upload app to Sauce Storage](./appium-examples/src/test/java/com/helpers/push_apps_to_storage.sh)
  * [Image Injection](./appium-examples/src/test/java/com/appium_app/image_injection)
  * [Biometric Login](./appium-examples/src/test/java/com/appium_app/biometric_login)
  * [Cucumber w/ Appium](./appium-junit4-cucumber-examples/src/test/resources/LoginPage.feature) `junit4` `cucumber`

- Emulators and Simulators
  * [iOS native app](./appium-examples/src/test/java/com/appium_app/simple_example/IOSNativeAppTest.java)
  * [Android native app](./appium-examples/src/test/java/com/appium_app/simple_example/AndroidNativeAppTest.java)
  * [Biometric Login](./appium-examples/src/test/java/com/appium_app/biometric_login)

## ⚙️Setup

*  Install [Git](https://github.com/saucelabs-training/demo-java/blob/main/docs/prerequisites.md#install-git)
*  Install [IntelliJ (or another IDE)](https://github.com/saucelabs-training/demo-java/blob/main/docs/prerequisites.md#install-intellij)
*  Install [JDK](https://github.com/saucelabs-training/demo-java/blob/main/docs/prerequisites.md#install-the-jdk)
*  Install [Maven](https://github.com/saucelabs-training/demo-java/blob/main/docs/prerequisites.md#install-maven)

### Import the Project

1. Create a directory on your machine.

2. Clone this repository into said directory.
    ```
    $ git clone https://github.com/saucelabs-training/demo-java.git
    ```

3. Import the project into your IntelliJ (or IDE of your choice) as a **Maven Project**.

4. Click through the prompts, and confirm when it asks to **Import from Sources**

5. Choose the **demo-java** directory as the **root** directory of the project.

### Set Your Sauce Labs Credentials
1. Copy your Sauce Labs **username** and **accessKey** in the [User Settings](https://app.saucelabs.com/user-settings) section of the [Sauce Labs Dashboard](https://app.saucelabs.com/dashboard/builds).
2. Open a Terminal window (command prompt for Windows) and set your Sauce Labs Environment variables:   
   **Mac OSX:**
   ```
   $ export SAUCE_USERNAME=""your username""
   $ export SAUCE_ACCESS_KEY=""your accessKey""
   $ export SCREENER_API_KEY=""your screener key""
   ```
   **Windows:**
   ```
   > set SAUCE_USERNAME=""username""
   > set SAUCE_ACCESS_KEY=""accessKey""
   > set SCREENER_API_KEY=""your screener key""
   ```
   > To set an environment variables permanently in Windows, you must append it to the `PATH` variable.
   
   > Go to **Control Panel > System > Windows version > Advanced System Settings > Environment Variables > System Variables > Edit > New**
   
   > Then set the ""Name"" and ""Value"" for each variable
   
3. Test the environment variables

    **Mac OSX:**
    ```
    $ echo $SAUCE_USERNAME
    $ echo $SAUCE_ACCESS_KEY
    ```

    ***WARNING FOR UNIX USERS!***
    
    *If you have problems setting your environment variables, run the following commands in your terminal:*

    ```
    $ launchctl setenv SAUCE_USERNAME $SAUCE_USERNAME
    $ launchctl setenv SAUCE_ACCESS_KEY $SAUCE_ACCESS_KEY
    ```

    **Windows:**
    ```
    > echo %SAUCE_USERNAME%
    > echo %SAUCE_ACCESS_KEY%
    ```

### Run a Maven Test

1. Run the following command to update any package dependencies:
    ```
    $ mvn dependency:resolve
    ```
2. Then run the following command to compile your test code:
    ```
    $ mvn test-compile
    ```
3. Finally, run the following test to see if you've properly configured the test environment:
    ```
    $ mvn test -pl best-practice -Dtest=DesktopTests 

    ```
    
   You can run different tests from different modules. Check out some examples by looking at the [CI YML files](./.github/workflows)

## Contributing 

This repository is maintained by the Solutions Architect team at Sauce Labs. **We welcome all ideas and contributions!**

Guidance for contributing can be found [here](./CONTRIBUTING.md) 


## Disclaimer

> The code in these scripts is provided on an ""AS-IS"" basis without warranty of any kind, either express or implied, including without limitation any implied warranties of condition, uninterrupted use, merchantability, fitness for a particular purpose, or non-infringement. These scripts are provided for educational and demonstration purposes only, and should not be used in production. Issues regarding these scripts should be submitted through GitHub. These scripts are maintained by the Technical Services team at Sauce Labs.
>
> Some examples in this repository, such as `appium-example`, `parallel-testing`, and `headless`, may require a different account tier beyond free trial. Please contact the [Sauce Labs Sales Team](https://saucelabs.com/contact) for support and information.
"
bogus/Java-Spring-Examples,master,41,41,2010-01-28T19:03:44Z,135,0,Java Course Examples with JPA / Spring MVC / JSF / AOP / Hibernate,,
HotswapProjects/HotswapAgentExamples,master,49,40,2014-03-16T07:36:06Z,323,25,Example applications for HotswapAgent plugins,,"HotswapAgent example applications
=================================

Example applications for HotswapAgent plugins.

The purpose of an example application is:
* complex automate integration tests (check various configurations before a release, see `run-tests.sh` script) 
* to check ""real world"" plugin usage during plugin development (i.e. inside container)
* to provide working solution for typical application setups
* sandbox to simulate issues for existing or new setups

Feel free to fork/branch and create an application for your setup (functional, but as simple as possible).
General setups will be merged into the master.

# plain-java
This example uses only core agent library and runs without any framework support. Check this example
to learn basic agent properties usage (extraClasspath, watchResources, autoHotswap).

# plain-servlet
Run hotwap agent with a servlet container/J2EE server (Jetty/Tomcat/JBoss). This example does pretty the same
as plain-java, but checks the value as HTTP response strings. This examples checks also that various application 
server versions are supported.

# custom-plugin
Detail explanation and example of how to create custom plugin even inside your application. 

# spring-hibernate
Complex project with typical setup Spring + Spring MVC + Hibernate. 

# seam-hibernate-jsf

# cdi-hibernate-jsf
"
stephanrauh/BootsFaces-Examples,master,25,51,2015-03-09T19:37:35Z,1295,0,,,"# BootsFaces-Examples
This is a collection of simple BootsFaces demo applications.
"
neo4j-examples/movies-java-spring-data-neo4j,main,520,317,2015-10-06T08:15:18Z,518,3,Neo4j Movies Example with Spring Data Neo4j,,
apache/camel-kafka-connector-examples,main,61,43,2020-04-28T15:07:18Z,1238,20,Apache Camel Kafka Connector Examples,camel integration java kafka,
wildfly-extras/wildfly-camel-examples,main,27,49,2016-08-12T11:54:48Z,3340,0,The WildFly-Camel Examples,,"## WildFly Camel Examples

This directory contains a suite of useful modules to demonstrate various features of the WildFly Camel Subsystem.
Their aim is to provide small, specific and working examples that can be used for reference in your own projects.

### Prerequisites

Please refer to the project [README documentation](https://github.com/wildfly-extras/wildfly-camel/blob/master/README.md) for information on how to build and test the project.
Please take into consideration the minimum Java and Maven requirements. The examples also require a running application server
with the wildfly-camel subsystem deployed.

### Running Examples

Each example aims to be interactive to help you learn how to get started with the WildFly Camel Subsystem. Each example
can be accessed by changing into the example source directory, building the project `mvn clean install` and then deploying
to a running application server `mvn install -Pdeploy`.

Examples can be undeployed from a running application server by running `mvn clean -Pdeploy`.

"
fukata/AES-256-CBC-Example,master,62,88,2012-02-15T07:54:50Z,119,3,aes-256-cbc encrypt and decrypt examples,,"# AES-256-CBC Example

Original program is [here](https://gist.github.com/799d6021890f34734470).

This sample, encryption, decryption input and output to the format of the following.

- Encryption
 - Input: Raw Text
 - Output: Base64
- Decryption
 - Input: Base64
 - Output: Raw Text

*Since you are writing a common key for encryption in the library that you created for each language, when you actually use, please change.*

## Java

	String src = ""Hello,CryptWorld"";
	String enc = AESUtil.encrypt(src);
	String dec = AESUtil.decrypt(enc);

## Node.js

	Encrypt = require './encrypt'
	src = 'Hello,CryptWorld'
	enc = Encrypt.encrypt src
	dec = Encrypt.decrypt enc
"
TeamDev-IP/JxBrowser-Examples,master,77,30,2018-04-06T17:23:12Z,1453,1,JxBrowser Examples & Tutorials,examples java javafx jxbrowser swing swt,"# Welcome to JxBrowser Examples

This repository contains a set of examples and tutorials you can use to walk through the main features of [JxBrowser](https://www.teamdev.com/jxbrowser).

## About JxBrowser

JxBrowser is a commercial cross-platform Java library that lets you integrate a Chromium-based web browser control into your Java Swing, JavaFX, or SWT desktop application to display modern web pages built with HTML5, CSS3, JavaScript.

With JxBrowser you can display modern web pages, PDFs, WebGL, work with DOM, JavaScript, WebRTC, network, printing, call Java from JavaScript, manage file downloads, convert HTML to PNG, debug web pages with DevTools, configure proxy, manage cookies, handle authentication, fill web forms, and much more.

## Running Examples

To run the examples please follow the instruction below:

1. Make sure your environment meets the
   [software and hardware requirements][requirements].

2. Clone this repository:
    ```bash
    git clone https://github.com/TeamDev-IP/JxBrowser-Examples
    ```
3. Open the Gradle project in your favourite IDE:
   - [Intellij IDEA][idea]
   - [Eclipse][eclipse]
   - [NetBeans][netbeans]

4. [Get][get-evaluation] a free 30-day trial license key.

5. To run an example please specify the `jxbrowser.license.key` VM parameter:
    ```bash
    -Djxbrowser.license.key=<your_trial_license_key>
    ```
 
## What's Next

- Learn about JxBrowser [architecture](https://jxbrowser-support.teamdev.com/docs/guides/introduction/architecture.html).
- Take a look at JxBrowser [features](https://jxbrowser-support.teamdev.com/docs/guides/engine.html).
- Explore the JxBrowser [API](https://jxbrowser-support.teamdev.com/docs/reference/).


## Terms and Privacy

The information in this repository is provided on the following terms: https://www.teamdev.com/terms-and-privacy


[requirements]: https://jxbrowser-support.teamdev.com/docs/guides/introduction/requirements.html
[idea]: https://www.jetbrains.com/help/idea/gradle.html#gradle_import
[eclipse]: https://marketplace.eclipse.org/content/buildship-gradle-integration#group-details
[netbeans]: https://netbeans.org/features/java/build-tools.html
[get-evaluation]: https://www.teamdev.com/jxbrowser#evaluate"
aws-samples/aws-cloudhsm-jce-examples,sdk5,33,56,2018-08-23T22:03:27Z,144,18,Sample applications demonstrating how to use the CloudHSM JCE,,"# aws-cloudhsm-jce-examples

These sample applications demonstrate how to use the JCE with CloudHSM. They show basic functionality,
as well as best practices regarding performance.

## License Summary

This sample code is made available under a modified MIT license. See the LICENSE file.

## Building the examples

### Dependencies

The latest SDK5 version of CloudHSM JCE is required.
They should be installed using the official procedures documented here:

* https://docs.aws.amazon.com/cloudhsm/latest/userguide/java-library-install_5.html

The examples are tested on a fresh Amazon Linux 2 AMI. You will need to have the following packages 
installed:

* OpenJDK 8
* Apache Maven 3.0.5

You can install these packages on Amazon Linux 2 by running

```
sudo yum install -y java-1.8.0-amazon-corretto-devel maven
```

If you are running on Amazon Linux 1, you will need to install extra packages to get Maven.
You can follow these instructions to build the samples on Amazon Linux 1:

```
# Maven is only available through extra packages
sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo
sudo sed -i s/\$releasever/6/g /etc/yum.repos.d/epel-apache-maven.repo

# You will need Java 1.8 to build the samples
sudo yum install -y java-1.8.0-openjdk-devel
sudo yum install -y apache-maven

# When updating alternatives, choose the 1.8 path: /usr/lib/jvm/jre-1.8.0-openjdk.x86_64/bin/java
sudo update-alternatives --config java
```


### Building

You can build the project using Maven. Maven will copy the required CloudHSM jars into a local repository
and build fat jars which can be executed from the command line. These fat jars will be placed in the
`target/assembly/` directory. 

Before you build your project, be sure to enter the correct CloudHSM version number based on which CloudHSM JCE Provider
you have installed on your system. By default, this project is set to use the latest available CloudHSM version, and 
you may need to make modifications if you are running an older version (note that not all tests are guaranteed to work 
with older versions of the client). To do this, modify the following line in the `pom.xml` to match your version:

```
<cloudhsmVersion>5.5.0</cloudhsmVersion>
```


To build the project, use the following command:

```
mvn validate
mvn clean package
```

## Running the samples

You will need to have a CloudHSM Client connected to an ACTIVE cluster. For more details, please follow
the official instructions here:

* https://docs.aws.amazon.com/cloudhsm/latest/userguide/getting-started.html

You will need to provide credentials to the JCE provider in order to run the samples. Please read about
JCE provider credentials here:

* https://docs.aws.amazon.com/cloudhsm/latest/userguide/java-library-install_5.html#java-library-credentials_5

All Java dependencies should be bundled in the fat jars.
Jars can be run using the following command line (as an example):

```
java -ea -jar target/assembly/login-runner.jar --help
```

## Running and verifying all the samples

To run and verify all the samples together, run the command ```mvn verify```
"
7DGroup/JMeter-examples,master,29,36,2018-12-14T14:30:09Z,7258,0,Blog Demo & Source code （文章示例及源码）,,"# PerformanceTest-Examples
![Spring Boot 2.0](https://img.shields.io/badge/Spring%20Boot-2.0-brightgreen.svg)
![Mysql 5.6](https://img.shields.io/badge/Mysql-5.6-blue.svg)
![JDK 1.8](https://img.shields.io/badge/JDK-1.8-brightgreen.svg)
![Maven](https://img.shields.io/badge/Maven-3.5.0-yellowgreen.svg)

**Blog Demo &amp; Source code （文章示例及源码）**

#### 性能基础系列：
- 接口
    - [性能基础之浅谈常见接口性能压测](https://blog.csdn.net/zuozewei/article/details/82836158)
    - [性能基础之常见RPC框架浅析](https://blog.csdn.net/zuozewei/article/details/85312689)
    - [秒懂HTTPS接口（原理篇）](https://blog.csdn.net/zuozewei/article/details/84727065)
    - [秒懂Dubbo接口（原理篇）](https://blog.csdn.net/zuozewei/article/details/85333060)
- 全链路
    - [性能基础之全链路压测知识整理](https://blog.csdn.net/zuozewei/article/details/84983834)

- 架构
    - [性能基础之大型网站架构演化（整理篇）](https://blog.csdn.net/zuozewei/article/details/85039849)
    - [性能基础之大型网站技术架构模式](https://blog.csdn.net/zuozewei/article/details/85226382)

- 操作系统
    - [性能基础之速读【性能之巅：洞悉系统、企业与云计算】](https://blog.csdn.net/zuozewei/article/details/85107901)
    - [性能基础之CPU、物理核、逻辑核概念与关系](https://blog.csdn.net/zuozewei/article/details/85251890)
    - [性能基础之理解Linux系统平均负载和CPU使用率](https://blog.csdn.net/zuozewei/article/details/86483503)

##### 性能闲谈系列：
- [浅谈window桌面GUI技术及图像渲染性能测试实践](https://blog.csdn.net/zuozewei/article/details/82656926)

#### JMeter系列：
- 脚本
    - [Jmeter接口测试demo](https://blog.csdn.net/zuozewei/article/details/79627177)
    - [秒懂HTTPS接口（JMeter压测篇）](https://blog.csdn.net/zuozewei/article/details/84778207)
    - [性能工具之JMeter压测WebSocket接口（一）](https://blog.csdn.net/zuozewei/article/details/83064219)

- 源码分析
    - [性能工具之JMeter5.0核心源码浅析](https://blog.csdn.net/zuozewei/article/details/85042829)
    - [性能工具之JMeter5.0核心类HashTree源码分析](https://blog.csdn.net/zuozewei/article/details/86748517)
    - [性能工具之JMeter5.0核心类StandardJMeterEngine源码分析](https://blog.csdn.net/zuozewei/article/details/87657696)
    - [性能工具之JMeter5.0核心类JMeterEngine源码分析](https://blog.csdn.net/zuozewei/article/details/87925297)

- 二次开发
    - [性能工具之Jmeter扩展函数及压测ActiveMQ实践](https://blog.csdn.net/zuozewei/article/details/82710274)
    - [性能工具之Jmeter压测Hprose RPC服务](https://blog.csdn.net/zuozewei/article/details/82765585)
    - [性能工具之Jmeter压测Thrift RPC服务](https://blog.csdn.net/zuozewei/article/details/82589810)
    - [性能工具之Jmeter扩展配置元件插件](https://blog.csdn.net/zuozewei/article/details/82887039)
    - [性能工具之JMeter两个Java API Demo](https://blog.csdn.net/zuozewei/article/details/87883055)
    
- 实时监控
    - [性能工具之JMeter+InfluxDB+Grafana打造压测可视化实时监控](https://blog.csdn.net/zuozewei/article/details/82911173)
    
- 其他
   - [性能工具之Taurus入门（安装篇）](https://zuozewei.blog.csdn.net/article/details/102719878)

#### 性能工具系列：
- 综合
    - [性能工具之Java分析工具BTrace入门](https://blog.csdn.net/zuozewei/article/details/82635139)
    - [性能工具之DOTNET性能分析工具](https://blog.csdn.net/zuozewei/article/details/80222211)

- Linux
    - [性能工具之15个常用的Linux文件系统命令](https://blog.csdn.net/zuozewei/article/details/85346442)
    - [性能工具之linux三剑客awk、grep、sed详解](https://blog.csdn.net/zuozewei/article/details/85709621)
    - [性能工具之linux常见日志统计分析命令](https://blog.csdn.net/zuozewei/article/details/85802582)

#### 性能监控系列：
- [性能监控之常见JDK命令行工具整理](https://blog.csdn.net/zuozewei/article/details/82695814)
- [性能监控之Telegraf+InfluxDB+Grafana linux服务器实时监控](https://blog.csdn.net/zuozewei/article/details/82929429)
- [性能监控之JMeter分布式压测轻量日志解决方案](https://blog.csdn.net/zuozewei/article/details/82966719)
- [性能监控之Telegraf+InfluxDB+Grafana NVIDIA GPU实时监控](https://blog.csdn.net/zuozewei/article/details/83118343)
- [性能监控之Telegraf+InfluxDB+Grafana window服务器安装使用](https://blog.csdn.net/zuozewei/article/details/88400701)
- [性能监控之Telegraf+InfluxDB+Grafana+Python实现Oracle实时监控](https://blog.csdn.net/zuozewei/article/details/89042921)
- [性能监控之Telegraf+InfluxDB+Grafana实现JMX实时监控](https://zuozewei.blog.csdn.net/article/details/102562702)
- [性能监控之Telegraf+InfluxDB+Grafana实现结构化日志实时监控](https://zuozewei.blog.csdn.net/article/details/102584480)

#### 性能数据系列：
- [Python脚本批量生成SQL语句](https://blog.csdn.net/zuozewei/article/details/83004726)
- [Java批量创建测试水印图片和GIF动图](https://zuozewei.blog.csdn.net/article/details/91806822)

#### 性能分析系列：
- [性能分析之大屏可视化平台瓶颈分析（window版）](https://blog.csdn.net/zuozewei/article/details/81093942)
- [性能分析之Linux系统平均负载案例分析](https://blog.csdn.net/zuozewei/article/details/86514406)
- [性能分析之单条SQL查询案例分析（mysql）](https://blog.csdn.net/zuozewei/article/details/86681249#_179)

#### 性能优化系列：
- [性能优化之MQ问题分析及解决方案](https://blog.csdn.net/zuozewei/article/details/79467404)

#### 性能报告系列：
- [HTML5大屏版性能测试报告](https://blog.csdn.net/zuozewei/article/details/81360803)
- [性能报告之路由器性能benchmark评估](https://blog.csdn.net/zuozewei/article/details/79861214)"
yidongnan/spring-cloud-consul-example,master,178,95,2016-06-07T09:13:53Z,1017,3,spring-cloud-consul-example is an example for microservices system,docker microservice spring-boot-admin spring-cloud-consul spring-cloud-sleuth swagger zipkin,"# spring-cloud-consul-example
README: [English](https://github.com/yidongnan/spring-cloud-consul-example/blob/master/README.md) | [中文](https://github.com/yidongnan/spring-cloud-consul-example/blob/master/README-zh.md)

spring-cloud-consul-example is an example for microservices system.

It's contain 
**configuration management, service discovery, circuit breakers, intelligent routing, distributed tracing, application monitor**.

The registry center uses the consul, if you want to use eureka, you can refer to
https://github.com/yidongnan/spring-cloud-netflix-example

## Getting Started
```shell
./gradlew clean build -x test
./buildDockerImage.sh
docker-compose up -d
```
if you want to start more serve, you should use 
```shell
docker-compose scale service-a=2 service-b=3  
```

## Technology List
* Spring Cloud Consul
* Spring Cloud Sleuth
* Spring Cloud Config
* Spring Boot Admin
* Spring Boot
* ZipKin
* Docker
* Swagger

## Architecture Overview
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Architecture.png"">

## Screenshots
### Api Route(Zuul)
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_001.png"">

### Consul DashBoard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_002.png"">

### Consul Key/Value DashBoard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_003.png"">

### ZipKin DashBoard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_004.png"">

### ZipKin Trace Detail
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_005.png"">

### ZipKin Dependencies Overview
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_006.png"">

### Spring Boot Admin DashBoard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_007.png"">

### Spring Boot Admin Detail
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_008.png"">

### Spring Boot Admin Environment
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_009.png"">

### Spring Boot Admin Thread Dump
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_010.png"">

### Spring Boot Admin Trace
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_011.png"">

### Hystrix Dashboard
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_012.png"">

### Hystrix Dashboard Detail
[](url ""title"")
<img src=""https://raw.githubusercontent.com/yidongnan/spring-cloud-consul-example/master/screenshots/Selection_013.png"">
"
Rookout/deployment-examples,master,28,35,2018-02-11T12:00:32Z,14376,1,Integration examples for Rookout ,,"# Examples for deploying Rookout

This repository contains full deployment examples, developed by Rookout   and the community, and supported by Rookout engineer team. 



[appengine]: https://cloud.google.com/appengine/docs/flexible/nodejs
[tutorial]: https://cloud.google.com/appengine/docs/flexible/nodejs/quickstart
[readme]: ../README.md
[contributing]: https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/master/CONTRIBUTING.md
"
mkyong/spring3-mvc-maven-xml-hello-world,master,43,1317,2015-06-15T04:12:26Z,164,8,Maven + Spring 3 MVC hello world example (XML),,"Maven - Spring 3 MVC Hello World
===============================
Template for Spring 3 MVC + JSP view + XML configuration, using Maven build tool.

###1. Technologies used
* Maven 3
* Spring 3.2.13.RELEASE
* JSTL 1.2
* Logback 1.1.3
* Boostrap 3

###2. To Run this project locally
```shell
$ git clone https://github.com/mkyong/spring3-mvc-maven-xml-hello-world
$ mvn jetty:run
```
Access ```http://localhost:8080/spring3```

###3. To import this project into Eclipse IDE
1. ```$ mvn eclipse:eclipse```
2. Import into Eclipse via **existing projects into workspace** option.
3. Done.

###4. Project Demo
Please refer to this article [Maven - Spring 3 MVC Hello World ](http://www.mkyong.com/spring3/spring-3-mvc-hello-world-example/)
"
wcong/learn-java,master,140,148,2015-11-29T08:29:13Z,352,21,example of learn java,,"## learn-java
example of learn java

algorithm has moved to [learn-algorithm](https://github.com/wcong/learn-algorithm)


"
thomasWeise/distributedComputingExamples,master,71,30,2016-02-17T21:18:51Z,332,0,Example codes for my Distributed Computing course at Hefei University.,axis2 c communication distributed-computing glassfish hadoop html java java-rmi java-servlet javascript javaserver-pages json-rpc jsp mpi servlet-container socket web-services xml xml-document,"# Examples for Distributed Computing

[<img alt=""Travis CI Build Status"" src=""https://img.shields.io/travis/thomasWeise/distributedComputingExamples/master.svg"" height=""20""/>](https://travis-ci.org/thomasWeise/distributedComputingExamples/)
[<img alt=""Shippable Build Status"" src=""https://img.shields.io/shippable/56d905429d043da07b368422.svg"" height=""20""/>](https://app.shippable.com/projects/56d905429d043da07b368422)

## 1. Introduction and Contents

### 1.1. Introduction

Distributed systems surround us everywhere today. Their most prominent example is the internet hosting the world wide web. The computing environment in enterprise computing systems is often distributed too, interconnecting different services from human resources, financial departments, to asset management systems. Many applications are even hosted in the cloud. Finally, large-scale engineering and scientific computing today rely heavily on clusters in order to parallelize their workload. These topics are discussed in my distributed computing lecture. In this repository, you can find the practical examples I use in my course.

### 1.2. Contents

1. [Sockets](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/)
  1. in [C](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/c)
  2. in [Java](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java)

2. [HTML, CSS, and JavaScript](http://github.com/thomasWeise/distributedComputingExamples/tree/master/html/)

3. [Java Servlets](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/)
  1. [deployable examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/examples)
  2. [HTTP Proxy Servlet](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/proxy)

4. [JavaServer Pages](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServerPages/)
  1. [deployable examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServerPages/examples)
  2. [stand-alone JSPs](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServerPages/standAloneJSPsWithJetty)

5. [Java RMI](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaRMI/)
  
6. [XML](http://github.com/thomasWeise/distributedComputingExamples/tree/master/xml/)
  1. [examples for XML documents and related standards](http://github.com/thomasWeise/distributedComputingExamples/tree/master/xml/xml)
  1. [examples for XML processing with Java](http://github.com/thomasWeise/distributedComputingExamples/tree/master/xml/java)
  
7. [Web Services](http://github.com/thomasWeise/distributedComputingExamples/tree/master/webServices/)
  
8. [JSON RPC](http://github.com/thomasWeise/distributedComputingExamples/tree/master/jsonRPC/)
  
9. [Message Passing Interface](http://github.com/thomasWeise/distributedComputingExamples/tree/master/mpi/)
  
10. [Hadoop](http://github.com/thomasWeise/distributedComputingExamples/tree/master/hadoop/)
  
Each of the above links leads you to a sub-directory containing a set of examples. Each sub-directory has an own `README.md` file with detailed descriptions. 

Since I also use the same code in my slides, there are some special comments such as `//(*@\serverBox{2)}@*)` for formatting in my codes ... you can safely ignore them ^_^

## 2. Concept of the Course

The concept of this course is that we want to understand how the web and distributed enterprise application environments work. We want to do that by starting to explore how to communicate over a network at the lowest level of abstraction (normally) available to programmers, the [socket API](https://en.wikipedia.org/wiki/Network_socket). From there, we work our way up step-by-step higher levels of abstraction, i.e., simpler and more powerful API stacking on top of each other (and ultimately grounded in sockets). This way, we will gain a solid understanding how distributed applications and the web work. We will be able to look at a website and immediately have a rough understanding of how it may work, down to the nuts and bolts. For each level of abstraction that we explore, we therefore always learn example technologies. 

### 2.1. The Basics: Sockets, TCP, UDP, Parallelism, and Mashalling

As said, we start at the very bottom: Communication in distributed systems today is usually either based on the [UDP](https://en.wikipedia.org/wiki/User_Datagram_Protocol) or [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol). Both protocols are accessed via the [socket API](https://en.wikipedia.org/wiki/Network_socket), for which we provide [examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/) in both [C](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/c) and [Java](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java). As part of these examples, we also show how text can be encoded in Java and how to construct servers which can process multiple requests in [parallel](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java/src/MinHTTPServerThreadPool.java). Sockets are thus the very basis of distributed applications, the lowest level with which a programmer might have to work.

### 2.2. The Outside View of an Enterprise: Dynamic Websites

We now are able to understand the basic communication processes going on in virtually any current computer network and the internet. We will use this understand to investigate how an organization or enterprise can present itself to the outside world via a website. We want to understand the technologies necessary to construct a website that can dynamically interact with a user.

#### 2.2.1. HTML, CSS, JavaScript

The [world wide web](https://en.wikipedia.org/wiki/World_Wide_Web) is based on three pillars: [HTTP](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol), [HTML](https://en.wikipedia.org/wiki/HTML)/[CSS](https://en.wikipedia.org/wiki/Cascading_Style_Sheets)/[Javascript](https://en.wikipedia.org/wiki/JavaScript), and [URLs](https://en.wikipedia.org/wiki/Uniform_Resource_Locator). HTTP, the Hyper Text Transfer Protocol, is a text-based protocol to query resources which is usually transmitted over TCP connections. Actually, we already provide  example implementations of both the [server](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java/src/MinHTTPServer.java) ([web server](https://en.wikipedia.org/wiki/Web_server)) and [client](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java/src/MinHTTPClient.java) ([web browser](https://en.wikipedia.org/wiki/Web_browser)) client side of the HTTP communication using [sockets](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java) (and even a small [parallel web server](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/java/src/MinHTTPServerThreadPool.java). We then provide some rudimentary [examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/html/) for [HTML](http://github.com/thomasWeise/distributedComputingExamples/tree/master/html/example_pain/index.html), [CSS](http://github.com/thomasWeise/distributedComputingExamples/tree/master/html/example_css/index.html), and [JavaScript](http://github.com/thomasWeise/distributedComputingExamples/tree/master/html/example_javascript_calculator/index.html).

#### 2.2.2. Java Servlets: HTTP Protocol Server-Side Implementation

Implementing HTTP based on sockets is quite complex. Sockets allow us access TCP. What we would like to have is a similarly elegant API to access HTTP (the next higher level of abstraction). One such technology are [Java Servlets](https://en.wikipedia.org/wiki/Java_Servlet). Servlets are used to implement the server-side of a HTTP conversation. A servlet is a sub-class of a special Java class which implements handler methods for different HTTP interactions (""[HTTP methods](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods)""). These methods are called by a [servlet container](https://en.wikipedia.org/wiki/Web_container), the actual implementation of the server. We can therefore fully concentrate on the application logic and don't need to worry about the protocol interaction itself. We provide a wide range of examples for [Java Servlets](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/), both [deployable examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/examples) as well as a stand-alone [HTTP Proxy Servlet](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/proxy). So with Java Servlets, we can build server components that can dynamically interact with a HTTP client (such as a web browser). This means that we can dynamically generate contents of a web page when a browser requests them. However, building complete dynamic web sites as Java Servlets is again quite cumbersome, as servlets are Java classes while web pages are HTML, which we would then write in form of string constants to be written to the output of a Servlet.

#### 2.2.3. JavaServer Pages: Implement Dynamic Web Pages

The next higher level of abstraction are [JavaServer Pages](https://en.wikipedia.org/wiki/JavaServer_Pages) (JSPs), which allow us to write HTML pages (or other text formats) and include Java source code in it. The pages are then served again by a servlet container. Whenever a page is sent to a client, the included Java code is first executed on the server side (and may generate additional output). Upon closer inspection, we can find that JSPs are actually ""special"" servlets: When a JSP is accessed for the first time, the servlet container dynamically creates the source code of a corresponding Java Servlet. This servlet is compiled, loaded, and then executed to create the dynamic content of the page to be sent to the client. Everything which was ""text"" in JSP becomes a String inside the servlet which is written to the servlet's HTTP response. Everything which was ""code"" in the JSP is copied directly into the handler methods of the servlet. JSPs are a more natural way to dynamically generate text (HTML) output and serve it to a client. By now, we have a solid understanding how dynamic contents in the web can be generated, how a user can interact with a web application via web forms by using her browser, and how we can realize sessions.

### 2.3. The Inside View of an Enterprise: Distributed Application Environment

While these technologies allow us to build a dynamic ""outside"" view of a company, the way the company presents itself in the web, we now explore the ""inside"" view of the distributed enterprise computing environment. Here the goal is to build an environment in which applications from different departments (financial department, human resources, asset management, ...) can be connected with each other in a future-safe, extensible way.

#### 2.3.1. Remote Procedure Calls with Java RMI

The first step on this road to enterprise computing are [Remote Procedure Calls](https://en.wikipedia.org/wiki/Remote_procedure_call) (RPCs), which we explore on the example of [Java Remote Method Invocation](https://en.wikipedia.org/wiki/Java_remote_method_invocation) (RMI). Our [examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaRMI/) show how an object of one application hosted on computer can be accessed from another program running on a another computer. This brings us already close to realizing distributed applications interconnected on a network. However, Java RMI is still a Java-specific technology and its protocol is binary. We would like to implement our distributed applications in a platform-independent way, by using very clear, well-specified, and easy-to-understand protocols.

#### 2.3.2. XML as Data Interchange Format

Our pursuit of such a technology forces us to first take the de-tour of learning about the Extensible Markup Language ([XML](https://en.wikipedia.org/wiki/Xml). XML is a self-documenting format for storing complex data structures in text. It is similar to HTML, but without any pre-defined semantic or presentation. These can be specified for each application. We both look at [examples for XML documents and related standards](http://github.com/thomasWeise/distributedComputingExamples/tree/master/xml/xml) themselves as well as [examples for XML processing with Java](http://github.com/thomasWeise/distributedComputingExamples/tree/master/xml/java).

#### 2.3.3. Web Services

We then discuss [Web Services](https://en.wikipedia.org/wiki/Web_service). Web services are the basic foundation of many distributed enterprise computing systems and [service-oriented architectures](https://en.wikipedia.org/wiki/Service-oriented_architecture). They are invoked using the [XML](http://github.com/thomasWeise/distributedComputingExamples/tree/master/xml/)-based [SOAP](https://en.wikipedia.org/wiki/SOAP) protocol usually over [HTTP](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol). Their interface and provided functionality is described via the Web Service Description Language ([WSDL](https://en.wikipedia.org/wiki/Web_Services_Description_Language)), another XML standard. Based on what we already know, we could now send XML data to a Java Servlet via HTTP-POST, parse this data with these Java XML processing technologies, use the same technologies to generate an output XML document, and send this one back as the response of the Java Servlet. Actually, we could even use JavaServer Pages for this purpose. However, there again is a simpler way: We can build services as simple Java objects and publish them to the [Apache Axis2/Java](http://axis.apache.org/axis2/java/core/) server. The server will make them accessible via SOAP and automatically generate WSDL descriptions. These can then be used to generate proxy objects for the client side using, e.g., [Maven](http://maven.apache.org/). We investigate this technology on [several examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/webServices/).

#### 2.3.4. JSON RPC

[JSON RPC](https://en.wikipedia.org/wiki/JSON-RPC) is another remote procedure call ([RPC](https://en.wikipedia.org/wiki/Remote_procedure_call)) approach (specified [here](http://json-rpc.org/)) where the exchanged data structures are encoded in the JavaScript Object Notation ([JSON](https://en.wikipedia.org/wiki/JSON)). The data is exchanged via either [HTTP](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol) or [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol). JSON RCPs are similar to web services, but designed to be more light-weighted. We again discuss several [examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/jsonRPC/).

### 2.4. Large-Scale Distributed Computations and Data Processing (as used in Data Mining and Engineering)

As last important use case for distributed computing, we consider how large-scale distributed computations can be realized. Such computations are needed in many [scenarios](http://www.hadoopilluminated.com/hadoop_illuminated/Hadoop_Use_Cases.html), ranging from simulations in engineering to data mining and processing in enterprises.

#### 2.4.1. Message Passing Interface: Processes that Communicate Frequently

We now focus on how the computing power of massive clusters can be utilized for large-scale scientific and engineering computations. Such large computations or simulations are often divided into several smaller sub-problems. These smaller problems are then solved *cooperatively* by multiple threads or processes in parallel. This often involves the exchange of messages at regular time intervals between processes working on closely related sub-problems. Obviously, Web Services, Java Servlets, or even just Java and the HTTP protocol, would be the wrong technologies for that: For large-scale computations, we want to get as efficient as possible with as little overhead as possible. This especially concerns communication, which is very expensive and the [limiting factor](https://en.wikipedia.org/wiki/Amdahl's_law) for the speedup we can achieve with distribution. We want to exchange primitive data types efficiently and we want to use communication paradigms not supported by HTTP/TCP, such as broadcasts, multicasts, and asynchronous communication. For this, an implementation of the Message Passing Interface ([MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface)) would be the method of choice. We explore this technology based on [several examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/mpi/) in the C programming language.

#### 2.4.2. MapReduce with Hadoop: Large-Scale Data Processing

In a final step we discuss a technology which combines the ability to create large-scale distributed computations (from the MPI world) with the rich tool support of the Java ecosystem: [MapReduce](https://en.wikipedia.org/wiki/MapReduce) with [Apache](http://hadoop.apache.org/) [Hadoop](https://en.wikipedia.org/wiki/Apache_Hadoop). MPI is the technology of choice if communication is expensive and the bottleneck of our application, frequent communication is required between processes solving related sub-problems, the available hardware is homogenous, processes need to be organized in groups or topological structures to make efficient use of collective communication to achieve high performance, the size of data that needs to be transmitted is smaller in comparison to runtime of computations, and when we do not need to worry much about exchanging data with a heterogeneous distributed application environment. Hadoop, on the other hand, covers use cases where communication is not the bottleneck, because computation takes much longer than communication (think Machine Learning), when the environment is heterogeneous, processes do not need to be organized in a special way and the division of tasks into sub-problems can be done efficiently by just slicing the input data into equal-sized pieces, where sub-problems have batch job character, where data is unstructured (e.g., text) and potentially huge (eating away the advantages of MPI-style communication), or where data comes from and results must be pushed back to other applications in the environment, say to HTTP/Java Servlet/Web Service stacks. Our [Hadoop examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/hadoop/) focus on the [MapReduce](https://en.wikipedia.org/wiki/MapReduce) pattern (which is a tiny little bit similar to scatter/gather/reduce in MPI, just for the scenario described above).

### 2.5. Summary

All in all, this course will give you a rough understanding of the dominant technologies in different fields of distributed computing, from dynamic websites over company-internal distributed application systems, to distributed engineering and scientific computations. Each field is explored with hands-on examples and you get to test and play with several example technologies.


## 3. Software Requirements

For each example, I explicitly list the required software and discuss how it can be obtained and installed. Here I give an overview over these software components.

### 3.1. Java JDK

Most of the examples I provide are written in the Java programming language and can run under arbitrary systems, given that Java is installed. In order to compile them, you need a [Java JDK](https://en.wikipedia.org/wiki/Java_Development_Kit) installed. My examples require [Java 7](https://en.wikipedia.org/wiki/Java_version_history#Java_SE_7) or later.

Under Windows, you need to download and install Java from the [Oracle website](http://www.oracle.com/technetwork/java/javase/downloads/index.html).

Under Linux, you would do `sudo apt-get install openjdk-7-jdk` (where you can replace `7` with any later version, such as `8`, if you like)

### 3.2. Maven

Several of my Java examples are built with [Maven](https://en.wikipedia.org/wiki/Apache_Maven). All of these examples have a `pom.xml` file in their root folder. In order to build them, you thus need to install Maven.

Under Windows, you need to download and install Maven from the [Apache website](http://maven.apache.org/download.cgi).

Under Linux, you would do `sudo apt-get install maven`.

If you are using Eclipse (see below), you do not need to install Maven as it is already integrated into Eclipse.

### 3.3. Eclipse 

I recommend [Eclipse](http://www.eclipse.org) as developer environment for all the Java examples in this repository. Each Java example actually comes already with an Eclipse `.project` file and with Eclipse `.settings`. Eclipse integrates both Maven and git. This means you can clone this repository from within Eclipse and directly import the Jave projects during this process. If you then right-click the Maven projects and choosen `Maven` -> `Update Project...`, Eclipse will also download and use all required libraries and dependencies as specified by the Maven `pom.xml` for you.

You can download Eclipse from the [Eclipse website](http://www.eclipse.org). I recommend to use at least Eclipse Mars.1 for its excellent Maven and git support.

### 3.4. GlassFish Server

For running some of the [Java Servlets](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/) and [JavaServer Pages](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServerPages/) examples, you need to download the [GlassFish Server](http://javaee.github.io/glassfish) from the corresponding [download website](http://javaee.github.io/glassfish/download). I recommend using at least GlassFish 4.1.2.

### 3.5. Apache Axis2/Java

For running the [Web Service](http://github.com/thomasWeise/distributedComputingExamples/tree/master/webServices/) examples, you will need to download [Apache Axis2/Java](http://axis.apache.org/axis2/java/core/) from the corresponding [download page](http://axis.apache.org/axis2/java/core/download.html). I recommend using at least Axis2 1.7.3.

### 3.6. GCC

In order to compile the examples written in the C programming language (such as the `C`-based [sockets examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/sockets/c)), you will need a C compiler such as GCC. Under Linux, it should normally be already installed and can otherwise be installed via `sudo apt-get install gcc`. Under Windows, you will need to install [MinGW](http://mingw.org/), usually via the [web installer](https://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download).

### 3.7. Cross-Compiling for Windows under Linux with GCC

Several of the C examples come for Windows or Linux. GCC allows you to cross-compile, i.e., if you are using Linux, you can compile C programs for Windows. For this purpose, you would first install `sudo apt-get install gcc-mingw-w64-i686` and then can use the command `gcc-mingw-w64-i686` in the same way you would use `gcc` under MinGW.

### 3.8. MPICH

In order to build and compile our [examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/mpi/) for using the Message Passing Interface (MPI), we need an [MPI implementation](https://en.wikipedia.org/wiki/Message_Passing_Interface#Implementations). We choose [MPICH](https://en.wikipedia.org/wiki/MPICH).

Under Linux, you can install the required files via `sudo apt-get install mpich libmpich-dev`.

### 3.9. Hadoop (also `ssh` and `rsync`)

In order to test our [Hadoop examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/hadoop/), we now need to set up a single-node Hadoop cluster. We therefore follow the guide given at [http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html). We need to install pre-requisits such as `ssh` and `rsync`. In the [Hadoop example readme](http://github.com/thomasWeise/distributedComputingExamples/tree/master/hadoop/README.md), we provide the installation guide for Hadoop 2.7.2 Linux / Ubuntu. It boils down to downloading and installing Hadoop from one of the mirrors provided at [http://www.apache.org/dyn/closer.cgi/hadoop/common/](http://www.apache.org/dyn/closer.cgi/hadoop/common/), plus following the guidelines of the linked tutorial.

## 4. Licensing

This work has purely educational purposes. Besides everything mentioned below, for anything in this repository, I impose one additional licensing condition: The code must never be used for anything which might violate the laws of Germany, China, or the USA. This also holds for any other file or resource provided here.

The examples in this repository are licensed under the [GNU GENERAL PUBLIC LICENSE Version 3, 29 June 2007](http://github.com/thomasWeise/distributedComputingExamples/tree/master/LICENSE), with the following exceptions:

### 4.1. Exception: Stand-Alone JSPs/JavaServlets

Everything in the directories [/javaServerPages/standAloneJSPsWithJetty](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServerPages/standAloneJSPsWithJetty) and [/javaServlets/proxy](http://github.com/thomasWeise/distributedComputingExamples/tree/master/javaServlets/proxy) is licensed under the [Apache License v2.0](http://www.opensource.org/licenses/apache2.0.php) and are partially derived from project [embedded-jetty-jsp](https://github.com/jetty-project/embedded-jetty-jsp) with copyright (c) 1995-2013 Mort Bay Consulting Pty. Ltd.

### 4.2. Exception: Hadoop Examples

Some of the [Hadoop examples](http://github.com/thomasWeise/distributedComputingExamples/tree/master/hadoop/) take some inspiration from the [maven-hadoop-java-wordcount-template](https://github.com/H4ml3t/maven-hadoop-java-wordcount-template) by [H3ml3t](https://github.com/H4ml3t), for which no licensing information is provided. The examples, are entirely differently in several ways, for instance in the way we build fat jars. Anyway, this original project is nicely described in [this blog entry](https://nosqlnocry.wordpress.com/2015/03/13/hadoop-mapreduce-wordcount-example-in-java-introduction-to-hadoop-job/).

Furthermore, the our [Hadoop word](http://github.com/thomasWeise/distributedComputingExamples/tree/master/hadoop/wordCount) is based on the well-known [word counting example](http://wiki.apache.org/hadoop/WordCount) for Hadoop's map reduce functionality. It is based on the version by provided Luca Menichetti [meniluca@gmail.com](mailto:meniluca@gmail.com) under the GNU General Public License version 2."
kon3ktor/complete-java-course,master,92,85,2020-01-28T21:07:48Z,102,2,Zero to Hero - Master Java with practical examples,,
kiat/OOP-Design-Patterns,master,85,46,2018-05-31T02:50:35Z,7228,0, OOP Design Patterns Code Examples,abstract-factory-pattern behavioral-patterns checkstyle command-pattern design-pattern design-patterns design-patterns-implemented-in-java design-patterns-java iterator-pattern junit object-oriented-programming observer-pattern singleton-pattern strategy-pattern structural-patterns template-method template-method-pattern template-pattern visitor-pattern,"

# Code Examples about Design Patterns  

In this Repository we collect example design patterns in **Java** and **C++**.


* Directory Java/ includes Java examples

* Directory C++/ includes C++ examples

## Java Examples

* We use [**Apache Maven**](https://maven.apache.org/) to build Java Examples.
* We use [**Junit**](junit.org) for unit test.
* We use [**findbugs**](http://findbugs.sourceforge.net/) for static code analysis. We use the [maven plugin for findbugs](https://gleclaire.github.io/findbugs-maven-plugin/)
* We use [**checkstyle**](http://checkstyle.sourceforge.net/) to check our code style. We use the [maven plugin for checkstyle](https://maven.apache.org/plugins/maven-checkstyle-plugin/)


## C++ Examples

We use CMake to build C++ code.


* Use Smart pointer in C++
* Use C++14
* Use one of the compiler [**LLvm**](https://llvm.org/) -  [**clang**](https://clang.llvm.org/),
'Gnu Compiler Collection' [**gcc**](https://gcc.gnu.org/onlinedocs/gcc/) or 'Gnu C Compiler' g++, and enable warning flags while compiling your code
* Check Memory Leaks using [**valgrind**](http://valgrind.org/)

```bash
valgrind --tool=memcheck <your_app> <your_apps_params>
```




-----



# Recommended Online Sources to learn Software Design Patterns


## Books
-----

1. [**Design Patterns: Elements of Reusable Object‐Oriented Software**](https://www.amazon.com/dp/0201633612) By Erich Gamma, Richard Helm, Ralph Johnson and John Vlissides Addison‐Wesley,1994

2. [**Head First Design Patterns**](https://www.amazon.com/dp/0596007124/) By Eric Freeman, Elisabeth Robson, Bert Bates, Kathy Sierra O’Reilly, 2004

3. [**Design Patterns Explained: A New Perspective on Object Oriented Design, (Software Patterns)**](https://www.amazon.com/dp/0321247140) by Alan Shalloway, James R. Trott, Addison Wesley, 2004 ISBN-13: 978-0321247148

4.  [**Pattern-Oriented Software Architecture Volume 1: A System of Patterns**]( https://www.amazon.com/Pattern-Oriented-Software-Architecture-System-Patterns/dp/0471958697) by Frank Buschmann, Regine Meunier, Hans Rohnert, Peter Sommerlad, Michael Stal. 1996, ISBN-10: 0471958697

5. [**Design Patterns
Explained Simply**](https://sourcemaking.com/design-patterns-ebook)

----

## Websites
1. https://refactoring.guru/design-patterns/catalog
List of Design Patterns with description and Example code. 

2. http://java-design-patterns.com
List of Software Design Patterns with examples in Java
http://java-design-patterns.com/patterns/


3. http://www.oodesign.com/
This website is an older websites. It provides a good list of the main
design patterns, description of them, examples and their UML diagrams.


4. https://sourcemaking.com/design_patterns
A professional Website with good different examples. If you are looking for different examples for each patterns than the classic examples. This site is a good source.

5. List of Software Design Patterns on Wikipedia 
https://en.wikipedia.org/wiki/Category:Software_design_patterns

---
## MOOCs

1. [Design Patterns by University of Alberta](https://www.coursera.org/learn/design-patterns/), this is part
[Software Design Architecture Specialization](https://www.coursera.org/specializations/software-design-architecture)
2. [Object-Oriented Java](https://www.coursera.org/learn/object-oriented-java)
3. [Software Design Abstraction](https://www.coursera.org/learn/software-design-abstraction)

---
## Youtube


1. [Videos by Christopher Okhravi describing examples ](https://www.youtube.com/playlist?list=PLrhzvIcii6GNjpARdnO4ueTUAVR9eMBpc) form [**Head First Design Patterns Book**](https://www.amazon.com/dp/0596007124/)

2. If you program C++, I highly Recommend Videos by Bjarne Stroustrup. For examples on [CppCon](https://www.youtube.com/channel/UCMlGfpWw-RUdWX_JbLCukXg), CppCon 2017, [Keynotes by Bjarne Stroustrup](https://www.youtube.com/watch?v=fX2W3nNjJIo&list=PLHTh1InhhwT6bwIpRk0ZbCA0N2p1taxd6) . (BTW, this line should be on top of top of this list :) )
"
aled/jsi-examples,master,45,28,2012-01-12T08:22:14Z,166,0,Simple examples of how to use the JSI library,,"jsi-examples
============

Simple examples of how to use the JSI library. The following commands will run the examples:

    git clone https://github.com/aled/jsi-examples.git
    cd jsi-examples
    mvn package
    cd target
    unzip jsi-examples-1.1.0-SNAPSHOT-jar-with-dependencies.jar
    java -cp .:./classes net.sf.jsi.examples.Contains
    java -cp .:./classes net.sf.jsi.examples.NearestN
"
b3rnoulli/rsocket-examples,master,59,25,2019-05-21T10:35:41Z,197,0,RSocket examples from article series,,"# RSocket Examples


## Introduction

This repository contains examples used in the series of articles about RSocket. The articles are available here: https://medium.com/@b3rnoulli/reactive-service-to-service-communication-with-rsocket-introduction-5d64e5b6909

It consist of following modules:
- interaction-model
- load-balancing
- resumability
- rpc
- spring-boot-requester
- spring-boot-responder

Each module address different aspect of the protocol, more detailed description is available in the module directories.

## Build

The modules use ```gradle``` as a build tool. In order to crate executable jars please invoke
`./gradlew clean build` on the root directory. Each module can be built individually using the same command, 
but executed in the particular module directory.

Please notice that examples were designed to run inside your IDE.
"
shekhargulati/day12-face-detection,master,93,110,2013-11-09T13:12:15Z,504,0,OpenCV Java example,,"day12-face-detection
====================

OpenCV Java example.
"
peter-lawrey/Performance-Examples,master,56,25,2012-11-30T11:49:18Z,158,1,Workshop Examples,,"Performance-Examples
===================="
bbende/nifi-streaming-examples,master,55,32,2016-02-01T18:06:51Z,1662,0,Collection of examples integrating NiFi with stream process frameworks.,,"# Apache NiFi Streaming Examples
Collection of examples integrating NiFi with stream process frameworks.

## Initial Setup

* Download the latest [Apache NiFi release](https://nifi.apache.org/download.html)

* Extract the tar and create two instances of NiFi:
  <pre><code>  
    tar xzvf nifi-1.0.0-bin.tar.gz
    mv nifi-1.0.0 nifi-edge
    tar xzvf nifi-1.0.0-bin.tar.gz
    mv nifi-1.0.0 nifi-core
  </code></pre>
* Configure the edge instance by editing nifi-edge/conf/nifi.properties and setting the following properties:
  <pre><code>  
    nifi.remote.input.socket.port=7088
    nifi.remote.input.secure=false
    nifi.web.http.port=7080
  </code></pre>
* Configure the core instance by editing nifi-core/conf/nifi.properties and setting the following properties:
  <pre><code> 
    nifi.remote.input.socket.port=8088
    nifi.remote.input.secure=false
    nifi.web.http.port=8080
  </code></pre> 
* Start both instances
  <pre><code> 
    ./nifi-core/bin/nifi.sh start
    ./nifi-edge/bin/nifi.sh start
  </code></pre>
* Open the UI for both instances in a browser
  <pre><code> 
    http://localhost:7080/nifi/
    http://localhost:8080/nifi/
  </code></pre>
* Setup initial dictionary files
  <pre><code>
    mkdir nifi-edge/data
    mkdir nifi-edge/data/dictionary
    mkdir nifi-core/data
    mkdir nifi-core/data/dictionary
  </code></pre>
* In each of the above dictionary directories, create a file called levels.txt with the content:
<pre><code>
    ERROR
    WARN
</code></pre>

* Import nifi-streaming-examples/templates/nifi-log-example-edge.xml into the the edge instance (http://localhost:7080/nifi)

* Import nifi-streaming-examples/templates/nifi-log-example-core.xml into the the core instance (http://localhost:8080/nifi)

* Start everything on the core instance (http://localhost:8080/nifi)
![Image](https://github.com/bbende/nifi-streaming-examples/blob/master/screens/nifi-core.png?raw=true)

* To start sending logs, starting everything on the edge instance (http://localhost:8080/nifi) EXCEPT the TailFile processor, the ""Generate Test Logs"" process group will send fake log messages
![Image](https://github.com/bbende/nifi-streaming-examples/blob/master/screens/nifi-edge.png?raw=true)

* To tail a real file, stop the ""Generate Test Logs"" process group, configure TailFile to point to your log file of choice, and start the TailFile processor

## Flink - WindowLogLevelCount - Setup
* For local testing, run a standalone Flink streaming job
<pre><code>
  cd nifi-flink-examples
  mvn clean package -PWindowLogLevelCount
  java -jar target/nifi-flink-examples-0.0.1-SNAPSHOT.jar
</code></pre>

## Apex - LogLevelApplicationRunner - Setup

* For local testing, run LogLevelApplicationRunner from your favorite IDE:
<pre><code>
  nifi-apex-examples/src/test/java/nifi/apex/examples/logs/LogLevelApplicationRunner.java
</code></pre>

## Storm - LogLevelCountTopology - Setup

* For local testing, run a standalone local Storm topology
<pre><code>
  cd nifi-storm-examples
  mvn clean package -PLogLevelCountTopology
  java -jar target/nifi-storm-examples-0.0.1-SNAPSHOT.jar
</code></pre>
"
line/line-fido2-server,main,489,84,2021-07-22T00:44:01Z,13885,16,FIDO2(WebAuthn) server officially certified by FIDO Alliance and Relying Party examples.,example fido2 java passwordless relying-party security spring-boot webauthn,"# LINE FIDO2 SERVER

![Stars](https://img.shields.io/github/stars/line/line-fido2-server.svg?style=social)
![Repo Size](https://img.shields.io/github/repo-size/line/line-fido2-server)
![License Apache-2.0](https://img.shields.io/github/license/line/line-fido2-server)
![Top Language](https://img.shields.io/github/languages/top/line/line-fido2-server)
![Spring Boot](https://img.shields.io/badge/Spring%20Boot-2.4.3-green)
![Java version](https://img.shields.io/badge/Java-1.8-green)
![Data base](https://img.shields.io/badge/DataBase-MySQL%2FH2%2FRedis-blue)
![Last Commit](https://img.shields.io/github/last-commit/line/line-fido2-server)
> **FIDO2(WebAuthn) Server officially certified by FIDO Alliance**

<img src=""images/fido2_certificate.jpg"" height=""500"" align=""center"" alt=""""/>

## Overview



FIDO (Fast IDentity Online) is an open standard for online authentication. It is designed to solve the password problems stemming from a lot of security problems as we are suffering today.

Rather than relying on symmetric credentials (like passwords or PINs, typically which is a knowledge-based factor), FIDO is based on a public-key cryptography algorithm that is based on asymmetric credentials.

Simply, the device generates the key pair and stores the private key within the secure area, and sends the corresponding public key (as the name implies it is okay to be public) to the server.

Then, if the authentication is needed, the server sends challenges to the device and the device generates the digital signature with the private key and sends it to the server.

Finally, the server can validate the signature with the registered public key.

### What is FIDO2
FIDO2 is an improved standard for use on the web and other platforms as well as mobile. Various web browsers and OS platforms currently support the FIDO2 standard API.

Basically, FIDO2 has the following operations - Registration, Authentication.

#### Registration
- The user is prompted to choose an available FIDO authenticator that matches the online service’s acceptance policy.
- User unlocks the FIDO authenticator using a fingerprint reader, a button on a second–factor device, securely–entered PIN, or other methods.
- The user’s device creates a new public/private key pair unique for the local device, online service, and user’s account.
- The public key is sent to the online service and associated with the user’s account. The private key and any information about the local authentication method (such as biometric measurements or templates) never leave the local device.

#### Authentication
- Online service challenges the user to log in with a previously registered device that matches the service’s acceptance policy.
- User unlocks the FIDO authenticator using the same method as at Registration time.
- The device uses the user’s account identifier provided by the service to select the correct key and sign the service’s challenge.
- The client device sends the signed challenge back to the service, which verifies it with the stored public key and lets the user log in.


## Screenshots
### Chrome on Mac with TouchId
<img src=""images/chrome_mac_touchid.gif"" width=""600"" align=""center"" alt=""registration_flow""/>

### Chrome on Mac with Secret Key (2FA)
<img src=""images/chrome_mac_secretkey.gif"" width=""600"" align=""center"" alt=""registration_flow""/>

### Chrome on Android with Fingerprint (Reg)
<img src=""images/chrome_android_fingerprint_reg.GIF"" height=""500"" align=""center"" alt=""registration_flow""/>

### Chrome on Android with Fingerprint (Auth)
<img src=""images/chrome_android_fingerprint_auth.GIF"" height=""500"" align=""center"" alt=""registration_flow""/>

## Modules
- server: The FIDO2 server implementation conforming to the FIDO2 standard
- common: FIDO2 related common models
- rp-server: The sample application with a FIDO2 RP implementation
- spring-boot-stater: The spring-boot-starter version of the LINE FIDO2 server application that can be easily integrated into a Spring Boot environment

## Features
- Supported attestation types
  - Basic
  - Self
  - Attestation CA (a.k.a Privacy CA)
  - None
  - Anonymization CA
- Supported attestation formats
  - Packed (FIDO2)
  - Tpm (Windows10 devices)
  - Android key attestation
  - Android SafetyNet (Any Android devices running 7+)
  - FIDO U2F (Legacy U2F authenticators)
  - Apple Anonymous
  - None
- Metadata service integration
  - FIDO MDSv2

## How to run
You need to run the FIDO2 server and RP Server first.

If you want to integrate your own RP Server, please implement APIs by referring to the sample codes. Regarding client sides, you may implement the web app for communicating with the RP server.

We also provide our server in the form of a spring boot starter.
Check out the spring-boot-starter directory.

### Manual

```bash
# Start RP Server
cd rpserver
./gradlew bootRun

# Start FIDO2 Server or Line-fido2-spring-boot Demo
cd server
./gradlew bootRun

cd spring-boot-starter/line-fido2-spring-boot-demo
./gradlew bootRun
```
### Docker for demo
If the [Docker environment is configured](https://docs.docker.com/get-started/), You can easily run applications with docker-compose.

```bash
# Start both RP Server and FIDO2 Server
docker-compose up
```

After running the applications, you can open the test page at the link below.

**http://localhost:8080/**

### Local DB
FIDO2 Server running on local environments uses h2 as an embedded DB. This needs to be replaced with commercial standalone DB for other environments such as staging, beta or real.

In the case of the local environment, you can use the h2 console. Add the following path /h2-console to the fido server URL to access the h2 web console.

e.g., http://localhost:8081/h2-console


If the below error occurs while logging in to h2-console,
```
No suitable driver found for 08001/0
```
try to remove or comment out *logbook-spring-boot-starter* from build.gradle.

```
implementation('org.zalando:logbook-spring-boot-starter:1.8.1')
```

### Lombok
This project utilizes Lombok to reduce implementing getter/setter/constructors. You need the Lombok plugin to build with IntelliJ and Eclipse.
See the following web pages to get information.

https://projectlombok.org/

### Issues
- If data.sql doesn't work well in an IntelliJ environment,
  try commenting on this part in build.gradle.
```groovy
jar {
  processResources {
    exclude(""**/*.sql"")
  }
}
```
- If Fido2StarterDemoApplication doesn't work well, try commenting on this part in build.gradle.
```groovy
task dockerBuild() {
  jar.enabled = false
  dependsOn(bootJar)
}
```
## API Guides
After running the applications, you can view API guide documents at the link below.

### Spring REST Docs
- server: http://localhost:8081/docs/api-guide.html

### Swagger UI
- rpserver: http://localhost:8080/swagger-ui.html
- server: http://localhost:8081/swagger-ui.html

## References
`LINE Engineering Blogs`
- [FIDO at LINE: A First Step to a World Without Passwords](https://engineering.linecorp.com/en/blog/fido-at-line/)
- [FIDO at LINE: FIDO2 server as an open-source project](https://engineering.linecorp.com/en/blog/fido-at-line-fido2-server-opensource/)

`LINE DevDay Videos`
- [Open source contribution Starting with LINE FIDO2 Server](https://youtu.be/xKzXi5ic4Do)
- [Strong customer authentication & biometrics using FIDO](https://youtu.be/S1y9wFh7_dc)
- [Cross Platform Mobile Security At LINE](https://youtu.be/4288h-EamTU)
- [Secure LINE login with biometric key replacing password](https://youtu.be/vCAu-y-iwyw)

`Internal`
- [Sequence Diagram](https://github.com/line/line-fido2-server/wiki/Sequence-diagrams)

`External`
- [FIDO2: WebAuthn & CTAP](https://fidoalliance.org/fido2/)
- [WebAuthn Level 2](https://www.w3.org/TR/2021/REC-webauthn-2-20210408/)
- [CTAP v2.1](https://fidoalliance.org/specs/fido-v2.1-ps-20210615/fido-client-to-authenticator-protocol-v2.1-ps-20210615.html)
"
GDG-Korea/HelloRx,master,108,27,2015-01-26T14:47:14Z,3379,0,RxAndroid (RxJava) examples ,,"# HelloRx
RxAndroid examples
"
zonbeka/Cplex-Examples,master,26,35,2014-06-09T19:12:14Z,1256,1,,,"examples
========
"
pcgrenier/nifi-examples,master,33,30,2015-02-06T02:54:27Z,14043,0,Apache Nifi Examples by http://www.nifi.rocks,,
dasniko/keycloak-extensions-demo,main,247,89,2021-11-17T14:52:13Z,390,0,"Demos, examples and playground for Keycloak extensions, providers, SPI implementations, etc.",examples extensions iam java keycloak oidc spi sso,"# Keycloak Extensions Demo

Demos, examples and playground for [Keycloak](https://www.keycloak.org) extensions, providers, SPI implementations, etc.

[![CI build](https://github.com/dasniko/keycloak-extensions-demo/actions/workflows/maven.yml/badge.svg)](https://github.com/dasniko/keycloak-extensions-demo/actions/workflows/maven.yml)
![](https://img.shields.io/github/license/dasniko/keycloak-extensions-demo?label=License)
![](https://img.shields.io/badge/Keycloak-24.0-blue)

This repository contains the following extensions, and probably (most likely 😉) more...

## Keycloak User Storage Provider

[Flintstones](./flintstones-userprovider) - Demo user storage provider, providing some members of the Flintstones family, through an HTTP-base API and in writable mode, also possible to add new users.

## Keycloak Authenticators

[MagicLink Authenticator](./magiclink) - demo authenticator which sends a magic link to the user with which the user can login without needing to provide a password.

[Captcha Authenticator](./captcha) - demo authenticator in which the user needs to solve a math task and submit the result, before successful authentication.

[MFA Authenticator](./mfa-authenticator) - very simple(!!!) demo authenticator which prints a generated OTP to stdout.

[Conditional Authenticator](./conditional-headers-authenticator) - conditions for authenticators which will decide upon
* a header and given value (or negated value) if `true`/`false`
* a authentication session note and given value (or negated value) if `true`/`false`

## Keycloak Event Listeners

### Session Restrictor

[Highlander](./event-listener) - demo event listener for Keycloak, allowing only the last session to survive (_Highlander mode - there must only be one!_), if a user logs in on multiple browsers/devices.
_(This was for long time not possible in Keycloak ootb, thus this event listener; since KC v19(?) this is natively supported.)_

### Event Forwarder

[AWS SNS Publisher](./event-listener) - demo event listener for Keycloak, simply forwarding/publishing all events to an AWS SNS topic.

### User Attribute Updater

[LastLoginTime](./event-listener) - demo event listener for Keycloak, storing the most recent login time in an user attribute.

## Custom Keycloak OIDC protocol token mapper

[LuckyNumberMapper](./tokenmapper) - example custom token mapper for Keycloak using the OIDC protocol.

## Keycloak REST endpoint/resource extension

[Custom Rest Resource](./rest-endpoint) - demo implementation for custom REST resources within Keycloak, public (unauthenticated) and secured (authenticated) endpoints.

## Custom Required Action

[MobileNumberRequiredAction](./requiredaction) - example which enforces the user to update its mobile phone number, if not already set.

## Custom Email Template & Sender Provider

[Email Provider](./email) for custom templates in JSON format (no actual emal, but for processing through external/3rd party services) and sending emails via a vendor specific (here: AWS SES) protocol, instead of SMTP.

## Demo Docker Compose Environment

There's a `docker-compose.yml` definition to use with Docker Compose. No Warranties, use at your own risk and fortune, I'm not giving any support to this!

Build and run all the stuff with:

    & ./mvnw clean package -DskipTests && docker compose up
"
techatspree/jbosscc-as7-examples,master,36,45,2012-03-01T19:05:14Z,674,21,JBoss AS 7 Example Projects,,
kittylyst/javanut6-examples,master,40,34,2015-02-11T23:00:43Z,137,1,Example Code for Java in a Nutshell (6th Edition),,"# javanut6-examples
Example Code for Java in a Nutshell (6th Edition)

This is the example programs and samples from Java in a Nutshell (6th Edition) 
written by Ben Evans and published by O'Reilly.

The initial code drop is incomplete - rather than spending a lot of time tidying
up the code from how it was actually written (& in several cases, the code
examples dated back to an older version of the text and have to be manually
extracted from the book text), I felt it better to get something out there and
in use, and add to it a bit at a time.

If you have specific requests, or suggestions for improvement, or possible
examples you'd like to see, please leave a Github issue. Pull requests are
also very welcome, but please ensure that they are formatted to Netbeans
default Java style before sending.

Special thanks to James Gough for his contributions to the Ch09 examples, and to
the other members of the London JSR 310 project team for making this API happen
in time for JDK 8.

Thanks,

-Ben (@kittylyst)
"
gstreamer-java/gst1-java-examples,master,53,37,2015-09-20T16:35:10Z,155,2,Repository for examples of using gst1-java-core,,"GStreamer Java examples
=======================

This repository contains a series of example projects for using
[GStreamer 1.x][gstreamer] with Java via the [GStreamer Java][gstreamer-java]
libraries, including [gst1-java-core][gst1-core] and extensions.

The code steps in each project source file are documented. Any questions, please
use the [mailing list][gstreamer-java-group].

## Requirements

All examples are self-contained Gradle projects. They should work inside your IDE
or via `./gradlew run` on the command line.

All the examples require an [installation of GStreamer][gstreamer-download] itself.
Windows users installing GStreamer should select the complete profile, rather than
the typical one.

Most examples work with JDK 8+. The JavaFX integration example requires JDK 11+
(and uses JavaFX 15).

## Examples

Inside each example there is an identical `Utils.java` file that contains some
useful code for setting up native paths for an installed version of GStreamer.
This code, and all the example code (aside from some files in the archive), is
free to adapt for your own usage.

### Getting started

- **BasicPipeline** : getting started running a video test source into a GStreamer
output window.

### Desktop (Swing / JavaFX)

- **SwingCamera** : using a camera (or test source) inside a Swing application,
using `gst1-java-swing`.
- **SwingPlayer** : a simple media player with Swing UI, including file selection,
playback controls, seeking and volume meters.
- **FXCamera** : using a camera (or test source) inside a JavaFX application,
using `gst1-java-fx`.
- **FXPlayer** : a simple media player with JavaFX UI, including file selection,
playback controls, seeking and volume meters.

### Server / Internet

- **HLS** : using HTTP Live Streaming to stream live video with Java2D rendered
overlay to browser using Javalin framework.
- **WebRTCSendRecv** : example of sending and receiving via WebRTC using the test
page at https://webrtc.nirbheek.in This is the test server used in upstream
GStreamer examples. You may need to configure permissions in the browser to
always allow audio for that site. You need to pass in the session ID from the
page on the CLI. If running in the terminal via Gradle, it is recommended to
use `./gradlew --console=plain run`.

### Miscellaneous

- **BufferProbe** : using a buffer probe to draw an animation on top of the video
stream using Java2D.
- **Controllers** : configuring controllers to control element properties (ported
from an upstream C example).

### Archive

Inside the archive folder are all the previously available examples, some of which
have not yet been adapted into self-contained example projects.

[gstreamer]: https://gstreamer.freedesktop.org/
[gstreamer-download]: https://gstreamer.freedesktop.org/download/
[gstreamer-java]: https://github.com/gstreamer-java
[gstreamer-java-group]: https://groups.google.com/forum/#!forum/gstreamer-java
[gst1-core]: https://github.com/gstreamer-java/gst1-java-core
"
Simsilica/Examples,master,25,9,2016-03-01T08:19:56Z,3655,3,"Example applications for various Simsilica libraries, singly or in combination.",,"# Examples
Example applications for various Simsilica libraries, singly or in combination.

## simple-jme
A simple JME ""blue cube"" example using a gradle build file and an asset project setup.

To run: `gradle run`

## zay-es-net-basic
A non-UI, non-graphical, example of using the zay-es-net networking layer for zay-es.

To run the server: `gradle runServer`

To run the client: `gradle runClient`

## network-basic
A base template project for network games.  Provides a simple main menu that includes
options for hosting a local game or connecting to a remote game.  Sets up the client/server
code but otherwise provides absolutely no game logic.  A blank canvas ready for 'game'.

To run: `gradle run`

## sim-eth-basic
A simple space ships 'game' built on JME, Lemur, SpiderMonkey, and the SimEthereal real-time
object synching library.

To run: `gradle run`

## sim-eth-es
A simple space ships 'game' built on JME, Lemur, Zay-ES, Zay-ES-Net, SpiderMonkey, and the SimEthereal real-time
object synching library.  This modifies the sim-eth-basic to be ES based using the Zay-ES library.

To run: `gradle run`
"
amitrp/spring-examples,main,30,30,2021-07-26T21:35:15Z,157,1,Contains Spring and Spring Boot Code Samples used in https://www.amitph.com/ tutorials,hibernate jpa-hibernate spring spring-boot spring-data-jdbc spring-data-jpa spring-data-rest spring-mvc,"# Spring Tutorials and Examples
Examples of using Spring Framework and Spring Boot
These examples are part of Spring & Spring Boot Tutorials on https://www.amitph.com/

## List of few relevant tutorials
- [Spring Data REST CRUD Example](https://www.amitph.com/spring-data-rest-example/)
- [Spring Data REST Projections and Excerpts](https://www.amitph.com/spring-data-rest-projections-and-excerpts/)
- [Spring Data JDBC Tutorial with Examples](https://www.amitph.com/introduction-spring-data-jdbc/)
- [Unit Tests for Spring Data JDBC Repositories](https://www.amitph.com/testing-spring-data-jdbc/)
- [How to Write a non-web Application with Spring Boot](https://www.amitph.com/non-web-application-spring-boot/)
- [CRUD REST Service With Spring Boot, Hibernate, and JPA](https://www.amitph.com/spring-boot-crud-hibernate-jpa/)
- [Understand Http PUT vs PATCH with Examples](https://www.amitph.com/http-put-vs-patch/)
- [Enable Spring Boot ApplicationStartup Metrics to Diagnose Slow Startup](https://www.amitph.com/spring-boot-startup-monitoring/)
- [Scheduled Tasks in Spring with @Scheduled](https://www.amitph.com/scheduled-tasks-in-spring/)
- [Spring Data JPA Composite Key with @EmbeddedId](https://www.amitph.com/spring-data-jpa-embeddedid/) 
- [Spring Data JPA find by @EmbeddedId Partially](https://www.amitph.com/spring-data-jpa-find-by-embeddedid-partially/)
- [Spring Boot Actuator with Spring Boot 2](https://www.amitph.com/spring-boot-actuator-spring-boot-2/)
- [Custom Health Check in Spring Boot Actuator](https://www.amitph.com/custom-health-check-spring-boot-actuator/)
- [Introduction to Spring Boot Admin Server with Example](https://www.amitph.com/spring-boot-admin-server/)
- [How to Secure Spring Boot Actuator Endpoints](https://www.amitph.com/how-to-secure-spring-boot-actuator-endpoints/)
- [Spring Boot Admin Server Example](https://www.amitph.com/spring-boot-admin-server/)
- [Spring Data and JPA Tutorial](https://www.amitph.com/spring-data-and-jpa-tutorial/)
- [Wildcard Queries with Spring Data JPA](https://www.amitph.com/spring-data-and-jpa-tutorial/)
- [Spring Boot Runners – Application Runner and Command Line Runner](https://www.amitph.com/spring-boot-runners/)
- [Spring Boot Rest Service](https://www.amitph.com/spring-boot-rest-service/)
- [Downloading Large Files using Spring WebClient](https://www.amitph.com/spring-webclient-large-file-download/)
- [Spring @RequestParam Annotation with Examples](https://www.amitph.com/spring-requestparam-annotation/)
- [Introduction to Spring WebClient](https://www.amitph.com/introduction-to-spring-webclient/)
- [Configure timeout for Spring WebFlux WebClient](https://www.amitph.com/spring-webflux-timeouts/)
- [How to Read JSON Data with WebClient](https://www.amitph.com/spring-webclient-read-json-data/)
- [Add URI Parameters to Spring WebClient Requests](https://www.amitph.com/spring-webclient-request-parameters/)
- [Spring Boot - Spring Data JPA - MySQL Example](https://www.amitph.com/spring-boot-data-jpa-mysql/)
- [Spring Boot - Spring Data JPA - Postgres Example](https://www.amitph.com/spring-boot-data-jpa-postgres/)
- [Spring Boot Exit Codes Examples with Exception Mapping](https://www.amitph.com/spring-boot-exit-codes/)
- [Using @ConfigurationProperties in Spring Boot](https://www.amitph.com/spring-boot-configuration-properties/)
- [Reading Nested Properties in Spring Boot](https://www.amitph.com/spring-boot-nested-configuration-properties/)
- [Reading HTTP Headers in Spring REST Controller](https://www.amitph.com/spring-rest-http-header/)
- [YAML to Map with Spring Boot](https://www.amitph.com/spring-boot-yaml-to-map/)
- [YAML to Java List of Objects in Spring Boot](https://www.amitph.com/spring-boot-yaml-to-list/)
- [Validations with @ConfigurationProperties in Spring Boot](https://www.amitph.com/spring-boot-configuration-properties-validation/)
- [Parallel Requests with Spring WebClient](https://www.amitph.com/spring-webclient-concurrent-calls/)
- [Custom Banners with Spring Boot](https://www.amitph.com/spring-boot-custom-banner/)
"
tomekkaczanowski/junit-put-examples,master,38,35,2013-04-08T21:53:54Z,244,0,"Code examples for Practical Unit Testing with JUnit and Mockito"" book""",,
loretoparisi/tensorflow-java,master,61,31,2017-03-10T17:29:41Z,97673,0,Tensorflow Java examples,deeplearning deeplearning-java java tensorflow tensorflow-java,"# tensorflow-java
Tensorflow Java pipeline and examples. This simple Java pipeline for TensorFlow Java API supports *Tensorflow >= 1.4* and it has been tested with Tensorflow from *TF 1.4.0* to *TF 1.13.1*. :new:

## How To Install
You need to run the `jni.sh` to install the right Java bindings for your platform and the `download.sh` script that will download the `inception5` model in order to be ready to run a simple examples:

```bash
git clone https://github.com/loretoparisi/tensorflow-java.git \
cd tensorflow-java \
sh jni.sh \
sh download.sh \
```

## A simple Hello World example
Create a simple Java class with a main to be executable and import `org.tensorflow.TensorFlow`

```java
import org.tensorflow.TensorFlow;

public class TensorFlowExample {
  public static void main(String[] args) {
    System.out.println(""TensorFlowExample using TensorFlow version: "" +  TensorFlow.version());
  }
}
```

Save it and then from command line compile and run

```bash
cd tensorflow-java
javac -cp lib/libtensorflow-1.13.1.jar TensorFlowExample.java
java -cp lib/libtensorflow-1.13.1.jar:. -Djava.library.path=./jni TensorFlowExample
```

If you get the TensorFlow version as output it worked!

```bash
TensorFlowExample using TensorFlow version: 1.13.1
```

## Real world (Inception) example
We use the `LabelImage` official Tensorflow example to label an example image with the inception graph model.

```
$ javac -cp lib/libtensorflow-1.13.1.jar LabelImage.java 
$ java -cp lib/libtensorflow-1.13.1.jar:. -Djava.library.path=./jni LabelImage models/ images/example-400x288.jpg 
BEST MATCH: lakeside (19,00% likely)
```

## Disclaimer
This example is provided as it is and it is based on the official Tensorflow Java JNI wrapper and example available [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java).
"
habren/JavaDesignPattern,master,56,47,2016-03-16T13:47:39Z,101,1,Examples for Java Design Pattern,,"Java设计模式
---

本项目主要记录《Java设计模式》系列文章对应的实例代码，具体的文章详见[作者个人博客](http://www.jasongj.com)[http://www.jasongj.com](http://www.jasongj.com)

- [Java设计模式（一） 简单工厂模式不简单](http://www.jasongj.com/design_pattern/simple_factory/)
- [Java设计模式（二） 工厂方法模式](http://www.jasongj.com/design_pattern/factory_method/)
- [Java设计模式（三） 抽象工厂模式](http://www.jasongj.com/design_pattern/abstract_factory/)
- [Java设计模式（四） 观察者模式 ](http://www.jasongj.com/design_pattern/observer/)
- [Java设计模式（五） 组合模式](http://www.jasongj.com/design_pattern/composite/)
- [Java设计模式（六） 代理模式 VS. 装饰模式](http://www.jasongj.com/design_pattern/proxy_decorator/)
"
haoxiaoyong1014/springboot-redis-examples,master,52,29,2018-07-27T00:49:24Z,2196,3,redis 使用场景及实例,,"# springboot-redis-example

2018/6/12 添加  springboot-redis-docker(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-redis-docker"">Docker 部署 SpringBoot 项目整合 Redis 镜像做访问计数(PV)Demo</a>)

2018/07/27  添加springboot-redis-ranking (<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-redis-ranking"">基于Redis实现商品排行榜</a>)

2018/08/01 添加 springboot-redis-fridends (<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-redis-friends"">基于Redis实现查询共同好友</a>,
结合前端vue.js,前端项目地址: <a href=""https://github.com/haoxiaoyong1014/common-friends"">common-friends</a>)

2018/11/16 添加 redis-manage(<a href=""https://github.com/haoxiaoyong1014/redis-manage"">Redis的后台管理</a>,结合前端项目<a href=""https://github.com/haoxiaoyong1014/redis-manage-view"">redis-manage-view</a>)

2019/8/16 添加 springboot-idempotent(<a href=""https://github.com/haoxiaoyong1014/springboot-examples/tree/master/springboot-idempotent"">springboot + redis + 注解 + 拦截器 实现接口幂等性校验</a>)

2019/9/14 添加 springboot-mybatis-redis-cache(<a href=""https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-mybatis-redis-cache"">使用redis做二级缓存</a>)

2019/10/29添加 [Redis专题(七)--基于Sentinel（哨兵）搭建实现Redis高可用集群](https://haoxiaoyong.cn/2019/10/29/2019/2019-12-03-redis-master-slave/)

2020/09/18添加 springboot-redis-range( [SpringBoot 使用 Redis Geo 实现查找附近的位置](https://github.com/haoxiaoyong1014/springboot-redis-examples/tree/master/springboot-redis-range))

持续更新中....
"
stunstunstun/awesome-spring-boot,master,420,94,2015-07-08T09:35:46Z,10325,3,Code based and real world examples of Spring Boot and shiny things. 😍,awesome-spring awesome-spring-boot java spring spring-boot springboot,"# <img src=""http://stormpath.com/wp-content/uploads/2016/05/spring-boot-logo.jpg"" width=""50"" align=""absmiddle""/> Awesome Spring Boot 

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![Build Status](https://travis-ci.org/stunstunstun/awesome-spring-boot.svg?branch=master)](https://travis-ci.org/stunstunstun/awesome-spring-boot)
[![Wercker](https://img.shields.io/badge/spring--boot-1.5.3.RELEASE-brightgreen.svg)]()
[![Wercker](https://img.shields.io/badge/java-8-brightgreen.svg)]()
[![Wercker](https://img.shields.io/badge/gradle-3.5-brightgreen.svg)]()

A curated list of amazingly examples of Spring Boot, resources and shiny things.

## Contents

<details>
<!-- toc -->

- [Tutorials](#tutorials)
- [DevOps](#devops)
  - [Prerequisite](#prerequisite)
  - [Test](#test)
  - [Build](#build)
  - [Run](#run)
- [Spring Boot Features](#spring-boot-features)

<!-- tocstop -->
</details>

## Tutorials

#### Afterwards Spring Boot works

Project | Build | Description |
---|---|----
[spring-boot-jdbc-example](https://github.com/stunstunstun/awesome-spring-boot/tree/master/spring-boot-jdbc-example) | Gradle | Integrating Spring Boot with JDBC
[spring-boot-jpa-example](https://github.com/stunstunstun/awesome-spring-boot/tree/master/spring-boot-jpa-example) | Gradle | Integrating Spring Boot with JPA
[spring-boot-mybatis-example](https://github.com/stunstunstun/awesome-spring-boot/tree/master/spring-boot-mybatis-example)| Gradle | Integrating Spring Boot with myBatis
[spring-boot-mybatis-multi-example](https://github.com/stunstunstun/awesome-spring-boot/tree/master/spring-boot-mybatis-multi-example) | Gradle | Integrating Spring Boot with multiple datasources
[spring-boot-mvc-example](https://github.com/stunstunstun/awesome-spring-boot/tree/master/spring-boot-mvc-example) | Gradle | Integrating Spring Boot with Spring MVC

#### Download

```
$ git clone https://github.com/stunstunstun/awesome-spring-boot.git
```

## DevOps

#### Prerequisite

Your operating system must have the JDK installed and it's recommended that you install the IDE to look up the source code.

#### Test

Check the test case with the `@Test` annotation.

```
$ gradlew test 
```

#### Build

Build the project and create executable jar and war files.

```
$ gradlew assemble 
```

It doesn't work? You should check execution permission.

```
$ chmod +x gradlew
```

#### Run

An example with spring-web-starter can be connected by Web Browser

```
$ gradlew :spring-boot-mvc-example:bootRun
```

```
GET http://localhost:8080/users
```

## Spring Boot Features

#### Bootstrap By Spring Boot CLI

`Install Spring Boot CLI`
```
$ brew tap pivotal/tap
$ brew install springboot
$ spring --version
```

`Create Project`
```
$ spring init --build=gradle --java-version=1.8 --dependencies=data-jpa spring-boot-jpa-example
```

## You can do it in yourself!

#### Spring Core
- http://vojtechruzicka.com/field-dependency-injection-considered-harmful/

#### Spring Boot Test
- https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-testing.html
- https://spring.io/blog/2016/04/15/testing-improvements-in-spring-boot-1-4
- https://docs.spring.io/spring/docs/current/spring-framework-reference/html/integration-testing.html
- http://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/mock/mockito/MockBean.html

#### Spring Data REST
- https://docs.spring.io/spring-data/rest/docs/current/reference/html/


#### Data Access
- https://spring.io/guides/gs/accessing-data-jpa/
- https://spring.io/guides/gs/accessing-data-mysql/
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-database-initialization.html

#### Logging
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-logging.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-logging.html
- https://www.slideshare.net/whiteship/ss-47273947

#### HTTP Client
- https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-restclient.html

#### Embedded Servlet Containers
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-embedded-servlet-containers.html

#### Profiles
- https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-profiles.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-properties-and-configuration.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-database-initialization.html

#### Actuator
- https://spring.io/guides/gs/actuator-service/
- https://github.com/spring-projects/spring-boot/tree/master/spring-boot-actuator
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-actuator.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-monitoring.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html 

#### Hotswapping
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-hotswapping.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/using-boot-devtools.html
- https://spring.io/blog/2015/06/17/devtools-in-spring-boot-1-3

#### Deploy To AWS, Cloud Foundry
- https://docs.spring.io/spring-boot/docs/current/reference/html/howto-traditional-deployment.html
- https://docs.spring.io/spring-boot/docs/current/reference/html/cloud-deployment.html

#### Spring Boot Book
- https://www.manning.com/books/spring-boot-in-practice
"
salaboy/Drools_jBPM5-Training-Examples,master,64,49,2011-01-28T18:46:55Z,469,1,jBPM5 & Drools - Community Training Course - Examples,,
jgperrin/net.jgp.labs.spark,master,92,43,2016-06-26T23:31:23Z,1832,3,Apache Spark examples exclusively in Java,data-ingestion dataframe ingestion java spark udf,"# Some Java examples for Apache Spark

## Welcome

Welcome to this project I started several years ago with this simple idea: let's use **Apache Spark with Java** and not learn all those complex stuff like Hadoop or Scala. I am not that smart anyway...

## A book!

This project has evolved in a book, named ""**[Spark in Action, 2nd edition](https://jgp.ai/sia)**"" published by Manning Publications. If you want to know more, and be guided through your Spark learning process, I can only recommend to read the book at Manning. Find out more about [Spark in Action, 2nd edition, on the Manning website](https://jgp.ai/sia). The book contains more examples, more explanation, is professionally written and edited. 

Spark in Action, 2e covers using Spark with Java, Python (PySpark), and Scala.

All Spark in Action's examples are on GitHub. Here are the repos with the book examples:

[Chapter 1](https://github.com/jgperrin/net.jgp.books.spark.ch01) So, what is Spark, anyway? _An introduction to Spark with a simple ingestion example._

[Chapter 2](https://github.com/jgperrin/net.jgp.books.spark.ch02) Architecture and flows _Mental model around Spark and exporting data to PostgreSQL from Spark._

[Chapter 3](https://github.com/jgperrin/net.jgp.books.spark.ch03) The majestic role of the dataframe.

[Chapter 4](https://github.com/jgperrin/net.jgp.books.spark.ch04) Fundamentally lazy.

[Chapter 5](https://github.com/jgperrin/net.jgp.books.spark.ch05) Building a simple app for deployment _and_ Deploying your simple app.

[Chapter 7](https://github.com/jgperrin/net.jgp.books.spark.ch07) Ingestion from files.

[Chapter 8](https://github.com/jgperrin/net.jgp.books.spark.ch08) Ingestion from databases.

[Chapter 9](https://github.com/jgperrin/net.jgp.books.spark.ch09) Advanced ingestion: finding data sources & building your own.

[Chapter 10](https://github.com/jgperrin/net.jgp.books.spark.ch10) Ingestion through structured streaming.

[Chapter 11](https://github.com/jgperrin/net.jgp.books.spark.ch11) Working with Spark SQL.

[Chapter 12](https://github.com/jgperrin/net.jgp.books.spark.ch12) Transforming your data.

[Chapter 13](https://github.com/jgperrin/net.jgp.books.spark.ch13) Transforming entire documents.

[Chapter 14](https://github.com/jgperrin/net.jgp.books.spark.ch14) Extending transformations with user-defined functions (UDFs).

[Chapter 15](https://github.com/jgperrin/net.jgp.books.spark.ch15) Aggregating your data.

[Chapter 16](https://github.com/jgperrin/net.jgp.books.spark.ch16) Cache and checkpoint: enhancing Spark’s performances.

[Chapter 17](https://github.com/jgperrin/net.jgp.books.spark.ch17) Exporting data & building full data pipelines.


In the meanwhile, this project is still live, with more raw-level examples, that may (or may not) work.


## This repo

This project is still live as I add experiments and answers to StackOverflow. I try to keep this project up to date with the version of Spark, but I must admit I only validate for compilations.

### Environment

These labs rely on:
* Apache Spark v3.2.0 (based on Scala v2.12).
* Java 8.

### Notes on Branches
The master branch will always contain the latest version of Spark, currently v3.2.0.

### Labs
A few labs around Apache Spark, exclusively in Java.

Organization is now in sub packages:

* l000_ingestion: Data ingestion from various sources.
* l020\_streaming: Data ingestion via streaming. Special note on [Streaming](src/main/java/net/jgp/labs/spark/l020_streaming/README.md).
* l050_connection: Connect to Spark.
* l100_checkpoint: Checkpoint introduced in Spark v2.1.0.
* l150_udf: UDF (User Defined Functions).
* l200_join: added join examples.
* l240_foreach: foreach() on a dataframe.
* l250_map: map (in the context of mapping, not always linked to map/reduce).
* l300_reduce: reduce.
* l400\_industry\_formats: working with industry formats, limited, for now, to HL7 and FHIR.
* l500_misc: other examples.
* l600_ml: ML (Machine Learning).
* l700_save: saving your results.
* l800_concurrency: labs around concurrency access, work in progress.
* l900_analytics: More complex examples of using Spark for Analytics.
* l900_analytics: More complex examples of using Spark for Analytics.

### Contribute

 * If you would like to see more labs, send your request to jgp at jgp dot net or [@jgperrin](https://twitter.com/jgperrin) on Twitter.
 * Contact me as well if you want to add some of your examples to this repo (or simply do a pull request).
 

"
sdaschner/coffee-testing,master,59,55,2018-04-10T10:26:00Z,397,1,Code examples for effective enterprise testing,,
Syncleus/aparapi-examples,master,58,21,2016-10-16T15:24:44Z,20607,3,A framework for executing native Java code on the GPU.,,"![](http://aparapi.com/images/logo-text-adjacent.png)

[![License](http://img.shields.io/:license-apache-blue.svg?style=flat-square)](http://www.apache.org/licenses/LICENSE-2.0.html)
[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.aparapi/aparapi-examples/badge.png?style=flat)](https://maven-badges.herokuapp.com/maven-central/com.aparapi/aparapi-examples/)
[![Gitter](https://badges.gitter.im/Syncleus/aparapi.svg)](https://gitter.im/Syncleus/aparapi?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

A framework for executing native Java code on the GPU.

**Licensed under the Apache Software License v2**

This project is a collection of examples for the Aparapi project. For more information see the Aparapi [website](http://Aparapi.com) or the [QOTO GitLab repository](https://git.qoto.org/aparapi/aparapi-examples). An up-to-date mirror of this repository is also maintained on [Github](https://github.com/Syncleus/aparapi-examples).

For detailed documentation see [Aparapi.com](http://Aparapi.com).

For support please use [Gitter](https://gitter.im/Syncleus/aparapi) or the [official Aparapi mailing list and Discourse forum](https://discourse.qoto.org/c/PROJ/APA).

Please file bugs and feature requests at [QOTO GitLab](https://git.qoto.org/aparapi/aparapi-examples); a mirror of older issues can be found at [Github](https://github.com/Syncleus/aparapi-examples/issues).

## Prerequisites

The examples should run on any system as-is. For GPU acceleration support you must have OpenCL installed and a compatible graphics card.

**Aparapi runs on all operating systems and platforms, however GPU acceleration support is currently provided for the following platforms: Windows 64bit, Windows 32bit, Mac OSX 64bit, Linux 64bit, and Linux 32bit.**

## Obtaining the Source

The official source repository for Aparapi Examples is located in the Syncleus Github repository and can be cloned using the
following command.

```bash

git clone https://git.qoto.org/aparapi/aparapi-examples.git
```

## Running

To run the examples simply checkout the git tag for the version you want to run and execute it through maven. Unless you
specifically want to try the latest snapshot it is important you checkout a specific git tag instead of the master
branch. To use the snapshot in the master branch you will have to manually install the core aparapi snapshot that
matches it since snapshots do not appear in maven central.

```bash

git checkout v3.0.0
mvn clean package exec:java
```
"
F4bwDP6a6W/spring-mvc-mini,master,426,328,2015-03-24T12:52:25Z,710,4,"Spring MVC Example Project, light weight, no Database",,"Spring-mvc-mini是一个完整的，轻量、简单的Java项目，基于Spring MVC.
里面有基本的增删改查的功能。而且无需修改任何内容，就可以直接跑起来。

另外我有一个Spring MVC的RESTful项目，数据库是Mysql，请参看：https://github.com/hot13399/spring-mvc-REST

-------------------
在这个项目里主要实现了以下技术：
* spring-webmvc
* svnkit
* jgit
* javax.mail
* jasypt
* dom4j
* spring scheduler

如何运行：
-------------------

在Windows的CMD：

    $ cd spring-mvc-mini
    $ mvn tomcat7:run [-Dmaven.tomcat.port=<port no.>] (In case 8080 is busy] 

通过浏览器打开：http://localhost:8080/spring-mvc-mini

如果你想要学习或贡献和这个项目：

就通过maven把它build成一个IDE项目，执行以下命令，打开CMD：

    $ cd spring-mvc-mini
    $ mvn eclipse:eclipse or mvn idea:idea

通过Eclipse或IDEA导入即可。

Note:
-------------------

 如果你要在Linux环境运行，以下的文件需要修改。

    $ spring-oss-mini\src\main\webapp\WEB-INF\spring\appServlet\servlet-context.xml:<context:property-placeholder 
	$ location=""file:/opt/web/spring-mvc-mini/resources/application.properties""/>
	$ spring-oss-mini\src\main\resources\logback.xml
	$ spring-oss-mini\resources\application.properties

 最后通过Maven build一个war包部署即可。



--------------------
Spring-mvc-mini is a mini project using Spring MVC.

In this project, you can see the code of:
* spring-webmvc
* svnkit
* javax.mail
* jasypt
* dom4j
* spring scheduler

To run the application:
From the command line with Maven:
    $ cd spring-mvc-mini
    $ mvn tomcat7:run [-Dmaven.tomcat.port=<port no.>] (In case 8080 is busy]

Access the deployed web application at: http://localhost:8080/spring-mvc-mini

To contribute to this project:
In your preferred IDE such as Eclipse:
    $ cd spring-mvc-mini
    $ mvn eclipse:eclipse

Import spring-mvc-mini as a Maven Project

If you want to deploy this project to Linux server, you might need to edit conf files:

    $ spring-oss-mini\src\main\webapp\WEB-INF\spring\appServlet\servlet-context.xml:<context:property-placeholder
	$ location=""file:/opt/web/spring-mvc-mini/resources/application.properties""/>
	$ spring-oss-mini\src\main\resources\logback.xml
	$ spring-oss-mini\resources\application.properties


"
kousen/mockito-hamcrest,master,58,63,2018-05-17T11:57:25Z,666,0,Examples for Mockito and Hamcrest Matchers course,,"# mockito-hamcrest
Examples for Mockito and Hamcrest Matchers course
"
asc-lab/java-cqrs-intro,master,189,57,2019-01-15T06:42:37Z,372,1,Examples of implementation CQRS with Event Sourcing - evolutionary approach,cqrs java-11,"# CQRS and Event Sourcing Intro for Developers

We live in a world of dynamically changing technologies. New ways of architecturing our solutions, new frameworks and libraries seem to appear on almost daily basis. 


**But good software engineering is not about fancy frameworks and solutions aggressively promoted by their vendors.** It is not about doing something because Netflix or Google did it. It is about taking well-thought-out decisions based on facts and knowledge. That’s why it is important to be familiar basic architectural concepts like CQRS. It is one of the tools we use in our software house every day. We mentioned CQRS in the article which is part of the series about [Microservices on .NET Core](https://altkomsoftware.pl/en/blog/building-microservices-on-net-core-1/), but it was presented from technical perspective and here we want to focus on basics concepts explanation with visualisation and examples.


[Check our article!](https://altkomsoftware.pl/en/blog/cqrs-event-sourcing/)

## No CQRS

<p align=""center"">
    <img alt=""No CQRS"" src=""https://raw.githubusercontent.com/asc-lab/java-cqrs-intro/master/readme-images/1_no_cqrs.png"" />
</p>

## Separate Commands and Queries

<p align=""center"">
    <img alt=""Separate Commands and Queries"" src=""https://raw.githubusercontent.com/asc-lab/java-cqrs-intro/master/readme-images/2_separe_commands_queries.png"" />
</p>

## Separate Models Commands and Queries

<p align=""center"">
    <img alt=""Separate Models Commands and Queries"" src=""https://raw.githubusercontent.com/asc-lab/java-cqrs-intro/master/readme-images/3_separate_models_commands_queries.png"" />
</p>

## Separate Storage Engines

<p align=""center"">
    <img alt=""Separate Storage Engines"" src=""https://raw.githubusercontent.com/asc-lab/java-cqrs-intro/master/readme-images/4_separate_storage_engines.png"" />
</p>

## Event Sourcing

<p align=""center"">
    <img alt=""Event Sourcing"" src=""https://raw.githubusercontent.com/asc-lab/java-cqrs-intro/master/readme-images/5_event_sourcing.png"" />
</p>
"
nitsanw/jmh-samples,master,69,22,2013-04-24T19:29:49Z,1812,1,JMH examples with my own examples + jar etc,,"jmh-samples
===========
<b>NOTE: As of 15/06/2013 the jar/samples were up to date. JMH has come a long way since and is much easier to play with.<br/>
I have now removed the old jar/samples and use the maven hosted dependency instead.<br/></b>
JMH samples.<br/>
This was setup to support my 2 blog posts about JMH:<br/>
http://psy-lob-saw.blogspot.com/2013/05/using-jmh-to-benchmark-multi-threaded.html<br/>
http://psy-lob-saw.blogspot.com/2013/04/writing-java-micro-benchmarks-with-jmh.html<br/>
And contains the examples discussed under the psy.lob.saw package.<br/>
The JMH framework is hosted here: http://openjdk.java.net/projects/code-tools/jmh/<br/>
The JMH samples are a MUST read (and are always up to date): http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/<br/>
"
camunda-community-hub/camunda-8-examples,main,29,35,2022-02-14T10:59:54Z,10584,12,,camunda-8,"[![](https://img.shields.io/badge/Community%20Extension-An%20open%20source%20community%20maintained%20project-FF4700)](https://github.com/camunda-community-hub/community)

# Camunda 8 Examples

A collection of examples related to the usage of Camunda 8.

## Table of Contents

1. **[Async Service Task Example](async-service-task/README.md)** : Implementation of an asynchronous service task with handling for an asynchronous service call.

2. **[Multi-instance Processing of a (Very) Large Sequence](large-multi-instance-example/README.md)** : Example demonstrating the processing of a very large sequence of entities using multi-instance subprocesses.

3. **[Payment Example Process Application](payment-example-process-application/README.md)** : Example of a process application containing a payment process and the required workers, forms, and dummy services.
   - **Deployment Example on Kubernetes**: [Available](payment-example-process-application/kube/README.md)

4. **[Integrate Camunda 8 with Microsoft PowerApps Dataverse](powerapps-dataverse/README.md)** : Guide for connecting the Camunda 8 REST Connector to Microsoft PowerApps Dataverse via OAuth2 to query data from tables.

5. **[Rollback on Error Example](rollback-on-error-example/README.md)** : Example of rollback on error in a process where two actions need to be executed synchronously.

6. **[Example for synchronous responses from processes](synchronous-response-springboot/README.md)** : Example of synchronous response from Camunda 8 processes.

7. **[Timer Testing](timer-testing/README.md)** : Example demonstrating how to test timers in Zeebe.

8. **[Pyzeebe & Connectors Example](weatherinfo-pyzeebe-connectors/README.md)** : Project containing a process, user form, Python worker using the pyzeebe client, and a custom worker template.

9. **[Zeebe Java Client Examples](zeebe-client-plain-java/README.md)** : Maven project containing several examples using the Zeebe Java client.

## How to use

Check out the repo. Navigate to the project you are interested in. Each project should contain:

* an introduction to the purpose
* a brief description of the functionality
* a guide on how to setup and test the example

## Report problems

If problems occur, please file an issue containing:

* which project should be used
* what did not work out
* which environment was used (java version, build tool, ...)
"
cirosantilli/java-cheat,master,167,59,2015-03-07T07:32:56Z,314,0,"Java minimal examples. Asserts used wherever possible. Cheatsheets, tutorials.",,"# Java Cheat ![logo](logo.png)

[![Build Status](https://travis-ci.org/cirosantilli/java-cheat.svg)](https://travis-ci.org/cirosantilli/java-cheat)

Java minimal examples. Asserts used wherever possible.

1.  [Getting started](getting-started.md)
1.  Code
    1.  [Main.java](Main.java)
    1.  [Hello world](HelloWorld.java)
    1.  Language
        1.  Types
            1.  Floating point
                1. [NaN](Nan.java)
            1.  [Array](ArrayCheat.java)
            1.  Classes
                1.  [Constructor](ConstructorCheat.java)
                1.  [super](SuperCheat.java)
                1.  [Nested class](NestedClassCheat.java)
            1.  [Generics](GenericsCheat.java)
        1.  Branching
            1.  [Exceptions](ExceptionCheat.java)
    1.  Standard library
        1.  [Collection](CollectionCheat.java)
            1.  [Collections](CollectionsCheat.java)
            1.  [List](ListCheat.java)
            1.  [Map](MapCheat.java)
        1.  [StringBuilder](StringBuilderCheat.java)
        1.  Streams
            1. [BufferedReader](BufferedReaderCheat.java)
        1.  lang
            1.  [String](StringCheat.java)
            1.  [Wrappers](WrappersCheat.java)
                1.  [Integer pool](IntegerPoolCheat.java)
    1.  [interactive](interactive/)
    1.  [Binary compatibility](binary-compatibility/)
    1.  [ClassNotFoundException](class-not-found/)
    1.  [JNI](jni/)
    1.  [WatchService](watch-service/)
    1.  [instrument](instrument/)
1.  Introduction
    1.  [Standards](standards.md)
        1. [Versions](versions.md)
    1.  [Implementations](implementations.md)
        1. [OpenJDK](openjdk.md)
    1.  [Classpath](classpath.md)
    1.  [Style guides](style-guides.md)
1.  Tools
    1. [java utility](java-utility.md)
    1. [Javadoc](javadoc/)
    1. [javac](javac/)
    1. [JAR](jar.md)
1.  [JVM](jvm.md)
    1. [Bytecode](bytecode.md)
1.  Third party
    1.  [JUnit](junit/)
    1.  Build tools
        1.  [Maven](maven/)
        1.  [Ant](ant.md)
        1.  [Gradle](gradle.md)
    1.  [Tomcat](tomcat.md)
1.  [update-java-alternatives](update-java-alternatives.md)
1.  [Bibliography](bibliography.md)

## WIP

1.  Code
    1.  [Java 8](java8/)
    1.  [JMX](jmx.md)
1.  Tools
    1.  [jconsole](jconsole.md)
    1.  [JAVA_HOME](java-home.md)
    1.  [JDB](jdb.md)
    1.  [javap](javap.md)
1.  Third party
    1.  [Spring](spring/)
    1.  [Jasmin](jasmin/)
    1.  [Java Decompiler](java-decompiler.md)
    1.  [Mockito](mockito/)
    1.  [Formal verification](formal-verification.md)
"
codecentric/java8-examples,master,25,37,2013-11-23T13:36:34Z,232,0,Some examples for the features introduced in Java 8,,"This repository contains some examples for the new features introuced in Java 8, such as:

* Default Methods
* Method References
* Lambdas
* Streaming API
* Time API (JSR-310)

You can get Java 8 from www.jdk8.java.net/download.html

IDE-Support with Spring Tool Suite
* Download STS 3.4.0 http://spring.io/tools/sts/all
* Install Java 8 Support via Update Site http://dist.springsource.com/snapshot/TOOLS/java8/e43"
waylife/DemoCollections,master,86,24,2015-10-13T13:41:44Z,945,2,"Some demos, examples",,
afsalashyana/JavaFX-Tutorial-Codes,master,111,121,2018-09-18T07:42:09Z,4961,1,General program examples that I use for tutorials in 'GenuineCoder' YouTube channel,demo demo-app excercises genuine tutorial tutorial-code,"# Genuine Coder Tutorial Code Collection
This repository contains general program examples that I use for my tutorial videos and blogs.

## [YouTube Tutorials](https://www.youtube.com/channel/UCCXbhmjID-T2I0KfuDPbi6A)

### [JavaFX Scene Transition](https://youtu.be/cqskg3DYH8g)
Tutorial about JavaFX scene transition with slide effect.
<p align=""left"">
  <img height=300 src=https://i.imgur.com/gxk3XU9.gif>
</p>

### [JavaFX Navigation Drawer](https://youtu.be/tgV8dDP9DtM)
JavaFX navigation drawer using JFXDrawer component from JFoenix library.
<p align=""left"">
  <img height=300 src=https://i.imgur.com/hpLZYDT.gif>
</p>

### [Ikonli with Java Swing](https://youtu.be/VHGxY-aR0ws)
Creating dynamic icons in Java Swing with Ikonli library. 
<p align=""left"">
  <img height=300 src=https://i.imgur.com/dbwteVM.png>
</p>

### [JavaFX Circular Scene Transition](https://youtu.be/cIrCNl02lDc)
Tutorial about JavaFX scene transition with circular-reveal effect.
<p align=""left"">
  <img height=450 src=.gif/JavaFXCircularReveal.gif>
</p>

### [JavaFX Custom Shape Buttons](https://youtu.be/QsQQ5D4TARw)
Creating JavaFX components with custom shapes. 
<p align=""left"">
  <img height=300 src=https://i.imgur.com/qIQBO5m.gif>
</p>

### [JavaFX Observable](https://youtu.be/JaqExzdJhEI)
Example of using JavaFX Observable and Bindings
<p align=""left"">
  <img height=300 src=https://i.imgur.com/oXI5Qnq.gif>
</p>

### [JavaFX Calculator](https://youtu.be/r1qowt6yYm8)
Sample JavaFX calculator with CSS styling
<p align=""left"">
  <img height=300 src=https://i.imgur.com/WVcMqsg.gif>
</p>

### [Java Swing Text Editor](http://www.genuinecoder.com/text-editor-java-with-source-notepad-html/)
Java swing based basic text editor
<p align=""left"">
  <img height=300 src=https://i.imgur.com/qiboR4J.gif>
</p>

### [Java Sorting Animation](https://youtu.be/Slo18MgCWYY)
Sorting algorithm execution animation using JavaFX charts
<p align=""left"">
  <img height=300 src=https://i.imgur.com/s8yJdiY.gif>
</p>

### JavaFX Self Writing Letter
Realtime letter writing animation using JavaFX
<p align=""left"">
  <img height=300 src=https://i.imgur.com/Rmv16MK.gif>
</p>

### [JavaFX Background Task](https://youtu.be/pdRX6CLP0tM)
Tutorial about JavaFX background tasks to asynchronously execute business logic in the background thread.
<p align=""left"">
  <img height=200 src=.gif/JavaFXBackgroundTask.gif>
</p>

## [JavaFX Blog Posts](https://genuinecoder.com/category/javafx/)
 * [JavaFX Image Button Tutorial](https://genuinecoder.com/javafx-image-button-tutorial/)
 * [JavaFX ObservableList Tutorial](https://genuinecoder.com/javafx-observable-list-tutorial/)
 * [JavaFX CheckComboBox Tutorial](https://genuinecoder.com/javafx-checkcombobox-with-example/)
 * [JavaFX Custom Shaped Buttons](https://genuinecoder.com/javafx-buttons-with-custom-shape/)
 * [JavaFX DatePicker Tutorial](https://genuinecoder.com/javafx-datepicker-tutorial-with-date-formatting-and-css-styling/)
 * [JavaFX Stage Icons](https://genuinecoder.com/javafx-application-icon-setup/)
 * [JavaFX 3D Tutorial](https://genuinecoder.com/javafx-3d/)
 * [JavaFX Communication between FXML Controllers](https://genuinecoder.com/javafx-communication-between-controllers/)
 * [JavaFX Splash Screen](https://genuinecoder.com/javafx-splash-screen-loading-screen/)
 * [JavaFX Animation Tutorial with Examples](https://genuinecoder.com/javafx-animation-tutorial/)
 * [Custom Shapes for JavaFX Components](https://genuinecoder.com/custom-shapes-for-javafx-ui-components/)
 * [JavaFX Scene Builder Tutorial](https://genuinecoder.com/javafx-scene-builder-tutorial-for-beginners/)
 * [JavaFX Observables and Bindings](https://genuinecoder.com/javafx-observables-and-bindings/)
 * [JavaFX Get Screen Size Programmatically](https://genuinecoder.com/javafx-get-screen-size-of-all-connected-monitors/)
 * [JavaFX Scene Switching Animation](https://genuinecoder.com/javafx-scene-switch-change-animation/)
 * [JavaFX FileChooser for Saving File](https://genuinecoder.com/save-files-javafx-filechooser/)
 * [Library Management System Development Tutorial using JavaFX](https://genuinecoder.com/javafx-complete-project-tutorial-library-management-system-html/)

## [Java Blog Posts](https://genuinecoder.com/category/java/)
 * [Create Animated GIF from still images in Java](https://genuinecoder.com/how-to-create-gif-from-multiple-images-in-java/)
 * [Create Excel Spreadsheet in Java](https://genuinecoder.com/how-to-create-excel-xlsx-spreadsheet-files-in-java/)
 * [Java with WebP images](https://genuinecoder.com/java-webp-image-read-save-tutorial/)
 * [Open Native File Explorer with Java](https://genuinecoder.com/how-to-open-file-explorer-in-java/)
 * [Java/JavaFX TrayIcon Tutorial](https://genuinecoder.com/java-trayicon-tutorial-with-popupmenu-and-images/)
 * [Downloading a file from Spring Boot Controller](https://genuinecoder.com/downloading-a-file-from-spring-controller-with-spring-boot/)
 * [Make EXE from Java JAR](https://genuinecoder.com/convert-java-jar-to-exe/)
"
aspose-slides/Aspose.Slides-for-Java,master,41,48,2011-11-25T13:57:36Z,96769,2,Aspose.Slides for Java Examples,,"![GitHub all releases](https://img.shields.io/github/downloads/aspose-slides/Aspose.slides-for-Java/total) ![GitHub](https://img.shields.io/github/license/aspose-slides/Aspose.slides-for-java)
# Java PowerPoint API

[Aspose.Slides](https://products.aspose.com/slides/java) a Java PowerPoint API for presentation manipulation and management. It allows developers to read, write, convert and manipulate PowerPoint presentations in Java applications with the ability to manipulate all document elements such as slides, tables, text, charts, shapes, images and SmartArt diagrams and more.

<p align=""center"">
  <a title=""Download complete Aspose.Slides for Java source code"" href=""https://github.com/asposeslides/Aspose_Slides_Java/archive/master.zip"">
	<img src=""https://raw.github.com/AsposeExamples/java-examples-dashboard/master/images/downloadZip-Button-Large.png"" />
  </a>
</p>

Directory | Description
--------- | -----------
[Examples](https://github.com/aspose-slides/Aspose.Slides-for-Java/tree/master/Examples)  | A collection of Java examples that help you learn how to use product features.
[Plugins](https://github.com/aspose-slides/Aspose.Slides-for-Java/tree/master/Plugins)  | Plugins to help integrate Aspose.Slides for Java in different environments.


## PowerPoint File Manipulation via Java

Checkout the [product overview](https://docs.aspose.com/slides/java/product-overview/) to know all about Aspose.Slides for Java. 

- Load & convert presentations to other formats.
- Create presentations from scratch. 
- Manipulate all of presentation elements via intuitive object model.
- Create or embed charts.
- Create or manipulate shapes.

## Read & Write Presentations

**Microsoft PowerPoint:** PPT, PPTX, PPS, POT, PPSX, PPTM, PPSM, POTX, POTM\
**OpenOffice:** ODP, OTP

## Save Presentations As

**Fixed Layout:** PDF, PDF/A, XPS
**Image:** JPEG, PNG, BMP, TIFF, GIF, SVG
**Web:** HTML, SWF

## Supported Environments

- **Microsoft Windows:** Windows Desktop & Server (x86, x64)
- **macOS:** Mac OS X
- **Linux:** Ubuntu, OpenSUSE, CentOS, and others
- **Java Versions:** `J2SE 6.0 (1.6)` or above

## Get Started with Aspose.Slides for Java

Aspose hosts all Java APIs at the [Aspose Repository](https://repository.aspose.com/webapp/#/artifacts/browse/tree/General/repo/com/aspose/aspose-slides). You can easily use Aspose.Slides for Java API directly in your Maven projects with simple configurations. For the detailed instructions please visit [Installing Aspose.Slides for Java from Maven Repository](https://docs.aspose.com/slides/java/installation/) documentation page.

## Convert Presentation to PDF

```java
// instantiate a Presentation object that represents a presentation file
Presentation pres = new Presentation(""demo.pptx"");
try {
    // save the presentation to PDF with default options
    pres.save(""output.pdf"", SaveFormat.Pdf);
} finally {
    if (pres != null) pres.dispose();
}
```

## Create Presentation from Scratch

```java
// instantiate Presentation
Presentation pres = new Presentation();
try {
    // get the first slide
    ISlide sld = (ISlide) pres.getSlides().get_Item(0);
    
    // add an AutoShape of Rectangle type
    IAutoShape ashp = sld.getShapes().addAutoShape(ShapeType.Rectangle, 150, 75, 150, 50);
    
    // add ITextFrame to the Rectangle
    ashp.addTextFrame(""Hello World"");
    
    // change the text color to Black (which is White by default)
    ashp.getTextFrame().getParagraphs().get_Item(0).getPortions().get_Item(0).getPortionFormat().getFillFormat()
            .setFillType(FillType.Solid);
    ashp.getTextFrame().getParagraphs().get_Item(0).getPortions().get_Item(0).getPortionFormat().getFillFormat()
            .getSolidFillColor().setColor(java.awt.Color.BLACK);
    
    // change the line color of the rectangle to White
    ashp.getShapeStyle().getLineColor().setColor(java.awt.Color.WHITE);
    
    // remove any fill formatting in the shape
    ashp.getFillFormat().setFillType(FillType.NoFill);
    
    // save the presentation to disk
    pres.save(""output.pptx"", SaveFormat.Pptx);
} finally {
    if (pres != null) pres.dispose();
}
```

[Home](https://www.aspose.com/) | [Product Page](https://products.aspose.com/slides/java) | [Docs](https://docs.aspose.com/slides/java/) | [Demos](https://products.aspose.app/slides/family) | [API Reference](https://apireference.aspose.com/slides/java) | [Examples](https://github.com/aspose-slides/Aspose.Slides-for-Java) | [Blog](https://blog.aspose.com/category/slides/) | [Search](https://search.aspose.com/) | [Free Support](https://forum.aspose.com/c/slides) | [Temporary License](https://purchase.aspose.com/temporary-license)
"
openzipkin/brave-example,master,209,139,2013-04-14T14:51:32Z,606,3,A collection of examples how to use brave instrumentation in various frameworks and libraries.,brave distributed-tracing openzipkin zipkin,"# Basic example showing distributed tracing across Java applications
This is an example app where two Java services collaborate on a request.

Notably, these services send data to [Zipkin](https://zipkin.io/), a
distributed tracing system. Zipkin allows you to see the how long the operation
took, as well how much time was spent in each service.

Here's an example of what it looks like:

<img width=""979"" alt=""zipkin screen shot"" src=""https://user-images.githubusercontent.com/64215/95572045-f98cfb80-0a5b-11eb-9d3b-9a1b9b1db6b4.png"">

# Implementation Overview
This example has two services: frontend and backend. Both are [instrumented](https://github.com/openzipkin/brave/tree/master/instrumentation)
to send tracing data to a third service [Zipkin](https://zipkin.io/). [Brave](https://github.com/openzipkin/brave)
performs this function.

# Running the example
To setup the demo, you need to start Frontend, Backend and Zipkin. You can do
this using Java commands or Docker.

Once the services start, open http://localhost:8081/
* This calls the backend (http://127.0.0.1:9000/api) and shows its result: a formatted date.

Afterward, you can view traces that went through the backend via http://127.0.0.1:9411/zipkin?serviceName=backend
* This is a locally run zipkin service which keeps traces in memory

## Tips

There are some interesting details that apply to all examples:
* If you pass the header `user_name` Brave will automatically propagate it to the backend!
  * `curl -s localhost:8081 -H'user_name: JC'`
* The below Logback pattern adds trace and span identifiers into log output
  * `%d{HH:mm:ss.SSS} [%thread] [%X{userName}] [%X{traceId}/%X{spanId}] %-5level %logger{36} - %msg%n`

## Example projects

Here are the example projects you can try:

* [armeria](armeria) `BRAVE_EXAMPLE=armeria docker-compose up`
  * Runtime: Armeria, SLF4J 1.7, JRE 21
  * Trace Instrumentation: [Armeria](https://armeria.dev/), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Brave API](https://github.com/openzipkin/brave/tree/master/brave#setup) [Java](armeria/src/main/java/brave/example/HttpTracingFactory.java)
  * You can also use Eureka discovery like this:
    * `BRAVE_EXAMPLE=armeria docker-compose -f docker-compose.yml -f docker-compose-eureka.yml up`

* [armeria-kafka](armeria-kafka) `BRAVE_EXAMPLE=armeria-kafka docker-compose -f docker-compose.yml -f docker-compose-kafka.yml up`
  * Runtime: Armeria, Kafka Clients and Streams 2.7, SLF4J 1.7, JRE 21
  * Trace Instrumentation: [Armeria](https://armeria.dev/), [Kafka Clients](https://github.com/openzipkin/brave/tree/master/instrumentation/kafka-clients), [Kafka Streams](https://github.com/openzipkin/brave/tree/master/instrumentation/kafka-streams), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Brave API](https://github.com/openzipkin/brave/tree/master/brave#setup) [Java](armeria/src/main/java/brave/example/HttpTracingFactory.java)

* [jersey2-cassandra3](jersey2-cassandra3) `BRAVE_EXAMPLE=jersey2-cassandra3 docker-compose up`
  * Runtime: JaxRS 2, Jersey 2, DataStax Java Driver 3, Apache Cassandra 4, SLF4J 1, JRE 8
  * Trace Instrumentation: [Jersey Server](https://github.com/openzipkin/brave/tree/master/instrumentation/jersey-server), [DataStax Java Driver](https://github.com/openzipkin/brave-cassandra/tree/master/cassandra-driver), [Apache Cassandra](https://github.com/openzipkin/brave-cassandra/tree/master/cassandra), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Brave API](https://github.com/openzipkin/brave/tree/master/brave#setup) [XML](jersey2-cassandra3/src/main/webapp/WEB-INF/tracing.xml)

* [netty4-grpc](netty4-grpc) `BRAVE_EXAMPLE=netty4-grpc docker-compose up`
  * Runtime: Netty 4.1, Google gRPC 1.34  , SLF4J 1.7, JRE 21
  * Trace Instrumentation: [Netty Codec HTTP](https://github.com/openzipkin/brave/tree/master/instrumentation/netty-codec-http), [Google gRPC](https://github.com/openzipkin/brave/tree/master/instrumentation/grpc), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Brave API](https://github.com/openzipkin/brave/tree/master/brave#setup) [Java](netty4-grpc/src/main/java/brave/example/TracingConfiguration.java)

* [webflux5-sleuth](webflux5-sleuth) `BRAVE_EXAMPLE=webflux5-sleuth docker-compose up`
  * Runtime: Spring 5, Reactor Netty 0.9, Spring Boot 2.3, Spring Cloud Sleuth 2.2, Log4J 2.13, JRE 21
  * Trace Instrumentation: [WebFlux Server](https://github.com/spring-cloud/spring-cloud-sleuth/blob/2.2.x/spring-cloud-sleuth-core/src/main/java/org/springframework/cloud/sleuth/instrument/web/TraceWebFilter.java), [WebFlux Client](https://github.com/spring-cloud/spring-cloud-sleuth/blob/2.2.x/spring-cloud-sleuth-core/src/main/java/org/springframework/cloud/sleuth/instrument/web/client/TraceWebClientBeanPostProcessor.java), [Reactor Context](https://github.com/spring-cloud/spring-cloud-sleuth/blob/2.2.x/spring-cloud-sleuth-core/src/main/java/org/springframework/cloud/sleuth/instrument/reactor/ScopePassingSpanSubscriber.java), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Spring Cloud Sleuth](https://github.com/spring-cloud/spring-cloud-sleuth/tree/2.2.x/spring-cloud-sleuth-core/src/main/java/org/springframework/cloud/sleuth/autoconfig) [Properties](webflux5-sleuth/src/main/resources/application.properties)
  * You can also use Eureka discovery like this:
    * `BRAVE_EXAMPLE=webflux5-sleuth docker-compose -f docker-compose.yml -f docker-compose-eureka.yml up`

* [webflux6-micrometer](webflux6-micrometer) `BRAVE_EXAMPLE=webflux6-micrometer docker-compose up`
  * Runtime: Spring 6, Reactor Netty, Spring Boot 3, Micrometer, Log4J 2, JRE 21
  * Trace Configuration: [Spring Boot Actuator](https://github.com/spring-projects/spring-boot/blob/3.2.x/spring-boot-project/spring-boot-actuator-autoconfigure/src/main/java/org/springframework/boot/actuate/autoconfigure/tracing/TracingProperties.java)

* [webmvc25-jetty](webmvc25-jetty) `BRAVE_EXAMPLE=webmvc25-jetty docker-compose up`
  * Runtime: Spring 2.5, Apache HttpClient 4.3, Servlet 2.5, Jetty 7.6, Log4J 1.2, JRE 6
  * Trace Instrumentation: [Servlet](https://github.com/openzipkin/brave/tree/master/instrumentation/servlet), [Spring MVC](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-webmvc), [Apache HttpClient](https://github.com/openzipkin/brave/tree/master/instrumentation/httpclient), [Log4J 1.2](https://github.com/openzipkin/brave/tree/master/context/log4j12)
  * Trace Configuration: [Brave Spring Beans](https://github.com/openzipkin/brave/tree/master/spring-beans#configuration) [XML](webmvc25-jetty/src/main/webapp/WEB-INF/applicationContext.xml)

* [webmvc3-jetty](webmvc3-jetty) `BRAVE_EXAMPLE=webmvc3-jetty docker-compose up`
  * Runtime: Spring 3.2, Apache HttpClient 4.3, Servlet 3.0, Jetty 8.1, Log4J 1.2, JRE 7
  * Trace Instrumentation: [Servlet](https://github.com/openzipkin/brave/tree/master/instrumentation/servlet), [Spring MVC](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-webmvc), [Spring Web](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-web), [Apache HttpClient](https://github.com/openzipkin/brave/tree/master/instrumentation/httpclient), [Log4J 1.2](https://github.com/openzipkin/brave/tree/master/context/log4j12)
  * Trace Configuration: [Brave Spring Beans](https://github.com/openzipkin/brave/tree/master/spring-beans#configuration) [XML](webmvc3-jetty/src/main/webapp/WEB-INF/applicationContext.xml)

* [webmvc4-jetty](webmvc4-jetty) `BRAVE_EXAMPLE=webmvc4-jetty docker-compose up`
  * Runtime: Spring 4.3, OkHttp 3.12, Jetty 9.2, Servlet 3.1, SLF4J 1.7, JRE 8
  * Trace Instrumentation: [Servlet](https://github.com/openzipkin/brave/tree/master/instrumentation/servlet), [Spring MVC](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-webmvc), [Spring Web](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-web), [OkHttp](https://github.com/openzipkin/brave/tree/master/instrumentation/okhttp3), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Brave API](https://github.com/openzipkin/brave/tree/master/brave#setup) [Spring Java Config](webmvc4-jetty/src/main/java/brave/example/TracingConfiguration.java)

* [webmvc4-boot](webmvc4-boot) `BRAVE_EXAMPLE=webmvc4-boot docker-compose up`
  * Runtime: Spring 4.3, OkHttp 3.14, Spring Boot 1.5, Servlet 3.1, Jetty 9.4, SLF4J 1.7, JRE 8
  * Trace Instrumentation: [Servlet](https://github.com/openzipkin/brave/tree/master/instrumentation/servlet), [Spring MVC](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-webmvc), [Spring Web](https://github.com/openzipkin/brave/tree/master/instrumentation/spring-web), [OkHttp](https://github.com/openzipkin/brave/tree/master/instrumentation/okhttp3), [SLF4J](https://github.com/openzipkin/brave/tree/master/context/slf4j)
  * Trace Configuration: [Brave API](https://github.com/openzipkin/brave/tree/master/brave#setup) [Spring Boot AutoConfiguration](webmvc4-boot/src/main/java/brave/example/TracingAutoConfiguration.java)

## Starting the services with Docker

[Docker Compose](https://docs.docker.com/compose/) is the easiest way to start.

Just run `docker-compose up`.

Armeria starts by default. To use a different version of the project, set the `VERSION` variable.

Ex. `VERSION=webmvc25-jetty docker-compose up`

## Starting the services from source

When not using Docker, you'll need to start services according to the frameworks used.

First, start [Zipkin](https://zipkin.io/). This stores and queries traces
reported by the example services. 

Starting Zipkin with Java:
```bash
curl -sSL https://zipkin.io/quickstart.sh | bash -s
java -jar zipkin.jar
```

### Java
In a separate tab or window, start each of `brave.example.Frontend` and `brave.example.Backend`.

Ex.
```bash
$ cd armeria
$ mvn compile exec:java -Dexec.mainClass=brave.example.Backend
$ mvn compile exec:java -Dexec.mainClass=brave.example.Frontend
```

### Servlet
In a separate tab or window, start a Jetty container for ""backend"" and ""frontend"".

Ex.
```bash
$ cd webmvc4-jetty
$ mvn jetty:run -Pfrontend
$ mvn jetty:run -Pbackend
```
"
realwear/Developer-Examples,integration,37,27,2017-07-28T12:11:37Z,29365,3,This repository contains a number of examples with full documentation to help developers create applications for the HMT-1,,"
## Introduction

The code in the Developer Examples app provide clear explanations of how to use the key features that the HMT-1 provides.

Some of the techniques use standard Android practices and are documented here to show common solutions for the HMT-1. Others techniques are unique to the HMT-1 and allow a developer to take advantage of the full WearHF system.

## [Tutorial](https://realwear.github.io/Developer-Examples/tutorial)

The following tutorial shows how to use the Developer Examples app.

## [Release Notes](https://realwear.github.io/Developer-Examples/release-notes)

The release notes are available to show all the changes for each version of the Developer Examples app.
"
serezhka/java-airplay-server-examples,master,75,28,2020-01-21T13:31:10Z,137291,6,,,"# java-airplay-server-examples

[![build](https://github.com/serezhka/java-airplay-server-examples/actions/workflows/build.yaml/badge.svg)](https://github.com/serezhka/java-airplay-server-examples/actions/workflows/build.yaml)
![ViewCount](https://views.whatilearened.today/views/github/serezhka/java-airplay-server-examples.svg)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](http://opensource.org/licenses/MIT)

#### <br><br><br> 14.12.2022: Check out new java-airplay project: https://github.com/serezhka/java-airplay <br><br><br>

All examples were tested with iPhone X (iOS 14.0.1)

## gstreamer-player

09.06.2022 supports both video and audio (alac + aac_eld)

Gstreamer installation required (see https://github.com/gstreamer-java/gst1-java-core)

<details>
  <summary>video demo</summary>

https://user-images.githubusercontent.com/476359/173236828-204a64c0-54da-4020-93c7-2987c4f9301c.mp4
</details>


TODO description

## tcp-forwarder

Forwards video and audio data to TCP

Play it with [GStreamer](https://gstreamer.freedesktop.org/) or [FFmpeg](https://www.ffmpeg.org/)

```Shell
cd tcp-forwarder/

gradle bootRun

gst-launch-1.0 -v tcpclientsrc port=5002 ! h264parse ! avdec_h264 ! autovideosink

or 

ffplay -f h264 -codec:v h264 -i tcp://localhost:5002 -v debug

ffplay -autoexit -f s16le -ar 44100 -ac 2 tcp://localhost:5003
```

You need to compile [lib-fdk-aac](https://github.com/serezhka/fdk-aac-jni) for aac-eld decoding

<details>
  <summary>gif demo</summary>

<img src=""https://github.com/serezhka/java-airplay-server-examples/blob/media/gstreamer_playback.gif"" width=""600"">
</details>


## h264-dump

Saves video data stream to .h264 file, decoded audio to .pcm file

```Shell
cd h264-dump/

gradle bootRun

ffplay -autoexit -f s16le -ar 44100 -ac 2 dump.pcm
```

You need to compile [lib-fdk-aac](https://github.com/serezhka/fdk-aac-jni) for aac-eld decoding

## vlcj-player

Playback screen mirroring in embedded vlc\
Install VLC (https://github.com/caprica/vlcj)

```Shell
cd vlcj-player/

gradle bootRun
```

<details>
  <summary>gif demo</summary>

<img src=""https://github.com/serezhka/java-airplay-server/blob/media/vlcj_player_demo.gif"" width=""600"">
</details>


## jmuxer-player

Playback screen mirroring with [jmuxer](https://github.com/samirkumardas/jmuxer)

```Shell
cd vlcj-player/

gradle bootRun
```

open index-h264.html in browser

<details>
  <summary>gif demo</summary>

<img src=""https://github.com/serezhka/java-airplay-server/blob/media/jmuxer_player_demo.gif"" width=""600"">
</details>
"
isaolmez/javabyexamples,master,40,47,2018-10-07T07:58:01Z,2939,30,Code examples for javabyexamples.com,,"# Java By Examples
Code examples for javabyexamples.com
"
CircleCI-Public/circleci-demo-java-spring,master,58,300,2017-05-22T23:27:50Z,945,2,Example Java application running on CircleCI,circleci circleci-demos java,"# CircleCI 2.0 Java Demo Application using Gradle and Spring [![CircleCI status](https://circleci.com/gh/CircleCI-Public/circleci-demo-java-spring.svg ""CircleCI status"")](https://circleci.com/gh/CircleCI-Public/circleci-demo-java-spring)

**Note:** This project is currently under substantial development to include additional use cases and show off more features of CircleCI.

If you are coming here form the [Java Language Guide](https://circleci.com/docs/2.0/language-java/#config-walkthrough) please follow along at [this revision](https://github.com/CircleCI-Public/circleci-demo-java-spring/tree/9dcdae5e2988b207e0ac9b6bb9cf8ed711fba4ad) before major changes began to take place.

This message will be removed once the CircleCI documentation matches this repository again.

---

This is an example application showcasing how to run a Java app on CircleCI 2.0.

This application uses the following tools:

* Gradle
* Java 11
* PostgreSQL
* Spring Boot
* Thymeleaf

You can follow along with this project by reading the [documentation](https://circleci.com/docs/2.0/language-java/).
An older version of this sample project that uses Maven is accessible [here](https://github.com/CircleCI-Public/circleci-demo-java-spring/tree/maven) though it is no longer being actively maintained.

## Local Development

### Starting the application
```
./gradlew bootRunDev
```

Navigate to http://localhost:8080

![Screenshot of index page](assets/index.png?raw=true ""Screenshot of index page"")

We use the [H2 Database](https://www.h2database.com/html/main.html) in memory for
local development. You can access the datbase UI at [http://localhost:8080/h2-console](http://localhost:8080/h2-console)
with the following credentials.

```
username: `sa`
password: `password`
JDBC URL: jdbc:h2:mem:testdb
```

## License

Copyright © 2019 CircleCI

Distributed under the MIT license, see the file LICENSE.
"
szaza/tensorflow-java-examples-spring,master,56,29,2018-03-05T07:16:10Z,666,1,"Tensorflow Java tutorial with Spring and Gradle. This is a simple example application, which uses Yolo with TF Java API and Spring Framework.",java spring tensorflow tutorial,"# TensorFlow Java tutorial with Spring Framework and Gradle
Object detection server side application sample program written in Java. It uses the TensorFlow Java API with a trained YOLOv2 model. The server application is implemented with Spring Framework and it is built by Gradle.

#### How it works?

It provides a web user interface to upload images and detect objects.

<img src=""https://github.com/szaza/java-tensorflow-spring/blob/master/sample/home-page.jpg"" alt=""TensorFlow Java API home page"" title=""TensorFlow Java API home page"" width=""600""/><br/>
Step1: upload your image

<img src=""https://github.com/szaza/java-tensorflow-spring/blob/master/sample/object-detection-page.jpg"" alt=""TensorFlow Java API object detection page"" title=""TensorFlow Java API object detection page"" width=""600""/><br/>Step2: display the recognized objects

#### Compile and run

Preconditions:
- Java JDK 1.8 or greater;
- TensorFlow 1.6 or grater;
- Git version control system;

Strongly recommended to install:
- nVidia CUDA Toolkit 8.0 or higher version;
- nVidia cuDNN GPU accelerated deep learning framework;

**Download the frozen graph and the label file**

Before compiling the source code you have to place the frozen graph and the label file into the `./graph/YOLO` directory. Download one of my graphs from my [google drive](https://drive.google.com/drive/folders/1GfS1Yle7Xari1tRUEi2EDYedFteAOaoN). There are two graphs: tiny-yolo-voc.pb and yolo-voc.pb. The tiny-yolo.pb has a lower size, however it is less accurate than the yolo-voc.pb. Modify the [application.yml](https://github.com/szaza/tensorflow-java-examples-spring/blob/master/src/main/resources/application.yml) configuration file if it is necessary. Here you can increase the file upload limit also.

**Compile with Gradle**

Compile the code by typing `./gradlew clean build` in the terminal window.<br/>
Run it with the command `./gradlew bootRun`

Open the [http://localhost:8080](http://localhost:8080) and you should see the webpage.<br/>

#### Demo application

Deployed to **Heroku** with a tiny-yolo model: https://still-crag-64816.herokuapp.com/

Have a look at my previous project for better understanding of the object detection part: [Tensorflow Java API example application](https://github.com/szaza/tensorflow-example-java) or visit my site: https://sites.google.com/view/tensorflow-example-java-api.

## News about YoloV3 support

The current solution doesn't support the YoloV3 model and unfortunately, I do not have time to implement it, however I would be very happy if I could help to implement and I could review a PR with this feture. 
For this reason I've started a new branch here: https://github.com/szaza/tensorflow-java-examples-spring/tree/feature/add-yolov3-support; If you are interested in this feature and you would like to be a collabortor, please add a comment for this thread: https://github.com/szaza/tensorflow-java-examples-spring/issues/2;

Many-many thank for any support!
"
jboss-developer/jboss-eap-quickstarts,8.0.x,819,1476,2011-06-09T17:54:35Z,64614,11,"The quickstarts demonstrate JBoss EAP, Jakarta EE 10 and a few additional technologies. They provide small, specific, working examples that can be used as a reference for your own project.",,
coyarzun89/FabTransitionActivity,master,342,64,2015-11-04T17:26:04Z,1787,10,Example of fab animation,,"# FabTransitionActivity
[![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-FabTransitionActivity-green.svg?style=true)](https://android-arsenal.com/details/1/2763)

It is based on [FabTransitionLayout](https://github.com/bowyer-app/FabTransitionLayout)

![transitionactivity](https://github.com/coyarzun89/FabTransitionActivity/blob/master/art/fabTransitionActivity.gif)

Warning: The new version 0.2.0 have minSdkVersion 15 because the [CircularReveal](https://github.com/ozodrukh/CircularReveal) project has moved from 14 to 15

Usage
====
### build.gradle

```
//this is very important, don't forget it
repositories {
    mavenCentral()

    maven {
        url ""https://jitpack.io""
    }
}

defaultConfig {
    minSdkVersion 15
}

dependencies {
    compile 'com.github.coyarzun89:fabtransitionactivity:0.2.0'
}


```

### Layout XML
```
<RelativeLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent"">
    
    <android.support.v7.widget.Toolbar
        android:id=""@+id/toolbar_actionbar""
        xmlns:app=""http://schemas.android.com/apk/res-auto""
        style=""@style/ToolBarStyle""
        xmlns:android=""http://schemas.android.com/apk/res/android""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:background=""@color/primary""
        app:titleTextAppearance=""@style/ToolbarTitle""
        android:minHeight=""56dp""
        android:paddingLeft=""36dp""
        android:elevation=""2dp"" />
        
    <ListView
        android:id=""@+id/list_mails""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:layout_below=""@id/toolbar_actionbar""/>

    <android.support.design.widget.FloatingActionButton
        android:id=""@+id/fab""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:layout_alignParentBottom=""true""
        android:layout_alignParentRight=""true""
        android:layout_marginBottom=""16dp""
        android:layout_marginRight=""16dp""
        android:src=""@drawable/ic_edit_white_24dp""
        app:borderWidth=""0dp""
        app:fabSize=""normal""
        app:rippleColor=""@color/primary""/>

    <com.github.fabtransitionactivity.SheetLayout
        android:id=""@+id/bottom_sheet""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:layout_gravity=""bottom""
        app:ft_container_gravity=""center""
        app:ft_color=""@color/primary""
        android:elevation=""2dp""/>

</RelativeLayout>

```

### Set up

```java
public class MainActivity extends BaseActivity implements SheetLayout.OnFabAnimationEndListener {

    @Bind(R.id.bottom_sheet) SheetLayout mSheetLayout;
    @Bind(R.id.fab) FloatingActionButton mFab;
    
    private static final int REQUEST_CODE = 1;
    
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        ButterKnife.bind(this);

        mSheetLayout.setFab(mFab);
        mSheetLayout.setFabAnimationEndListener(this);
    }
    
    @OnClick(R.id.fab)
    void onFabClick() {
        mSheetLayout.expandFab();
    }

    @Override
    public void onFabAnimationEnd() {
        Intent intent = new Intent(this, AfterFabAnimationActivity.class);
        startActivityForResult(intent, REQUEST_CODE);
    }

   @Override
   public void onActivityResult(int requestCode, int resultCode, Intent data) {
       super.onActivityResult(requestCode, resultCode, data);
       if(requestCode == REQUEST_CODE){
           mSheetLayout.contractFab();
       }
   }
```

# Credits
This library use following libraries.
* [CircularReveal](https://github.com/ozodrukh/CircularReveal)
"
in28minutes/JavaTutorialForBeginners,master,29,63,2016-08-31T07:26:09Z,137,1,Java Tutorial for Beginners with examples,java java-8,"# Title of the Best Course in the world
## Caption for the course.

* [Installing Eclipse, Maven and Java](#installing-tools)
* [Running Examples](#running-examples)
* [Course Overview](#course-overview)
  - [Course Steps](#step-list)
  - [Expectations](#expectations)
* [About in28Minutes](#about-in28minutes)
  - [Our Beliefs](#our-beliefs)
  - [Our Approach](#our-approach)
  - [Find Us](#useful-links)
  - [Other Courses](#other-courses)

## Getting Started
- Eclipse - https://courses.in28minutes.com/p/eclipse-tutorial-for-beginners
- Maven - https://courses.in28minutes.com/p/maven-tutorial-for-beginners-in-5-steps
- JUnit - https://courses.in28minutes.com/p/junit-tutorial-for-beginners
- Mockito - https://courses.in28minutes.com/p/mockito-for-beginner-in-5-steps

## Installing Tools
- PDF : https://github.com/in28minutes/SpringIn28Minutes/blob/master/InstallationGuide-JavaEclipseAndMaven_v2.pdf
- Video : https://www.youtube.com/playlist?list=PLBBog2r6uMCSmMVTW_QmDLyASBvovyAO3
- GIT Repository : https://github.com/in28minutes/getting-started-in-5-steps

## Running Examples
- Download the zip or clone the Git repository.
- Unzip the zip file (if you downloaded one)
- Open Command Prompt and Change directory (cd) to folder containing pom.xml
- Installation Video : https://www.youtube.com/playlist?list=PLBBog2r6uMCSmMVTW_QmDLyASBvovyAO3
- For help : use our installation guide - https://github.com/in28minutes/SpringIn28Minutes/blob/master/InstallationGuide-JavaEclipseAndMaven_v2.pdf 

## Course Overview

- I'm Ranga Karanam. I've so and so much experience with ...
- In this course, You will learn the *** Framework step by step with (*** functionality) using (*** framework features)
- You will learn the basics like *** and move on to the advanced concepts like ***.
- You will use 
  - ... todo ...
  - Maven for dependency management, building and running the application in tomcat.
  - Eclipse IDE.


### Introduction
Developing your first application with XYZ Framework is fun.

Introduction to XYZ Framework..

In this course, you will learn the basics developing a Basic Todo Management Application using XYZ Framework.

You will build the application step by step - in more than 25 steps. This course would be a perfect first step as an introduction to XYZ Framework.

You will be using Spring (Dependency Management), Spring MVC, Spring Boot, Spring Security (Authentication and Authorization), BootStrap (Styling Pages), Maven (dependencies management), Eclipse (IDE) and Tomcat Embedded Web Server. We will help you set up each one of these.

You will learn about
- Topic No 1
- Topic No 1
- Topic No 1
- Topic No 1
- Topic No 1

### Step Wise Details
- Step 01: Learn to Dance
- Step 02: 
- Step 03: 
- Step 04: 
- Step 05: 
- Step 06: 
- Step 07: 
- Step 08: 
- Step 09: 
- Step 10: 
- Step 11: 
- Step 12: 
- Step 13: 
- Step 14: 
- Step 15: 
- Step 16: 
- Step 17: 
- Step 18: 
- Step 19: 
- Step 20: 
- Step 21: 
- Step 22: 
- Step 23: 
- Step 24: 
- Step 25: 

### Expectations
- You should know ***. 
- You should know ***. 
- You are NOT expected to have any experience with Eclipse,Maven or Tomcat.
- We will help you install Eclipse and get up and running with Maven and Tomcat.

## Let's have some fun
- What are we waiting for?
- Let's have some fun with *** in 25 Steps.
- I had fun creating this course and hope you would too.
- Thanks for your interest in Our Course 
  - I hope you’re as excited as I am!  
  - If you’re ready to learn more and sign up for the course, 
  - go ahead and hit that Enroll button, 
  - or take a test drive by using the Free Preview feature.  
- See you in the course!

## Exercises
- TODO

## Future Things To Do
- TODO

## Conclusion
- Thats a lot of ground you have covered over the last so and so..
- To find out more about *** use these References  
- I had fun creating this course and I'm sure you had some fun too.
- Good Luck and Bye from the team here at in28Minutes
- Do not forget to leave us a review.

## About in28Minutes

At in28Minutes, we ask ourselves one question everyday
> How do we create more amazing course experiences? 
> We use 80-20 Rule. We discuss 20% things used 80% of time in depth.

We are creating amazing learning experiences for learning Spring Boot with AWS, Azure, GCP, Docker, Kubernetes and Full Stack. 300,000 Learners rely on our expertise.  [Find out more.... ](https://github.com/in28minutes/learn#best-selling-courses)

![in28MinutesLearningRoadmap-July2019.png](https://github.com/in28minutes/in28Minutes-Course-Roadmap/raw/master/in28MinutesLearningRoadmap-July2019.png)
"
tdziurko/Guava-Lessons,master,100,44,2012-02-18T16:34:34Z,122,1,Various examples of usage Google Guava API.,,
mianshenglee/my-example,master,123,143,2019-08-23T10:14:26Z,29223,7,example code for my article,,"# 1. 说明

在写文章过程中，经常会使用一些示例工程来辅助说明，本仓库用于存放一些示例工程，以便于读者可以参考。

# 2. 示例说明

## 2.1 java应用监测：`java-monitor-example`

用于[java监测技术文章](https://mianshenglee.github.io/)的示例说明，此示例是一个`spring boot`工程，里面包含简单的`controller`和`service`类，`OOM`的接口等功能。

文章列表如下：

- [java应用监测(1)-java程序员应该知道的应用监测技术](https://mianshenglee.github.io/2019/08/23/java-monitor-1.html)
- [java应用监测(2)-java命令的秘密]( https://mianshenglee.github.io/2019/08/24/java-monitor-2.html )
- [java应用监测(3)-这些命令行工具你掌握了吗]( https://mianshenglee.github.io/2019/08/25/java-monitor-3.html )
- [java应用监测(4)-线上问题排查套路]( https://mianshenglee.github.io/2019/08/26/java-monitor-4.html )
- [java应用监测(5)-可视化监测工具]( https://mianshenglee.github.io/2019/08/27/java-monitor-5.html )
- [java应用监测(6)-第三方内存分析工具MAT]( https://mianshenglee.github.io/2019/08/29/java-monitor-6.html )
- [java应用监测(7)-在线动态诊断神器BTrace]( https://mianshenglee.github.io/2019/08/30/java-monitor-7.html )
- [java应用监测(8)-阿里诊断工具arthas]( https://mianshenglee.github.io/2019/08/31/java-monitor-8.html )

## 2.2 Swagger企业实践：`springboot-swagger-demo`

基于springboot2+swagger2，结合在企业中的实践，对接口文档的编写进行详细说明。

1. `hello-swagger-demo`

- 示例功能： 包括swagger介绍及文档生成说明，构建示例工程及配置描述，使用注解添加文档内容说明，使用全局参数进行接口认证。
- 文章：[springboot+swagger接口文档企业实践（上）](https://mianshenglee.github.io/2019/11/13/springboot-swagger1.html)

2. `advance-sagger-demo`

- 示例功能：包含对接口进行动态过滤，结合easymock进行数据模拟，对接口文档进行离线文档输出等功能。
- 文章：[springboot+swagger接口文档企业实践（下）](https://mianshenglee.github.io/2019/11/21/springboot-swagger2.html)

## 2.3 logback企业实践：`springboot-logback-demo`

基于springboot+logback，对日志输出框架的使用示例，结合在企业中的实践进行详细说明。

1. `logback-simple-demo`

- 示例功能： 使用springboot+logback构建示例工程及配置描述，对logback配置文件的详述及使用，实现按日志级别输出到文件功能。
- 文章：[springboot+logback日志输出企业实践（上）](https://mianshenglee.github.io/2019/11/28/logback1.html)

2. `logback-advance-demo`

- 示例功能：对 logback 的进阶使用进行描述，主要包括日志异步输出，多环境日志配置以及使用MDC进行分布式系统请求追踪。
- 文章：[springboot+logback日志输出企业实践（下）]( https://mianshenglee.github.io/2019/11/29/logback2.html )



## 2.4 java动态代理：`dynamic-proxy-demo`

对java的动态代理技术的使用示例，示例中包含了java反射、静态代理、动态代理、Spring AOP的使用实例。配套以下文章进行学习：

- 文章：[java开发必学知识:动态代理](https://mianshenglee.github.io/2019/12/20/dynamicproxy.html)



## 2.5 多数据源处理： `multi-datasource`

基于 Spring Boot 2+MyBatis Plus ，对多数据源的处理代码。

1. `basic-multi-datasource`
- 示例功能： 使用多套数据源的策略，实现一主一从的数据库逻辑。
- 文章：[搞定SpringBoot多数据源(1)：多套源策略](https://mianshenglee.github.io/2020/01/13/multi-datasource-1.html)

2. `dynamic-datasource`

- 示例功能： 使用动态数据源策略进行数据源切换，也可使用 AOP 方式进行数据源切换，实现一主一从的数据库逻辑。
- 文章：[搞定SpringBoot多数据源(2)：动态数据源](https://mianshenglee.github.io/2020/01/13/multi-datasource-2.html)

3. `parametric-dynamic-datasource`

- 示例功能： 根据参数动态添加数据源以及切换数据源，解决不确定数据源的问题。
- 文章：[搞定SpringBoot多数据源(3)：参数化变更源](https://mianshenglee.github.io/2020/01/13/multi-datasource-3.html)

## 2.6 使用python自动化生成数据库说明文档：` python/tool-gen-db-doc `

通过使用 SQL 读取数据库表及字段元信息，然后输出到 excel 文档的思路，以 python 的实现方式完成自动生成文档功能

- 文章：[还在手工生成数据库文档？3个步骤自动完成了解一下](https://mianshenglee.github.io/2020/08/30/db-doc-python.html)

# 如何找到我的更多文章

- [我的Blog](https://mianshenglee.github.io)：`https://mianshenglee.github.io/`

- 我的公众号（搜索`Mason技术记录`）：

![mason](https://gitee.com/mianshenglee/datastorage/raw/master/md-photo/myphoto/wx/wx-public.jpg)

- 各大博客平台（CSDN，掘金，开源中国，博客园，语雀，segmentfault，开发者头条），搜索`Mason技术记录`也可以找到









"
langmi/spring-batch-examples-readers,master,29,38,2013-04-29T09:21:25Z,456,0,,,
mayanhui/hadoop-hbase-examples,master,37,27,2013-02-22T02:33:43Z,357,0,"hadoop hbase use case and examples, inclusing MR,HBaseUtil...",,"Applications based on hadoop & hbase

#1. hadoop mapreduce application

(1) multi-jobs 

(2) distribute cache

(3) split file size

#2. hbase application

(1) bulk load vv to hbase

(2) bulk load search keyword to hbase

(3) bulk load ads

#3. Redis read & write

(1) random read

(2) mapreduce bulk load

(3) hash type data bulk load
"
datumbox/datumbox-framework-examples,develop,41,26,2015-05-02T12:29:17Z,619,0,Code examples on how to use the Datumbox Machine Learning Framework.,,"Code Examples for Datumbox Machine Learning Framework
=====================================================

[![Datumbox](http://www.datumbox.com/img/logo.png)](http://www.datumbox.com/)

This project provides examples on how to use the [Datumbox Machine Learning Framework](https://github.com/datumbox/datumbox-framework/) v0.8.3-SNAPSHOT (Build 20201014).

Copyright & License
-------------------

Copyright (c) 2013-2020 [Vasilis Vryniotis](http://blog.datumbox.com/author/bbriniotis/). 

The code is licensed under the [Apache License, Version 2.0](./LICENSE).

How to use
----------

The code uses Maven Project Structure and contains the following code examples:

- [Classification.java](./src/main/java/com/datumbox/examples/Classification.java): Contains an example on how to perform Classification.
- [Clustering.java](./src/main/java/com/datumbox/examples/Clustering.java): It is an example that runs Cluster Analysis.
- [Regression.java](./src/main/java/com/datumbox/examples/Regression.java): Shows how to run Regression Analysis.
- [DataModeling.java](./src/main/java/com/datumbox/examples/DataModeling.java): Explains how to use the convenience Modeler class.
- [TextClassification.java](./src/main/java/com/datumbox/examples/TextClassification.java): Uses the convenience TextClassifier class.

All of the above files contain a main() method. To use it just clone the project on your workspace and run any of the above files.

The project contains also 5 configuration files in the resources folder:

- [datumbox.configuration.properties](./src/main/resources/datumbox.configuration.properties): It defines for the default storage engine (required).
- [datumbox.concurrencyconfiguration.properties](./src/main/resources/datumbox.concurrencyconfiguration.properties): It controls the concurrency levels (required).
- [datumbox.inmemoryconfiguration.properties](./src/main/resources/datumbox.inmemoryconfiguration.properties): It contains the configurations for the InMemory storage engine (required).
- [datumbox.mapdbconfiguration.properties](./src/main/resources/datumbox.mapdbconfiguration.properties): It contains the configurations for the MapDB storage engine (optional).
- [logback.xml](./src/main/resources/logback.xml): It contains the configuration file for the logger (optional).

Finally in the resources folder there are several [real world datasets](./src/main/resources/datasets/) which are used for testing.

Useful Links
------------

- [Datumbox Machine Learning Framework](https://github.com/datumbox/datumbox-framework/)
- [Datumbox Zoo: Pre-trained models](https://github.com/datumbox/datumbox-framework-zoo/)
- [Datumbox.com](http://www.datumbox.com/)
- [Machine Learning Blog](http://blog.datumbox.com/)

"
mp911de/spring-cloud-vault-config-samples,main,94,64,2016-04-27T14:15:05Z,438,3,Examples for Spring Vault and Spring Cloud Vault Config,samples spring spring-cloud-vault spring-vault vault,
Gsantomaggio/rabbitmqexample,master,56,21,2014-04-27T10:15:42Z,507,0,RabbitMQ Examples,,"rabbitmqexample
===============

Here some RabbitMQ example. 
1. webSocketPython : How to redirect RabbitMQ messages to web-page using http://www.tornadoweb.org/. 

To get ready you need pika and tornado in this way: 
```
pip install pika 
pip install tornado 

```
Execute my-server.py and open a web page on http://localhost:8888/ 
Try to send a message to ""my_queue"" on rabbitmq (or simply use sendtest.py)  , it will be redirected to all connected clients. 


"
bonigarcia/selenium-webdriver-java,master,155,87,2019-12-11T17:14:07Z,4740,3,"Examples of the O'Reilly book Hands-On Selenium WebDriver with Java""""",docker gradle java junit4 junit5 maven selenium selenium-jupiter selenium-webdriver selenium4 testng,"[![Build Status](https://github.com/bonigarcia/selenium-webdriver-java/workflows/build/badge.svg)](https://github.com/bonigarcia/selenium-webdriver-java/actions)
[![badge-jdk](https://img.shields.io/badge/jdk-17-green.svg)](https://www.oracle.com/java/technologies/downloads/)
[![License badge](https://img.shields.io/badge/license-Apache2-green.svg)](https://www.apache.org/licenses/LICENSE-2.0)
[![Support badge](https://img.shields.io/badge/stackoverflow-selenium_webdriver-green.svg?logo=stackoverflow)](https://stackoverflow.com/questions/tagged/selenium-webdriver)
[![Twitter Follow](https://img.shields.io/twitter/follow/boni_gg.svg?style=social)](https://twitter.com/boni_gg)

# Hands-On Selenium WebDriver with Java [![][Logo]][GitHub Repository]

This repository contains a comprehensive collection of examples about [Selenium] 4 using [Java] as language binding. These examples are explained in the O'Reilly book [Hands-On Selenium WebDriver with Java].

[![][Cover]][Hands-On Selenium WebDriver with Java]

This repo has been implemented as a multi-module project (using [Maven] and [Gradle] as build tools) composed of tests based on different frameworks: [JUnit 4], [JUnit 5] (alone or extended with [Selenium-Jupiter]), and [TestNG].

## Practice site

This repo also contains a [Practice site], i.e., a representative set of sample web pages used as the system under test (SUT) in the Selenium WebDriver test examples. This site is hosted using [GitHub Pages].

## Tags

This repo uses Git tags to track the evolution of the codebase in time. These tags are the following:

* `1.0.0`: The examples of the first version of the book (released in April 2022) are based on this tag.
* `1.1.0`: Bump to Java 11, due to the incompatibility of TestNG 7.6.0 (released on May 18, 2022) with Java 8.
* `1.2.0`: Remove GitHub token from the workflow setup, not required anymore since WebDriverManager 5.3.0 (released on August 21, 2022).
* `1.3.0`: Bump to Java 17, due to the incompatibility of Spring Boot 3.0.0 (released on Nov 24, 2022) with Java 11.

## About

selenium-webdriver-java (Copyright &copy; 2021-2024) is an open-source project created and maintained by [Boni Garcia], licensed under the terms of [Apache 2.0 License].

[Logo]: https://bonigarcia.dev/selenium-webdriver-java/img/hands-on-icon.png
[GitHub Repository]: https://github.com/bonigarcia/selenium-webdriver-java/
[Apache 2.0 License]: https://www.apache.org/licenses/LICENSE-2.0
[Boni Garcia]: https://bonigarcia.dev/
[Gradle]: https://gradle.org/
[Java]: https://www.java.com/
[JUnit 4]: https://junit.org/junit4/
[JUnit 5]: https://junit.org/junit5/docs/current/user-guide/
[Maven]: https://maven.apache.org/
[Selenium]: https://www.selenium.dev/
[Selenium-Jupiter]: https://bonigarcia.dev/selenium-jupiter/
[TestNG]: https://testng.org/doc/
[Hands-On Selenium WebDriver with Java]: https://oreil.ly/1E7CX
[Cover]: https://bonigarcia.dev/img/hands-on-selenium-webdriver-java.png
[Practice site]: https://bonigarcia.dev/selenium-webdriver-java/
[GitHub Pages]: https://pages.github.com/
"
matzuk/Clean-multimodel-arch,master,176,56,2018-08-23T08:14:45Z,243,0,Multimodel architecture example,,
esanchezros/quickfixj-spring-boot-starter-examples,master,57,34,2017-11-02T21:58:14Z,246,0,QuickFixJ Spring Boot Starter Examples,,
halysongoncalves/Material-Design-Example,master,126,61,2014-12-16T12:41:07Z,43382,0,Material-Design-Example,,"Material Design Example
========================
[![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-Android--ObservableScrollView-brightgreen.svg?style=flat)](https://android-arsenal.com/details/3/1296)

Material Design Example is a sample application for the new design concept made by Google, Material Design. Besides the design, we have the new APIs introduced in Android SDK Lollipop:

* Custom theme colors
* Circular reveal
* Activity transitions
* Toolbar
* Recycler View
* Card View
* Floating Action Button
* ObservableScrollView

Pre-requisites
--------------

*  Android SDK v14
*  Android Support Repository

Screenshots
-------------

<img src=""art/MaterialExampleDesign1.png"" height=""400"" alt=""Screenshot""/> 
<img src=""art/MaterialExampleDesign2.png"" height=""400"" alt=""Screenshot""/> 


Getting Started
---------------

This sample uses the Gradle build system. To build this project, use the
""gradlew build"" command or use ""Import Project"" in Android Studio.

 Support
-------

If you've found an error in this sample, please file an issue:
https://github.com/halysongoncalves/Material-Design-Example

Patches are encouraged, and may be submitted by forking this project and
submitting a pull request through GitHub. Please see CONTRIBUTING.md for more details.

Contributions
---------------
Any contributions are welcome!  
Please check the [contributing guideline](https://github.com/halysongoncalves/Material-Design-Example/blob/master/CONTRIBUTING.md) before submitting a new issue.

Credits
---------------
* Inspired by `ObservableScrollView` in [romannurik-code](https://code.google.com/p/romannurik-code/).
* Inspired by `Android-ObservableScrollView` in [ksoichiro](https://github.com/ksoichiro/Android-ObservableScrollView).

Samples
---------------
  [![Google Play](http://developer.android.com/images/brand/en_generic_rgb_wo_45.png)](https://play.google.com/store/apps/details?id=br.com.halyson.materialdesign)

<h2>Copyright</h2>

    Copyright 2014 Halyson Gonçalves. All rights reserved.

    Licensed under the Apache License, Version 2.0 (the ""License"");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an ""AS IS"" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.


"
jrodenbostel/beyond-the-examples,master,31,28,2014-04-08T01:25:05Z,261,1,Code to support the Beyond The Examples series of blog posts at http://justinrodenbostel.com,,"beyond-the-examples
===================

A series of projects intended to provide a step-by-step walkthrough of Spring-Boot, building an application from provided examples to something more useful in a real-world setting.
"
sandeep0402/technicalsand.com-examples,master,28,29,2020-09-26T12:17:32Z,5952,1,All the examples mention in https://technicalsand.com ,,"# technicalsand.com-examples
All the examples mention in https://technicalsand.com 
"
senbox-org/snap-examples,master,39,20,2015-03-24T10:04:47Z,368,0,SNAP example projects showing how to extend SNAP or build new applications on SNAP,,"# snap-examples
SNAP example projects showing how to extend SNAP or build new applications on SNAP

## TOC

* **snap-desktop-basic-single** - Template for a basic SNAP desktop extension that generates a single plugin (@snap dev team: keep this simple as possible!)
* **snap-desktop-basic-multi** - Template for a basic SNAP desktop extension that generates multiple plugins (@snap dev team: keep this simple as possible!)
* **snap-engine-python-operator** - Template for a basic SNAP engine extension that generates a single plugin comprising one or more data processing operators written in Python
"
xumingming/storm-lib,master,60,40,2012-05-19T02:59:54Z,122,1,"hold storm examples, tests etc here.",,"storm-lib
=========

hold storm examples, tests etc here."
eclipse/hawkbit-examples,master,27,23,2016-10-20T14:01:39Z,549,8,,,"<img src=hawkbit_logo.png width=533 height=246 />

# Eclipse hawkBit™ - Examples collection

Example projects that show how [hawkBit](https://github.com/eclipse/hawkbit) can be customized or hawkBit compatible APIs leveraged.

[![Circle CI](https://circleci.com/gh/eclipse/hawkbit-examples.svg?style=shield)](https://circleci.com/gh/eclipse/hawkbit-examples)

## API client examples

- `hawkbit-example-ddi-feign-client` : Example client based on the feign project for hawkBit's [Direct Device Integration API](https://www.eclipse.org/hawkbit/apis/ddi_api).
- `hawkbit-example-mgmt-feign-client` : Example client based on the feign project for hawkBit's [Management API](https://www.eclipse.org/hawkbit/apis/management_api)

## Simulators

- `hawkbit-device-simulator` : Simulates device software updates, leveraging the hawkBit device integration options.  
- `hawkbit-example-mgmt-simulator` : Example client simulation for the _hawkBit_ Management API based on Spring Boot and the hawkbit-example-mgmt-feign-client.


## Customization examples

- `hawkbit-custom-theme-example` : Example for a customized theme for [Management UI](https://www.eclipse.org/hawkbit/ui).
"
wildfly/wildfly-archetypes,main,27,40,2014-06-16T13:05:02Z,1401,6,WildFly maven archetypes & examples,,"WildFly archetypes
==================

This project contains Maven Archetypes to generate Maven projects to develop Jakarta EE applications with [WildFly](https://wildfly.org/)

* [wildfly-jakartaee-webapp-archetype](/wildfly-jakartaee-webapp-archetype/) generates a Maven project to develop a simple Web Archive (WAR) with WildFly
* [wildfly-jakartaee-ear-archetype](/wildfly-jakartaee-ear-archetype/) generates a Maven project to develop a Entreprise Archive (EAR) with WildFly. It generates an EJB and WAR modules to compose the EAR
* [wildfly-subsystem-archetype](/wildfly-subsystem-archetype/) generates a Maven project to develop a WildFly subsystem to extend the capabilities of WildFly.

## Component dependencies

The versions of all dependencies and plugins that are used by this archetype are configured in the parent's `pom.xml`.

To update the archetypes to new versions:

* update to latest ""org.jboss:jboss-parent"" version found at https://repo.maven.apache.org/maven2/org/jboss/jboss-parent/
* update the version property named ""version.wildfly.bom""
* update the version property named ""version.wildfly.core"" to the version bundled with WildFly (found in ""%WILDFLY_HOME%/modules/system/layers/base/org/jboss/as/controller/main"").
* check whether dependencies have changed.
* check the plugin versions and update if necessary:
  * wildfly-maven-plugin: https://repo.maven.apache.org/maven2/org/wildfly/plugins/wildfly-maven-plugin/
  * maven-compiler-plugin: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-compiler-plugin/
  * maven-surefire-plugin: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-surefire-plugin/
  * maven-failsafe-plugin: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-failsafe-plugin/
  * maven-war-plugin: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-war-plugin/
  * maven-ear-plugin: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-ear-plugin/
  * maven-ejb-plugin: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-ejb-plugin/

### Injection of dependencies in the archetypes resources

The versions of all dependencies and plugins that are used by this archetype are configured in the parent's `pom.xml`.

For each archetype, their archetype-resources `pom.xml` is still in Git but in a separate source tree (e.g. `wildfly-jakartaee-ear-archetype/src/main/resources-filtered/archetype-resources/pom.xml`).
When the archetypes are built, their `pom.xml` are filtered with the property values from the parent pom (so their own `version.wildfly.bom` will have the *actual* value of the parent's `version.wildfly.bom`).

The reason of this structure is that we want to evaluate some property values when we built the archetype (for the versions) and keep others that will be evaluate when the project is generated by the archetypes (eg `${rootArtifactId}`) . The latter properties are escaped from filtering by prepending a `/`."
cescoffier/reactive-systems-in-java,main,78,35,2021-03-03T09:33:02Z,1824,14,Reactive Systems in Java Code Examples,,"# Reactive Systems in Java book examples

Welcome World!

These are the working examples for Reactive Systems in Java from O'Reilly and written by Clement Escoffier and Ken Finnigan.

## How to open and run the examples?
Readers of the book should directly open projects from sub-folders: they are all independent and self-contained.

You will find Maven build descriptors for each project, so you can load the projects with text editors or integrated development environments such as IntelliJ IDEA, Eclipse IDE or Microsoft Visual Studio Code.

As an example if you want to build the code example from the chapter 2, open a terminal and run:

```shell script
$ cd chapter-2
$ mvn package # or ./mvnw package
```

The book examples work best using some Unix environment: Linux, macOS or the Windows Subsystem for Linux from Microsoft.

## What is the structure of the repository?

The following folders are available:

* [Chapter 2 - Introduction to Quarkus](./chapter-2)
* [Chapter 3 - Distributed Systems: What the heck?](./chapter-3)
* [Chapter 4 - Design Principles of Reactive Systems](./chapter-4)
* [Chapter 5 - Reactive Programming: Taming the Asynchronicity](./chapter-5)
* [Chapter 7 - Mutiny: An Event-Driven Reactive Programming API](./chapter-7)
* [Chapter 8 - HTTP with Reactive in Mind](./chapter-8)
* [Chapter 9 - Accessing Data Reactively](./chapter-9)
* [Chapter 10 - Reactive Messaging: The Connective Tissue](./chapter-10)
* [Chapter 11 - The Event Bus: The Backbone](./chapter-11)
* [Chapter 12 - Reactive REST Client: Connecting with HTTP Endpoints](./chapter-12)
* [Chapter 13 - Observing Reactive and Event-Driven Architectures](./chapter-13)

The _main_ branch is where you must look for working examples.

"
Wikidata/Wikidata-Toolkit-Examples,master,48,22,2015-11-15T17:04:28Z,126,1,Examples showing how to use Wikidata Toolkit as a Maven library in your project,,"# Wikidata Toolkit Examples

This is an example project that shows how to set up a Java project that
uses [Wikidata Toolkit](https://github.com/Wikidata/Wikidata-Toolkit).
It contains several simple example programs and bots in the source directory.

What's found in this repository
-------------------------------

The individual examples are documented in the README file of each package.


Running examples using an IDE
-----------------------------

You can import the project into any Java IDE that supports Maven (and maybe git)
and run the example programs from there. Wikidata Toolkit provides detailed
[instructions on how to set up Eclipse for using Maven and git](https://www.mediawiki.org/wiki/Wikidata_Toolkit/Eclipse_setup).


Running examples directly using Maven
-------------------------------------

You can also run the code directly using Maven from the command line. For this,
you need to have Maven and (obviously) Java installed. To compile the project
and obtain necessary dependencies, run

```mvn compile```

Thereafter, you can run any individual example using its Java class name, for
example:

```mvn exec:java -Dexec.mainClass=""examples.FetchOnlineDataExample""```

Credits and License
-------------------

This project is copied from the [Wikidata Toolkit](https://github.com/Wikidata/Wikidata-Toolkit) examples module.
Authors can be found there.

License: [Apache 2.0](LICENSE)

"
algorithmica-repository/top20,master,129,182,2014-06-24T00:35:49Z,9377,8,It consists of all the code examples of Top-20(problem solving) course taken at algorithmica,,"top20
=====

It consists of all the code examples of Top-20(Problem solving) course taken up at Algorithmica across all years. You can use/redistribute this code for academic purpose only. 
"
YugabyteDB-Samples/orm-examples,master,31,21,2019-03-09T02:13:37Z,794,21,Examples showing how to use various ORMs with YSQL,,"# Using ORMs with YugabyteDB

This repository has examples showing build a simple REST API server using ORMs on top of YugabyteDB (using the YSQL API). The scenario modelled is that of a simple online e-commerce store. It consists of the following.

* The users of the ecommerce site are stored in the `users` table.
* The `products` table contains a list of products the ecommerce site sells.
* The orders placed by the users are populated in the `orders` table. An order can consist of multiple line items, each of these are inserted in the `orderline` table.

## Step 1. Install YugabyteDB

You should first [install YugabyteDB](https://docs.yugabyte.com/latest/quick-start/), which is a distributed SQL database compatible with the PostgreSQL language.

## Step 2. Bring up the REST API server

The same REST APIs are implemented using various ORMs. Each of these is present in one of the sub-directories in this repo. For example, to start the REST API server using `Spring`, simply go to the appropriate directory and follow the instructions there.

By default, the REST API server listens on `localhost` port `8080`.

| Directory  | ORM |
| ------------- | ------------- |
| [Java - Spring](https://github.com/YugaByte/orm-examples/blob/master/java/spring)  | Spring Data JPA (uses Hibernate internally)   |
| [Core Java - Hibernate](https://github.com/YugaByte/orm-examples/blob/master/java/hibernate)  | Core Java - Hibernate Example   |
| [Java - Mybatis](https://github.com/YugaByte/orm-examples/blob/master/java/mybatis)  | Java - Mybatis Example   |
| [Scala - Play](https://github.com/YugaByte/orm-examples/blob/master/java/ebean)  | Play Framework Example   |
| [Golang - Gorm](https://github.com/YugaByte/orm-examples/blob/master/golang/gorm)  | Gorm   |
| [NodeJS - Sequelize](https://github.com/YugaByte/orm-examples/blob/master/node/sequelize)  | Sequelize   |
| [Python - SQLAlchemy](https://github.com/YugaByte/orm-examples/blob/master/python/sqlalchemy)  | SQL Alchemy   |
| [Python - django](https://github.com/YugaByte/orm-examples/blob/master/python/django)  | Django   |
| [Ruby on Rails - ActiveRecord](https://github.com/YugaByte/orm-examples/tree/master/ruby/ror)  | ActiveRecord   |
| [Rust - Diesel](https://github.com/YugaByte/orm-examples/blob/master/rust/diesel)  | Rust Diesel   |
| [C# - Dapper](https://github.com/YugaByte/orm-examples/blob/master/csharp/dapper)  | Dapper   |
| [Php - Laravel](https://github.com/YugaByte/orm-examples/blob/master/php/laravel/)  | Php Laravel   |



## Step 3. Create a user

You can create a user named `John Smith` and email `jsmith@example.com` as follows:

```
$ curl --data '{ ""firstName"" : ""John"", ""lastName"" : ""Smith"", ""email"" : ""jsmith@example.com"" }' \
       -v -X POST -H 'Content-Type:application/json' http://localhost:8080/users
```

This will return the inserted record as a JSON document:
```
{
  ""userId"": ""1"",
  ""firstName"": ""John"",
  ""lastName"": ""Smith"",
  ""email"": ""jsmith@example.com""
}
```

You can connect to YugabyteDB using `psql` and select these records:
```
postgres=# select * from users;
 user_id | first_name | last_name |  user_email
---------+------------+-----------+---------------
       1 | John       | Smith     | jsmith@example.com(1 row)
```

## Step 4. List all users

You can list the current set of users by running the following:
```
$ curl http://localhost:8080/users
```

You should see the following output:
```
{
  ""content"": [
    {
      ""userId"":""1"",
      ""email"":""jsmith@example.com"",
      ""firstName"":""John"",
      ""lastName"":""Smith""
    }
  ],
  ...
}
```

## Step 5. Create a product

You can create a product listing as follows:
```
$ curl \
  --data '{ ""productName"": ""Notebook"", ""description"": ""200 page notebook"", ""price"": 7.50 }' \
  -v -X POST -H 'Content-Type:application/json' http://localhost:8080/products
```

You should see the following return value:
```
{
  ""productId"": ""1"",
  ""productName"": ""Notebook"",
  ""description"": ""200 page, hardbound, blank notebook"",
  ""price"": 7.5}
```

## Step 6. List all products

You can do this as follows:
```
$ curl http://localhost:8080/products
```

You should see an output as follows:
```
{
  ""content"":[
    {
      ""productId"": ""1"",
      ""productName"": ""Notebook"",""description"":""200 page, hardbound, blank notebook"",
      ""price"": 7.5
    }
  ],
  ...
}
```

## Step 7. Create an order

Creating an order involves a user id ordering a particular product, this can be achieved as follows:
```
$ curl \
  --data '{ ""userId"": ""1"", ""products"": [ { ""productId"": 1, ""units"": 2 } ] }' \
  -v -X POST -H 'Content-Type:application/json' http://localhost:8080/orders
```

You should see the following return value:
```
TBD
```

Note that you can check out multiple products in one order. As an example, the following POST payload makes one user (id=1) checkout two products (id=1 and id=2) by creating the following payload:

```
{ ""userId"": ""1"", ""products"": [ { ""productId"": 1, ""units"": 2 }, { ""productId"": 2, ""units"": 4 } ] }
```
"
ttddyy/datasource-proxy-examples,master,50,21,2015-04-02T06:00:55Z,206,1,examples for how to use datasource-proxy,,"# datasource-proxy example projects

Requires Java 17 to compile.

[**jndi-embedded-example**](jndi-embedded-example/README.md)
- JNDI lookup with *embedded* tomcat

[**jndi-external-example**](jndi-external-example/README.md)
- JNDI lookup with *external* tomcat

[**spring-javaconfig-example**](spring-javaconfig-example/README.md)
- programmatic `ProxyDataSource` creation

[**spring-xml-example**](spring-xml-example/README.md)
- programmatic `ProxyDataSource` creation

[**Hibernate-5-example**](hibernate-5-example/README.md)
- programmatic `ProxyDataSource` creation

[**Hibernate-6-example**](hibernate-6-example/README.md)
- programmatic `ProxyDataSource` creation

[**springboot-autoconfig-example**](springboot-autoconfig-example/README.md)
- programmatic `ProxyDataSource` creation
"
rd-1-2022/ai-openai-helloworld,main,32,30,2023-08-05T15:15:30Z,120,4,Simple HelloWorld examples,,"# Spring AI with OpenAI

This project contains a web service that will accept HTTP GET requests at
`http://localhost:8080/ai/simple`.

There is optional `message` parameter whose default value is ""Tell me a joke"".

The response to the request is from the OpenAI ChatGPT Service.

## Prerequisites

Before using the AI commands, make sure you have a developer token from OpenAI.

Create an account at [OpenAI Signup](https://platform.openai.com/signup) and generate the token at [API Keys](https://platform.openai.com/account/api-keys).

The Spring AI project defines a configuration property named `spring.ai.openai.api-key` that you should set to the value of the `API Key` obtained from `openai.com`.

Exporting an environment variable is one way to set that configuration property.
```shell
export SPRING_AI_OPENAI_API_KEY=<INSERT KEY HERE>
```

Setting the API key is all you need to run the application.
However, you can find more information on setting started in the [Spring AI reference documentation section on OpenAI Chat](https://docs.spring.io/spring-ai/reference/api/clients/openai-chat.html).

## Building and running

```
./mvnw spring-boot:run
```

## Access the endpoint

To get a response to the default request of ""Tell me a joke""

```shell 
curl localhost:8080/ai/simple
```

A sample response is 

```text
Sure, here's a classic one for you:

Why don't scientists trust atoms?

Because they make up everything!
```

Now using the `message` request parameter
```shell
curl --get  --data-urlencode 'message=Tell me a joke about a cow.' localhost:8080/ai/simple 
```

A sample response is

```text
Why did the cow go to space?

Because it wanted to see the mooooon!
```

Alternatively use the [httpie](https://httpie.io/) client
```shell
http localhost:8080/ai/simple message=='Tell me a joke about a cow.'
```
"
oskardudycz/EventSourcing.JVM,main,240,36,2022-02-04T09:46:11Z,2913,14,Examples and Tutorials of Event Sourcing in JVM languages,cqrs eventsourcing java jvm spring,"[![Github Sponsors](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&link=https://github.com/sponsors/oskardudycz/)](https://github.com/sponsors/oskardudycz/) [![blog](https://img.shields.io/badge/blog-event--driven.io-brightgreen)](https://event-driven.io/?utm_source=event_sourcing_jvm) [![Architecture Weekly](https://img.shields.io/badge/%F0%9F%9A%80-Architecture%20Weekly-important)](https://www.architecture-weekly.com/?utm_source=event_sourcing_jvm) [![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/oskardudycz/) 

# EventSourcing.JVM

Tutorial, practical samples and other resources about Event Sourcing in JVM. See also my similar repositories for [.NET](https://github.com/oskardudycz/EventSourcing.NetCore) and [NodeJS](https://github.com/oskardudycz/EventSourcing.NodeJS).

- [EventSourcing.JVM](#eventsourcingjvm)
  - [Event Sourcing](#event-sourcing)
    - [What is Event Sourcing?](#what-is-event-sourcing)
    - [What is Event?](#what-is-event)
    - [What is Stream?](#what-is-stream)
    - [Event representation](#event-representation)
    - [Retrieving the current state from events](#retrieving-the-current-state-from-events)
    - [Event Store](#event-store)
  - [Videos](#videos)
    - [Practical introduction to Event Sourcing with Spring Boot and EventStoreDB](#practical-introduction-to-event-sourcing-with-spring-boot-and-eventstoredb)
    - [Let's build the worst Event Sourcing system!](#lets-build-the-worst-event-sourcing-system)
    - [The Light and The Dark Side of the Event-Driven Design](#the-light-and-the-dark-side-of-the-event-driven-design)
    - [Conversation with Yves Lorphelin about CQRS](#conversation-with-yves-lorphelin-about-cqrs)
    - [How to deal with privacy and GDPR in Event-Sourced systems](#how-to-deal-with-privacy-and-gdpr-in-event-sourced-systems)
  - [Support](#support)
  - [Introduction to Event Sourcing self-paced kit](#introduction-to-event-sourcing-self-paced-kit)
    - [Exercises](#exercises)
  - [Samples](#samples)
    - [Event Sourcing with Spring Boot and EventStoreDB](#event-sourcing-with-spring-boot-and-eventstoredb)
      - [Overview](#overview)
      - [Main assumptions](#main-assumptions)
      - [Prerequisites](#prerequisites)
      - [Tools used](#tools-used)
    - [Event Versioning](#event-versioning)
    - [Uniqueness](#uniqueness)
    - [Distributed Processes](#distributed-processes)
  - [Articles](#articles)
  
## Event Sourcing

### What is Event Sourcing?

Event Sourcing is a design pattern in which results of business operations are stored as a series of events. 

It is an alternative way to persist data. In contrast with state-oriented persistence that only keeps the latest version of the entity state, Event Sourcing stores each state change as a separate event.

Thanks for that, no business data is lost. Each operation results in the event stored in the databse. That enables extended auditing and diagnostics capabilities (both technically and business-wise). What's more, as events contains the business context, it allows wide business analysis and reporting.

In this repository I'm showing different aspects, patterns around Event Sourcing. From the basic to advanced practices.

Read more in my article:
-   📝 [How using events helps in a teams' autonomy](https://event-driven.io/en/how_using_events_help_in_teams_autonomy/?utm_source=event_sourcing_jvm)
-   📝 [When not to use Event Sourcing?](https://event-driven.io/en/when_not_to_use_event_sourcing/?utm_source=event_sourcing_jvm)

### What is Event?

Events, represent facts in the past. They carry information about something accomplished. It should be named in the past tense, e.g. _""user added""_, _""order confirmed""_. Events are not directed to a specific recipient - they're broadcasted information. It's like telling a story at a party. We hope that someone listens to us, but we may quickly realise that no one is paying attention.

Events:
- are immutable: _""What has been seen, cannot be unseen""_.
- can be ignored but cannot be retracted (as you cannot change the past).
- can be interpreted differently. The basketball match result is a fact. Winning team fans will interpret it positively. Losing team fans - not so much.

Read more in my articles:
-   📝 [What's the difference between a command and an event?](https://event-driven.io/en/whats_the_difference_between_event_and_command/?utm_source=event_sourcing_jvm)
-   📝 [Events should be as small as possible, right?](https://event-driven.io/en/whats_the_difference_between_event_and_command/?utm_source=event_sourcing_jvm)

### What is Stream?

Events are logically grouped into streams. In Event Sourcing, streams are the representation of the entities. All the entity state mutations ends up as the persisted events. Entity state is retrieved by reading all the stream events and applying them one by one in the order of appearance.

A stream should have a unique identifier representing the specific object. Each event has its own unique position within a stream. This position is usually represented by a numeric, incremental value. This number can be used to define the order of the events while retrieving the state. It can be also used to detect concurrency issues. 

### Event representation

Technically events are messages. 

They may be represented, e.g. in JSON, Binary, XML format. Besides the data, they usually contain:
- **id**: unique event identifier.
- **type**: name of the event, e.g. _""invoice issued""_.
- **stream id**: object id for which event was registered (e.g. invoice id).
- **stream position** (also named _version_, _order of occurrence_, etc.): the number used to decide the order of the event's occurrence for the specific object (stream).
- **timestamp**: representing a time at which the event happened.
- other metadata like `correlation id`, `causation id`, etc.

Sample event JSON can look like:

```json
{
  ""id"": ""e44f813c-1a2f-4747-aed5-086805c6450e"",
  ""type"": ""invoice-issued"",
  ""streamId"": ""INV/2021/11/01"",
  ""streamPosition"": 1,
  ""timestamp"": ""2021-11-01T00:05:32.000Z"",

  ""data"":
  {
    ""issuedTo"": {
      ""name"": ""Oscar the Grouch"",
      ""address"": ""123 Sesame Street"",
    },
    ""amount"": 34.12,
    ""number"": ""INV/2021/11/01"",
    ""issuedAt"": ""2021-11-01T00:05:32.000Z""
  },

  ""metadata"": 
  {
    ""correlationId"": ""1fecc92e-3197-4191-b929-bd306e1110a4"",
    ""causationId"": ""c3cf07e8-9f2f-4c2d-a8e9-f8a612b4a7f1""
  }
}
```

### Retrieving the current state from events

In Event Sourcing, the state is stored in events. Events are logically grouped into streams. Streams can be thought of as the entities' representation. Traditionally (e.g. in relational or document approach), each entity is stored as a separate record.

| Id       | IssuerName       | IssuerAddress     | Amount | Number         | IssuedAt   |
| -------- | ---------------- | ----------------- | ------ | -------------- | ---------- |
| e44f813c | Oscar the Grouch | 123 Sesame Street | 34.12  | INV/2021/11/01 | 2021-11-01 |

 In Event Sourcing, the entity is stored as the series of events that happened for this specific object, e.g. `InvoiceInitiated`, `InvoiceIssued`, `InvoiceSent`. 

```json          
[
    {
        ""id"": ""e44f813c-1a2f-4747-aed5-086805c6450e"",
        ""type"": ""invoice-initiated"",
        ""streamId"": ""INV/2021/11/01"",
        ""streamPosition"": 1,
        ""timestamp"": ""2021-11-01T00:05:32.000Z"",

        ""data"":
        {
            ""issuedTo"": {
                ""name"": ""Oscar the Grouch"",
                ""address"": ""123 Sesame Street"",
            },
            ""amount"": 34.12,
            ""number"": ""INV/2021/11/01"",
            ""initiatedAt"": ""2021-11-01T00:05:32.000Z""
        }
    },        
    {
        ""id"": ""5421d67d-d0fe-4c4c-b232-ff284810fb59"",
        ""type"": ""invoice-issued"",
        ""streamId"": ""INV/2021/11/01"",
        ""streamPosition"": 2,
        ""timestamp"": ""2021-11-01T00:11:32.000Z"",

        ""data"":
        {
            ""issuedTo"": ""Cookie Monster"",
            ""issuedAt"": ""2021-11-01T00:11:32.000Z""
        }
    },        
    {
        ""id"": ""637cfe0f-ed38-4595-8b17-2534cc706abf"",
        ""type"": ""invoice-sent"",
        ""streamId"": ""INV/2021/11/01"",
        ""streamPosition"": 3,
        ""timestamp"": ""2021-11-01T00:12:01.000Z"",

        ""data"":
        {
            ""sentVia"": ""email"",
            ""sentAt"": ""2021-11-01T00:12:01.000Z""
        }
    }
]
```

All of those events shares the stream id (`""streamId"": ""INV/2021/11/01""`), and have incremented stream position.
We can get to conclusion that in Event Sourcing entity is represented by stream, so sequence of event correlated by the stream id ordered by stream position.

To get the current state of entity we need to perform the stream aggregation process. We're translating the set of events into a single entity. This can be done with the following the steps:
1. Read all events for the specific stream.
2. Order them ascending in the order of appearance (by the event's stream position).
3. Construct the empty object of the entity type (e.g. with default constructor).
4. Apply each event on the entity.

This process is called also _stream aggregation_ or _state rehydration_.

Read more in my article:
-   📝 [Why Partial<Type> is an extremely useful TypeScript feature?](https://event-driven.io/en/partial_typescript/?utm_source=event_sourcing_jvm)
-   📝 [How to get the current entity state from events?](https://event-driven.io/en/how_to_get_the_current_entity_state_in_event_sourcing/?utm_source=event_sourcing_jvm)

### Event Store

Event Sourcing is not related to any type of storage implementation. As long as it fulfils the assumptions, it can be implemented having any backing database (relational, document, etc.). The state has to be represented by the append-only log of events. The events are stored in chronological order, and new events are appended to the previous event. Event Stores are the databases' category explicitly designed for such purpose. 

In the further samples, I'll use [EventStoreDB](https://developers.eventstore.com/). It's the battle-tested OSS database created and maintained by the Event Sourcing authorities. It supports many dev environments via gRPC clients, including JVM.

Read more in my article:
-   📝 [What if I told you that Relational Databases are in fact Event Stores?](https://event-driven.io/en/relational_databases_are_event_stores/=event_sourcing_jvm)

## Videos

### Practical introduction to Event Sourcing with Spring Boot and EventStoreDB

<a href=""https://www.youtube.com/watch?v=LaUSPtwFLSg"" target=""_blank""><img src=""https://img.youtube.com/vi/LaUSPtwFLSg/0.jpg"" alt=""Practical introduction to Event Sourcing with Spring Boot and EventStoreDB"" width=""320"" height=""240"" border=""10"" /></a>

### Facts and Myths about CQRS

<a href=""https://www.youtube.com/watch?v=9COWKz1E32w"" target=""_blank""><img src=""https://img.youtube.com/vi/9COWKz1E32w/0.jpg"" alt=""Facts and Myths about CQRS"" width=""320"" height=""240"" border=""10"" /></a>

### Let's build the worst Event Sourcing system!

<a href=""https://www.youtube.com/watch?v=Lu-skMQ-vAw"" target=""_blank""><img src=""https://img.youtube.com/vi/Lu-skMQ-vAw/0.jpg"" alt=""Let's build the worst Event Sourcing system!"" width=""320"" height=""240"" border=""10"" /></a>

### The Light and The Dark Side of the Event-Driven Design

<a href=""https://www.youtube.com/watch?v=ZGugOiYcq8k"" target=""_blank""><img src=""https://img.youtube.com/vi/ZGugOiYcq8k/0.jpg"" alt=""The Light and The Dark Side of the Event-Driven Design"" width=""320"" height=""240"" border=""10"" /></a>

### Conversation with [Yves Lorphelin](https://github.com/ylorph/) about CQRS

<a href=""https://www.youtube.com/watch?v=D-3N2vQ7ADE"" target=""_blank""><img src=""https://img.youtube.com/vi/D-3N2vQ7ADE/0.jpg"" alt=""Event Store Conversations: Yves Lorphelin talks to Oskar Dudycz about CQRS (EN)"" width=""320"" height=""240"" border=""10"" /></a>

### How to deal with privacy and GDPR in Event-Sourced systems

<a href=""https://www.youtube.com/watch?v=7NGlYgobTyY"" target=""_blank""><img src=""https://img.youtube.com/vi/7NGlYgobTyY/0.jpg"" alt=""How to deal with privacy and GDPR in Event-Sourced systems"" width=""320"" height=""240"" border=""10"" /></a>

## Support

Feel free to [create an issue](https://github.com/oskardudycz/EventSourcing.JVM/issues/new) if you have any questions or request for more explanation or samples. I also take **Pull Requests**!

💖 If this repository helped you - I'd be more than happy if you **join** the group of **my official supporters** at:

👉 [Github Sponsors](https://github.com/sponsors/oskardudycz) 

⭐ Star on GitHub or sharing with your friends will also help!

## [Introduction to Event Sourcing self-paced kit](./workshops/introduction-to-event-sourcing/)

Event Sourcing is perceived as a complex pattern. Some believe that it's like Nessie, everyone's heard about it, but rarely seen it. In fact, Event Sourcing is a pretty practical and straightforward concept. It helps build predictable applications closer to business. Nowadays, storage is cheap, and information is priceless. In Event Sourcing, no data is lost. 

The workshop aims to build the knowledge of the general concept and its related patterns for the participants. The acquired knowledge will allow for the conscious design of architectural solutions and the analysis of associated risks. 

The emphasis will be on a pragmatic understanding of architectures and applying it in practice using Marten and EventStoreDB.

1. Introduction to Event-Driven Architectures. Differences from the classical approach are foundations and terminology (event, event streams, command, query).
2. What is Event Sourcing, and how is it different from Event Streaming. Advantages and disadvantages.
3. Write model, data consistency guarantees on examples from Marten and EventStoreDB.
4. Various ways of handling business logic: Aggregates, Command Handlers, functional approach.
5. Projections, best practices and concerns for building read models from events on the examples from Marten and EventStoreDB.
6. Challenges in Event Sourcing and EDA: deliverability guarantees, sequence of event handling, idempotency, etc.
8. Saga, Choreography, Process Manager,  distributed processes in practice.
7. Event Sourcing in the context of application architecture, integration with other approaches (CQRS, microservices, messaging, etc.).
8. Good and bad practices in event modelling.
9. Event Sourcing on production, evolution, events' schema versioning, etc.

You can do the workshop as a self-paced kit. That should give you a good foundation for starting your journey with Event Sourcing and learning tools like Marten and EventStoreDB. If you'd like to get full coverage with all nuances of the private workshop, feel free to contact me via [email](mailto:oskar.dudycz@gmail.com).

Read also more in my article [Introduction to Event Sourcing - Self Paced Kit](https://event-driven.io/en/introduction_to_event_sourcing/?utm_source=event_sourcing_jvm).

### Exercises

1. [Events definition](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e01_events_definition).
2. [Getting State from events](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e02_getting_state_from_events).
3. Appending Events:
   * [EventStoreDB](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e03_appending_event/esdb)
   * _TODO: Axon Server_
4. Getting State from events
   * [EventStoreDB](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e04_getting_state_from_events)
   * _TODO: Axon Server_
5. Business logic:
   * [General](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e05_business_logic)
   * [EventStoreDB](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e06_business_logic/esdb)
   * _TODO: Axon Server_
6. Optimistic Concurrency:
   * [EventStoreDB](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e07_optimistic_concurrency/esdb)
   * _TODO: Axon Server_
7. Projections:
   * [General](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e08_projections_singlestream)
   * [Idempotency](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e09_projections_singlestream_idempotency)
   * [Eventual Consistency](./workshops/introduction-to-event-sourcing/exercises/src/test/java/io/eventdriven/introductiontoeventsourcing/e10_projections_singlestream_eventual_consistency)


## Samples

See also fully working, real-world samples of Event Sourcing and CQRS applications in [Samples folder](./samples/event-sourcing-esdb-simple).

Samples are using CQRS architecture. They're sliced based on the business modules and operations. Read more about the assumptions in [""How to slice the codebase effectively?""](https://event-driven.io/en/how_to_slice_the_codebase_effectively/?utm_source=event_sourcing_jvm).

### Event Sourcing with Spring Boot and EventStoreDB

#### Overview

Sample is showing basic Event Sourcing flow. It uses [EventStoreDB](https://developers.eventstore.com/) for event storage and [Spring Data JPA](https://spring.io/projects/spring-data-jpa) backed with [PostgreSQL](https://www.postgresql.org/) for read models. 

The presented use case is Shopping Cart flow:
1. The customer may add a product to the shopping cart only after opening it.
2. When selecting and adding a product to the basket customer needs to provide the quantity chosen. The product price is calculated by the system based on the current price list.
3. The customer may remove a product with a given price from the cart.
4. The customer can confirm the shopping cart and start the order fulfilment process.
5. The customer may also cancel the shopping cart and reject all selected products.
6. After shopping cart confirmation or cancellation, the product can no longer be added or removed from the cart.

Technically it's modelled as Web API written in [Spring Boot](https://spring.io/projects/spring-boot) and [Java 17](https://www.oracle.com/java/technologies/downloads/). 

There are two variations of those samples:
- [Event Sourcing with Spring Boot and EventStoreDB](./samples/event-sourcing-esdb-simple)
- [Event Sourcing with Spring Boot and EventStoreDB using Aggregate pattern](./samples/event-sourcing-esdb-aggregates)

#### Main assumptions
- explain basics of Event Sourcing, both from the write model ([EventStoreDB](https://developers.eventstore.com/)) and read model part ([PostgreSQL](https://www.postgresql.org/) and [Spring Data JPA](https://spring.io/projects/spring-data-jpa)),
- present that you can join classical approach with Event Sourcing without making a massive revolution,
- [CQRS](https://event-driven.io/en/cqrs_facts_and_myths_explained/) architecture sliced by business features, keeping code that changes together at the same place. Read more in [How to slice the codebase effectively?](https://event-driven.io/en/how_to_slice_the_codebase_effectively/),
- clean, composable (pure) functions for command, events, projections, query handling, minimising the need for marker interfaces. Thanks to that testability and easier maintenance.
- easy to use and self-explanatory fluent API for registering commands and projections with possible fallbacks,
- registering everything into regular DI containers to integrate with other application services.
- pushing the type/signature enforcement on edge, so when plugging to DI.

#### Prerequisites

For running the Event Store examples you need to have:

1. Java JDK 17 (or later) installed - https://www.oracle.com/java/technologies/downloads/.
2. Installed IntelliJ, Eclipse, VSCode or other preferred IDE.
3. [Docker](https://store.docker.com/search?type=edition&offering=community) installed.

#### Tools used

1. [EventStoreDB](https://eventstore.com) - Event Store 
2. [PostgreSQL](https://www.postgresql.org/) - Read Models
3. [Spring Boot](https://spring.io/projects/spring-boot) - Web Application framework

### [Event Versioning](./samples/events-versioning)
Shows how to handle basic event schema versioning scenarios using event and stream transformations (e.g. upcasting):
- [Simple mapping](./samples/events-versioning/#simple-mapping)
  - [New not required property](./samples/events-versioning/#new-not-required-property)
  - [New required property](./samples/events-versioning/#new-required-property)
  - [Renamed property](./samples/events-versioning/#renamed-property)
- [Upcasting](./samples/events-versioning/#upcasting)
  - [Changed Structure](./samples/events-versioning/#changed-structure)
  - [New required property](./samples/events-versioning/#new-required-property-1)
- [Downcasters](./samples/events-versioning/#downcasters)
- [Events Transformations](./samples/events-versioning/#events-transformations)
- [Stream Transformation](./samples/events-versioning/#stream-transformation)
- [Summary](./samples/events-versioning/#summary)
- 📝 [Simple patterns for events schema versioning](https://event-driven.io/en/simple_events_versioning_patterns/?utm_source=event_sourcing_jvm) 

### [Uniqueness](./samples/uniqueness/)
Shows how to handle unique constraint checks in an event-sources system. Explains various techniques, like:
- talking to business,
- stream id design,
- reservation pattern.

Read more in [How to ensure uniqueness in Event Sourcing](https://event-driven.io/en/uniqueness-in-event-sourcing/?utm_source=event_sourcing_jvm).

### [Distributed Processes](./samples/distributed-processes/)
Shows how to handle distributed processes in Event Sourcing in practice. Explains various use cases, like:
- batch processing,
- saga vs process managers,
- distributed processes in the single module and across boundaries,
- internal vs external events,
- compensating failures,
- implementation of command and event bus in EventStoreDB.

Read more in [How to ensure uniqueness in Event Sourcing](https://event-driven.io/en/uniqueness-in-event-sourcing/?utm_source=event_sourcing_jvm).

## Articles

Read also more on the **Event Sourcing** and **CQRS** topics in my [blog](https://event-driven.io/?utm_source=event_sourcing_jvm) posts:
-   📝 [What's the difference between a command and an event?](https://event-driven.io/en/whats_the_difference_between_event_and_command/?utm_source=event_sourcing_jvm)
-   📝 [Event Streaming is not Event Sourcing!](https://event-driven.io/en/event_streaming_is_not_event_sourcing/?utm_source=event_sourcing_jvm)
-   📝 [Events should be as small as possible, right?](https://event-driven.io/en/events_should_be_as_small_as_possible/?utm_source=event_sourcing_jvm)
-   📝 [How to get the current entity state from events?](https://event-driven.io/en/how_to_get_the_current_entity_state_in_event_sourcing/?utm_source=event_sourcing_jvm)
-   📝 [How to ensure uniqueness in Event Sourcing](https://event-driven.io/en/uniqueness-in-event-sourcing/?utm_source=event_sourcing_jvm)
-   📝 [Anti-patterns in event modelling - Property Sourcing](https://event-driven.io/en/property-sourcing/?utm_source=event_sourcing_jvm)
-   📝 [Anti-patterns in event modelling - State Obsession](https://event-driven.io/en/state-obsession/?utm_source=event_sourcing_jvm)
-   📝 [Why a bank account is not the best example of Event Sourcing?](https://event-driven.io/en/bank_account_event_sourcing/?utm_source=event_sourcing_jvm)
-   📝 [When not to use Event Sourcing?](https://event-driven.io/en/when_not_to_use_event_sourcing/?utm_source=event_sourcing_jvm)
-   📝 [CQRS facts and myths explained](https://event-driven.io/en/cqrs_facts_and_myths_explained/?utm_source=event_sourcing_jvm)
-   📝 [How to slice the codebase effectively?](https://event-driven.io/en/how_to_slice_the_codebase_effectively/?utm_source=event_sourcing_jvm)
-   📝 [Generic does not mean Simple](https://event-driven.io/en/generic_does_not_mean_simple/?utm_source=event_sourcing_jvm)
-   📝 [Can command return a value?](https://event-driven.io/en/can_command_return_a_value/?utm_source=event_sourcing_jvm)
-   📝 [Twelve things I learned about Java during my last code review](https://event-driven.io/pl/12_things_I_learned_on_last_pull_request_review/?utm_source=event_sourcing_jvm)
-   📝 [How to use ETag header for optimistic concurrency](https://event-driven.io/en/how_to_use_etag_header_for_optimistic_concurrency/?utm_source=event_sourcing_jvm)
-   📝 [Dealing with Eventual Consistency and Idempotency in MongoDB projections](https://event-driven.io/en/dealing_with_eventual_consistency_and_idempotency_in_mongodb_projections/?utm_source=event_sourcing_jvm)
-   📝 [Long-polling, how to make our async API synchronous](https://event-driven.io/en/long_polling_and_eventual_consistency/?utm_source=event_sourcing_jvm)
-   📝 [A simple trick for idempotency handling in the Elastic Search read model](https://event-driven.io/en/simple_trick_for_idempotency_handling_in_elastic_search_readm_model/?utm_source=event_sourcing_jvm)
-   📝 [How to (not) do the events versioning?](https://event-driven.io/en/how_to_do_event_versioning/?utm_source=event_sourcing_jvm)
-   📝 [Simple patterns for events schema versioning](https://event-driven.io/en/simple_events_versioning_patterns/?utm_source=event_sourcing_jvm)
-   📝 [How to create projections of events for nested object structures?](https://event-driven.io/en/how_to_create_projections_of_events_for_nested_object_structures/?utm_source=event_sourcing_jvm)
-   📝 [How to scale projections in the event-driven systems?](https://event-driven.io/en/how_to_scale_projections_in_the_event_driven_systems/?utm_source=event_sourcing_jvm)
-   📝 [Immutable Value Objects are simpler and more useful than you think!](https://event-driven.io/en/immutable_value_objects/?utm_source=event_sourcing_jvm)
-   📝 [How using events helps in a teams' autonomy](https://event-driven.io/en/how_using_events_help_in_teams_autonomy/?utm_source=event_sourcing_jvm)
-   📝 [What texting your Ex has to do with Event-Driven Design?](https://event-driven.io/en/what_texting_ex_has_to_do_with_event_driven_design/?utm_source=event_sourcing_jvm)
-   📝 [What if I told you that Relational Databases are in fact Event Stores?](https://event-driven.io/en/relational_databases_are_event_stores/?utm_source=event_sourcing_jvm)
-   📝 [Are Temporal Tables an alternative to Event Sourcing?](https://event-driven.io/en/temporal_tables_and_event_sourcing/?utm_source=event_sourcing_jvm)
-   📝 [Optimistic concurrency for pessimistic times](https://event-driven.io/en/optimistic_concurrency_for_pessimistic_times/?utm_source=event_sourcing_jvm)
-   📝 [Outbox, Inbox patterns and delivery guarantees explained](https://event-driven.io/en/outbox_inbox_patterns_and_delivery_guarantees_explained/?utm_source=event_sourcing_jvm)
-   📝 [Saga and Process Manager - distributed processes in practice](https://event-driven.io/en/saga_process_manager_distributed_transactions/?utm_source=event_sourcing_jvm)


**EventSourcing.JVM** is Copyright &copy; 2022 [Oskar Dudycz](http://event-driven.io) and other contributors under the [MIT license](LICENSE).
"
eazybytes/openapi,main,44,73,2022-07-10T03:25:03Z,214,0,OpenAPI Specification & Swagger Tools : Zero To Master - Code Examples,openapi-specification openapi3 swagger3,"# OpenAPI Specification & Swagger Tools - Zero To Master

[![Image](https://github.com/eazybytes/openapi/blob/main/openapi.png ""OpenAPI Specification &amp; Swagger Tools - Zero To Master"")](https://www.udemy.com/course/openapi-specification-swagger-tools-zero-to-master/?referralCode=F002A9A799DB126CD189)

**'OpenAPI Specification & Swagger Tools - Zero To Master'** course will help in understanding about Open API Specification and how to describe, document APIs using OpenAPI & Swagger tools.

## Topics covered in the course

1) Designing APIs with OpenAPI Specifications and Swagger Tools
2) Describing, Documenting APIs details using OpenAPI Specifications
3) History of OpenAPI & Swagger and relation between them
4) Details about Swagger tools like Swagger Editor, Swagger UI,SwaggerHub,SwaggerHub Explore,Swagger Codegen etc.
5) How to get started with OpenAPI in code first & Design first scenarios
6) How to write a valid OpenAPI document using YAML syntax
7) Writing re-usable content inside Open API specification with components
8) Data types supported by Open API specification & their details
9) Inheritance & polymorphism inside OpenAPI with keywords oneOf, anyOf, allOf and not
10 ) How to describe APIs security inside Open API specification
11) How to mock APIs with Open API specification & Prism mock server
12) How to generate client code & server stubs using OpenAPI for various popular programming languages & frameworks
13) Deploying & Hosting Open API specification inside a GitHub page along with Swagger UI
14) Providing examples data for the APIs inside Open API specification
15) Advantages of using Open API specification 
16) Providing better documentation using CommonMark syntax inside Open API specification 

## Pre-requisite for the course

- Basic knowledge on APIs
- Interest to learn and explore about OpenAPI & Swagger tools

# Important Links

- Open API Website - https://www.openapis.org
- Swagger Website - https://swagger.io
- Swagger Editor - https://editor.swagger.io
- SwaggerHub Explore - https://explore.swaggerhub.com/
- OpenAPI Map - https://openapi-map.apihandyman.io/
- OpenAPI & SpringBoot library - https://springdoc.org
- List of OpenAPI tools - https://openapi.tools/
- Prism Mock server - https://stoplight.io/open-source/prism
- SWAPI The Star Wars API - https://swapi.dev/
- REQRES Mock APIs - https://reqres.in
"
zuo26/BlogSample,master,154,34,2019-08-27T15:40:56Z,851,0,blog example.,,"### 持续更新，欢迎 star

- example41: 汉字笔顺动画
- example40: Espresso UI 自动化实践
- example39: AIDL 使用实践
- example38: 自定义 ClassLoader 使用实践
- example19: 编译 so 库实战
- example18: Lottie 使用
- example17: Activity 过渡动画实践
- example16: 矢量可绘制动画、裁剪视图动画、布局过渡动画
- example13: 带回弹效果的 RecyclerView 实战
- example11: 可拖拽工具类 ViewDragHelper 使用
- example10: 嵌套滑动实战"
AdoptOpenJDK/jdk9-jigsaw,master,285,150,2015-09-10T14:50:19Z,8227,7,Examples and exercises based on some of the features of jigsaw in JDK9/Jigsaw (Early Access builds),challenge code-examples examples exercises java java9 jdk9 jigsaw jlink jshell modular modularisation modules,"# jdk9-jigsaw

Ver la [versión en Español](es/README.md) (See [Spanish version](es/README.md))

Examples of some of the features of Jigsaw released in the Early Access build of JDK9.

Many of the examples here are directly from the Project Jigsaw: Module System Quick-Start Guide, see [http://openjdk.java.net/projects/jigsaw/quick-start](http://openjdk.java.net/projects/jigsaw/quick-start) but we have also contributions from the Java community.

___


####   Please note you are in the `master` branch which contains exercises which need to be solved by looking at documentation or resources provided in this repo. Hints may be provided within the source or script files. If you hit a roadblock and really want to see a possible solution you can switch to the `exercise-solutions` branch for that. 

####   Looking at the solutions can take away the challenge behind solving the exercises. Stay on the `master` branch in case you would like to continue to have fun solving the exercises and working through the challenges.

___

## Setup (all platforms)

See [Download, install and verify JDK](setupAndVerifyJDK.md) and return to this page to continue with the rest of the steps.
         
#### Download and install `git` or `git-bash`

- Ensure you have a `git` client installed on your local machine/VM/vagrant box, for Windows users `git-bash` is recommended 

#### Download and install the `tree` and `wget` command

See [Download and install tree and wget](setupTreeAndWget.md) and return to this page to continue with the rest of the steps.

#### Vagrant box

- Alternatively a Vagrant box is available at https://github.com/ali-ince/LJC_April2017_Hackday, please make use of this facility (thanks @ali-ince).

#### (Optional) Install JDK 9 compliant IDE

- Install the latest IDE (IntelliJ, Eclipse, NetBeans - paid or community version) that supports JDK 9 EA, once installed configure the IDE to pickup the JDK 9 EA installed in the previous steps.

See [Download, install and configure Eclipse Oxygen for JDK9](setupEclipseOxygen.md).

#### Other preparations

- Get familiar with the command-line a bit as we will be using much of it during the weekend

- Prepare your VMs or cloud instances with the above, in case your local machine is not up for any installation or configurations 

**Note:** the bash files provided should work on Linux and in theory on the MacOS as well.

##### Windows users

 - if you use `git-bash` (recommended) or `cgywin` should work for you - run the `.sh` scripts in one of the the environments. In the worst case scenario, we would have to manually convert the `.sh` files into `.bat`, with minor tweaks should also work there. Happy to receive a pull request for it. Or you could use **bach**, a platform independent Java Shell Builder. It's usage is explained in `session-3-jshell`.
 - check if the literal JDK path (or `%JAVA_HOME%`) has been added to the `PATH` environment variable or add it manually
 - ensure the JDK is installed in a folder where the name does not have a space in it 
 - in case folder name looks something `C:\Program files...`, ensure that (name does not contain spaces):
    - the path to the JDK in `JAVA_HOME` has `C:\Program~1` instead of `C:\Program files...`
    - the environment variable `PATH` refers to the `JAVA_HOME` environment variable
    - the environment variable `CLASSPATH` refers to the `JAVA_HOME` environment variable
 - in some instances `jlink` was not yet available when JDK is installed via the `.exe` file, even after the above path settings were applied (please verify beforehand)

##### MacOSX users
 - `jlink` is not yet available when JDK is installed via the `.dmg` file (please verify beforehand)

## Exercises / examples covered

Please ensure you have verified that the necessary JDK programs work in your environment with the help of the [Download, install and verify JDK](setupAndVerifyJDK.md) resource. 

- Session 1: Jigsaw Introduction
   - Greetings [./session-1-jigsaw-intro/01_Greetings](./session-1-jigsaw-intro/01_Greetings)
   - Greetings world [./session-1-jigsaw-intro/02_GreetingsWorld](./session-1-jigsaw-intro/02_GreetingsWorld)
   - Multi-module compilation [./session-1-jigsaw-intro/03_MultiModuleCompilation](./session-1-jigsaw-intro/03_MultiModuleCompilation)
   - Packaging [./session-1-jigsaw-intro/04_Packaging](./session-1-jigsaw-intro/04_Packaging)
   - Missing requires [./session-1-jigsaw-intro/05_Missing_requires](./session-1-jigsaw-intro/05_Missing_requires)
   - Missing exports [./session-1-jigsaw-intro/05_Missing_exports](./session-1-jigsaw-intro/05_Missing_exports)
   - Services [./session-1-jigsaw-intro/06_Services](./session-1-jigsaw-intro/06_Services)
   - javac --patch-module option [./session-1-jigsaw-intro/07_patch_module_option](session-1-jigsaw-intro/07_patch_module_option)
   - Modules export conflict [./session-1-jigsaw-intro/08_ModulesExportConflict](session-1-jigsaw-intro/08_ModulesExportConflict)
   - Automatic modules [./session-1-jigsaw-intro/09_Automodules](session-1-jigsaw-intro/09_Automodules)

- Session 2: JLink
   - JLink example [./session-2-jlink/01_JLink](session-2-jlink/01_JLink)
   - JMod example [./session-2-jlink/02_JMod](session-2-jlink/02_JMod) 

- Session 3: JShell
   - JShell quick tutorial [./session-3-jshell/](./session-3-jshell/)
   - JShell examples [./session-3-jshell/JShell-Examples](./session-3-jshell/JShell-Examples)
   - shellFX [./session-3-jshell/shellFX/](./session-3-jshell/shellFX/)
   - teamshell [./session-3-jshell/teamshell/](./session-3-jshell/teamshell/)
   - bach - Java Shell Builder [./session-3-jshell/bach-building-with-jshell](./session-3-jshell/bach-building-with-jshell)
   
- Session 3: Refactoring/migration sessions
   - Junit 5 migration to Java 9 modules [./session-3-refactoring-migration/01_junit5_to_java_9](session-3-refactoring-migration/01_junit5_to_java_9)
   - Building Java 9 Modules using Gradle (from monolith to modular) [./session-3-refactoring-migration/02_monolith_to_modular_using_gradle](session-3-refactoring-migration/02_monolith_to_modular_using_gradle)
   - ServiceMonitor - Migration from Java 8 to Java 9 [./session-3-refactoring-migration/03_ServiceMonitor_migration_to_java_9](session-3-refactoring-migration/03_ServiceMonitor_migration_to_java_9)
   - ServiceMonitor - Modularisation to Java 9 Modules (Maven project) [./session-3-refactoring-migration/04_ServiceMonitor_modularisation_to_java_9](session-3-refactoring-migration/04_ServiceMonitor_modularisation_to_java_9)

- Session 4: Multirelease JARs
   - Create multirelease JAR file [./session-4-multirelease-jars/01_Create_multirelease_jar/](./session-4-multirelease-jars/01_Create_multirelease_jar/)

- Session 5: Reactive streams API
   - Create Flow subscriber [./session-5-reactive-api/01_Create_subscriber/](./session-5-reactive-api/01_Create_subscriber/)

- Session 6: Security enhancements
   - Basic ALPN [./session-6-security/01_Basic_ALPN/](./session-6-security/01_Basic_ALPN/)
   - Custom ALPN [./session-6-security/02_Custom_ALPN2/](./session-6-security/02_Custom_ALPN2/)

Each example is enclosed in a folder of its own containing bash scripts to compile, package and run the respective examples. Use these scripts for each of the examples.

## Community contributions

See [guidelines on how to contribute](CONTRIBUTING.md).

## License

See [License](LICENSE) document to find out about the licensing terms and conditions.

## Resources

### Must reads
- [The State of the Module System](http://openjdk.java.net/projects/jigsaw/spec/sotms/)
- [JEP 261](http://openjdk.java.net/jeps/261)
- [http://mail.openjdk.java.net/pipermail/adoption-discuss/2015-September/001053.html](http://mail.openjdk.java.net/pipermail/adoption-discuss/2015-September/001053.html) <br/>
- [http://mail.openjdk.java.net/pipermail/adoption-discuss/2015-September/001056.html](http://mail.openjdk.java.net/pipermail/adoption-discuss/2015-September/001056.html)

### Other resources
- [Module System JSR (376)](https://www.jcp.org/en/jsr/detail?id=376)
- [JDK 9 / Jigsaw Resources](./Java-9-Resources.md)
- [Adopt OpenJDK homepage](https://adoptopenjdk.java.net/)
- [Adopt OpenJDK: Getting Started Kit](http://bit.ly/1NUkPWw)

---

![I need you for Java SE 9 development](I-need-you-for-Java-SE-9-development.png ""I need you for Java SE 9 development"")
"
laolunsi/spring-boot-examples-old,master,31,31,2019-02-27T06:59:36Z,1405,0,old - :smile:Spring/SpringBoot/SpringCloud系列快速上手教程、源码学习、实战示例代码，新仓库在 https://github.com/laolunsi/spring-boot-examples,,"# SpringBoot系列基本教程
---

**本仓库不再更新，请移步新仓库[https://github.com/laolunsi/spring-boot-stack](https://github.com/laolunsi/spring-boot-stack)**

---


该仓库为springboot快速上手教程对应的示例代码，主要讲解SpringBoot相关的技术，后续计划包括SpringSecurity、SpringCloud、Spring源码等内容。

如果该系列教程对您有所帮助的话，还请点个star给予支持！感谢！

---
补充：
> 1. 后缀为demo，表示技术示例、问题解决方案，专注实际问题解决
> 2. 后缀为study，表示对某类问题的深入学习，更关心源码层面

---

## SpringBoot教程

1. ssm-demo: [SSM框架整合](https://blog.csdn.net/qq_28379809/article/details/83218797)
2. spring-boot-admin-demo: [SpringBoot Admin监控应用健康状况](https://blog.csdn.net/qq_28379809/article/details/102593592)
3. spring-boot-mongo-demo: [SpringBoot整合MongoDB](https://blog.csdn.net/qq_28379809/article/details/102952974)
4. spring-boot-redis-demo: [SpringBoot整合Redis](https://blog.csdn.net/qq_28379809/article/details/102961559)
5. spring-boot-swagger-demo: [SpringBoot使用Swagger构建RestApi接口文档](https://blog.csdn.net/qq_28379809/article/details/103008307)
6. spring-boot-config: [SpringBoot配置深入学习](http://www.eknown.cn/index.php/spring-boot/config.html)
7. spring-boot-application-study: [SpringBoot Application深入学习](http://www.eknown.cn/index.php/spring-boot/spring-boot-application.html)
8. spring-boot-params-time-demo: [SpringBoot项目接收时间类型参数完整解决方案](http://www.eknown.cn/index.php/spring-boot/params-time.html)
9. spring-boot-exception-demo: [SpringBoot统一异常处理](http://www.eknown.cn/index.php/spring-boot/exception-handler.html)
10. spring-boot-logback-demo: [SpringBoot日志管理之Logback](http://www.eknown.cn/index.php/spring-boot/logback.html)
11. spring-boot-mail-demo: [SpringBoot发送邮件](http://www.eknown.cn/index.php/spring-boot/email.html)

---

## SpringSecurity教程

1. sso-auth2-demo: [SpringSecurity+OAuth2实现单点登录系统](https://blog.csdn.net/qq_28379809/article/details/102734384)



持续更新中...

---

## 加入微信群

添加我的个人微信，备注 **加群** 即可。欢迎大家加入，一起分享学习和开发中遇到的问题！

![file](http://zfh-public-blog.oss-cn-beijing.aliyuncs.com/image-1578375120717.png)



## 关注公众号

关注公众号：猿生物语。每周分享**干货**技术文章。可免费获取云盘学习资料。

如果大家想要实时关注我的文章和分享动态的话，可以关注一下！

![file](http://zfh-public-blog.oss-cn-beijing.aliyuncs.com/image-1578371742220.png)



"
SomMeri/org.meri.jpa.tutorial,master,72,42,2012-01-31T13:05:07Z,200,1,Examples and test cases for JPA tutorial.,,
mraible/java-webapp-security-examples,master,38,28,2015-07-09T22:17:50Z,844,0,"Example projects showing how to configure security with Java EE, Spring Security and Apache Shiro.",,"# Java Web Application Security Examples
Example projects showing how to configure security with Java EE, Spring Security and Apache Shiro.
"
lidong1665/seata-spring-boot-dubbo-nacos-shardingsphere-examples,master,61,43,2020-05-22T01:42:23Z,135,5,"如何进行seata1.2.0、sharding-sphere4.1.0和dubbo2.7.5 的整合,以及使用nacos作为我们的配置中心和注册中心",,"### 1.介绍
本篇将介绍,如何进行seata1.2.0、sharding-sphere4.1.0和dubbo2.7.5 的整合,以及使用nacos作为我们的配置中心和注册中心。如果你还是一个初学者，先建议学习一下，陈建斌的[七步带你集成Seata 1.2 高可用搭建](https://mp.weixin.qq.com/s/2KSidJ72YsovpJ94P1aK1g)，这篇文章清楚的阐述了初学者容易遇到的5个问题，并且都提供完整的解决思路。

### 2.环境配置
 - mysql: 5.7.12

- nacos:  1.2.1

- spring-boot:  2.2.6.RELEASE

- seata: 1.2.0

- dubbo:2.7.5

- sharding-sphere: 4.1.0

- 开发环境: jdk1.8.0 


#### 2.1 nacos安装
nacos下载：[https://github.com/alibaba/nacos/releases/tag/1.2.1](https://github.com/alibaba/nacos/releases/tag/1.2.1)

Nacos 快速入门：[https://nacos.io/en-us/docs/quick-start.html](https://nacos.io/en-us/docs/quick-start.html)

```shell
sh startup.sh -m standalone
```

在浏览器打开Nacos web 控制台：http://127.0.0.1:8848/nacos/index.html

输入nacos的账号和密码 分别为`nacos：nacos`

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200521172522791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAwNDY5MDg=,size_16,color_FFFFFF,t_70)
这是时候naocs 就正常启动了。
#### 2.2 seata1.2.0安装

##### 2.2.1 在 [Seata Release](https://github.com/seata/seata/releases/tag/v1.2.0) 下载最新版的 Seata Server 并解压得到如下目录：


```shell
.
├──bin
├──conf
└──lib
```
##### 2.2.2 修改 conf/registry.conf 配置，
目前seata支持如下的file、nacos 、apollo、zk、consul的注册中心和配置中心。这里我们以`nacos` 为例。
将 type 改为 nacos

```bash
registry {
  # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa
  type = ""nacos""

  nacos {
    application = ""seata-server""
    serverAddr = ""127.0.0.1:8848""
    namespace = ""40508bb4-179e-4c98-a2f1-c2c031c20b3c""
    cluster = ""default""
    username = ""worker2""
    password = ""xxxxxxx""
  }
}

config {
  # file、nacos 、apollo、zk、consul、etcd3
  type = ""nacos""

  nacos {
    serverAddr = ""127.0.0.1:8848""
    namespace = ""40508bb4-179e-4c98-a2f1-c2c031c20b3c""
    group = ""SEATA_GROUP""
    username = ""worker2""
    password = ""xxxxxxx""
  }
}
```
- serverAddr = ""127.0.0.1:8848""   ：nacos 的地址
- namespace = """" ：nacos的命名空间默认为``
- cluster = ""default""  ：集群设置未默认 `default`

##### 2.2.3 修改 conf/config.txt配置

```
service.vgroupMapping.order-service-seata-service-group=default
service.vgroupMapping.account-service-seata-service-group=default
service.vgroupMapping.storage-service-seata-service-group=default
service.vgroupMapping.business-service-seata-service-group=default
store.mode=db
store.db.driverClassName=com.mysql.jdbc.Driver
store.db.datasource=druid
store.db.dbType=mysql
store.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true
store.db.user=root
store.db.password=123456
store.db.minConn=1
store.db.maxConn=3
store.db.global.table=global_table
store.db.branch.table=branch_table
store.db.query-limit=100
store.db.lockTable=lock_table
```
配置的详细说明参考官网：[https://seata.io/zh-cn/docs/user/configurations.html](https://seata.io/zh-cn/docs/user/configurations.html)

这里主要修改了如下几项：
- store.mode :存储模式 默认file  这里我修改为db 模式 ，并且需要三个表`global_table`、`branch_table`和`lock_table`
- store.db.driverClassName： 0.8.0版本默认没有，会报错。添加了 `com.mysql.jdbc.Driver`
- store.db.datasource=dbcp ：数据源 dbcp
- store.db.db-type=mysql : 存储数据库的类型为`mysql`
- store.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true : 修改为自己的数据库`url`、`port`、`数据库名称`
- store.db.user=lidong :数据库的账号
- store.db.password=cwj887766@@ :数据库的密码
- service.vgroupMapping.order-service-seata-service-group=default
- service.vgroupMapping.account-service-seata-service-group=default
- service.vgroupMapping.storage-service-seata-service-group=default
- service.vgroupMapping.business-service-seata-service-group=default

##### 2.2.4 db模式下的所需的三个表
数据库脚本位于[https://github.com/seata/seata/tree/develop/script/server/db](https://github.com/seata/seata/tree/develop/script/server/db)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200521173848590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAwNDY5MDg=,size_16,color_FFFFFF,t_70)
这里我用的是mysql数据库，直接下载mysq.sql就可以了。

`global_table`的表结构

```sql
CREATE TABLE `global_table` (
  `xid` varchar(128) NOT NULL,
  `transaction_id` bigint(20) DEFAULT NULL,
  `status` tinyint(4) NOT NULL,
  `application_id` varchar(64) DEFAULT NULL,
  `transaction_service_group` varchar(64) DEFAULT NULL,
  `transaction_name` varchar(64) DEFAULT NULL,
  `timeout` int(11) DEFAULT NULL,
  `begin_time` bigint(20) DEFAULT NULL,
  `application_data` varchar(2000) DEFAULT NULL,
  `gmt_create` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`xid`),
  KEY `idx_gmt_modified_status` (`gmt_modified`,`status`),
  KEY `idx_transaction_id` (`transaction_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

```

`branch_table`的表结构

```sql
CREATE TABLE `branch_table` (
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(128) NOT NULL,
  `transaction_id` bigint(20) DEFAULT NULL,
  `resource_group_id` varchar(32) DEFAULT NULL,
  `resource_id` varchar(256) DEFAULT NULL,
  `lock_key` varchar(128) DEFAULT NULL,
  `branch_type` varchar(8) DEFAULT NULL,
  `status` tinyint(4) DEFAULT NULL,
  `client_id` varchar(64) DEFAULT NULL,
  `application_data` varchar(2000) DEFAULT NULL,
  `gmt_create` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`branch_id`),
  KEY `idx_xid` (`xid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;


```
`lock_table`的表结构

```sql
create table `lock_table` (
  `row_key` varchar(128) not null,
  `xid` varchar(96),
  `transaction_id` long ,
  `branch_id` long,
  `resource_id` varchar(256) ,
  `table_name` varchar(32) ,
  `pk` varchar(32) ,
  `gmt_create` datetime ,
  `gmt_modified` datetime,
  primary key(`row_key`)
);
```

##### 2.2.5 将 Seata 配置添加到 Nacos 中

nacos导入脚本位于[https://github.com/seata/seata/tree/develop/script/config-center/nacos](https://github.com/seata/seata/tree/develop/script/config-center/nacos)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200521174115613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAwNDY5MDg=,size_16,color_FFFFFF,t_70)
使用方法：

```bash
sh ${SEATAPATH}/script/config-center/nacos/nacos-config.sh -h localhost -p 8848 -g SEATA_GROUP -t 40508bb4-179e-4c98-a2f1-c2c031c20b3c -u worker-w xxxxxx
```
参数描述:

- -h: host, 默认值 localhost.

- -p: port, 默认值 is 8848.

- -g: 配置分组 默认值 'SEATA_GROUP'.

- -t: 命名空间.

- -u: 用户名, nacos 1.2.0+ 之后添加权限验证 默认为“”

- -w: 密码, nacos 1.2.0+ 之后添加权限验证 默认为“”
- 
在 Nacos 管理页面应该可以看到Group 为SEATA_GROUP的配置 
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200521174606735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAwNDY5MDg=,size_16,color_FFFFFF,t_70)
这样seata-sever就搭建完成。

### 3.sharding-sphere中seata柔性事务实现
#### 3.1 实现原理
整合`Seata AT`事务时，需要把`TM`，`RM`，`TC`的模型融入到`ShardingSphere` 分布式事务的`SPI`的生态中。在数据库资源上，`Seata`通过对接`DataSource`接口，让`JDBC`操作可以同`TC`进行`RPC`通信。同样，`ShardingSphere`也是面向`DataSource`接口对用户配置的物理`DataSource`进行了聚合，因此把物理`DataSource`二次包装为`Seata `的`DataSource`后，就可以把`Seata AT`事务融入到`ShardingSphere`的分片中。
#### 3.2实现原理图
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200521175420580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAwNDY5MDg=,size_16,color_FFFFFF,t_70)
#### 3.3 实现的步骤

 1. Init（Seata引擎初始化）
包含Seata柔性事务的应用启动时，用户配置的数据源会按seata.conf的配置，适配为Seata事务所需的DataSourceProxy，并且注册到RM中。

 2. Begin（开启Seata全局事务）
TM控制全局事务的边界，TM通过向TC发送Begin指令，获取全局事务ID，所有分支事务通过此全局事务ID，参与到全局事务中；全局事务ID的上下文存放在当前线程变量中。

3. 执行分片物理SQL
处于Seata全局事务中的分片SQL通过RM生成undo快照，并且发送participate指令到TC，加入到全局事务中。ShardingSphere的分片物理SQL是按多线程方式执行，因此整合Seata AT事务时，需要在主线程和子线程间进行全局事务ID的上下文传递，这同服务间的上下文传递思路完全相同。

5. Commit/rollback（提交Seata事务）
提交Seata事务时，TM会向TC发送全局事务的commit和rollback指令，TC根据全局事务ID协调所有分支事务进行commit和rollback。

### 4.sharding-sphere中seata的整合
##### 4.1使用Spring-boot引入Maven依赖

```xml
<dependency>
    <groupId>org.apache.shardingsphere</groupId>
    <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
    <version>${shardingsphere.version}</version>
</dependency>

<!-- 使用BASE事务时，需要引入此模块 -->
<dependency>
    <groupId>org.apache.shardingsphere</groupId>
    <artifactId>sharding-transaction-base-seata-at</artifactId>
    <version>${sharding-sphere.version}</version>
</dependency>
```

##### 4.2.Seata的AT模式使用的BASE柔性事务管理器
在每一个分片数据库实例中执创建undo_log表（以MySQL为例）

```sql
CREATE TABLE IF NOT EXISTS `undo_log`
(
  `id`            BIGINT(20)   NOT NULL AUTO_INCREMENT COMMENT 'increment id',
  `branch_id`     BIGINT(20)   NOT NULL COMMENT 'branch transaction id',
  `xid`           VARCHAR(100) NOT NULL COMMENT 'global transaction id',
  `context`       VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization',
  `rollback_info` LONGBLOB     NOT NULL COMMENT 'rollback info',
  `log_status`    INT(11)      NOT NULL COMMENT '0:normal status,1:defense status',
  `log_created`   DATETIME     NOT NULL COMMENT 'create datetime',
  `log_modified`  DATETIME     NOT NULL COMMENT 'modify datetime',
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`)
) ENGINE = InnoDB
  AUTO_INCREMENT = 1
  DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table';
```
##### 4.3.在classpath中增加seata.conf

```shell
client {
    application.id = example    ## 应用唯一id
    transaction.service.group = my_test_tx_group   ## 所属事务组
}
```




##### 4.4业务方发起全局事务，配置柔性事务类型

```java
 @GlobalTransactional(timeoutMills = 300000, name = ""dubbo-gts-seata-example"")
 @Override
public ObjectResponse handleBusiness(BusinessDTO businessDTO) {
        TransactionTypeHolder.set(TransactionType.BASE);
        //执行业务逻辑
}
```
**备注**：也可是使用注解` @ShardingTransactionType`的形式
```java
 @GlobalTransactional(timeoutMills = 300000, name = ""dubbo-gts-seata-example"")
 @ShardingTransactionType(TransactionType.BASE)
@Override
 public ObjectResponse handleBusiness(BusinessDTO businessDTO) {
     //执行业务逻辑  
}
        
```

### 5.案例实现

参考官网中用户购买商品的业务逻辑。整个业务逻辑由4个微服务提供支持：

- 库存服务：扣除给定商品的存储数量。
- 订单服务：根据购买请求创建订单。
- 帐户服务：借记用户帐户的余额。
- 业务服务：处理业务逻辑。

请求逻辑架构
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190905111031350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9saWRvbmcxNjY1LmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70)

#### 5.1 源码地址
- samples-common ：公共模块

- samples-account ：用户账号模块

- samples-order ：订单模块

- samples-storage ：库存模块

- samples-business ：业务模块

#### 5.2 数据库
注意: MySQL必须使用`InnoDB engine`.

如下，并且每个库中都需要一个undo_log表
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200521180601443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAwNDY5MDg=,size_16,color_FFFFFF,t_70)
#### 5.3 以账号服务为例 
分析需要项目中所需要的配置
##### 5.3.1 引入的依赖

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.2.6.RELEASE</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>
    <artifactId>seata-spring-boot-dubbo-nacos-shardingsphere-examples</artifactId>
    <packaging>pom</packaging>
    <name>seata-spring-boot-dubbo-nacos-shardingsphere-examples</name>
    <groupId>io.seata</groupId>
    <version>1.2.0</version>
    <description>Demo project for Spring Boot Dubbo</description>

    <modules>
        <module>samples-common-service</module>
        <module>samples-account-service</module>
        <module>samples-order-service</module>
        <module>samples-storage-service</module>
        <module>samples-business-service</module>
    </modules>

    <properties>
        <springboot.verison>2.2.6.RELEASE</springboot.verison>
        <java.version>1.8</java.version>
        <mybatis-plus.version>2.3</mybatis-plus.version>
        <nacos.version>0.2.3</nacos.version>
        <lombok.version>1.16.22</lombok.version>
        <dubbo.version>2.7.5</dubbo.version>
        <nacos-client.verison>1.2.1</nacos-client.verison>
        <seata.version>1.2.0</seata.version>
        <netty.version>4.1.32.Final</netty.version>
        <sharding-sphere.version>4.1.0</sharding-sphere.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
            <version>${springboot.verison}</version>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
            <version>${springboot.verison}</version>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <version>${springboot.verison}</version>
        </dependency>

        <dependency>
            <groupId>com.baomidou</groupId>
            <artifactId>mybatis-plus-boot-starter</artifactId>
            <version>3.3.1</version>
        </dependency>


        <dependency>
            <groupId>org.apache.dubbo</groupId>
            <artifactId>dubbo</artifactId>
            <version>${dubbo.version}</version>
            <exclusions>
                <exclusion>
                    <artifactId>spring</artifactId>
                    <groupId>org.springframework</groupId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.dubbo</groupId>
            <artifactId>dubbo-spring-boot-starter</artifactId>
            <version>${dubbo.version}</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-config-spring -->
        <dependency>
            <groupId>org.apache.dubbo</groupId>
            <artifactId>dubbo-configcenter-nacos</artifactId>
            <version>${dubbo.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.dubbo</groupId>
            <artifactId>dubbo-registry-nacos</artifactId>
            <version>${dubbo.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.dubbo</groupId>
            <artifactId>dubbo-metadata-report-nacos</artifactId>
            <version>${dubbo.version}</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/io.seata/seata-all -->

        <dependency>
            <groupId>io.seata</groupId>
            <artifactId>seata-spring-boot-starter</artifactId>
            <version>${seata.version}</version>
        </dependency>


        <dependency>
            <groupId>com.alibaba.nacos</groupId>
            <artifactId>nacos-client</artifactId>
            <version>${nacos-client.verison}</version>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-maven-plugin</artifactId>
            <version>${springboot.verison}</version>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <version>${lombok.version}</version>
        </dependency>


        <dependency>
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <version>${netty.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpclient</artifactId>
            <version>4.5</version>
        </dependency>

        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>5.1.47</version>
        </dependency>
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>sharding-jdbc-core</artifactId>
            <version>${sharding-sphere.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
            <version>${sharding-sphere.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>sharding-transaction-base-seata-at</artifactId>
            <version>${sharding-sphere.version}</version>
        </dependency>

        <dependency>
            <groupId>com.zaxxer</groupId>
            <artifactId>HikariCP</artifactId>
            <version>3.3.1</version>
        </dependency>
    </dependencies>


    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-deploy-plugin</artifactId>
                <configuration>
                    <skip>true</skip>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <configuration>
                    <source>${java.version}</source>
                    <target>${java.version}</target>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>

```
注意：
- `seata-spring-boot-starter`: 这个是spring-boot seata 所需的主要依赖，1.0.0版本开始加入支持。
- `dubbo-spring-boot-starter`:   springboot dubbo的依赖
- `sharding-transaction-base-seata-at` ：sharding和seata整合的依赖

其他的就不一一介绍，其他的一目了然，就知道是干什么的。

##### 5.3.2  application.yml配置

```yml
server:
  port: 8102
spring:
  shardingsphere:
    datasource:
      names: ds0
      ds0:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.jdbc.Driver
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds0?useUnicode=true&characterEncoding=UTF-8&useSSL=false
        username: root
        password: 123456
    sharding:
      tables:
        t_account:
          actual-data-nodes: ds0.t_account$->{0..1}
          table-strategy:
            inline:
              sharding-column: id
              algorithm-expression: t_account$->{id % 2}
    props:
      sql.show: true

#====================================Dubbo config===============================================
dubbo:
  application:
    id: dubbo-account-example
    name: dubbo-account-example
    qosEnable: false
  protocol:
    id: dubbo
    name: dubbo
    port: 20883
  registry:
    id: dubbo-account-example-registry
    address: nacos://127.0.0.1:8848?namespace=40508bb4-179e-4c98-a2f1-c2c031c20b3c
  config-center:
    address: nacos://127.0.0.1:8848?namespace=40508bb4-179e-4c98-a2f1-c2c031c20b3c
  metadata-report:
    address: nacos://127.0.0.1:8848?namespace=40508bb4-179e-4c98-a2f1-c2c031c20b3c
#====================================mybatis-plus config===============================================
mybatis-plus:
  mapperLocations: classpath*:/mapper/*.xml
  typeAliasesPackage: io.seata.samples.integration.*.entity
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      id-type: auto

#====================================Seata Config===============================================

seata:
  enabled: true
  application-id: account-seata-example
  tx-service-group: account-service-seata-service-group # 事务群组（可以每个应用独立取名，也可以使用相同的名字）
  registry:
    file:
      name: file.conf
    type: nacos
    nacos:
      server-addr: localhost:8848
      namespace: 40508bb4-179e-4c98-a2f1-c2c031c20b3c
      cluster: default
  config:
    file:
      name: file.conf
    type: nacos
    nacos:
      namespace: 40508bb4-179e-4c98-a2f1-c2c031c20b3c
      server-addr: localhost:8848
      group: SEATA_GROUP
  enable-auto-data-source-proxy: true
  use-jdk-proxy: true

```
##### 5.3.3  在classpath中增加seata.conf

```bash
client {
    application.id = account-seata-example ## 应用唯一id
    transaction.service.group = account-service-seata-service-group ## 所属事务组
}
```

##### 5.3.4 启动所有的sample模块
启动 `samples-account-service`、`samples-order-service`、`samples-storage-service`、`samples-business-service`

并且在nocos的控制台查看注册情况: http://192.168.10.200:8848/nacos/#/serviceManagement

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190905131449502.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9saWRvbmcxNjY1LmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70)
我们可以看到上面的服务都已经注册成功。

### 6.测试结果
### 6. 1 发送一个下单请求(正常情况)
使用postman 发送 ：[http://localhost:8104/business/dubbo/buy](http://localhost:8104/business/dubbo/buy) 

请求参数：

```json
{
    ""userId"": 1,
    ""commodityCode"":""C201901140001"",
    ""name"":""fan"",
    ""count"":50,
    ""amount"":""100""
}
```
返回参数

```json
{
    ""status"": 200,
    ""message"": ""成功"",
    ""data"": null
}
```
这时候控制台：
##### 6.1.1 BusinessService 服务日志

```bash
2020-05-22 09:15:54.763  INFO 13384 --- [nio-8104-exec-4] i.s.s.i.c.controller.BusinessController  : 请求参数：BusinessDTO(userId=1, commodityCode=C201901140001, name=fan, count=50, amount=100)
2020-05-22 09:15:54.794  INFO 13384 --- [nio-8104-exec-4] i.seata.tm.api.DefaultGlobalTransaction  : Begin new global transaction [192.168.10.107:8091:2012243535]
2020-05-22 09:15:54.794  INFO 13384 --- [nio-8104-exec-4] i.s.s.i.c.service.BusinessServiceImpl    : 开始全局事务，XID = 192.168.10.107:8091:2012243535
2020-05-22 09:15:55.527  INFO 13384 --- [nio-8104-exec-4] i.seata.tm.api.DefaultGlobalTransaction  : [192.168.10.107:8091:2012243535] commit status: Committed
```
##### 6.1.2 AccountService 服务日志

```bash
2020-05-22 09:15:54.959  INFO 8792 --- [:20883-thread-3] i.s.s.i.a.dubbo.AccountDubboServiceImpl  : 全局事务id ：192.168.10.107:8091:2012243535
Creating a new SqlSession
Registering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@29020a6b]
JDBC Connection [io.seata.rm.datasource.ConnectionProxy@23fa611b] will be managed by Spring
==>  Preparing: update t_account set amount = amount-100.0 where id = 1 
==> Parameters: 
2020-05-22 09:15:54.960  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Logic SQL: SELECT id, amount FROM t_account WHERE id = 1 FOR UPDATE
2020-05-22 09:15:54.960  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@60fae881, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@66f8eb00), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@66f8eb00, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=16, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@5f10e4e6, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@57d40a06, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@27d65b5e, containsSubquery=false)
2020-05-22 09:15:54.960  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, amount FROM t_account1 WHERE id = 1 FOR UPDATE
2020-05-22 09:15:54.962  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Logic SQL: update t_account set amount = amount-100.0 where id = 1
2020-05-22 09:15:54.962  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : SQLStatement: UpdateStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.UpdateStatement@5ba704b6, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@294b424c), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@294b424c)
2020-05-22 09:15:54.962  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: update t_account1 set amount = amount-100.0 where id = 1
2020-05-22 09:15:54.964  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Logic SQL: SELECT id, amount FROM t_account WHERE id in (?)
2020-05-22 09:15:54.964  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@697bcc02, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@299ee29), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@299ee29, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=16, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@1b05b402, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@68afcc0c, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@4352f7f9, containsSubquery=false)
2020-05-22 09:15:54.964  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, amount FROM t_account1 WHERE id in (?) ::: [1]
<==    Updates: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@29020a6b]
Transaction synchronization committing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@29020a6b]
Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@29020a6b]
Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@29020a6b]
2020-05-22 09:15:55.078  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Logic SQL: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now())
2020-05-22 09:15:55.079  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@354923b3, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2ebdd5c8), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2ebdd5c8, columnNames=[branch_id, xid, context, rollback_info, log_status, log_created, log_modified], insertValueContexts=[InsertValueContext(parametersCount=5, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=109, stopIndex=109, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=112, stopIndex=112, parameterMarkerIndex=1), ParameterMarkerExpressionSegment(startIndex=115, stopIndex=115, parameterMarkerIndex=2), ParameterMarkerExpressionSegment(startIndex=118, stopIndex=118, parameterMarkerIndex=3), ParameterMarkerExpressionSegment(startIndex=121, stopIndex=121, parameterMarkerIndex=4), org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@5fd3f282, org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@2e3bb335], parameters=[2012243539, 192.168.10.107:8091:2012243535, serializer=jackson, javax.sql.rowset.serial.SerialBlob@d4e81a62, 0])], generatedKeyContext=Optional.empty)
2020-05-22 09:15:55.079  INFO 8792 --- [:20883-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now()) ::: [2012243539, 192.168.10.107:8091:2012243535, serializer=jackson, javax.sql.rowset.serial.SerialBlob@d4e81a62, 0]
2020-05-22 09:15:55.562  INFO 8792 --- [atch_RMROLE_1_8] i.s.core.rpc.netty.RmMessageListener     : onMessage:xid=192.168.10.107:8091:2012243535,branchId=2012243539,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/ds0,applicationData=null
2020-05-22 09:15:55.563  INFO 8792 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch committing: 192.168.10.107:8091:2012243535 2012243539 jdbc:mysql://127.0.0.1:3306/ds0 null
2020-05-22 09:15:55.564  INFO 8792 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch commit result: PhaseTwo_Committed
2020-05-22 09:15:56.217  INFO 8792 --- [  AsyncWorker_1] ShardingSphere-SQL                       : Logic SQL: DELETE FROM undo_log WHERE  branch_id IN  (?)  AND xid IN  (?) 
2020-05-22 09:15:56.217  INFO 8792 --- [  AsyncWorker_1] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@5b1d0b10, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5f2284ab), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5f2284ab)
2020-05-22 09:15:56.217  INFO 8792 --- [  AsyncWorker_1] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM undo_log WHERE  branch_id IN  (?)  AND xid IN  (?)  ::: [2012243539, 192.168.10.107:8091:2012243535]

```
##### 6.1.3 StorageService 服务日志

```bash
2020-05-22 09:15:54.796  INFO 9580 --- [:20888-thread-3] i.s.s.i.s.dubbo.StorageDubboServiceImpl  : 全局事务id ：192.168.10.107:8091:2012243535
Creating a new SqlSession
Registering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073]
JDBC Connection [io.seata.rm.datasource.ConnectionProxy@42cfeb03] will be managed by Spring
==>  Preparing: SELECT id,commodity_code,name,count FROM t_storage WHERE (commodity_code = ?) 
==> Parameters: C201901140001(String)
2020-05-22 09:15:54.798  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Logic SQL: SELECT  id,commodity_code,name,count  FROM t_storage 
 
 WHERE (commodity_code = ?)
2020-05-22 09:15:54.798  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@5ec9be76, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7cd6d3e), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7cd6d3e, projectionsContext=ProjectionsContext(startIndex=8, stopIndex=35, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=commodity_code, alias=Optional.empty), ColumnProjection(owner=null, name=name, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@738d41ac, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@3680c897, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@b2abab7, containsSubquery=false)
2020-05-22 09:15:54.798  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT  id,commodity_code,name,count  FROM t_storage0 
 
 WHERE (commodity_code = ?) ::: [C201901140001]
2020-05-22 09:15:54.798  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT  id,commodity_code,name,count  FROM t_storage1 
 
 WHERE (commodity_code = ?) ::: [C201901140001]
<==    Columns: id, commodity_code, name, count
<==        Row: 1, C201901140001, 水杯, 650
<==      Total: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073]
Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073] from current transaction
==>  Preparing: update t_storage set count = count-50 where id = 1 
==> Parameters: 
2020-05-22 09:15:54.802  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Logic SQL: SELECT id, count FROM t_storage WHERE id = 1 FOR UPDATE
2020-05-22 09:15:54.802  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@1460703d, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@63ac0932), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@63ac0932, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=15, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@44882968, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@7694cb15, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@15dbf90b, containsSubquery=false)
2020-05-22 09:15:54.802  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, count FROM t_storage1 WHERE id = 1 FOR UPDATE
2020-05-22 09:15:54.804  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Logic SQL: update t_storage set count = count-50 where id = 1
2020-05-22 09:15:54.804  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : SQLStatement: UpdateStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.UpdateStatement@7029adff, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7341e361), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7341e361)
2020-05-22 09:15:54.804  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: update t_storage1 set count = count-50 where id = 1
2020-05-22 09:15:54.817  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Logic SQL: SELECT id, count FROM t_storage WHERE id in (?)
2020-05-22 09:15:54.817  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@44300acf, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@4680ebc4), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@4680ebc4, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=15, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@3e86252e, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@42a08374, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@e1a5a04, containsSubquery=false)
2020-05-22 09:15:54.817  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, count FROM t_storage1 WHERE id in (?) ::: [1]
<==    Updates: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073]
Transaction synchronization committing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073]
Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073]
Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@48378073]
2020-05-22 09:15:54.885  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Logic SQL: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now())
2020-05-22 09:15:54.885  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@23a45738, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6d82d00), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6d82d00, columnNames=[branch_id, xid, context, rollback_info, log_status, log_created, log_modified], insertValueContexts=[InsertValueContext(parametersCount=5, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=109, stopIndex=109, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=112, stopIndex=112, parameterMarkerIndex=1), ParameterMarkerExpressionSegment(startIndex=115, stopIndex=115, parameterMarkerIndex=2), ParameterMarkerExpressionSegment(startIndex=118, stopIndex=118, parameterMarkerIndex=3), ParameterMarkerExpressionSegment(startIndex=121, stopIndex=121, parameterMarkerIndex=4), org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@10b328c0, org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@48eb75ea], parameters=[2012243537, 192.168.10.107:8091:2012243535, serializer=jackson, javax.sql.rowset.serial.SerialBlob@d6553184, 0])], generatedKeyContext=Optional.empty)
2020-05-22 09:15:54.885  INFO 9580 --- [:20888-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now()) ::: [2012243537, 192.168.10.107:8091:2012243535, serializer=jackson, javax.sql.rowset.serial.SerialBlob@d6553184, 0]
2020-05-22 09:15:55.528  INFO 9580 --- [atch_RMROLE_1_8] i.s.core.rpc.netty.RmMessageListener     : onMessage:xid=192.168.10.107:8091:2012243535,branchId=2012243537,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/ds2,applicationData=null
2020-05-22 09:15:55.529  INFO 9580 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch committing: 192.168.10.107:8091:2012243535 2012243537 jdbc:mysql://127.0.0.1:3306/ds2 null
2020-05-22 09:15:55.529  INFO 9580 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch commit result: PhaseTwo_Committed
2020-05-22 09:15:55.532  INFO 9580 --- [  AsyncWorker_1] ShardingSphere-SQL                       : Logic SQL: DELETE FROM undo_log WHERE  branch_id IN  (?)  AND xid IN  (?) 
2020-05-22 09:15:55.532  INFO 9580 --- [  AsyncWorker_1] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@6eb59ea6, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6a8a17a8), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6a8a17a8)
2020-05-22 09:15:55.532  INFO 9580 --- [  AsyncWorker_1] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM undo_log WHERE  branch_id IN  (?)  AND xid IN  (?)  ::: [2012243537, 192.168.10.107:8091:2012243535]

```

##### 6.1.4 OrderService 服务日志

```bash
2020-05-22 09:15:54.956  INFO 6268 --- [:20880-thread-3] i.s.s.i.o.dubbo.OrderDubboServiceImpl    : 全局事务id ：192.168.10.107:8091:2012243535
Creating a new SqlSession
SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@23bc1e40] was not registered for synchronization because synchronization is not active
JDBC Connection [io.seata.rm.datasource.ConnectionProxy@2d7be447] will not be managed by Spring
==>  Preparing: insert into t_order values(?,?,1,?,50,100.0) 
==> Parameters: 1263639694564524034(String), 4e7d738e311a40cd8176795aafb8a247(String), C201901140001(String)
2020-05-22 09:15:55.132  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Logic SQL: insert into t_order values(?,?,1,?,50,100.0)
2020-05-22 09:15:55.132  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@385e4984, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@29447530), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@29447530, columnNames=[id, order_no, user_id, commodity_code, count, amount], insertValueContexts=[InsertValueContext(parametersCount=3, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=27, stopIndex=27, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=29, stopIndex=29, parameterMarkerIndex=1), LiteralExpressionSegment(startIndex=31, stopIndex=31, literals=1), ParameterMarkerExpressionSegment(startIndex=33, stopIndex=33, parameterMarkerIndex=2), LiteralExpressionSegment(startIndex=35, stopIndex=36, literals=50), LiteralExpressionSegment(startIndex=38, stopIndex=42, literals=100.0)], parameters=[1263639694564524034, 4e7d738e311a40cd8176795aafb8a247, C201901140001])], generatedKeyContext=Optional.empty)
2020-05-22 09:15:55.132  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: insert into t_order1 values(?, ?, 1, ?, 50, 100.0) ::: [1263639694564524034, 4e7d738e311a40cd8176795aafb8a247, C201901140001]
2020-05-22 09:15:55.135  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM t_order WHERE id in (?)
2020-05-22 09:15:55.135  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@64adbefc, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5de023c8), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5de023c8, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=order_no, alias=Optional.empty), ColumnProjection(owner=null, name=user_id, alias=Optional.empty), ColumnProjection(owner=null, name=commodity_code, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@578730b1, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@c691133, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@7ecd35e7, containsSubquery=false)
2020-05-22 09:15:55.135  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_order0 WHERE id in (?) ::: [1263639694564524034]
2020-05-22 09:15:55.135  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_order1 WHERE id in (?) ::: [1263639694564524034]
2020-05-22 09:15:55.202  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Logic SQL: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now())
2020-05-22 09:15:55.202  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@79890300, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1f521715), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1f521715, columnNames=[branch_id, xid, context, rollback_info, log_status, log_created, log_modified], insertValueContexts=[InsertValueContext(parametersCount=5, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=109, stopIndex=109, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=112, stopIndex=112, parameterMarkerIndex=1), ParameterMarkerExpressionSegment(startIndex=115, stopIndex=115, parameterMarkerIndex=2), ParameterMarkerExpressionSegment(startIndex=118, stopIndex=118, parameterMarkerIndex=3), ParameterMarkerExpressionSegment(startIndex=121, stopIndex=121, parameterMarkerIndex=4), org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@6d458949, org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@3204530f], parameters=[2012243541, 192.168.10.107:8091:2012243535, serializer=jackson, javax.sql.rowset.serial.SerialBlob@c45d57c1, 0])], generatedKeyContext=Optional.empty)
2020-05-22 09:15:55.203  INFO 6268 --- [:20880-thread-3] ShardingSphere-SQL                       : Actual SQL: ds0 ::: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now()) ::: [2012243541, 192.168.10.107:8091:2012243535, serializer=jackson, javax.sql.rowset.serial.SerialBlob@c45d57c1, 0]
<==    Updates: 1
Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@23bc1e40]
2020-05-22 09:15:55.596  INFO 6268 --- [atch_RMROLE_1_8] i.s.core.rpc.netty.RmMessageListener     : onMessage:xid=192.168.10.107:8091:2012243535,branchId=2012243541,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/ds1,applicationData=null
2020-05-22 09:15:55.597  INFO 6268 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch committing: 192.168.10.107:8091:2012243535 2012243541 jdbc:mysql://127.0.0.1:3306/ds1 null
2020-05-22 09:15:55.597  INFO 6268 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch commit result: PhaseTwo_Committed
2020-05-22 09:15:56.526  INFO 6268 --- [  AsyncWorker_1] ShardingSphere-SQL                       : Logic SQL: DELETE FROM undo_log WHERE  branch_id IN  (?)  AND xid IN  (?) 
2020-05-22 09:15:56.526  INFO 6268 --- [  AsyncWorker_1] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@3d80f8b5, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1c45d32), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1c45d32)
2020-05-22 09:15:56.526  INFO 6268 --- [  AsyncWorker_1] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM undo_log WHERE  branch_id IN  (?)  AND xid IN  (?)  ::: [2012243541, 192.168.10.107:8091:2012243535]

```

### 6. 2 发送一个下单请求(异常回滚情况)
我们`samples-business`将`BusinessServiceImpl`的`handleBusiness2` 下面的代码去掉注释

```java
if (!flag) {
  throw new RuntimeException(""测试抛异常后，分布式事务回滚！"");
}
```
使用postman 发送 ：[http://localhost:8104/business/dubbo/buy2](http://localhost:8104/business/dubbo/buy2) 


```json
{
    ""userId"":1,
    ""commodityCode"":""C201901140001"",
    ""name"":""fan"",
    ""count"":50,
    ""amount"":""100""
}
```

响应结果：

```json
{
    ""timestamp"": ""2020-05-22T01:27:53.517+0000"",
    ""status"": 500,
    ""error"": ""Internal Server Error"",
    ""message"": ""测试抛异常后，分布式事务回滚！"",
    ""path"": ""/business/dubbo/buy2""
}
```
##### 6.2.1 BusinessService 服务日志

```shell
2020-05-22 09:27:52.386  INFO 13384 --- [nio-8104-exec-7] i.s.s.i.c.controller.BusinessController  : 请求参数：BusinessDTO(userId=1, commodityCode=C201901140001, name=fan, count=50, amount=100)
2020-05-22 09:27:52.422  INFO 13384 --- [nio-8104-exec-7] i.seata.tm.api.DefaultGlobalTransaction  : Begin new global transaction [192.168.10.107:8091:2012243545]
2020-05-22 09:27:52.422  INFO 13384 --- [nio-8104-exec-7] i.s.s.i.c.service.BusinessServiceImpl    : 开始全局事务，XID = 192.168.10.107:8091:2012243545
2020-05-22 09:27:53.515  INFO 13384 --- [nio-8104-exec-7] i.seata.tm.api.DefaultGlobalTransaction  : [192.168.10.107:8091:2012243545] rollback status: Rollbacked
2020-05-22 09:27:53.516 ERROR 13384 --- [nio-8104-exec-7] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.RuntimeException: 测试抛异常后，分布式事务回滚！] with root cause

java.lang.RuntimeException: 测试抛异常后，分布式事务回滚！
	at io.seata.samples.integration.call.service.BusinessServiceImpl.handleBusiness2(BusinessServiceImpl.java:99) ~[classes/:na]
	at io.seata.samples.integration.call.service.BusinessServiceImpl$$FastClassBySpringCGLIB$$2ab3d645.invoke(<generated>) ~[classes/:na]
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) ~[spring-aop-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) ~[spring-aop-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at io.seata.spring.annotation.GlobalTransactionalInterceptor$1.execute(GlobalTransactionalInterceptor.java:109) ~[seata-all-1.2.0.jar:1.2.0]
	at io.seata.tm.api.TransactionalTemplate.execute(TransactionalTemplate.java:104) ~[seata-all-1.2.0.jar:1.2.0]
	at io.seata.spring.annotation.GlobalTransactionalInterceptor.handleGlobalTransaction(GlobalTransactionalInterceptor.java:106) ~[seata-all-1.2.0.jar:1.2.0]
	at io.seata.spring.annotation.GlobalTransactionalInterceptor.invoke(GlobalTransactionalInterceptor.java:83) ~[seata-all-1.2.0.jar:1.2.0]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) ~[spring-aop-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) ~[spring-aop-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at io.seata.samples.integration.call.service.BusinessServiceImpl$$EnhancerBySpringCGLIB$$11be97b5.handleBusiness2(<generated>) ~[classes/:na]
	at io.seata.samples.integration.call.controller.BusinessController.handleBusiness2(BusinessController.java:48) ~[classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_144]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_144]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_144]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_144]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:879) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.5.RELEASE.jar:5.2.5.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1594) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_144]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_144]
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.33.jar:9.0.33]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_144]
```

##### 6.2.2 AccountService 服务日志

```bash
2020-05-22 09:27:52.635  INFO 8792 --- [:20883-thread-4] i.s.s.i.a.dubbo.AccountDubboServiceImpl  : 全局事务id ：192.168.10.107:8091:2012243545
Creating a new SqlSession
Registering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58622fda]
JDBC Connection [io.seata.rm.datasource.ConnectionProxy@529a44aa] will be managed by Spring
==>  Preparing: update t_account set amount = amount-100.0 where id = 1 
==> Parameters: 
2020-05-22 09:27:52.637  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Logic SQL: SELECT id, amount FROM t_account WHERE id = 1 FOR UPDATE
2020-05-22 09:27:52.637  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@60fae881, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1798d09d), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1798d09d, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=16, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@5ecd214b, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@2645a0de, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@26fa0fa8, containsSubquery=false)
2020-05-22 09:27:52.637  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, amount FROM t_account1 WHERE id = 1 FOR UPDATE
2020-05-22 09:27:52.640  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Logic SQL: update t_account set amount = amount-100.0 where id = 1
2020-05-22 09:27:52.640  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : SQLStatement: UpdateStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.UpdateStatement@5ba704b6, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@73f934c4), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@73f934c4)
2020-05-22 09:27:52.640  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: update t_account1 set amount = amount-100.0 where id = 1
2020-05-22 09:27:52.643  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Logic SQL: SELECT id, amount FROM t_account WHERE id in (?)
2020-05-22 09:27:52.643  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@697bcc02, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@38a68471), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@38a68471, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=16, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@77bfb086, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@4ddaf5a1, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@13ea38b2, containsSubquery=false)
2020-05-22 09:27:52.643  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, amount FROM t_account1 WHERE id in (?) ::: [1]
<==    Updates: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58622fda]
Transaction synchronization committing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58622fda]
Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58622fda]
Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58622fda]
2020-05-22 09:27:52.757  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Logic SQL: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now())
2020-05-22 09:27:52.757  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@354923b3, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@4d520553), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@4d520553, columnNames=[branch_id, xid, context, rollback_info, log_status, log_created, log_modified], insertValueContexts=[InsertValueContext(parametersCount=5, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=109, stopIndex=109, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=112, stopIndex=112, parameterMarkerIndex=1), ParameterMarkerExpressionSegment(startIndex=115, stopIndex=115, parameterMarkerIndex=2), ParameterMarkerExpressionSegment(startIndex=118, stopIndex=118, parameterMarkerIndex=3), ParameterMarkerExpressionSegment(startIndex=121, stopIndex=121, parameterMarkerIndex=4), org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@5fd3f282, org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@2e3bb335], parameters=[2012243550, 192.168.10.107:8091:2012243545, serializer=jackson, javax.sql.rowset.serial.SerialBlob@4e4593ee, 0])], generatedKeyContext=Optional.empty)
2020-05-22 09:27:52.757  INFO 8792 --- [:20883-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now()) ::: [2012243550, 192.168.10.107:8091:2012243545, serializer=jackson, javax.sql.rowset.serial.SerialBlob@4e4593ee, 0]
2020-05-22 09:27:53.190  INFO 8792 --- [atch_RMROLE_1_8] i.s.core.rpc.netty.RmMessageListener     : onMessage:xid=192.168.10.107:8091:2012243545,branchId=2012243550,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/ds0,applicationData=null
2020-05-22 09:27:53.190  INFO 8792 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch Rollbacking: 192.168.10.107:8091:2012243545 2012243550 jdbc:mysql://127.0.0.1:3306/ds0
2020-05-22 09:27:53.191  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM undo_log WHERE branch_id = ? AND xid = ? FOR UPDATE
2020-05-22 09:27:53.191  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@6481a025, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@59a7b23f), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@59a7b23f, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=branch_id, alias=Optional.empty), ColumnProjection(owner=null, name=xid, alias=Optional.empty), ColumnProjection(owner=null, name=context, alias=Optional.empty), ColumnProjection(owner=null, name=rollback_info, alias=Optional.empty), ColumnProjection(owner=null, name=log_status, alias=Optional.empty), ColumnProjection(owner=null, name=log_created, alias=Optional.empty), ColumnProjection(owner=null, name=log_modified, alias=Optional.empty), ColumnProjection(owner=null, name=ext, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@5760477b, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@535fd94f, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@165d4d40, containsSubquery=false)
2020-05-22 09:27:53.191  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM undo_log WHERE branch_id = ? AND xid = ? FOR UPDATE ::: [2012243550, 192.168.10.107:8091:2012243545]
2020-05-22 09:27:53.193  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM t_account WHERE id in (?)
2020-05-22 09:27:53.193  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@761b9b19, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2781f95b), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2781f95b, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@a39c945, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@7672b20f, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@7de97fec, containsSubquery=false)
2020-05-22 09:27:53.194  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_account1 WHERE id in (?) ::: [1]
2020-05-22 09:27:53.195  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: UPDATE t_account SET amount = ? WHERE id = ?
2020-05-22 09:27:53.195  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: UpdateStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.UpdateStatement@4df03ffe, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@113d823e), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@113d823e)
2020-05-22 09:27:53.195  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: UPDATE t_account1 SET amount = ? WHERE id = ? ::: [3600.0, 1]
2020-05-22 09:27:53.212  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: DELETE FROM undo_log WHERE branch_id = ? AND xid = ?
2020-05-22 09:27:53.212  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@2baab4f5, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@723ca8dc), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@723ca8dc)
2020-05-22 09:27:53.212  INFO 8792 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM undo_log WHERE branch_id = ? AND xid = ? ::: [2012243550, 192.168.10.107:8091:2012243545]
2020-05-22 09:27:53.286  INFO 8792 --- [atch_RMROLE_1_8] i.s.r.d.undo.AbstractUndoLogManager      : xid 192.168.10.107:8091:2012243545 branch 2012243550, undo_log deleted with GlobalFinished
2020-05-22 09:27:53.287  INFO 8792 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch Rollbacked result: PhaseTwo_Rollbacked
```

##### 6.2.3 StorageService 服务日志

```bash
2020-05-22 09:27:52.425  INFO 9580 --- [:20888-thread-4] i.s.s.i.s.dubbo.StorageDubboServiceImpl  : 全局事务id ：192.168.10.107:8091:2012243545
Creating a new SqlSession
Registering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2]
JDBC Connection [io.seata.rm.datasource.ConnectionProxy@3052f6a2] will be managed by Spring
==>  Preparing: SELECT id,commodity_code,name,count FROM t_storage WHERE (commodity_code = ?) 
==> Parameters: C201901140001(String)
2020-05-22 09:27:52.428  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Logic SQL: SELECT  id,commodity_code,name,count  FROM t_storage 
 
 WHERE (commodity_code = ?)
2020-05-22 09:27:52.428  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@5ec9be76, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@75506ecc), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@75506ecc, projectionsContext=ProjectionsContext(startIndex=8, stopIndex=35, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=commodity_code, alias=Optional.empty), ColumnProjection(owner=null, name=name, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@1b7a39b9, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@44efbcfd, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@632fb524, containsSubquery=false)
2020-05-22 09:27:52.428  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT  id,commodity_code,name,count  FROM t_storage0 
 
 WHERE (commodity_code = ?) ::: [C201901140001]
2020-05-22 09:27:52.428  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT  id,commodity_code,name,count  FROM t_storage1 
 
 WHERE (commodity_code = ?) ::: [C201901140001]
<==    Columns: id, commodity_code, name, count
<==        Row: 1, C201901140001, 水杯, 600
<==      Total: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2]
Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2] from current transaction
==>  Preparing: update t_storage set count = count-50 where id = 1 
==> Parameters: 
2020-05-22 09:27:52.432  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Logic SQL: SELECT id, count FROM t_storage WHERE id = 1 FOR UPDATE
2020-05-22 09:27:52.432  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@1460703d, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@782b9d5a), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@782b9d5a, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=15, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@1131e855, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@585126e2, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@2209f5bf, containsSubquery=false)
2020-05-22 09:27:52.432  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, count FROM t_storage1 WHERE id = 1 FOR UPDATE
2020-05-22 09:27:52.433  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Logic SQL: update t_storage set count = count-50 where id = 1
2020-05-22 09:27:52.433  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : SQLStatement: UpdateStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.UpdateStatement@7029adff, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@18814e21), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@18814e21)
2020-05-22 09:27:52.433  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: update t_storage1 set count = count-50 where id = 1
2020-05-22 09:27:52.445  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Logic SQL: SELECT id, count FROM t_storage WHERE id in (?)
2020-05-22 09:27:52.445  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@44300acf, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@247fbd61), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@247fbd61, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=15, distinctRow=false, projections=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@41198f32, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@53fb3176, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@2a5b57d9, containsSubquery=false)
2020-05-22 09:27:52.445  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT id, count FROM t_storage1 WHERE id in (?) ::: [1]
<==    Updates: 1
Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2]
Transaction synchronization committing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2]
Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2]
Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3aaa9dd2]
2020-05-22 09:27:52.541  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Logic SQL: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now())
2020-05-22 09:27:52.541  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@23a45738, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7401fc21), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7401fc21, columnNames=[branch_id, xid, context, rollback_info, log_status, log_created, log_modified], insertValueContexts=[InsertValueContext(parametersCount=5, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=109, stopIndex=109, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=112, stopIndex=112, parameterMarkerIndex=1), ParameterMarkerExpressionSegment(startIndex=115, stopIndex=115, parameterMarkerIndex=2), ParameterMarkerExpressionSegment(startIndex=118, stopIndex=118, parameterMarkerIndex=3), ParameterMarkerExpressionSegment(startIndex=121, stopIndex=121, parameterMarkerIndex=4), org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@10b328c0, org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@48eb75ea], parameters=[2012243547, 192.168.10.107:8091:2012243545, serializer=jackson, javax.sql.rowset.serial.SerialBlob@e6006345, 0])], generatedKeyContext=Optional.empty)
2020-05-22 09:27:52.541  INFO 9580 --- [:20888-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now()) ::: [2012243547, 192.168.10.107:8091:2012243545, serializer=jackson, javax.sql.rowset.serial.SerialBlob@e6006345, 0]
2020-05-22 09:27:53.340  INFO 9580 --- [atch_RMROLE_1_8] i.s.core.rpc.netty.RmMessageListener     : onMessage:xid=192.168.10.107:8091:2012243545,branchId=2012243547,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/ds2,applicationData=null
2020-05-22 09:27:53.340  INFO 9580 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch Rollbacking: 192.168.10.107:8091:2012243545 2012243547 jdbc:mysql://127.0.0.1:3306/ds2
2020-05-22 09:27:53.340  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM undo_log WHERE branch_id = ? AND xid = ? FOR UPDATE
2020-05-22 09:27:53.340  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@361d5f71, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@12dcbe90), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@12dcbe90, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=branch_id, alias=Optional.empty), ColumnProjection(owner=null, name=xid, alias=Optional.empty), ColumnProjection(owner=null, name=context, alias=Optional.empty), ColumnProjection(owner=null, name=rollback_info, alias=Optional.empty), ColumnProjection(owner=null, name=log_status, alias=Optional.empty), ColumnProjection(owner=null, name=log_created, alias=Optional.empty), ColumnProjection(owner=null, name=log_modified, alias=Optional.empty), ColumnProjection(owner=null, name=ext, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@1c1b52bb, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@1824d5e0, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@5d265880, containsSubquery=false)
2020-05-22 09:27:53.341  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM undo_log WHERE branch_id = ? AND xid = ? FOR UPDATE ::: [2012243547, 192.168.10.107:8091:2012243545]
2020-05-22 09:27:53.343  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM t_storage WHERE id in (?)
2020-05-22 09:27:53.343  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@19c73cee, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6c3144f4), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6c3144f4, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=commodity_code, alias=Optional.empty), ColumnProjection(owner=null, name=name, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@52840747, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@3d09a7cf, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@5dbcf0f1, containsSubquery=false)
2020-05-22 09:27:53.343  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_storage1 WHERE id in (?) ::: [1]
2020-05-22 09:27:53.344  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: UPDATE t_storage SET count = ? WHERE id = ?
2020-05-22 09:27:53.344  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: UpdateStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.UpdateStatement@2c4d9b68, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@49808f57), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@49808f57)
2020-05-22 09:27:53.344  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: UPDATE t_storage1 SET count = ? WHERE id = ? ::: [600, 1]
2020-05-22 09:27:53.346  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: DELETE FROM undo_log WHERE branch_id = ? AND xid = ?
2020-05-22 09:27:53.346  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@9b8689c, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@39477e77), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@39477e77)
2020-05-22 09:27:53.346  INFO 9580 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM undo_log WHERE branch_id = ? AND xid = ? ::: [2012243547, 192.168.10.107:8091:2012243545]
2020-05-22 09:27:53.399  INFO 9580 --- [atch_RMROLE_1_8] i.s.r.d.undo.AbstractUndoLogManager      : xid 192.168.10.107:8091:2012243545 branch 2012243547, undo_log deleted with GlobalFinished
2020-05-22 09:27:53.399  INFO 9580 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch Rollbacked result: PhaseTwo_Rollbacked
```

##### 6.2.4 OrderService 服务日志

```bash
2020-05-22 09:27:52.615  INFO 6268 --- [:20880-thread-4] i.s.s.i.o.dubbo.OrderDubboServiceImpl    : 全局事务id ：192.168.10.107:8091:2012243545
Creating a new SqlSession
SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3be964] was not registered for synchronization because synchronization is not active
JDBC Connection [io.seata.rm.datasource.ConnectionProxy@efc0713] will not be managed by Spring
==>  Preparing: insert into t_order values(?,?,1,?,50,100.0) 
==> Parameters: 1263642704673898497(String), 72ac94267b7f4f729b42ff72e641a0c4(String), C201901140001(String)
2020-05-22 09:27:52.799  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Logic SQL: insert into t_order values(?,?,1,?,50,100.0)
2020-05-22 09:27:52.799  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@385e4984, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@ac38214), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@ac38214, columnNames=[id, order_no, user_id, commodity_code, count, amount], insertValueContexts=[InsertValueContext(parametersCount=3, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=27, stopIndex=27, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=29, stopIndex=29, parameterMarkerIndex=1), LiteralExpressionSegment(startIndex=31, stopIndex=31, literals=1), ParameterMarkerExpressionSegment(startIndex=33, stopIndex=33, parameterMarkerIndex=2), LiteralExpressionSegment(startIndex=35, stopIndex=36, literals=50), LiteralExpressionSegment(startIndex=38, stopIndex=42, literals=100.0)], parameters=[1263642704673898497, 72ac94267b7f4f729b42ff72e641a0c4, C201901140001])], generatedKeyContext=Optional.empty)
2020-05-22 09:27:52.799  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: insert into t_order1 values(?, ?, 1, ?, 50, 100.0) ::: [1263642704673898497, 72ac94267b7f4f729b42ff72e641a0c4, C201901140001]
2020-05-22 09:27:52.802  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM t_order WHERE id in (?)
2020-05-22 09:27:52.802  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@64adbefc, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@68010a02), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@68010a02, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=order_no, alias=Optional.empty), ColumnProjection(owner=null, name=user_id, alias=Optional.empty), ColumnProjection(owner=null, name=commodity_code, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@2feef267, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@4a8eb7b2, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@13b4c98b, containsSubquery=false)
2020-05-22 09:27:52.802  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_order0 WHERE id in (?) ::: [1263642704673898497]
2020-05-22 09:27:52.802  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_order1 WHERE id in (?) ::: [1263642704673898497]
2020-05-22 09:27:52.875  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Logic SQL: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now())
2020-05-22 09:27:52.875  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@79890300, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2160f297), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2160f297, columnNames=[branch_id, xid, context, rollback_info, log_status, log_created, log_modified], insertValueContexts=[InsertValueContext(parametersCount=5, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=109, stopIndex=109, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=112, stopIndex=112, parameterMarkerIndex=1), ParameterMarkerExpressionSegment(startIndex=115, stopIndex=115, parameterMarkerIndex=2), ParameterMarkerExpressionSegment(startIndex=118, stopIndex=118, parameterMarkerIndex=3), ParameterMarkerExpressionSegment(startIndex=121, stopIndex=121, parameterMarkerIndex=4), org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@6d458949, org.apache.shardingsphere.sql.parser.sql.segment.dml.item.ExpressionProjectionSegment@3204530f], parameters=[2012243552, 192.168.10.107:8091:2012243545, serializer=jackson, javax.sql.rowset.serial.SerialBlob@582376a0, 0])], generatedKeyContext=Optional.empty)
2020-05-22 09:27:52.875  INFO 6268 --- [:20880-thread-4] ShardingSphere-SQL                       : Actual SQL: ds0 ::: INSERT INTO undo_log (branch_id, xid, context, rollback_info, log_status, log_created, log_modified) VALUES (?, ?, ?, ?, ?, now(), now()) ::: [2012243552, 192.168.10.107:8091:2012243545, serializer=jackson, javax.sql.rowset.serial.SerialBlob@582376a0, 0]
<==    Updates: 1
Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3be964]
2020-05-22 09:27:52.980  INFO 6268 --- [atch_RMROLE_1_8] i.s.core.rpc.netty.RmMessageListener     : onMessage:xid=192.168.10.107:8091:2012243545,branchId=2012243552,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/ds1,applicationData=null
2020-05-22 09:27:52.980  INFO 6268 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch Rollbacking: 192.168.10.107:8091:2012243545 2012243552 jdbc:mysql://127.0.0.1:3306/ds1
2020-05-22 09:27:52.980  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM undo_log WHERE branch_id = ? AND xid = ? FOR UPDATE
2020-05-22 09:27:52.980  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@24965d4, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1a720567), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@1a720567, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=branch_id, alias=Optional.empty), ColumnProjection(owner=null, name=xid, alias=Optional.empty), ColumnProjection(owner=null, name=context, alias=Optional.empty), ColumnProjection(owner=null, name=rollback_info, alias=Optional.empty), ColumnProjection(owner=null, name=log_status, alias=Optional.empty), ColumnProjection(owner=null, name=log_created, alias=Optional.empty), ColumnProjection(owner=null, name=log_modified, alias=Optional.empty), ColumnProjection(owner=null, name=ext, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@14b5e859, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@108a6e17, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@5588e262, containsSubquery=false)
2020-05-22 09:27:52.981  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM undo_log WHERE branch_id = ? AND xid = ? FOR UPDATE ::: [2012243552, 192.168.10.107:8091:2012243545]
2020-05-22 09:27:52.983  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: SELECT * FROM t_order WHERE id in (?)
2020-05-22 09:27:52.983  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@64adbefc, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6497500b), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@6497500b, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=7, distinctRow=false, projections=[ShorthandProjection(owner=Optional.empty, actualColumns=[ColumnProjection(owner=null, name=id, alias=Optional.empty), ColumnProjection(owner=null, name=order_no, alias=Optional.empty), ColumnProjection(owner=null, name=user_id, alias=Optional.empty), ColumnProjection(owner=null, name=commodity_code, alias=Optional.empty), ColumnProjection(owner=null, name=count, alias=Optional.empty), ColumnProjection(owner=null, name=amount, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@272e6058, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@35a71d2d, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@369b70d4, containsSubquery=false)
2020-05-22 09:27:52.983  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_order0 WHERE id in (?) ::: [1263642704673898497]
2020-05-22 09:27:52.983  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: SELECT * FROM t_order1 WHERE id in (?) ::: [1263642704673898497]
2020-05-22 09:27:52.985  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: DELETE FROM t_order WHERE id = ?
2020-05-22 09:27:52.985  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@2f28ed8, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2778c7cc), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@2778c7cc)
2020-05-22 09:27:52.985  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM t_order0 WHERE id = ? ::: [1263642704673898497]
2020-05-22 09:27:52.985  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM t_order1 WHERE id = ? ::: [1263642704673898497]
2020-05-22 09:27:53.022  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Logic SQL: DELETE FROM undo_log WHERE branch_id = ? AND xid = ?
2020-05-22 09:27:53.022  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : SQLStatement: DeleteStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.DeleteStatement@15c0ff43, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@4cfe761d), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@4cfe761d)
2020-05-22 09:27:53.022  INFO 6268 --- [atch_RMROLE_1_8] ShardingSphere-SQL                       : Actual SQL: ds0 ::: DELETE FROM undo_log WHERE branch_id = ? AND xid = ? ::: [2012243552, 192.168.10.107:8091:2012243545]
2020-05-22 09:27:53.127  INFO 6268 --- [atch_RMROLE_1_8] i.s.r.d.undo.AbstractUndoLogManager      : xid 192.168.10.107:8091:2012243545 branch 2012243552, undo_log deleted with GlobalFinished
2020-05-22 09:27:53.128  INFO 6268 --- [atch_RMROLE_1_8] io.seata.rm.AbstractRMHandler            : Branch Rollbacked result: PhaseTwo_Rollbacked
```

我们查看数据库数据，已经回滚，和上面的数据一致。

到这里一个简单的`seata1.2.0`、`sharding-sphere4.1.0`和`dubbo2.7.5` 的整合案例基本就分析结束。感谢你的学习。如果想交流的可以私信我。
"
cloudsimplus/cloudsimplus,master,386,185,2015-03-18T17:11:29Z,45896,21,"State-of-the-art Framework 🏗 for Cloud Computing ⛅️ Simulation: a modern, full-featured, easier-to-use, highly extensible 🧩, faster 🚀 and more accurate ☕️ Java 17+ tool for cloud computing research 🎓. Examples: https://github.com/cloudsimplus/cloudsimplus-examples",auto-scaling cloud-computing cloud-infrastructure cloud-simulation cloudsim cloudsim-simulator cloudsimplus google-cluster-data iaas java java-17 load-balancing paas research saas simulation simulation-framework test-bed trace workload,"<a id=""top""></a>

<p align=""center"">
<b><a href=""#overview"">Overview</a></b>
|
<b><a href=""#exclusive-features"">Exclusive Features</a></b>
|
<b><a href=""#structure"">Structure</a></b>
|
<b><a href=""#usage"">How to use</a></b>
|
<b><a href=""#example"">Example</a></b>
|
<b><a href=""#docs-help"">Docs and Help</a></b>
|
<b><a href=""#consulting"">Consulting</a></b>
|
<b><a href=""#general-features"">General Features</a></b>
|
<b><a href=""#publications"">Publications</a></b>
|
<b><a href=""#projects"">Related Projects</a></b>
|
<b><a href=""#license"">License</a></b>
|
<b><a href=""#contributing"">Contributing</a></b>
</p>

<a id=""overview""></a>

# 1. Overview

[![Consulting](https://img.shields.io/badge/Consulting-Click%20here-brightgreen)](#consulting) [![Build Status](https://github.com/cloudsimplus/cloudsimplus/actions/workflows/build.yml/badge.svg)](https://github.com/cloudsimplus/cloudsimplus/actions/workflows/build.yml) [![Codacy Badge](https://app.codacy.com/project/badge/Grade/9aaa4b031c1d4143bdd39c4eedf49562)](https://www.codacy.com/gh/cloudsimplus/cloudsimplus/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=cloudsimplus/cloudsimplus&amp;utm_campaign=Badge_Grade) [![Codacy Code Coverage](https://app.codacy.com/project/badge/Coverage/9aaa4b031c1d4143bdd39c4eedf49562)](https://www.codacy.com/gh/manoelcampos/cloudsimplus/dashboard?utm_source=github.com&utm_medium=referral&utm_content=manoelcampos/cloudsimplus&utm_campaign=Badge_Coverage) [![Maven Central](https://img.shields.io/maven-central/v/org.cloudsimplus/cloudsimplus.svg?label=Maven%20Central)](https://central.sonatype.com/search?q=cloudsimplus&namespace=org.cloudsimplus) [![Documentation Status](https://readthedocs.org/projects/cloudsimplus/badge/?version=latest)](http://cloudsimplus.rtfd.io/en/latest/?badge=latest) [![GPL licensed](https://img.shields.io/badge/license-GPL-blue.svg)](http://www.gnu.org/licenses/gpl-3.0) [![GitHub Repo stars](https://img.shields.io/github/stars/cloudsimplus/cloudsimplus?label=Contribute.%20Star%20it.)](https://github.com/cloudsimplus/cloudsimplus) [![Twitter Follow](https://img.shields.io/twitter/follow/cloudsimplus?style=social)](http://twitter.com/cloudsimplus)

CloudSim Plus is a modern, up-to-date, full-featured and fully documented **Java 17** simulation framework. It's easy to use and extend, enabling modeling, simulation, and experimentation of Cloud computing infrastructures and application services. 
It allows developers to focus on specific system design issues to be investigated, without concerning the low-level details related to Cloud-based infrastructures and services.
 
CloudSim Plus is a fork of CloudSim 3, re-engineered primarily to avoid code duplication, provide code reuse and ensure compliance with software engineering principles and recommendations for extensibility improvements and accuracy. It's currently the state-of-the-art in cloud computing simulation framework. 

The efforts dedicated to this project have been recognized by the [EU/Brasil Cloud FORUM](https://eubrasilcloudforum.eu). 
A post about CloudSim Plus is available at 
[this page of the Forum](https://eubrasilcloudforum.eu/en/instituto-federal-de-educação-do-tocantins-brazil-instituto-de-telecomunicações-portugal-and), including a White Paper available in the [Publications Section](#publications).

CloudSim Plus started through a partnership between the [Instituto de Telecomunicações (IT, Portugal)](http://www.it.pt), 
the [Universidade da Beira Interior (UBI, Portugal)](http://www.ubi.pt) 
and the [Instituto Federal de Educação Ciência e Tecnologia do Tocantins (IFTO, Brazil)](http://www.ifto.edu.br). 
It was partially supported by the Portuguese [Fundação para a Ciência e a Tecnologia (FCT)](https://www.fct.pt) 
and by the [Brazilian foundation Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES)](http://www.capes.gov.br).

> **Note**
> If you are using CloudSim Plus in your research, please make sure you cite this paper: M. C. Silva Filho, R. L. Oliveira, C. C. Monteiro, P. R. M. Inácio, and M. M. Freire. [CloudSim Plus: a Cloud Computing Simulation Framework Pursuing Software Engineering Principles for Improved Modularity, Extensibility and Correctness,](https://doi.org/10.23919/INM.2017.7987304) in IFIP/IEEE International Symposium on Integrated Network Management, 2017, p. 7.

**IMPORTANT**
---
- Developing and maintaining this project takes a huge effort. This way, any kind of [contribution](#contributing) is encouraged. Show your support by giving it a star :star: using the button at the top of the GitHub page. It takes no time, helps promoting the project and keeps it evolving. Thanks in advance :clap:.
- If you are not intending to make changes and contribute back to the project, you shouldn't fork it. Your fork become obsolete as the project is updated. 
- If you're willing to use the framework to develop your own project on top of it, creating a fork is the worst way. You aren't supposed to change the framework code to implement your project, but to extend it by creating some subclasses. Unless you are planning to contribute your changes back, you'll end up with an incompatible and obsolete version of the framework. The project is constantly evolving and bugfixes are a priority. Your fork with personal changes will miss those updates and high performance improvements.
---

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""exclusive-features""></a>

# 2. Main Exclusive Features 🧰

CloudSim Plus provides lots of exclusive features, from the most basic ones to build simple simulations, 
to advanced features for simulating more realistic cloud scenarios: 

1. It is easier to use. [A complete and easy-to-understand simulation scenario can be built in few lines of code.](#example)
1. Multi-cloud simulations with inter-datacenter VM migrations ([#361](https://github.com/cloudsimplus/cloudsimplus/issues/361)).
1. Creation of joint power- and network-aware simulations ([#45](https://github.com/cloudsimplus/cloudsimplus/issues/45)).
1. Vertical ([#7](https://github.com/cloudsimplus/cloudsimplus/issues/7)) and Horizontal VM scaling ([#41](https://github.com/cloudsimplus/cloudsimplus/issues/41)).
1. [Highly accurate power usage computation](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/power/PowerExampleSchedulingInterval.java) ([#153](https://github.com/cloudsimplus/cloudsimplus/issues/153)).
1. [Built-in computation of CPU utilization history and energy consumption for VMs (and Hosts)](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/power/PowerExample.java) ([#168](https://github.com/cloudsimplus/cloudsimplus/issues/168)).
1. [Virtual Memory and Reduced bandwidth allocation](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/resourceusage/VirtualMemoryForRequestedRamHigherThanAvailableExample.java) when RAM and BW are oversubscribed. ([#170](https://github.com/cloudsimplus/cloudsimplus/issues/170)). 
1. [Automatically power Hosts on and off according to demand](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/power/HostActivationExample.java) ([#128](https://github.com/cloudsimplus/cloudsimplus/issues/128)) and support defining a startup and shutdown delay/power consumption ([#238](https://github.com/cloudsimplus/cloudsimplus/issues/238)).
1. [Parallel execution of simulations in multi-core computers](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/ParallelSimulationsExample.java), allowing multiple simulations to be run simultaneously in an isolated way ([#38](https://github.com/cloudsimplus/cloudsimplus/issues/38)).
1. Delay creation of submitted VMs and [Cloudlets](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/dynamic/DynamicCloudletsArrival1.java), enabling simulation of dynamic arrival of tasks ([#11](https://github.com/cloudsimplus/cloudsimplus/issues/11), [#23](https://github.com/cloudsimplus/cloudsimplus/issues/23)). 
1. [Allow dynamic creation of VMs and Cloudlets in runtime](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/dynamic/DynamicCreationOfVmsAndCloudletsExample.java), enabling VMs to be created on-demand ([#43](https://github.com/cloudsimplus/cloudsimplus/issues/43)).
1. [Listeners](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/listeners) to enable simulation configuration, monitoring and data collection.
1. Create [simulations](https://github.com/cloudsimplus/cloudsimplus-examples/tree/master/src/main/java/org/cloudsimplus/examples/traces/google) from [Google Cluster Data](https://github.com/google/cluster-data/blob/master/ClusterData2011_2.md) 
    trace files. ([#149](https://github.com/cloudsimplus/cloudsimplus/issues/149)).
1. Strongly object-oriented, allowing chained calls such as `cloudlet.getVm().getHost().getDatacenter()` without even worrying about `NullPointerException` ([#10](https://github.com/cloudsimplus/cloudsimplus/issues/10)).
1. Classes and interfaces for implementing [heuristics](http://en.wikipedia.org/wiki/Heuristic) such as [Tabu Search](http://en.wikipedia.org/wiki/Tabu_search), [Simulated Annealing](http://en.wikipedia.org/wiki/Simulated_annealing), [Ant Colony Systems](http://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms) and so on ([example here](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/brokers/DatacenterBrokerHeuristicExample.java)).
1. [Implementation of the Completely Fair Scheduler](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler) used in recent versions of the Linux Kernel ([example here](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/schedulers/LinuxCompletelyFairSchedulerExample.java)) ([#58](https://github.com/cloudsimplus/cloudsimplus/issues/58)).
1. [Host Fault Injection and Recovery Mechanism](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/HostFaultInjectionExample1.java) to enable injection of random failures into Hosts CPU cores and replication of failed VMs ([#81](https://github.com/cloudsimplus/cloudsimplus/issues/81)).
1. [Creation of Hosts at Simulation Runtime](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/dynamic/DynamicHostCreation.java) to enable physical expansion of Datacenter capacity ([#124](https://github.com/cloudsimplus/cloudsimplus/issues/124)).
1. [Enables the simulation to keep running, waiting for dynamic and even random events such as the arrival of Cloudlets and VMs](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/dynamic/KeepSimulationRunningExample.java) ([#130](https://github.com/cloudsimplus/cloudsimplus/issues/130)).
1. TableBuilder objects that are used in all examples and enable printing simulation results in different formats such as Markdown Table, CSV or HTML.
1. Colors log messages and enables filtering the level of messages to print ([#24](https://github.com/cloudsimplus/cloudsimplus/issues/24)). ![](docs/images/log-messages-by-type.png) If you want to just see messages from warning level, call `Log.setLevel(ch.qos.logback.classic.Level.WARN);`
1. [Enables running the simulation synchronously, making it easier to interact with it and collect data inside a loop, as the simulation goes on](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/synchronous/SynchronousSimulationExample1.java). This brings freedom to implement your simulations ([#205](https://github.com/cloudsimplus/cloudsimplus/issues/205)).
1. [Allows placing a group of VMs into the same Host.](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/VmGroupPlacementExample1.java) ([#90](https://github.com/cloudsimplus/cloudsimplus/issues/90)).
1. [Enables Broker to try selecting the closest Datacenter to place VMs, according to their time zone.](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/brokers/DatacenterSelectionByTimeZoneExample.java) ([#212](https://github.com/cloudsimplus/cloudsimplus/issues/212)).
1. Non-Live VM migration from/to public-cloud datacenters ([#437](https://github.com/cloudsimplus/cloudsimplus/issues/437)).
1. Support VM startup/shutdown delay and boot overhead ([#435](https://github.com/cloudsimplus/cloudsimplus/issues/435))
1. It outperforms CloudSim 4, as can be seen [here](docs/performance.md).

<a id=""structure""></a>

# 3. Project's Structure 🏗

CloudSim Plus has a simpler structure to make it ease to use and understand. It consists of 4 modules, 2 of which are new, as presented below.

![CloudSim Plus Modules](https://github.com/cloudsimplus/cloudsimplus/raw/master/docs/images/modules.png)

- cloudsimplus (this module): the CloudSim Plus cloud simulation framework API, which is used by all other modules. 
  It is the main and only required module you need to write cloud simulations. 
- [cloudsimplus-examples](https://github.com/cloudsimplus/cloudsimplus-examples): includes a series of different examples, since minimal simulation scenarios using basic 
  CloudSim Plus features, to complex scenarios using workloads from trace files or Vm migration examples. This is an excellent starting point for learning how to build cloud simulations using CloudSim Plus.
- [cloudsimplus-testbeds](https://github.com/cloudsimplus/cloudsimplus-testbeds): enables implementation of simulation testbeds in a repeatable manner, 
  allowing a researcher to execute several simulation runs for a given experiment and collect statistical data using a scientific approach. 
- [cloudsimplus-benchmarks](https://github.com/cloudsimplus/cloudsimplus-benchmarks): a new module used just internally to implement micro benchmarks to assess framework performance.

It also has a better package organization, 
improving [Separation of Concerns (SoC)](https://en.wikipedia.org/wiki/Separation_of_concerns) 
and making it easy to know where a desired class is and what is inside each package. 
The figure below presents the new package organization. 
The dark yellow packages are new in CloudSim Plus and include its exclusive interfaces and classes. 
The light yellow ones were introduced just to better organize existing CloudSim classes and interfaces. 

![CloudSim Plus Packages](https://github.com/cloudsimplus/cloudsimplus/raw/master/docs/images/package-structure-reduced.png)

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""usage""></a>

## 4. Project Requirements

CloudSim Plus is a Java 17 project that uses maven for build and dependency management. To build and run the project, you need JDK 17+ installed and an updated version of maven (such as 3.8.6+). Maven is already installed on your IDE. Unless it's out-of-date or you want to build the project from the command line, you need to install maven into your operating system. All project dependencies are download automatically by maven.

# 5. How to Use CloudSim Plus 👩🏽‍💻 

> **Warning**
> Before trying to use this project, make sure you have JDK 17 installed.

There are 2 ways to use CloudSim Plus:

- creating your own project and add it as a dependency. This way, it will be downloaded directly from [Maven Central](https://maven-badges.herokuapp.com/maven-central/org.cloudsimplus/cloudsimplus).
- downloading the [cloudsimplus-examples](https://github.com/cloudsimplus/cloudsimplus-examples) project and following the instructions there.

Check sections below if you want to add CloudSim Plus as a dependency into your own Maven or Gradle project. This way you can start building your simulations from scratch.

## 5.1 Maven

Add the following dependency into the pom.xml file of your own Maven project. 

```xml
<dependency>
    <groupId>org.cloudsimplus</groupId>
    <artifactId>cloudsimplus</artifactId>
    <!-- Set a specific version or use the latest one -->
    <version>LATEST</version>
</dependency>
```

## 5.2 Gradle

Add the following dependency into the build.gradle file of your own Gradle project. 

```groovy
dependencies {
    //Set a specific version or use the latest one
    implementation 'org.cloudsimplus:cloudsimplus:LATEST'
}
```

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""example""></a>

# 6. Building CloudSim Plus

CloudSim Plus is a maven project. The previuos section just showed that you don't need to download the project sources to understand how the project works or to create your own experiments or tool on top of CloudSim Plus. You can just download the [example's project](https://github.com/cloudsimplus/cloudsimplus-examples) and start your experiments or a new simulation framewework from there. Anyway, if you want to build CloudSim Plus, you have two ways:

## 6.1 Using some IDE

Open the project on your favorite IDE and click the build button and that is it.

## 6.2 Using a terminal

Open a terminal at the project root directory and type one of the following commands: 

on Linux/macOS 

```bash
./mvnw clean install
```

on Windows

```bash
mvnw.cmd clean install
```

# 7. A Minimal but Complete Simulation Example ⚙️

In order to build a simulation scenario, you have to create at least:
 
- a datacenter with a list of physical machines (Hosts); 
- a broker that allows submission of VMs and Cloudlets to be executed, on behalf of a given customer, into the cloud infrastructure; 
- a list of customer's virtual machines (VMs); 
- and a list of customer's cloudlets (objects that model resource requirements of different applications).

Due to the simplicity provided by CloudSim Plus, all the code to create a minimal simulation scenario can be as simple as presented below.
A more adequate and reusable example is available
[here](https://github.com/cloudsimplus/cloudsimplus-examples/blob/master/src/main/java/org/cloudsimplus/examples/BasicFirstExample.java),
together with other ones available in the [cloudsimplus-examples](https://github.com/cloudsimplus/cloudsimplus-examples) repository. 

```java
//Enables just some level of logging.
//Make sure to import org.cloudsimplus.util.Log;
//Log.setLevel(ch.qos.logback.classic.Level.WARN);

//Creates a CloudSimPlus object to initialize the simulation.
var simulation = new CloudSimPlus();

//Creates a Broker that will act on behalf of a cloud user (customer).
var broker0 = new DatacenterBrokerSimple(simulation);

//Host configuration
long ram = 10000; //in Megabytes
long storage = 100000; //in Megabytes
long bw = 100000; //in Megabits/s
        
//Creates one host with a specific list of CPU cores (PEs).
//Uses a PeProvisionerSimple by default to provision PEs for VMs
//Uses ResourceProvisionerSimple by default for RAM and BW provisioning
//Uses VmSchedulerSpaceShared by default for VM scheduling
var host0 = new HostSimple(ram, bw, storage, List.of(new PeSimple(20000)));

//Creates a Datacenter with a list of Hosts.
//Uses a VmAllocationPolicySimple by default to allocate VMs
var dc0 = new DatacenterSimple(simulation, List.of(host0));

//Creates one VM with one CPU core to run applications.
//Uses a CloudletSchedulerTimeShared by default to schedule Cloudlets
var vm0 = new VmSimple(1000, 1);
vm0.setRam(1000).setBw(1000).setSize(1000);

//Creates Cloudlets that represent applications to be run inside a VM.
//It has a length of 1000 Million Instructions (MI) and requires 1 CPU core 
//UtilizationModel defining the Cloudlets use only 50% of any resource all the time
var utilizationModel = new UtilizationModelDynamic(0.5);
var cloudlet0 = new CloudletSimple(10000, 1, utilizationModel);
var cloudlet1 = new CloudletSimple(10000, 1, utilizationModel);
var cloudletList = List.of(cloudlet0, cloudlet1);

broker0.submitVmList(List.of(vm0));
broker0.submitCloudletList(cloudletList);

/*Starts the simulation and waits all cloudlets to be executed, automatically
stopping when there is no more events to process.*/
simulation.start();

/*Prints the results when the simulation is over
(you can use your own code here to print what you want from this cloudlet list).*/
new CloudletsTableBuilder(broker0.getCloudletFinishedList()).build();
```

The presented results are structured and clear to allow better understanding. 
For example, the image below shows the output for a simulation with two cloudlets (applications).

![Simulation Results](https://github.com/cloudsimplus/cloudsimplus/raw/master/docs/images/simulation-results.png)

## 7.1 Comparison with CloudSim

A complete, side-by-side [comparison between CloudSim and CloudSim
Plus Java simulation scenarios
is available
here](http://cloudsimplus.org/docs/CloudSim-and-CloudSimPlus-Comparison.html).

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""docs-help""></a>

# 8. Documentation and Help 📘🆘

The project documentation originated from CloudSim was entirely updated and extended. 
You can see the javadoc documentation for classes and their elements directly on your IDE.

The documentation is available online at [ReadTheDocs](http://cloudsimplus.rtfd.io/en/latest/?badge=latest), 
which includes a FAQ and guides.
CloudSim Plus has extended documentation of classes and interfaces and also includes extremely helpful
package documentation that can be viewed directly on your IDE or at the link provided above.
Such a package documentation gives a general overview of the classes used to build a cloud simulation. Also, check the [publications](#publications) section to access published CloudSim Plus papers.

A Google Group forum is available at <https://groups.google.com/group/cloudsimplus> and you can also use the [Discussions page here](https://github.com/cloudsimplus/cloudsimplus/discussions).

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""consulting""></a>

# 9. Consulting and Professional Support 👨🏽‍🏫

If you are doing research on cloud computing simulation and facing challenging issues, I've started to offer my consulting services.

I can help you with different kinds of issues and provide specific features for your simulations, including resource allocation, task scheduling, VM placement and migration, metrics computation, process automation, debugging, results analysis, validation and more.

If you have a CloudSim project and want to migrate to CloudSim Plus to benefit from its extensive documentation, active development and support, exclusive features, great accuracy and performance, the consulting can be fit for you too.

**Get the [contact e-mail here](https://github.com/manoelcampos).**

<a id=""general-features""></a>

# 10. General Features of the Framework 🛠

CloudSim Plus supports modeling and simulation of:

* large scale Cloud computing data centers;
* virtualized server hosts, with customizable policies for provisioning host resources to virtual machines;
* data center network topologies and message-passing applications;
* federated clouds;
* user-defined policies for allocation of hosts to virtual machines and policies for allocation of host resources to virtual machines.

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""publications""></a>

# 11. CloudSim Plus Publications 📝

1. M. C. Silva Filho, R. L. Oliveira, C. C. Monteiro, P. R. M. Inácio, and M. M. Freire. [CloudSim Plus: a Cloud Computing Simulation Framework Pursuing Software Engineering Principles for Improved Modularity, Extensibility and Correctness,](https://doi.org/10.23919/INM.2017.7987304) in IFIP/IEEE International Symposium on Integrated Network Management, 2017, p. 7. If you are using CloudSim Plus in your research, please make sure you cite that paper. You can check the paper presentation [here](http://cloudsimplus.org/docs/presentation/).
2. White Paper. [CloudSim Plus: A Modern Java 17+ Framework for Modeling and Simulation of Cloud Computing Infrastructures and Services](https://cloudsimplus.github.io/cloudsimplus-whitepaper). 2016.
3. R. L. Oliveira. [Virtual Machine Allocation in Cloud Computing Environments based on Service Level Agreements](https://doi.org/10400.6/7839) (only in Portuguese). Master's Dissertation. University of Beira Interior, 2017 (Supervisor: M. M. Freire).
  
<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""projects""></a>

# 12. Related Projects 🧩

Here, it's presented a list of some projects based on CloudSim Plus, which trust in its accuracy, performance, maintainability and extensibility.
If you want your project to be listed here, send us a Pull Request. Make sure your project has a descriptive README.

1. [CloudSim Plus Py4j gateway](https://github.com/pkoperek/cloudsimplus-gateway): building CloudSim Plus simulations in Python
1. [PySDNSim](https://github.com/ulfaric/PySDNSim): a Python simulation tool for microservice-based SDN using CloudSim Plus as the underlying framework.
1. [RECAP Discrete Event Simulation Framework:](https://bitbucket.org/RECAP-DES/recap-des/) an extension for CloudSimPlus
1. [CloudSim Plus Automation](https://github.com/cloudsimplus/cloudsimplus-automation): defining CloudSim Plus simulation scenarios into a YAML file.
1. [LEAF](https://github.com/dos-group/leaf-java): Simulator for modeling Large Energy-Aware Fog computing environments.
1. [EPCSAC](https://github.com/TNanukem/EPCSAC): Extensible Platform for Cloud Scheduling Algorithm Comparison.
1. [SatEdgeSim](https://github.com/wjy491156866/SatEdgeSim): A Toolkit for Modeling and Simulation of Performance Evaluation in Satellite Edge Computing Environments.

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""license""></a>

# 13. License ⚖️

This project is licensed under [GNU GPLv3](http://www.gnu.org/licenses/gpl-3.0), as defined inside CloudSim 3 source files.

<p align=""right""><a href=""#top"">:arrow_up:</a></p>

<a id=""contributing""></a>

# 14. Contributing 🤝

You are welcome to contribute to the project. 
However, make sure you read the [contribution guide](https://github.com/cloudsimplus/.github/blob/main/CONTRIBUTING.md) before starting. 
The guide provides information on the different ways you can contribute, 
such as by requesting a feature, reporting an issue, fixing a bug or providing some new feature.

<p align=""right""><a href=""#top"">:arrow_up:</a></p>
"
b4w/Education,master,61,36,2015-12-15T19:48:55Z,58587,0,Directory with lerning examples and programms.,,"# Education
Directory with lerning examples and programms.

# [Notes](https://github.com/b4w/Education/tree/master/Notes ""Notes"")
Some notes for online cources and more. 
* [android](https://github.com/b4w/Education/tree/master/Notes/android ""android"")
* [databases](https://github.com/b4w/Education/tree/master/Notes/databases ""databases"")
* [devops](https://github.com/b4w/Education/tree/master/Notes/devops ""devops"")
* [java](https://github.com/b4w/Education/tree/master/Notes/java ""java"")

# [Projects](https://github.com/b4w/Education/tree/master/Progects ""Projects"")
* [Spring / Spring boot](https://github.com/b4w/Education/tree/master/Progects/Java/Spring ""spring"")

# [Wiki](https://github.com/b4w/Education/wiki ""wiki"")
Notes for Stepic online course.
"
bezkoder/spring-boot-spring-security-jwt-authentication,master,1210,783,2019-10-15T16:02:02Z,141,23,"Spring Boot + Security: Token Based Authentication example with JWT, Authorization, Spring Data & MySQL",jwt jwt-authentication spring-boot spring-boot-2 spring-boot-security spring-boot-server spring-data spring-security spring-security-jwt,"# Spring Boot JWT Authentication example with Spring Security & Spring Data JPA

## User Registration, User Login and Authorization process.
The diagram shows flow of how we implement User Registration, User Login and Authorization process.

![spring-boot-jwt-authentication-spring-security-flow](spring-boot-jwt-authentication-spring-security-flow.png)

## Spring Boot Server Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-jwt-authentication-spring-security-architecture](spring-boot-jwt-authentication-spring-security-architecture.png)

## Dependency
– If you want to use PostgreSQL:
```xml
<dependency>
  <groupId>org.postgresql</groupId>
  <artifactId>postgresql</artifactId>
  <scope>runtime</scope>
</dependency>
```
– or MySQL:
```xml
<dependency>
  <groupId>com.mysql</groupId>
  <artifactId>mysql-connector-j</artifactId>
  <scope>runtime</scope>
</dependency>
```
## Configure Spring Datasource, JPA, App properties
Open `src/main/resources/application.properties`
- For PostgreSQL:
```
spring.datasource.url= jdbc:postgresql://localhost:5432/testdb
spring.datasource.username= postgres
spring.datasource.password= 123

spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation= true
spring.jpa.properties.hibernate.dialect= org.hibernate.dialect.PostgreSQLDialect

# Hibernate ddl auto (create, create-drop, validate, update)
spring.jpa.hibernate.ddl-auto= update

# App Properties
bezkoder.app.jwtSecret= bezKoderSecretKey
bezkoder.app.jwtExpirationMs= 86400000
```
- For MySQL
```
spring.datasource.url=jdbc:mysql://localhost:3306/testdb_spring?useSSL=false
spring.datasource.username=root
spring.datasource.password=123456

spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQLDialect
spring.jpa.hibernate.ddl-auto=update

# App Properties
bezkoder.app.jwtSecret= ======================BezKoder=Spring===========================
bezkoder.app.jwtExpirationMs=86400000
```
## Run Spring Boot application
```
mvn spring-boot:run
```

## Run following SQL insert statements
```
INSERT INTO roles(name) VALUES('ROLE_USER');
INSERT INTO roles(name) VALUES('ROLE_MODERATOR');
INSERT INTO roles(name) VALUES('ROLE_ADMIN');
```

For more detail, please visit:
> [Secure Spring Boot with Spring Security & JWT Authentication](https://bezkoder.com/spring-boot-jwt-authentication/)

> [For MongoDB](https://bezkoder.com/spring-boot-jwt-auth-mongodb/)

## Refresh Token

![spring-boot-refresh-token-jwt-example-flow](spring-boot-refresh-token-jwt-example-flow.png)

For instruction: [Spring Boot Refresh Token with JWT example](https://bezkoder.com/spring-boot-refresh-token-jwt/)

## More Practice:
> [Spring Boot JWT Authentication example using HttpOnly Cookie](https://www.bezkoder.com/spring-boot-login-example-mysql/)

> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Associations:
> [Spring Boot One To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-one-to-many/)

> [Spring Boot Many To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA One To One example with Spring Boot](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)

## Fullstack Authentication

> [Spring Boot + Vue.js JWT Authentication](https://bezkoder.com/spring-boot-vue-js-authentication-jwt-spring-security/)

> [Spring Boot + Angular 8 JWT Authentication](https://bezkoder.com/angular-spring-boot-jwt-auth/)

> [Spring Boot + Angular 10 JWT Authentication](https://bezkoder.com/angular-10-spring-boot-jwt-auth/)

> [Spring Boot + Angular 11 JWT Authentication](https://bezkoder.com/angular-11-spring-boot-jwt-auth/)

> [Spring Boot + Angular 12 JWT Authentication](https://www.bezkoder.com/angular-12-spring-boot-jwt-auth/)

> [Spring Boot + Angular 13 JWT Authentication](https://www.bezkoder.com/angular-13-spring-boot-jwt-auth/)

> [Spring Boot + Angular 14 JWT Authentication](https://www.bezkoder.com/angular-14-spring-boot-jwt-auth/)

> [Spring Boot + Angular 15 JWT Authentication](https://www.bezkoder.com/angular-15-spring-boot-jwt-auth/)

> [Spring Boot + Angular 16 JWT Authentication](https://www.bezkoder.com/angular-16-spring-boot-jwt-auth/)

> [Spring Boot + Angular 17 JWT Authentication](https://www.bezkoder.com/angular-17-spring-boot-jwt-auth/)

> [Spring Boot + React JWT Authentication](https://bezkoder.com/spring-boot-react-jwt-auth/)

## Fullstack CRUD App

> [Vue.js + Spring Boot + H2 Embedded database example](https://www.bezkoder.com/spring-boot-vue-js-crud-example/)

> [Vue.js + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-vue-js-mysql/)

> [Vue.js + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-vue-js-postgresql/)

> [Angular 8 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + MySQL example](https://bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-spring-boot-postgresql/)

> [Angular 10 + Spring Boot + MySQL example](https://bezkoder.com/angular-10-spring-boot-crud/)

> [Angular 10 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-10-spring-boot-postgresql/)

> [Angular 11 + Spring Boot + MySQL example](https://bezkoder.com/angular-11-spring-boot-crud/)

> [Angular 11 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-11-spring-boot-postgresql/)

> [Angular 12 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-12-spring-boot-crud/)

> [Angular 12 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-12-spring-boot-mysql/)

> [Angular 12 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-12-spring-boot-postgresql/)

> [Angular 13 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-13-crud/)

> [Angular 13 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-13-mysql/)

> [Angular 13 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-13-postgresql/)

> [Angular 14 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-14-crud/)

> [Angular 14 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-14-mysql/)

> [Angular 14 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-14-postgresql/)

> [Angular 15 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-15-crud/)

> [Angular 15 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-15-mysql/)

> [Angular 15 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-15-postgresql/)

> [Angular 16 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-16-crud/)

> [Angular 16 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-16-mysql/)

> [Angular 16 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-16-postgresql/)

> [Angular 17 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-17-crud/)

> [Angular 17 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-17-mysql/)

> [Angular 17 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-17-postgresql/)

> [React + Spring Boot + MySQL example](https://bezkoder.com/react-spring-boot-crud/)

> [React + Spring Boot + PostgreSQL example](https://bezkoder.com/spring-boot-react-postgresql/)

> [React + Spring Boot + MongoDB example](https://bezkoder.com/react-spring-boot-mongodb/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React.js with Spring Boot Rest API](https://bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue.js with Spring Boot Rest API](https://bezkoder.com/integrate-vue-spring-boot/)
"
bitmovin/bitmovin-api-sdk-examples,main,37,28,2019-08-13T12:36:17Z,662,9,Set of encoding workflow examples highlighting the use of the Bitmovin API SDKs,,"<p align=""center"">
  <a href=""https://www.bitmovin.com"">
    <img alt=""Bitmovin API SDK Examples Header"" src=""https://cdn.bitmovin.com/frontend/encoding/openapi-clients/readme-headers/Readme_OpenApi_Header.png"" >
  </a>

  <h4 align=""center"">This repository provides examples demonstrating usage of the <br><a href=""https://bitmovin.com/docs/encoding/sdks"" target=""_blank"">Bitmovin API SDKs</a> in different programming languages.</h4>

  <p align=""center"">
    <a href=""LICENSE""><img src=""https://img.shields.io/badge/License-MIT-yellow.svg"" alt=""License""></img></a>
  </p>
</p>

### 💡 Getting started

You'll need an active Bitmovin API key for these examples to work.

> Don't have an account yet? [Sign up for a free Bitmovin trial plan](https://dashboard.bitmovin.com/signup)!

If you are new to the topic, we suggest reading our tutorial [Understanding the Bitmovin Encoding Object Model](https://bitmovin.com/docs/encoding/tutorials/understanding-the-bitmovin-encoding-object-model) to get a basic idea of the building blocks that make up an encoding.

For instructions how to set up the configuration environment and run examples, consult the `README.md` file in the subfolder for your preferred programming language.

For full documentation of all available API endpoints, see the [Bitmovin API reference](https://bitmovin.com/docs/encoding/api-reference).

### Overview
+ [Fixed Bitrate Ladder Encoding](#fixed-bitrate-ladder-encoding)  
   Generate multiple MP4 renditions from a single input file using a fixed set of resolutions and target bitrates
+ [Generating Default Manifests](#generating-default-manifests)  
   Generate basic DASH and HLS manifests tailored to your encoding output
+ [Per-Title Encoding](#per-title-encoding)  
   Generate optimized renditions by letting the Per-Title algorithm choose resolutions and bitrates based on the complexity of your content
+ [Multi Codec Encoding](#multi-codec-encoding)  
   Run a multi-codec workflow following the best practices.
+ [Multi-language Broadcast TS Encoding](#multi-language-broadcast-ts-encoding)  
   Add multiple audio streams to a Broadcast TS muxing
+ [Applying Filters](#applying-filters)  
   Enhance and manipulate content by applying pre-defined video or audio filters
+ [Server-Side Ad Insertion (SSAI)](#server-side-ad-insertion-ssai)  
   Prevent blocking of ads by delivering a continuous content stream
+ [RTMP Live Encoding](#rtmp-live-encoding)  
   Start a live encoding using an RTMP stream as input
+ [RTMP Live HD Encoding](#rtmp-live-hd-encoding)  
   Start a live encoding with HD option using an RTMP stream as input
+ [Batch Encoding](#batch-encoding)  
   Efficiently start and track a large number of encodings
+ [Multiple Inputs Concatenation](#multiple-inputs-concatenation)  
   Combine multiple input files into a single output using concatenation and trimming
+ [HDR SDR Conversion](#hdr-sdr-conversion)
   Convert dynamic range format between DolbyVision, HDR10, HLG and SDR.
+ [CDN](#cdn)
   Use the Bitmovin CDN Streaming storage to distribute your assets.


+ **Content Protection**
    + [Applying CENC DRM Content Protection](#applying-cenc-drm-content-protection)  
      Encrypt output to prevent unauthorized playback
    + [Applying Content Protection with SPEKE](#applying-drm-content-protection-with-speke)  
      Obtain DRM keys from a SPEKE server


+ **Audio Manipulations**

  Map, mix and merge audio streams and channels from one or multiple sources
   + [Simple Handling - Implicit Mapping](#simple-handling---implicit-mapping)
   + [Simple Handling - Distinct Input Files](#simple-handling---distinct-input-files)
   + [Channel Mixing - Swapping Channels](#channel-mixing---swapping-channels)
   + [Channel Mixing - Downmixing](#channel-mixing---downmixing)
   + [Stream Mapping - Mono Input Tracks](#stream-mapping---mono-input-tracks)
   + [Stream Merging - Multiple Streams](#stream-merging---background-audio)

### More examples?
For more code snippets, and sometimes complete scripts, please have a look at our [tutorials](https://bitmovin.com/docs/encoding/tutorials) and our [Community pages](https://community.bitmovin.com/docs?tags=code-example%7Cbitmovin-encoding&utm_source=github&utm_medium=bitmovin-api-sdk-examples&utm_campaign=dev-community)

---
### Fixed Bitrate Ladder Encoding

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/FixedBitrateLadder.cs"">C#</a> -
<a href=""java/src/main/java/FixedBitrateLadder.java"">Java</a> -
<a href=""javascript/src/FixedBitrateLadder.ts"">TS/JS</a> -
<a href=""php/src/FixedBitrateLadder.php"">PHP</a> -
<a href=""python/src/fixed_bitrate_ladder.py"">Python</a>

This example demonstrates how to create multiple MP4 renditions in a single encoding, using a fixed resolution- and bitrate ladder.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### Generating Default Manifests

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/DefaultManifest.cs"">C#</a> -
<a href=""java/src/main/java/DefaultManifests.java"">Java</a> -
<a href=""javascript/src/DefaultManifest.ts"">TS/JS</a> -
<a href=""php/src/DefaultManifest.php"">PHP</a> -
<a href=""python/src/default_manifest.py"">Python</a>

This example demonstrates how to create basic DASH and HLS manifests for an encoding. Default manifests will try include all the encoding's features that are supported by the respective manifest type.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### Per-Title Encoding

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/PerTitleEncoding.cs"">C#</a> -
<a href=""java/src/main/java/PerTitleEncoding.java"">Java</a> -
<a href=""javascript/src/PerTitleEncoding.ts"">TS/JS</a> -
<a href=""php/src/PerTitleEncoding.php"">PHP</a> -
<a href=""python/src/per_title_encoding.py"">Python</a>

This example shows how to do a Per-Title encoding with default manifests.
A Per-Title encoding automatically detects the optimal codec settings for your video assets.

Visit https://bitmovin.com/per-title-encoding/ to get an insight what Per-Title encoding is and how it works.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### Multi Codec Encoding

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/MultiCodecEncoding.cs"">C#</a> -
<a href=""java/src/main/java/MultiCodecEncoding.java"">Java</a> -
<a href=""javascript/src/MultiCodecEncoding.ts"">TS/JS</a> -
<a href=""php/src/MultiCodecEncoding.php"">PHP</a> -
<a href=""python/src/multi_codec_encoding.py"">Python</a>

This example showcases how to run a multi-codec workflow following the best practices.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### Multi-language Broadcast TS Encoding

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/MultiLanguageBroadcastTs.cs"">C#</a> -
<a href=""java/src/main/java/MultiLanguageBroadcastTs.java"">Java</a> -
<a href=""javascript/src/MultiLanguageBroadcastTs.ts"">TS/JS</a> -
 <a href=""php/src/MultiLanguageBroadcastTs.php"">PHP</a> -
<a href=""python/src/multi_language_broadcast_ts.py"">Python</a>

This example demonstrates how multiple audio streams can be included in a BroadcastTS muxing. BroadcastTS muxings are [MPEG transport stream](https://en.wikipedia.org/wiki/MPEG_transport_stream) muxings which allow setting custom properties such as [PCR](https://en.wikipedia.org/wiki/MPEG_transport_stream#PCR) interval and [PID](https://en.wikipedia.org/wiki/MPEG_transport_stream#Packet_identifier_(PID))s for transmission to traditional broadcast targets like set top boxes, QAM streamers and similar devices. This muxing is not generally used for streaming to IP devices such as browsers, iOS, or Android devices.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### Applying Filters

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/Filters.cs"">C#</a> -
<a href=""java/src/main/java/Filters.java"">Java</a> -
<a href=""javascript/src/Filters.ts"">TS/JS</a> -
<a href=""php/src/Filters.php"">PHP</a> -
<a href=""python/src/filters.py"">Python</a>

This example demonstrates how to apply filters to a video stream. Filters will manipulate the content of a stream, e.g. remove noise or add a watermark image. See the [Encoding Filters API Reference](https://bitmovin.com/docs/encoding/api-reference/sections/filters) for a complete list of available filters.

 Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))
 + `WATERMARK_IMAGE_PATH` ([?](#WATERMARK_IMAGE_PATH))
 + `TEXT_FILTER_TEXT` ([?](#TEXT_FILTER_TEXT))

---
### Server-Side Ad Insertion (SSAI)

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/ServerSideAdInsertion.cs"">C#</a> -
<a href=""java/src/main/java/ServerSideAdInsertion.java"">Java</a> -
<a href=""javascript/src/ServerSideAdInsertion.ts"">TS/JS</a> -
<a href=""php/src/ServerSideAdInsertion.php"">PHP</a> -
<a href=""python/src/server_side_ad_insertion.py"">Python</a>

This example demonstrates how to create multiple fMP4 renditions with Server Side Ad Insertion (SSAI).

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### RTMP Live Encoding

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/RtmpLiveEncoding.cs"">C#</a> -
<a href=""java/src/main/java/RtmpLiveEncoding.java"">Java</a> -
<a href=""javascript/src/RtmpLiveEncoding.ts"">TS/JS</a> -
<a href=""php/src/RtmpLiveEncoding.php"">PHP</a> -
<a href=""python/src/rtmp_live_encoding.py"">Python</a>

This example shows how to configure and start a live encoding using default DASH and HLS manifests.
For more information see: https://bitmovin.com/live-encoding-live-streaming

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### RTMP Live HD Encoding

<a href=""java/src/main/java/RtmpLiveHdEncoding.java"">Java</a> -
<a href=""dotnet/Bitmovin.Api.Sdk.Examples/RtmpLiveHdEncoding.cs"">C#</a> -
<a href=""javascript/src/RtmpLiveHdEncoding.ts"">TS/JS</a> -
<a href=""php/src/RtmpLiveHdEncoding.php"">PHP</a> -
<a href=""python/src/rtmp_live_hd_encoding.py"">Python</a>


This example shows how to configure and start a live encoding with HD option using default DASH and HLS manifests.
For more information see: https://bitmovin.com/live-encoding-live-streaming

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### Batch Encoding

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/BatchEncoding.cs"">C#</a> -
<a href=""java/src/main/java/BatchEncoding.java"">Java</a> -
<a href=""javascript/src/BatchEncoding.ts"">TS/JS</a> -
<a href=""php/src/BatchEncoding.php"">PHP</a> -
<a href=""python/src/batch_encoding.py"">Python</a>

This example demonstrates how to efficiently execute a large batch of encodings in parallel. In
order to keep the startup time for each encoding to a minimum, it is advisable to constantly have
some encodings queued. Encodings will therefore be started in a way to maintain a constant queue
size.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))


---
### CDN

<a href=""java/src/main/java/EncodingWithCdnOutput.java"">Java</a> -
<a href=""javascript/src/EncodingWithCdnOutput.ts"">TS/JS</a> -
<a href=""python/src/encoding_with_cdn_output.py"">Python</a>

This example demonstrates how to use the Bitmovin CDN Streaming storage to distribute your assets to end users.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))

---
### Multiple Inputs Concatenation

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/ConcatenationMultipleInputs.cs"">C#</a> -
<a href=""java/src/main/java/ConcatenationMultipleInputs.java"">Java</a> -
<a href=""javascript/src/ConcatenationMultipleInputs.ts"">TS/JS</a> -
<a href=""php/src/ConcatenationMultipleInputs.php"">PHP</a> -
<a href=""python/src/concatenation_multiple_inputs.py"">Python</a>

This example demonstrates how to use concatenation and trimming to combine multiple input files into a single output.
This script is the full version of the script documented in the tutorial on concatenation and trimming https://bitmovin.com/docs/encoding/tutorials/stitching-and-trimming-part-1-the-basics

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `HTTP_INPUT_BUMPER_FILE_PATH` ([?](#HTTP_INPUT_BUMPER_FILE_PATH))
+ `HTTP_INPUT_PROMO_FILE_PATH` ([?](#HTTP_INPUT_PROMO_FILE_PATH))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

---
### HDR SDR Conversion
<a href=""python/src/hdr_conversions.py"">Python</a> -
<a href=""java/src/main/java/HdrConversions.java"">Java</a> -
<a href=""javascript/src/HdrConversions.ts"">TS/JS</a>

This example demonstrates how to convert dynamic range format between DolbyVision, HDR10, HLG and SDR.

The supported HDR/SDR conversions are as follows. If the target output format is either DolbyVision, HDR10 or HLG, this example adds SDR renditions automatically. This example works only with Bitmovin Encoder version 2.98.0 or later.

  - Input: DolbyVision
    - Output:
      - DolbyVision and SDR
      - HDR10 and SDR
  - Input: HDR10
    - Output:
      - HDR10 and SDR
      - HLG and SDR
  - Input: HLG
    - Output:
      - HLG and SDR
      - HDR10 and SDR
  - Input: SDR
    - Output:
      - HDR10 and SDR
      - HLG and SDR

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `HTTP_INPUT_AUDIO_FILE_PATH` ([?](#HTTP_INPUT_AUDIO_FILE_PATH))
+ `HDR_CONVERSION_INPUT_FORMAT` ([?](#HDR_CONVERSION_INPUT_FORMAT))
+ `HDR_CONVERSION_OUTPUT_FORMAT` ([?](#HDR_CONVERSION_OUTPUT_FORMAT))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

If you want to load a DolbyVision metadata as a sidecar XML file, the following parameter also needs to be specified. If that parameter is not provided for a DolbyVision encoding, the example assumes the corresponding metadata is embedded into the DolbyVision input mezzanine file itself.
+ `HTTP_INPUT_DOLBY_VISION_METADATA_FILE_PATH` ([?](#HTTP_INPUT_DOLBY_VISION_METADATA_FILE_PATH))

---
### Content Protection
#### Applying CENC DRM Content Protection

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/CencDrmContentProtection.cs"">C#</a> -
<a href=""java/src/main/java/CencDrmContentProtection.java"">Java</a> -
<a href=""javascript/src/CencDrmContentProtection.ts"">TS/JS</a> -
<a href=""php/src/CencDrmContentProtection.php"">PHP</a> -
<a href=""python/src/cenc_drm_content_protection.py"">Python</a>
<a href=""go/cmd/cenc_drm_content_protection.go"">Go</a>

This example shows how DRM content protection can be applied to a fragmented MP4 muxing. DRM is used to prevent playback on unauthorized devices (piracy) and requires integration with a key server.
The encryption is configured to be compatible with both FairPlay and Widevine, using the [MPEG Common Encryption](https://en.wikipedia.org/wiki/MPEG_Common_Encryption) standard.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))
+ `DRM_KEY` ([?](#DRM_KEY))
+ `DRM_FAIRPLAY_IV` ([?](#DRM_FAIRPLAY_IV))
+ `DRM_FAIRPLAY_URI` ([?](#DRM_FAIRPLAY_URI))
+ `DRM_WIDEVINE_KID` ([?](#DRM_WIDEVINE_KID))
+ `DRM_WIDEVINE_PSSH` ([?](#DRM_WIDEVINE_PSSH))

---
#### Applying DRM Content Protection with SPEKE

<a href=""java/src/main/java/DrmContentProtectionWithSpeke.java"">Java</a> -
<a href=""javascript/src/DrmContentProtectionWithSpeke.ts"">TS/JS</a> -
<a href=""python/src/drm_content_protection_with_speke.py"">Python</a>

This example builds on the previous one, but shows how keys for DRM content protection
can be obtained from a SPEKE server, and adds FairPlay DRM. Manifests are built
from scratch, with DASH for CENC protected outputs, and HLS for FairPlay

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))
+ `SPEKE_URL` ([?](#SPEKE_URL))
+ and for AWS IAM authentication
    + `SPEKE_ARN` ([?](#SPEKE_ARN))
    + `SPEKE_GATEWAY_REGION` ([?](#SPEKE_GATEWAY_REGION))
+ or for simple credentials
    + `SPEKE_USERNAME` ([?](#SPEKE_USERNAME))
    + `SPEKE_PASSWORD` ([?](#SPEKE_PASSWORD))

Optional Parameters
+ `DRM_FAIRPLAY_IV` ([?](#DRM_FAIRPLAY_IV))
+ `DRM_CONTENT_ID` ([?](#DRM_CONTENT_ID))
+ `DRM_KEY_ID` ([?](#DRM_KEY_ID))

---
### Audio Manipulations
A set of examples that demonstrate how to perform audio stream and channel manipulations.
They are provided as illustrations of the [tutorial on audio manipulations]
(https://bitmovin.com/docs/encoding/tutorials/separating-and-combining-audio-streams)

#### Simple Handling - Implicit Mapping

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/AudioManipulations/SimpleHandlingImplicitMapping.cs"">C#</a> -
<a href=""java/src/main/java/AudioManipulations/SimpleHandling_ImplicitMapping.java"">Java</a> -
<a href=""javascript/src/AudioManipulations/SimpleHandlingImplicitMapping.ts"">TS/JS</a> -
<a href=""php/src/AudioManipulations/SimpleHandling_ImplicitMapping.php"">PHP</a> -
<a href=""python/src/audio_manipulations/simple_handling_implicit_mapping.py"">Python</a>

This example demonstrates the simplest mechanism to include a stereo audio stream in an output
MP4, from an input file containing a stereo audio stream (and a video stream), with the use of a
single IngestInputStream.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH_STEREO_SOUND` ([?](#HTTP_INPUT_FILE_PATH_STEREO_SOUND))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

#### Simple Handling - Distinct Input Files

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/AudioManipulations/SimpleHandlingDistinctInputFiles.cs"">C#</a> -
<a href=""java/src/main/java/AudioManipulations/SimpleHandling_DistinctInputFiles.java"">Java</a> -
<a href=""javascript/src/AudioManipulations/SimpleHandlingDistinctInputFiles.ts"">TS/JS</a> -
<a href=""php/src/AudioManipulations/SimpleHandling_DistinctInputFiles.php"">PHP</a> -
<a href=""python/src/audio_manipulations/simple_handling_distinct_input_files.py"">Python</a>

This example demonstrates how to combine and map audio streams from multiple input files into a
single output MP4 file with multiple audio streams/tracks, with multiple IngestInputStreams.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH` ([?](#HTTP_INPUT_FILE_PATH))
+ `HTTP_INPUT_FILE_PATH_STEREO_SOUND` ([?](#HTTP_INPUT_FILE_PATH_STEREO_SOUND))
+ `HTTP_INPUT_FILE_PATH_SURROUND_SOUND` ([?](#HTTP_INPUT_FILE_PATH_SURROUND_SOUND))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

#### Channel Mixing - Swapping Channels

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/AudioManipulations/ChannelMixingSwappingChannels.cs"">C#</a> -
<a href=""java/src/main/java/AudioManipulations/ChannelMixing_SwappingChannels.java"">Java</a> -
<a href=""javascript/src/AudioManipulations/ChannelMixingSwappingChannels.ts"">TS/JS</a> -
<a href=""php/src/AudioManipulations/ChannelMixing_SwappingChannels.php"">PHP</a> -
<a href=""python/src/audio_manipulations/channel_mixing_swapping_channels.py"">Python</a>

This example demonstrates how to swap 2 audio channels from a stereo input, using a simple
AudioMixInputStream configuration.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH_STEREO_SOUND` ([?](#HTTP_INPUT_FILE_PATH_STEREO_SOUND))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

#### Channel Mixing - Downmixing

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/AudioManipulations/ChannelMixingDownmixing.cs"">C#</a> -
<a href=""java/src/main/java/AudioManipulations/ChannelMixing_Downmixing.java"">Java</a> -
<a href=""javascript/src/AudioManipulations/ChannelMixingDownmixing.ts"">TS/JS</a> -
<a href=""php/src/AudioManipulations/ChannelMixing_Downmixing.php"">PHP</a> -
<a href=""python/src/audio_manipulations/channel_mixing_downmixing.py"">Python</a>

This example demonstrates one mechanism to downmix a 5.1 stream down to 2.0.
It uses an advanced AudioMixInputStream configuration with gain adjusted on each input channel.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH_SURROUND_SOUND` ([?](#HTTP_INPUT_FILE_PATH_SURROUND_SOUND))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

#### Stream Mapping - Mono Input Tracks

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/AudioManipulations/StreamMappingMonoInputTracks.cs"">C#</a> -
<a href=""java/src/main/java/AudioManipulations/StreamMapping_MonoInputTracks.java"">Java</a> -
<a href=""javascript/src/AudioManipulations/StreamMappingMonoInputTracks.ts"">TS/JS</a> -
<a href=""php/src/AudioManipulations/StreamMapping_MonoInputTracks.php"">PHP</a> -
<a href=""python/src/audio_manipulations/stream_mapping_mono_input_tracks.py"">Python</a>

This example demonstrates one mechanism to create single output tracks from multiple mono input
tracks, using multiple IngestInputStreams (by position in the source),
and mapping them to output channels (by type).

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH_MULTIPLE_MONO_AUDIO_TRACKS` ([?](#HTTP_INPUT_FILE_PATH_MULTIPLE_MONO_AUDIO_TRACKS))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

#### Stream Merging - Background Audio

<a href=""dotnet/Bitmovin.Api.Sdk.Examples/AudioManipulations/StreamMergingBackgroundAudio.cs"">C#</a> -
<a href=""java/src/main/java/AudioManipulations/StreamMerging_BackgroundAudio.java"">Java</a> -
<a href=""javascript/src/AudioManipulations/StreamMergingBackgroundAudio.ts"">TS/JS</a> -
<a href=""php/src/AudioManipulations/StreamMerging_BackgroundAudio.php"">PHP</a> -
<a href=""python/src/audio_manipulations/stream_merging_background_audio.py"">Python</a>

This example demonstrates how to merge multiple stereo streams (from a single file, but this can
easily be extended to select them from separate input files), adjusting gain on the second stream
to turn it into a background effect.

Required configuration parameters:
+ `BITMOVIN_API_KEY` ([?](#BITMOVIN_API_KEY))
+ `BITMOVIN_TENANT_ORG_ID` ([?](#BITMOVIN_TENANT_ORG_ID))
+ `HTTP_INPUT_HOST` ([?](#HTTP_INPUT_HOST))
+ `HTTP_INPUT_FILE_PATH_TWO_STEREO_TRACKS` ([?](#HTTP_INPUT_FILE_PATH_TWO_STEREO_TRACKS))
+ `S3_OUTPUT_BUCKET_NAME` ([?](#S3_OUTPUT_BUCKET_NAME))
+ `S3_OUTPUT_ACCESS_KEY` ([?](#S3_OUTPUT_ACCESS_KEY))
+ `S3_OUTPUT_SECRET_KEY` ([?](#S3_OUTPUT_SECRET_KEY))
+ `S3_OUTPUT_BASE_PATH` ([?](#S3_OUTPUT_BASE_PATH))

## Configuration Parameters

These are the parameters that need to be supplied for the examples to work.
They can be defined in a file, set as environment variables or passed directly to the `run-example` script.

**Note!** See the `README.md` of the API SDK examples in your preferred programming language on how to configure parameters.

<a name=""BITMOVIN_API_KEY"">**`BITMOVIN_API_KEY`**</a> - Your API key for the Bitmovin API

<a name=""BITMOVIN_TENANT_ORG_ID"">**`BITMOVIN_TENANT_ORG_ID`**</a> - The ID of the Organisation in which you want to perform the encoding. Only required if working with a multi-tenant account.

<a name=""HTTP_INPUT_HOST"">**`HTTP_INPUT_HOST`**</a> - The Hostname or IP address of the HTTP server hosting your input files
Example: `my-storage.biz`

<a name=""HTTP_INPUT_FILE_PATH"">**`HTTP_INPUT_FILE_PATH`**</a> - The path to your input file on the HTTP host
Example: `videos/1080p_Sintel.mp4`

<a name=""HTTP_INPUT_BUMPER_FILE_PATH"">**`HTTP_INPUT_BUMPER_FILE_PATH`**</a> - The path to your input file on the provided HTTP server to be concatenated before HTTP_INPUT_FILE_PATH
Example: `videos/bumper.mp4`

<a name=""HTTP_INPUT_PROMO_FILE_PATH"">**`HTTP_INPUT_PROMO_FILE_PATH`**</a> - The path to your input file on the provided HTTP server to be concatenated after HTTP_INPUT_FILE_PATH
Example: `videos/promo.mp4`

<a name=""HTTP_INPUT_AUDIO_FILE_PATH"">**`HTTP_INPUT_AUDIO_FILE_PATH`**</a> - The path to your audio input file on the provided HTTP server. It's used when you want to load audio stream from a separated input file.
Example: `audio/aac.mp4`

<a name=""HTTP_INPUT_DOLBY_VISION_METADATA_FILE_PATH"">**`HTTP_INPUT_DOLBY_VISION_METADATA_FILE_PATH`**</a> - The path to your DolbyVision metadata file. This parameter is required only when using a DolbyVision input file with a separated sidecar XML metadata file.

<a name=""HDR_CONVERSION_INPUT_FORMAT"">**`HDR_CONVERSION_INPUT_FORMAT`**</a> - The input dynamic range format. Either DolbyVision, HDR10, HLG, or SDR can be specified. This parameter needs to be matched with the actual dynamic range format of the input file.
Example: `DolbyVision`, `HDR10`, `HLG`, `SDR`.

<a name=""HDR_CONVERSION_OUTPUT_FORMAT"">**`HDR_CONVERSION_OUTPUT_FORMAT`**</a> - The output dynamic range format to be converted from the input file.
If the input dynamic range is `DolbyVision`, the supported output dynamic range format is either `DolbyVision`, `HDR10` or `SDR`.
If the input dynamic range is `HDR10`, the supported output dynamic range format is either `HDR10`, `HLG` or `SDR`.
If the input dynamic range is `HLG`, the supported output dynamic range format is either `HDR10`, `HLG` or `SDR`.
If the input dynamic range is `SDR`, the supported output dynamic range format is either `HDR10`, `HLG` or `SDR`.
Example: `DolbyVision`, `HDR10`, `HLG`, `SDR`.

<a name=""HTTP_INPUT_FILE_PATH_STEREO_SOUND"">**`HTTP_INPUT_FILE_PATH_STEREO_SOUND`**</a> - the path to a file containing a video with a single audio stereo stream
Example: `videos/1080p_Sintel_Stereo.mp4`

<a name=""HTTP_INPUT_FILE_PATH_SURROUND_SOUND"">**`HTTP_INPUT_FILE_PATH_SURROUND_SOUND`**</a> - the path and filename for a file containing a video with a 5.1 audio stream
Example: `videos/1080p_Sintel_Surround.mp4`

<a name=""HTTP_INPUT_FILE_PATH_MULTIPLE_MONO_AUDIO_TRACKS"">**`HTTP_INPUT_FILE_PATH_MULTIPLE_MONO_AUDIO_TRACKS`**</a> - the path to a file containing a video with multiple mono audio tracks
Example: `videos/1080p_Sintel_8_Mono_Audio_Tracks.mp4`

<a name=""HTTP_INPUT_FILE_PATH_TWO_STEREO_TRACKS"">**`HTTP_INPUT_FILE_PATH_TWO_STEREO_TRACKS`**</a> - the path to a file containing a video with 2 stereo tracks
Example: `videos/1080p_Sintel_Two_Stereos.mp4`

<a name=""S3_OUTPUT_BUCKET_NAME"">**`S3_OUTPUT_BUCKET_NAME`**</a> - The name of your S3 output bucket  
Example: `my-s3-bucket-name`

<a name=""S3_OUTPUT_ACCESS_KEY"">**`S3_OUTPUT_ACCESS_KEY`**</a> - The access key of your S3 output bucket  
Example: `AKIAIOSFODNN7EXAMPLE`

<a name=""S3_OUTPUT_SECRET_KEY"">**`S3_OUTPUT_SECRET_KEY`**</a> - The secret key of your S3 output bucket  
Example: `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY`

<a name=""S3_OUTPUT_BASE_PATH"">**`S3_OUTPUT_BASE_PATH`**</a> - The base path on your S3 output bucket where content will be written  
Example: `/outputs`

<a name=""WATERMARK_IMAGE_PATH"">**`WATERMARK_IMAGE_PATH`**</a> - The path to the watermark image  
Example: `http://my-storage.biz/logo.png`

<a name=""TEXT_FILTER_TEXT"">**`TEXT_FILTER_TEXT`**</a> - The text to be displayed by the text filter

<a name=""DRM_KEY"">**`DRM_KEY`**</a> - 16 byte encryption key, represented as 32 hexadecimal characters  
Example: `cab5b529ae28d5cc5e3e7bc3fd4a544d`

<a name=""DRM_FAIRPLAY_IV"">**`DRM_FAIRPLAY_IV`**</a> - 16 byte initialization vector, represented as 32 hexadecimal characters  
Example: `08eecef4b026deec395234d94218273d`

<a name=""DRM_FAIRPLAY_URI"">**`DRM_FAIRPLAY_URI`**</a> - URI of the licensing server  
Example: `skd://userspecifc?custom=information`

<a name=""DRM_WIDEVINE_KID"">**`DRM_WIDEVINE_KID`**</a> - 16 byte encryption key id, represented as 32 hexadecimal characters  
Example: `08eecef4b026deec395234d94218273d`

<a name=""DRM_WIDEVINE_PSSH"">**`DRM_WIDEVINE_PSSH`**</a> - Base64 encoded PSSH payload  
Example: `QWRvYmVhc2Rmc2FkZmFzZg==`

<a name=""DRM_CONTENT_ID"">**`DRM_CONTENT_ID`**</a> - An optional content ID used to register the DRM keys with the SPEKE provider   
Example: `my-content-id`

<a name=""DRM_KEY_ID"">**`DRM_KEY_ID`**</a> - An optional 16-byte hex key ID used to refer to a key stored in the DRM provider system (in particular with SPEKE)   
Example: `d94238436e2fe421a27a7d5dd3d26f31`

<a name=""SPEKE_URL"">**`SPEKE_URL`**</a> - The URL of the SPEKE server  
Example: `https://my-speke-server.com/v1.0/vod`

<a name=""SPEKE_ARN"">**`SPEKE_ARN`**</a> - For AWS IAM authentication, the role ARN for the user providing access to the SPEKE server  
Example: `arn:aws:iam::1234567890:role/speke_role_assumption`

<a name=""SPEKE_GATEWAY_REGION"">**`SPEKE_GATEWAY_REGION`**</a> - For AWS IAM authentication, the AWS Gateway region hosting the SPEKE server   
Example: `eu-west-1`

<a name=""SPEKE_USERNAME"">**`SPEKE_USERNAME`**</a> - For basic authentication with the SPEKE server

<a name=""SPEKE_PASSWORD"">**`SPEKE_PASSWORD`**</a> - For basic authentication with the SPEKE server

You may also add your own parameters in your configuration. The ConfigProvider class in each example offers a generic function to get the value of the parameter by its name.
"
cincheo/jsweet-examples,master,36,18,2015-11-10T11:04:33Z,785,9,A set of simple examples to show what can be done with the JSweet transpiler (Java to JavaScript),,"# JSweet examples [![](https://github.com/cincheo/jsweet-examples/workflows/Build%20examples%20with%20Gradle/badge.svg)](https://github.com/cincheo/jsweet-examples/actions)

A set of simple examples to show what can be done in Java with the [JSweet transpiler](https://github.com/cincheo/jsweet).

All these example are written in Java using the JSweet APIs (candies)] They are then transpiled to JavaScript by the JSweet transpiler.

- Simple canvas drawing (`canvasdrawing`): demonstrates the use of HTML5 canvas. [browse](http://examples.jsweet.org/jsweet-examples/webapp/canvasdrawing/index.html)
- Simple HTML form control (`inputcontrol`): demonstrates the use of HTML5 forms and inputs. [browse](http://examples.jsweet.org/jsweet-examples/webapp/inputcontrol/index.html)
- Simple jQuery (`jquery`): demonstrates the use of JQuery with JSweet. [browse](http://examples.jsweet.org/jsweet-examples/webapp/jquery/index.html)
- Simple Angular (`angularjs`): demonstrates the use of Angular with JSweet. [browse](http://examples.jsweet.org/jsweet-examples/webapp/angularjs/index.html)
- Simple Knockout (`knockoutjs`): demonstrates the use of Knockout with JSweet. [browse](http://examples.jsweet.org/jsweet-examples/webapp/knockoutjs/index.html)
- Ray tracer (`raytracer`): draws a 3D scene, adapted from the TypeScript example page. [browse](http://examples.jsweet.org/jsweet-examples/webapp/raytracer/index.html)
- Todos (`todomvc`): demonstrates the use of Backbone and Underscore with JSweet, adapted from the TypeScript example page. [browse](http://examples.jsweet.org/jsweet-examples/webapp/todomvc/index.html)
- Blocks game (`blocksgame`): demonstrates how to write an HTML5 mobile game with JSweet. [browse](http://examples.jsweet.org/jsweet-examples/webapp/blocksgame/index.html)
- Promises (`promises`): demonstrates the use of the latest EcmaScript6 Promise API. [browse](http://examples.jsweet.org/jsweet-examples/webapp/promises/index.html)

Visit the live JSweet's example page (http://www.jsweet.org/examples) to browse the examples, run them and debug the Java code within your favorite browser. Note that all these examples are responsive and should work as well on a Web browser and on a mobile.

Visit also https://github.com/cincheo/jsweet-examples-threejs for some examples using the Threejs framework (WebGL-powered 3D)]

## Usage

```
> git clone https://github.com/cincheo/jsweet-examples.git
> cd jsweet-examples
```

### Build with Gradle
```
./gradlew jsweetClean jsweet (--refresh-dependencies) (--info)
```
### Build with Maven
```
mvn clean generate-sources
```
### Build with Ant
```
ant
```

### Run in your favorite browser
```
> firefox webapp/${example-name}/index.html
```

## Prerequisites

The `node` and `npm` executables must be in the path (https://nodejs.org)]
Install Maven (https://maven.apache.org/install.html)]
"
atduskgreg/Processing-Shader-Examples,master,92,15,2011-06-26T23:05:34Z,620,0,Experiments working with shaders in Processing. Click the link below for formatted notes.,,
ramalho/python-patterns-examples,master,88,15,2015-08-12T21:49:12Z,424,1,A collection of Design Patters implemented in Python,,"# python-patterns-examples
A collection of Design Patters imlemented in Python
"
aalmiray/javatrove,master,73,36,2016-07-06T10:06:02Z,865,1,Code examples for The Java Trove series,,
Hemant-Jain-Author/Problem-Solving-in-Data-Structures-Algorithms-using-Java,master,111,76,2018-03-10T18:32:02Z,826,0,Code examples of Problem Solving in Data Structures and Algorithms using Java,,"# Problem-Solving-in-Data-Structures-Algorithms-using-Java

**This is the code repository of book ""Problem Solving in Data Structures & Algorithms Using Java"".**

![alt text](https://m.media-amazon.com/images/I/41eQl-YMyfL.jpg)


**About The Book**
- This textbook provides in depth coverage of various Data Structures and Algorithms.
- Concepts are discussed in easy to understand manner.
- Large number of diagrams are provided to grasp concepts easily.
- Time and Space complexities of various algorithms are discussed.
- Helpful for interviews preparation and competitive coding. 
- Large number of interview questions are solved.
- Java solutions are provided with input and output. 
- Guide you through how to solve new problems in programming interview of various software companies.


**Table of Contents**
- Chapter 0: How to use this book.
- Chapter 1: Algorithms Analysis
- Chapter 2: Approach to solve algorithm design problems
- Chapter 3: Abstract Data Type & JAVA Collections
- Chapter 4: Searching
- Chapter 5: Sorting
- Chapter 6: Linked List
- Chapter 7: Stack
- Chapter 8: Queue
- Chapter 9: Tree
- Chapter 10: Priority Queue
- Chapter 11: Hash-Table
- Chapter 12: Graphs
- Chapter 13: String Algorithms
- Chapter 14: Algorithm Design Techniques
- Chapter 15: Brute Force Algorithm
- Chapter 16: Greedy Algorithm
- Chapter 17: Divide & Conquer
- Chapter 18: Dynamic Programming
- Chapter 19: Backtracking
- Chapter 20: Complexity Theory
"
4xes/FlipAnimation,master,370,61,2016-09-14T11:10:01Z,1090,1,Simple example for flip animation,,"### Simple flip animation demo.

<img src=""/art/readme_demo.gif?raw=true"" width=360 height=640 alt=""Quick Demo"">"
eventuate-tram/eventuate-tram-examples-customers-and-orders-redis,master,52,42,2019-03-22T18:02:34Z,296,5,"Microservices, Choreography-based saga, CQRS and Redis!",,
matsim-org/matsim-example-project,master,114,895,2015-09-28T12:44:19Z,194,2,A small example of how to use MATSim as a library.,,"# matsim-example-project

A small example of how to use MATSim as a library.

By default, this project uses the latest (pre-)release. In order to use a different version, edit `pom.xml`.

A recommended directory structure is as follows:
* `src` for sources
* `original-input-data` for original input data (typically not in MATSim format)
* `scenarios` for MATSim scenarios, i.e. MATSim input and output data.  A good way is the following:
  * One subdirectory for each scenario, e.g. `scenarios/mySpecialScenario01`.
  * This minimally contains a config file, a network file, and a population file.
  * Output goes one level down, e.g. `scenarios/mySpecialScenario01/output-from-a-good-run/...`.
  
  
### Import into eclipse

1. download a modern version of eclipse. This should have maven and git included by default.
1. `file->import->git->projects from git->clone URI` and clone as specified above.  _It will go through a 
sequence of windows; it is important that you import as 'general project'._
1. `file->import->maven->existing maven projects`

Sometimes, step 3 does not work, in particular after previously failed attempts.  Sometimes, it is possible to
right-click to `configure->convert to maven project`.  If that fails, the best thing seems to remove all 
pieces of the failed attempt in the directory and start over.

### Import into IntelliJ

`File -> New -> Project from Version Control` paste the repository url and hit 'clone'. IntelliJ usually figures out
that the project is a maven project. If not: `Right click on pom.xml -> import as maven project`.

### Java Version

The project uses Java 11. Usually a suitable SDK is packaged within IntelliJ or Eclipse. Otherwise, one must install a 
suitable sdk manually, which is available [here](https://openjdk.java.net/)

### Building and Running it locally

You can build an executable jar-file by executing the following command:

```sh
./mvnw clean package
```

or on Windows:

```sh
mvnw.cmd clean package
```

This will download all necessary dependencies (it might take a while the first time it is run) and create a file `matsim-example-project-0.0.1-SNAPSHOT.jar` in the top directory. This jar-file can either be double-clicked to start the MATSim GUI, or executed with Java on the command line:

```sh
java -jar matsim-example-project-0.0.1-SNAPSHOT.jar
```



### Licenses
(The following paragraphs need to be adjusted according to the specifications of your project.)

The **MATSim program code** in this repository is distributed under the terms of the [GNU General Public License as published by the Free Software Foundation (version 2)](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html). The MATSim program code are files that reside in the `src` directory hierarchy and typically end with `*.java`.

The **MATSim input files, output files, analysis data and visualizations** are licensed under a <a rel=""license"" href=""http://creativecommons.org/licenses/by/4.0/"">Creative Commons Attribution 4.0 International License</a>.
<a rel=""license"" href=""http://creativecommons.org/licenses/by/4.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by/4.0/80x15.png"" /></a><br /> MATSim input files are those that are used as input to run MATSim. They often, but not always, have a header pointing to matsim.org. They typically reside in the `scenarios` directory hierarchy. MATSim output files, analysis data, and visualizations are files generated by MATSim runs, or by postprocessing.  They typically reside in a directory hierarchy starting with `output`.

**Other data files**, in particular in `original-input-data`, have their own individual licenses that need to be individually clarified with the copyright holders.


"
sujee/hbase-mapreduce,master,49,30,2010-04-09T17:24:46Z,349,3,map reduce examples on HBaase,,
puniverse/comsat-examples,master,48,15,2014-01-21T20:07:45Z,16272,2,Comsat Examples,,"# COMSAT Examples

This project includes some examples that makes use of an embedded Jetty servers and several others that are packaged into WAR files and can be deployed to servlet containers.

## Running the Jetty examples

In the shell:

```sh
gradle :comsat-examples-embeddedjetty:run
```

A Jetty web actors example can be run with:

```sh
gradle :comsat-examples-jetty-webactor:run
```

A Dropwizard example can be run with:

```sh
gradle :comsat-examples-dropwizard:runSimple
```

## Non-web examples

```sh
gradle :comsat-examples-db:runSimple
gradle :comsat-examples-retrofit:runSimple
```

## Running the WAR examples

For convenience, we've included a tiny program (`embedded-tomcat`) that runs a Tomcat server, creates a database, and compiles and deploys all WAR examples.

In the shell, type:

```sh
gradle :embedded-tomcat:run
```

Then, in a web browser, access any of the following links:

* [http://localhost:8080/comsat-examples-servlet/fiberservlet](http://localhost:8080/comsat-examples-servlet/fiberservlet) - a servlet that runs in a fiber.
* [http://localhost:8080/comsat-examples-jaxrs/rest/myresource](http://localhost:8080/comsat-examples-jaxrs/rest/myresource) - a JAX-RS REST service that runs in a fiber (the first time this is accessed, it will take a while as Jersey is initialized).
* [http://localhost:8080/comsat-examples-webactors/webactor](http://localhost:8080/comsat-examples-webactors/webactor) - a WebActors example

### Hot Code Swapping

1. Open an new shell and build the upgrade module:

```sh
gradle :comsat-examples-webactors-codeswap:jar
```

2. Run and access [http://localhost:8080/comsat-examples-webactors/webactor](http://localhost:8080/comsat-examples-webactors/webactor) as explained above. 

3. Copy the upgrade module jar file into the `modules/` directory:

```sh
cp comsat-examples-webactors-codeswap/build/libs/comsat-examples-webactors-codeswap.jar modules
```

You will now see the new actor behave differently in the test web page.

## Running Spaceships

Stop the server if running and uncomment the following line in `embedded-tomcat/build.gradle`:

```
from project("":comsat-examples-spaceships"").war
```

Restart the server with:

```sh
gradle :embedded-tomcat:run
```

Then, open [http://localhost:8080/comsat-examples-spaceships/login](http://localhost:8080/comsat-examples-spaceships/login) in your browser.

## License

These examples are released under the [MIT license](http://opensource.org/licenses/MIT).

Copyright (c) 2014-2015 Parallel Universe
"
juneau001/GenericsExamples,master,31,18,2014-07-07T12:01:11Z,144,1,,,
bibryam/camel-message-routing-examples,master,45,22,2013-08-03T21:35:35Z,164,0,Instant Apache Camel Message Routing Examples,,"### Instant Apache Camel Message Routing Examples

Creating a Camel project  
Routing messages to different destinations  
Using components  
Connecting routes  
Removing unwanted messages  
Transforming messages  
Splitting a message into many  
Aggregating multiple messages into one  
Reorganizing messages  
Multicasting messages  
Error handling and monitoring  
Testing messaging applications  

#### Run the examples with: mvn test
"
s4/examples,master,50,4,2010-11-03T14:25:53Z,2331,1,Example applications,,"S4 Example Applications
=======================

This is a set of example applications using S4. To build and deploy an example

1. Read the example's README file for build instructions
2. Refer to the [Getting Started](http://wiki.s4.io/Tutorials/GettingStarted) wiki for instructions on how to deploy and run the application

Realtime Twitter Topic Count
----------------------------

This application detects popular hashtags on Twitter by listening to the
Twitter gardenhose.

Build instructions: twittertopiccount/README.md
"
eventuate-tram/eventuate-tram-core-examples-basic,master,38,31,2017-07-30T04:20:29Z,299,12,Basic examples for Eventuate Tram,,
yandex-qatools/htmlelements-examples,master,27,19,2013-05-06T10:11:34Z,189,3,Getting started examples for HtmlElements framework on java,,"## HtmlElements Examples
You can find some examples in *test* dir of modules: 

### HtmlElements Thucydides Example
[Examples of thucydides + HtmlElements](https://github.com/yandex-qatools/htmlelements-examples/tree/master/htmlelements-thucydides-example/src/test/java/my/company/web)

### HtmlElements JUnit Example
[Getting Started (RU)](https://github.com/yandex-qatools/htmlelements-examples/blob/master/htmlelements-junit-example/src/site/junit-example.md)

[Examples of simple JUnit + HtmlElements source](https://github.com/yandex-qatools/htmlelements-examples/blob/master/htmlelements-junit-example/src/test/java/my/company/web/)
"
douglascraigschmidt/CS892,master,70,128,2014-08-10T13:15:10Z,11989,1,This contains the source code examples and programming assignments for my CS 282 class,,
little-hands/ddd-examples,master,140,9,2020-03-02T20:50:43Z,191,0,,,"# ddd-examples
DDDのサンプルコードを掲載しています

## パッケージ構成
* com.littlehands
  * task_management: シンプルなDDD事例として、タスク管理のサンプルコードです
  * aggregate: 集約のサンプルコードです
"
joinfaces/joinfaces-maven-jar-example,5.3.x,79,75,2016-05-12T12:02:29Z,3061,14, JoinFaces Maven Jar Example,angularfaces bootsfaces butterfaces jetty joinfaces jsf mojarra myfaces primefaces spring-boot tomcat undertow,"JoinFaces Example
=====
[![Build Status](https://github.com/joinfaces/joinfaces-maven-jar-example/actions/workflows/maven.yml/badge.svg)](https://github.com/joinfaces/joinfaces-maven-jar-example/actions)
[![Codecov](https://codecov.io/gh/joinfaces/joinfaces-maven-jar-example/branch/4.7.x/graph/badge.svg)](https://codecov.io/gh/joinfaces/joinfaces-maven-jar-example)
[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=joinfaces_joinfaces-maven-jar-example&metric=bugs)](https://sonarcloud.io/dashboard?id=joinfaces_joinfaces-maven-jar-example)
[![License](http://img.shields.io/:license-apache-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

This SAP (Single Page Application) illustrates JSF usage inside JAR packaged Spring Boot Application.

[JoinFaces](https://joinfaces.org) autoconfigures 
[PrimeFaces](https://primefaces.org/), 
[PrimeFaces Extensions](https://primefaces-extensions.github.io/), 
[Apache MyFaces Tobago](https://github.com/apache/myfaces-tobago), 
[OmniFaces](https://omnifaces.org/), 
[AdminFaces](https://adminfaces.github.io/site/), 
[Mojarra](https://eclipse-ee4j.github.io/mojarra/) and 
[MyFaces](http://myfaces.apache.org) libraries to run at embedded 
[Tomcat](https://tomcat.apache.org/), 
[Jetty](https://www.eclipse.org/jetty) or 
[Undertow](https://undertow.io/). 
It autoconfigures [Weld](https://weld.cdi-spec.org),
[Apache OpenWebBeans](https://openwebbeans.apache.org/) and
[Rewrite](https://www.ocpsoft.org/rewrite/) too.

## Run Example Application locally

1- Clone this project
```Shell
git clone https://github.com/joinfaces/joinfaces-maven-jar-example.git
```

2- Build
```Shell
mvn clean install
```

3- Run
```Shell
java -jar target/joinfaces-example-5.3.x.jar
```

4- Access starter page at **http://localhost:8080/** This page can help you to choose the JoinFaces Starter that fits your needs. You may log in with credentials

| User       | Password | Roles      |
|------------|----------|------------|
| persapiens | 123      | ROLE_ADMIN |
| nyilmaz    | qwe      | ROLE_USER  |

Optional: If your IDE is showing build errors install [Lombok](https://projectlombok.org/setup/overview)

## Key Files

### pom.xml

Includes joinfaces starter dependency. All other jsf dependencies are included transitively.

```xml
<properties>
   <joinfaces.version>5.3.0-m3</joinfaces.version>
</properties>

<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.joinfaces</groupId>
            <artifactId>joinfaces-bom</artifactId>
            <version>${joinfaces.version}</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>

<dependencies>
  <dependency>
    <groupId>org.joinfaces</groupId>
    <artifactId>faces-spring-boot-starter</artifactId>
  </dependency>
</dependencies>
```

Note that **security-spring-boot-starter** is included to secure the application.

```xml
<dependencies>
    <dependency>
        <groupId>org.joinfaces</groupId>
        <artifactId>security-spring-boot-starter</artifactId>
    </dependency>
</dependencies>
```

### src/main/resources/application.yml

Configure faces.PROJECT_STATE and faces.primefaces.THEME properties.

```yml
joinfaces:
  faces:
    PROJECT_STAGE: Development
  primefaces: 
    theme: overcast
```

### src/main/resources/META-INF/resources/content/starter.xhtml

Example page to help you choose the right JoinFaces Starter for you. 

Note that xhtml, js, css and images files should be located at **src/main/resources/META-INF/resources** directory to JSF use them.

Look at **authorize** and **anonymous** jsf spring security facelet tags in action to secure page information.

```xhtml
  <sec:authorize access=""hasRole('ROLE_ADMIN')"">
    <p:panelGrid columns=""1"" rendered=""#{sec:isFullyAuthenticated()}"">
      <p:link title=""Logout"" href=""/logout"">
        <p:outputLabel value=""You are logged in as an ADMIN"" />
      </p:link>
    </p:panelGrid>
  </sec:authorize>
```

### src/main/java/org/joinfaces/example/JoinFacesExampleApplication.java

Very simple spring main application. Only SpringBootApplication annotation is required.

<pre>
@SpringBootApplication
public class JoinFacesExampleApplication {
</pre>

### src/main/java/org/joinfaces/example/SecurityConfig.java

Spring Security configuration class to secure authentication with credentials to persapiens and nyilmaz users.

### src/main/java/org/joinfaces/example/view/StarterMBean.java

Managed bean using ViewScoped CDI annotation. The equivalent spring scope of ViewScoped annotation is configured automatically by JoinFaces Starter.

<pre>
@Named
<b>@ViewScoped</b>
public class StarterMBean {
</pre>

## Getting Help

* Take a look at [JoinFaces Wiki](https://github.com/joinfaces/joinfaces/wiki).
* Report questions and bugs at [github.com/joinfaces/joinfaces-example/issues](https://github.com/joinfaces/joinfaces-maven-jar-example/issues).

## Contributing

* Report documentation, features, enhancement and bugs at [github.com/joinfaces/joinfaces-example/issues](https://github.com/joinfaces/joinfaces-maven-jar-example/issues).
* Pull requests are welcome.
"
graalvm/simplelanguage,master,590,193,2015-04-30T22:58:08Z,1445,31,A simple example language built using the Truffle API.,,"# SimpleLanguage

A simple demonstration language built using Truffle for GraalVM.

SimpleLanguage is heavily documented to explain the how and why of writing a
Truffle language. A good way to find out more is to read the source with
comments. Start reading [here](https://github.com/graalvm/simplelanguage/blob/master/language/src/main/java/com/oracle/truffle/sl/SLLanguage.java).
We also like to encourage people to clone the repository and start hacking.

This repository is licensed under the permissive UPL licence. Fork it to begin
your own Truffle language.

For instructions on how to get started please refer to [our website](http://www.graalvm.org/docs/graalvm-as-a-platform/implement-language/)

# Building for a JVM

Build the project with `mvn package`.
To run simple language using a JDK from JAVA_HOME run `./sl`.

# Building a Native Image

Build the project with `mvn package -Pnative`.
To run simple language natively run `./standalone/target/slnative`.
"
graalvm/fastr-examples,master,58,15,2016-10-24T18:19:30Z,379,7,,,"# GraalVM Examples

A collection of examples and use-cases for the GraalVM and FastR.

[GraalVM](http://graalvm.org) is a universal virtual machine for running applications written in JavaScript, 
Python 3, Ruby, R, JVM-based languages like Java, Scala, Kotlin, and LLVM-based languages 
such as C and C++.

FastR is a GraalVM based implementation of the R programming language, that provides significant improvements in the performance of R code,
the embedding of the R execution engine into Java applications, and the ability to interface with other GraalVM and JVM languages including Python, Java, and Scala. 
FastR is also able to utilize the [tooling support](https://medium.com/graalvm/analyzing-the-heap-of-graalvm-polyglot-applications-b9963e68a6a) provided by the
[GraalVM ecosystem](https://medium.com/graalvm/graalvm-ten-things-12d9111f307d).

* [FastR Java UI](./fastr_javaui/README.md) is a Java based Swing desktop UI application showing visualization interactively generated an by R script.
* [rJava Benchmark](./r_java_bench) shows how fast rJava can be on FastR (spoiler: orders of magnitude faster).
* [FastR Embedding](./r_java_embedding) show how to embed FastR into Java applications and pass Java objects to R scripts like if they were native R objects (e.g. R data frame).
* [Weather Predictor](./weather_predictor/README.md) is an application that performs temperature prediction using Ruby, R and Node.js.
* [FastR Scalar](./fastr_scalar/README.md) is a simple, straightforward implementation of ""Conway's Game of Life"" written in R.
* [Node.js & FastR](./fastr_node/README.md) is a Node.js web server showing visualization computed and generated in FastR.

## Setup

In order to run the examples, the latest GraalVM must be installed.
It can be downloaded from the [GraalVM homepage](http://www.graalvm.org/downloads/).
The examples work on both the Community and Enterprise edition of GraalVM.

Once downloaded, extract the archive, set the `GRAALVM_DIR` environment variable to point to the graalvm directory, 
and install additional languages using [`./install_components.sh`](install_components.sh).

## Further information

* [GraalVM homepage](http://graalvm.org)
* [FastR reference manual](http://www.graalvm.org/docs/reference-manual/languages/r/)
* [FastR on Github](https://github.com/oracle/fastr)

## License

All the examples are licensed under the [GPLv3 license](https://www.gnu.org/licenses/gpl-3.0).

## Troubleshooting

A typical problem is proxy set-up: verify that you have the `http_proxy`, `https_proxy`, and `no_proxy` environment variables set properly.


"
CuteXiaoKe/iText7-examples,master,69,18,2018-04-11T07:33:48Z,17290,2,iText7官网系列教程的样例，持续更新，并且自己有博客介绍程序,,"# iText7-examples

## 介绍

&nbsp;&nbsp;&nbsp;&nbsp;iText7官网上有三本电子书的，目前已翻译完成：  

1. 《iText 7 Jump-Start Tutorial》
2. 《iText 7: Building Blocks》
3. 《iText 7: Converting HTML to PDF with pdfHTML》  

&nbsp;&nbsp;&nbsp;&nbsp;访问我的[CSDN博客](https://blog.csdn.net/u012397189)，CSDN上面有专栏，[iText学习笔记](https://blog.csdn.net/u012397189/category_9270695.html
)对应第一本书的内容，还有一些自己的一些见解。

&nbsp;&nbsp;&nbsp;&nbsp;目前正在整理和翻译《Digital Signatures for PDF documents》,这本书是itext5版本的，正在转换成iText7版本。

&nbsp;&nbsp;&nbsp;&nbsp;还有收集网友问题、系统整理iText相关资料，自己总结。


## 系列文章

&nbsp;&nbsp;&nbsp;&nbsp;《iText 7 Jump-Start Tutorial》的翻译文章：

0. 系列导读，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/52161418) | [知乎](https://zhuanlan.zhihu.com/p/375104044)
1. 第一章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/52161461) | [知乎](https://zhuanlan.zhihu.com/p/375109293) | [公众号](https://mp.weixin.qq.com/s/O7B6o_9bnvcsEaqBLmtlWA)  代码实践：[CSDN
博客](https://blog.csdn.net/u012397189/article/details/74926755) 
2. 第二章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/76726576) | [知乎](https://zhuanlan.zhihu.com/p/393654915) | [公众号](https://mp.weixin.qq.com/s/83IKa_Vr32Wy2K2tq_VjAA)  代码实践：[CSDN
博客](https://blog.csdn.net/u012397189/article/details/77119609) 
3. 第三章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/77540464) | [知乎](https://zhuanlan.zhihu.com/p/397083648) | [公众号](https://mp.weixin.qq.com/s/d3T97V6jUV7cox4aeZ7MAQ)  代码实践：[CSDN
博客](https://blog.csdn.net/u012397189/article/details/77541052)
4. 第四章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/77942866) | [知乎](https://zhuanlan.zhihu.com/p/462476906) | [公众号](https://mp.weixin.qq.com/s/tEU1UoVSHmWOvzcaq-9L1A)   代码实践：[CSDN博客](https://blog.csdn.net/u012397189/article/details/77945763) 
5. 第五章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/78558619) | [知乎](https://zhuanlan.zhihu.com/p/481364611) | [公众号](https://mp.weixin.qq.com/s/RIHeJQMqxyT9BSz2UUvbRQ)   代码实践：[CSDN博客](https://blog.csdn.net/u012397189/article/details/78559277) 
6. 第六章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/78742207) | [知乎](https://zhuanlan.zhihu.com/p/586693000)   代码实践：[CSDN博客](https://blog.csdn.net/u012397189/article/details/78745027)
7. 第七章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/78882454) | [知乎](https://zhuanlan.zhihu.com/p/587443224)   代码实践：[CSDN博客](https://blog.csdn.net/u012397189/article/details/78885790)

&nbsp;&nbsp;&nbsp;&nbsp;《iText 7: Building Blocks》的翻译文章：

0. 系列导读，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/79834501) 
1. 第一章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/79888252)  代码实践:[CSDN博客](https://blog.csdn.net/u012397189/article/details/79915660)
2. 第二章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/91346951)
3. 第三章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/117649650)
4. 第四章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/125724156)
5. 第五章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/126345744)
6. 第六章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/126645769)
7. 第七章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/126837712)

&nbsp;&nbsp;&nbsp;&nbsp;《iText 7: Converting HTML to PDF with pdfHTML》的翻译文章

1. 第一章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/127058001)
2. 第二章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/127150134)
3. 第三章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/127394654)
4. 第四章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/127683350)
5. 第五章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/127976075)
6. 第六章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/128039175)
7. 第七章，文章地址：[CSDN博客](https://blog.csdn.net/u012397189/article/details/128136342)

## 目录结构

&nbsp;&nbsp;&nbsp;&nbsp;iText-start文件夹对应《iText 7 Jump-Start Tutorial》，《iText 7: Building Blocks》源码请查阅[官方源码](https://github.com/itext/i7js-highlevel)，《iText 7: Converting
 HTML to
 PDF with
 pdfHTML》请查阅[官方源码](https://github.com/itext/i7js-examples)，里面每一目录都是IDEA工程，采用maven构建项目
 
 &nbsp;&nbsp;&nbsp;&nbsp;或者直接点击[微信文章](https://mp.weixin.qq.com/s/wCcyLlLqOhay00lzuSsEUg)下载代码资源

## 运行

&nbsp;&nbsp;&nbsp;&nbsp;使用IDE打开工程，maven构建项目即可。

## 微信公众号

&nbsp;&nbsp;&nbsp;&nbsp;欢迎关注我的微信公众号：CuteXiaoKe，里面有最新的pdf相关知识和资源。

![微信公众号](http://oss.cuteke.cn/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7.png)

## LICENSE

&nbsp;&nbsp;&nbsp;&nbsp;本项目遵循iText7的APGL协议。"
fishpro/spring-boot-study,master,288,225,2019-07-10T12:55:52Z,491,12,about learning Spring Boot via examples. 基于 spring boot 2.x 的学习教程简洁易懂,shiro spring spring-boot spring-boot-examples spring-boot-jwt spring-boot-mybatis spring-boot-redis spring-boot-security spring-boot-shiro spring-boot-upload-file spring-boot-webservice spring-jpa thymeleaf xmldom4j,"最近上来看了下，还有兄弟在看这个教程，不胜荣幸，我最近上 github 的实际不多，有问题请加微信号 fishpro 或 QQ 502086
# 为什么要写 Spring Boot 系列文章

好记性不如烂笔头，学习 Spring Boot 一定要自己多练练，并能够把他记录下来，当有需要的时候，可以查看自己编写功能教程，能够很快获取相关代码，使用到项目中。

本系列文章是针对 Spring Boot 各个知识点实战训练的笔记，所有代码都经过测试获取正确的结果。并且不断的添加到本系列中。

本教程适用 Spring Boot 2.x 版本，当有代码对 Spring Boot 版本有特别要求的时候的时候，示例说明中有特别说明。

**喜欢的给个 star 呗**

# Spring Boot 知识图谱-入门教程目录

本系列文章一般都是一个知识点一个独立的项目源码，综合应用可能包含多个知识点，比如动态数据源切换技术本身包括 Aop、注解、数据库访问、连接池。

![Spring Boot 2.0](https://img.shields.io/badge/Spring%20Boot-2.0-brightgreen.svg)
![Mysql 5.6](https://img.shields.io/badge/Mysql-5.6-blue.svg)
![JDK 1.8](https://img.shields.io/badge/JDK-1.8-brightgreen.svg)
![Maven](https://img.shields.io/badge/Maven-3.5.0-yellowgreen.svg)
![license](https://img.shields.io/badge/license-MPL--2.0-blue.svg)

## 了解 Spring Boot
- [Spring Boot 入门前的准备-Java JDK for window mac 安装](https://www.cnblogs.com/fishpro/p/spring-knowledge-graph-1-window-mac-install-jdk.html)
- [Spring Boot 入门前的准备-IntelliJ IDEA 开发工具的安装与使用](https://www.cnblogs.com/fishpro/p/spring-knowledge-graph-1-java-ide.html)
- [Spring Boot 概述](https://www.cnblogs.com/fishpro/p/11135358.html)
- [Spring Boot 特性及Spring Boot 2.0新特性](https://www.cnblogs.com/fishpro/p/11135362.html)
- [Spring Boot 学习前你应该知道的 Maven 知识](https://www.cnblogs.com/fishpro/p/11140900.html)
- [Spring Boot 学习之 IDEA 环境下多模块 Multi Modules](https://www.cnblogs.com/fishpro/p/11165827.html)
- [Spring Boot 学习之 IDEA 环境下的 github 创建提交与修改](https://www.cnblogs.com/fishpro/p/11167353.html)
- [Spring Boot 快速入门 HelloWorld示例](https://www.cnblogs.com/fishpro/p/spring-boot-study-helloworld.html)
- [Spring Boot 快速入门 HelloWorld示例详解](https://www.cnblogs.com/fishpro/p/10675293.html)
- [Spring Boot 学习方法论-如何正确的入门 Sprint Boot](https://www.cnblogs.com/fishpro/p/11144008.html)

## Spring Boot 环境及配置

- [Spring Boot 多环境配置](https://www.cnblogs.com/fishpro/p/11154872.html) 
- [Spring Boot 自定义 Banner](https://www.cnblogs.com/fishpro/p/spring-boot-study-banner.html)
- Spring Boot 生产环境部署方式
- [Spring Boot 配置文件和命令行配置](https://www.cnblogs.com/fishpro/p/spring-boot-study-cfg.html)
- [Spring Boot 利用 nginx 实现生产环境的伪热更新](https://www.cnblogs.com/fishpro/p/spring-boot-study-hotstart.html)

## Spring Boot Web 开发

- [Spring Boot @Controller @RestController 使用教程](https://www.cnblogs.com/fishpro/p/spring-boot-study-restcontroller.html)
- [SpringBoot RESTful API 架构风格实践](https://www.cnblogs.com/fishpro/p/spring-boot-study-restful.html)
- [Spring Boot RestApi 测试教程 Mock 的使用](https://www.cnblogs.com/fishpro/p/spring-boot-study-resttest-mock.html)
- [Spring Boot 集成 Swagger2 教程](https://www.cnblogs.com/fishpro/p/spring-boot-study-swagger2.html)

## Spring Boot 基础

- [Spring Boot Log 日志管理](https://www.cnblogs.com/fishpro/p/11167469.html)
- [Spring Boot 全局异常处理](https://www.cnblogs.com/fishpro/p/11179688.html)
- [Spring Boot 使用 Aop 实现日志全局拦截](https://www.cnblogs.com/fishpro/p/11183086.html)
- Spring Boot 中的日期处理
- [Spring Boot Thymeleaf 模板引擎的使用](https://www.cnblogs.com/fishpro/p/11175391.html)
- [Spring Boot FreeMarker 使用教程](https://www.cnblogs.com/fishpro/p/spring-boot-study-freemarker.html)
- SpringBoot使用模板 Velocity（Spring Boot 已经不支持 Velocity了

## Spring Boot 持久层技术

- [Spring Boot 数据库应用 JDBC 使用教程](https://www.cnblogs.com/fishpro/p/spring-boot-study-jdbc.html)
- [Spring Boot 数据库应用 Mybatis使用教程](https://www.cnblogs.com/fishpro/p/spring-boot-study-mybatis.html)
- [Spring Boot 数据库应用 使用Jpa使用教程](https://www.cnblogs.com/fishpro/p/spring-boot-study-jpa.html)
- [Spring Boot 数据库应用 动态数据源](https://www.cnblogs.com/fishpro/p/spring-boot-study-dynamicdb.html)


- [Spring Boot Kafka 入门示例](https://www.cnblogs.com/fishpro/p/12784514.html)

## Spring Boot 缓存技术

- [Spring Boot 中的缓存应用（上）使用ehcache](https://www.cnblogs.com/fishpro/p/spring-boot-study-ehcache.html)
- [Spring Boot 中的缓存应用（中）使用Redis](https://www.cnblogs.com/fishpro/p/spring-boot-study-redis.html)
- [Spring Boot 中的缓存应用（下）使用Memcached](https://www.cnblogs.com/fishpro/p/spring-boot-study-memcached.html)


## Spring Boot 安全

- [Spring Boot 权限应用 使用Shiro](https://www.cnblogs.com/fishpro/p/spring-boot-study-study.html)
- [Spring Boot 权限应用 使用Spring Security](https://www.cnblogs.com/fishpro/p/spring-boot-study-securing.html)
- [Spring Boot 权限应用 使用Jwt](https://www.cnblogs.com/fishpro/p/spring-boot-study-jwt.html)
- [Spring Boot Shiro 整合验证码]

## Spring Boot 常用操作

- [Spring Boot 文件上传](https://www.cnblogs.com/fishpro/p/spring-boot-study-upload.html)
- [Spring Boot 操作 Excel](https://www.cnblogs.com/fishpro/p/spring-boot-study-excel.html)
- [Spring Boot使用Quartz定时任务](https://www.cnblogs.com/fishpro/p/spring-boot-study-quartz.html)
- [Spring Boot 邮件发送](https://www.cnblogs.com/fishpro/p/spring-boot-study-sendemail.html)
- [Spring Boot FTP上传与下载](https://www.cnblogs.com/fishpro/p/spring-boot-study-ftpclient.html)
- [Spring Boot 中使用 HttpClient 进行 POST GET PUT DELETE](https://www.cnblogs.com/fishpro/p/spring-boot-study-httpclient.html)
- [Spring Boot 开放 WebService 服务](https://www.cnblogs.com/fishpro/p/spring-boot-study-webservice.html)
- [Spring Boot 使用 CXF 调用 WebService 服务](https://www.cnblogs.com/fishpro/p/spring-boot-study-cxfclient.html)
- [Spring Boot 使用 JAX-WS 调用 WebService 服务](https://www.cnblogs.com/fishpro/p/spring-boot-study-webservicejaxws.html)
- [Spring Boot Json应用 JackJson FastJson](https://www.cnblogs.com/fishpro/p/spring-boot-study-jackjson.html)
- [Spring Boot 使用 Dom4j XStream 操作 Xml](https://www.cnblogs.com/fishpro/p/spring-boot-study-xml.html)

## Spring Boot 生产环境实战

- [Spring Boot 利用 nginx 实现生产环境的伪热更新](https://www.cnblogs.com/fishpro/p/spring-boot-study-hotstart.html)
- [Spring Boot 多站点利用 Redis 实现 Session 共享](https://www.cnblogs.com/fishpro/p/spring-boot-study-sharedsession.html)

"
IanDarwin/patterns-demos,master,79,26,2018-02-02T20:08:07Z,114,0,Examples of Design Patterns in Java,design-patterns java patterns,
perspilling/jdbi-examples,master,41,15,2013-12-22T19:54:18Z,191,1,Some examples of using JDBI as a persistence framework,,"# JDBI examples

This repo contains some example code used to try out using [JDBI](http://jdbi.org) as a persistence framework
in Java projects.

The domain model used in the examples looks like this:

| Team | ---> | Person | -(cascade)-> | Address |

## Notes

### CGLIB issue with references

JDBI generates boilerplate code from annotated interfaces or abstract classes. When using
abstract classes it would be nice to di the following:

```java
@RegisterMapper(AddressMapper.class)
public abstract class AddressAbstractClassJdbiDao implements AddressDao {
}

...

public Foo {
    private AddressDao addressDao = dbi.onDemand(AddressAbstractClassJdbiDao.class);
}
```

However, this doesn't work. You will get a null pointer exception. Instead you must use
the abstract (implementation) class as reference, like this:


```java
@RegisterMapper(AddressMapper.class)
public abstract class AddressAbstractClassJdbiDao implements AddressDao {
}

...

public Foo {
    private AddressAbstractClassJdbiDao addressDao = dbi.onDemand(AddressAbstractClassJdbiDao.class);
}
```

### CGLIB issue with abstract classes

It seems that when using abstract classes with CGLIB you need to put them in a separate file,
otherwise you get the following error:

```
java.lang.IllegalArgumentException: Superclass has no null constructors but no arguments were given
	at org.skife.jdbi.cglib.proxy.Enhancer.emitConstructors(Enhancer.java:721)
	at org.skife.jdbi.cglib.proxy.Enhancer.generateClass(Enhancer.java:499)
```






"
beaunus/stanford-algs,master,350,226,2016-12-28T10:30:22Z,223994,9,Example Test Cases for Stanford's Algorithms Coursera Specialization,algorithms algorithms-stanford coursera stanford stanford-algs test-cases,"# stanford-algs

## Overview

This repository contains some example test case files for Stanford's Coursera specialization [_Learn To Think Like A Computer Scientist_](https://www.coursera.org/specializations/algorithms)

## Intention

These files are intended to be used as a supplement to the above course.

In order to comply with the [Coursera Honor Code](https://www.google.com/search?q=Coursera+Honor+Code), please do not share any solutions to the _actual_ assignments from the course.

## Getting Started

If you want to know more about using this repository, check out the [wiki](https://github.com/beaunus/stanford-algs/wiki).

## Contributing

If you are interested in contributing, please read our [CONTRIBUTING](CONTRIBUTING.md) guide.

## Disclaimer

The programming assignments themselves are intellectual property of the Coursera course. The Coursera community has given permission to re-publish the assignments.

Any infringement on intellectual property rights is accidental. If you feel that this repository is out of line, please let us know and we will do our best to comply with your request.
"
Cascading/Impatient,master,79,75,2012-06-20T18:10:39Z,15901,1,"source examples to support the Cascading for the Impatient"" blog post series""",,"## Cascading for the Impatient

Welcome to [Cascading for the Impatient](http://docs.cascading.org/impatient), a tutorial for [Cascading 3.1.x](http://www.cascading.org/) to get you started. Quickly. Like, yesterday.

This set of progressive coding examples starts with a simple file copy and builds up to a MapReduce implementation of the TF-IDF algorithm.

You can read the full series here: http://docs.cascading.org/impatient/

If you have a question or run into any problems send an email to the [cascading-user-list](https://groups.google.com/forum/#!forum/cascading-user).


### Part 1
* Implements simplest Cascading app possible
* Copies each TSV line from source tap to sink tap
* Roughly, in about a dozen lines of code
* Physical plan: 1 Mapper

### Part 2
* Implements a simple example of WordCount
* Uses a regex to split the input text lines into a token stream
* Generates a DOT file, to show the Cascading flow graphically
* Physical plan: 1 Mapper, 1 Reducer

### Part 3
* Uses a custom Function to scrub the token stream
* Discusses when to use standard Operations vs. creating custom ones
* Physical plan: 1 Mapper, 1 Reducer

### Part 4
* Shows how to use a HashJoin on two pipes
* Filters a list of stop words out of the token stream
* Physical plan: 1 Mapper, 1 Reducer

### Part 5
* Calculates TF-IDF using an ExpressionFunction
* Shows how to use a CountBy, SumBy, and a CoGroup
* Physical plan: 10 Mappers, 8 Reducers

### Part 6
* Includes unit tests in the build
* Shows how to use other TDD features: checkpoints, assertions, traps, debug
* Physical plan: 11 Mappers, 8 Reducers

### Part 7
This example is currently not implemented.

### Part 8
* Scalding equivalents of previous examples in Cascading
"
ddd-by-examples/library,master,4103,656,2019-01-11T09:14:03Z,48023,17,A comprehensive Domain-Driven Design example with problem space strategic analysis and various tactical patterns.,aggregate aggregate-root archunit c4 crud ddd ddd-architecture domain-driven-design event-storming events functions hexagonal-architecture ports-and-adapters spring vavr,"[![CircleCI](https://circleci.com/gh/ddd-by-examples/library.svg?style=svg)](https://circleci.com/gh/ddd-by-examples/library)
[![Code Coverage](https://codecov.io/gh/ddd-by-examples/library/branch/master/graph/badge.svg)](https://codecov.io/gh/ddd-by-examples/library)

# Table of contents

1. [About](#about)
2. [Domain description](#domain-description)
3. [General assumptions](#general-assumptions)  
    3.1 [Process discovery](#process-discovery)  
    3.2 [Project structure and architecture](#project-structure-and-architecture)    
    3.3 [Aggregates](#aggregates)  
    3.4 [Events](#events)  
    3.4.1 [Events in Repositories](#events-in-repositories)   
    3.5 [ArchUnit](#archunit)  
    3.6 [Functional thinking](#functional-thinking)  
    3.7 [No ORM](#no-orm)  
    3.8 [Architecture-code gap](#architecture-code-gap)  
    3.9 [Model-code gap](#model-code-gap)   
    3.10 [Spring](#spring)  
    3.11 [Tests](#tests)  
4. [How to contribute](#how-to-contribute)
5. [References](#references)

## About

This is a project of a library, driven by real [business requirements](#domain-description).
We use techniques strongly connected with Domain Driven Design, Behavior-Driven Development,
Event Storming, User Story Mapping. 

## Domain description

A public library allows patrons to place books on hold at its various library branches.
Available books can be placed on hold only by one patron at any given point in time.
Books are either circulating or restricted, and can have retrieval or usage fees.
A restricted book can only be held by a researcher patron. A regular patron is limited
to five holds at any given moment, while a researcher patron is allowed an unlimited number
of holds. An open-ended book hold is active until the patron checks out the book, at which time it
is completed. A closed-ended book hold that is not completed within a fixed number of 
days after it was requested will expire. This check is done at the beginning of a day by 
taking a look at daily sheet with expiring holds. Only a researcher patron can request
an open-ended hold duration. Any patron with more than two overdue checkouts at a library
branch will get a rejection if trying a hold at that same library branch. A book can be
checked out for up to 60 days. Check for overdue checkouts is done by taking a look at
daily sheet with overdue checkouts. Patron interacts with his/her current holds, checkouts, etc.
by taking a look at patron profile. Patron profile looks like a daily sheet, but the
information there is limited to one patron and is not necessarily daily. Currently a
patron can see current holds (not canceled nor expired) and current checkouts (including overdue).
Also, he/she is able to hold a book and cancel a hold.

How actually a patron knows which books are there to lend? Library has its catalogue of
books where books are added together with their specific instances. A specific book
instance of a book can be added only if there is book with matching ISBN already in
the catalogue.  Book must have non-empty title and price. At the time of adding an instance
we decide whether it will be Circulating or Restricted. This enables
us to have book with same ISBN as circulated and restricted at the same time (for instance,
there is a book signed by the author that we want to keep as Restricted)

## General assumptions

### Process discovery

The first thing we started with was domain exploration with the help of Big Picture EventStorming.
The description you found in the previous chapter, landed on our virtual wall:    
![Event Storming Domain description](docs/images/eventstorming-domain-desc.png)   
The EventStorming session led us to numerous discoveries, modeled with the sticky notes:  
![Event Storming Big Picture](docs/images/eventstorming-big-picture.jpg)   
During the session we discovered following definitions:  
![Event Storming Definitions](docs/images/eventstorming-definitions.png)    

This made us think of real life scenarios that might happen. We discovered them described with the help of
the **Example mapping**:  
![Example mapping](docs/images/example-mapping.png)  

This in turn became the base for our *Design Level* sessions, where we analyzed each example:  
![Example mapping](docs/images/eventstorming-design-level.jpg)  

Please follow the links below to get more details on each of the mentioned steps:
- [Big Picture EventStorming](./docs/big-picture.md)
- [Example Mapping](docs/example-mapping.md)
- [Design Level EventStorming](docs/design-level.md)

### Project structure and architecture
At the very beginning, not to overcomplicate the project, we decided to assign each bounded context
to a separate package, which means that the system is a modular monolith. There are no obstacles, though,
to put contexts into maven modules or finally into microservices.

Bounded contexts should (amongst others) introduce autonomy in the sense of architecture. Thus, each module
encapsulating the context has its own local architecture aligned to problem complexity.
In the case of a context, where we identified true business logic (**lending**) we introduced a domain model
that is a simplified (for the purpose of the project) abstraction of the reality and utilized
hexagonal architecture. In the case of a context, that during Event Storming turned out to lack any complex
domain logic, we applied CRUD-like local architecture.  

![Architecture](docs/images/architecture-big-picture.png) 

If we are talking about hexagonal architecture, it lets us separate domain and application logic from
frameworks (and infrastructure). What do we gain with this approach? Firstly, we can unit test most important
part of the application - **business logic** - usually without the need to stub any dependency.
Secondly, we create ourselves an opportunity to adjust infrastructure layer without the worry of
breaking the core functionality. In the infrastructure layer we intensively use Spring Framework
as probably the most mature and powerful application framework with an incredible test support.
More information about how we use Spring you will find [here](#spring).

As we already mentioned, the architecture was driven by Event Storming sessions. Apart from identifying
contexts and their complexity, we could also make a decision that we separate read and write models (CQRS).
As an example you can have a look at **Patron Profiles** and *Daily Sheets*.

### Aggregates
Aggregates discovered during Event Storming sessions communicate with each other with events. There is
a contention, though, should they be consistent immediately or eventually? As aggregates in general
determine business boundaries, eventual consistency sounds like a better choice, but choices in software
are never costless. Providing eventual consistency requires some infrastructural tools, like message broker
or event store. That's why we could (and did) start with immediate consistency.

> Good architecture is the one which postpones all important decisions

... that's why we made it easy to change the consistency model, providing tests for each option, including
basic implementations based on **DomainEvents** interface, which can be adjusted to our needs and
toolset in future. Let's have a look at following examples:

* Immediate consistency
    ```groovy
    def 'should synchronize Patron, Book and DailySheet with events'() {
        given:
            bookRepository.save(book)
        and:
            patronRepo.publish(patronCreated())
        when:
            patronRepo.publish(placedOnHold(book))
        then:
            patronShouldBeFoundInDatabaseWithOneBookOnHold(patronId)
        and:
            bookReactedToPlacedOnHoldEvent()
        and:
            dailySheetIsUpdated()
    }
    
    boolean bookReactedToPlacedOnHoldEvent() {
        return bookRepository.findBy(book.bookId).get() instanceof BookOnHold
    }
    
    boolean dailySheetIsUpdated() {
        return new JdbcTemplate(datasource).query(""select count(*) from holds_sheet s where s.hold_by_patron_id = ?"",
                [patronId.patronId] as Object[],
                new ColumnMapRowMapper()).get(0)
                .get(""COUNT(*)"") == 1
    }
    ```
   _Please note that here we are just reading from database right after events are being published_
   
   Simple implementation of the event bus is based on Spring application events:
    ```java
    @AllArgsConstructor
    public class JustForwardDomainEventPublisher implements DomainEvents {
    
        private final ApplicationEventPublisher applicationEventPublisher;
    
        @Override
        public void publish(DomainEvent event) {
            applicationEventPublisher.publishEvent(event);
        }
    }
    ```

* Eventual consistency
    ```groovy
    def 'should synchronize Patron, Book and DailySheet with events'() {
        given:
            bookRepository.save(book)
        and:
            patronRepo.publish(patronCreated())
        when:
            patronRepo.publish(placedOnHold(book))
        then:
            patronShouldBeFoundInDatabaseWithOneBookOnHold(patronId)
        and:
            bookReactedToPlacedOnHoldEvent()
        and:
            dailySheetIsUpdated()
    }
    
    void bookReactedToPlacedOnHoldEvent() {
        pollingConditions.eventually {
            assert bookRepository.findBy(book.bookId).get() instanceof BookOnHold
        }
    }
    
    void dailySheetIsUpdated() {
        pollingConditions.eventually {
            assert countOfHoldsInDailySheet() == 1
        }
    }
    ```
    _Please note that the test looks exactly the same as previous one, but now we utilized Groovy's
    **PollingConditions** to perform asynchronous functionality tests_

    Sample implementation of event bus is following:
    
    ```java
    @AllArgsConstructor
    public class StoreAndForwardDomainEventPublisher implements DomainEvents {
    
        private final JustForwardDomainEventPublisher justForwardDomainEventPublisher;
        private final EventsStorage eventsStorage;
    
        @Override
        public void publish(DomainEvent event) {
            eventsStorage.save(event);
        }
    
        @Scheduled(fixedRate = 3000L)
        @Transactional
        public void publishAllPeriodically() {
            List<DomainEvent> domainEvents = eventsStorage.toPublish();
            domainEvents.forEach(justForwardDomainEventPublisher::publish);
            eventsStorage.published(domainEvents);
        }
    }
    ```

To clarify, we should always aim for aggregates that can handle a business operation atomically
(transactionally if you like), so each aggregate should be as independent and decoupled from other
aggregates as possible. Thus, eventual consistency is promoted. As we already mentioned, it comes
with some tradeoffs, so from the pragmatic point of view immediate consistency is also a choice.
You might ask yourself a question now: _What if I don't have any events yet?_. Well, a pragmatic
approach would be to encapsulate the communication between aggregates in a _Service-like_ class,
where you could call proper aggregates line by line explicitly.

### Events
Talking about inter-aggregate communication, we must remember that events reduce coupling, but don't remove
it completely. Thus, it is very vital to share(publish) only those events, that are necessary for other
aggregates to exist and function. Otherwise there is a threat that the level of coupling will increase
introducing **feature envy**, because other aggregates might start using those events to perform actions
they are not supposed to perform. A solution to this problem could be the distinction of domain events
and integration events, which will be described here soon.  

### Events in Repositories 
Repositories are one of the most popular design pattern. They abstract our domain model from data layer. 
In other words, they deal with state. That said, a common use-case is when we pass a new state to our repository,
so that it gets persisted. It may look like so:

```java
public class BusinessService {
   
    private final PatronRepository patronRepository;
    
    void businessMethod(PatronId patronId) {
        Patron patron = patronRepository.findById(patronId);
        //do sth
        patronRepository.save(patron);
    }
}
```

Conceptually, between 1st and 3rd line of that business method we change state of our Patron from A to B. 
This change might be calculated by dirty checking or we might just override entire Patron state in the database. 
Third option is _Let's make implicit explicit_ and actually call this state change A->B an **event**. 
After all, event-driven architecture is all about promoting state changes as domain events.

Thanks to this our domain model may become immutable and just return events as results of invoking a command like so:

```java
public BookPlacedOnHold placeOnHold(AvailableBook book) {
      ...
}
```

And our repository might operate directly on events like so:

```java
public interface PatronRepository {
     void save(PatronEvent event) {
}
```

### ArchUnit

One of the main components of a successful project is technical leadership that lets the team go in the right
direction. Nevertheless, there are tools that can support teams in keeping the code clean and protect the
architecture, so that the project won't become a Big Ball of Mud, and thus will be pleasant to develop and
to maintain. The first option, the one we proposed, is [ArchUnit](https://www.archunit.org/) - a Java architecture
test tool. ArchUnit lets you write unit tests of your architecture, so that it is always consistent with initial
vision. Maven modules could be an alternative as well, but let's focus on the former.

In terms of hexagonal architecture, it is essential to ensure, that we do not mix different levels of
abstraction (hexagon levels):
```java 
@ArchTest
public static final ArchRule model_should_not_depend_on_infrastructure =
    noClasses()
        .that()
        .resideInAPackage(""..model.."")
        .should()
        .dependOnClassesThat()
        .resideInAPackage(""..infrastructure.."");
```      
and that frameworks do not affect the domain model  
```java
@ArchTest
public static final ArchRule model_should_not_depend_on_spring =
    noClasses()
        .that()
        .resideInAPackage(""..io.pillopl.library.lending..model.."")
        .should()
        .dependOnClassesThat()
        .resideInAPackage(""org.springframework.."");
```    

### Functional thinking
When you look at the code you might find a scent of functional programming. Although we do not follow
a _clean_ FP, we try to think of business processes as pipelines or workflows, utilizing functional style through
following concepts.

_Please note that this is not a reference project for FP._

#### Immutable objects
Each class that represents a business concept is immutable, thanks to which we:
* provide full encapsulation and objects' states protection,
* secure objects for multithreaded access,
* control all side effects much clearer. 

#### Pure functions
We model domain operations, discovered in Design Level Event Storming, as pure functions, and declare them in
both domain and application layers in the form of Java's functional interfaces. Their implementations are placed
in infrastructure layer as ordinary methods with side effects. Thanks to this approach we can follow the abstraction
of ubiquitous language explicitly, and keep this abstraction implementation-agnostic. As an example, you could have
a look at `FindAvailableBook` interface and its implementation:

```java
@FunctionalInterface
public interface FindAvailableBook {

    Option<AvailableBook> findAvailableBookBy(BookId bookId);
}
```

```java
@AllArgsConstructor
class BookDatabaseRepository implements FindAvailableBook {

    private final JdbcTemplate jdbcTemplate;

    @Override
    public Option<AvailableBook> findAvailableBookBy(BookId bookId) {
        return Match(findBy(bookId)).of(
                Case($Some($(instanceOf(AvailableBook.class))), Option::of),
                Case($(), Option::none)
        );
    }  

    Option<Book> findBy(BookId bookId) {
        return findBookById(bookId)
                .map(BookDatabaseEntity::toDomainModel);
    }

    private Option<BookDatabaseEntity> findBookById(BookId bookId) {
        return Try
                .ofSupplier(() -> of(jdbcTemplate.queryForObject(""SELECT b.* FROM book_database_entity b WHERE b.book_id = ?"",
                                      new BeanPropertyRowMapper<>(BookDatabaseEntity.class), bookId.getBookId())))
                .getOrElse(none());
    }  
} 
```
    
#### Type system
_Type system - like_ modelling - we modelled each domain object's state discovered during EventStorming as separate
classes: `AvailableBook`, `BookOnHold`, `CheckedOutBook`. With this approach we provide much clearer abstraction than
having a single `Book` class with an enum-based state management. Moving the logic to these specific classes brings
Single Responsibility Principle to a different level. Moreover, instead of checking invariants in every business method
we leave the role to the compiler. As an example, please consider following scenario: _you can place on hold only a book
that is currently available_. We could have done it in a following way:
```java
public Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(Book book) {
  if (book.status == AVAILABLE) {  
      ...
  }
}
```
but we use the _type system_ and declare method of following signature
```java
public Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(AvailableBook book) {
      ...
}
```  
The more errors we discover at compile time the better.

Yet another advantage of applying such type system is that we can represent business flows and state transitions
with functions much easier. As an example, following functions:
```
placeOnHold: AvailableBook -> BookHoldFailed | BookPlacedOnHold
cancelHold: BookOnHold -> BookHoldCancelingFailed | BookHoldCanceled
``` 
are much more concise and descriptive than these:
```
placeOnHold: Book -> BookHoldFailed | BookPlacedOnHold
cancelHold: Book -> BookHoldCancelingFailed | BookHoldCanceled
```
as here we have a lot of constraints hidden within function implementations.

Moreover if you think of your domain as a set of operations (functions) that are being executed on business objects
(aggregates) you don't think of any execution model (like async processing). It is fine, because you don't have to.
Domain functions are free from I/O operations, async, and other side-effects-prone things, which are put into the
infrastructure layer. Thanks to this, we can easily test them without mocking mentioned parts. 

#### Monads
Business methods might have different results. One might return a value or a `null`, throw an exception when something
unexpected happens or just return different objects under different circumstances. All those situations are typical
to object-oriented languages like Java, but do not fit into functional style. We are dealing with this issues
with monads (monadic containers provided by [Vavr](https://www.vavr.io)):
* When a method returns optional value, we use the `Option` monad:

    ```java
    Option<Book> findBy(BookId bookId) {
        ...
    }
    ```

* When a method might return one of two possible values, we use the `Either` monad:

    ```java
    Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(AvailableBook book) {
        ...
    }
    ```

* When an exception might occur, we use `Try` monad:

    ```java
    Try<Result> placeOnHold(@NonNull PlaceOnHoldCommand command) {
        ...
    }
    ```

Thanks to this, we can follow the functional programming style, but we also enrich our domain language and
make our code much more readable for the clients.

#### Pattern Matching
Depending on a type of a given book object we often need to perform different actions. Series of if/else or switch/case statements
could be a choice, but it is the pattern matching that provides the most conciseness and flexibility. With the code
like below we can check numerous patterns against objects and access their constituents, so our code has a minimal dose
of language-construct noise:
```java
private Book handleBookPlacedOnHold(Book book, BookPlacedOnHold bookPlacedOnHold) {
    return API.Match(book).of(
        Case($(instanceOf(AvailableBook.class)), availableBook -> availableBook.handle(bookPlacedOnHold)),
        Case($(instanceOf(BookOnHold.class)), bookOnHold -> raiseDuplicateHoldFoundEvent(bookOnHold, bookPlacedOnHold)),
        Case($(), () -> book)
    );
}
```

### (No) ORM
If you run `mvn dependency:tree` you won't find any JPA implementation. Although we think that ORM solutions (like Hibernate)
are very powerful and useful, we decided not to use them, as we wouldn't utilize their features. What features are
talking about? Lazy loading, caching, dirty checking. Why don't we need them? We want to have more control
over SQL queries and minimize the object-relational impedance mismatch ourselves. Moreover, thanks to relatively
small aggregates, containing as little data as it is required to protect the invariants, we don't need the
lazy loading mechanism either.
With Hexagonal Architecture we have the ability to separate domain and persistence models and test them
independently. Moreover, we can also introduce different persistence strategies for different aggregates. 
In this project, we utilize both plain SQL queries and `JdbcTemplate` and use new and very promising 
project called Spring Data JDBC, that is free from the JPA-related overhead mentioned before.
Please find below an example of a repository:

```java
interface PatronEntityRepository extends CrudRepository<PatronDatabaseEntity, Long> {

    @Query(""SELECT p.* FROM patron_database_entity p where p.patron_id = :patronId"")
    PatronDatabaseEntity findByPatronId(@Param(""patronId"") UUID patronId);

}
```

At the same time we propose other way of persisting aggregates, with plain SQL queries and `JdbcTemplate`:  

```java
@AllArgsConstructor
class BookDatabaseRepository implements BookRepository, FindAvailableBook, FindBookOnHold {

    private final JdbcTemplate jdbcTemplate;

    @Override
    public Option<Book> findBy(BookId bookId) {
        return findBookById(bookId)
                .map(BookDatabaseEntity::toDomainModel);
    }

    private Option<BookDatabaseEntity> findBookById(BookId bookId) {
        return Try
                .ofSupplier(() -> of(jdbcTemplate.queryForObject(""SELECT b.* FROM book_database_entity b WHERE b.book_id = ?"",
                                     new BeanPropertyRowMapper<>(BookDatabaseEntity.class), bookId.getBookId())))
                .getOrElse(none());
    }
    
    ...
}
```
_Please note that despite having the ability to choose different persistence implementations for aggregates
it is recommended to stick to one option within the app/team_ 
    
### Architecture-code gap
We put a lot of attention to keep the consistency between the overall architecture (including diagrams)
and the code structure. Having identified bounded contexts we could organize them in modules (packages, to
be more specific). Thanks to this we gain the famous microservices' autonomy, while having a monolithic
application. Each package has well defined public API, encapsulating all implementation details by using
package-protected or private scopes.

Just by looking at the package structure:

```
└── library
    ├── catalogue
    ├── commons
    │   ├── aggregates
    │   ├── commands
    │   └── events
    │       └── publisher
    └── lending
        ├── book
        │   ├── application
        │   ├── infrastructure
        │   └── model
        ├── dailysheet
        │   ├── infrastructure
        │   └── model
        ├── librarybranch
        │   └── model
        ├── patron
        │   ├── application
        │   ├── infrastructure
        │   └── model
        └── patronprofile
            ├── infrastructure
            ├── model
            └── web
```
you can see that the architecture is screaming that it has two bounded contexts: **catalogue**
and **lending**. Moreover, the **lending context** is built around five business objects: **book**,
**dailysheet**, **librarybranch**, **patron**, and **patronprofile**, while **catalogue** has no subpackages,
which suggests that it might be a CRUD with no complex logic inside. Please find the architecture diagram
below.

![Component diagram](docs/c4/component-diagram.png)

Yet another advantage of this approach comparing to packaging by layer for example is that in order to 
deliver a functionality you would usually need to do it in one package only, which is the aforementioned
autonomy. This autonomy, then, could be transferred to the level of application as soon as we split our
_context-packages_ into separate microservices. Following this considerations, autonomy can be given away
to a product team that can take care of the whole business area end-to-end.

### Model-code gap
In our project we do our best to reduce _model-code gap_ to bare minimum. It means we try to put equal attention
to both the model and the code and keep them consistent. Below you will find some examples.

#### Placing on hold
![Placing on hold](docs/images/placing_on_hold.jpg)

Starting with the easiest part, below you will find the model classes corresponding to depicted command and events:

```java
@Value
class PlaceOnHoldCommand {
    ...
}
```
```java
@Value
class BookPlacedOnHold implements PatronEvent {
    ...
}
```
```java
@Value
class MaximumNumberOfHoldsReached implements PatronEvent {
    ...    
}
```
```java
@Value
class BookHoldFailed implements PatronEvent {
    ...
}
```

We know it might not look impressive now, but if you have a look at the implementation of an aggregate,
you will see that the code reflects not only the aggregate name, but also the whole scenario of `PlaceOnHold` 
command handling. Let us uncover the details:

```java
public class Patron {

    public Either<BookHoldFailed, BookPlacedOnHoldEvents> placeOnHold(AvailableBook book) {
        return placeOnHold(book, HoldDuration.openEnded());
    }
    
    ...
}    
```

The signature of `placeOnHold` method screams, that it is possible to place a book on hold only when it
is available (more information about protecting invariants by compiler you will find in [Type system section](#type-system)).
Moreover, if you try to place available book on hold it can **either** fail (`BookHoldFailed`) or produce some events -
what events?

```java
@Value
class BookPlacedOnHoldEvents implements PatronEvent {
    @NonNull UUID eventId = UUID.randomUUID();
    @NonNull UUID patronId;
    @NonNull BookPlacedOnHold bookPlacedOnHold;
    @NonNull Option<MaximumNumberOfHoldsReached> maximumNumberOfHoldsReached;

    @Override
    public Instant getWhen() {
        return bookPlacedOnHold.when;
    }

    public static BookPlacedOnHoldEvents events(BookPlacedOnHold bookPlacedOnHold) {
        return new BookPlacedOnHoldEvents(bookPlacedOnHold.getPatronId(), bookPlacedOnHold, Option.none());
    }

    public static BookPlacedOnHoldEvents events(BookPlacedOnHold bookPlacedOnHold, MaximumNumberOfHoldsReached maximumNumberOfHoldsReached) {
        return new BookPlacedOnHoldEvents(bookPlacedOnHold.patronId, bookPlacedOnHold, Option.of(maximumNumberOfHoldsReached));
    }

    public List<DomainEvent> normalize() {
        return List.<DomainEvent>of(bookPlacedOnHold).appendAll(maximumNumberOfHoldsReached.toList());
    }
}
```

`BookPlacedOnHoldEvents` is a container for `BookPlacedOnHold` event, and - if patron has 5 book placed on hold already -
`MaximumNumberOfHoldsReached` (please mind the `Option` monad). You can see now how perfectly the code reflects
the model.

It is not everything, though. In the picture above you can also see a big rectangular yellow card with rules (policies)
that define the conditions that need to be fulfilled in order to get the given result. All those rules are implemented 
as functions **either** allowing or rejecting the hold:

![Restricted book policy](docs/images/placing-on-hold-policy-restricted.png)
```java
PlacingOnHoldPolicy onlyResearcherPatronsCanHoldRestrictedBooksPolicy = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {
    if (toHold.isRestricted() && patron.isRegular()) {
        return left(Rejection.withReason(""Regular patrons cannot hold restricted books""));
    }
    return right(new Allowance());
};
```

![Overdue checkouts policy](docs/images/placing-on-hold-policy-overdue.png)

```java
PlacingOnHoldPolicy overdueCheckoutsRejectionPolicy = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {
    if (patron.overdueCheckoutsAt(toHold.getLibraryBranch()) >= OverdueCheckouts.MAX_COUNT_OF_OVERDUE_RESOURCES) {
        return left(Rejection.withReason(""cannot place on hold when there are overdue checkouts""));
    }
    return right(new Allowance());
};
```

![Max number of holds policy](docs/images/placing-on-hold-policy-max.png)

```java
PlacingOnHoldPolicy regularPatronMaximumNumberOfHoldsPolicy = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {
    if (patron.isRegular() && patron.numberOfHolds() >= PatronHolds.MAX_NUMBER_OF_HOLDS) {
        return left(Rejection.withReason(""patron cannot hold more books""));
    }
    return right(new Allowance());
};
```

![Open ended hold policy](docs/images/placing-on-hold-policy-open-ended.png)

```java
PlacingOnHoldPolicy onlyResearcherPatronsCanPlaceOpenEndedHolds = (AvailableBook toHold, Patron patron, HoldDuration holdDuration) -> {
    if (patron.isRegular() && holdDuration.isOpenEnded()) {
        return left(Rejection.withReason(""regular patron cannot place open ended holds""));
    }
    return right(new Allowance());
};
```

#### Spring
Spring Framework seems to be the most popular Java framework ever used. Unfortunately it is also quite common
to overuse its features in the business code. What you find in this project is that the domain packages
are fully focused on modelling business problems, and are free from any DI, which makes it easy to
unit-test it which is invaluable in terms of code reliability and maintainability. It does not mean,
though, that we do not use Spring Framework - we do. Below you will find some details:
- Each bounded context has its own independent application context. It means that we removed the runtime
coupling, which is a step towards extracting modules (and microservices). How did we do that? Let's have
a look:
    ```java
    @SpringBootConfiguration
    @EnableAutoConfiguration
    public class LibraryApplication {
    
        public static void main(String[] args) {
            new SpringApplicationBuilder()
                    .parent(LibraryApplication.class)
                    .child(LendingConfig.class).web(WebApplicationType.SERVLET)
                    .sibling(CatalogueConfiguration.class).web(WebApplicationType.NONE)
                    .run(args);
        }
    }
    ```
- As you could see above, we also try not to use component scan wherever possible. Instead we utilize
`@Configuration` classes where we define module specific beans in the infrastructure layer. Those
configuration classes are explicitly declared in the main application class.

### Tests
Tests are written in a BDD manner, expressing stories defined with Example Mapping.
It means we utilize both TDD and Domain Language discovered with Event Storming. 

We also made an effort to show how to create a DSL, that enables to write
tests as if they were sentences taken from the domain descriptions. Please
find an example below:

```groovy
def 'should make book available when hold canceled'() {
    given:
        BookDSL bookOnHold = aCirculatingBook() with anyBookId() locatedIn anyBranch() placedOnHoldBy anyPatron()
    and:
        PatronEvent.BookHoldCanceled bookHoldCanceledEvent = the bookOnHold isCancelledBy anyPatron()

    when:
        AvailableBook availableBook = the bookOnHold reactsTo bookHoldCanceledEvent
    then:
        availableBook.bookId == bookOnHold.bookId
        availableBook.libraryBranch == bookOnHold.libraryBranchId
        availableBook.version == bookOnHold.version
}
``` 
_Please also note the **when** block, where we manifest the fact that books react to 
cancellation event_

## How to contribute

The project is still under construction, so if you like it enough to collaborate, just let us
know or simply create a Pull Request.


## How to Build

### Requirements

* Java 11
* Maven

### Quickstart

You can run the library app by simply typing the following:

```console
$ mvn spring-boot:run
...
...
2019-04-03 15:55:39.162  INFO 18957 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
2019-04-03 15:55:39.425  INFO 18957 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2019-04-03 15:55:39.428  INFO 18957 --- [           main] io.pillopl.library.LibraryApplication    : Started LibraryApplication in 5.999 seconds (JVM running for 23.018)

```

### Build a Jar package

You can build a jar with maven like so:

```console
$ mvn clean package
...
...
[INFO] Building jar: /home/pczarkowski/development/spring/library/target/library-0.0.1-SNAPSHOT.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
```

### Build with Docker

If you've already built the jar file you can run:

```console
docker build -t spring/library .
```

Otherwise you can build the jar file using the multistage dockerfile:

```console
docker build -t spring/library -f Dockerfile.build .
```

Either way once built you can run it like so:

```console
$ docker run -ti --rm --name spring-library -p 8080:8080 spring/library
```

### Production ready metrics and visualization
To run the application as well as Prometheus and Grafana dashboard for visualizing metrics you can run all services:

```console
$ docker-compose up
```

If everything goes well, you can access the following services at given location:
* http://localhost:8080/actuator/prometheus - published Micrometer metrics
* http://localhost:9090 - Prometheus dashboard
* http://localhost:3000 - Grafana dashboard

In order to see some metrics, you must create a dashboard. Go to `Create` -> `Import` and select attached `jvm-micrometer_rev8.json`. File has been pulled from 
`https://grafana.com/grafana/dashboards/4701`.

Please note application will be run with `local` Spring profile to setup some initial data.

## References

1. [Introducing EventStorming](https://leanpub.com/introducing_eventstorming) by Alberto Brandolini
2. [Domain Modelling Made Functional](https://pragprog.com/book/swdddf/domain-modeling-made-functional) by Scott Wlaschin
3. [Software Architecture for Developers](https://softwarearchitecturefordevelopers.com) by Simon Brown
4. [Clean Architecture](https://www.amazon.com/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164) by Robert C. Martin
5. [Domain-Driven Design: Tackling Complexity in the Heart of Software](https://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215) by Eric Evans
"
janbodnar/Java-Swing-Examples,master,36,20,2018-03-05T17:18:50Z,500,2,Java Swing code examples,gui java swing,"# Java-Swing-Examples
Java Swing code examples from Java Swing tutorial

Built with OpenJDK 13

https://zetcode.com/javaswing/

### Advanced Java Swing e-book 
https://zetcode.com/ebooks/advancedjavaswing/
"
CasterIO/RxExamples,master,45,14,2016-01-08T13:09:23Z,132,1,Samples from the Rx Episodes on Caster.IO,,
aillamsun/genesis,master,80,49,2016-10-14T03:32:07Z,987,1,Spring cloud Example,distributed-transaction eureka genesis-microservices hystrix-dashboard lcn mapper mybatis pagehelper spring-boot spring-cloud spring-cloud-lcn spring-config swagger-ui zipkin-sleuth zuul-feign,"## Genesis. Is a Spring Cloud Project

------
## 技术架构
genesis 是一个基于Spring cloud(Camden.SR1) Spring Boot(1.4.1.RELEASE) Mybatis(3.3.0) 通用Mapper 通用分页Pagehelper完成的一个基础组件架构，
使用Spring Cloud Eureka、Feign、Zuul、Spring config、Zipkin、Sleuth、Hystrix Turbine、Hystrix Dashboard...
## MAVEN模块说明
#### 1. 基础组件说明
| 项目名称                                     | 端口   | 描述                     | URL             |
| ---------------------------------------- | ---- | ---------------------- | --------------- |
| genesis-common                | 无 | 公共模块（工具类,资源......）            | 无            |
| genesis-core               | 无 | 核心代码               | 无            |
| genesis-model               | 无 | 公共实体对象      
| spar_generator              | 无 | 生成mybatis mapper model实体      
| spar_mapper               | 无 | 抽离的mapper mapper.xml     
------
#### 2. Spring Cloud(genesis-microservices)组件说明
| 项目名称                                     | 端口   | 描述                     | URL             |
| ---------------------------------------- | ---- | ---------------------- | --------------- |
| genesis-microservices-discovery               | 8761 8762 8763 | 服务注册中心(用作和8762 8763实现高可用注册中心)            | 无            |
| genesis-microservices-config               | 8040 | 服务配置中心服务          | 无            |
| genesis-microservices-config-client               | 8041 | 服务配置客户端测试启动访问(ip:port/message打印)            | 无            |
| genesis-microservices-gateway               | 8050 | 服务网关    | 无            |
| genesis-microservices-hystrix-dashboard               | 8051 | 服务监控(Hystrix Dashboard)    | 无            |
| genesis-microservices-hystrix-turbine               | 8052 |  服务监控(Hystrix  Turbine)  | 无            |
| genesis-microservices-monitor               | 8060 | 服务监控(spring boot admin)    | 无            |
| genesis-microservices-security               | 无 | security    | 无            | 
| genesis-microservices-sleuth               | 8092 | 提供测试Zipkin 服务 提供本地、远程调用API    | 无            |
| genesis-microservices-zipkin               | 8091 |Zipkin Server 对Spring Cloud应用进行服务追踪分析(主要和Sleuth)    | 无            |
| genesis-microservices-bus-kafka               | 无 |bus-kafka    | 无            |
| genesis-microservices-bus-amqp                | 无 |bus-amqp    | 无            |
------
#### 3. Spring(genessis-spring)扩展组件说明
| 项目名称                                     | 端口   | 描述                     | URL             |
| ---------------------------------------- | ---- | ---------------------- | --------------- |
| genesis-spring-extends                | 无 | Spring 扩展(更新中...)            | 无            |
| genesis-spring-plugins              | 无 | Spring 插件(更新中...)               | 无            |
| genesis-spring-plugins-mybatis             | 无 | Spring boot mybatis stater自定义(在genesis-provider-goods使用测试)             | 无            |
------
#### 4. Examples(genesis-examples) 提供真是服务使用
| 项目名称                                     | 端口   | 描述                     | URL             |
| ---------------------------------------- | ---- | ---------------------- | --------------- |
| genesis-common-config                | 无 | 通用配置            | 无            |
| genesis-provider-by-feign                | 8080 | API接口(使用Feign 负载均衡)            | 无            |
| genesis-provider-by-ribbon                | 8084 | API接口(使用 Ribbon 负载均衡)            | 无            |
| genesis-provider-by-zuul                | 8085 | API接口网关(使用Zuul)            | 无            |
| genesis-provider-goods              | 8081 | Goods服务提供者(此服务使用了genesis-spring-plugins-mybatis stater)              | 无            |
| genesis-provider-goods2              | 8082 | Goods服务提供者(用于启动测试 API goods模块Feign Client负载均衡)              | 无            
| genesis-provider-order              | 8083 | Order服务提供者              | 无            |
| genesis-sleuth-zipkin-demo              | 8093 | sleuth-zipkin-demo 接口              | 无            |
------
#### 5. 分布式事务Example(更新中....)(genesis-transaction-examples) 提供LCN分布式事务功能实现        |
| 项目名称                                     | 端口   | 描述                     | URL             |
| ---------------------------------------- | ---- | ---------------------- | --------------- |
| tx-manager              | 8010 | 事务管理            | 无            |
| tx-user-ms              | 8011 | 用户服务          | 无            |
| tx-userMoney-ms             | 1012 | 用户金钱管理服务          | 无            |


## 架构图(目前待完善)

后续会更新架构图出去，暂时先这样看着... 焦灼中..........

![Markdown](http://p1.bqimg.com/1949/744b75531ed0a198.png)

## 服务中心HA说明
| 项目名称                                     | 端口   | 描述                     | URL             |
| ---------------------------------------- | ---- | ---------------------- | --------------- |
| genesis-microservices-discovery               | 8761  8762 8763| 服务注册中心)            | 无            |

> * 1,（C:\Windows\System32\drivers\etc\hosts文件）
```java
127.0.0.1 discovery1
127.0.0.1 discovery2
127.0.0.1 discovery3
```
	

> * 2,每个配置里面都有一个application.properties，本机为了方便在idea工具启动  所以使用了两个项目

> * 3,以后线上可以使用一个工程即可 如下：



#### application-chengdu-1.properties
```java
spring.application.name=eureka-server-clustered
server.port=8761
eureka.instance.hostname=discovery1
eureka.client.serviceUrl.defaultZone=http://${security.user.name}:${security.user.password}@discovery2:8762/eureka/,http://${security.user.name}:${security.user.password}@discovery3:8763/eureka/
```

#### application-chengdu-2.properties
```java
spring.application.name=eureka-server-clustered
server.port=8762
eureka.instance.hostname=discovery2
eureka.client.serviceUrl.defaultZone=http://${security.user.name}:${security.user.password}@discovery1:8761/eureka/,http://${security.user.name}:${security.user.password}@discovery3:8763/eureka/
```

#### application-chengdu-3.properties
```java
spring.application.name=eureka-server-clustered
server.port=8763
eureka.instance.hostname=discovery3
eureka.client.serviceUrl.defaultZone=http://${security.user.name}:${security.user.password}@discovery1:8761/eureka/,http://${security.user.name}:${security.user.password}@discovery2:8762/eureka/
```

### 命令启动格式1：
```java
java -jar discovery-1.0.0.jar  --spring.profiles.active=chengdu-1
java -jar discovery-1.0.0.jar --spring.profiles.active=chengdu-2
java -jar discovery-1.0.0.jar --spring.profiles.active=chengdu-3
```


命令修改为：
```java
java -jar discovery-1.0.0.jar
```
	
### 效果图:

### [访问discovery1](http://discovery1:8761)
![discovery1](http://i4.buimg.com/1949/c1c8bed93bd1e784s.jpg)
	

## 监控视图测试

### 使用说明：


#### Spring boot Admin 监控
> * 数据库脚本 genesis-common-config resources/db/下面spring-cloud-test.sql
> * 首先启动：genesis-microservices-monitor 端口 8060
> * 启动 genesis-provider-goods 端口 8081

访问 http://localhost:8060 admin UI
访问 http://localhost:8081/goods
#### 效果图

-----
#### Hystrix-dashboard 监控
> * 数据库脚本 genesis-common-config resources/db/下面spring-cloud-test.sql
> * 首先启动：genesis-microservices-discovery
> * 启动genesis-microservices-hystrix-dashboard 端口 8051
> * 启动genesis-provider-by-feign 端口8080

访问 http://localhost:8051 
在地址栏输入:http://localhost:8080/hystrix.stream

#### 效果图
![效果图](http://i4.buimg.com/1949/0b6e7467b99a1e00.jpg)

-----
#### Hystrix Turbine 监控
> * 数据库脚本 genesis-common-config resources/db/下面spring-cloud-test.sql
> * 首先启动：genesis-microservices-discovery
> * genesis-provider-goods,genesis-provider-order
> * genesis-provider-by-feign,genesis-provider-by-ribbon
> * genesis-microservices-hystrix-dashboard 端口 8051
> * 启动genesis-microservices-hystrix-turbine 端口 8052
> * 分别启动 genesis-provider-goods 端口8081 、genesis-provider-order 端口 8083

访问http://localhost:8051
输入框输入：http://localhost:8052/turbine.stream 
分别访问 feign ribbon 
#### 效果图1
![效果图1](http://i4.buimg.com/1949/38ae38087f6ff6cd.jpg)
确认：
#### 效果图2
![效果图2](http://i4.buimg.com/1949/d4bc21c6f96033b3.jpg)


## 服务跟踪监控Zipkin、Sleuth 测试

### 使用说明：

#### 项目启动
> * 启动 Zipkin Server 服务 genesis-microservices-zipkin 端口 8091
> * 启动 Zipkin Server 服务demo  genesis-microservices-sleuth 端口 8092
> * 启动测试 Zipkin、Sleuth 服务提供者  genesis-sleuth-zipkin-demo 端口 8093
> * 直接调用 8092 Controller接口即可

#### 跟踪列表效果图

![跟踪列表](http://i2.bvimg.com/607995/f0d7b6f6dfcaca6d.jpg)

#### 跟踪详细信息效果图

![跟踪详细信息](http://i2.bvimg.com/607995/e99769c237cb33b6.jpg)

## Zuul 和 Feign 测试

### 使用说明：

#### 1,项目启动：
> * 数据库脚本 genesis-common-config resources/db/下面spring-cloud-test.sql
> * 首先启动：genesis-microservices-discovery
> * 测试Fegin可以启动genesis-provider-by-feign。前提启动genesis-provider-good、genesis-provider-order
> * 测试Zuul可以启动genesis-provider-by-zuul 。前提启动genesis-provider-good、genesis-provider-order
> * genesis-provider-by-feign提供swgger UI 通过API文档Try 就可以了


## API 文档访问测试

### 使用说明：

#### 1,项目启动：
> * 启动API genesis-provider-by-feign访问http://localhost:8080/swagger-ui.html
![Markdown](http://i2.bvimg.com/607995/7d2dd1afb7ee0104.jpg)


## 分布式事务基于Spring Cloud + LCN

### LCN 
    首先感谢LCN提供
[LCN](https://github.com/1991wangliang/tx-lcn)

### 使用说明：
    
#### 1,项目启动：

> * 首先启动 tx-manager
[tx-manager](http://localhost:8100/index)

效果图
![manager](http://i1.bvimg.com/607995/10d7b69bf61f4e10.jpg)

> * 启动 tx-user-ms 和 tx-user-money-ms

#### 测试

> * 访问 http://localhost:8011/user/save

Controller  

```java
@RequestMapping(value = ""/save"",method = RequestMethod.POST)
    public int save() {
        return userService.save();
    }
```


Service

```java
    @TxTransaction
    @Transactional
    public int save() {

        User user = new User();
        user.setUserName(""Test Tx"");
        user.setPassword(""11111"");
        int rs1 = userMapper.insert(user);
        /**
         * 保存 余额 分布式服务
         */
        int rs2 = userMoneyClient.save();

        /**
         * 抛出异常
         */
        int v = 100 / 0;
        return rs1 + rs2;
    }
```


UserMoneyClient

```java
@FeignClient(name = ""genesis-tx-user-money-ms"", configuration = TransactionRestTemplateConfiguration.class)
public interface UserMoneyClient {

    @RequestMapping(value = ""/user-money/save"",method = RequestMethod.POST)
    int save();
}
```
    


"
caprica/vlcj-player,master,172,102,2015-01-28T19:35:22Z,605,3,Feature-rich example vlcj media player,,"*You are currently looking at the development branch of vlcj-player for vlcj-4.0.0, if you want a stable version of
vlcj-player that works with vlcj-3 you should switch to the
[vlcj-3.x branch](https://github.com/caprica/vlcj-player/tree/vlcj-3.x).*

vlcj-player
===========

The vlcj-player is a media player application built using vlcj with a Swing
rich-client user interface. 

The main goal of the project is to provide an extensive demo application 
showing how to build media players with vlcj, and to include as many features
of vlcj as possible.

Generally the vlcj-player tries to match the Qt interface of VLC with as many
of the same features implemented as possible.

However, it is not possible to get a 100% like-for-like implementation since
LibVLC, used by vlcj, exposes only a sub-set of the total functionality of VLC. 

Screenshot
----------

![vlcj-player](https://github.com/caprica/vlcj-player/raw/master/doc/vlcj-player.png ""vlcj-player"")

Features
--------

 - audio player
 - video player
 - full-screen
 - audio equalizer
 - video adjustments
 - title selection
 - chapter navigation
 - audio track selection
 - video track selection
 - subtitle track selection
 - load external subtitle file
 - change audio device
 - change audio stereo mode
 - change playback speed
 - capture and display native logs
 - capture and display video surface debug messages (e.g. to test mouse and keyboard events still work)
 - volume controls
 - mute
 - zoom/scale
 - aspect ratio
 - crop
 - logo/marquee
 - always on top
 - video snapshots
 - drag and drop local files to the main window
 - drag and drop URLs from web browsers to the main window (e.g. to play a YouTube video)
 - redirect native output streams (on Linux)

...and a whole bunch of other nifty stuff.
 

Status
------

This project is currently a work-in-progress.

If you execute ""mvn install"" or ""mvn package"", you will get a distribution
package that you can unpack. This will give you the vlcj-player application jar
and all of the dependencies - you can simply execute `java -jar vlcj-player-1.0.0-SNAPSHOT.jar`
and the application should start.

On the other hand, just run it from an Eclipse project.

License
-------

The vlcj-player project is provided under the GPL, version 3 or later.
"
lczmdr/drools-developers-cookbook-examples,master,29,25,2010-09-24T00:51:00Z,561,0,Drools Developer's Cookbook examples,,
thomasdarimont/keycloak-project-example,main,306,76,2021-04-22T11:48:45Z,26756,20,An example project for Keycloak Customizations,,
mkurz/deadbolt-2-java-examples,main,27,25,2012-12-11T20:12:32Z,323,0,Example usages of Deadbolt 2 Java,,"deadbolt-2-java-examples
=========================

Example usages of Deadbolt 2's Java API.  Deadbolt 2 is an authorisation module for Play 2.

Deadbolt 2 comprises of several modules - a common core, and language-specific implementations for Java and Scala.  Example applications and a user guide are also available.  

All modules related to Deadbolt 2, including the user guide, are grouped together in the [Deadbolt 2](https://github.com/schaloner/deadbolt-2) Github super-module.  Installation information, including Deadbolt/Play compatibility, can also be found here."
mpatric/mp3agic-examples,master,33,23,2013-05-28T08:15:07Z,207,0,Example apps using mp3agic library,,
EsotericSoftware/spine-superspineboy,master,221,86,2014-04-15T08:54:39Z,34746,0,Example platformer game for spine-libgdx.,,"![Super Spineboy](http://i.imgur.com/6jMhdeU.jpg)

Super Spineboy is a platformer game for Windows, Mac and Linux written using [Spine](http://esotericsoftware.com/) and [spine-libgdx](https://github.com/EsotericSoftware/spine-runtimes/tree/master/spine-libgdx). Spine is a 2D animation tool specifically for games and Super Spineboy shows some of the ways to make use of Spine skeletons and animations in an actual game.

[![](http://i.imgur.com/7QMVJmt.png)](https://www.youtube.com/watch?v=zAZ_PxxEgDI)

## Download

Super Spineboy can be [downloaded](http://esotericsoftware.com/files/runtimes/superSpineboy.jar) in binary form and run on Windows, Mac or Linux. Java 1.6+ is required. To run Super Spineboy, double click the `superSpineboy.jar` file or run it from the command line:

```
java -jar superSpineboy.jar
```

## Controls

* Left click shoots toward the mouse position. Hold to keep shooting.
* `A` is left, `D` is right, `W` is jump.
* Alternatively, `left arrow` is left, `right arrow` is right, `space` is jump.
* Press `alt + enter` or click `Fullscreen` in the menu to run the game fullscreen.
* Press the number keys `1` through `6` to control the game speed, allowing you to see how smooth the animations are and the transitions between animations.
* Press `tilda` or `P` to pause.
* Press `Z` to zoom in/out so you can see the animations more easily.

## Gameplay tips

You may find Super Spineboy difficult at first. The game is relatively short, so the difficulty ramps up quickly. These tips may help you overcome the hordes!

* Don't move through further into the level until you've killed all the enemies you find.
* Spineboy's weapon shoots very fast, but suffers from reduced accuracy when shot continuously. Cease firing momentarily to regain accuracy. 
* You cannot shoot backward when running away, but you can jump while running away and shoot backward in the air.
* Standing your ground and mowing down enemies is great, but there are quickly so many enemies that you get overrun. When this happens, goomba head stomp the enemies. This is key to winning!
* Getting sandwiched between two groups of enemies is a sure way to die. Head stomp your way to one side so you aren't surrounded.
* If the game runs poorly, try unchecking `Background` in the menu.

## Source

Super Spineboy is written in Java and uses OpenGL, [libgdx](http://libgdx.badlogicgames.com/), [Spine](http://esotericsoftware.com/) and [spine-libgdx](https://github.com/EsotericSoftware/spine-runtimes/tree/master/spine-libgdx). A loose [MVC](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller) design pattern is used for code organization. This makes for a clean separation between the game logic and what is drawn.

The Super Spineboy source can be downloaded from GitHub using a Git client or as a [zip file](https://github.com/EsotericSoftware/spine-superspineboy/archive/master.zip). To run from source using Eclipse, click `File` -> `Import` -> `Existing projects`.

## License

Super Spineboy is licensed under the [Spine Runtime License](https://github.com/EsotericSoftware/spine-superspineboy/blob/master/LICENSE). Please see the license for full details, but this basically means that if you license [Spine](http://esotericsoftware.com/), you can create derivative works or otherwise use Super Spineboy however you like.

## Screenshots

![](http://i.imgur.com/TQi1qXB.png)

![](http://i.imgur.com/j3RwiU7.png)

![](http://i.imgur.com/Y3uAOSj.png)
"
callstack/repack-examples,main,40,15,2022-07-01T15:30:32Z,1807,7,Repository with examples for Re.Pack,,"# repack-examples

A repository with examples for [Re.Pack](https://github.com/callstack/repack).

## Usage

Install dependencies:

```bash
yarn install
```

Run scripts inside desired example:

```bash
yarn workspace <name> run start
yarn workspace <name> run ios
yarn workspace <name> run android
```

for example:

```bash
yarn workspace local-chunks run start
```
"
camelinaction/camelinaction2,master,609,401,2015-07-06T16:50:52Z,5600,2,:camel: This project hosts the source code for the examples of the Camel in Action 2nd ed book :closed_book: written by Claus Ibsen and Jonathan Anstey.,apache-camel book camel eip integration java microservice,"Camel in Action 2nd Edition
===========================

This project hosts the source code for the examples of the [Camel in Action](https://www.manning.com/books/camel-in-action-second-edition) 2nd edition book written by [Claus Ibsen](https://twitter.com/davsclaus) and [Jonathan Anstey](https://twitter.com/jon_anstey). 

![Camel in Action 2nd ed cover](/docs/images/cia2-cover.png?raw=true)

Table of Contents
-----------------

Part 1 - First Steps

- 1 [Meeting Camel](chapter1)
- 2 [Routing with Camel](chapter2)

Part 2 - Core Camel

- 3 [Transforming data with Camel](chapter3)
- 4 [Using beans with Camel](chapter4)
- 5 [Enterprise integration patterns](chapter5)
- 6 [Using components](chapter6)

Part 3 - Developing and testing

- 7 [Microservices](chapter7)
- 8 [Developing Camel projects](chapter8)
- 9 [Testing](chapter9)
- 10 [RESTful web services](chapter10)

Part 4 - Going further with Camel

- 11 [Error handling](chapter11)
- 12 [Transactions and idempotency](chapter12)
- 13 [Parallel processing](chapter13)
- 14 [Securing Camel](chapter14)

Part 5 - Running and managing Camel

- 15 [Running and deploying Camel](chapter15)
- 16 [Management and monitoring](chapter16)

Part 6 - Out in the Wild

- 17 [Clustering](chapter17)
- 18 [Microservices with Docker and Kubernetes](chapter18)
- 19 [Camel tooling](chapter19)

Bonus Chapters

- 20 [Reactive Camel](chapter20)
- 21 Camel and the IoT by Henryk Konsek (has no source code)

Appendixes

- A Simple, the expression language
- B The Camel community


Downloading the source code
---------------------------

You can either download a .zip with all the source code from the [releases page](https://github.com/camelinaction/camelinaction2/releases), or use the github way of cloning the repository on your computer.

System requirements
---------------------------
You need JDK 8 installed on your system in order to compile the source code.   
Maven version >= 3.5.  
Apache Camel 2.20.1 or newer 2.x version.  

Camel 3.x support is *not* on the main branch, but provided as _best effort_ on [dedicated branches](https://github.com/camelinaction/camelinaction2/branches)

Up to date source code
----------------------

We the authors, intended to keep this source code up to date with future releases of Apache Camel. Giving our readers the best experience with the book and using the latest Camel releases. 


Errata
------
Any mistakes in the book can be reported to us via github issues tracker.
The errata can be [viewed here](errata.txt)

Getting in touch
----------------

To get in touch with the us the authors you can:

* write on the [Manning Author Online forum](https://forums.manning.com/forums/camel-in-action-second-edition)
* reach out to us on twitter: [@davsclaus](https://twitter.com/davsclaus), [@jon_anstey](https://twitter.com/jon_anstey)
* or use the [github issue tracker](https://github.com/camelinaction/camelinaction2/issues)


Happy reading and riding the Camel.

Claus Ibsen, and Jonathan Anstey
"
janbodnar/Java-Advanced,master,46,25,2018-01-12T15:21:37Z,3086,9,Examples for Advanced Java course,advanced-programming course java programming-language,"# Java-Advanced
Examples for Advanced Java course
https://zetcode.com/

Available under 2-Clause BSD License https://opensource.org/licenses/BSD-2-Clause


## VS Code

Extensions:

- Java Platforma Support
- Trailing
- vscode-icons
- Rewrap


The project `settings.json`

```json
{
    ""jdk.runConfig.vmOptions"": ""--enable-preview --source 22"",
    ""jdk.jdkhome"": ""c:\\Users\\Jano\\.jdks\\jdk22.0.0_36"",
}
```


The `settings.json`

```json
{
    ""editor.rulers"": [
        80
    ],
    ""workbench.iconTheme"": ""vscode-icons"",
    ""terminal.integrated.defaultProfile.windows"": ""Command Prompt"",
    ""jdk.jdkhome"": ""c:\\Users\\Jano\\.jdks\\jdk22.0.0_36"",
    ""editor.stickyScroll.enabled"": false,
    ""editor.minimap.enabled"": false,
}
"
lynxbroker/API-examples,master,28,16,2019-06-06T07:04:12Z,2552,0,Code samples that show some of the LYNX API possible implementations,automated-trading ibapi lynx-api trading-algorithms,"# LYNX API examples

Code samples that show some of the LYNX API possible implementations.  



### Table of contents
- [**Excel**](https://github.com/lynxbroker/API-examples/tree/master/Excel) - request real-time market data from TWS via API using Microsoft Excel
- [**Java**](https://github.com/lynxbroker/API-examples/tree/master/Java) - code samples of the API integration with Java & [*quickstart*](https://github.com/lynxbroker/API-examples/tree/master/Java/quickstart) application
- [**Python**](https://github.com/lynxbroker/API-examples/tree/master/Python) - code samples of the API integration with Python



---
##### For more information in regard to the API Documentation, visit our [website](https://api.lynx.academy).

---



<p align=""center"">
  <img src=""Java/place_order/images/logo_cover.svg"">
</p>
"
RameshMF/jsp-servlet-jdbc-mysql-crud-tutorial,master,133,151,2019-03-10T06:19:51Z,2477,5,JSP Servlet JDBC MySQL CRUD Example Tutorial,,"# jsp-servlet-jdbc-mysql-crud-tutorial
JSP Servlet JDBC MySQL CRUD Example Tutorial 

https://www.javaguides.net/2019/03/jsp-servlet-jdbc-mysql-crud-example-tutorial.html
"
Petikoch/Java_MVVM_with_Swing_and_RxJava_Examples,master,110,30,2015-09-11T13:03:19Z,2343,3,"Explorative Java Swing GUI example code from 2016 with an implementation of MVVM (Model View ViewModel) using RxJava and RxSwing. DON'T use it in production, there are some open issues here!",java mvvm rxjava swing-gui,
eljefe6a/beamexample,master,111,75,2016-07-26T05:40:13Z,1434,4,An example Apache Beam project.,,"# Apache Beam Example Code

An example Apache Beam project.

### Description

This example can be used with conference talks and self-study. The base of the examples are taken from Beam's `example` directory. They are modified to use Beam as a dependency in the `pom.xml` instead of being compiled together. The example code is changed to output to local directories.

## How to clone and run

1. Open a terminal window.
1. Run `git clone git@github.com:eljefe6a/beamexample.git`
1. Run `cd beamexample/BeamTutorial`
1. Run `mvn compile`
1. Create local output directory: `mkdir output`
1. Run `mvn compile exec:java -Dexec.mainClass=""org.apache.beam.examples.tutorial.game.solution.Exercise1"" -Pdirect-runner`
1. Run `cat output/user_score` to verify the program ran correctly and the output file was created.

### Using a Java IDE

1. Follow the [IDE Setup](http://beam.incubator.apache.org/contribute/contribution-guide/#optional-ide-setup) instructions on the Apache Beam Contribution Guide.

## Other Runners

### Apache Flink

1. Follow the first steps from [Flink's Quickstart](https://ci.apache.org/projects/flink/flink-docs-release-1.1/quickstart/setup_quickstart.html) to [download Flink](https://ci.apache.org/projects/flink/flink-docs-release-1.1/quickstart/setup_quickstart.html#download).
1. Create the `output` directory.
1. To run on a JVM-local cluster: `mvn compile exec:java -Dexec.mainClass=org.apache.beam.examples.tutorial.game.solution.Exercise1 -Dexec.args='--runner=FlinkRunner --flinkMaster=[local]'  -Pflink-runner`
1. To run on an out-of-process local cluster (note that the steps below should also work on a real cluster if you have one running):
   1. [Start a local Flink cluster](https://ci.apache.org/projects/flink/flink-docs-release-1.1/quickstart/setup_quickstart.html#start-a-local-flink-cluster).
   1. Navigate to the WebUI (typically [http://localhost:8081](http://localhost:8081)), click [JobManager](http://localhost:8081/#/jobmanager/config), and note the value of `jobmanager.rpc.port`. The default is probably 6123.
   1. Run `mvn package -Pflink-runner` to generate a JAR file. Note the location of the generated JAR (probably `./target/BeamTutorial-bundled-flink.jar`)
   1. Run `mvn -X -e compile exec:java -Dexec.mainClass=org.apache.beam.examples.tutorial.game.solution.Exercise1 -Dexec.args='--runner=FlinkRunner --flinkMaster=localhost:6123 --filesToStage=./target/BeamTutorial-bundled-flink.jar' -Pflink-runner`, replacing the defaults for port and JAR file if they differ.
   1. Check in the [WebUI](http://localhost:8081) to see the job listed.
1. Run `cat output/user_score` to verify the pipeline ran correctly and the output file was created.

### Apache Spark

1. Create the `output` directory.
1. Allow all users (Spark may run as a different user) to write to the `output` directory. `chmod 1777 output`.
1. Change the output file to a fully-qualified path. For example, `this(""output/user_score"");` to `this(""/home/vmuser/output/user_score"");`
1. Run `mvn package -Pspark-runner`
1. Run `spark-submit --jars ./target/BeamTutorial-bundled-spark.jar --class org.apache.beam.examples.tutorial.game.solution.Exercise2 --master yarn-client ./target/BeamTutorial-bundled-spark.jar --runner=SparkRunner`


### Google Cloud Dataflow

1. Follow the steps in either of the [Java quickstarts for Cloud Dataflow](https://cloud.google.com/dataflow/docs/quickstarts) to initialize your Google Cloud setup.
1. [Create a bucket](https://cloud.google.com/storage/docs/creating-buckets) on Google Cloud Storage for staging and output.
1. Run `mvn -X compile exec:java -Dexec.mainClass=""org.apache.beam.examples.tutorial.game.solution.Exercise1"" -Dexec.args='--runner=DataflowRunner --project=<YOUR-GOOGLE-CLOUD-PROJECT> --gcpTempLocation=gs://<YOUR-BUCKET-NAME> --outputPrefix=gs://<YOUR-BUCKET-NAME>/output/'  -Pdataflow-runner`, after replacing `<YOUR-GCP-PROJECT>` and `<YOUR-BUCKET-NAME>` with the appropriate values.
1. Check the [Cloud Dataflow Console](https://console.cloud.google.com/dataflow) to see the job running.
1. Check the output bucket to see the generated output: `https://console.cloud.google.com/storage/browser/<YOUR-BUCKET-NAME>/`

## Further Reading

* The World Beyond Batch Streaming [Part 1](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) and [Part 2](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102)
* [Future-Proof Your Big Data Processing with Apache Beam](http://thenewstack.io/apache-beam-will-make-big-difference-organization/)
* [Future-proof and scale-proof your code](https://www.oreilly.com/ideas/future-proof-and-scale-proof-your-code)
* [Question and Answers with the Apache Beam Team](http://www.jesse-anderson.com/2016/07/question-and-answers-with-the-apache-beam-team/)
"
USCDataScience/dl4j-kerasimport-examples,master,27,28,2017-02-12T02:12:12Z,86643,0,This repository contains deeplearning4j examples for importing and making use of models trained in keras,,"# DL4J Keras Import Examples

This repository contains deeplearning4j examples for importing and making use of models trained in keras

# Index
+ `deep-learning-models` contains popular deep learning models implemented in keras  
+ `dl4j-import-example` contains examples for importing keras models to deeplearning4j, 
 first example: an image classifier based on InceptionV3 net.
"
ypriverol/spark-java8,master,42,35,2015-10-21T22:31:45Z,618,0,Java 8 and Spark learning through examples ,dataset java lambda learning-spark spark,"# Java 8 and Spark Learning tutorials

This is a collection of [Java 8](http://www.oracle.com/technetwork/java/javase/overview/java8-2100321.html) and [Apache Spark](http://spark.apache.org/) examples and concepts,
from basic to advanced. It explain basic concepts introduced by Java 8 and how you can merge them with Apache Spark.

The current tutorial or set of examples provide a way of understand Spark 2.0 in details but also to get familiar with
Java 8 and it new features like lambda, Stream and reaction programming.

## Why Java 8

Java 8 is the latest version of Java which includes two major changes: Lambda expressions and Streams. Java 8 is a revolutionary release of the world’s #1 development platform.
It includes a huge upgrade to the Java programming model and a coordinated evolution of the JVM, Java language, and libraries. Java 8 includes features for productivity,
ease of use, improved polyglot programming, security and improved performance. Welcome to the latest iteration of the largest, open, standards-based, community-driven platform.

 1- Lambda Expressions, a new language feature, has been introduced in this release. They enable you to treat functionality as a method argument, or code as data.
    Lambda expressions let you express instances of single-method interfaces (referred to as functional interfaces) more compactly.

 2- Classes in the new java.util.stream package provide a Stream API to support functional-style operations on streams of elements. The Stream API is integrated into the Collections API,
    which enables bulk operations on collections, such as sequential or parallel map-reduce transformations including performance improvement for HashMaps with Key Collisions.

## Why Spark

[Apache Spark™](http://spark.apache.org/) is a fast and general engine for large-scale data processing. Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java,
Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine
learning, GraphX for graph processing, and Spark Streaming.

## Instructions

A good way of using these examples is by first cloning the repo, and then
starting your own [Spark Java 8](http://github.con/ypriverol/spark-java8).

### Installing Java 8 and Spark

Java 8 can be download [here](http://www.oracle.com/technetwork/java/javase/overview/java8-2100321.html). After the installation
you need to be sure that the version you are using is java 8, you can check that by running:

```bach
java -version
```

In order to setup Spark locally in you machine you should download the spark version from [here](http://spark.apache.org/downloads.html). Then you should follow the next steps:

```bach
> tar zxvf spark-xxx.tgz
> cd spark-xxx
> build/mvn -DskipTests clean package
```

After the compilation and before running your first example you should add to your profile the [SPARK MASTER Variable](http://spark.apache.org/docs/latest/spark-standalone.html):

```bach
 > export SPARK_LOCAL_IP=127.0.0.1
```
To be sure that you spark is installed properly in your machine you can run the first example from spark:

```bach
> ./bin/run-example SparkPi
```

## Datasets

Some of the datasets we will use in this learning tutorial are:
  - Tweets Archive from [@ypriverol](https://twitter.com/ypriverol) is used in the word count
  - We will be using datasets from the [KDD Cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html). The results
    of this competition can be found [here](http://cseweb.ucsd.edu/~elkan/clresults.html).

## References

The reference book for these and other Spark related topics is:

- *Learning Spark* by Holden Karau, Andy Konwinski, Patrick Wendell, and Matei Zaharia.

## Examples

The following examples can be examined individually, although there is a more or less linear 'story' when followed in sequence. By using different datasets they try to solve a related set of tasks with it.

### [RDD Basic Examples](https://github.com/ypriverol/spark-java8/wiki/2-RDD-Basic-Examples)

Here a list of the most basic examples in Spark-Java8 and definition of the most basic concepts in Spark.

 1- [SparkWordCount](https://github.com/ypriverol/spark-java8/wiki/2.1--Spark-Word-Count): About How to create a simple JavaRDD in Spark.
 
 2- [MaptoDouble](https://github.com/ypriverol/spark-java8/wiki/2.2-Map-To-Double): How to generate general statistics about an RDD in Spark
 
 3- [SparkAverage](https://github.com/ypriverol/spark-java8/wiki/2.3-Spark-Average): How to compute the average of a set of numbers in Spark.

### [RDD Sampling Examples](https://github.com/ypriverol/spark-java8/wiki/3-Spark-Sampling-Examples)

 1- [SparkSampling](https://github.com/ypriverol/spark-java8/wiki/3.1-SparkSampling): Basic Spark Sampling using functions sample and takesample.  
"
gephi/gephi-plugins-bootcamp,master,69,129,2011-11-20T22:53:20Z,111771,2,Out of the box plug-ins development suite. Contains examples for all types of plug-ins.,,"# Gephi Plugins Bootcamp

Get started with the [Gephi](http://gephi.org) Platform and start to create [Gephi Plugins](https://gephi.org/plugins/#/) by looking at these examples.

The Gephi Plugins Bootcamp is the best sources of examples and good practices to create all types of plug-ins (layout, filter, io, visualization, ...). Consult the [**Javadoc**](https://gephi.org/javadoc/0.9.3/) to discover the different APIs. Documentation is also available on the [Gephi Plugins](https://github.com/gephi/gephi-plugins) repository.

![Gephi Plugins Bootcamp](http://gephi.org/images/plugins_ribbon.png)

## What's inside?

Complete list of the plug-ins examples included in the bootcamp:

### Layout

* **Grid Layout**
	* Place all nodes in a simple grid. Users can configure the size of the area and the speed.

* **Sorted Grid Layout** 
	* Same example as Grid Layout but users can sort nodes with an attribute column.

### Filter

* **Transform to Undirected** 
	* Edge filter to remove mutual edges in a directed graph.

* **Top nodes** 
	* Keep the top K nodes using an attribute column.

* **Remove Edge Crossing** 
	* Example of a complex filter implementation which removes edges until no crossing occurs.

### Tool

* **Find** 
	* Tool with an autocomplete text field to find any node based on labels and zoom by it.

* **Add Nodes** 
	* Listen to mouse clicks and adds nodes. Also adds edges if selecting other nodes.

### Export

* **JPG Export** 
	* Vectorial export to the JPG image format. Contains a settings panel to set the width and height.

* **SQLite Database Export** 
	* Current graph export to a SQLite Database file. A new sub-menu is added in the Export menu and an example of a custom exporter is shown.

### Preview

* **Highlight Mutual Edges** 
	* Colors differently mutual edges. Overwrites and extends the default edge renderer.

* **Glow Renderer** 
	* Adds a new renderer for node items which draws a glow effect around nodes.

* **Node Z-ordering** 
	* Extends the default node builder by reordering the node items by size or any number columns. Also shows how to create complex Preview UI.
	
* **Square shaped nodes** 
	* Demonstrates how to extend and replace a default renderer. Extends node default renderer to support square shaped nodes.

### Import

* **Matrix Market Importer** 
	* File importer for the Matrix Market format.

### Statistic

* **Count Self-Loop** 
	* Example of a statistics result at the global level. Simply counts the number of self-loop edges in the graph.

* **Average Euclidean Distance** 
	* Example of a per-node calculation. For a given node it calculates the average distance to others.

### Generator

* **Simple generator**
	* Hello world generator which creates a two nodes network.

* **Streaming generator**
	* Shows how to create a continuous generator using threads.
	
### Data laboratory

* **Interactive sparkline**
	* Table cell action that shows an interactive sparkline of a number list or dynamic number.
	
* **Convert column to dynamic**
	* Column action that replaces a column with its dynamic equivalent with a defined interval.
	
* **Invert row selection**
	* General action (plugin) that inverts the current table row selection.
	
* **Equal values merge strategy**
	* Column merge strategy that creates a new boolean column with values indicating if the two given columns have the same value.
	
* **Set node(s) color**
	* Nodes action that edits the color of one or more nodes

### Plugins sub-menu

* **Test action** 
	* Simple action which display a message and a dialog.

* **Remove self loops** 
	* Action which accesses the graph and remove self-loops, if any.

* **Using Progress and Cancel** 
	* Action which creates a long task and execute it with progress and cancel support.

### Execute at startup

* **When UI is ready** 
	* Do something when the UI finished loading.

* **Workspace select events** 
	* Do something when a workspace is selected.

### Processor

* **Initial Position** 
	* Set up the nodes' initial position always the same. It calculates a hash with all nodes so the X/Y position is randomized always in the same way.

### New Panel

* **New panel** 
	* Example of a new panel plugin set up at the ranking position.
"
bezkoder/spring-boot-login-example,master,160,106,2021-12-14T10:16:50Z,109,2,"Spring Boot Login and Registration example with MySQL, JWT, Rest Api - Spring Boot Spring Security Login example",authentication authorization jwt jwt-auth jwt-authentication jwt-authorization jwt-token login mysql rest-api spring-boot spring-data-jpa spring-security token-based-authentication,"# Spring Boot Login example with Spring Security, MySQL and JWT
Build a Spring Boot Login and Registration example (Rest API) that supports JWT with HttpOnly Cookie. You’ll know:

- Appropriate Flow for User Login and Registration with JWT and HttpOnly Cookies
- Spring Boot Rest Api Architecture with Spring Security
- How to configure Spring Security to work with JWT
- How to define Data Models and association for Authentication and Authorization
- Way to use Spring Data JPA to interact with MySQL Database

## User Registration, Login and Authorization process.

![spring-boot-login-example-flow](spring-boot-login-example-flow.png)

## Spring Boot Server Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-login-example-architecture](spring-boot-login-example-architecture.png)

For more detail, please visit:
> [Spring Boot Login example with MySQL and JWT](https://www.bezkoder.com/spring-boot-login-example-mysql/)

> [For H2 Embedded database](https://www.bezkoder.com/spring-boot-security-login-jwt/)

> [For MongoDB](https://www.bezkoder.com/spring-boot-jwt-auth-mongodb/)

Working with Front-end:
> [Angular 12](https://www.bezkoder.com/angular-12-jwt-auth-httponly-cookie/) / [Angular 13](https://www.bezkoder.com/angular-13-jwt-auth-httponly-cookie/) / [Angular 14](https://www.bezkoder.com/angular-14-jwt-auth/) / [Angular 15](https://www.bezkoder.com/angular-15-jwt-auth/) / [Angular 16](https://www.bezkoder.com/angular-16-jwt-auth/) / [Angular 17](https://www.bezkoder.com/angular-17-jwt-auth/)

> [React](https://www.bezkoder.com/react-login-example-jwt-hooks/) / [React Redux](https://www.bezkoder.com/redux-toolkit-auth/)

## Dependency
– If you want to use PostgreSQL:
```xml
<dependency>
  <groupId>org.postgresql</groupId>
  <artifactId>postgresql</artifactId>
  <scope>runtime</scope>
</dependency>
```
– or MySQL:
```xml
<dependency>
  <groupId>com.mysql</groupId>
  <artifactId>mysql-connector-j</artifactId>
  <scope>runtime</scope>
</dependency>
```
## Configure Spring Datasource, JPA, App properties
Open `src/main/resources/application.properties`
- For PostgreSQL:
```
spring.datasource.url= jdbc:postgresql://localhost:5432/testdb
spring.datasource.username= postgres
spring.datasource.password= 123

spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation= true
spring.jpa.properties.hibernate.dialect= org.hibernate.dialect.PostgreSQLDialect

# Hibernate ddl auto (create, create-drop, validate, update)
spring.jpa.hibernate.ddl-auto= update

# App Properties
bezkoder.app.jwtCookieName= bezkoder
bezkoder.app.jwtSecret= ======================BezKoder=Spring===========================
bezkoder.app.jwtExpirationMs= 86400000
```
- For MySQL
```
spring.datasource.url= jdbc:mysql://localhost:3306/testdb?useSSL=false
spring.datasource.username= root
spring.datasource.password= 123456

spring.jpa.properties.hibernate.dialect= org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.hibernate.ddl-auto= update

# App Properties
bezkoder.app.jwtCookieName= bezkoder
bezkoder.app.jwtSecret= ======================BezKoder=Spring===========================
bezkoder.app.jwtExpirationMs= 86400000
```
## Run Spring Boot application
```
mvn spring-boot:run
```

## Run following SQL insert statements
```
INSERT INTO roles(name) VALUES('ROLE_USER');
INSERT INTO roles(name) VALUES('ROLE_MODERATOR');
INSERT INTO roles(name) VALUES('ROLE_ADMIN');
```

## Refresh Token

[Spring Boot Refresh Token with JWT example](https://www.bezkoder.com/spring-boot-refresh-token-jwt/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Rest Controller Unit Test with @WebMvcTest](https://www.bezkoder.com/spring-boot-webmvctest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Associations:
> [JPA/Hibernate One To Many example in Spring Boot](https://www.bezkoder.com/jpa-one-to-many/)

> [JPA/Hibernate Many To Many example in Spring Boot](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA/Hibernate One To One example in Spring Boot](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)

## Fullstack CRUD App

> [Vue.js + Spring Boot + H2 Embedded database example](https://www.bezkoder.com/spring-boot-vue-js-crud-example/)

> [Vue.js + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-vue-js-mysql/)

> [Vue.js + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-vue-js-postgresql/)

> [Angular 8 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-spring-boot-postgresql/)

> [Angular 10 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-10-spring-boot-crud/)

> [Angular 10 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-10-spring-boot-postgresql/)

> [Angular 11 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-11-spring-boot-crud/)

> [Angular 11 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-11-spring-boot-postgresql/)

> [Angular 12 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-12-spring-boot-crud/)

> [Angular 12 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-12-spring-boot-mysql/)

> [Angular 12 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-12-spring-boot-postgresql/)

> [Angular 13 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-13-crud/)

> [Angular 13 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-13-mysql/)

> [Angular 13 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-13-postgresql/)

> [Angular 14 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-14-crud/)

> [Angular 14 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-14-mysql/)

> [Angular 14 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-14-postgresql/)

> [Angular 15 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-15-crud/)

> [Angular 15 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-15-mysql/)

> [Angular 15 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-15-postgresql/)

> [Angular 16 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-16-crud/)

> [Angular 16 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-16-mysql/)

> [Angular 16 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-16-postgresql/)

> [Angular 17 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-17-crud/)

> [Angular 17 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-17-mysql/)

> [Angular 17 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-17-postgresql/)

> [React + Spring Boot + MySQL example](https://www.bezkoder.com/react-spring-boot-crud/)

> [React + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-react-postgresql/)

> [React + Spring Boot + MongoDB example](https://www.bezkoder.com/react-spring-boot-mongodb/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://www.bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React.js with Spring Boot Rest API](https://www.bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue.js with Spring Boot Rest API](https://www.bezkoder.com/integrate-vue-spring-boot/)
"
politrons/reactive,master,316,57,2015-09-08T06:11:22Z,1546,6,Reactive: Examples of the most famous reactive libraries that you can find in the market.,akka flow flux java reactivestreams reactivex reactor rsocket rxjava spring stream,"Author Pablo Picouto Garcia

Is this repo useful? Please ⭑Star this repository and share the love.

Here we cover with examples the most famous [reactive](https://www.reactivemanifesto.org/) libraries that you can find
in the market.

## ReactiveX

![My image](src/main/resources/img/reactivex.png)

Marble diagrams are not clear enough?.

Here we cover with some practical examples, the most common use of
the [ReactiveX](https://github.com/ReactiveX/RxJava/wiki) platform for Java.

RxScala examples [here](https://github.com/politrons/reactiveScala)

* **Contactable**

  ![My image](src/main/resources/img/rsz_publishconnectc.png)
    * [HotObservable](src/test/java/rx/observables/connectable/HotObservable.java)

* **Combining**

  ![My image](src/main/resources/img/rsz_1zipo.png)
    * [Chain](src/test/java/rx/observables/combining/ObservableChain.java)
    * [Concat](src/test/java/rx/observables/combining/ObservableConcat.java)
    * [Merge](src/test/java/rx/observables/combining/ObservableMerge.java)
    * [Zip](src/test/java/rx/observables/combining/ObservableZip.java)
    * [Switch](src/test/java/rx/observables/combining/ObservableSwitch.java)

* **Creating**

  ![My image](src/main/resources/img/rsz_1createc.png)
    * [Create](src/test/java/rx/observables/creating/ObservableCreate.java)
    * [Defer](src/test/java/rx/observables/creating/ObservableDefer.java)
    * [Interval](src/test/java/rx/observables/creating/ObservableInterval.java)
    * [Subscription](src/test/java/rx/observables/creating/ObservableSubscription.java)

* **Filtering**

  ![My image](src/main/resources/img/rsz_1filter.png)
    * [Debounce](src/test/java/rx/observables/filtering/ObservableDebounce.java)
    * [Distinct](src/test/java/rx/observables/filtering/ObservableDistinct.java)
    * [Skip](src/test/java/rx/observables/filtering/ObservableSkip.java)
    * [Take](src/test/java/rx/observables/filtering/ObservableTake.java)
    * [First](src/test/java/rx/observables/filtering/ObservableFirst.java)
    *[Run java classes](src/test/java/java11/HelloWorld11.java)


* **Transforming**

  ![My image](src/main/resources/img/rsz_flatmap.png)
    * [Map](src/test/java/rx/observables/transforming/ObservableMap.java)
    * [FlatMap](src/test/java/rx/observables/transforming/ObservableFlatMap.java)
    * [GroupBy](src/test/java/rx/observables/transforming/ObservableGroupBy.java)
    * [Scan](src/test/java/rx/observables/transforming/ObservableScan.java)
    * [Collect](src/test/java/rx/observables/transforming/ObservableCollect.java)
    * [Buffer](src/test/java/rx/observables/transforming/ObservableBuffer.java)
    * [Window](src/test/java/rx/observables/transforming/ObservableWindow.java)
    * [Compose](src/test/java/rx/observables/transforming/ObservableCompose.java)

* **Scheduler**

  ![My image](src/main/resources/img/rsz_2subscribeonc.png)
    * [Asynchronous](src/test/java/rx/observables/scheduler/ObservableAsynchronous.java)

* **Errors**

  ![My image](src/main/resources/img/rsz_2subscribeonc.png)
    * [Exceptions](src/test/java/rx/observables/errors/ObservableExceptions.java)

* **Utils**
    * [Delay](src/test/java/rx/observables/utils/ObservableDelay.java)
    * [AmbConditional](src/test/java/rx/observables/utils/ObservableAmbConditional.java)
    * [Cache](src/test/java/rx/observables/utils/ObservableCache.java)
    * [ToBlocking](src/test/java/rx/observables/utils/ObservableToBlocking.java)

* **Single**
  An Observable that just emit 1 item through the pipeline.
    * [SingleFeatures](src/test/java/rx/single/SingleFeatures.java)

* **Relay**
  A subject which subscribe observers and keep the pipeline open all the time.
    * [Relay](src/test/java/rx/relay/Relay.java)

## Spring Reactor

![My image](src/main/resources/img/reactor.png)

The reactive stream API implementation of Spring.

![My image](src/main/resources/img/rsz_1createc.png)

* [Creating](src/test/java/reactor/ReactorCreating.java)

![My image](src/main/resources/img/rsz_1zipo.png)

* [Combining](src/test/java/reactor/ReactorCombining.java)

![My image](src/main/resources/img/rsz_flatmap.png)

* [Transforming](src/test/java/reactor/ReactorTransforming.java)

![My image](src/main/resources/img/rsz_1filter.png)

* [Filtering](src/test/java/reactor/ReactorFiltering.java)

![My image](src/main/resources/img/rsz_2subscribeonc.png)

* [Async](src/test/java/reactor/ReactorAsync.java)

## Akka

![My image](src/main/resources/img/akka.png)

Implementation of Akka patterns using Akka typed, using Java DSL.

* [patterns](src/test/java/akka/AkkaFeatures.java)

## Akka Stream

The reactive stream API implementation of Akka.

* [Source, Flow, Sink](https://github.com/politrons/Akka/blob/master/src/main/scala/stream/AkkaStream.scala)
* [Subscriber](https://github.com/politrons/Akka/blob/master/src/main/scala/stream/Subscriber.scala)
* [Back-pressure](https://github.com/politrons/Akka/blob/master/src/main/scala/stream/BackPressure.scala)
* [GraphDSL](https://github.com/politrons/Akka/blob/master/src/main/scala/stream/Graphs.scala)

## RSocket

![My image](src/main/resources/img/rsocket.png)

Binary protocol for use on byte stream transports.

* [Fire and Forget](src/test/java/rsocket/RSocketFireAndForget.java)
* [Request Response](src/test/java/rsocket/RSocketRequestResponse.java)
* [Request Stream](src/test/java/rsocket/RSocketRequestStream.java)
* [Request Channel](src/test/java/rsocket/RSocketRequestChannel.java)

## Quarkus

![My image](src/main/resources/img/quarkus_logo.png)

Example of most important features of the red hat framework.

* [features](quarkus/)

## Micronaut

![My image](src/main/resources/img/micronaut.png)

A modern, JVM-based, full-stack framework for building modular, easily testable microservice and serverless
applications.

* [features](https://github.com/politrons/micronaut)

## Oracle Helidon

![My image](src/main/resources/img/helidon.png)

Helidon is a collection of Java libraries for writing microservices that run on a fast web core powered by Netty.

* [WebClient / WebServer](src/test/java/helidon/HelidonWebServer.java)
* [Reactive Messaging](src/test/java/helidon/HelidonReactiveMessaging.java)
* [Kafka connector](src/test/java/helidon/HelidonKafka.java)
* [Scheduler](src/test/java/helidon/HelidonScheduler.java)

##  

![My image](src/main/resources/img/vavr.png)

Example of most important features of this functional programing library for Java.

* [effects](src/test/java/vavr/VavrEffects.java)
* [Functions](src/test/java/vavr/VavrFunctions.java)
* [Collections](src/test/java/vavr/VavrCollections.java)
* [Pattern matching](src/test/java/vavr/VavrPatternMatching.java)
* [Future](src/test/java/vavr/VavrFuture.java)

## Category Theory

![My image](src/main/resources/img/pure.png)

Example of Monad implementation for Java.

* [monad](src/test/java/effects/PolEffectSystem.java)


## ![My image](src/main/resources/img/curator-logo.png)

Apache Curator is a Java/JVM client library for Apache ZooKeeper, a distributed coordination service.

* [distributed lock and counter](src/test/java/curator/ApacheCuratorFeature.java)

## Reactive Stream Monads combination

A Combination of Monads that implement Reactive Stream.

* [ReactiveStream](src/test/java/ReactiveMonadsCombinations.java)

## Observer V Iterator Pattern

An explanation, comparative and benchmark between these two patterns.

* [ObserverVsIterator](src/test/java/rx/utils/ObserverVsIterator.java)

## RxJava V Spring Reactor

A Comparative and benchmark between these two frameworks.

* [ReactorVsRx](src/test/java/rx/utils/ReactorVsRx.java)

## Java 8

![My image](src/main/resources/img/rsz_stream.jpg)

* [Stream](src/test/java/java8/StreamUtils.java)
* [Functions](src/test/java/java8/Functions.java)
* [CompletableFuture](src/test/java/java8/CompletableFutureFeature.java)

## Java 9

![My image](src/main/resources/img/java-9.png)

* [Flow](src/test/java/java9/FlowFeatures.java)
* [Features](src/test/java/java9/UtilFeatures.java)
* [Optional](src/test/java/java9/OptionalImprovements.java)
* [Module system](src/test/java/module-info.java.bak)

## Java 10

![My image](src/main/resources/img/10.png)

* [Collections](src/test/java/java10/Collections.java)
* [Local variable type inference](src/test/java/java10/LocalVariableTypeInference.java)

## Java 11

![My image](src/main/resources/img/11.png)

* [HttpClient2](src/test/java/java11/HttpClient2Feature.java)
* [String](src/test/java/java11/StringFeatures.java)
* [File](src/test/java/java11/FileFeatures.java)
* [Collection](src/test/java/java11/CollectionFeatures.java)
* [Local variable](src/test/java/java11/LocalVariableFeature.java)

## Java 12

![My image](src/main/resources/img/12.png)

* [Switch Expression](https://github.com/politrons/reactive/blob/master/src/test/java/java12/Java12Features.java#L16)
* [String API](https://github.com/politrons/reactive/blob/master/src/test/java/java12/Java12Features.java#L50)
* [JVM Constants API](https://github.com/politrons/reactive/blob/master/src/test/java/java12/Java12Features.java#L101)

## Java 14

![My image](src/main/resources/img/j14.png)

* [Pattern matching](https://github.com/politrons/reactive/blob/master/src/test/java/java14/Java14Features.java#L11)
* [Multiline text](https://github.com/politrons/reactive/blob/master/src/test/java/java14/Java14Features.java#L31)
* [Record type](https://github.com/politrons/reactive/blob/master/src/test/java/java14/Java14Features.java#L54)

## Java 15

* [Sealed class](src/test/java/java15/Java15Features.java)

## Java 16

![My image](src/main/resources/img/16.png)

* [Features](src/test/java/java16/Java16Features.java)

## Java 17

![My image](src/main/resources/img/j17.jpg)

* [Features](src/test/java/java17/Java17Features.java)

## Java 18

Project Loom feature

* [Features](src/test/java/loom/LoomFeatures.java)

## Java 19

Pattern matching improvements & Virtual Thread

* [Features](src/test/java/java19/Java19Features.java)

## ![My image](src/main/resources/img/eclipse.png)

Eclipse Collections is one of the best Java collections framework ever that brings happiness to your Java development.

* [feature](src/test/java/eclipse_collection/EclipseCollectionFeature.java)

## ![My image](src/main/resources/img/kafka.png)

Examples of patterns using Apache Kafka.

* **[Throttling](kafka/src/test/java/com/politrons/kafka/KafkaThrottling.java)**
* **[Assign](kafka/src/test/java/com/politrons/kafka/KafkaAssignment.java)**
* **[Stream](kafka/src/test/java/com/politrons/kafka/KafkaStreamFeature.java)**
* **[balancing](kafka/src/test/java/com/politrons/kafka/KafkaBalancing.java)**
* **[Sagas](kafka/src/test/java/com/politrons/kafka/sagas/KSaga.java)**
* **[Delay](kafka/src/test/java/com/politrons/kafka/KafkaDelay.java)**
* **[AdminClient](kafka/src/test/java/com/politrons/kafka/KafkaAdminClient.java)**

## Software craftsmanship

* [(S)ingle responsibility principle](src/test/java/good_practices/SRP.java)
* [(O)pen/Closed principle](src/test/java/good_practices/OpenClosedPrinciple.java)
* [(L)iskov substitution principle](src/test/java/good_practices/LiskovSubstitutionPrinciple.java)
* [(I)nterface segregation principle](src/test/java/good_practices/InterfaceSegregationPrinciple.java)
* [(D)on't repeat yourself](src/test/java/good_practices/DRY.java)

## Programs

* [PaymentAPI:](https://github.com/politrons/PaymentAPI) A Reactive microservice with DDD + CQRS + Event Sourcing
* [Reactive StarWars](https://github.com/politrons/reactiveStarWars) A Star wars reactive microservice platform, formed
  by four services
"
lkrnac/book-eiws-code-samples,master,107,63,2015-03-16T18:53:45Z,1998,0,Examples for book Pivotal Certified Spring Enterprise Integration Specialist Exam A Study Guide,,"[ ![Codeship Status for lkrnac/book-eiws-code-samples](https://codeship.com/projects/3d6d0a40-ae3f-0132-7ed9-2ecd9a04cc80/status?branch=master)](https://codeship.com/projects/68847)

Examples for book **Pivotal Certified Spring Enterprise Integration Specialist Exam A Study Guide** http://www.apress.com/9781484207949

# More information
http://lkrnac.net/blog/2015/10/enterprise-spring-examples-and-integration-tests

# Build
    cd 0000-examples-parent
    mvn clean install
    cd ../0000-examples
    mvn clean install

# Possible first time build error
Error message:

    [ERROR] Failed to execute goal org.hornetq:hornetq-maven-plugin:1.2.0:start (start) on project 0501-jms11-jndi: Execution start of goal org.hornetq:hornetq-maven-plugin:1.2.0:start failed: A required class was missing while executing org.hornetq:hornetq-maven-plugin:1.2.0:start: org/slf4j/LoggerFactory

Just continue build where it ended:

    mvn clean install -rf :0501-jms11-jndi

"
berndruecker/trip-booking-saga-java,master,295,135,2017-04-19T06:20:03Z,344,2,Example implementation of the Saga pattern for the classic trip booking example using the lightweight open source workflow engine (Camunda).,saga-pattern,"# Saga example: trip booking

The Saga pattern describes how to solve distributed (business) transactions without two-phase-commit as this does not scale in distributed systems. The basic idea is to break the overall transaction into multiple steps or activities. Only the steps internally can be performed in atomic transactions but the overall consistency is taken care of by the Saga. The Saga has the responsibility to either get the overall business transaction completed or to leave the system in a known termination state. So in case of errors a business rollback procedure is applied which occurs by calling compensation steps or activities in reverse order. A more detailed look on Sagas is available in [Saga: How to implement complex business transactions without two phase commit](
https://blog.bernd-ruecker.com/saga-how-to-implement-complex-business-transactions-without-two-phase-commit-e00aa41a1b1b)

In the example hotel, car and flight booking might be done by different remote services. So there is not technical transaction, but a business transaction. When the flight booking cannot be carried out succesfully you need to cancel hotel and car. 

![Saga example](docs/example-use-case.png)

Using [Camunda](https://camunda.org/) you can implement the Saga either by using graphical modeling or by a Java DSL, called Model-API. As Camunda is very lightweight you can start the so called process engine, define the Saga and run instances by a couple of lines of Java code (if you use the default configuration and an in-memory H2 database), see [TripBookingSaga.java](src/main/java/io/flowing/trip/saga/camunda/simple/TripBookingSaga.java):

```java
public class TripBookingSaga {

  public static void main(String[] args) {
    // Configure and startup (in memory) engine
    ProcessEngine camunda = 
        new StandaloneInMemProcessEngineConfiguration()
          .buildProcessEngine();
    
    // define saga as BPMN process
    ProcessBuilder saga = Bpmn.createExecutableProcess(""trip"");
    
    // - flow of activities and compensating actions
    saga.startEvent()
        .serviceTask(""car"").name(""Reserve car"").camundaClass(ReserveCarAdapter.class)
          .boundaryEvent().compensateEventDefinition().compensateEventDefinitionDone()
          .compensationStart().serviceTask(""car-compensate"").name(""Cancel car"").camundaClass(CancelCarAdapter.class).compensationDone()
        .serviceTask(""hotel"").name(""Book hotel"").camundaClass(BookHotelAdapter.class)
          .boundaryEvent().compensateEventDefinition().compensateEventDefinitionDone()
          .compensationStart().serviceTask(""hotel-compensate"").name(""Cancel hotel"").camundaClass(CancelHotelAdapter.class).compensationDone()
        .serviceTask(""flight"").name(""Book flight"").camundaClass(BookFlightAdapter.class)
          .boundaryEvent().compensateEventDefinition().compensateEventDefinitionDone()
          .compensationStart().serviceTask(""flight-compensate"").name(""Cancel flight"").camundaClass(CancelFlightAdapter.class).compensationDone()
        .endEvent();
    
    // - trigger compensation in case of any exception (other triggers are possible)
    saga.eventSubProcess()
        .startEvent().error(""java.lang.Throwable"")
        .intermediateThrowEvent().compensateEventDefinition().compensateEventDefinitionDone()
        .endEvent();     

    // finish Saga and deploy it to Camunda
    camunda.getRepositoryService().createDeployment() //
        .addModelInstance(""trip.bpmn"", saga.done()) //
        .deploy();
    
    // now we can start running instances of our saga - its state will be persisted
    camunda.getRuntimeService().startProcessInstanceByKey(""trip"", Variables.putValue(""name"", ""trip1""));
    camunda.getRuntimeService().startProcessInstanceByKey(""trip"", Variables.putValue(""name"", ""trip2""));
  }

}
```

The real logic is attached as Java code by the adapter classes, e.g. the [BookHotelAdapter](src/main/java/io/flowing/trip/saga/camunda/adapter/BookHotelAdapter.java).

The definition might look a bit verbose, as you have to use BPMN terminology. But you could write a thin [SagaBuilder](src/main/java/io/flowing/trip/saga/camunda/springboot/builder/SagaBuilder.java) that improves readability of the Saga definition:

```java
SagaBuilder saga = SagaBuilder.newSaga(""trip"")
        .activity(""Reserve car"", ReserveCarAdapter.class) 
        .compensationActivity(""Cancel car"", CancelCarAdapter.class) 
        .activity(""Book hotel"", BookHotelAdapter.class) 
        .compensationActivity(""Cancel hotel"", CancelHotelAdapter.class) 
        .activity(""Book flight"", BookFlightAdapter.class) 
        .compensationActivity(""Cancel flight"", CancelFlightAdapter.class) 
        .end()
        .triggerCompensationOnAnyError();

camunda.getRepositoryService().createDeployment() 
        .addModelInstance(saga.getModel()) 
        .deploy();
```

The engine will take care of state handling, compensation and could also handle timeouts and escalations.

In real-life scenarios you might configure and run the Camunda engine differently, e.g. by using Spring or Spring Boot. In this example you can also use the [Spring Boot Application](src/main/java/io/flowing/trip/saga/camunda/springboot/Application.java) in order to fire the application up - and afterwords even connect Camundas visual tooling.

A visual representation is automatically created in the background by Camunda. (**You need to use Camunda in a version >= 7.8.0.**)

![Cockpit Screenshot](docs/screenshot.png)

The flow can also be modeled graphically instead of using the Model API. In this case use the [Camunda Modeler](https://camunda.org/download/modeler/) to draw the BPMN notation:

![Compensation in BPMN](docs/example-bpmn.png)

The [trip.bpmn (BPMN model file)](docs/trip.bpmn)


# Get started

You need

* Java
* Maven

Required steps

* Checkout or download this project
* Run the [Application.java](src/main/java/io/flowing/trip/saga/camunda/springboot/Application.java) class as this is a Spring Boot application running everything at once, starting exactly one Saga that is always ""crashing"" in the flight booking
* If you like you can access the Camunda database from the outside, e.g. using the [""Camunda Standalone Webapp""](https://camunda.org/download/) to inspect state. Use the follwing connection url: ```jdbc:h2:tcp://localhost:8092/mem:camunda;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE```. Note that you need [Camunda Enterprise](https://camunda.com/trial/) to see historical data.

As an alternative:
* Run the [TripBookingSaga.java](src/main/java/io/flowing/trip/saga/camunda/simple/TripBookingSaga.java) class via your favorite IDE - it also will run instances of the Saga without requiring any infrastructure

"
douglascraigschmidt/LiveLessons,master,588,665,2014-07-17T16:46:47Z,39886,7,"This repository contains all the source code examples from my LiveLessons course on Java Concurrent Programming"" and my various LiveTraining courses"," as described at http://www.dre.vanderbilt.edu/~schmidt/DigitalLearning.""","LiveLessons and LiveTraining Source Repo
========================================

This GitHub repo contains source code examples from my LiveLessons
courses on [Design Patterns in
Java](http://www.dre.vanderbilt.edu/~schmidt/LiveLessons/DPiJava/) and
[Java
Concurrency](http://www.dre.vanderbilt.edu/~schmidt/LiveLessons/CPiJava/),
as well as my LiveTraining courses on [Java 8
Concurrency](https://www.safaribooksonline.com/live-training/courses/java-8-concurrency/0636920091080/).
"
codingXiaxw/ssm,master,909,446,2016-11-16T15:59:05Z,10845,1,:on: a simple example introducing SSM's basic development knowledge with detailed manual ,,"## 一个案例带你快速入门SSM开发

**写在前面的话:**关于SSM框架的工程搭建请点击这里前往我的博客[SSM整合工程的搭建](http://codingxiaxw.cn/2016/11/15/44-ssm%E7%9A%84%E6%95%B4%E5%90%88/)

## 开发环境
IDEA Spring3.x+SpringMVC+Mybatis  
没有用到maven管理工具。

## 1.实现商品的列表展示

### 1.1提出需求
功能描述:在页面中展示商品列表。

### 1.2编写表

sql语句见github中.sql文件。

### 1.3持久层mapper的编写
编写好数据库后我们便可以通过MyBatis逆向工程快速生成对单表映射的sql，包括mapper.java、mapper.xml和pojo类。

根据逆向工程生成的这三个文件与单表都是一对一的关系，例如通过Items表会生成ItemsMapper.java、ItemsMapper.xml和Items.java的pojo类，这里我们为了便于需求的扩展，所以另外自己编写一个ItemsCustom.java并继承Items.java和Items.java的包装类ItemsQueryVo.java，代码如下:
```java
public class ItemsQueryVo {
	//商品信息
	private ItemsCustom itemsCustom;

	public ItemsCustom getItemsCustom() {
		return itemsCustom;
	}

	public void setItemsCustom(ItemsCustom itemsCustom) 	{
		this.itemsCustom = itemsCustom;
	}	
}
```

然后自己编写一个ItemsCustomerMapper.xml:
```xml
<?xml version=""1.0"" encoding=""UTF-8"" ?>
<!DOCTYPE mapper
PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN""
""http://mybatis.org/dtd/mybatis-3-mapper.dtd"">
<mapper namespace=""mapper.ItemsMapperCustom"">

	<!-- 商品查询的sql片段
	建议是以单表为单位定义查询条件
	建议将常用的查询条件都写出来
	 -->
	<sql id=""query_items_where"">
		<if test=""itemsCustom!=null"">
			<if test=""itemsCustom.name!=null and itemsCustom.name!=''"">
				and  name like '%${itemsCustom.name}%'
			</if>
			<if test=""itemsCustom.id!=null"">
				and  id = #{itemsCustom.id}
			</if>
		
		</if>
		
	</sql>
	
	<!-- 商品查询 
	parameterType：输入 查询条件
	-->
	
	<select id=""findItemsList"" parameterType=""po.ItemsQueryVo""
			resultType=""po.ItemsCustom"">
		SELECT * FROM items 
		<where>
			<include refid=""query_items_where""/>
		</where>
	</select>
</mapper>
```
与ItemsCustomMapper.java:
```java
public interface ItemsMapperCustom {
	// 商品查询列表
	List<ItemsCustom> findItemsList(ItemsQueryVo itemsQueryVo)
			throws Exception;
}
```

至于Mapper的配置我们已经在springmvc.xml中通过spring组件扫描器
```xml

	<!--
	MapperScannerConfigurer：mapper的扫描器，将包下边的mapper接口自动创建代理对象，
	自动创建到spring容器中，bean的id是mapper的类名（首字母小写）
	 -->
	<bean class=""org.mybatis.spring.mapper.MapperScannerConfigurer"">
		<!-- 配置扫描包的路径
		如果要扫描多个包，中间使用半角逗号分隔
		要求mapper.xml和mapper.java同名且在同一个目录
		 -->
		<property name=""basePackage"" value=""mapper""/>
		<!-- 使用sqlSessionFactoryBeanName -->
		<property name=""sqlSessionFactoryBeanName"" value=""sqlSessionFactory""/>
	</bean>
```
进行了统一的配置。


接口里面调用xml文件中查询表中所有商品列表信息的sql语句，然后我们便可以进行业务逻辑层的代码编写.


### 1.4业务逻辑层service的编写
首先我们在service包下创建一个商品的service接口ItemsService.java文件，里面编写的方法和ItemsCustomMapper.java中的方法对应以实现商品列表的查询:
```java
public interface ItemsService {

    //商品的查询列表
    public List<ItemsCustom> findItemsList(ItemsQueryVo itemsQueryVo)
            throws Exception;
}
```

然后编写其实现类ItemsServiceImpl.java:
```java
public class ItemsServiceImpl implements ItemsService {

    //注入mapper
    @Autowired
    private ItemsMapperCustom itemsMapperCustom;

    //商品的查询列表
    @Override
    public List<ItemsCustom> findItemsList(ItemsQueryVo itemsQueryVo) throws Exception {

        return itemsMapperCustom.findItemsList(itemsQueryVo);
    }
}
```

代码中通过Spring框架的DI注入依赖对象mapper即itemsMapperCustom对象，然后调用itemsMapperCustom的findItemsList方法实现商品列表查询,然后在spring配置文件applicationContext-service.xml中要进行service的配置，添加如下标签:
```xml
<!--商品配置的service-->
	<bean id=""itemsService"" class=""service.impl.ItemsServiceImpl""/>
```
便可。接下来便应该完成控制层Controller.java的代码编写了。

### 1.5控制层Controller的编写
在controller包下创建一个ItemsController.java，里面编写代码:
```java
@Controller
public class ItemsController {

    //注入service
    @Autowired
    private ItemsService itemsService;

    @RequestMapping(""/queryItems"")
    public ModelAndView queryItems() throws Exception {
        //调用servie来查询商品列表
        List<ItemsCustom> itemsList=itemsService.findItemsList(null);

        ModelAndView modelAndView=new ModelAndView();
        modelAndView.addObject(""itemsList"",itemsList);
        //指定逻辑视图名itemsList
        modelAndView.setViewName(""itemsList"");

        return modelAndView;
    }
}
```
通过@Autowired注解完成service的依赖注入，通过@Controller注解将Controller自动添加到spring容器IOC中，通过@RequestMapping(""/queryItems"")注解指明访问该Controller的url。  

至于itemsList.jsp的页面编写代码如下:  
```xml
<%@ page language=""java"" contentType=""text/html; charset=UTF-8""
    pageEncoding=""UTF-8""%>
<%@ taglib uri=""http://java.sun.com/jsp/jstl/core"" prefix=""c"" %>
<%@ taglib uri=""http://java.sun.com/jsp/jstl/fmt""  prefix=""fmt""%>
<!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd"">
<html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
<title>查询商品列表</title>
</head>
<body> 
<form action=""${pageContext.request.contextPath }/items/queryItem.action"" method=""post"">
查询条件：
<table width=""100%"" border=1>
<tr>
<td><input type=""submit"" value=""查询""/></td>
</tr>
</table>
商品列表：
<table width=""100%"" border=1>
<tr>
	<td>商品名称</td>
	<td>商品价格</td>
	<td>生产日期</td>
	<td>商品描述</td>
	<td>操作</td>
</tr>
<c:forEach items=""${itemsList }"" var=""item"">
<tr>
	<td>${item.name }</td>
	<td>${item.price }</td>
	<td><fmt:formatDate value=""${item.createtime}"" pattern=""yyyy-MM-dd HH:mm:ss""/></td>
	<td>${item.detail }</td>
	
	<td><a href=""${pageContext.request.contextPath }/items/editItems.action?id=${item.id}"">修改</a></td>

</tr>
</c:forEach>

</table>
</form>
</body>

</html>
```
然后我们运行服务器，输入网址`http://localhost:8080/SpringMvcMybatis/queryItems.action`，发现无法看到页面，这是因为我们的spring配置文件没有得到加载，需要在web.xml文件中加入如下内容进行spring容器的配置:  
```xml
    <!--配置spring容器监听器-->
    <context-param>
        <param-name>contextConfigLocation</param-name>
        <param-value>/WEB-INF/classes/config/spring/applicationContext-*.xml</param-value>
    </context-param>
    <listener>
        <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
    </listener>
```
然后重新运行服务器并输入网址，看到如下页面，说明成功使用SSM框架完成开发显示商品列表的项目:
![](http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-11-16%20%E4%B8%8B%E5%8D%888.00.34.png)


到此，我们便通过SSM的整合工程项目，完成了对商品列表的查询。接下来我们再实现对商品的另一个功能:修改商品信息。

## 2.实现商品信息的修改
### 2.1需求
功能描述:商品信息修改。操作流程：1.在商品列表页面点击修改连接。2.打开商品修改页面，显示了当前商品的信息(根据商品id查询商品信息)。3.修改商品信息，点击提交(更新商品信息)。  

通过此案例，我们也会穿插用SSM进行注解开发的基础知识如: @RequestMapping注解的改善、controller方法返回值、Controller方法中的参数与页面参数的绑定。

### 2.2mapper的编写
此功能涉及到的mapper为ItemsMapper.java与ItemsMapper.xml，已使用逆向工程为我们生成。

### 2.3service的编写
在ItemsService接口中添加方法:
```java
   //根据商品id查询商品信息
    public ItemsCustom findItemsById(int id) throws Exception;
    
      //更新商品信息
    /**
     * 定义service接口，遵循单一职责，将业务参数细化(不要使用包装类型，比如map)
     * @param id 修改商品的id
     * @param itemsCustom 修改商品的信息
     * @throws Exception
     */
    public void updateItems(Integer id,ItemsCustom itemsCustom) throws Exception;
```

然后是实现类ItemsServiceImpl.java:
```java
 
 	//注入依赖对象itemsMapper
 	 @Autowired
    private ItemsMapper itemsMapper;

    @Override
    public ItemsCustom findItemsById(int id) throws Exception {

        Items items=itemsMapper.selectByPrimaryKey(id);

        //在这里以后随着需求的变化，需要查询商品的其它相关信息，返回到controller
        //所以这个时候用到扩展类更好，如下
        ItemsCustom itemsCustom=new ItemsCustom();
        //将items的属性拷贝到itemsCustom
        BeanUtils.copyProperties(items,itemsCustom);

        return itemsCustom;
    }

    @Override
    public void updateItems(Integer id,ItemsCustom itemsCustom) throws Exception {

        //在service中一定要写业务代码




        //对于关键业务数据的非空校验
        if (id==null)
        {
            //抛出异常，提示调用接口的用户，id不能唯恐
            //...
        }

        itemsMapper.updateByPrimaryKeyWithBLOBs(itemsCustom);
    }
```

说一句:对service的开发是整个系统中开发最重要的部分，所以你要把service的开发放在学习的重点上。接下来就要写Controller的代码了，然而写Controller的过程中会学到很多注解开发的基础知识。


### 2.4Controller的编写之@RequestMapping的特性学习

#### 2.4.1窄化请求映射
我们除了在Controller方法的上面加上一个@RequestMapping的注解指定url外(完成url映射)，还可以在Controller类的上面指定一个@RequestMapping注解指定访问路径的根url，如这里我们是对商品的操作，所以可以在Controller类上面加上一个@RequestMapping的注解指定访问商品信息的根路径(叫“窄化请求映射”):
```java
@Controller
//定义url的根路径，访问时根路径+方法名的url
@RequestMapping(""/items"")
public class ItemsController {
}
```
使用窄化请求映射的好处:更新规范系统的url，避免url冲突。  

然后继续我们的Controller开发，添加方法:
```java
    @RequestMapping(value = ""/editItems"",method = RequestMethod.GET)
    public ModelAndView editItems() throws Exception
    {
        ModelAndView modelAndView=new ModelAndView();

        //调用service查询商品的信息
        ItemsCustom itemsCustom=itemsService.findItemsById(1);
        //将模型数据传到jsp
        modelAndView.addObject(""item"",itemsCustom);
        //指定逻辑视图名
        modelAndView.setViewName(""editItem"");

        return modelAndView;
    }
```

编写editItem.jsp页面:
```xml
<%@ page language=""java"" contentType=""text/html; charset=UTF-8""
    pageEncoding=""UTF-8""%>
<%@ taglib uri=""http://java.sun.com/jsp/jstl/core"" prefix=""c"" %>
<%@ taglib uri=""http://java.sun.com/jsp/jstl/fmt""  prefix=""fmt""%>
<!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd"">
<html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8"">
<title>修改商品信息</title>

</head>
<body> 
<form id=""itemForm"" action=""${pageContext.request.contextPath }/items/editItemSubmit.action"" method=""post"" >
<input type=""hidden"" name=""id"" value=""${id }""/>
修改商品信息：
<table width=""100%"" border=1>
<tr>
	<td>商品名称</td>
	<td><input type=""text"" name=""name"" value=""${itemsCustom.name }""/></td>
</tr>
<tr>
	<td>商品价格</td>
	<td><input type=""text"" name=""price"" value=""${itemsCustom.price }""/></td>
</tr>
<tr>
	<td>商品简介</td>
	<td>
	<textarea rows=""3"" cols=""30"" name=""detail"">${itemsCustom.detail }</textarea>
	</td>
</tr>
<tr>
<td colspan=""2"" align=""center""><input type=""submit"" value=""提交""/>
</td>
</tr>
</table>
</form>
</body>
</html>
```
然后运行服务器，此时应该输入网址`http://localhost:8080/SpringMvcMybatis/items/queryItems.action`而不是`http://localhost:8080/SpringMvcMybatis/queryItems.action`,然后点击右边的修改链接便可以进去相应的修改页面:![](http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-11-16%20%E4%B8%8B%E5%8D%888.55.33.png)  

#### 2.4.2限制http请求的方法
不知道你发现没有，我们在Controller的editItems()方法上的注解中加入的是`value = ""/editItems"",method = RequestMethod.GET`参数而不再是单单的`""/editItems""`参数了，这里我们便用到了使用@RequestMapping注解限制http请求的方法。如果你将这里的`method = RequestMethod.GET`改为`method = RequestMethod.POST`，然后在页面中再点击修改链接时就会报错。 

另外method属性的属性值为数组，我们也可以将注解中的参数改为`ethod = {RequestMethod.GET,RequestMethod.POST}`表示请求既可以为POST请求又可以为GET请求。 


### 2.5Controller的编写之Controller方法返回值学习
#### 2.5.1返回ModerAndView

目前我们使用的方式都是返回的ModerAndView对象，例如我们已经编写的Controller中的queryItems()方法和editItems()方法。接下来我们看看返回字符串的方法编写。

#### 2.5.2返回字符串
首先注释掉我们返回值为ModerAndView类型的editItems()方法。如果controller方法返回jsp页面，可以简单将方法返回值类型定义 为字符串，最终返回逻辑视图名。编写返回值为String类型的editItems()方法，代码如下:
```java
    //方法返回字符串，字符串就是逻辑视图名，Model作用是将数据填充到request域，在页面显示
    @RequestMapping(value = ""/editItems"",method = RequestMethod.GET)
    public String editItems(Model model) throws Exception
    {

    
        //调用service查询商品的信息
        ItemsCustom itemsCustom=itemsService.findItemsById(1);

        model.addAttribute(""itemsCustom"",itemsCustom);

        return ""editItem"";
    }
```
方法中我们需要传入一个Model对象，作用是将数据填充到request域，在页面显示。然后运行服务器，输入`http://localhost:8080/SpringMvcMybatis/items/queryItems.action`照常正确访问该网站。再来介绍返回值为void的方法。

#### 2.5.3返回void
同样注释掉返回值为String类型的editItems()方法，然后加入返回值为void的editItems()方法:
```java
    @RequestMapping(value = ""/editItems"",method = RequestMethod.GET)
    public void editItems(HttpServletRequest request, HttpServletResponse response) throws Exception
    {

        //调用service查询商品的信息
        ItemsCustom itemsCustom=itemsService.findItemsById(id);

        request.setAttribute(""item"",itemsCustom);

        //注意如果使用request转向页面，这里需要指定页面的完整路径
        request.getRequestDispatcher(""/WEB-INF/jsp/editItem.jsp"").forward(request,response);
    }
```

其实这里就是运用的原生态的Servlet的开发方式，运行服务器，输入`http://localhost:8080/SpringMvcMybatis/items/queryItems.action`仍照常正确访问该网站。  


通过这种返回值为void的方法我们容易输出json、xml格式的数据，即通过response指定响应结果，例如响应json数据如下：
```java
response.setCharacterEncoding(""utf-8"");
response.setContentType(""application/json;charset=utf-8"");
response.getWriter().write(""json串"");
```

上面我们就通过完成商品信息的编辑功能介绍了Controller中三种返回值类型的方法。而通过返回字符串的方法，有时候会返回一些特殊的字符串(例如返回`return ""forward:url路径""`或`return ""redirect:url路径""`)。分别代表请求转发和请求冲定向，下面我们通过完善编辑商品信息后进行提交的功能来讲解这两种返回特殊字符串类型的方法。在Controller中添加editItemSubmit()方法:
```java
 //商品提交页面
    //itemsQueryVo是包装类型的pojo
    @RequestMapping(""/editItemSubmit"")
    public String editItemSubmit() throws Exception
    {
        //请求转发,使用forward进行请求转发，request数据可以共享，url地址栏不会
//        return ""forward:queryItems.action"";

        //使用redirect进行重定向，request数据无法共享，url地址栏会发生变化的。由于我们重定向的页面queryItems.action与本页面editItemSubmit.action在同一根目录下，所以不需要加入根路径
       return ""redirect:queryItems.action"";
    }
```

运行服务器，然后我们便可以在editItems.jsp页面通过点击""提交""按钮请求转发或者请求重定向到我们的`queryItems.action`页面。如上，我便介绍完Contoller方法返回值的知识。接下来介绍Controller方法中的参数与页面参数绑定的知识。  

### 2.6Controller的编写之方法参数与页面参数的绑定
不知你注意到没有，在Controller的方法中我们传入的参数都是我们自己根据需求手动传入的参数，而真正的需求中我们是需要将页面中的参数传递到Controller的方法中的，那如何将页面的参数绑定到Controller的方法中呢？看下方参数绑定的过程图解:  

![](http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-11-16%20%E4%B8%8B%E5%8D%889.33.44.png)

首先我们看看Controller的方法中默认支持的形参(即之前我们根据需求手动传入的参数，这些参数处理适配器会默认识别并进行赋值)有:1.HttpServletRequest:通过request对象获取请求信息。 2.HttpServletResponse:通过response处理响应信息。3.HttpSession:通过session对象得到session中存放的对象。4.Model/modelmap/map:通过model向页面传递数据，页面通过${item.XXXX}获取item对象的属性值,如下:
```java
//调用service查询商品信息
Items item = itemService.findItemById(id);
model.addAttribute(""item"", item);
```
但是值得我们关心的不是这些默认的参数，而是我们自定义参数传入Controller方法的形参中，继续往下面看。

#### 2.6.1@RequestParam
如果request请求的参数名和controller方法的形参数名称一致，适配器自动进行参数绑定。如果不一致可以通过
@RequestParam 指定request请求的参数名绑定到哪个方法形参上。

对于必须要传的参数，通过@RequestParam中属性required设置为true，如果不传此参数则报错。
 
对于有些参数如果不传入，还需要设置默认值，使用@RequestParam中属性defaultvalue设置默认值。

例如Controller中的方法:
```java
    @RequestMapping(value = ""/editItems"",method = RequestMethod.GET)
    public void editItems(HttpServletRequest request, HttpServletResponse response,@RequestParam(value = ""item_id"",required = false,defaultValue = ""1"") Integer id) throws Exception
    {

        //调用service查询商品的信息
        ItemsCustom itemsCustom=itemsService.findItemsById(id);

        request.setAttribute(""item"",itemsCustom);

        //zhuyi如果使用request转向页面，这里需要指定页面的完整路径
        request.getRequestDispatcher(""/WEB-INF/jsp/editItem.jsp"").forward(request,response);
    }
```

没对形参id加上@RequestParam注解时，当我们从页面进入到editItems.action时，只有从页面传入的参数名为id时该id参数值才会传到editItems()方法的id参数值上，如果从页面传入的参数明不为id而为其他参数名时例如`http://localhost:8080/SpringMvcMybatis/items/editItems.action?item_id=1`，此时通过调试会发现editItems()方法中的id属性值为null;而当我们为形参id加上了@RequestParam注解并指定了其属性`value = ""item_id""`后，若从页面传入的参数名为item_id，则该参数值会因为添加了`value = ""item_id""`该属性而被赋值给id属性。`required`属性若设置为true，则如果从页面进入到editItem.action时没有传入此参数则会报错。`defaultvalue`属性值表示为该参数赋默认值。

#### 2.6.2绑定简单类型
上述那个editItem()方法时原始的servlet开发方法，接下来我们用返回值为String 类型的方法进行注解开发的基础知识讲解。

可以绑定整型、字符串、单精/双精度、日期、布尔型，很简单处理，我不进行讲解，通过下面绑定pojo类型你就会清楚了。

#### 2.6.3绑定pojo类型
绑定pojo类型又可以分为绑定简单pojo类型和绑定包装pojo类型。

##### 2.6.3.1绑定简单pojo类型
简单pojo类型只包括简单类型的属性。绑定过程:request请求的参数名称和pojo的属性名一致，就可以绑定成功。  

修改Controller中的editItemSubmit()方法:
```java
//商品提交页面
    //itemsQueryVo是包装类型的pojo
    @RequestMapping(""/editItemSubmit"")
    public String editItemSubmit(Integer id,ItemsCustom itemsCustom) throws Exception
    {
        //进行数据回显
        model.addAttribute(""id"",id);
//        model.addAttribute(""item"",itemsCustom);


        itemsService.updateItems(id,itemsCustom);
        //请求转发
//        return ""forward:queryItems.action"";



        //重定向
       return ""redirect:queryItems.action"";
    }
```
点击提交按钮，从editItem.jsp页面进入editItemSubmit.action时，就会将编辑页面的参数都映射到该方法的id形参和ItemsCustom对象中，此时我们修改商品的信息，然后点击提交按钮，服务器反应过程如下:点击提交按钮，页面从editItem.jsp进入到editItemSubmit.action并将修改后的商品信息提交到数据库并将这些参数传入到ItemsCustom对象的属性中，然后重定向到queryItems.action进行商品的列表信息展示。  

**问题:**如果controller方法形参中有多个pojo且pojo中有重复的属性，使用简单pojo绑定无法有针对性的绑定，比如:方法形参有items和User，pojo同时存在name属性，从http请求过程的name无法有针对性的绑定到items或user。要解决此种方法我们就需要用到下面的绑定包装的pojo类型。

##### 2.6.3.2绑定包装的pojo类型
这里我们复制editItem.jsp页面粘贴出一个editItem2.jsp页面，染护修改editItem2.jsp中的参数名为itemsCustom.name、itemsCustom.price、itemsCustom.detail，修改Controller中的editItemSubmit方法中的形参为`public String editItemSubmit(Integer id,ItemsCustom itemsCustom,ItemsQueryVo itemsQueryVo) throws Exception{...}
`修改editItems的返回值类型为`editItems2`。运行程序，点击提交按钮，页面信息成功传入到itemsQueryVo的属性中。成功运行后我们还是将信息改回成原来的模样，方便后面的测试。  

#### 2.6.4使用属性编辑器完成自定义绑定

此时我们在editItem.jsp中添加上日期的信息展示:
```xml
<tr>
	<td>商品生产日期</td>
	<td><input type=""text"" name=""createtime"" value=""<fmt:formatDate value=""${itemsCustom.createtime}"" pattern=""yyyy-MM-dd HH-mm-ss""/>""/></td>
</tr>
```

然后运行程序，当点击提交按钮时会报错，你知道为什么吗？原因是因为通过点击提交按钮，页面中参数名为""createtime""的参数名由于跟Controller方法中的形参ItemsCustom有相同的属性名createtime，所以此时页面中的日期会映射到ItemsCustom的Date属性中,但是从页面传过来的日期是字符串类型，而ItemsCustom的属性是java.util.Date类型，所以当然会报错。这样的话，我们就必须完成日期字符串向java类型日期的转换。此时我们就需要自定义日期类型的绑定，即使用属性编辑器来完成自定义的绑定。有如下两种方法:1.使用WebDataBinder（了解），在Controller中添加如下代码:
```java
    //自定义属性编辑器
    @InitBinder
    public void initBinder(WebDataBinder binder) throws  Exception{

        //Date.class必须是与controller方法形参pojo属性一致的date类型，这里是java.util.Date
        binder.registerCustomEditor(Date.class,new CustomDateEditor(new SimpleDateFormat(""yyyy-MM-dd HH-mm-ss""),true));
    }
```
运行程序，点击提交按钮后不会再出现报错信息，且editItem.jsp页面的createtime参数也成功传入到了ItemsCustom的createtime属性中。使用这种方法的问题是无法在多个controller共用。那我们就来介绍第二种方法:使用WebBindingInitializer（了解）。首先我们需要编写一个自定义属性编辑器CustomPropertyEditor.java，代码如下:
```java
public class CustomPropertyEditor implements PropertyEditorRegistrar
{

    @Override
    public void registerCustomEditors(PropertyEditorRegistry binder) {
        binder.registerCustomEditor(Date.class,new CustomDateEditor(new SimpleDateFormat(""yyyy-MM-dd HH-mm-ss""),true));

    }
}
```

然后要在springmvc.xml文件中加入对它的配置:
```xml
<!-- 注册属性编辑器 -->
	<bean id=""customPropertyEditor"" class=""cn.itcast.ssm.propertyeditor.CustomPropertyEditor""></bean> 
<!-- 自定义webBinder -->
	<bean id=""customBinder""
		class=""org.springframework.web.bind.support.ConfigurableWebBindingInitializer"">
		<property name=""propertyEditorRegistrars"">
			<list>
				<ref bean=""customPropertyEditor""/>
			</list>
		</property>
	</bean>
```

然后要在注解适配器的配置标签中加入如下属性:
```xml
<bean class=""org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"">
	<property name=""webBindingInitializer"" ref=""customBinder""></property> 
</bean>
```

这样我们便可以注释掉第一种属性编辑器的代码了，使用第二种方式虽然配置很繁琐，但是很适用。运行程序，也成功将editItem.jsp页面的createtime参数映射到ItemsCustom的createtime属性中。下面我再讲一种自定义绑定参数的方法。

#### 2.6.5使用转换器完成自定义参数绑定(想往架构师方向发展的要掌握这种方法)
首先要定义一个转换器CustomDateConverter.java完成日期的转换，代码如下:
```java
public class CustomDateConverter implements Converter<String,Date> {

    @Override
    public Date convert(String source) {

        try{
            return new SimpleDateFormat(""yyyy-MM-dd HH-mm-ss"").parse(source);
        }catch (Exception e)
        {
            e.printStackTrace();
        }

        return null;
    }
}
```
在定义一个StringTrimConverter.java用于去除日期字符串两边的空格,代码如下:
```java
public class StringTrimConverter implements Converter<String,String> {

    @Override
    public String convert(String source) {

        try{
            //去掉字符串两边的空格，如果去除后为空则返回null
            if (source!=null)
            {
                source=source.trim();
                if (source.equals(""""))
                    return null;
            }
        }catch (Exception e)
        {
            e.printStackTrace();
        }

        return source;
    }
}
```

定义好后就需要对转换器进行配置:思路就是先定义一个转换器然后注入到适配器中。而对于转换器在springmvc.xml中的配置有两种方式，第一种方式针对不使用`<mvc:annotation-driven>`,第二种方式针对使用`<mvc:annotation-driven>`,我们就来讲讲第二种方式。在springmvc.xml中添加如下配置:
```xml
    <!--mvc的注解驱动器，通过它可以替代下边的处理器映射器和适配器-->
    <mvc:annotation-driven conversion-service=""conversionService"">
    </mvc:annotation-driven>

    <!--转换器-->
    <!-- conversionService -->
    <bean id=""conversionService""
          class=""org.springframework.format.support.FormattingConversionServiceFactoryBean"">
        <!-- 转换器 -->
        <property name=""converters"">
            <list>
                <bean class=""controller.converter.CustomDateConverter""/>
                <bean class=""controller.converter.StringTrimConverter""/>
            </list>
        </property>
    </bean>
```

使用了注解驱动的配置后，我们就可以注释掉处理器映射器与处理器适配器了。运行程序，也成功将editItem.jsp页面的createtime参数映射到ItemsCustom的createtime属性中。

由于往后我们还要进行json数据的开发，所以这里我们还是不采用使用注解驱动的方式，还是采用注解映射器与注解适配器的方式进行开发。修改后的最后的springmvc.xml配置信息如下:
```xml
  <!--使用spring组件扫描
    一次性配置此包下所有的Handler-->
    <context:component-scan base-package=""controller""/>

    <!--mvc的注解驱动器，通过它可以替代下边的处理器映射器和适配器-->
    <!--<mvc:annotation-driven></mvc:annotation-driven>-->

    <!--注解处理器映射器-->
    <bean class=""org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping""/>

    <!--注解的适配器-->
    <bean class=""org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"">
        <property name=""webBindingInitializer"" ref=""customBinder""></property>
    </bean>

    <!--配置视图解析器
    要求将jstl的包加到classpath-->
    <bean class=""org.springframework.web.servlet.view.InternalResourceViewResolver"">
        <property name=""prefix"" value=""/WEB-INF/jsp/"" />
        <property name=""suffix"" value="".jsp"" />
    </bean>



      <!-- 自定义webBinder -->
    <bean id=""customBinder""
          class=""org.springframework.web.bind.support.ConfigurableWebBindingInitializer"">
        <property name=""conversionService"" ref=""conversionService""/>
        <!--早期的自定义属性编辑器-->
        <!--<property name=""propertyEditorRegistrars"">-->
            <!--<list>-->
                <!--<ref bean=""customPropertyEditor""/>-->
            <!--</list>-->
        <!--</property>-->
    </bean>

    <!-- 注册属性编辑器 -->
    <bean id=""customPropertyEditor"" class=""controller.propertyeditor.CustomPropertyEditor""></bean>



    <!--mvc的注解驱动器，通过它可以替代下边的处理器映射器和适配器-->
    <!--<mvc:annotation-driven conversion-service=""conversionService"">-->
    <!--</mvc:annotation-driven>-->

    <!--转换器-->
    <!-- conversionService -->
    <bean id=""conversionService""
          class=""org.springframework.format.support.FormattingConversionServiceFactoryBean"">
        <!-- 转换器 -->
        <property name=""converters"">
            <list>
                <bean class=""controller.converter.CustomDateConverter""/>
                <bean class=""controller.converter.StringTrimConverter""/>
            </list>
        </property>
    </bean>
```

这个converter的配置是一劳永逸的配置，也就是系统架构级别的配置，希望你能成功掌握。

好了，通过上述的案例，便成功的使用了SSM框架对对商品信息的三个功能。希望通过这个案例，你能成功掌握SSM框架。接下来我将讲解使用SSM进行注解开发的高级知识。博客链接[SSM注解开发的高级知识讲解](http://codingxiaxw.cn/2016/11/19/46-ssm%E9%AB%98%E7%BA%A7%E5%BC%80%E5%8F%91/),源码链接[点击这里前往我的github](https://github.com/codingXiaxw/ssm2)

## 3.联系

  If you have some questions after you see this article,you can tell your doubts in the comments area or you can find some info by  clicking these links.


- [Blog@codingXiaxw's blog](http://codingxiaxw.cn)

- [Weibo@codingXiaxw](http://weibo.com/u/5023661572?from=hissimilar_home&refer_flag=1005050003_)

- [Zhihu@codingXiaxw](http://www.zhihu.com/people/e9f78fa34b8002652811ac348da3f671)  
- [Github@codingXiaxw](https://github.com/codingXiaxw)
"
wangjianfengnb/Sample,master,106,35,2016-06-20T07:01:38Z,156,4,some blog example,,
boylegu/SpringBoot-vue,master,1951,866,2017-06-20T07:07:19Z,33570,25,A example demo base SpringBooot with vueJS2.x + webpack2.x as Java full stack web practice,,"[![jdkversions](https://img.shields.io/badge/Java-1.7%2B-yellow.svg)]()
[![vueversions](https://img.shields.io/badge/vue.js-2.2.x-brightgreen.svg)]()
[![es2015](https://img.shields.io/badge/ECMAScript-6-green.svg)]()
[![ver](https://img.shields.io/badge/release-v0.1-red.svg)]()
[![MIT](https://img.shields.io/badge/license-MIT-ff69b4.svg)]()


<p align=""center"">
  <a href =""##""><img alt=""spring_vue"" src=""https://github.com/boylegu/SpringBoot-vue/blob/master/images/newlogo.jpg?raw=true""></a></p>

<h4 align=""center"" style=""color:	#3399FF"">
Convenient & efficient and better performance for Java microservice full stack.
</h4>

<p align=""center"" style=""color: #FF66FF"">Commemorate the 6 anniversary of enter the profession.</p>

<p align=""center"" style=""color: #FF9933"">Give beginner as a present.</p>

<p align=""right"" style=""color: #3399FF"">———————By Boyle Gu</p>

### [Chinese README[中文]](https://github.com/boylegu/SpringBoot-vue/blob/master/README-CN.md)

## Overview

Now about Web develop fields. It's very bloated, outmoded and some development efficiency have a lower with each other than other dynamic language when people refers to Java. Even before somebody shouts loudly ‘Java was died’. But is this really the case? In fact, If you often attention to Java in long time, your feel is too deep. Though it's many disadvantages and verbose. It couldn't be denied that Java is still best language in industry member, and advance with the times. This project is a CRUD demo example base Spring Boot with Vue2 + webpack2. I hope pass thought this project for express Java microservice fast full stack base web practice.

## Why Spring Boot

Spring is a very popular Java-based framework for building web and enterprise applications. Unlike many other frameworks, which focus on only one area, Spring framework provides a wide verity of features addressing the modern business needs via its portfolio project. The main goal of the Spring Boot framework is to reduce overall development time and increase efficiency by having a default setup for unit and integration tests.

In relation to Spring, 
Spring Boot aims to make it easy to create Spring-powered, production-grade applications and services with minimum fuss. It takes an opinionated view of the Spring platform so that new and existing users can quickly get to the bits they need.

The diagram below shows Spring Boot as a point of focus on the larger Spring ecosystem:

<p align=""center"">
  <a href =""##""><img alt=""spring_vue"" src=""https://github.com/boylegu/SpringBoot-vue/blob/master/images/springboot.png?raw=true""></a></p>

The primary goals of Spring Boot are:

- To provide a radically faster and widely accessible ‘getting started’ experience for all Spring development.

- To be opinionated out of the box, but get out of the way quickly as requirements start to diverge from the defaults.

- To provide a range of non-functional features that are common to large classes of projects (e.g. embedded servers, security, metrics, health checks, externalized configuration).

**Spring Boot does not generate code and there is absolutely no requirement for XML configuration.**

Below are this project code snippet. Do you think simple? 

~~~~java
@RestController
@RequestMapping(""/api/persons"")
public class MainController {

    @RequestMapping(
            value = ""/detail/{id}"", 
            method = RequestMethod.GET, 
            produces = MediaType.APPLICATION_JSON_VALUE
            )
    public ResponseEntity<Persons> getUserDetail(@PathVariable Long id) {

        /*
        *    @api {GET} /api/persons/detail/:id  details info
        *    @apiName GetPersonDetails
        *    @apiGroup Info Manage
        *    @apiVersion 1.0.0
        *
        *    @apiExample {httpie} Example usage:
        *
        *        http GET http://127.0.0.1:8000/api/persons/detail/1
        *
        *    @apiSuccess {String} email
        *    @apiSuccess {String} id
        *    @apiSuccess {String} phone
        *    @apiSuccess {String} sex
        *    @apiSuccess {String} username
        *    @apiSuccess {String} zone
        */

        Persons user = personsRepository.findById(id);

        return new ResponseEntity<>(user, HttpStatus.OK);
    }

}
~~~~

## Why MVVM

Although it seems similar to MVC (except with a ""view model"" object in place of the controller), there's one major difference — the view owns the view model. Unlike a controller, a view model has no knowledge of the specific view that's using it.

This seemingly minor change offers huge benefits:

1. View models are testable. Since they don't need a view to do their work, presentation behavior can be tested without any UI automation or stubbing.

2. View models can be used like models. If desired, view models can be copied or serialized just like a domain model. This can be used to quickly implement UI restoration and similar behaviors.

3. View models are (mostly) platform-agnostic. Since the actual UI code lives in the view, well-designed view models can be used on the iPhone, iPad, and Mac, with only minor tweaking for each platform.

4. Views and view controllers are simpler. Once the important logic is moved elsewhere, views and VCs become dumb UI objects. This makes them easier to understand and redesign.
In short, replacing MVC with MVVM can lead to more versatile and rigorous UI code.

>  *In short, replacing MVC with MVVM can lead to more versatile and rigorous UI code.*

## Why to choose Vue.js

Vue.js is relatively new and is gaining lot of traction among the community of developers. VueJs works with MVVM design paradigm and has a very simple API. Vue is inspired by AngularJS, ReactiveJs and updates model and view via two way data binding.

Components are one of the most powerful features of Vue. They help you extend basic HTML elements to encapsulate reusable code. At a high level, components are custom elements that Vue’s compiler attaches behavior to. 

<p align=""center"">
  <a href =""##""><img style=""box-shadow: 8px 8px 5px #888888;""alt=""spring_vue"" src=""http://i2.muimg.com/536217/5ae4b10becac44b0.png""></a>
  
## What's Webpack

Webpack is a powerful tool that bundles your app source code efficiently and loads that code from a server into a browser. It‘s excellent solution in frontend automation project.

## Demo


This's a sample ShangHai people information system as example demo.

[![demo-image](https://github.com/boylegu/SpringBoot-vue/blob/master/images/demo.gif?raw=true)]()

### Feature (v0.1)
- Spring Boot (Back-end) 

  - Build RestFul-API on SpringBoot with `@RequestMapping` and base CRUD logic implementation

  - Handle CORS(Cross-origin resource sharing) 

  - Unit test on SpringBoot

  - Support hot reload

  - Add interface documents about it's rest-api

  - Pagination implementation of RestFul-API with JPA and SpringBoot

- VueJS & webpack (front-end)

  - Follow ECMAScript 6

  - What about coding by single file components in vueJS
  
  - Simple none parent-child communication and parent-child communication 

  - Interworking is between data and back-end
  
  - How grace import third JS package in vue
  
  - Handle format datetime
  
  - Pagination implementation
  
  - Reusable components
  
     - DbHeader.vue
     - DbFooter.vue  (sticky footer) 
     - DbFilterinput.vue
     - DbModal.vue
     - DbSidebar.vue
     - DbTable.vue

  - Config front-end env on webpack2 (include in vue2, handle static file, build different environment...... with webpack2)

### Main technology stack

- Java 1.8+
- Spring Boot 1.5.x
- Maven
- sqlite (not recommend, only convenience example)
- vueJS 2.x
- webpack 2.x
- element ui
- axios

### Preparation

- Please must install Java 1.8  or even higher version
- install Node.js / NPM
- Clone Repository

        git clone https://github.com/boylegu/SpringBoot-vue.git
        
        cd springboot_vue


### Installation  
        
- Build front-end environment

        cd springboot_vue/frontend

        npm install 

### Usage

- Run back-end server

        cd springboot_vue/target/
        
        java -jar springboot_vue-0.0.1-SNAPSHOT.jar

[![](https://github.com/boylegu/SpringBoot-vue/blob/master/images/spring_run.png?raw=true)]()

- Run Front-end Web Page

        cd springboot_vue/frontend

        npm run dev

> You can also run `cd springboot_vue/frontend;npm run build` and it's with Nginx in the production environment


## Future Plan

This project can be reference,study or teaching demonstration. After, I will update at every increment version in succession. In future,I have already some plan to below:

1. User Authentication
2. state manage with vuex
3. use vue-route
4. add docker deploy method
5. support yarn
... ...

## Support

1. Github Issue

2. To e-mail: gubaoer@hotmail.com

3. You can also join to QQ Group: 315308272

## Related projects

- [Sanic-Vue for Python](https://github.com/boylegu/SanicCRUD-vue)

## My Final Thoughts

```
      .   ____          _
     /\\ / ___'_ __ _ _(_)_ __  __ _
    ( ( )\___ | '_ | '_| | '_ \/ _` |
     \\/  ___)| |_)| | | | | || (_| |
      '  |____| .__|_| |_|_| |_\__, |
\  ===========|_|==============|___/== ▀
\- ▌          SpringBoot-vue             ▀
 - ▌                            (o)        ▀
/- ▌            Go Go Go !               ▀
/  =================================== ▀
                    ██


```
"
coditori/javatori,master,44,27,2016-10-30T09:17:02Z,4270,14,"Code Tutorials, Examples, and Best Practices.",best-practices cxf examples hamcrest hibernate java jax-rs junit mockito spring spring-boot spring-data-jpa spring-mvc spring-security swagger-ui tutorial tutorial-code tutorial-exercises tutorials,"# Java Code Tutorials, Spring boot Integrations
These projects usually are a simple Enterprise combination of existing technologies. The following sample applications are provided:
<table>
<thead>
<tr>
<th>Sample</th>
<th align=""center"">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan=""2""><strong>projects</strong></td>
</tr>
<tr>
<td><a href=""/projects/spring-boot-reactive-restful-nosql-mongodb"">Spring Boot, WebFlux, MongoDB</a></td>
<td align=""center"">WebFlux API with entire reactive process and Integration Test</td>
</tr>
<tr>
<td><a href=""/projects/spring-boot-reactive-restful-rdbms"">Spring Boot, WebFlux, H2</a></td>
<td align=""center"">WebFlux API with reactive web and service layer (not repository layer) and Integration (End-To-End) Test</td>
</tr>
<tr>
<td><a href=""/projects/spring-boot-actuator-logger"">Spring Boot Actuator</a></td>
<td align=""center"">If need Log files rather than Actuator Endpoints according to Security concerns, Can be used alongside Syslog and Elasticsearch</td>
</tr>
<tr>
<td><a href=""/projects/spring-boot-cxf"">Spring Boot, CXF JAX-RS</a></td>
<td align=""center"">CXF is good for ""both"" JAX-RS and JAX-WS</td>
</tr>
<tr>
<td><a href=""/projects/spring-boot-restful"">Spring Boot RESTful</a></td>
<td align=""center"">If don't care about JAX-RS standards use Spring RESTful</td>
</tr>
<tr>
<td><a href=""/projects/spring-boot-maven-modules/spring-boot-restful"">""Modular"" Spring Boot RESTful</a></td>
<td align=""center"">A Separated layers project but a Modular application is an old approach take a look at Microservices</td>
</tr>
<tr>
<td><a href=""/projects/hibernate"">Hibernate</a></td>
<td align=""center"">A bare Hibernate layer to work on just Data Access Layer (working on DB)</td>
</tr>
</tbody>
</table>
"
aws-samples/serverless-snippets,main,114,71,2022-07-22T12:06:44Z,16766,11,Snippets of code used for Serverless Development. Code examples hosted on serverlessland.com/snippets,aws serverless snippets,"<div align=""center"">

<h1>⚡️ Serverless Snippets</h1>
<p>Discover, Explore and Share Serverless Snippets.</>

<hr />

<img alt=""header"" src=""./snippets.png"" />

  <h3>Features: Discover and explore reuseable code samples, Filter snippets, 1 click deploy, Supports any programming language, and much more...</h3>

 [View Snippets](https://serverlessland.com/snippets)

</div>

<hr/>

This repo contains Serverless Snippets that you can copy to help develop your own projects.

These snippets are hosted on [Serverless Land](https://serverlessland.com/snippets).

## Why Serverless Snippets was created?

Across the community and internet there are hundreds of examples of how to use AWS Services with code, tutorials and examples. Often developers are repeating small tasks going back to previous local code snippets and reusing them. 

This collection on [ServerlessLand](https://serverlessland.com) is designed to help engineers share useful code with each other.

With Serverless Snippets engineers can find, explore and filter snippets, and as contributions grow we hope Severless Snippets can simplify your development experince.

---

## How can you contribute?

Serverless Snippets is designed to help the community find and explore code and tools. We welcome contributions to the Snippet list. You can add simple snippets, multi stage snippets (instructions), or tabbed snippets (think snippets supporting multiple run times).

- Learn more about these snippets at https://serverlessland.com/snippets.
- To learn more about submitting a snippet, read the [adding snippet guide](https://github.com/aws-samples/serverless-snippets/blob/main/ADDING_SNIPPET.md).


---

## Linking Snippets Directly into the AWS Console.

Thanks to [https://twitter.com/lajacobsson](https://twitter.com/lajacobsson) it is possible to enable the CloudWatch Insights Queries directly into your AWS console and have them update every 12 hours.

Check the project [https://github.com/ljacobsson/cw-logs-insights-snippets](https://github.com/ljacobsson/cw-logs-insights-snippets) to get started.

<img width=""1277"" alt=""image"" src=""https://user-images.githubusercontent.com/3268013/184601436-61ceb2e0-a128-4490-abc8-6e9ffd5577ca.png"">




---

Important: this application could use various AWS services and there are costs associated with these services after the Free Tier usage - please see the [AWS Pricing page](https://aws.amazon.com/pricing/) for details. You are responsible for any AWS costs incurred. No warranty is implied in this example.


----
Copyright 2022 Amazon.com, Inc. or its affiliates. All Rights Reserved.

SPDX-License-Identifier: MIT-0
"
storm-book/examples-ch06-real-life-app,master,31,30,2012-04-06T05:10:31Z,754,0,A Storm Based DRPC Search Engine,,
bbilger/jrestless-examples,master,29,13,2016-08-16T18:37:41Z,1348,4,JRestless Examples,api-gateway aws-lambda java jax-rs jersey jrestless serverless,"# JRestless Examples

[![Build Status](https://travis-ci.org/bbilger/jrestless-examples.svg?branch=master)](https://travis-ci.org/bbilger/jrestless-examples)
[![GitHub issues](https://img.shields.io/github/issues/bbilger/jrestless-examples.svg)](https://github.com/bbilger/jrestless-examples/issues)
[![GitHub license](https://img.shields.io/badge/license-Apache%202-blue.svg)](https://raw.githubusercontent.com/bbilger/jrestless-examples/master/LICENSE)

This repository contains examples for [JRestlesss](https://github.com/bbilger/jrestless).

## Deployment

JRestless does not depend on the [serverless framework](https://github.com/serverless/serverless) but it simplifies the necessary AWS configuration tremendously. So all examples contain a `serverless` configuration and the installation descriptions assume you have `serverless` installed and configured.

You can install `serverless` as described in the docs https://serverless.com/framework/docs/guide/installing-serverless/

To run the AWS examples setup your AWS account as described in the docs https://serverless.com/framework/docs/providers/aws/guide/credentials/

## Build

All examples can be built either with Gradle or Maven. The default build system, however, is Gradle.

If you want to use Maven you have to replace `artifact: build/distributions/SOME-EXAMPLE.zip` by `artifact: target/SOME-EXAMPLE.jar` in all `serverless.yml` files or at least the example you want to try out. You can run the following script to do this automatically:

```bash
git clone https://github.com/bbilger/jrestless-examples.git
cd jrestless-examples
find . -path ./.git -prune -o -name 'serverless.yml' -type f -exec sed -i 's/artifact: build\/distributions\/\([a-z0-9-]\+\)\.zip/artifact: target\/\1.jar/' {} +
```

The descriptions of the examples are also valid for Gradle, only. If you use Maven, use ""mvn package"" instead of ""./gradlew build"".

## Examples

* [AWS](aws)
  * [API Gateway](aws/gateway)
    * [aws-gateway-showcase](aws/gateway/aws-gateway-showcase)
      * Example showing JRestless' features.
    * [aws-gateway-spring](aws/gateway/aws-gateway-spring)
      * Example showing how to use Spring in JRestless.
    * [aws-gateway-cdi](aws/gateway/aws-gateway-cdi)
      * Example showing how to use CDI/Weld in JRestless.
    * [aws-gateway-cors](aws/gateway/aws-gateway-cors-frontend)
      * Example showing how to use CORS in JRestless.
    * [aws-gateway-guice](aws/gateway/aws-gateway-guice)
      * Example showing how to use Guice in JRestless.
    * [aws-gateway-usage-example](aws/gateway/aws-gateway-usage-example)
      * Simple JRestless usage example.
    * [aws-gateway-binary](aws/gateway/aws-gateway-binary)
      * Example showing how to return and receive binary data.
    * [aws-gateway-security-cognito-authorizer](aws/gateway/aws-gateway-security-cognito-authorizer)
      * Example showing how to use a cognito user pool authorizer.
    * [aws-gateway-security-custom-authorizer](aws/gateway/aws-gateway-security-custom-authorizer)
      * Example showing how to use a custom authorizer.
  * [Lambda Service Function](aws/service)
    * [aws-service-usage-example](aws/service/aws-service-usage-example)
      * Example showing how to invoke one Lambda (service) function from another (API Gateway).
  * [SNS Function](aws/sns)
    * [aws-sns-usage-example](aws/sns/aws-sns-usage-example)
      * Example showing how to use JRestless to handle SNS notifications.
"
jonsychen/microservices-examples,master,34,13,2017-05-26T06:43:22Z,372,0,基于Spring Boot/Spring Cloud 的微服务架构,microservice spring-boot spring-cloud,"# 基于Spring Boot/Spring Cloud 的微服务架构
## 项目介绍
### 预备知识
+ <a href=""https://start.spring.io/"" target=""_blank"">创建一个Spring Boot初始项目</a>
+ <a href=""https://springcloud.cc/"" target=""_blank"">Spring Cloud 相关项目</a>

### 项目结构
+ config : 配置文件仓库
+ api-config : 配置管理中心
+ api-registry : 服务注册中心
+ api-gateway : 服务网关
+ api-monitor : 服务监控中心
+ api-service1 : 测试服务1
+ api-service2 : 测试服务2

### 项目架构
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/architecture.png)

## RUN DEMO
### 运行api-registry
    访问地址：http://localhost:8761/
![image](https://github.com/jonsychen/rest-security-demo/raw/master/etc/gettoken.png)
### 运行api-config
### 运行api-gateway
### 运行api-service1,api-service2
### 运行api-monitor
### 运行结束后，配置中心如下：
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/registercenter.png)
### 下面开始测试同步/异步接口，同步使用restful，异步使用基于rabbitmq的消息队列实现。
### 示例1(同步)
    1.使用postman通过网关访问service1提供的sayhi服务。
	2.网关收到请求后，解析请求的url，并匹配动态路由表，找到对应的服务名后向注册中心获取service1服务的当前运行的所有实例，再通过客服端负载均衡，将请求发送到指定的server1服务示例上。
	3.service1服务实例收到sayhi请求，同样经过客户端负载均衡后，调用service2服务的指定实例。
	4.service2服务实例收到sayhi请求，开始执行sayhi方法，打印并返回“hi from service2”。
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/service1_sayhi.png)

### 示例2(异步)
	1.使用postman通过网关访问service1提供的send服务。
	2.网关收到请求后，解析请求的url，并匹配动态路由表，找到对应的服务名后向注册中心获取service1服务的当前运行的所有实例，再通过客服端负载均衡，将请求发送到指定的service1服务示例上。
    3.service1服务实例收到send请求，接收请求参数，并将参数继续发送到指定的队列，等待其他服务处理后续操作，同步返回""message has been sent successfully""。
	4.service2监听指定队列，接收到待处理的消息，打印消息内容。
	5.service2处理完消息后，将处理结果发送到指定队列。
	6.service1监听指定结果通知队列，接收到待处理的消息，打印消息内容。
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/service1_send.png)

### 示例3（实现动态配置的更改）
    1.使用http get ""localhost:8881/author"", 来使用网关提供的打印author服务。
	2.网关收到打印author的请求，开始打印并返回author为""Jonsy（author.name具体的值定义在配置文件中）。
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/gateway_author1.jpg)
###
	3.修改配置仓库中service1-dev.properties中的author.name为""frank""。
	4.使用http post ""localhost:8881/bus/refresh?destination=gateway:**"",刷新服务名为gateway的所有服务实例。
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/gateway_author2.jpg)
###	
	5.再次使用http get ""localhost:8881/author"", 来使用网关提供的打印author服务。
	6.网关收到打印author的请求，开始打印并返回author为""frank”（配置修改已生效）
![image](https://github.com/jonsychen/microservices-examples/blob/master/etc/gateway_author3.jpg)


### 需要注意的地方
    1.这个架构使用rabbitmq作为消息总线，所以需要用户自行安装rabbitmq，并修改配置仓库中的相关配置。
	2.配置中心里面配置的仓库地址，需要修改为自己的仓库地址。
	3.IOC容器中的对象引用配置文件变量的时候，需要在类名上加上@RefreshScope来强制更新，否则动态修改的配置文件内容不会重新加载。

## 联系我
    Email: jonsychen@hotmail.com/i@jonsy.me
    OICQ: 903352005
    WeChat: Jonsychen_2013 
"
dkpro/dkpro-core-examples,master,33,17,2015-11-07T10:35:39Z,423,3,Ready-to-use examples of dkpro-core components and pipelines.,,"# Ready-to-use examples of dkpro-core components and pipelines

This package, *dkpro-core-examples*, demonstrates the use of [DKPro Core](http://dkpro.github.io/) components, such as readers, annotators, and writers.
Each module in this project refers to a DKPro core component, providing a simple pipeline that is
usable as is.

This branch uses DKPro Core version 1.9.0-SNAPSHOT.

## Content 

So far, *dkpro-core-examples* comprises the following examples:

* **nameannotation-asl**: a dictionary-based name annotator that uses a custom annotation type. 
* **lda-asl**: pipelines to demonstrates how to estimate an LDA model and how to use it to infer topic proportions
in documents. Note that the API and hence the examples have changed in v1.9.x.
* **tokenizedwriter-asl**: demonstrates the `TokenizedTextWriter` which writes all tokens from all documents separated
by whitespaces, one sentence per line; can be used to prepare data for external tools such as Word2Vec. 
* **stanfordcorecomponents-gpl**: demonstrates the usage of the Stanford Core NLP tools; mind that they are
 GPL-licensed!
* **wordembeddings-asl**: a pipeline that shows how to generate [word embeddings](https://en.wikipedia.org/wiki/Word_embedding) from a custom corpus and how to use them with an annotator.
* **phraseannotator-asl**: pipelines demonstrating the usage of the classes `FrequencyCounter` and `PhraseAnnotator` to detect lexical phrases in a frequency-based manner.

## Contact

In case you have any questions or problems with these examples, we are happy to help you -- this is a tutorial project, so we are glad to improve things and make life easier for both new and experienced [DKPro Core](http://dkpro.github.io/) users.
The easiest ways to get in touch are the [DKPro Core mailing lists](https://dkpro.github.io/dkpro-core/pages/mailinglists/) or to [submit an issue](https://github.com/dkpro/dkpro-core-examples/issues).
"
LorenzoBettini/packtpub-xtext-book-examples,master,34,20,2013-08-01T08:28:39Z,4623,1,"Examples for the book Implementing Domain-Specific Languages with Xtext and Xtend"" 978-1782160304""",,"Implementing Domain-Specific Languages with Xtext and Xtend
============================

This repository contains the sources of the Examples for the book  
*""Implementing Domain-Specific Languages with Xtext and Xtend""*  
ISBN: 978-1782160304

http://www.packtpub.com/implementing-domain-specific-languages-with-xtext-and-xtend/book

ERRATA and changes in new versions of Xtext
====

The book was written using Xtext 2.4.2 and some changes were introduced in new versions of Xtext that require some modifications in the sources (and make some parts written in the book not consistent).

In the following we detail the changes required to adapt the examples to the new versions of Xtext.

## General Book ERRATA

Some initial ERRATA, related to errors and typos in the text of the book can be found on the publisher web site: select ""Support"", search for the book, e.g., type ""Xtext"" and select the book title.  It should be possible to access it directly following [this link](https://www.packtpub.com/books/content/support/12928).

As reported in Issue https://github.com/LorenzoBettini/packtpub-xtext-book-examples/issues/1 in the ExpressionsTypeProvider and ExpressionsInterpreter xtend files, you get compilation errors ""Cannot convert..."" if you have only one dispatch method for an Expression class; as soon as you add another dispatch method, say, e.g., one for Variable, the error will go away, since a method accepting AbstractElement will be generated. 

## Xtext 2.4.3

Xtext 2.4.3 generates the .ecore (and the corresponding .genmodel) file in the directory model/generated underneath the project directory, and not in the src-gen folder.

This is due to a new generation fragment in the mwe2 file: instead of


	fragment = ecore.EcoreGeneratorFragment auto-inject {

(which is now deprecated) the following fragment is now used by default in new Xtext projects

	fragment = ecore.EMFGeneratorFragment auto-inject {

and this fragment generates the .ecore and the .genmodel files in the folder ""model/generated""

## Xtext 2.5

To specify a type literal you can simply write its name: there's no need to use the keyword **typeof** anymore.

For example, instead of

	typeof(String)

you can simply write

	String

## Xtext 2.6


### Xbase

The Xbase rule **XExpressionInsideBlock** has changed into **XExpressionOrVarDeclaration**.

Thus, the Xbase Expressions example's grammar now reads:

	ExpressionsModel returns XBlockExpression:
		{ExpressionsModel}
		(expressions+=XExpressionOrVarDeclaration)*;

## Xtext 2.7

### Testing with CompilationTestHelper

The class **org.eclipse.xtext.xbase.compiler.CompilationTestHelper** (contained in the bundle _org.eclipse.xtext.xbase.junit_) requires additional bindings which are created by default when your grammar uses Xbase.  However, this class could be used also for testing code generation also in languages that do not use Xbase (this is the case in the book, Chapter 7, for the examples Entities and Expressions); see also [this discussion in the Xtext forum](https://www.eclipse.org/forums/index.php/t/807828/).

The symptom is this exception when running the Junit tests that use CompilationTestHelper

	com.google.inject.ConfigurationException: Guice configuration errors:
	
	1) No implementation for org.eclipse.xtend.lib.macro.file.MutableFileSystemSupport was bound.
	  while locating org.eclipse.xtend.lib.macro.file.MutableFileSystemSupport
	    for field at org.eclipse.xtext.generator.FileSystemSupportBasedFileSystemAccess.fileSystemSupport(Unknown Source)
	  while locating com.google.inject.Provider<org.eclipse.xtext.xbase.compiler.RegisteringFileSystemAccess>
	    for field at org.eclipse.xtext.xbase.compiler.CompilationTestHelper$Result.fileSystemAccessProvider(Unknown Source)
	  while locating com.google.inject.Provider<org.eclipse.xtext.xbase.compiler.CompilationTestHelper$Result>
	    for field at org.eclipse.xtext.xbase.compiler.CompilationTestHelper.resultProvider(Unknown Source)
	  while locating org.eclipse.xtext.xbase.compiler.CompilationTestHelper
	    for field at org.example.expressions.tests.ExpressionsGeneratorTest._compilationTestHelper(Unknown Source)
	  while locating org.example.expressions.tests.ExpressionsGeneratorTest

To solve this problem the missing bindings in languages that do not use Xbase must be added explicitly; there are two ways of solving this:

**1. Add the bindings in the runtime module of the language**

For example, for the Entities example, you must add the following bindings in the _EntitiesRuntimeModule_ (first, make sure you have the following dependencies in the MANIFEST.MF: _org.eclipse.xtend.lib.macro_ and _org.eclipse.xtext.xbase_):

```javascript
public class EntitiesRuntimeModule extends org.example.entities.AbstractEntitiesRuntimeModule {

    //... existing bindings

    // this is required only by the CompilationTestHelper since Xtext 2.7
    public Class<? extends org.eclipse.xtend.lib.macro.file.MutableFileSystemSupport> bindMutableFileSystemSupport() {
		return org.eclipse.xtext.xbase.file.JavaIOFileSystemSupport.class;
	}

    // this is required only by the CompilationTestHelper since Xtext 2.7
    public Class<? extends com.google.inject.Provider<org.eclipse.xtext.xbase.file.WorkspaceConfig>> provideWorkspaceConfig() {
		return org.eclipse.xtext.xbase.file.RuntimeWorkspaceConfigProvider.class;
	}
} 
```

**2. Add the bindings in a custom InjectorProvider in the tests project**

If you do not want to add these bindings in the main DSL runtime module (after all, you need them only for testing), you can create a custom injector provider in the tests project (inheriting from the generated one in src-gen folder) to be used only for the test(s) that use CompilationTestHelper.  This custom injector provider must define a custom Guice module, inheriting from the DSL main module, and provide the additional bindings.

For example, for the Expressions example, you must add the following class in the test project (first, make sure you have the following dependencies in the MANIFEST.MF: _org.eclipse.xtend.lib.macro_ and _org.eclipse.xtext.xbase_):

```javascript
package org.example.expressions.tests;

import org.example.expressions.ExpressionsInjectorProvider;
import org.example.expressions.ExpressionsRuntimeModule;
import org.example.expressions.ExpressionsStandaloneSetup;

import com.google.inject.Guice;
import com.google.inject.Injector;

public class ExpressionsInjectorProviderCustom extends ExpressionsInjectorProvider {

	@Override
	protected Injector internalCreateInjector() {
		return new ExpressionsStandaloneSetup() {
			@Override
			public Injector createInjector() {
				return Guice.createInjector(new ExpressionsRuntimeModule() {
					// this is required only by the CompilationTestHelper since
					// Xtext 2.7
					@SuppressWarnings(""unused"")
					public Class<? extends org.eclipse.xtend.lib.macro.file.MutableFileSystemSupport> bindMutableFileSystemSupport() {
						return org.eclipse.xtext.xbase.file.JavaIOFileSystemSupport.class;
					}

					// this is required only by the CompilationTestHelper since
					// Xtext 2.7
					@SuppressWarnings(""unused"")
					public Class<? extends com.google.inject.Provider<org.eclipse.xtext.xbase.file.WorkspaceConfig>> provideWorkspaceConfig() {
						return org.eclipse.xtext.xbase.file.RuntimeWorkspaceConfigProvider.class;
					}
				});
			}
		}.createInjectorAndDoEMFRegistration();
	}
}
```

And then you must use this injector provider in the @InjectWith annotation of the test that uses CompilationTestHelper; in this example:

```javascript
@RunWith(typeof(XtextRunner))
@InjectWith(typeof(ExpressionsInjectorProviderCustom))
class ExpressionsGeneratorTest {
	
	@Inject extension CompilationTestHelper
	...
```


### Inject Xtext TemporaryFolder when using CompilationTestHelper

This is not a strict requirement, but Xtext 2.7 introduced an improved version of _TemporaryFolder_ (see org.junit.rules.TemporaryFolder), it ""allows creation of files and folders that are guaranteed to be deleted when the test method finishes (whether it passes or fails)"".

If you want to use this improved version, you need to inject it with the @Rule annotation, e.g.,

```javascript
import org.eclipse.xtext.junit4.TemporaryFolder

@RunWith(typeof(XtextRunner))
@InjectWith(typeof(EntitiesInjectorProvider))
class EntitiesGeneratorTest {
	
	@Rule
	@Inject public TemporaryFolder temporaryFolder
	
	@Inject extension CompilationTestHelper
	...
```

### Model inferrer in Xbase

Some methods in the JvmModelInferrer have been deprecated and should be updated in the examples as follows:

Instead of the following acceptor invocation

	acceptor.accept(entity.toClass(""entities.""+entity.name)).initializeLater [

You should now pass directly as the last argument a lambda expression

	acceptor.accept(entity.toClass(""entities.""+entity.name)) [

This method in the JvmTypesBuilder has been deprecated

```javascript
@Deprecated
public JvmTypeReference newTypeRef(EObject ctx, Class<?> clazz, JvmTypeReference... typeArgs) {
	return references.getTypeForName(clazz, ctx, typeArgs);
}
```

In the inferrer you should call directly 

```javascript
public JvmTypeReference typeRef(Class<?> clazz, JvmTypeReference... typeArgs) {
```

(So the EObject context is not required anymore).

For example, instead of

	entity.toMethod(""toString"", entity.newTypeRef(typeof(String)))

You should write (recall that typeof is not required anymore to specify a type literal):

	entity.toMethod(""toString"", typeRef(String))

### Xtext Buckminster Wizard

This wizard provided by Xtext was not updated and it generates the projects-platform.rmap incorrectly (see also [this forum post](https://www.eclipse.org/forums/index.php/t/811323/)); the quickiest way to fix it is to change the property _eclipse.target.platform_ from _juno_ (or _kepler_) to _luna_ so that the new version of EMF, required by Xtext 2.7, will be found in the Luna update site. 

Moreover, recently, another architecture fragment has been introduced, ""pcc64le"", which is only available from the ""Luna Updates"" site, not from the main ""Luna Releases""; you should then update the target plaform RMAP in order to use also the eclipse/updates/4.4 update site
(see the updated [projects-platform.rmap](https://github.com/LorenzoBettini/packtpub-xtext-book-examples/blob/master/org.example.build.hello.buckminster/projects-platform.rmap ""projects-platform.rmap"") file in the org.example.build.hello.buckminster example).

The sympthom of this problem is this error during target platform resolution:

```
ERROR   [0007] : No suitable provider for component 
org.eclipse.core.filesystem.linux.ppc64le:osgi.bundle/[1.4.0.v20140808-1353,1.4.0.v20140808-1353]
    (&(target.arch=ppc64le)(target.os=linux))
    was found in resourceMap ... projects-platform.rmap
```

## Xtext 2.8

All Xtext plug-ins now require JavaSE-1.6 as execution environment.  If you start from scratch new Xtext projects, you don't have to worry about that.  However, if you had previously created Xtext projects, you need to adjust them all so that at least JavaSE-1.6 is specified as the execution environment.

You can do that with a Search-Replace in the workspace:

- in the files org.eclipse.jdt.core.prefs you need to replace 1.5 with 1.6
- in MANIFEST.MF and .classpath files you need to replace J2SE-1.5 with JavaSE-1.6

Running the mwe2 workflows requires in the classpath.  Again, if you start from scratch new Xtext projects, you don't have to worry about that.  Otherwise, you will experience such errors when running the mwe2 workflow

```
Could not load class: org.eclipse.core.runtime.OperationCanceledException
Add org.eclipse.equinox.common to the class path.
```

To solve this, just add org.eclipse.equinox.common as dependency in your DSL main project.

Just like with every new version of Xtext, please run mwe2 to re-generate all the artifacts, and make sure to merge the plugin.xml with the plugin.xml_gen.

### Xtext 2.8 new formatter API

Xtext 2.8 introduced a new formatter API (currently provisional), more details can be found here: https://www.eclipse.org/Xtext/releasenotes.html#/releasenotes/2015/03/11/version-2-8-0.

To enable the new formatter API, the mwe2 file should be changed:

	fragment = formatting2.Formatter2Fragment {}

Please note that the new formatter API is completely different from the previous one, described in the book.
"
NationalSecurityAgency/skills-client-examples,master,28,17,2020-02-24T16:12:35Z,171,1,SkillTree skills-client-examples,,"# SkillTree Integration Examples

SkillTree is an innovative approach to implementing application training.

To learn about the SkillTree platform please visit our [Official Documentation](https://code.nsa.gov/skills-docs/). 
These pages provide in-depth guidance on the installation, usage and contribution. 

# Workflows Status

[![CI Badge](https://github.com/NationalSecurityAgency/skills-client-examples/workflows/Continuous%20Integration/badge.svg)](https://github.com/NationalSecurityAgency/skills-client-examples/actions?query=workflow%3A%22Continuous+Integration%22)

"
rubel007cse/MasteringJava,master,36,28,2016-12-05T14:07:07Z,320,0,Best of Java Examples for Learning,,"# MasteringJava
Best of Java Examples for Learning.
[Go to [/src ](https://github.com/rubel007cse/MasteringJava/tree/master/src ""Click to go to '/src' "")folder from above for exploring details examples with comments to each code line.]
## Example of Following topics
1. HelloWorld : My first Java program
2. Learning Basic Java Syntax
3. Java DataTypes examples
4. Java Variables
5. Knowing Java Operators
6. Java Number and Java String learning
7. Practicing Java if-else Loops
8. Learning Java Switch Statement
9. Java Array Practicing Examples
10. Working with Java Methods
11. Understanding the Java Class and Objects
12. Testing Java Exception
13. Java Exception throwing examples
14. Java Inheritance
15. Java Overriding , OverLoading
16. Java Polymorphism
17. Abstraction in Java
18. Learning Java Interfaces
19. Encapsulation in Java & Getter Setter
20. Java Thread
21. Java Constructor
22. IS A, HAS A Relation
23. This Keyword
24. Java Operators
25. Java Access Modifier
26. Super KeyWord
27. Java Enum
28. Java Singleton
29. Generics
30. Collections
31. ArrayList
32. Iterating
33. LinkedList
34. Map
35. File i/o

![learn-java-book-by-mosharrof-rubel](https://cloud.githubusercontent.com/assets/8050966/25072666/7e219bd6-22f6-11e7-8ee3-0bd2b9a3d35a.jpg)

# [Order Book from Rokomari ](https://goo.gl/zjo5yY)

## About Me
Software Specialist |  Java/Android Dev | Author | Lecturer at Southeast University (Part time)

Find me on Socials :
[ [Linkedin ](https://www.linkedin.com/in/rubel007cse ""Click to go to 'Linkedin' "") ]
[ [Facebook ](https://www.facebook.com/rubel007cse ""Click to go to 'Facebook' "") ]
[ [Web ](http://mrubel.com ""Click to go to 'MRubel.com' "") ]
"
aspose-email/Aspose.Email-for-Java,master,32,24,2011-11-25T14:04:36Z,38539,4,Aspose.Email for Java Examples,,"![GitHub all releases](https://img.shields.io/github/downloads/aspose-email/Aspose.email-for-Java/total) ![GitHub](https://img.shields.io/github/license/aspose-email/Aspose.email-for-java)
# Java Email API

[Aspose.Email for Java](https://products.aspose.com/email/java) is a complete set of Email Processing APIs to create, read and manipulate emails from within your applications. It makes it easier to work with many Outlook email message formats such as MSG, EML, EMLX and MHT files without the need of installing Microsoft Outlook. It also enables you to manage message storage files - Personal Storage Files (PST), Offline Storage Files (OST) along with message sending and receiving capabilities. You can also read and extract Outlook PST file that can be saved to disk in MSG format.

Directory | Description
--------- | -----------
[Examples](https://github.com/aspose-email/Aspose.Email-for-Java/tree/master/Examples) | A collection of Java examples that help you learn the product features.
[Plugins](https://github.com/aspose-email/Aspose.Email-for-Java/tree/master/Plugins) | Plugins that will demonstrate one or more features of Aspose.Email for Java.

<p align=""center"">
  <a title=""Download complete Aspose.Email for Java source code"" href=""https://github.com/asposeemail/Aspose_Email_Java/archive/master.zip"">
    <img src=""https://raw.githubusercontent.com/AsposeExamples/java-examples-dashboard/master/images/downloadZip-Button-Large.png"" />
  </a>
</p>

## Email API Features

- Create messages from scratch or load existing email files for editing.
- Create and Set contents of MIME messages.
- Extract contents from emails.
- Load and save [appointment in ICS format](https://docs.aspose.com/email/java/working-with-appointments/).
- Ability to connect to SMTP, POP3, IMAP, Exchange server.
- Works with Thunderbird, Zimbra and IBM Notes.

## Read & Write Email Formats

**Microsoft Outlook:** MSG, PST, OST, OFT\
**Email:** EML, EMLX, MBOX\
**Others:** ICS, VCF, HTML, MHTML

## Read Email Formats

**Mac Outlook:** OLM

## Supported Environments

- **Microsoft Windows:** Windows Desktop & Server (x86, x64)
- **macOS:** Mac OS X
- **Linux:** Ubuntu, OpenSUSE, CentOS, and others
- **Java Versions:** `J2SE 7.0 (1.7)`, `J2SE 8.0 (1.8)`

## Get Started with Aspose.Email for Java

Aspose hosts all Java APIs at the [Aspose Repository](https://repository.aspose.com/webapp/#/artifacts/browse/tree/General/repo/com/aspose/aspose-email). You can easily use Aspose.BarCode for Java API directly in your Maven projects with simple configurations. For the detailed instructions please visit [Installing Aspose.Email for Java from Maven Repository](https://docs.aspose.com/email/java/installation/) documentation page.

## Perform IMAP Message Backup Operation using Java

```java
ImapClient imapClient = new ImapClient();
imapClient.setHost(""<HOST>"");
imapClient.setPort(993);
imapClient.setUsername(""<USERNAME>"");
imapClient.setPassword(""<PASSWORD>"");
imapClient.setSupportedEncryption(EncryptionProtocols.Tls);
imapClient.setSecurityOptions(SecurityOptions.SSLImplicit);

ImapMailboxInfo mailboxInfo = imapClient.getMailboxInfo();

ImapFolderInfo info = imapClient.getFolderInfo(mailboxInfo.getInbox().getName());
ImapFolderInfoCollection infos = new ImapFolderInfoCollection();
infos.add(info);

imapClient.backup(infos, dataDir + ""\\ImapBackup.pst"", BackupOptions.None);
```

[Home](https://www.aspose.com/) | [Product Page](https://products.aspose.com/email/java) | [Docs](https://docs.aspose.com/email/java/) | [Demos](https://products.aspose.app/email/family) | [API Reference](https://apireference.aspose.com/email/java) | [Examples](https://github.com/aspose-email/Aspose.Email-for-Java) | [Blog](https://blog.aspose.com/category/email/) | [Search](https://search.aspose.com/) | [Free Support](https://forum.aspose.com/c/email) | [Temporary License](https://purchase.aspose.com/temporary-license)
"
stuartaroth/programmersguidetothegalaxy,master,63,15,2016-04-07T01:07:12Z,254,3,Syntax Examples across Languages,,"##### www.programmersguidetothegalaxy.com is a project with a simple goal:
##### Allow engineers to quickly learn how to do ""x"" in ""y"" language.

While programming concepts are universal, syntax is not. This project aims to give users a tool that will allow them to get working quickly on technology stacks that are new to them.

This project can help add to your tool belt, allowing you to easily use the best libraries and frameworks for the task at hand, regardless of your current experience and knowledge.

> If all you have is a hammer, everything looks like a nail

##### Contributing

Pull requests are very welcome! All new code should follow the established style.

Currently the focus should be adding new languages, across all the currently included folders/concepts.

New folders/concepts should try to include examples across all supported languages.

Before pull requesting, you should run the command ./run_all_examples.sh

When doing this all your code should compile and run.

Issues can be used to report bugs / request languages and folders.

Here is the current site repo:
https://github.com/stuartaroth/programmersguidetothegalaxy-site-jquery
"
rosshambrick/AsyncExamples,master,53,10,2015-03-06T21:06:43Z,232,2,,,"# AsyncExamples
"
jonashackt/spring-boot-vuejs,master,2024,684,2017-09-11T09:42:52Z,25651,22,Example project showing how to build a Spring Boot App providing a GUI with Vue.js,axios backend docker frontend heroku jest nightwatch rest-api rest-backend spring-boot vue vue-cli vue-cli-3 vue-cli-plugin vue-frontend vuejs vuejs2 webpack,"# spring-boot-vuejs

[![Build Status](https://github.com/jonashackt/spring-boot-vuejs/workflows/build/badge.svg)](https://github.com/jonashackt/spring-boot-vuejs/actions)
[![codecov](https://codecov.io/gh/jonashackt/spring-boot-vuejs/branch/master/graph/badge.svg?token=gMQBTyKuKS)](https://codecov.io/gh/jonashackt/spring-boot-vuejs)
[![License](http://img.shields.io/:license-mit-blue.svg)](https://github.com/jonashackt/spring-boot-vuejs/blob/master/LICENSE)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)
[![versionspringboot](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27parent%27%5D%2F%2A%5Blocal-name%28%29%3D%27version%27%5D&label=springboot)](https://github.com/spring-projects/spring-boot)
[![versionjava](https://img.shields.io/badge/jdk-8,_11,_15-brightgreen.svg?logo=java)](https://github.com/spring-projects/spring-boot)
[![versionvuejs](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.dependencies.vue&label=vue&logo=vue.js)](https://vuejs.org/)
[![versiontypescript](https://img.shields.io/badge/dynamic/json?color=blue&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.devDependencies.typescript&label=typescript&logo=typescript)](https://www.typescriptlang.org/)
[![versionbootstrap](https://img.shields.io/badge/dynamic/json?color=blueviolet&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.dependencies.bootstrap&label=bootstrap&logo=bootstrap.js)](https://getbootstrap.com/)
[![versionnodejs](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27build%27%5D%2F%2A%5Blocal-name%28%29%3D%27plugins%27%5D%2F%2A%5Blocal-name%28%29%3D%27plugin%27%5D%2F%2A%5Blocal-name%28%29%3D%27executions%27%5D%2F%2A%5Blocal-name%28%29%3D%27execution%27%5D%2F%2A%5Blocal-name%28%29%3D%27configuration%27%5D%2F%2A%5Blocal-name%28%29%3D%27nodeVersion%27%5D&label=nodejs&logo=node.js)](https://nodejs.org/en/)
[![versionwebpack](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package-lock.json&query=$.dependencies.webpack.version&label=webpack&logo=webpack)](https://webpack.js.org/)
[![versionaxios](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.dependencies.axios&label=axios)](https://github.com/axios/axios)
[![versionjest](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package-lock.json&query=$.dependencies.jest.version&label=jest&logo=jest)](https://jestjs.io/)
[![versionnightwatch](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package-lock.json&query=$.dependencies.nightwatch.version&label=nightwatch)](http://nightwatchjs.org/)
[![Deployed on Heroku](https://img.shields.io/badge/heroku-deployed-blueviolet.svg?logo=heroku)](https://spring-boot-vuejs.herokuapp.com/)
[![Pushed to Docker Hub](https://img.shields.io/badge/docker_hub-released-blue.svg?logo=docker)](https://hub.docker.com/r/jonashackt/spring-boot-vuejs)
    
> **If you´re a JavaMagazin / blog.codecentric.de / Softwerker reader**, consider switching to [vue-cli-v2-webpack-v3](https://github.com/jonashackt/spring-boot-vuejs/tree/vue-cli-v2-webpack-v3)

![localhost-first-run](screenshots/localhost-first-run.png)

A live deployment is available on Heroku: https://spring-boot-vuejs.herokuapp.com

This project is used as example in a variety of articles & as eBook:

[![java-magazin-8.2018](screenshots/java-magazin-8.2018.png)](https://jaxenter.de/ausgaben/java-magazin-8-18)
[![entwickler-press-092018](screenshots/entwickler-press-092018.jpg)](https://www.amazon.com/Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook/dp/B07HQF9VX4/ref=sr_1_1?ie=UTF8&qid=1538484852&sr=8-1&keywords=Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook)
[![softwerker-vol12](screenshots/softwerker-vol12.png)](https://info.codecentric.de/softwerker-vol-12)

[blog.codecentric.de/en/2018/04/spring-boot-vuejs](https://blog.codecentric.de/en/2018/04/spring-boot-vuejs) | [JavaMagazin 8.2018](https://jaxenter.de/ausgaben/java-magazin-8-18) | [entwickler.press shortcuts 229](https://www.amazon.com/Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook/dp/B07HQF9VX4/ref=sr_1_1?ie=UTF8&qid=1538484852&sr=8-1&keywords=Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook) | [softwerker Vol.12](https://info.codecentric.de/softwerker-vol-12)

## Upgrade procedure

Get newest node & npm:
```shell
brew upgrade node
npm install -g npm@latest
```

Update vue-cli
```shell
npm install -g @vue/cli
```

Update Vue components/plugins (see https://cli.vuejs.org/migrating-from-v3/#upgrade-all-plugins-at-once)
```shell
vue upgrade
```

## In Search of a new Web Frontend-Framework after 2 Years of absence...

Well, I’m not a Frontend developer. I’m more like playing around with Spring Boot, Web- & Microservices & Docker, automating things with Ansible and Docker, Scaling things with Spring Cloud, Docker Compose, and Traefik... And the only GUIs I’m building are the ""new JS framework in town""-app every two years... :) So the last one was Angular 1 - and it felt, as it was a good choice! I loved the coding experience and after a day of training, I felt able to write awesome Frontends...

But now we’re 2 years later and I heard from afar, that there was a complete rewrite of Angular (2), a new kid in town from Facebook (React) and lots of ES201x stuff and dependency managers like bower and Co. So I’m now in the new 2-year-cycle of trying to cope up again - and so glad I found this article: https://medium.com/reverdev/why-we-moved-from-angular-2-to-vue-js-and-why-we-didnt-choose-react-ef807d9f4163

Key points are:
* Angular 2 isn’t the way to go if you know version 1 (complete re-write, only with Typescript, loss of many of 1’s advantages, Angular 4 is coming)
* React  (facebookish problems (licence), need to choose btw. Redux & MObX, harder learning curve, slower coding speed)

![comparison-angular-react-vuejs](screenshots/comparison-angular-react-vuejs.png)

And the [introduction phrase](https://vuejs.org/v2/guide/index.html) sounds really great:

> Vue (pronounced /vjuː/, like view) is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable. The core library is focused on the view layer only and is very easy to pick up and integrate with other libraries or existing projects. On the other hand, Vue is also perfectly capable of powering sophisticated Single-Page Applications when used in combination with modern tooling and supporting libraries.

So I think, it could be a good idea to invest a day or so into Vue.js. Let’s have a look here!



## Setup Vue.js & Spring Boot

### Prerequisites

#### MacOSX

```
brew install node
npm install -g @vue/cli
```

#### Linux

```
sudo apt update
sudo apt install node
npm install -g @vue/cli
```

#### Windows

```
choco install npm
npm install -g @vue/cli
```

## Project setup

```
spring-boot-vuejs
├─┬ backend     → backend module with Spring Boot code
│ ├── src
│ └── pom.xml
├─┬ frontend    → frontend module with Vue.js code
│ ├── src
│ └── pom.xml
└── pom.xml     → Maven parent pom managing both modules
```

## Backend

Go to https://start.spring.io/ and initialize a Spring Boot app with `Web` and `Actuator`. Place the zip’s contents in the backend folder.

Customize pom to copy content from Frontend for serving it later with the embedded Tomcat:

```xml
<build>
  <plugins>
    <plugin>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-maven-plugin</artifactId>
    </plugin>
    <plugin>
      <artifactId>maven-resources-plugin</artifactId>
      <executions>
        <execution>
          <id>copy Vue.js frontend content</id>
          <phase>generate-resources</phase>
          <goals>
            <goal>copy-resources</goal>
          </goals>
          <configuration>
            <outputDirectory>src/main/resources/public</outputDirectory>
            <overwrite>true</overwrite>
            <resources>
              <resource>
                <directory>${project.parent.basedir}/frontend/target/dist</directory>
                <includes>
                  <include>static/</include>
                  <include>index.html</include>
                  <include>favicon.ico</include>
                </includes>
              </resource>
            </resources>
          </configuration>
        </execution>
      </executions>
    </plugin>
  </plugins>
</build>
```


## Frontend

Creating our `frontend` project is done by the slightly changed (we use `--no-git` here, because our parent project is already a git repository and otherwise vue CLI 3 would initialize an new one):

```
vue create frontend --no-git
```

see https://cli.vuejs.org/guide/

This will initialize a project skeleton for Vue.js in /frontend directory - it, therefore, asks some questions in the cli:

![vuejs-cli3-create](screenshots/vuejs-cli3-create.png)

__Do not__ choose the default preset with `default (babel, eslint)`, because we need some more plugins for our project here (choose the Plugins with the __space bar__):

![vuejs-cli3-select-plugins](screenshots/vuejs-cli3-select-plugins.png)

You can now also use the new `vue ui` command/feature to configure your project:

![vue-ui](screenshots/vue-ui.png)

If you want to learn more about installing Vue.js, head over to the docs: https://vuejs.org/v2/guide/installation.html


### Use frontend-maven-plugin to handle NPM, Node, Bower, Grunt, Gulp, Webpack and so on :)

If you’re a backend dev like me, this Maven plugin here https://github.com/eirslett/frontend-maven-plugin is a great help for you - because, if you know Maven, that’s everything you need! Just add this plugin to the frontend’s `pom.xml`:

```xml
<build>
    <plugins>
        <plugin>
            <groupId>com.github.eirslett</groupId>
            <artifactId>frontend-maven-plugin</artifactId>
            <version>${frontend-maven-plugin.version}</version>
            <executions>
                <!-- Install our node and npm version to run npm/node scripts-->
                <execution>
                    <id>install node and npm</id>
                    <goals>
                        <goal>install-node-and-npm</goal>
                    </goals>
                    <configuration>
                        <nodeVersion>v10.10.0</nodeVersion>
                    </configuration>
                </execution>
                <!-- Install all project dependencies -->
                <execution>
                    <id>npm install</id>
                    <goals>
                        <goal>npm</goal>
                    </goals>
                    <!-- optional: default phase is ""generate-resources"" -->
                    <phase>generate-resources</phase>
                    <!-- Optional configuration which provides for running any npm command -->
                    <configuration>
                        <arguments>install</arguments>
                    </configuration>
                </execution>
                <!-- Build and minify static files -->
                <execution>
                    <id>npm run build</id>
                    <goals>
                        <goal>npm</goal>
                    </goals>
                    <configuration>
                        <arguments>run build</arguments>
        </configuration>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

### Tell Webpack to output the dist/ contents to target/

Commonly, node projects will create a dist/ directory for builds which contains the minified source code of the web app - but we want it all in `/target`. Therefore we need to create the optional [vue.config.js](https://cli.vuejs.org/config/#vue-config-js) and configure the `outputDir` and `assetsDir` correctly: 

```javascript
module.exports = {
  ...
  // Change build paths to make them Maven compatible
  // see https://cli.vuejs.org/config/
  outputDir;: 'target/dist',
  assetsDir;: 'static';
}
```


## First App run

Inside the root directory, do a: 

```
mvn clean install
```

Run our complete Spring Boot App:

```
mvn --projects backend spring-boot:run
```

Now go to http://localhost:8098/ and have a look at your first Vue.js Spring Boot App.



## Faster feedback with webpack-dev-server

The webpack-dev-server, which will update and build every change through all the parts of the JavaScript build-chain, is pre-configured in Vue.js out-of-the-box! So the only thing needed to get fast feedback development-cycle is to cd into `frontend` and run:

```
npm run serve
```

That’s it! 


## Browser developer tools extension

Install vue-devtools Browser extension https://github.com/vuejs/vue-devtools and get better feedback, e.g. in Chrome:

![vue-devtools-chrome](screenshots/vue-devtools-chrome.png)


## IntelliJ integration

There's a blog post: https://blog.jetbrains.com/webstorm/2018/01/working-with-vue-js-in-webstorm/

Especially the `New... Vue Component` looks quite cool :)



## HTTP calls from Vue.js to (Spring Boot) REST backend

Prior to Vue 2.0, there was a build in solution (vue-resource). But from 2.0 on, 3rd party libraries are necessary. One of them is [Axios](https://github.com/mzabriskie/axios) - also see blog post https://alligator.io/vuejs/rest-api-axios/

```
npm install axios --save
```

Calling a REST service with Axios is simple. Go into the script area of your component, e.g. Hello.vue and add:

```js
import axios from 'axios'

data ();{
  return {
    response: [],
    errors: []
  }
},

callRestService ();{
  axios.get(`api/hello`)
    .then(response => {
      // JSON responses are automatically parsed.
      this.response = response.data
    })
    .catch(e => {
      this.errors.push(e)
    })
}
}
```

In your template area you can now request a service call via calling `callRestService()` method and access `response` data:

```html
<button class=”Search__button” @click=""callRestService()"">CALL Spring Boot REST backend service</button>

<h3>{{ response }}</h3>
```

### The problem with SOP

Single-Origin Policy (SOP) could be a problem if we want to develop our app. Because the webpack-dev-server runs on http://localhost:8080 and our Spring Boot REST backend on http://localhost:8098.

We need to use Cross-Origin Resource Sharing Protocol (CORS) to handle that (read more background info about CORS here https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS)


#### Enabling Axios CORS support

Create a central Axios configuration file called `http-commons.js`:

```js
import axios from 'axios'

export const AXIOS = axios.create({
  baseURL: `http://localhost:8098`,
  headers: {
    'Access-Control-Allow-Origin': 'http://localhost:8080'
  }
})
```

Here we allow requests to the base URL of our Spring Boot App on port 8098 to be accessible from 8080.

Now we could use this configuration inside our Components, e.g. in `Hello.vue`:
```js
import {AXIOS} from './http-common'

export default {
  name: 'hello',

  data () {
    return {
      posts: [],
      errors: []
    }
  },
  methods: {
    // Fetches posts when the component is created.
    callRestService () {
      AXIOS.get(`hello`)
        .then(response => {
          // JSON responses are automatically parsed.
          this.posts = response.data
        })
        .catch(e => {
          this.errors.push(e)
        })
    }
  }
```

#### Enabling Spring Boot CORS support

Additionally, we need to configure our Spring Boot backend to answer with the appropriate CORS HTTP Headers in its responses (there's a good tutorial here: https://spring.io/guides/gs/rest-service-cors/). Therefore we add the annotation `@CrossOrigin` to our BackendController:

```java
@CrossOrigin(origins = ""http://localhost:8080"")
@RequestMapping(path = ""/hello"")
public @ResponseBody String sayHello() {
    LOG.info(""GET called on /hello resource"");
    return HELLO_TEXT;
}
```

Now our Backend will respond CORS-enabled and will accept requests from 8080. But as this only enables CORS on one method, we have to repeatedly add this annotation to all of our REST endpoints, which isn’t a nice style. We should use a global solution to allow access with CORS enabled to all of our REST resources. This could be done in the `SpringBootVuejsApplication.class`:

```java
// Enable CORS globally
@Bean
public WebMvcConfigurer corsConfigurer() {
  return new WebMvcConfigurerAdapter() {
    @Override
    public void addCorsMappings(CorsRegistry registry) {
      registry.addMapping(""/api/*"").allowedOrigins(""http://localhost:8080"");
    }
  };
}
```

Now all calls to resources behind `api/` will return the correct CORS headers. 


#### But STOP! Webpack & Vue have something much smarter for us to help us with SOP!

Thanks to my colleague [Daniel](https://www.codecentric.de/team/dre/) who pointed me to the nice proxying feature of Webpack dev-server, we don't need to configure all the complex CORS stuff anymore!

According to the [Vue CLI 3 docs](https://cli.vuejs.org/config) the only thing we need to [configure is a devserver-proxy](https://cli.vuejs.org/config/#devserver-proxy) for our webpack devserver requests. This could be done easily in the optional [vue.config.js](https://cli.vuejs.org/config/#vue-config-js) inside `devServer.proxy`: 

```js
module.exports = {
  // proxy all webpack dev-server requests starting with /api
  // to our Spring Boot backend (localhost:8098) using http-proxy-middleware
  // see https://cli.vuejs.org/config/#devserver-proxy
  devServer: {
    proxy: {
      '/api': {
        target: 'http://localhost:8098',
        ws: true,
        changeOrigin: true
      }
    }
  },
  ...
}
```

With this configuration in place, the webpack dev-server uses the [http-proxy-middleware](https://github.com/chimurai/http-proxy-middleware), which is a really handy component, to proxy all frontend-requests from http://localhost:8080 --> http://localhost:8098 - incl. Changing the Origin accordingly.

This is used in the webpack build process to configure the proxyMiddleware (you don't need to change something here!):

```js
// proxy api requests
Object.keys(proxyTable).forEach(function (context) {
  var options = proxyTable[context];
  if (typeof options === 'string') {
    options = { target: options }
  }
  app.use(proxyMiddleware(options.filter || context, options))
})
```

## Using history mode for nicer URLs

If we use the default configuration of the generated Vue.js template, we see URLs with a `#` inside them - like this:

```
http://localhost:8098/#/bootstrap

or

http://localhost:8098/#/user
```

With the usage of __[HTML5 history mode](https://router.vuejs.org/guide/essentials/history-mode.html#html5-history-mode)__, we can achieve much nicer URLs without the `#` in them. Only thing to do in the Vue.js frontend is to configure our router accordingly inside the [router.js](frontend/src/router.js):

```
...

Vue.use(Router);

const router = new Router({
    mode: 'history', // uris without hashes #, see https://router.vuejs.org/guide/essentials/history-mode.html#html5-history-mode
    routes: [
        { path: '/', component: Hello },
        { path: '/callservice', component: Service },
        ...
```

That's nearly everything. BUT only nearly! If one clicks on a link inside our frontend, the user is correctly send to the wished component. 

But if the user enters the URL directly into the Browser, we get a `Whitelabel Error Page` because our Spring Boot backend gives us a __HTTP 404__ - since this URL isn't present in the backend:

![html5-history-mode-whitelabel-error-page-404](screenshots/html5-history-mode-whitelabel-error-page-404.gif)

The solution is to redirect or better forward the user to the frontend (router) again. The [Vue.js docs don't provide an example configuration for Spring Boot](https://router.vuejs.org/guide/essentials/history-mode.html#example-server-configurations), but luckily [there are other resources](https://www.baeldung.com/spring-redirect-and-forward). In essence we have to implement a forwarding controller in our [BackendController](backend/src/main/java/de/jonashackt/springbootvuejs/controller/BackendController.java):

```
    // Forwards all routes to FrontEnd except: '/', '/index.html', '/api', '/api/**'
    // Required because of 'mode: history' usage in frontend routing, see README for further details
    @RequestMapping(value = ""{_:^(?!index\\.html|api).$}"")
    public String redirectApi() {
        LOG.info(""URL entered directly into the Browser, so we need to redirect..."");
        return ""forward:/"";
    }
```

This controller will forward every request other then `'/', '/index.html', '/api', '/api/**'` to our Vue.js frontend.


## Bootstrap & Vue.js

There’s a nice integration of Bootstrap in Vue.js: https://bootstrap-vue.js.org/

```
npm install bootstrap-vue
```

Now you can use all the pretty Bootstrap stuff with ease like:

```
<b-btn @click=""callRestService()"">CALL Spring Boot REST backend service</b-btn>
```

instead of

```
<button type=""button"" class=”btn” @click=""callRestService()"">CALL Spring Boot REST backend service</button>
```

The docs contain all the possible components: https://bootstrap-vue.js.org/docs/components/alert/

See some elements, when you go to http://localhost:8080/#/bootstrap/ - this should look like this:

![bootstrap-styled-vuejs](screenshots/bootstrap-styled-vuejs.png)

A good discussion about various UI component frameworks: http://vuetips.com/bootstrap


## Heroku Deployment

As you may already read, the app is automatically deployed to Heroku on https://spring-boot-vuejs.herokuapp.com/.

The project makes use of the nice Heroku Pipelines feature, where we do get a full Continuous Delivery pipeline with nearly no effort:

![heroku-pipeline](screenshots/heroku-pipeline.png)

And with the help of super cool `Automatic deploys`, we have our GitHub Actions build our app after every push to master - and with the checkbox set to `Wait for CI to pass before deploy` - the app gets also automatically deployed to Heroku - but only, if the GitHub Actions (and Codegov...) build succeeded:

![heroku-automatic-deploys](screenshots/heroku-automatic-deploys.png)

You only have to connect your Heroku app to GitHub, activate Automatic deploys and set the named checkbox. That's everything!


#### Accessing Spring Boot REST backend on Heroku from Vue.js frontend

Frontend needs to know the Port of our Spring Boot backend API, which is [automatically set by Heroku every time, we (re-)start our App](https://stackoverflow.com/a/12023039/4964553).

> You can [try out your Heroku app locally](https://devcenter.heroku.com/articles/heroku-local)! Just create a .env-File with all your Environment variables and run `heroku local`! 

To access the Heroku set port, we need to use relative paths inside our Vue.js application instead of hard-coded hosts and ports! 

All we need to do is to configure Axios in such a way inside our [frontend/src/components/http-common.js](https://github.com/jonashackt/spring-boot-vuejs/blob/master/frontend/src/components/http-common.js):

```
export const AXIOS = axios.create({
  baseURL: `/api`
})
```

#### Using Heroku's Postgres as Database for Spring Boot backend and Vue.js frontend

First, add [Heroku Postgres database](https://elements.heroku.com/addons/heroku-postgresql) for your Heroku app. 

Then follow these instructions on Stackoverflow to configure all needed Environment variables in Heroku: https://stackoverflow.com/a/49978310/4964553

Mind the addition to the backend's [pom.xml](backend/pom.xml) described here: https://stackoverflow.com/a/49970142/4964553

Now you're able to use Spring Data's magic - all you need is an Interface like [UserRepository.java](backend/src/main/java/de/jonashackt/springbootvuejs/repository/UserRepository.java):

```java
package de.jonashackt.springbootvuejs.repository;

import de.jonashackt.springbootvuejs.domain.User;
import org.springframework.data.repository.CrudRepository;
import org.springframework.data.repository.query.Param;

import java.util.List;

public interface UserRepository extends CrudRepository<User, Long> {

    List<User> findByLastName(@Param(""lastname"") String lastname);

    List<User> findByFirstName(@Param(""firstname"") String firstname);

}

```

Now write your Testcases accordingly like [UserRepositoryTest.java](backend/src/test/java/de/jonashackt/springbootvuejs/repository/UserRepositoryTest.java):

```java
package de.jonashackt.springbootvuejs.repository;

import de.jonashackt.springbootvuejs.domain.User;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.orm.jpa.DataJpaTest;
import org.springframework.boot.test.autoconfigure.orm.jpa.TestEntityManager;
import org.springframework.test.context.junit4.SpringRunner;

import java.util.List;

import static org.hamcrest.Matchers.contains;
import static org.junit.Assert.*;

@RunWith(SpringRunner.class)
@DataJpaTest
public class UserRepositoryTest {

  @Autowired
  private TestEntityManager entityManager;

  @Autowired
  private UserRepository users;

  private final User norbertSiegmund = new User(""Norbert"", ""Siegmund"");
  private final User jonasHecht = new User(""Jonas"", ""Hecht"");

  @Before
  public void fillSomeDataIntoOurDb() {
    // Add new Users to Database
    entityManager.persist(norbertSiegmund);
    entityManager.persist(jonasHecht);
  }

  @Test
  public void testFindByLastName() throws Exception {
    // Search for specific User in Database according to lastname
    List<User> usersWithLastNameSiegmund = users.findByLastName(""Siegmund"");

    assertThat(usersWithLastNameSiegmund, contains(norbertSiegmund));
  }


  @Test
  public void testFindByFirstName() throws Exception {
    // Search for specific User in Database according to firstname
    List<User> usersWithFirstNameJonas = users.findByFirstName(""Jonas"");

    assertThat(usersWithFirstNameJonas, contains(jonasHecht));
  }

}
```

Then include this functionality in your REST-API - see [BackendController.java](backend/src/main/java/de/jonashackt/springbootvuejs/controller/BackendController.java):

```java
    @RequestMapping(path = ""/user"", method = RequestMethod.POST)
    @ResponseStatus(HttpStatus.CREATED)
    public @ResponseBody long addNewUser (@RequestParam String firstName, @RequestParam String lastName) {
        User user = new User(firstName, lastName);
        userRepository.save(user);

        LOG.info(user.toString() + "" successfully saved into DB"");

        return user.getId();
    }
```
 
and use it from the Vue.js frontend, see [User.vue](frontend/src/components/User.vue):

```html
<template>
<div class=""user"">
 <h1>Create User</h1>

 <h3>Just some database interaction...</h3>

 <input type=""text"" v-model=""user.firstName"" placeholder=""first name"">
 <input type=""text"" v-model=""user.lastName"" placeholder=""last name"">

 <button @click=""createUser()"">Create User</button>

 <div v-if=""showResponse""><h6>User created with Id: {{ response }}</h6></div>

 <button v-if=""showResponse"" @click=""retrieveUser()"">Retrieve user {{user.id}} data from database</button>

 <h4 v-if=""showRetrievedUser"">Retrieved User {{retrievedUser.firstName}} {{retrievedUser.lastName}}</h4>

</div>
</template>

<script>
// import axios from 'axios'
import {AXIOS} from './http-common'

export default {
 name: 'user',

 data () {
   return {
     response: [],
     errors: [],
     user: {
       lastName: '',
       firstName: '',
       id: 0
     },
     showResponse: false,
     retrievedUser: {},
     showRetrievedUser: false
   }
 },
 methods: {
   // Fetches posts when the component is created.
   createUser () {
     var params = new URLSearchParams();
     params.append('firstName', this.user.firstName);
     params.append('lastName', this.user.lastName);

     AXIOS.post(`/user`, params)
       .then(response => {
         // JSON responses are automatically parsed.
         this.response = response.data;
         this.user.id = response.data;
         console.log(response.data);
         this.showResponse = true
       })
       .catch(e => {
         this.errors.push(e)
       })
   },
   retrieveUser () {
     AXIOS.get(`/user/` + this.user.id)
       .then(response => {
         // JSON responses are automatically parsed.
         this.retrievedUser = response.data;
         console.log(response.data);
         this.showRetrievedUser = true
       })
       .catch(e => {
         this.errors.push(e)
       })
   }
 }
}

</script>
```


## Testing 

### Install vue-test-utils

https://github.com/vuejs/vue-test-utils

`npm install --save-dev @vue/test-utils`

### Jest

Jest is a new shooting star in the sky of JavaScript testing frameworks: https://facebook.github.io/jest/

Intro-Blogpost: https://blog.codecentric.de/2017/06/javascript-unit-tests-sind-schwer-aufzusetzen-keep-calm-use-jest/

Examples: https://github.com/vuejs/vue-test-utils-jest-example

Vue.js Jest Docs: https://vue-test-utils.vuejs.org/guides/#testing-single-file-components-with-jest

A Jest Unittest looks like [Hello.spec.js](frontend/test/components/Hello.spec.js):

```js
import { shallowMount } from '@vue/test-utils';
import Hello from '@/components/Hello'

describe('Hello.vue', () => {
  it('should render correct hello message', () => {
    // Given
    const hellowrapped = shallowMount(Hello, {
      propsData: { hellomsg: 'Welcome to your Jest powered Vue.js App' },
      stubs: ['router-link', 'router-view']
    });

    // When
    const contentH1 = hellowrapped.find('h1');

    // Then
    expect(contentH1.text()).toEqual('Welcome to your Jest powered Vue.js App');
  })
})
```

To pass Component props while using Vue.js Router, see https://stackoverflow.com/a/37940045/4964553.

How to test components with `router-view` or `router-link` https://vue-test-utils.vuejs.org/guides/using-with-vue-router.html#testing-components-that-use-router-link-or-router-view.

The test files itself could be named `xyz.spec.js` or `xyz.test.js` - and could reside nearly everywhere in the project.

##### Jest Configuration  

The Jest run-configuration is done inside the [package.json](frontend/package.json):

```js
""scripts"";: {
    ...
    ""test:unit"";: ""vue-cli-service test:unit --coverage"",;
    ....
  },
```

Jest can be configured via `jest.config.js` in your project root, or the `jest` field in [package.json](frontend/package.json). In our case we especially need to configure `coverageDirectory`:

```json
  ],
  ""jest"": {
    ...
    ""coverageDirectory"": ""<rootDir>/tests/unit/coverage"",
    ""collectCoverageFrom"": [
      ""src/**/*.{js,vue}"",
      ""!src/main.js"",
      ""!src/router/index.js"",
      ""!**/node_modules/**""
    ]
  }
}
```

Jest needs to know the right output directory `/tests/unit/coverage` to show a correct output when `npm run test:unit` is run (or the corresponding Maven build). If you run the Jest Unit tests now with:

`npm run test:unit`

- you´ll recognize the table of test covered files:

![unittestrun-jest](screenshots/unittestrun-jest.png)


##### Integration in Maven build (via frontend-maven-plugin)

Inside the [pom.xml](pom.xml) we always automatically run the Jest Unittests with the following configuration:

```xml
<!-- Run Unit tests -->
  <execution>
    <id>npm run test:unit</id>
    <goals>
      <goal>npm</goal>
    </goals>
    <!-- optional: default phase is ""generate-resources"" -->
    <phase>test</phase>
    <!-- Optional configuration which provides for running any npm command -->
    <configuration>
      <arguments>run test:unit</arguments>
    </configuration>
  </execution>
```

This will integrate the Jest Unittests right after the npm run build command, just you are used to in Java-style projects:

![maven-integration-jest-unittests](screenshots/maven-integration-jest-unittests.png)

And don't mind the depiction with `ERROR` - this is just a known bug: https://github.com/eirslett/frontend-maven-plugin/issues/584


##### Run Jest tests inside IntelliJ

First, we need to install the NodeJS IntelliJ plugin (https://www.jetbrains.com/help/idea/developing-node-js-applications.html), which isn't bundled with IntelliJ by default:

![nodejs-intellij-plugin](screenshots/nodejs-intellij-plugin.png)

IntelliJ Jest integration docs: https://www.jetbrains.com/help/idea/running-unit-tests-on-jest.html

The automatic search inside the [package.json](frontend/package.json) for the Jest configuration file [jest.conf.js](frontend/test/unit/jest.conf.js) doesn't seem to work right now, so we have to manually configure the `scripts` part of:

```
""unit"": ""jest --config test/unit/jest.conf.js --coverage"",
```

inside the Run Configuration under `Jest` and `All Tests`:

![configure-jest-inside-intellij](screenshots/configure-jest-inside-intellij.png)

Now, when running `All Tests`, this should look like you're already used to Unittest IntelliJ-Integration:

![run-jest-inside-intellij](screenshots/run-jest-inside-intellij.png)

 

## End-2-End (E2E) tests with Nightwatch

Great tooling: http://nightwatchjs.org/ - Nightwatch controls WebDriver / Selenium standalone Server in own child process and abstracts from those, providing a handy DSL for Acceptance tests:

Docs: http://nightwatchjs.org/gettingstarted/#browser-drivers-setup

![http://nightwatchjs.org/img/operation.png](http://nightwatchjs.org/img/operation.png)

Nightwatch is configured through the [nightwatch.conf.js](/frontend/test/e2e/nightwatch.conf.js). Watch out for breaking changes in 1.x: https://github.com/nightwatchjs/nightwatch/wiki/Migrating-to-Nightwatch-1.0

More options could be found in the docs: http://nightwatchjs.org/gettingstarted/#settings-file


#### Write Nightwatch tests

An example Nightwatch test is provided in [HelloAcceptance.test.js](/frontend/test/e2e/specs/HelloAcceptance.test.js):

```js
module.exports = {
    'default e2e tests': browser => {
        browser
            .url(process.env.VUE_DEV_SERVER_URL)
            .waitForElementVisible('#app', 5000)
            .assert.elementPresent('.hello')
            .assert.containsText('h1', 'Welcome to your Vue.js powered Spring Boot App')
            .assert.elementCount('img', 1)
            .end()
    }
}
```

##### Run E2E Tests

`npm run test:e2e`


## Run all tests

 `npm test`



## NPM Security

npm Security - npm@6

https://medium.com/npm-inc/announcing-npm-6-5d0b1799a905

`npm audit`

https://blog.npmjs.org/post/173719309445/npm-audit-identify-and-fix-insecure

Run `npm audit fix` to update the vulnerable packages. Only in situations, where nothing else helps, try `npm audit fix --force` (this will also install braking changes)

https://nodejs.org/en/blog/vulnerability/june-2018-security-releases/

---> __Update NPM regularly__

https://docs.npmjs.com/troubleshooting/try-the-latest-stable-version-of-npm

`npm install -g npm@latest`

---> __Update Packages regularly__

https://docs.npmjs.com/getting-started/updating-local-packages

`npm outdated`

`npm update`




## Shift from templates to plugin-based architecture in Vue Cli 3

In the long run, templates like the main [webpack](https://github.com/vuejs-templates/webpack) are deprecated in the Vue.js universe:

https://vuejsdevelopers.com/2018/03/26/vue-cli-3/

Plugins bring the following benefits compared to templates:

* No lock in, as plugins can be added at any point in the development lifecycle
* Zero config plugins allow you to spend time developing rather than configuring
* Easy to upgrade, as configuration can be customized without “ejecting”
* Allows developers to make their own plugins and presets

Starting point: https://cli.vuejs.org/


#### OMG! My package.json is so small - Vue CLI 3 Plugins

From https://cli.vuejs.org/guide/plugins-and-presets.html:

> Vue CLI uses a plugin-based architecture. If you inspect a newly created project's package.json, you will find dependencies that start with `@vue/cli-plugin-`. Plugins can modify the internal webpack configuration and inject commands to `vue-cli-service`. Most of the features listed during the project creation process are implemented as plugins.

With plugings, extensions to an existing project could also be made via: `vue add pluginName`. E.g. if you want to add Nightwatch E2E tests to your project, just run `vue add @vue/e2e-nightwatch`. All scoped packages are available here: https://github.com/vuejs/vue-cli/tree/dev/packages/%40vue

These new Vue CLI 3 plugin architecture cleans our big `package.json` to a really neat compact thing. This was the old big dependency block:

````json
  ""devDependencies"": {
    ""@vue/test-utils"": ""^1.0.0-beta.25"",
    ""autoprefixer"": ""^7.1.2"",
    ""babel-core"": ""^6.26.3"",
    ""babel-helper-vue-jsx-merge-props"": ""^2.0.3"",
    ""babel-jest"": ""^21.0.2"",
    ""babel-loader"": ""^7.1.5"",
    ""babel-plugin-dynamic-import-node"": ""^1.2.0"",
    ""babel-plugin-syntax-jsx"": ""^6.18.0"",
    ""babel-plugin-transform-es2015-modules-commonjs"": ""^6.26.0"",
    ""babel-plugin-transform-runtime"": ""^6.22.0"",
    ""babel-plugin-transform-vue-jsx"": ""^3.5.0"",
    ""babel-preset-env"": ""^1.7.0"",
    ""babel-preset-stage-2"": ""^6.22.0"",
    ""babel-register"": ""^6.22.0"",
    ""chalk"": ""^2.4.1"",
    ""chromedriver"": ""^2.41.0"",
    ""copy-webpack-plugin"": ""^4.5.2"",
    ""cross-spawn"": ""^5.0.1"",
    ""css-loader"": ""^0.28.0"",
    ""extract-text-webpack-plugin"": ""^3.0.0"",
    ""file-loader"": ""^1.1.4"",
    ""friendly-errors-webpack-plugin"": ""^1.6.1"",
    ""html-webpack-plugin"": ""^2.30.1"",
    ""jest"": ""^22.0.4"",
    ""jest-serializer-vue"": ""^0.3.0"",
    ""nightwatch"": ""^1.0.11"",
    ""node-notifier"": ""^5.1.2"",
    ""optimize-css-assets-webpack-plugin"": ""^3.2.0"",
    ""ora"": ""^1.2.0"",
    ""portfinder"": ""^1.0.17"",
    ""postcss-import"": ""^11.0.0"",
    ""postcss-loader"": ""^2.1.6"",
    ""postcss-url"": ""^7.2.1"",
    ""rimraf"": ""^2.6.0"",
    ""selenium-server"": ""^3.14.0"",
    ""semver"": ""^5.5.1"",
    ""shelljs"": ""^0.7.6"",
    ""uglifyjs-webpack-plugin"": ""^1.3.0"",
    ""url-loader"": ""^1.1.1"",
    ""vue-jest"": ""^1.0.2"",
    ""vue-loader"": ""^13.7.3"",
    ""vue-style-loader"": ""^3.0.1"",
    ""vue-template-compiler"": ""^2.5.17"",
    ""webpack"": ""^3.6.0"",
    ""webpack-bundle-analyzer"": ""^2.13.1"",
    ""webpack-dev-server"": ""^2.11.3"",
    ""webpack-merge"": ""^4.1.4""
  },
````

As you can see, we´re not only maintaining our high-level libraries of choice like nightwatch, jest and so on. We´re also maintaining libraries that they use itself. Now this is over with Vue CLI 3. Let´s have a look at the super clean dependency block now:

```json
""devDependencies"": {
    ""@vue/cli-plugin-babel"": ""^3.0.3"",
    ""@vue/cli-plugin-e2e-nightwatch"": ""^3.0.3"",
    ""@vue/cli-plugin-unit-jest"": ""^3.0.3"",
    ""@vue/cli-service"": ""^3.0.3"",
    ""@vue/test-utils"": ""^1.0.0-beta.20"",
    ""babel-core"": ""7.0.0-bridge.0"",
    ""babel-jest"": ""^23.0.1"",
    ""node-sass"": ""^4.9.0"",
    ""sass-loader"": ""^7.0.1"",
    ""vue-template-compiler"": ""^2.5.17""
  },
``` 

As you dig into the directories like `node_modules/@vue/cli-plugin-e2e-nightwatch`, you´ll find where the used libraries of nightwatch are configured - in the respective `package.json` there:

```json
  ""dependencies"": {
    ""@vue/cli-shared-utils"": ""^3.0.2"",
    ""chromedriver"": ""^2.40.0"",
    ""deepmerge"": ""^2.1.1"",
    ""execa"": ""^0.10.0"",
    ""nightwatch"": ""^0.9.21"",
    ""selenium-server"": ""^3.13.0""
  },
```

This is really cool, I have to admit!


#### The vue.config.js file

Vue CLI 3 removes the need for explicit configuration files - and thus you wont find any `build` or `config` directories in your projects root any more. This now implements a ""convention over configuration"" approach, which makes it much easier to kick-start a Vue.js project, as it provides widly used defaults to webpack etc. It also eases the upgradeability of Vue.js projects - or even makes it possible. 

__But__: How do we configure webpack etc. for CORS handling, the build directories and so on? This could be done with the optional [vue.config.js](https://cli.vuejs.org/config/#vue-config-js):

```javascript
module.exports = {
  // proxy all webpack dev-server requests starting with /api
  // to our Spring Boot backend (localhost:8098) using http-proxy-middleware
  // see https://cli.vuejs.org/config/#devserver-proxy
  devServer: {
    proxy: {
      '/api': {
        target: 'http://localhost:8098',
        ws: true,
        changeOrigin: true
      }
    }
  },
  // Change build paths to make them Maven compatible
  // see https://cli.vuejs.org/config/
  outputDir: 'target/dist'
}
```

#### Updating Vue in an existing project

Update your local `@vue/cli` to the latest version:

```
npm install -g @vue/cli
```

Then update Vue.js and all your other JS dependencies with:

```
cd frontend
npm update
```


## Upgrade to Vue.js 3.x/4.x next

Let's move from 2.6.x -> 3.x/4.x next here.

> Be aware that [the latest version of vue currently is `2.6.x` and `3.x` is considered `next`](https://www.npmjs.com/package/vue)!

There are some resources:

https://v3.vuejs.org/guide/migration/introduction.html#quickstart

https://johnpapa.net/vue2-to-vue3/

And if we are using 3.x, we can even migrate to 4.x: https://cli.vuejs.org/migrating-from-v3/


#### Upgrade from 2.x to 3.x

There's a migration tooling, simply use:

```shell
vue add vue-next
```

This took around 3 minutes or more on my MacBook and changed some files:

![vue-js-2.x-to-3.x-next-upgrade](screenshots/vue-js-2.x-to-3.x-next-upgrade.png)

The [package.json](frontend/package.json) got some new or upgraded deps:

![vue-js-2.x-to-3.x-next-upgrade-dependencies](screenshots/vue-js-2.x-to-3.x-next-upgrade-dependencies.png)

[As John stated in his post](https://johnpapa.net/vue2-to-vue3/) it's strange to find `beta` versions with `vue`, `vue-router` and `vuex`. 

So in order to see what a fresh skeleton would produce, let's also create one in another dir ([I assume you have `npm install -g @vue/cli` installed](https://v3.vuejs.org/guide/migration/introduction.html#quickstart):

```shell
mkdir vue3test && cd vue3test
vue create hello-vue3
```

I aligned my project to match the latest skeleton generation much better: So router, store and api got their own directories. The views are now in the correct folder `views` - and I extracted one component to use from the newly introduced `Home.vue` view: the `HelloSpringWorld.vue` component.

I also went over the [package.json](frontend/package.json) and upgraded to the latest release versions instead of alphas (except `@vue/test-utils` which only has a `rc` atm).

All imports were refactored too. Coming from this style:

```javascript
import Vue from 'vue'
import Router from 'vue-router'
```

everything now reads:

```javascript
import { createApp } from 'vue';
import { createRouter, createWebHistory } from 'vue-router'
```

Also check your `router.js` or [router/index.js](frontend/src/router/index.js)! Using a path redirect like this leads to a non working routing configuration:

```javascript
    // otherwise redirect to home
    { path: '*', redirect: '/' }
```

The error in the Browser console states:

```shell
Uncaught Error: Catch all routes (""*"") must now be defined using a param with a custom regexp.
See more at https://next.router.vuejs.org/guide/migration/#removed-star-or-catch-all-routes.
```

I changed it to the new param with regex syntax like this:

```javascript
    // otherwise redirect to home
    { path: '/:pathMatch(.*)*', redirect: '/' }
```

A crucial point to get jest to work again, was to add the following to the [jest.config.js](frontend/jest.config.js):

```javascript
  transform: {
    '^.+\\.vue$': 'vue-jest'
  }
```

Otherwise my tests ran into the following error:

```shell
npm run test:unit

> frontend@4.0.0 test:unit
> vue-cli-service test:unit --coverage

 FAIL  tests/unit/views/User.spec.js
  ● Test suite failed to run

    Vue packages version mismatch:

    - vue@3.0.11 (/Users/jonashecht/dev/spring-boot/spring-boot-vuejs/frontend/node_modules/vue/index.js)
    - vue-template-compiler@2.6.12 (/Users/jonashecht/dev/spring-boot/spring-boot-vuejs/frontend/node_modules/vue-template-compiler/package.json)

    This may cause things to work incorrectly. Make sure to use the same version for both.
    If you are using vue-loader@>=10.0, simply update vue-template-compiler.
    If you are using vue-loader@<10.0 or vueify, re-installing vue-loader/vueify should bump vue-template-compiler to the latest.

      at Object.<anonymous> (node_modules/vue-template-compiler/index.js:10:9)
```

Luckily this so answer helped me out: https://stackoverflow.com/a/65111966/4964553

And finally Bootstrap Vue doesn't support Vue 3.x right now: https://github.com/bootstrap-vue/bootstrap-vue/issues/5196 - So I temporarily commented out the imports.


#### Add TypeScript

Vue 3.x is now build with TypeScript: https://v3.vuejs.org/guide/typescript-support.html

> A static type system can help prevent many potential runtime errors as applications grow, which is why Vue 3 is written in TypeScript. This means you don't need any additional tooling to use TypeScript with Vue - it has first-class citizen support.

There's also a huge documentation of TypeScript itself at https://www.typescriptlang.org/docs/ I can also recommend https://medium.com/js-dojo/adding-typescript-to-your-existing-vuejs-2-6-app-aaa896c2d40a

To migrate your project there's the command:

```shell
vue add typescript
```

The first question arises: `Use class-style component syntax? (Y/n)` whether to use class-style component syntax or not. I didn't use it. I think the interface definitions of components are concise enough without the class-style. But let's see how this will work out.

So this was the output:

```shell
vue add typescript
 WARN  There are uncommitted changes in the current repository, it's recommended to commit or stash them first.
? Still proceed? Yes

📦  Installing @vue/cli-plugin-typescript...


added 59 packages, removed 58 packages, and audited 2219 packages in 6s

85 packages are looking for funding
  run `npm fund` for details

3 low severity vulnerabilities

To address all issues (including breaking changes), run:
  npm audit fix --force

Run `npm audit` for details.
✔  Successfully installed plugin: @vue/cli-plugin-typescript

? Use class-style component syntax? No
? Use Babel alongside TypeScript (required for modern mode, auto-detected polyfills, transpiling JSX)? Yes
? Use TSLint? Yes
? Pick lint features: Lint on save
? Convert all .js files to .ts? Yes
? Allow .js files to be compiled? Yes
? Skip type checking of all declaration files (recommended for apps)? Yes

🚀  Invoking generator for @vue/cli-plugin-typescript...
📦  Installing additional dependencies...


added 2 packages, and audited 2221 packages in 3s
...
✔  Successfully invoked generator for plugin: @vue/cli-plugin-typescript
```

Now I went through all the componentes and views and extended `<script>` to `<script lang=""ts"">`.

Also I changed

```javascript
  export default {
```

to

```javascript
import { defineComponent } from 'vue';

export default defineComponent({
```

Now we need to transform our JavaScript code into TypeScript.

A really good introduction could be found here: https://www.vuemastery.com/blog/getting-started-with-typescript-and-vuejs/

> This process will take a while, depending on your code - and mainly on your knowledge about TypeScript. But I think it's a great path to go!

Don't forget to deactivate source control for `.js` and `.map` files in `src`, because these will now be generated (aka transpiled) from TypeScript and [shouldn't be checked in (anymore)](https://stackoverflow.com/a/26464907/4964553).

I enhanced my [frontend/.gitignore](frontend/.gitignore) like this:

```shell
# TypeScript
*.map
src/*.js
test/*.js
```

##### Vuex Store with TypeScript

According to https://next.vuex.vuejs.org/guide/typescript-support.html#typing-store-property-in-vue-component in order to use vuex store with TypeScript, we:

> must declare your own module augmentation.

TLDR; we need to create a file [src/vuex.d.ts](frontend/src/vuex.d.ts):

```javascript
import { ComponentCustomProperties } from 'vue'
import { Store } from 'vuex'

declare module '@vue/runtime-core' {
  // declare your own store states
  interface State {
    count: number
  }

  // provide typings for `this.$store`
  interface ComponentCustomProperties {
    $store: Store<State>
  }
}
```


#### Bootstrap support for Vue.js 3/Next

Our View [Bootstrap.vue](frontend/src/views/Bootstrap.vue) is based on the library `bootstrap-vue`, which brings in some nice Bootstrap CSS stylings & components.

But bootstrap-vue isn't compatible with Vue.js 3/Next: https://github.com/bootstrap-vue/bootstrap-vue/issues/5196 and it's unclear, when it's going to support it - or even if at all.

With the upgrade to Vue.js 3.x our `bootstrap-vue` based component view stopped working.

There's also another change: [Bootstrap 5.x is here to be the next evolutionary step - and it even dropped the need for JQuery](https://blog.getbootstrap.com/2020/06/16/bootstrap-5-alpha/).

But also Bootstrap 5.x isn't supported by `bootstrap-vue` right now. So let's try to use Bootstrap without it?!

Therefore install bootstrap next (which - as like Vue.js - stands for the new version 5):

```shell
npm i bootstrap@next
npm i @popperjs/core
```

Since Bootstrap 5 depends on `popperjs` for tooltips (see https://getbootstrap.com/docs/5.0/getting-started/introduction/#js), we also need to include it.

We can remove `""bootstrap-vue"": ""2.21.2""` and `""jquery"": ""3.6.0"",` from our `package.json`.

We also need to import Bootstrap inside our [main.ts](frontend/src/main.ts):

```javascript
import ""bootstrap/dist/css/bootstrap.min.css"";
import ""bootstrap"";
```

Let's try to use Bootstrap 5 inside our [Bootstrap.vue](frontend/src/views/Bootstrap.vue).

And also inside the `Login.vue` and the `Protected.vue`. Using Bootstrap 5.x components without `bootstrap-vue` seems to be no problem (see docs how to use here: https://getbootstrap.com/docs/5.0/components/badge/).


## Build and run with Docker

In the issue [jonashackt/spring-boot-vuejs/issues/25](https://github.com/jonashackt/spring-boot-vuejs/issues/25) the question on how to build and run our spring-boot-vuejs app with Docker. 

As already stated in the issue there are multiple ways of doing this. One I want to outline here is a more in-depth variant, where you'll know exacltly what's going on behind the scenes.

First we'll make use of [Docker's multi-stage build feature](https://docs.docker.com/develop/develop-images/multistage-build/) - in __the first stage__ we'll build our Spring Boot Vue.js app using our established Maven build process. Let's have a look into our [Dockerfile](Dockerfile):

```dockerfile
# Docker multi-stage build

# 1. Building the App with Maven
FROM maven:3-jdk-11

ADD . /springbootvuejs
WORKDIR /springbootvuejs

# Just echo so we can see, if everything is there :)
RUN ls -l

# Run Maven build
RUN mvn clean install
```

A crucial part here is to add all necessary files into our Docker build context - but leaving out the underlying OS specific node libraries! As not leaving them out would lead [to errors like](https://stackoverflow.com/questions/37986800/node-sass-could-not-find-a-binding-for-your-current-environment?page=1&tab=active#tab-top):

```
Node Sass could not find a binding for your current environment: Linux 64-bit with Node.js 11.x
```

Therefore we create a [.dockerignore](.dockerignore) file and leave out the directories `frontend/node_modules` & `frontend/node` completely using the `frontend/node*` configuration:

```
# exclude underlying OS specific node modules
frontend/node*

# also leave out pre-build output folders
frontend/target
backend/target
```

We also ignore the pre-build output directories.

In __the second stage__ of our [Dockerfile](Dockerfile) we use the build output of the first stage and prepare everything to run our Spring Boot powered Vue.js app later:

```dockerfile
# Just using the build artifact and then removing the build-container
FROM openjdk:11-jdk

MAINTAINER Jonas Hecht

VOLUME /tmp

# Add Spring Boot app.jar to Container
COPY --from=0 ""/springbootvuejs/backend/target/backend-0.0.1-SNAPSHOT.jar"" app.jar

ENV JAVA_OPTS=""""

# Fire up our Spring Boot app by default
ENTRYPOINT [ ""sh"", ""-c"", ""java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar"" ]
```

Now we should everything prepared to run our Docker build:

```
docker build . --tag spring-boot-vuejs:latest
```

This build can take a while, since all Maven and NPM dependencies need to be downloaded for the build.

When the build is finished, simply start a Docker container based on the newly build image and prepare the correct port to be bound to the Docker host for easier access later:

```
docker run -d -p 8098:8098 --name myspringvuejs spring-boot-vuejs
```

Have a look into your running Docker containers with `docker ps` and you should see the new container:

```
$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
745e854d7781        spring-boot-vuejs   ""sh -c 'java $JAVA_O…""   12 seconds ago      Up 11 seconds       0.0.0.0:8098->8098/tcp   myspringvuejs
```

If you want to see the typical Spring Boot startup logs, just use `docker logs 745e854d7781 --follow`:

```
$ docker logs 745e854d7781 --follow

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.1.2.RELEASE)

2019-01-29 09:42:07.621  INFO 8 --- [           main] d.j.s.SpringBootVuejsApplication         : Starting SpringBootVuejsApplication v0.0.1-SNAPSHOT on 745e854d7781 with PID 8 (/app.jar started by root in /)
2019-01-29 09:42:07.627  INFO 8 --- [           main] d.j.s.SpringBootVuejsApplication         : No active profile set, falling back to default profiles: default
2019-01-29 09:42:09.001  INFO 8 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-01-29 09:42:09.103  INFO 8 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 90ms. Found 1 repository interfaces.
2019-01-29 09:42:09.899  INFO 8 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$bb072d94] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-01-29 09:42:10.715  INFO 8 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8098 (http)
2019-01-29 09:42:10.765  INFO 8 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-01-29 09:42:10.765  INFO 8 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.14]
2019-01-29 09:42:10.783  INFO 8 --- [           main] o.a.catalina.core.AprLifecycleListener   : The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib]
2019-01-29 09:42:10.920  INFO 8 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-01-29 09:42:10.921  INFO 8 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3209 ms
2019-01-29 09:42:11.822  INFO 8 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-01-29 09:42:12.177  INFO 8 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-01-29 09:42:12.350  INFO 8 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-01-29 09:42:12.520  INFO 8 --- [           main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.7.Final}
2019-01-29 09:42:12.522  INFO 8 --- [           main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-01-29 09:42:12.984  INFO 8 --- [           main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-01-29 09:42:13.894  INFO 8 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2019-01-29 09:42:15.644  INFO 8 --- [           main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@64524dd'
2019-01-29 09:42:15.649  INFO 8 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-01-29 09:42:16.810  INFO 8 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-01-29 09:42:16.903  WARN 8 --- [           main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-01-29 09:42:17.116  INFO 8 --- [           main] o.s.b.a.w.s.WelcomePageHandlerMapping    : Adding welcome page: class path resource [public/index.html]
2019-01-29 09:42:17.604  INFO 8 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
2019-01-29 09:42:17.740  INFO 8 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8098 (http) with context path ''
2019-01-29 09:42:17.745  INFO 8 --- [           main] d.j.s.SpringBootVuejsApplication         : Started SpringBootVuejsApplication in 10.823 seconds (JVM running for 11.485)
```

Now access your Dockerized Spring Boot powererd Vue.js app inside your Browser at [http://localhost:8098](http://localhost:8098). 

If you have played enough with your Dockerized app, don't forget to stop (`docker stop 745e854d7781`) and remove (`docker rm 745e854d7781`) it in the end.


#### Autorelease to Docker Hub on hub.docker.com

We also want to have the current version of our code build and released to https://hub.docker.com/. Therefore head to the repositories tab in Docker Hub and click `Create Repository`:

![docker-hub-create-repo](screenshots/docker-hub-create-repo.png)

As the docs state, there are some config options to [setup automated builds](https://docs.docker.com/docker-hub/builds/).

Finally, we should see our Docker images released on https://hub.docker.com/r/jonashackt/spring-boot-vuejs and could run this app simply by executing:

```
docker run -p 8098:8098 jonashackt/spring-boot-vuejs:latest
```

This pulls the latest `jonashackt/spring-boot-vuejs` image and runs our app locally:

```
docker run -p 8098:8098 jonashackt/spring-boot-vuejs:latest
Unable to find image 'jonashackt/spring-boot-vuejs:latest' locally
latest: Pulling from jonashackt/spring-boot-vuejs
9a0b0ce99936: Pull complete
db3b6004c61a: Pull complete
f8f075920295: Pull complete
6ef14aff1139: Pull complete
962785d3b7f9: Pull complete
e275e7110d81: Pull complete
0ce121b6a2ff: Pull complete
71607a6adeb3: Pull complete
Digest: sha256:4037576ba5f6c58ed067eeef3ab2870a9de8dd1966a5906cb3d36d0ad98fa541
Status: Downloaded newer image for jonashackt/spring-boot-vuejs:latest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.2.0.RELEASE)

2019-11-02 16:15:37.967  INFO 7 --- [           main] d.j.s.SpringBootVuejsApplication         : Starting SpringBootVuejsApplication v0.0.1-SNAPSHOT on aa490bc6ddf4 with PID 7 (/app.jar started by root in /)
2019-11-02 16:15:37.973  INFO 7 --- [           main] d.j.s.SpringBootVuejsApplication         : No active profile set, falling back to default profiles: default
2019-11-02 16:15:39.166  INFO 7 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-11-02 16:15:39.285  INFO 7 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 99ms. Found 1 repository interfaces.
2019-11-02 16:15:39.932  INFO 7 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-11-02 16:15:40.400  INFO 7 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8098 (http)
2019-11-02 16:15:40.418  INFO 7 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
...
2019-11-02 16:15:54.048  INFO 7 --- [nio-8098-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-11-02 16:15:54.081  INFO 7 --- [nio-8098-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 32 ms
```


Now head over to [http://localhost:8098/](http://localhost:8098/) and see the app live :)


# Run with JDK 8, 9 or 11 ff

As with Spring Boot, we can define the desired Java version simply by editing our backend's [pom.xml](backend/pom.xml): 

```
	<properties>
		<java.version>1.8</java.version>
	</properties>
```

If you want to have `JDK9`, place a `<java.version>9</java.version>` or other versions just as you like to (see [this stackoverflow answer](https://stackoverflow.com/questions/54467287/how-to-specify-java-11-version-in-spring-spring-boot-pom-xml)).

Spring Boot handles the needed `maven.compiler.release`, which tell's Java from version 9 on to build for a specific target.

We just set `1.8` as the baseline here, since if we set a newer version as the standard, builds on older versions then 8 will fail (see [this build log for example](https://travis-ci.org/jonashackt/spring-boot-vuejs/builds/547227298).

Additionally, we use GitHub Actions to run the Maven build on some mayor Java versions - have a look into the [build.yml](.github/workflows/build.yml) workflow:

```yaml
jobs:
  build:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        java-version: [ 8, 11, 15 ]
```


# Secure Spring Boot backend and protect Vue.js frontend

Securing parts of our application must consist of two parts: securing the Spring Boot backend - and reacting on that secured backend in the Vue.js frontend.

https://spring.io/guides/tutorials/spring-security-and-angular-js/

https://developer.okta.com/blog/2018/11/20/build-crud-spring-and-vue

https://auth0.com/blog/vuejs2-authentication-tutorial/

https://medium.com/@zitko/structuring-a-vue-project-authentication-87032e5bfe16





## Secure the backend API with Spring Security

https://spring.io/guides/tutorials/spring-boot-oauth2

https://spring.io/guides/gs/securing-web/

https://www.baeldung.com/rest-assured-authentication

Now let's focus on securing our Spring Boot backend first! Therefore we introduce a new RESTful resource, that we want to secure specifically:


                   +---+                  +---+                  +---+
                   |   | /api/hello       |   | /api/user        |   | /api/secured
                   +---+                  +---+                  +---+
                     |                      |                      |
        +-----------------------------------------------------------------------+
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |  Spring Boot backend                                                  |
        |                                                                       |
        +-----------------------------------------------------------------------+


#### Configure Spring Security

First we add a new REST resource `/secured` inside our `BackendController we want to secure - and use in a separate frontend later:

```
    @GetMapping(path=""/secured"")
    public @ResponseBody String getSecured() {
        LOG.info(""GET successfully called on /secured resource"");
        return SECURED_TEXT;
    }
```

With Spring it is relatively easy to secure our API. Let's add `spring-boot-starter-security` to our [pom.xml](backend/pom.xml):

```xml
		<!-- Secure backend API -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-security</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.security</groupId>
			<artifactId>spring-security-test</artifactId>
			<scope>test</scope>
		</dependency>
```

Also create a new @Configuration annotated class called [WebSecurityConfiguration.class](backend/src/main/java/de/jonashackt/springbootvuejs/configuration/WebSecurityConfiguration.java):

```java
package de.jonashackt.springbootvuejs.configuration;

import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.config.http.SessionCreationPolicy;

@Configuration
@EnableWebSecurity
public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {

        http
            .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) // No session will be created or used by spring security
        .and()
            .httpBasic()
        .and()
            .authorizeRequests()
                .antMatchers(""/api/hello"").permitAll()
                .antMatchers(""/api/user/**"").permitAll() // allow every URI, that begins with '/api/user/'
                .antMatchers(""/api/secured"").authenticated()
                .anyRequest().authenticated() // protect all other requests
        .and()
            .csrf().disable(); // disable cross site request forgery, as we don't use cookies - otherwise ALL PUT, POST, DELETE will get HTTP 403!
    }

    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.inMemoryAuthentication()
                .withUser(""foo"").password(""{noop}bar"").roles(""USER"");
    }
}

```

Using a simple `http.httpBasic()` we configure to provide a Basic Authentication for our secured resources.

To deep dive into the Matcher configurations, have a look into https://docs.spring.io/spring-security/site/docs/current/reference/htmlsingle/#jc-authorize-requests

#### Be aware of CSRF!

__BUT:__ Be aware of the CSRF (cross site request forgery) part! The defaults will render a [HTTP 403 FORBIDDEN for any HTTP verb that modifies state (PATCH, POST, PUT, DELETE)](https://docs.spring.io/spring-security/site/docs/current/reference/htmlsingle/#csrf-configure):

> by default Spring Security’s CSRF protection will produce an HTTP 403 access denied.

For now we can disable the default behavior with `http.csrf().disable()`


#### Testing the secured Backend

See https://www.baeldung.com/rest-assured-authentication

Inside our [BackendControllerTest](backend/src/test/java/de/jonashackt/springbootvuejs/controller/BackendControllerTest.java) we should check, whether our API reacts with correct HTTP 401 UNAUTHORIZED, when called without our User credentials:

```
	@Test
	public void secured_api_should_react_with_unauthorized_per_default() {

		given()
		.when()
			.get(""/api/secured"")
		.then()
			.statusCode(HttpStatus.SC_UNAUTHORIZED);
	}
```

Using `rest-assured` we can also test, if one could access the API correctly with the credentials included:

```
	@Test
	public void secured_api_should_give_http_200_when_authorized() {

		given()
			.auth().basic(""foo"", ""bar"")
		.when()
			.get(""/api/secured"")
		.then()
			.statusCode(HttpStatus.SC_OK)
			.assertThat()
				.body(is(equalTo(BackendController.SECURED_TEXT)));
	}
```

The crucial point here is to use the `given().auth().basic(""foo"", ""bar"")` configuration to inject the correct credentials properly.



#### Configure credentials inside application.properties and environment variables

Defining the users (and passwords) inside code (like our [WebSecurityConfiguration.class](backend/src/main/java/de/jonashackt/springbootvuejs/configuration/WebSecurityConfiguration.java)) that should be given access to our application is a test-only practice!

For our super simple example application, we could have a solution quite similar - but much more safe: If we would be able to extract this code into configuration and later use Spring's powerful mechanism of overriding these configuration with environment variables, we could then store them safely inside our deployment pipelines settings, that are again secured by another login - e.g. as Heroku Config Vars.

Therefore the first step would be to delete the following code:

```
@Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.inMemoryAuthentication()
                .withUser(""foo"").password(""{noop}bar"").roles(""USER"");
    }
```

and add the following configuration to our [application.properties](backend/src/main/resources/application.properties):

```
spring.security.user.name=sina
spring.security.user.password=miller
```

Running our tests using the old credentials should fail now. Providing the newer one, the test should go green again.

Now introducing environment variables to the game could also be done locally inside our IDE for example. First change the test `secured_api_should_give_http_200_when_authorized` again and choose some new credentials like user `maik` with pw `meyer`.

Don't change the `application.properties` right now - use your IDE's run configuration and insert two environment variables:

```
SPRING_SECURITY_USER_NAME=maik
SPRING_SECURITY_USER_PASSWORD=meyer
```

Now the test should run green again with this new values.


## Protect parts of Vue.js frontend

Now that we have secured a specific part of our backend API, let's also secure a part of our Vue.js frontend:

        +-----------------------------------------------------------------------+
        |  Vue.js frontend                                                      |
        |                                                                       |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |   |                 |    |                 |    |                 |   |
        |   |                 |    |                 |    |  Protected      |   |
        |   |                 |    |                 |    |                 |   |
        |   |                 |    |                 |    |  Vue.js View    |   |
        |   |                 |    |                 |    |                 |   |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |                                                                       |
        +-----------------------------------------------------------------------+

                   +---+                  +---+                  +---+
                   |   | /api/hello       |   | /api/user        |   | /api/secured
                   +---+                  +---+                  +---+
                     |                      |                      |
        +-----------------------------------------------------------------------+
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |  Spring Boot backend                                                  |
        +-----------------------------------------------------------------------+


#### Create a new Vue Login component

As there is already a secured Backend API, we also want to have a secured frontend part. 

Every solution you find on the net seems to be quite overengineered for the ""super-small-we-have-to-ship-today-app"". Why should we bother with a frontend auth store like vuex at the beginning? Why start with OAuth right up front? These could be easily added later on!

The simplest solution one could think about how to secure our frontend, would be to create a simple Login.vue component, that simply accesses the `/api/secured` resource every time the login is used.

Therefore we use [Vue.js conditionals](https://vuejs.org/v2/guide/conditional.html) to show something on our new [Login.vue](frontend/src/components/Login.vue):

```
<template>
  <div class=""protected"" v-if=""loginSuccess"">
    <h1><b-badge variant=""success"">Access to protected site granted!</b-badge></h1>
    <h5>If you're able to read this, you've successfully logged in.</h5>
  </div>
  <div class=""unprotected"" v-else-if=""loginError"">
    <h1><b-badge variant=""danger"">You don't have rights here, mate :D</b-badge></h1>
    <h5>Seams that you don't have access rights... </h5>
  </div>
  <div class=""unprotected"" v-else>
    <h1><b-badge variant=""info"">Please login to get access!</b-badge></h1>
    <h5>You're not logged in - so you don't see much here. Try to log in:</h5>

    <form @submit.prevent=""callLogin()"">
      <input type=""text"" placeholder=""username"" v-model=""user"">
      <input type=""password"" placeholder=""password"" v-model=""password"">
      <b-btn variant=""success"" type=""submit"">Login</b-btn>
      <p v-if=""error"" class=""error"">Bad login information</p>
    </form>
  </div>

</template>

<script>
import api from './backend-api'

export default {
  name: 'login',

  data () {
    return {
      loginSuccess: false,
      loginError: false,
      user: '',
      password: '',
      error: false
    }
  }
}

</script>
``` 

For now the conditional is only handled by two boolean values: `loginSuccess` and `loginError`.

To bring those to life, we implement the `callLogin()` method:

```
,
  methods: {
    callLogin() {
      api.getSecured(this.user, this.password).then(response => {
        console.log(""Response: '"" + response.data + ""' with Statuscode "" + response.status)
        if(response.status == 200) {
          this.loginSuccess = true
        }
      }).catch(error => {
        console.log(""Error: "" + error)
        this.loginError = true
      })
    }
  }
```

With this simple implementation, the Login component asks the Spring Boot backend, if a user is allowed to access the `/api/secured` resource. The [backend-api.js](frontend/src/components/backend-api.js) provides an method, which uses axios' Basic Auth feature:

```
    getSecured(user, password) {
        return AXIOS.get(`/secured/`,{
            auth: {
                username: user,
                password: password
            }});
    }
``` 

Now the Login component works for the first time:

![secure-spring-vue-simple-login](screenshots/secure-spring-vue-simple-login.gif)




#### Protect multiple Vue.js components

Now we have a working Login component. Now let's create a new `Protected.vue` component, since we want to have something that's only accessible, if somebody has logged in correctly:

```
<template>
  <div class=""protected"" v-if=""loginSuccess"">
    <h1><b-badge variant=""success"">Access to protected site granted!</b-badge></h1>
    <h5>If you're able to read this, you've successfully logged in.</h5>
  </div>
  <div class=""unprotected"" v-else>
    <h1><b-badge variant=""info"">Please login to get access!</b-badge></h1>
    <h5>You're not logged in - so you don't see much here. Try to log in:</h5>
    <router-link :to=""{ name: 'Login' }"" exact target=""_blank"">Login</router-link>
  </div>

</template>

<script>
import api from './backend-api'

export default {
  name: 'protected',

  data () {
    return {
      loginSuccess: false,
      error: false
    }
  },
  methods: {
    //
  }
}

</script>
```

This component should only be visible, if the appropriate access was granted at the Login. Therefore we need to solve 2 problems:

* __Store the login state__
* __Redirect user from Protected.vue to Login.vue, if not authenticated before__



#### Store login information with vuex

The super dooper simple solution would be to simply use `LocalStorage`. But with [vuex](https://github.com/vuejs/vuex) there is a centralized state management in Vue.js, which is pretty popular. So we should invest some time to get familiar with it. There's a full guide available: https://vuex.vuejs.org/guide/ and a great introductory blog post here: https://pusher.com/tutorials/authentication-vue-vuex

You could also initialize a new Vue.js project with Vue CLI and mark the `vuex` checkbox. But we try to extend the current project here.

First we add [the vuex dependency](https://www.npmjs.com/package/vuex) into our [package.json](frontend/package.json):

```
...
    ""vue"": ""^2.6.10"",
    ""vue-router"": ""^3.0.6"",
    ""vuex"": ""^3.1.1""
  },
```

> There are four things that go into a Vuex module: the initial [state](https://vuex.vuejs.org/guide/state.html), [getters](https://vuex.vuejs.org/guide/getters.html), [mutations](https://vuex.vuejs.org/guide/mutations.html) and [actions](https://vuex.vuejs.org/guide/actions.html)

#### Define the vuex state

To implement them, we create a new [store.js](frontend/src/store.js) file:

```
import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)

export default new Vuex.Store({
    state: {
        loginSuccess: false,
        loginError: false,
        userName: null
    },
  mutations: {

  },
  actions: {

  },
  getters: {
  
  }
})

``` 

We only have an initial state here, which is that a login could be successful or not - and there should be a `userName`.


#### Define a vuex action login() and the mutations login_success & login_error

Then we have a look onto __vuex actions: They provide a way to commit mutations to the vuex store.__ 

As our app here is super simple, we only have one action to implement here: `login`. We omit the `logout` and `register` actions, because we only define one admin user in the Spring Boot backend right now and don't need an implemented logout right now. Both could be implemented later!

We just shift our logic on how to login a user from the `Login.vue` to our vuex action method:

```
    mutations: {
        login_success(state, name){
            state.loginSuccess = true
            state.userName = name

        },
        login_error(state){
            state.loginError = true
            state.userName = name
        }
    },
    actions: {
        async login({commit}, user, password) {
            api.getSecured(user, password)
                .then(response => {
                    console.log(""Response: '"" + response.data + ""' with Statuscode "" + response.status);
                    if(response.status == 200) {
                        // place the loginSuccess state into our vuex store
                        return commit('login_success', name);
                    }
                }).catch(error => {
                    console.log(""Error: "" + error);
                    // place the loginError state into our vuex store
                    commit('login_error', name);
                    return Promise.reject(""Invald credentials!"")
                })
        }
    },
```

Instead of directly setting a boolean to a variable, we `commit` a mutation to our store if the authentication request was successful or unsuccessful. We therefore implement two simple mutations: `login_success` & `login_error`


#### Last but not least: define getters for the vuex state

To be able to access vuex state from within other components, we need to implement getters inside our vuex store. As we only want some simple info, we need the following getters:

```
    getters: {
        isLoggedIn: state => state.loginSuccess,
        hasLoginErrored: state => state.loginError
    }
```

#### Use vuex Store inside the Login component and forward to Protected.vue, if Login succeeded

Instead of directly calling the auth endpoint via axios inside our Login component, we now want to use our vuex store and its actions instead. Therefore we don't even need to import the [store.js](frontend/src/store.js) inside our `Login.vue`, we can simply access it through `$store`. Thy is that? Because we already did that inside our [main.js](frontend/src/main.js):

```
import store from './store'

...

new Vue({
    router,
    store,
    render: h => h(App)
}).$mount('#app')
```

With that configuration `store` and `router` are accessible from within every Vue component with the `$` prefixed :) 

If we have a look into our `Login.vue` we see that in action:

```
callLogin() {
      this.$store.dispatch('login', { user: this.user, password: this.password})
        .then(() => this.$router.push('/Protected'))
        .catch(error => {
          this.error.push(error)
        })
    }
```

Here we access our vuex store action `login` and issue a login request to our Spring Boot backend. If this succeeds, we use the Vue `$router` to forward the user to our `Protected.vue` component.


#### Redirect user from Protected.vue to Login.vue, if not authenticated before

Now let's enhance our [router.js](frontend/src/router.js) slightly. We use the Vue.js routers' [meta field](https://router.vuejs.org/guide/advanced/meta.html) feature to check, whether a user is loggin in already and therefore should be able to access our Protected component with the URI `/protected` :

```
    {
        path: '/protected',
        component: Protected,
        meta: { 
            requiresAuth: true 
        }
    },
``` 

We also add a new behavior to our router, that checks if it requires authentication every time a route is accessed. If so, it will redirect to our Login component:

```
router.beforeEach((to, from, next) => {
    if (to.matched.some(record => record.meta.requiresAuth)) {
        // this route requires auth, check if logged in
        // if not, redirect to login page.
        if (!store.getters.isLoggedIn) {
            next({
                path: '/login'
            })
        } else {
            next();
        }
    } else {
        next(); // make sure to always call next()!
    }
});
```

Now if one clicks onto `Protected` and didn't login prior, our application redirects to `Login` automatically:

![secure-spring-redirect-to-login](screenshots/secure-spring-redirect-to-login.gif)

With this redirect, we also don't need the part with `<div class=""protected"" v-if=""loginSuccess"">` inside our Login.vue, since in case of a successful login, the user is directly redirected to the Protected.vue.


## Check auth state at secured backend endpoints

We're now already where we wanted to be at the first place: Our Spring Boot backend has a secured API endpoint, which works with simple user/password authentication. And our Vue.js frontend uses this endpoint to do a Login and protect the `Protected` component, if the user didn't log in before. The login state is held in the frontend, using the `vuex` store.

Now if we want to go a step ahead and call a secured API endpoint in the backend from within our `Protected` frontend component, we need to fully store the credentials inside our `vuex` store, so we could access our secured resource


        +-----------------------------------------------------------------------+
        |  Vue.js frontend                                                      |
        |                          +----------------------------------------+   |
        |                          |                vuex store              |   |
        |                          +----------------------------------------+   |
        |                                   |                      |            |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |   |                 |    |                 |    |                 |   |
        |   |                 |    |    Login.vue    |    |    Protected    |   |
        |   |                 |    |                 |    |                 |   |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |                                           |               |           |
        +-------------------------------------------|---------------|-----------+
                                                    |-------------| |  
                   +---+                  +---+                  +---+
                   |   | /api/hello       |   | /api/user        |   | /api/secured
                   +---+                  +---+                  +---+
                     |                      |                      |
        +-----------------------------------------------------------------------+
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |  Spring Boot backend                                                  |
        +-----------------------------------------------------------------------+

Therefore we enhance our [store.js](frontend/src/store.js):

```
export default new Vuex.Store({
    state: {
        loginSuccess: false,
        loginError: false,
        userName: null,
        userPass: null,
        response: []
    },
    mutations: {
        login_success(state, payload){
            state.loginSuccess = true;
            state.userName = payload.userName;
            state.userPass = payload.userPass;
        },
    ...
    },
    actions: {
        login({commit}, {user, password}) {
            ...
                            // place the loginSuccess state into our vuex store
                            commit('login_success', {
                                userName: user,
                                userPass: password
                            });
            ...
    getters: {
        isLoggedIn: state => state.loginSuccess,
        hasLoginErrored: state => state.loginError,
        getUserName: state => state.userName,
        getUserPass: state => state.userPass
    }
```

> Be sure to use the current way to define and [interact with vuex mutations](https://vuex.vuejs.org/guide/mutations.html). Lot's of blog posts are using an old way of committing multiple parameters like `commit('auth_success', token, user)`. This DOES NOT work anymore. Only the first parameter will be set, the others are lost! 

Now inside our [Protected.vue](frontend/src/components/Protected.vue), we can use the stored credentials to access our `/secured` endpoint:

```
<script>
  import api from './backend-api'
  import store from './../store'

export default {
  name: 'protected',

  data () {
    return {
      backendResponse: '',
      securedApiCallSuccess: false,
      errors: null
    }
  },
  methods: {
    getSecuredTextFromBackend() {
      api.getSecured(store.getters.getUserName, store.getters.getUserPass)
              .then(response => {
                console.log(""Response: '"" + response.data + ""' with Statuscode "" + response.status);
                this.securedApiCallSuccess = true;
                this.backendResponse = response.data;
              })
              .catch(error => {
                console.log(""Error: "" + error);
                this.errors = error;
              })
    }
  }
}
```

Feel free to create a nice GUI based on `securedApiCallSuccess`, `backendResponse` and `errors` :)



# Links

Nice introductory video: https://www.youtube.com/watch?v=z6hQqgvGI4Y

Examples: https://vuejs.org/v2/examples/

Easy to use web-based Editor: https://vuejs.org/v2/examples/
"
TimothyWrightSoftware/Fundamental-2D-Game-Programming-With-Java,master,90,48,2015-02-05T01:44:52Z,102324,2,"Source code examples for the book Fundamental 2D Game Programming with Java""""",,"# Fundamental-2D-Game-Programming-With-Java
Source code examples for the book ""Fundamental 2D Game Programming with Java""
"
carlphilipp/clean-architecture-example,master,517,166,2018-04-11T01:09:36Z,179,1,An example to create a clean architecture with Java 11,clean-architecture,"## Clean Architecture Example

### Blog post

https://medium.com/slalom-engineering/clean-architecture-with-java-11-f78bba431041

### Pre-requisite

Java 11

```
> java -version
openjdk version ""11"" 2018-09-25
OpenJDK Runtime Environment 18.9 (build 11+28)
OpenJDK 64-Bit Server VM 18.9 (build 11+28, mixed mode)
```

### Compile

`./gradlew clean build`

### Run Spring example

`java -jar application/spring-app/build/libs/spring-app-1.0.0.jar`

### Run Vertx example

`java -jar application/vertx-app/build/libs/vertx-app-1.0.0-fat.jar`

### Use the webbapps

#### Create User
```
POST: http://localhost:8080/users
Body:
{
  ""email"": ""test@test.com"",
  ""password"": ""mypassword"",
  ""lastName"": ""Doe"",  
  ""firstName"": ""John""
}
```

#### Get all users
```
GET: http://localhost:8080/users
```

#### Get one user
```
GET: http://localhost:8080/users/0675171368e011e882d5acde48001122
```

#### Login
```
GET: http://localhost:8080/login?email=test@test.com&password=mypassword
```
"
cstew/Splash,master,569,152,2015-07-17T13:51:25Z,380,4,An example of a splash screen done the right way ,,"# Splash
An example of a splash screen done the right way on Android

![](art/sample_splash.gif)
"
RameshMF/gof-java-design-patterns,master,49,44,2018-02-11T16:54:50Z,307,0,Repository for all GOF design patterns with examples in Java.,design-patterns gof-patterns,"<div dir=""ltr"" style=""text-align: left;"" trbidi=""on"">
<div class=""separator"" style=""clear: both; text-align: center;"">
<a href=""https://3.bp.blogspot.com/-dXzvWYhPucA/WwgfWrX75CI/AAAAAAAACR8/Tz_HGOSwSoARRBXJBOpHtW0C7u1dIBkwgCLcBGAs/s1600/design_patterns_gof.png"" imageanchor=""1"" style=""margin-left: 1em; margin-right: 1em;""><span style=""font-family: &quot;verdana&quot; , sans-serif;""><img border=""0"" data-original-height=""88"" data-original-width=""365"" height=""154"" src=""https://3.bp.blogspot.com/-dXzvWYhPucA/WwgfWrX75CI/AAAAAAAACR8/Tz_HGOSwSoARRBXJBOpHtW0C7u1dIBkwgCLcBGAs/s640/design_patterns_gof.png"" width=""640""></span></a></div>
<span style=""font-family: &quot;verdana&quot; , sans-serif;"">List of all design patterns referred from the book: <a href=""https://www.amazon.com/Design-Patterns-Elements-Reusable-Object-Oriented/dp/0201633612v"" target=""_blank"">Design Patterns: Elements of Reusable Object-Oriented Software (Addison-Wesley Professional Computing Series)</a><img alt="""" border=""0"" height=""1"" src=""//ir-in.amazon-adsystem.com/e/ir?t=rameshfadatar-21&amp;l=am2&amp;o=31&amp;a=B000SEIBB8"" style=""border: none !important; margin: 0px !important;"" width=""1""></span><br>
<span style=""font-family: &quot;verdana&quot; , sans-serif;"">All the design patterns explained by real-world examples, class diagrams, source code, applicability, references etc.</span><br>
<h3 style=""text-align: left;"">
<span style=""font-family: &quot;verdana&quot; , sans-serif;"">Design Patterns(GOF)</span></h3>
<div class=""widget LinkList"" data-version=""2"" id=""LinkList1"">
<div class=""widget-content"">
<ul>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/design-patterns-overview.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Design Patterns Overview</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2018/01/object-oriented-design-principles.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Object Oriented Design Principles</span></a></li>
</ul>
</div>
</div>
<div class=""widget LinkList"" data-version=""2"" id=""LinkList2"">
<h3 class=""title"">
<span style=""font-family: &quot;verdana&quot; , sans-serif;""> Creational Patterns </span></h3>
<div class=""widget-content"">
<ul>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/singleton-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Singleton Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/factory-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Factory Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/abstract-factory-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Abstract Factory Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/builder-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Builder Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/prototype-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Prototype Design Pattern</span></a></li>
<li><a href=""http://ramesh-java-design-patterns.blogspot.com/2018/05/object-pool-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Object Pool Design Pattern</span></a></li>
</ul>
</div>
</div>
<div class=""widget LinkList"" data-version=""2"" id=""LinkList3"">
<h3 class=""title"">
<span style=""font-family: &quot;verdana&quot; , sans-serif;""> Structural Patterns </span></h3>
<div class=""widget-content"">
<ul>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/adapter-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Adapter Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/bridge-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Bridge Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/composite-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Composite Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/decorator-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Decorator Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/facade-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Facade Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/flyweight-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Flyweight Design Pattern</span></a></li>
<li><a href=""http://ramesh-java-design-patterns.blogspot.in/2017/12/proxy-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Proxy Design Pattern</span></a></li>
</ul>
</div>
</div>
<div class=""widget LinkList"" data-version=""2"" id=""LinkList4"">
<h3 class=""title"">
<span style=""font-family: &quot;verdana&quot; , sans-serif;""> Behavioral Patterns </span></h3>
<div class=""widget-content"">
<ul>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/chain-of-responsibility.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Chain of responsibility</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/command-design-pattern_23.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Command Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/iterator-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Iterator Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2018/03/mediator-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Mediator Design Pattern</span></a></li>
<li><a href=""http://ramesh-java-design-patterns.blogspot.in/2018/03/memento-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Memento Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/observer-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Observer Design Pattern</span></a></li>
<li><a href=""http://ramesh-java-design-patterns.blogspot.in/2018/02/state-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">State Design Pattern</span></a></li>
<li><a href=""http://ramesh-java-design-patterns.blogspot.in/2018/02/strategy-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Strategy Design Pattern</span></a></li>
<li><a href=""https://ramesh-java-design-patterns.blogspot.in/2017/12/template-method-design-pattern.html"" target=""_blank""><span style=""font-family: &quot;verdana&quot; , sans-serif;"">Template Method Design Pattern</span></a></li>
<li><span style=""font-family: &quot;verdana&quot; , sans-serif;""><a href=""https://ramesh-java-design-patterns.blogspot.in/2018/05/delegation-pattern.html"" target=""_blank"">Delegation Pattern</a></span></li>
</ul>
<div>
<span style=""font-family: &quot;verdana&quot; , sans-serif;"">Download source code from our Github Repository :</span></div>
<div>
<span style=""font-family: &quot;verdana&quot; , sans-serif;""><a href=""https://github.com/RameshMF/gof-java-design-patterns"" target=""_blank"">https://github.com/RameshMF/gof-java-design-patterns</a></span></div>
</div>
</div>
</div>
"
chcordova/design-patterns-head-first-book,master,48,37,2018-06-14T06:08:34Z,45221,0,O'Reilly Head First Design Patterns - Java 8 Examples,,"# [O'Reilly Head First Design Patterns] - Java 8 Examples
![Cover](head-firts-design-patterns-cover.png)
"
florina-muntenescu/DroidconMVVM,master,480,114,2016-03-31T10:29:13Z,204,2,Hello," World!"" example of the Model-View-ViewModel pattern""","# Model-View-ViewModel ""Hello, World!""

This is a ""Hello, World!"" project done for a Droidcon Zagreb 2016 talk on [MVVM & RxJava – the perfect mix][droidcon].

The project contains an exemplification of the Model-View-ViewModel pattern used together with RxJava.
A ""Hello, World!"" greeting will be displayed based on the selected language. 

The `DataModel` provides supported languages and also retrieval of the greeting based on the language.
The `ViewModel` exposes greetings and supported languages as stream of events through [RxJava Observables][observables]. The ViewModel also allows setting the selected language.
The `View` is an Activity that contains a Spinner with the supported languages and a text view that displays a greeting, based on the selected language.


![Model-View-ViewModel](https://github.com/florina-muntenescu/DroidconMVVM/blob/readme/screenshots/mvvm.png?raw=true)

[droidcon]: <http://droidcon.hr/en/sessions/mvvm-rxjava-perfect-mix/>
[observables]: <http://reactivex.io/documentation/observable.html>

"
gridgain/gridgain-advanced-examples,master,28,15,2014-06-08T18:23:50Z,199,0,,,"gridgain-advanced-examples
=========================

This project contains advanced examples of GridGain usage, above and beyond the examples that are included with the GridGain distributions.
"
gzz2017gzz/spring-boot2-example,master,53,39,2019-01-18T07:24:17Z,1691,3,spring-boot2- example,,
MahmoudElSharkawy/Automation-Practice,master,34,18,2019-07-16T12:54:13Z,77941,10,Test Automation Practice Examples,,"# Automation-Practice
This is where I practice Test Automation!

### The main Frameworks included in the project:
* Selenium Webdriver
* Rest-Assured
* TestNG
* Allure Report
* Extent Reports
* Apachi POI


### Project Design:
* Page Object Model (POM) design pattern
* Data Driven framework
* Fluent design approach (method chaining)
* Have a supporting Utilities package in *src/main/java* file path, named ***""Utils""*** that includes many wrapper methods in static classes which services as a core engine for the project 
* Implementing the ***Test Automation Pyramid*** by have 2 different test automation levels which are SERVICE and GUI layers


### How to check the execution logs and open the latest execution reports from GitHub Actions:
* You need to be logged-in to the GitHub as a prerequisite
* Open the GitHub Actions tab
* Open the latest workflow run from the list
* To check the execution logs, click on ""Test on Ubuntu"" job and open the ""Run Tests - Chrome Headless"" step and then you can see and check the execution logs
* To open the Allure report, in the *Artifacts* section, Click on the ""Allure Report"" and then unzip the archive file and then open the ""index.html"" file (If you are on Windows and the report opened with empty data, you need to open the ""allow-file-access_open-report_chrome_windows.bat"" file to be able to see the report data)
* To open the Extent report, in the *Artifacts* section, Click on the ""Extent Report"" and then unzip the archive file and then open the ""ExtentReports.html"" file


### How to run the project main test cases locally:
* A properties file ***""automationPractice.properties""*** can be found it *src/main/resources* file path including all the configurations needed in the execution
* Can find the test cases in the *src/test/java* folder mainly in the *phptravels.tests* and *restfulbooker.tests* packages
* Can find the test suite for all the main practice test cases in the *src/test/resources/TestSuits* folder in the *automationPractice.xml* file
* To start the execution, please make sure that the ""execution.type"" property is ""Local"" if you are running locally then right click on the test suite xml file and click Run As >> TestNG Suit 
* After executing, you can easily generate the ***Allure Report*** by opening a command-line terminal on the project root path and type `mvn allure:serve` (needs to be able to execute mvn commands); Or you can find the Extent Report ***ExtentReports.html*** in the project root path for the latest execution


###### Finally, you can also find a [playlist on Youtube](https://youtube.com/playlist?list=PLmayvCz0Xqr6TT-XJHlPtjDSdJ8WArBHi) (Arabic content) that summarizes and executing the project for some cases
"
JenniferRanjani/Object-Oriented-Programming-with-Java,master,25,34,2018-09-18T10:46:26Z,321,0,Contains basic examples for understanding Java concepts.,,"# Object-Oriented-Programming-with-Java
Contains the codes used for demonstrating the concepts
"
LB-Yu/data_systems_learning,master,33,30,2020-03-08T13:04:41Z,984,20,Learning summary and examples about data systems.,big-data distributed-systems flink hbase spark,"This repository contains some demos for learning data systems. Specifically contains:
+ Demos of SQL parsing tools, such as Apache callcite, Antlr.
+ Demo of big data storage and computing framework, such as Hadoop, Kafka, Flink."
javaturk/OOP,master,55,22,2014-12-19T00:23:54Z,156,3,Examples of OOP with Java course.,,"Programming examples for OOP with Java.

This is a repository that has all of the examples of OOP with Java course. 
The presentations and other materials can be found at www.javaturk.org address.

Please contact me at akin@javaturk.org if you need further help.

Thanks.

"
forax/loom-fiber,master,114,24,2018-07-28T17:30:23Z,5015,1,Continuation & Fiber examples using the OpenJDK project Loom prototype,,"# loom-fiber
This repository contains both my experimentation of the OpenJDK project Loom prototype
and a presentation and examples showing how to use it.

There is a [presentation of the loom project](loom%20is%20looming.pdf)
wiht the [examples](src/main/java/fr/umlv/loom/example).

## How to build

Download the latest early access build of jdk-20 [http://jdk.java.net/](http://jdk.java.net/)
set the environment variable JAVA_HOME to point to that JDK and then use Maven.

```
  export JAVA_HOME=/path/to/jdk
  mvn package
```

## How to run the examples

On top of each example, there is the command line to run it.
- Loom is a preview version so `--enable-preview` is required,
- For `ScopeLocal` and `StructuredTaskScope`, these are not yet part of the official API
  and are declared in module/package `jdk.incubator.concurrent`so this module
  has to be added to the command line with `--add-modules jdk.incubator.concurrent`,
- If you want to play with the internals, the class `Continuation` is hidden thus
  `--add-exports java.base/jdk.internal.vm=ALL-UNNAMED` should be added to the command line.

## AsyncScope

This repository also contains a high-level structured concurrency construct named
[src/main/java/fr/umlv/loom/structured/AsyncScope.java](AsyncScope) that is a proposed replacement
to the more low level `StructuredTaskScope` currently provided by the OpenJDK loom repository.

## Loom actor framework

At some point of the history, this project was containing an actor system based on loom.
It has now its own repository [https://github.com/forax/loom-actor](https://github.com/forax/loom-actor).

## Loom expressjs

There is a re-implementation of the [expressjs API](https://expressjs.com/en/4x/api.html) in Java using Loom
[JExpressLoom.java](https://github.com/forax/jexpress/blob/master/src/main/java/JExpressLoom.java).
"
suyash248/spring_framework,master,33,35,2015-01-04T18:35:49Z,25325,0,"Examples on Spring(Core, AOP, DAO, Transaction Management)",java spring spring-aop spring-core spring-dao spring-di spring-transaction-manager,"# Spring Framework

- Spring Core(IOC & DI)
- Spring AOP
- Spring DAO & Integrations
- Spring Transaction Management
"
njnareshjoshi/articles,master,118,120,2017-02-03T17:07:14Z,4629,2,This repository along with the exercises repository (https://github.com/njnareshjoshi/exercises) contains coding examples for my blog ProgrammingMitra,java java-8 java-cloning java-serialization jpa-auditing spring spring-data,"This repository along with the [exercises](https://github.com/njnareshjoshi/exercises) repository contains coding examples for my blog [ProgrammingMitra](https://www.programmingmitra.com).

### Spring
* [Introduction To Spring](https://www.programmingmitra.com/2016/05/introduction-to-spring.html)
* [Spring Modular Architecture](https://www.programmingmitra.com/2018/07/spring-modular-architecture.html)

### Spring Data
* [Spring Data JPA Auditing: Saving CreatedBy, CreatedDate, LastModifiedBy, LastModifiedDate Automatically](https://www.programmingmitra.com/2017/02/automatic-spring-data-jpa-auditing-saving-CreatedBy-createddate-lastmodifiedby-lastmodifieddate-automatically.html)
* [JPA Auditing: Persisting Audit Logs Automatically Using EntityListeners](https://www.programmingmitra.com/2017/02/automatic-jpa-auditing-persisting-audit-logs-automatically-using-entityListeners.html)
* [AutoWiring Spring Beans Into Classes Not Managed By Spring Like JPA Entity Listeners](https://www.programmingmitra.com/2017/03/AutoWiring-Spring-Beans-Into-Classes-Not-Managed-By-Spring-Like-JPA-Entity-Listeners.html)
* [Implementing Our Own Custom Spring Data Solr Repository](https://www.programmingmitra.com/2016/01/how-to-write-custom-implementation-for.html)

### What In Java
* [What is Variable Shadowing And Hiding In Java](https://www.programmingmitra.com/2018/02/what-is-variable-shadowing-and-hiding.html)
* [Everything About Method Overloading Vs Method Overriding](https://www.programmingmitra.com/2017/05/everything-about-method-overloading-vs-method-overriding.html)
* [Everything About ClassNotFoundException Vs NoClassDefFoundError](https://www.programmingmitra.com/2017/04/Difference-Between-ClassNotFoundException-and-NoClassDefFoundError.html)
* [Java Cloning - Copy Constructor versus Cloning](https://www.programmingmitra.com/2017/01/Java-cloning-copy-constructor-versus-Object-clone-or-cloning.html)
* [Java Cloning And Types Of Cloning (Shallow And Deep) In Details With Example](https://www.programmingmitra.com/2016/11/Java-Cloning-Types-of-Cloning-Shallow-Deep-in-Details-with-Example.html)
* [Java Lambda Expression Explained With Example](https://www.programmingmitra.com/2016/06/java-lambda-expression-explained-with-example.html)
* [What are JDK And JRE? JDK And JRE File Structure Explained](https://www.programmingmitra.com/2016/05/jdk-and-jre-file-structure.html)
* [What are 5 Different Ways To Create Objects In Java? Explained With Example](https://www.programmingmitra.com/2016/05/different-ways-to-create-objects-in-java-with-example.html)
* [Plain Old Java Object (POJO) Explained](https://www.programmingmitra.com/2016/05/plain-old-java-object-pojo-explained.html)
* [Types Of References In Java(Strong Soft Weak Phantom)](https://www.programmingmitra.com/2016/05/types-of-references-in-javastrong-soft.html)
* [What is Serialization? Everything About Java Serialization Explained With Example](https://www.programmingmitra.com/2019/08/what-is-serialization-everything-about-java-serialization-explained-with-example.html)
* [Java Serialization Magic Methods And Their Uses With Example](https://www.programmingmitra.com/2019/08/java-serialization-magic-methods-and-their-uses-with-example.html)

### Why In Java
* [Java Integer Cache - Why Integer.valueOf(127) == Integer.valueOf(127) Is True](https://www.programmingmitra.com/2018/11/java-integer-cache.html)
* [Why Instance Variable Of Super Class Is Not Overridden In Sub Class](https://www.programmingmitra.com/2018/11/why-instance-variable-of-super-class-is-not-overridden-In-sub-class.html)
* [Why String is Immutable And Final In Java](https://www.programmingmitra.com/2018/02/why-string-is-immutable-and-final-in-java.html)
* [Why String is Stored In String Constant Pool](https://www.programmingmitra.com/2018/02/why-string-is-stored-in-constant-pool.html)
* [Why We Should Follow Method Overriding Rules](https://www.programmingmitra.com/2017/12/why-we-should-follow-method-overriding-rules.html)
* [Why Should We Follow Method Overloading Rules](https://www.programmingmitra.com/2017/12/why-to-follow-method-overloading-rules.html)
* [How Does JVM Handle Method Overloading And Overriding Internally](https://www.programmingmitra.com/2017/05/how-does-jvm-handle-method-overriding-internally.html)
* [Java Cloning - Why Even Copy Constructors Are Not Sufficient](https://www.programmingmitra.com/2017/01/java-cloning-why-copy-constructors-are-not-sufficient-or-good.html)
* [Java Cloning - Copy Constructor versus Cloning](https://www.programmingmitra.com/2017/01/Java-cloning-copy-constructor-versus-Object-clone-or-cloning.html)
* [Why An outer Java class can’t be static](https://www.programmingmitra.com/2016/10/why-outer-java-class-cant-be-static.html)
* [Why An outer Java class can’t be private or protected](https://www.programmingmitra.com/2016/10/why-a-java-class-can-not-be-private-or-protected.html)
* [Why Java is Purely Object Oriented Language Or Why Not](https://www.programmingmitra.com/2016/06/why-java-is-purely-object-oriented-or-why-not.html)
* [Why Single Java Source File Can Not Have More Than One public class](https://www.programmingmitra.com/2016/05/Why-Single-Java-Source-File-Can-Not-Have-More-Than-One-public-class.html)

### How In Java
* [How To Customize Serialization In Java By Using Externalizable Interface](https://www.programmingmitra.com/2019/08/how-to-customize-serialization-in-java-by-using-externalizable-interface.html)
* [What are 5 Different Ways To Create Objects In Java? Explained With Example](https://www.programmingmitra.com/2016/05/different-ways-to-create-objects-in-java-with-example.html)
* [How To Create Objects By Using Reflection APIs In Java With Example](https://www.programmingmitra.com/2016/05/creating-objects-through-reflection-in-java-with-example.html)
* [How To Install Multiple Versions Of Java On The Same Machine](https://www.programmingmitra.com/2019/03/how-to-install-multiple-versions-of-java-on-the-same-machine.html)
* [How To Create An Immutable Class In Java With Example](https://www.programmingmitra.com/2018/02/how-to-create-immutable-class-in-java.html)
* [How Does JVM Handle Polymorphism (Method Overloading And Method Overriding) Internally](https://www.programmingmitra.com/2017/05/how-does-jvm-handle-method-overriding-internally.html)
* [Java Cloning - How Copy Constructors are Better Than Cloning](https://www.programmingmitra.com/2017/01/Java-cloning-copy-constructor-versus-Object-clone-or-cloning.html)
* [How To Create An Immutable Class In Java With Example](https://www.programmingmitra.com/2018/02/how-to-create-immutable-class-in-java.html)

### Useful Dev Tools
* [How To Install Multiple Versions Of Java On The Same Machine](https://www.programmingmitra.com/2019/03/how-to-install-multiple-versions-of-java-on-the-same-machine.html)
* [Project Lombok : The Boilerplate Code Extractor](https://www.programmingmitra.com/2017/01/Project-Lombok-The-Boilerplate-Code-Extractor.html)
* [Useful Git Commands](https://www.programmingmitra.com/2019/01/useful-git-commands.html)

### ClassNotFoundException Vs NoClassDefFoundError
* [Difference Between ClassNotFoundException And NoClassDefFoundError](https://www.programmingmitra.com/2017/04/Difference-Between-ClassNotFoundException-and-NoClassDefFoundError.html)

### Java Cloning Vs Copy Constructors Vs Defensive Copy Methods
* [Java Cloning and Types of Cloning (Shallow and Deep) in Details with Example](https://www.programmingmitra.com/2016/11/Java-Cloning-Types-of-Cloning-Shallow-Deep-in-Details-with-Example.html)
* [Java Cloning Copy Constructor Versus Object Clone Or Cloning](https://www.programmingmitra.com/2017/01/Java-cloning-copy-constructor-versus-Object-clone-or-cloning.html)
* [Java Cloning Why Copy Constructors Are Not Sufficient Or Good](https://www.programmingmitra.com/2017/01/java-cloning-why-copy-constructors-are-not-sufficient-or-good.html)

### Immutability In Java
* [How To Create Immutable Class In Java](https://www.programmingmitra.com/2018/02/how-to-create-immutable-class-in-java.html)
* [Why String Is Immutable And Final In Java](https://www.programmingmitra.com/2018/02/why-string-is-immutable-and-final-in-java.html)

### Java Integer Cache
* [Java Integer Cache - Why Integer.valueOf(127) == Integer.valueOf(127) Is True](https://www.programmingmitra.com/2018/11/java-integer-cache.html)

### Java 8 - Lambda
* [Java Lambda Expression Explained With Example](https://www.programmingmitra.com/2016/06/java-lambda-expression-explained-with-example.html)
* [How To Install Multiple Versions Of Java On The Same Machine](https://www.programmingmitra.com/2019/03/how-to-install-multiple-versions-of-java-on-the-same-machine.html)

### Java Object Creation
* [Different Ways To Create Objects In Java With Example](https://www.programmingmitra.com/2016/05/different-ways-to-create-objects-in-java-with-example.html)
* [How To Create Objects By Using Reflection APIs In Java With Example](https://www.programmingmitra.com/2016/05/creating-objects-through-reflection-in-java-with-example.html)

### Java Method Overloading And Overriding
* [Everything About Method Overloading Vs Method Overriding](https://www.programmingmitra.com/2017/05/everything-about-method-overloading-vs-method-overriding.html)
* [Why We Should Follow Method Overriding Rules](https://www.programmingmitra.com/2017/12/why-we-should-follow-method-overriding-rules.html)
* [How Does JVM Handle Method Overloading And Overriding Internally](https://www.programmingmitra.com/2017/05/how-does-jvm-handle-method-overriding-internally.html)
* [Why Instance Variable Of Super Class Is Not Overridden In Sub Class](https://www.programmingmitra.com/2018/11/why-instance-variable-of-super-class-is-not-overridden-In-sub-class.html)

### Java Serialization And Externalization
* [What is Serialization? Everything About Java Serialization Explained With Example](https://www.programmingmitra.com/2019/08/what-is-serialization-everything-about-java-serialization-explained-with-example.html)
* [How To Customize Serialization In Java By Using Externalizable Interface](https://www.programmingmitra.com/2019/08/how-to-customize-serialization-in-java-by-using-externalizable-interface.html)
* [What are 5 Different Ways To Create Objects In Java? Explained With Example](https://www.programmingmitra.com/2016/05/different-ways-to-create-objects-in-java-with-example.html)
* [Java Serialization Magic Methods And Their Uses With Example](https://www.programmingmitra.com/2019/08/java-serialization-magic-methods-and-their-uses-with-example.html)"
RandyAbernethy/ThriftBook,master,110,40,2014-04-04T21:33:26Z,327,3,Source for the examples in the Programmer's Guide to Apache Thrift,,"The Programmer's Guide to Apache Thrift
=======================================

Source for the examples in: The Programmer's Guide to Apache Thrift

http://www.manning.com/abernethy/

The book is organized into three parts:

Part I - Apache Thrift Overview
-------------------------------

A high level introduction to Apache Thrift and its architecture. Examples from this part are hello worldish. This part also covers basic Apache Thrift setup and debugging.

Part II - Programming Apache Thrift
-----------------------------------

This part digs into each layer of the Apache Thrift framework, examining transports, protocols, types, services, servers and the Apache Thrift interface definition language in detail. Examples from these chapters use C++, Java and Python as the demonstration languages. C++ examples provide makefiles and Java examples provide Build.xml files for building with make/ant respectively. Build scripts and code  have been tested with various Apache Thrift versions. In general you should use the latest version of Apache Thrift. The Ant builds depend on SLF4J. The python examples are directly executable. You can checkout older version of this repo for examples compatible with older versions of Apache Thrift.

Part III - Apache Thrift Language Libraries
-------------------------------------------

This part of the book provides jump starts for the most popular platforms and languages used with Apache Thrift. The Web, and backend systems are examined through the lens of C++, Java, C#, JavaScript, Python, PHP, Perl and Ruby. Web chapters are complete or in-progress for Haxe, Go and Rust (code is/will-be found here). Part III also includes the final chapter, ""Apache Thrift in the Enterprise"", which demonstrates Apache Thrift in use with messaging systems and takes a pragmatic look at the key advantages of Apache Thrift and some of the common best practices for developing with the framework.

Tools - Miscellaneous Thrift Stuff
----------------------------------

This folder is for various Thrift related stuff. Presently only a GEdit language file for Apache Thrift IDL.

Development Environment
-----------------------

The Dockerfile in the root of this repo defines a development environment for the book which will make it easy to build and test all of the examples in the book. This file is configured to support C++, Java and Python as built but it is easy to add additional language support to the container or similarly configured system by following the instruction in the book. Apache Thrift is undergoing an important change on the way to v1.0. 

 - Switch out of the build platform (compiler and all libs) from autotools to cmake

As things migrate I will update this Dockerfile. You can ""$ docker run -it randyabernethy/thrift-book"" to run the prebuilt image on Docker Hub (https://hub.docker.com/r/randyabernethy/thrift-book/).

[![](https://images.microbadger.com/badges/image/randyabernethy/thrift-book.svg)](https://microbadger.com/images/randyabernethy/thrift-book ""Thrift Book Layers"")

"
bekwam/examples-javafx-repos1,master,26,19,2015-06-10T01:01:09Z,2289,5,Repository of JavaFX examples,,"# examples-fx-repos1
Repository of JavaFX examples
"
AutomateThePlanet/Design-Patterns-for-High-Quality-Automated-Tests-Java-Edition,master,54,44,2020-11-04T09:27:31Z,22680,0,Examples for Design Patterns for High-quality Automated Tests Java Edtion,,"## Before You Get Started ##

You need to have prior experience in OOP programming language such as C#, Java, etc. I believe that you can get the book's ideas just from reading the presented code. However, it is recommended to download and run all of the solutions on your machine. 

**As a bonus to the book, you can find video recordings with explanations for each chapter.** To get them, you can join for free the book's LinkedIn group. There you can find even more info about design patterns in automated testing and best practices or use it as an easy way to reach me. Before joining, you need to provide proof that you purchased the book. Just go to https://bit.ly/3eGTAUl

To build and execute the code, you will need a Java IDE, such as IntelliJ, Eclipse, or NetBeans. My preferred choice is IntelliJ. Also, it is recommended to install the latest version of the Java SDK. I show examples of new Java versions’ features through the book, so I encourage you to install the latest possible version. For software project management, I used Maven, and for unit testing framework TestNG, which means that depending on the IDE you picked, you will have to install the required plugins.

## Questions/Reader feedback/Errata ##

You can contact me at LinkedIn - [https://bit.ly/2NjWJ19](https://bit.ly/2NjWJ19) if you are having any problems with any aspect of the book, and I will do my best to address it.

## Foreword ##  
  
Since I usually skip the Foreword chapters of other books, I will try to be short. My core belief is that to achieve high-quality test automation that brings value- you need to understand core programming concepts such as SOLID and the usage of design patterns. After you master them, the usual career transition is into more architecture roles, such as choosing the best possible approaches for solving particular test automation challenges. This is the essence of the book. No more “Hello world” examples but some serious literature about test automation practices!  
P.S. After the first book's success, Design Patterns for High-Quality Automated Tests C# Edition, many people asked me when there will be a version for Java. This is why I started refreshing my Java knowledge and started writing. One year later, the book is here. More or less, the book explains the same concepts, but all code examples and specifics target the Java world. If you have read the C# edition, you can skip some of the more theoretical chapters or recheck them for a refresher.  
You may notice that I have changed the sub-title for those of you who have purchased the C# version. I believe that the new sub-title communicates much better the ideas of the book. I won't bother you with lengthy introductions and discussions about what clean code means. There are whole books about the subject. But if I had to summarize what clean code means in one sentence, I would say: ""Clean code is code that is easy to understand and easy to change."" Easy to understand means the code is easy to read, whether that reader is the original author of the code or somebody else. Its meaning is clear, so it minimizes the need for guesswork and the possibility of misunderstandings. It is easy to understand on every level. Easy to change means the code is easy to extend and refactor, and it's easy to fix bugs in the codebase. This can be achieved if the person making the changes understands the code and feels confident that the code changes do not break any existing functionality. I will end the intro with two quotes by two famous authors Robert C. Martin and Michael Feathers.
""If you want your code to be easy to write, make it easy to read.""  
""Clean code always looks like it  
 
### Who Is This Book For?  ### 
The book is not a getting started guide. If you don't have any prior programming experience in writing automated tests through WebDriver, this book won't be very useful to you. I believe it might be invaluable for the readers that have a couple of years of experience and whose job is to create/maintain test automation frameworks, or to write high-quality reliable automated tests.  
The book is written in Java. However, I believe that you can use the approaches and practices in every OOP language. If you have a Python background, you will get everything you need, don't worry. However, if you are a C# developer, I would suggest checking the book's C# version.  
Even if you don't get all the concepts from the first read, try to use and incorporate some of them. Later you can return and reread them. I believe with the accumulation of experience using high-quality practices- you will become a hard-core test automation ninja!

## What this book covers ##  
### Chapter 1. Defining High-Quality Test Attributes  ###
I think many terms are misunderstood and engineers are using them without fully understanding them, such as a library, framework, test framework. I believe this is the basic knowledge that all test engineers should have. The reader will learn about the top-quality attributes each test library should strive to have, which we will discuss in much more detail in the next chapters. Moreover, since we want to treat the test code as production one, we will talk about SOLID principles and how we can incorporate them into the development of the tests.  
###  Chapter 2. Optimizing and Refactoring Legacy Flaky Tests  ### 
We will discuss the Hermetic test pattern where each test should be isolated from others. Will learn about the Adapter design pattern where some of the unstable behaviours of WebDriver will be wrapped in a class and fixed. The same pattern will be used to improve the WebDriver API for locating elements and making it easier to use. Finally, we will talk about the random run order principle where the tests should be able to run no matter their order.  
###  Chapter 3. Strategies for Speeding-up the Tests  ### 
After the tests are stabilized and always passing the next step is to improve their speed. One of the approaches will be login to a website through cookies instead of using the UI. Next, the readers will see how to reuse the WebDriver browser instead of restarting it all the time earning more than 40% decrease in test execution time. We will talk about how to handle asynchronous requests and make test code parallelizable. Finally, we will mention the “Black Hole Proxy” approach isolating 3rd party services’ requests while further improving the speed of the automated tests.  
###  Chapter 4. Test Readability  ### 
Learn how to hide nitty-gritty low-level WebDriver API details in the so-called page objects, making the tests much more readable. Also, the readers will see how to create two different types of page objects depending on their needs. In the second part of the chapter, we will talk about coding standards - naming the variables and methods right, as well as placing the correct comments. At the end of the section, we will discuss various tools that can help us to enforce all these standards.  
### Chapter 5. Enhancing the Test Maintainability and Reusability  ### 
We will talk about how to reuse more code across page objects by using the Template Method design pattern. Also, we will see a 3rd type of page object model where the assertions and elements will be used as properties instead of coming from base classes, which will introduce the benefits of the composition over the inheritance principle. In the second part of the chapter, we will discuss how to reuse common test workflows through the Facade design pattern. At the end of the section, we will talk about an enhanced version of the pattern where we can test different versions of the same web page (new and old).  
### Chapter 6. API Usability  ### 
In this chapter, we will learn how to make the test library API easy to use, learn, and understand. First, we will talk about different approaches on how to use already developed page object models through the Singleton design pattern or Factory design pattern. After that, we will look at another approach called Fluent API or Chaining Methods. At the end of the section, we will discuss whether it is a good idea to expose the page objects elements to the users of your test library.  
### Chapter 7. Building Extensibility in Your Test Library  ### 
If you create a well-designed library, most probably other teams can start using it too, so you need to be sure that your library is easily extensible. It should allow everyone to modify it and add new features to it without causing you to spend tons of time rewriting existing logic or making already written tests to fail. In this chapter, the reader will learn how to improve extensibility for finding elements by creating custom selectors through the Strategy design pattern. After that, we will investigate ways on how we can add additional behaviors to existing WebDriver actions via Observer design pattern or built-in EventFiringWebDriver.  
### Chapter 8. Assessment System for Tests’ Architecture Design  ### 
In this chapter, we will look into an assessment system that can help you decide which design solution is better- for example, to choose one between 5 different versions of page objects. We will talk about the various criteria of the system and why they are essential. In the second part of the section, we will use the system to evaluate some of the design patterns we used previously and assign them ratings.  
### Chapter 9. Benchmarking for Assessing Automated Test Components Performance  ### 
The evaluation of core quality attributes is not enough to finally decide which implementation is better or not. The test execution time should be a key component too. In this chapter, we will examine a library that can help us measure the performance of our automated tests’ components.  
### Chapter 10. Test Data Preparation and Configuring Test Environments  ### 
One of the essential parts of each automated test is the test data which we use in it. It is important that the data is relevant and accessible. In the chapter, we will discuss how we can create such data through fixtures, APIs, DB layers or custom tools. Also, we will review how to set up the right way the environment in which the tests run.  
###  Appendix 1. Defining the Primary Problems that Test Automation Frameworks Solve  ### 
In the first appendix chapter, we will define the problems that the automation framework is trying to solve. To determine what is needed to deliver high-quality software, we need to understand what the issues are in the first place.  
### Appendix 2. Most Exhaustive CSS Selectors Cheat Sheet  ### 
A big part of the job of writing maintainable and stable web automation is related to finding the proper element's selectors. Here will look into a comprehensive list of CSS selectors.  
### Appendix 3. Most Exhaustive XPath Selectors Cheat Sheet  ### 
The other types of very useful locators are the XPath ones. Knowing them in detail can help you significantly improve the stability and the readability of your tests.  
"
Sensebloom/OSCeleton-examples,master,39,10,2010-12-17T16:58:50Z,509,7,A few processing sketches that read OSCeleton messages via OSC to demonstrate the message format.,,"OSCeleton-examples
=========

What is this?
-------------

Just a few simple demos we created  to demonstrate how
to use [OSCeleton](https://github.com/Sensebloom/OSCeleton).
We have 2 processing sketches and 1 animata skeleton animation.


How do I use it?
----------------

Go get [OSCeleton](https://github.com/Sensebloom/OSCeleton), follow
the instructions there and run the OSCeleton executable.

For the processing examples you need to get and install the
[OscP5 library](http://www.sojamo.de/libraries/oscP5/).

For the stickmanetic processing sketch you additionally need to get
and install
[pbox2d](http://code.google.com/p/pbox2d/).

Run the skecthes ;)

We also have an animata demo. Run OSCeleton with the options you see
in the .bat file, open the animata animation and have fun!


OSC Message format
------------------

Check the README on
[OSCeleton](https://github.com/Sensebloom/OSCeleton)
and check the following method on the processing sketches:
    void oscEvent(OscMessage msg)


Other
-----

### For death threats and other stuff, come join the fun in our [google group](http://groups.google.com/group/osceleton)!

Have fun!
"
MammatusTech/qbit-microservices-examples,master,46,11,2015-07-30T20:24:56Z,164,2,Qbit Microservices Examples,,"[-qbit docs-](https://github.com/advantageous/qbit/wiki)

![Mammatus Tech](http://www.mammatustech.com/_/rsrc/1242100869097/config/app/images/customLogo/customLogo.gif?revision=6)

## Tutorials and examples
Qbit Microservices Examples


1. [QBit Microservice Hello World tutorial](https://github.com/MammatusTech/qbit-microservices-examples/wiki/Getting-started-with-QBit-Microservice-Lib)
2. [QBit Microservice Reactive programming tutorial](https://github.com/MammatusTech/qbit-microservices-examples/wiki/Reactor-tutorial--%7C-reactively-handling-async-calls-with-QBit-Reactive-Microservices)

Go see the wiki. All of the tutorials are there. 


## Background information.

[Reactive Programming](http://rick-hightower.blogspot.com/2015/03/reactive-programming-service-discovery.html), [Java Microservices](http://rick-hightower.blogspot.com/2015/03/java-microservices-architecture.html), [Rick Hightower](http://www.linkedin.com/in/rickhigh)



[High-speed microservices consulting firm and authors of QBit with lots of experience with Vertx - Mammatus Technology](http://www.mammatustech.com/)

[Highly recommended consulting and training firm who specializes in microservices architecture and mobile development that are already very familiar with QBit and Vertx as well as iOS and Android - About Objects](http://www.aboutobjects.com/)

[Java Microservices Architecture](http://www.mammatustech.com/java-microservices-architecture)

[Microservice Service Discovery with Consul] (http://www.mammatustech.com/Microservice-Service-Discovery-with-Consul)

[Microservices Service Discovery Tutorial with Consul](http://www.mammatustech.com/consul-service-discovery-and-health-for-microservices-architecture-tutorial)



[Reactive Microservices]
(http://www.mammatustech.com/reactive-microservices)

[High Speed Microservices]
(http://www.mammatustech.com/high-speed-microservices)


[Java Microservices Consulting](http://www.mammatustech.com/java-microservices-consulting)

[Microservices Training](http://www.mammatustech.com/java-reactive-microservice-training)
"
gokhanyavas/Java-Programming-Examples-and-Notes,master,32,19,2017-04-09T19:17:31Z,210,0,Java Programalama Ornek ve Notlari,,"# Java-Programalama-Ornek-ve-Notlari

Java Programalama üzerine başlangıç seviyesinden orta seviyeye kadar birçok konuyla ilgili örnekler bulunmaktadır. Örneklerin içinde konuyla ilgili detaylı bilgiler yer almaktadır. 

gokhanyavas.com
"
nmcl/JavaSim,master,36,19,2012-05-09T20:30:57Z,1086,12,JavaSim simulation classes and examples,,"JavaSIM is an object-oriented simulation package based upon C++SIM and has been in use since 1997. It provides discrete event process-based simulation similar to SIMULA's simulation class and libraries. A complete list of the capabilities provided follows:

- The core of the system gives SIMULA-like simulation routines, random number generators, queueing algorithms and in C++SIM there are thread package interfaces, though for Java that's not necessary.
- Entity and set manipulation facilities similar to SIMSET.
- Classes allow ""non-causal"" events, such as interrupts, to be handled.
- Various routines for gathering statistics, such as histogram and variance classes.

The system also comes with complete examples and tests which illustrate many of the issues raised in using the simulation package.

Over the years C++SIM and JavaSim have been used by many commercial and academic organisations.

Prior to 2007 both C++SIM and JavaSim were freely available in source and binary from Newcastle University, under the University's own licence. However, in late 2007 Newcastle University decided that everything could be released into open source under LGPL. In 2015 the code was moved from Codehaus to github. All JIRAs from there were also recreated as github issues.

You can find details of the releases in the https://github.com/nmcl/JavaSim/releases section as well as binary downloads for some releases.

----

To build:

mvn compile

Run tests:

mvn test

Run tests and create installation:

mvn install

To run the examples check the README in that directory.
"
TechPrimers/stock-price-viewer-microservices-part1,master,137,223,2017-08-02T16:52:01Z,685,7,Spring Cloud services with 5 microservices - End to End Example,spring-boot spring-cloud spring-cloud-config spring-cloud-eureka spring-cloud-microservice spring-cloud-netflix spring-jpa spring-mvc,"# Stock Viewer Example - Part 1

In this Part, we covered the below microservices:s
- `db-service` - For interactive with MySQL DB
- `stock-service` - For pulling Stock Price from YahooFinance API
- `eureka-service` - Service Registry for registering all microservices

## Architecture Diagram:
![Architecture](Architecture.png)

## Dockerized Version
Dockernized version of this project is available at in [master-docker](https://github.com/TechPrimers/stock-price-viewer-microservices-part1/tree/master-docker) branch
"
draptik/angulardemorestful,master,243,211,2013-07-14T13:51:52Z,5693,0,"AngularJs intro: Focusing on the REST part with examples in java, nodejs and even dotnet ;-) This repo is from 2013 and is still being cloned...",,"angulardemorestful
==================

This is a sample project for some of my blog posts at [http://draptik.github.io](http://draptik.github.io).

## Git instructions for specific blog posts

- [http://draptik.github.io/blog/2013/07/13/angularjs-example-using-a-java-restful-web-service/](http://draptik.github.io/blog/2013/07/13/angularjs-example-using-a-java-restful-web-service/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step1
```

- [http://draptik.github.io/blog/2013/07/18/guice-in-java-web-application/](http://draptik.github.io/blog/2013/07/18/guice-in-java-web-application/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step2-guice
```

- [http://draptik.github.io/blog/2013/07/19/unit-testing-restful-services/](http://draptik.github.io/blog/2013/07/19/unit-testing-restful-services/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step3-backend-test
```

- [http://draptik.github.io/blog/2013/07/28/restful-crud-with-angularjs/](http://draptik.github.io/blog/2013/07/28/restful-crud-with-angularjs/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step4-angularjs-crud
```
- [http://draptik.github.io/blog/2013/08/19/angularjs-and-cors/](http://draptik.github.io/blog/2013/08/19/angularjs-and-cors/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step5-split-frontend-backend-cors
```

- [http://draptik.github.io/blog/2013/10/01/node-dot-js-backend-providing-rest/](http://draptik.github.io/blog/2013/10/01/node-dot-js-backend-providing-rest/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step6-nodejs-backend
```

- [http://draptik.github.io/blog/2014/07/18/dot-net-backend-providing-rest/](http://draptik.github.io/blog/2014/07/18/dot-net-backend-providing-rest/)

``` sh
git clone git@github.com:draptik/angulardemorestful.git
cd angulardemorestful
git checkout -f step7-aspnet-webapi-backend
```
"
allure-examples/testng-java-maven,main,118,235,2013-11-26T15:10:53Z,1458,0,"Example of Allure Report usage with TestNG, Java and Maven",allure allure-report example java maven testng,"# Allure Example

> Example of Allure Report usage with TestNG, Java and Maven

<!--<img src=""https://allurereport.org/public/img/allure-report.svg"" alt=""Allure Report logo"" style=""float: right"" />-->

- Learn more about Allure Report at https://allurereport.org
- 📚 [Documentation](https://allurereport.org/docs/) – discover official documentation for Allure Report
- ❓ [Questions and Support](https://github.com/orgs/allure-framework/discussions/categories/questions-support) – get help from the team and community
- 📢 [Official annoucements](https://github.com/orgs/allure-framework/discussions/categories/announcements) – be in touch with the latest updates
- 💬 [General Discussion ](https://github.com/orgs/allure-framework/discussions/categories/general-discussion) – engage in casual conversations, share insights and ideas with the community

---

The generated report is available here: [https://allure-examples.github.io/testng-java-maven](https://allure-examples.github.io/testng-java-maven/)
"
bentolor/java9to13,master,40,46,2019-07-01T15:16:42Z,197950,0,Power Catchup – Java 9 to 13: HTML5 Presentation and Code Examples,,
g0t4/jgsu-spring-petclinic,main,25,2339,2020-08-10T01:34:41Z,7430,15,WIP update of spring-petclinic example used in my Jenkins Getting Started course on Pluralsight,,
alexjlockwood/adp-path-morph-play-to-pause,master,348,40,2015-03-22T02:49:29Z,216,8,Play-to-pause path morphing example,,"# material-pause-play-animation

View the animation on [YouTube](http://youtu.be/46zeFyiMBS4).

![Material Pause-to-Play Animation](http://i.imgur.com/Y7fOyWw.gif)
"
habuma/spring-boot-in-action-samples,master,128,81,2015-12-09T20:11:12Z,385,2,Example code from Spring Boot in Action,,"# Spring Boot in Action Sample Code

This repository contains example code from Spring Boot in Action. In as much as is possible when writing compilable/verifiable code to be injected into a not-easily-verifiable work of prose, the code should be aligned with what was printed. There may be slight variations, however.

This code will be tagged with FIRST_PRINTING to indicate that the code aligns with the first printing of the first edition of the book. This allows for further evolution of the code after publication while still maintaining a reference back to the code as it aligns with the printed book.

Please feel free to offer suggestions in the form of pull requests if you see opportunity for improvement.

And I'd certainly appreciate it if you'd please purchase a copy of _Spring Boot in Action_ ([Amazon](http://www.amazon.com/Spring-Boot-Action-Craig-Walls/dp/1617292540) | [Manning](https://www.manning.com/books/spring-boot-in-action) | [Barnes & Noble](http://www.barnesandnoble.com/w/spring-boot-in-action-craig-walls/1121907935)).
"
frogermcs/GithubClient,master,1204,221,2015-05-27T16:43:03Z,190,17,Example of Github API client implemented on top of Dagger 2 DI framework. ,,"# GithubClient
Example of Github API client implemented on top of Dagger 2 DI framework. 

This code was created as an example for Dependency Injection with Dagger 2 series on my dev-blog:

- [Introdution to Dependency Injection](http://frogermcs.github.io/dependency-injection-with-dagger-2-introdution-to-di/)
- [Dagger 2 API](http://frogermcs.github.io/dependency-injection-with-dagger-2-the-api/)
- [Dagger 2 - custom scopes](http://frogermcs.github.io/dependency-injection-with-dagger-2-custom-scopes/)
- [Dagger 2 - graph creation performance](http://frogermcs.github.io/dagger-graph-creation-performance/)
- [Dependency injection with Dagger 2 - Producers](http://frogermcs.github.io/dependency-injection-with-dagger-2-producers/)
- [Inject everything - ViewHolder and Dagger 2 (with Multibinding and AutoFactory example)](http://frogermcs.github.io/inject-everything-viewholder-and-dagger-2-example/)
 
This code was originally prepared for my presentation at Google I/O Extended 2015 in Tech Space Cracow. http://www.meetup.com/GDG-Krakow/events/221822600/
"
asaharland/beam-pipeline-examples,master,29,13,2018-08-30T18:57:23Z,62362,0,Apache Beam examples for running on Google Cloud Dataflow.,apache-beam aws-s3 google-cloud google-cloud-dataflow google-cloud-platform google-cloud-pubsub google-cloud-storage,"# Apache Beam Examples

## About
This repository contains Apache Beam code examples for running on Google Cloud Dataflow. The following examples are contained in this repository:
* Streaming pipeline
    * Reading CSVs from a Cloud Storage bucket and streaming the data into BigQuery
* Batch pipeline
    * Reading from AWS S3 and writing to Google BigQuery
    * Reading from Google Cloud Storage and writing to Google BigQuery

## Streaming pipeline
The goal of this example is to overcome the limitations of micro-batching with BigQuery.
This exapmle covers the following steps:
* Reads a number of CSV files from Cloud Storage
* Covers the CSV files into a Java Object
* Writes the rows into BigQuery

For more details on the limitations of micro-batching within BigQuery, check out my blog.

### Running the example

#### Setup & Configuration
* Ensure that you have billing enabled for your project
* Enable the following Google Cloud Platform APIs:
    * Cloud Dataflow, Compute Engine, Stackdriver Logging, Google Cloud Storage, Google Cloud Storage JSON, BigQuery, Google Cloud Pub/Sub, Google Cloud Datastore, and Google Cloud Resource Manager APIs.
* Create a Google Cloud Storage bucket to stage your Cloud Dataflow code. Make sure you note the bucket name as you will need it later.
* Create a BigQuery dataset called finance. Keep note of the fully qualified dataset name which is in the format projectName:finance
* Upload the sample_1.csv and sample_2.csv to your Google Cloud Storage bucket
* Validate that the data has been loaded into BigQuery

#### Reading from Cloud Storage and writing to BigQuery
```
mvn compile exec:java \
-Dexec.mainClass=com.harland.example.batch.BigQueryImportPipeline \
-Dexec.args=""--project=<GCP PROJECT ID> \
--bucketUrl=gs://<GCS BUCKET NAME> \
--bqTableName=<BIGQUERY TABLE e.g. project:finance.transactions> \
--runner=DataflowRunner \
--region=europe-west1 \
--stagingLocation=gs://<DATAFLOW BUCKET>/stage/ \
--tempLocation=gs://<DATAFLOW BUCKET>/temp/""
```

## Batch Pipeline
The goal of the example code is to calculate the total amount transferred for each user_id in the transfers_july.csv.
This is purely fictitious example that covers the following steps: 
* Reads a CSV file from AWS S3 
* Converts the CSV file into a Java Object
* Creates key, value pairs where user_id is the key and amount is the value
* Sums the amount for each user_id
* Writes the result to BigQuery

### Running the example

#### Setup & Configuration
* Ensure that you have billing enabled for your project
* Enable the following Google Cloud Platform APIs:
    * Cloud Dataflow, Compute Engine, Stackdriver Logging, Google Cloud Storage, Google Cloud Storage JSON, BigQuery, Google Cloud Pub/Sub, Google Cloud Datastore, and Google Cloud Resource Manager APIs.
* Create a Google Cloud Storage bucket to stage your Cloud Dataflow code. Make sure you note the bucket name as you will need it later.
* Create a BigQuery dataset called finance. Keep note of the fully qualified dataset name which is in the format projectName:finance
* Upload the transfers_july.csv to your AWS S3/Google Cloud Storage bucket

#### Reading from AWS S3 and writing to BigQuery
```
mvn compile exec:java \
-Dexec.mainClass=com.harland.example.batch.BigQueryImportPipeline \
-Dexec.args=""--project=<GCP PROJECT ID> \
--bucketUrl=s3://<S3 BUCKET NAME> \
--awsRegion=eu-west-1 \
--bqTableName=<BIGQUERY TABLE e.g. project:finance.transactions> \
--awsAccessKey=<YOUR ACCESS KEY> \
--awsSecretKey=<YOUR SECRET KEY> \
--runner=DataflowRunner \
--region=europe-west1 \
--stagingLocation=gs://<DATAFLOW BUCKET>/stage/ \
--tempLocation=gs://<DATAFLOW BUCKET>/temp/""
```

#### Reading from Google Cloud Storage and writing to BigQuery
```
mvn compile exec:java \
-Dexec.mainClass=com.harland.example.batch.BigQueryImportPipeline \
-Dexec.args=""--project=<GCP PROJECT ID> \
--bucketUrl=gs://<GCS BUCKET NAME> \
--bqTableName=<BIGQUERY TABLE e.g. project:finance.transactions> \
--runner=DataflowRunner \
--region=europe-west1 \
--stagingLocation=gs://<DATAFLOW BUCKET>/stage/ \
--tempLocation=gs://<DATAFLOW BUCKET>/temp/""
```

## Built with
* Java 8
* Maven 3
* Apache Beam 2.5.0
"
CodelyTV/java-oop-examples,master,29,13,2018-06-08T16:20:27Z,472,0,Object-Oriented Programming recap with Java examples,java java8 oop oop-examples oop-principles,"# Object-Oriented Programming concepts recap with Java examples

## Concept

* Software development paradigm
* We should represent our system concepts using classes
* Classes deals with common behaviour to all of its different instances (objects):

![Classes vs objects](resources/blueprint-vs-house.png)
* Objects have their own memory
* Object communicate between them sending and receiving messages

## Visibility and inheritance

### `public`, `protected`, and `private` visibility keywords
* When do you use each one?
    * Guilt presumption
    * Simplify our classes API (exposed methods) => Easier to understand, easier to be SRP compliant, avoid having to maintain public methods because others are coupled to them
* Question:
    * Which would be the output of the `Child#visibilityTest` method?
    * Solution: `ChildShould`. Possible answers:
```
        ""Child#privateMethod Child#protectedMethod Child#publicMethod"" // a
        ""Parent#privateMethod Child#protectedMethod Child#publicMethod"" // b
        ""Parent#privateMethod Parent#protectedMethod Child#publicMethod"" // c
        ""Parent#privateMethod Child#protectedMethod Parent#publicMethod"" // d
        ""Parent#privateMethod Parent#protectedMethod Parent#publicMethod"" // e
        // It doesn't compile // f
```

### `static` keyword
* What is it for?
* Question:
    * Which would be the output for the following `getTotal` calls?
    * Solution: `CounterShould`. Possible answers:
```java
Counter counterA = new Counter();
Counter counterB = new Counter();
Counter counterC = new Counter();

counterA.increaseTotal();
counterA.increaseTotal();
counterA.increaseTotal();

counterB.increaseTotal();
counterB.increaseTotal();

counterC.increaseTotal();

// a:
counterA.getTotal(); // 0
counterB.getTotal(); // 0
counterC.getTotal(): // 0

// b:
counterA.getTotal(); // 6
counterB.getTotal(); // 6
counterC.getTotal(): // 6

// c:
counterA.getTotal(); // 3
counterB.getTotal(); // 5
counterC.getTotal(): // 6

// c:
counterA.getTotal(); // 6
counterB.getTotal(); // 3
counterC.getTotal(): // 1
```
   
### `final` keyword
* What does it do in attributes?
    * Does not allow to redefine them
* What does it do in methods?
    * Does not allow to override them
* What does it do in classes?
    * Does not allow to inherit from them
* When we should use it?
    * Same reasoning as with the visibility keywords: Guilt presumption.
    * Why: Make the next developer think twice before extending from it.
    * Key concept: [Composition over Inheritance](https://medium.com/humans-create-software/composition-over-inheritance-cb6f88070205).

### `abstract` classes vs `interface`s
* What's the difference?
    * Interfaces:
        * Doesn't allow to implement method bodies. It only allow us to declare method contracts/headers. <- True until Java8
        * They're great because as they have fewer capabilities, they are easier to read and understand without letting us mess up adding behaviour.
        * A class can implement different interfaces.
    * Abstract classes:
        * Allow to implement method bodies.
        * A class can only extend from one abstract class.    
* When we should use `abstract` classes?
    * Opinion: Almost never. Just exceptional cases. We should have a very big reason to do so 🙂
* When we should use `interfaces`?
    * Opinion: In order to decouple from infrastructure* stuff.
    * *Infrastructure: behaviour related to a third party library or component (Postgres DB, AWS SDK, Slack SDK, MailChimp API…)
    * Usage example:
```java

interface ProductRecommender
{
    Recommendations findFor(ProductId productId);
}

final class BlueknowProductRecommender implements ProductRecommender
{
    @Override
    public Recommendations findFor(ProductId productId) {
        // Call to the Blueknow service API
        // Parse the JSON response into a `Recommendations` class instance
        return recommendations;
    }
}
```

Example:
* Context:
    * We have a Builder system in order to build our applications
    * We want to notify the development team once the build is ready to be deployed
    * We're testing different messaging apps such as Slack and HipChat
    * In order to do not miss our notifications, we want to be notified through the `#dev-notifications` Slack channel, and through the `dev-notifications@codely.tv` mailing list
* Questions:
    * How would you model these different classes and their interactions?
"
ralscha/spring4ws-demos,master,32,19,2013-09-16T16:26:15Z,982,0,WebSocket examples with Spring 4,java spring spring-boot spring-framework spring-mvc websocket,"Sample applications with the Spring Framework 5 Websocket/SockJS/STOMP support. 
"
mythz/java-linq-examples,master,87,8,2015-04-30T16:07:58Z,262,0,C#'s 101 LINQ Samples translated to Java,,"101 C# LINQ Samples in Java
===========================

Port of the [C# 101 LINQ Samples](http://code.msdn.microsoft.com/101-LINQ-Samples-3fb9811b) rewritten into Andriod-compatible [Java 1.7](http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html).

Compare Java to other LINQ examples written in:

 - [Kotlin](https://github.com/mythz/kotlin-linq-examples)
 - [Groovy](https://gitlab.com/svermeulen/groovy-linq-samples)
 - [Swift](https://github.com/mythz/swift-linq-examples)
 - [Clojure](https://github.com/mythz/clojure-linq-examples)
 - [Dart](https://github.com/mythz/dart-linq-examples)
 - [Elixir](https://github.com/omnibs/elixir-linq-examples)
 - [Python](https://github.com/rogerwcpt/python-linq-samples)
 - [#Script code](https://sharpscript.net/linq/restriction-operators?lang=code)
 - [#Script lisp](https://sharpscript.net/linq/restriction-operators?lang=lisp)

## [Call .NET Web Services from Java](http://docs.servicestack.net/java-add-servicestack-reference)

If you're looking for an effortles typed API for consuming .NET Web Services in pure Java or Android Java Apps checkout ServiceStack's [Java Add ServiceStack Reference](https://github.com/ServiceStack/ServiceStack/wiki/Java-Add-ServiceStack-Reference).

### Running the examples

Each of the LINQ Examples can be run from the included Android App with its results logged to the screen:

![](https://raw.githubusercontent.com/ServiceStack/Assets/master/img/wikis/java/linq-examples-screenshot.png)

Run the included [Android Studio project](https://github.com/mythz/java-linq-examples/tree/master/src) to execute all the examples. You can also choose to only run specific examples by commenting out any of the sections you're not interested in [MainActivity.java](https://github.com/mythz/java-linq-examples/blob/432dfeb0ea3c95ecdd8e007886a77d1508d6f312/src/app/src/main/java/servicestack/net/javalinqexamples/MainActivity.java#L54-L67).

A copy of the LINQ examples output is also available in [linq-log.txt](https://raw.githubusercontent.com/mythz/java-linq-examples/master/linq-log.txt).


### Contents

The samples below mirrors the C# LINQ samples layout with the names of the top-level Java methods matching their corresponding C# examples.

#### [LINQ - Restriction Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Restrictions.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Restriction-Operators-b15d29ca)
#### [LINQ - Projection Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Projections.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-to-DataSets-09787825)
#### [LINQ - Partitioning Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Partitioning.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Partitioning-Operators-c68aaccc)
#### [LINQ - Ordering Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Ordering.java) / [MSDN C#](http://code.msdn.microsoft.com/SQL-Ordering-Operators-050af19e)
#### [LINQ - Grouping Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Grouping.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-to-DataSets-Grouping-c62703ea)
#### [LINQ - Set Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/SetOperators.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Set-Operators-374f34fe)
#### [LINQ - Conversion Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Conversion.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Conversion-Operators-e4e59714)
#### [LINQ - Element Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/ElementOperators.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Element-Operators-0f3f12ce)
#### [LINQ - Generation Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/GenerationOperators.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Generation-Operators-8a3fbff7)
#### [LINQ - Quantifiers](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/Quantifiers.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Quantifiers-f00e7e3e)
#### [LINQ - Aggregate Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/AggregateOperators.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Aggregate-Operators-c51b3869)
#### [LINQ - Miscellaneous Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/MiscOperators.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Miscellaneous-6b72bb2a)
#### [LINQ - Query Execution](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/QueryExecution.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Query-Execution-ce0d3b95)
#### [LINQ - Join Operators](https://github.com/mythz/java-linq-examples/blob/master/src/app/src/main/java/servicestack/net/javalinqexamples/JoinOperators.java) / [MSDN C#](http://code.msdn.microsoft.com/LINQ-Join-Operators-dabef4e9)

## Java Functional Utils

Unlike many modern languages supporting a functional-style, Java doesn't have any LINQ-like utils built-in by default. It's also not very extensible which combined with the lack of proper Type Inference, Type Erasure and Closures in Java 1.7 makes the equivalent Java source code particularly more verbose.

To improve the development experience in Java, we've added common functional utils to simplify programming in a functional style inside [ServiceStack's Java and Android Client Library](https://github.com/ServiceStack/ServiceStack/wiki/Java-Add-ServiceStack-Reference): **net.servicestack:android**. 

### Install

To include it in your Android Studio project, add it to your **build.gradle** dependency, e.g:

    dependencies {
        compile fileTree(dir: 'libs', include: ['*.jar'])
        compile 'net.servicestack:android:1.0.24'
    }

Pure Java projects should add the **net.servicestack:client** dependency instead:

    dependencies {
        compile 'net.servicestack:client:1.0.24'
    }

Alternatively this library is also automatically added when Adding a Typed Remote Service Reference with ServiceStack IDE Plugins for [Intellij IDEA](https://github.com/ServiceStack/ServiceStack/wiki/Java-Add-ServiceStack-Reference#servicestack-idea-android-studio-plugin
) and [Eclipse Maven projects](https://github.com/ServiceStack/ServiceStack.Java/tree/master/src/ServiceStackEclipse#eclipse-integration-with-servicestack).

### Usage

Once the dependency is added you can add a static import to access [all the functional utils](https://github.com/ServiceStack/ServiceStack.Java/blob/master/src/AndroidClient/client/src/main/java/net/servicestack/func/Func.java) used in the LINQ examples below:

```java
import static net.servicestack.func.Func.*;
```

##  Side-by-side - C# LINQ vs Java

For a side-by-side comparison, the original **C#** source code is displayed above the equivalent **Java** translation. 

  - The **Output** shows the logging output of running the **Java** Android App. 
  - Outputs ending with `...` illustrates only a partial response is displayed. 
  - The C# ObjectDumper util used is downloadable from MSDN - [ObjectDumper.zip](http://code.msdn.microsoft.com/Visual-Studio-2008-C-d295cdba/file/46086/1/ObjectDumper.zip)

The Java LINQ Examples are limited to Java 1.7 so they're available on Android. 


LINQ - Restriction Operators
----------------------------

### linq1: Where - Simple 1

```csharp
//c#
public void Linq1() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var lowNums = 
        from n in numbers 
        where n < 5 
        select n; 
  
    Console.WriteLine(""Numbers < 5:""); 
    foreach (var x in lowNums) 
    { 
        Console.WriteLine(x); 
    } 
}  
```
```java
//java
public void linq1(){
    int[] numbers = new int[]{ 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> lowNums = filter(toList(numbers), new Predicate<Integer>() {
        @Override
        public boolean apply(Integer n) {
            return n < 5;
        }
    });

    Log.d(""Numbers < 5:"");
    for (int n : lowNums){
        Log.d(n);
    }
}
```
#### Output

    Numbers < 5:
    4
    1
    3
    2
    0

### linq2: Where - Simple 2
```csharp
//c#
public void Linq2() 
{ 
    List<Product> products = GetProductList(); 
  
    var soldOutProducts = 
        from p in products 
        where p.UnitsInStock == 0 
        select p; 
  
    Console.WriteLine(""Sold out products:""); 
    foreach (var product in soldOutProducts) 
    { 
        Console.WriteLine(""{0} is sold out!"", product.ProductName); 
    } 
} 
```
```java
//java
public void linq2(){
    List<Product> products = getProductList();

    List<Product> soldOutProducts = filter(products, new Predicate<Product>() {
        @Override
        public boolean apply(Product p) {
            return p.unitsInStock == 0;
        }
    });

    Log.d(""Sold out products:"");
    for (Product p : soldOutProducts) {
        Log.d(p.productName + "" is sold out!"");
    }
}
```
#### Output

    Sold out products:
    Chef Anton's Gumbo Mix is sold out!
    Alice Mutton is sold out!
    Thüringer Rostbratwurst is sold out!
    Gorgonzola Telino is sold out!
    Perth Pasties is sold out!

### linq3: Where - Simple 3
```csharp
//c#
public void Linq3() 
{ 
    List<Product> products = GetProductList(); 
  
    var expensiveInStockProducts = 
        from p in products 
        where p.UnitsInStock > 0 && p.UnitPrice > 3.00M 
        select p; 
  
    Console.WriteLine(""In-stock products that cost more than 3.00:""); 
    foreach (var product in expensiveInStockProducts) 
    { 
        Console.WriteLine(""{0} is in stock and costs more than 3.00."", product.ProductName); 
    } 
} 
```
```java
//java
public void linq3(){
    List<Product> products = getProductList();

    ArrayList<Product> expensiveInStockProducts = filter(products, new Predicate<Product>() {
        @Override
        public boolean apply(Product p) {
            return p.unitsInStock > 0 && p.unitPrice > 3.00;
        }
    });

    Log.d(""In-stock products that cost more than 3.00:"");
    for (Product p : expensiveInStockProducts) {
        Log.d(p.productName + "" is in stock and costs more than 3.00."");
    }
}
```
#### Output

    In-stock products that cost more than 3.00:
    Chai is in stock and costs more than 3.00.
    Chang is in stock and costs more than 3.00.
    Aniseed Syrup is in stock and costs more than 3.00.
    ...

### linq4: Where - Drilldown
```csharp
//c#
public void Linq4() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var waCustomers = 
        from c in customers 
        where c.Region == ""WA"" 
        select c; 
  
    Console.WriteLine(""Customers from Washington and their orders:""); 
    foreach (var customer in waCustomers) 
    { 
        Console.WriteLine(""Customer {0}: {1}"", customer.CustomerID, customer.CompanyName); 
        foreach (var order in customer.Orders) 
        { 
            Console.WriteLine(""  Order {0}: {1}"", order.OrderID, order.OrderDate); 
        } 
    } 
} 
```
```java
//java
public void linq4(){
    List<Customer> customers = getCustomerList();

    List<Customer> waCustomers = filter(customers, new Predicate<Customer>() {
        @Override
        public boolean apply(Customer c) {
            return ""WA"".equals(c.region);
        }
    });

    Log.d(""Customers from Washington and their orders:"");
    for (Customer c : waCustomers){
        Log.d(""Customer "" + c.customerId + "" "" + c.companyName);
        for (Order o : c.orders){
            Log.d(""  Order "" + o.orderId + "": "" + dateFmt(o.orderDate));
        }
    }
}
```
#### Output

    Customers from Washington and their orders:
    Customer LAZYK Lazy K Kountry Store
      Order 10482: 1997/03/21
      Order 10545: 1997/05/22
    Customer TRAIH Trail's Head Gourmet Provisioners
      Order 10574: 1997/06/19
      Order 10577: 1997/06/23
      Order 10822: 1998/01/08
      ...

### linq5: Where - Indexed
```csharp
//c#
public void Linq5() 
{ 
    string[] digits = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    var shortDigits = digits.Where((digit, index) => digit.Length < index); 
  
    Console.WriteLine(""Short digits:""); 
    foreach (var d in shortDigits) 
    { 
        Console.WriteLine(""The word {0} is shorter than its value."", d); 
    } 
}
```
```java
//java
public void linq5(){
    String[] digits = new String[]{ ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    List<String> shortDigits = filteri(digits, new PredicateIndex<String>() {
        @Override
        public boolean apply(String s, int i) {
            return s.length() < i;
        }
    });

    Log.d(""Short digits:"");
    for (String d : shortDigits){
        Log.d(""The word "" + d + "" is shorter than its value."");
    }
}
```
#### Output

    Short digits:
    The word five is shorter than its value.
    The word six is shorter than its value.
    The word seven is shorter than its value.
    The word eight is shorter than its value.
    The word nine is shorter than its value.

LINQ - Projection Operators
---------------------------

### linq6: Select - Simple 1
```csharp
//c#
public void Linq6() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var numsPlusOne = 
        from n in numbers 
        select n + 1; 
  
    Console.WriteLine(""Numbers + 1:""); 
    foreach (var i in numsPlusOne) 
    { 
        Console.WriteLine(i); 
    } 
}
```
```java
//java
public void linq06(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> numsPlusOne = map(toList(numbers), new Function<Integer, Integer>() {
        @Override
        public Integer apply(Integer i) {
            return i + 1;
        }
    });

    Log.d(""Numbers + 1:"");
    for (Integer n : numsPlusOne){
        Log.d(n);
    }
}
```
#### Output

    Numbers + 1:
    6
    5
    2
    4
    10
    9
    7
    8
    3
    1

### linq7: Select - Simple 2
```csharp
//c#
public void Linq7() 
{ 
    List<Product> products = GetProductList(); 
  
    var productNames = 
        from p in products 
        select p.ProductName; 
  
    Console.WriteLine(""Product Names:""); 
    foreach (var productName in productNames) 
    { 
        Console.WriteLine(productName); 
    } 
}
```
```java
//java
public void linq07(){
    List<Product> products = getProductList();

    List<String> productNames = map(products, new Function<Product, String>() {
        @Override
        public String apply(Product p) {
            return p.productName;
        }
    });

    Log.d(""Product Names:"");
    for (String productName : productNames){
        Log.d(productName);
    }
}
```
#### Output

    Product Names:
    Chai
    Chang
    Aniseed Syrup
    Chef Anton's Cajun Seasoning
    Chef Anton's Gumbo Mix
    ...

### linq8: Select - Transformation
```csharp
//c#
public void Linq8() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
    string[] strings = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    var textNums = 
        from n in numbers 
        select strings[n]; 
  
    Console.WriteLine(""Number strings:""); 
    foreach (var s in textNums) 
    { 
        Console.WriteLine(s); 
    } 
}
```
```java
//java
public void linq08(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };
    final String[] strings = new String[] { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    List<String> textNums = map(toList(numbers), new Function<Integer, String>() {
        @Override
        public String apply(Integer n) {
            return strings[n];
        }
    });

    Log.d(""Number strings:"");
    for (String s : textNums){
        Log.d(s);
    }
}
```
#### Output

    Number strings:
    five
    four
    one
    three
    nine
    eight
    six
    seven
    two
    zero

### linq9: Select - Anonymous Types 1
```csharp
//c#
public void Linq9() 
{ 
    string[] words = { ""aPPLE"", ""BlUeBeRrY"", ""cHeRry"" }; 
  
    var upperLowerWords = 
        from w in words 
        select new { Upper = w.ToUpper(), Lower = w.ToLower() }; 
  
    foreach (var ul in upperLowerWords) 
    { 
        Console.WriteLine(""Uppercase: {0}, Lowercase: {1}"", ul.Upper, ul.Lower); 
    } 
}
```
```java
//java
public void linq09(){
    String[] words = new String[]{ ""aPPLE"", ""BlUeBeRrY"", ""cHeRry"" };

    List<Tuple<String,String>> upperLowerWords = map(words, new Function<String, Tuple<String,String>>(){
        @Override
        public Tuple<String,String> apply(String w) {
            return new Tuple<>(w.toUpperCase(), w.toLowerCase());
        }
    });

    for (Tuple<String,String> ul : upperLowerWords){
        Log.d(""Uppercase: "" + ul.A + "", Lowercase: "" + ul.B);
    }
}
```
#### Output

    Uppercase: APPLE, Lowercase: apple
    Uppercase: BLUEBERRY, Lowercase: blueberry
    Uppercase: CHERRY, Lowercase: cherry

### linq10: Select - Anonymous Types 2
```csharp
//c#
public void Linq10() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
    string[] strings = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    var digitOddEvens = 
        from n in numbers 
        select new { Digit = strings[n], Even = (n % 2 == 0) }; 
  
    foreach (var d in digitOddEvens) 
    { 
        Console.WriteLine(""The digit {0} is {1}."", d.Digit, d.Even ? ""even"" : ""odd""); 
    } 
}
```
```java
//java
public void linq10(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };
    final String[] strings = new String[] { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    List<Tuple<String, Boolean>> digitOddEvens = map(toList(numbers), new Function<Integer, Tuple<String, Boolean>>() {
        @Override
        public Tuple<String, Boolean> apply(Integer n) {
            return new Tuple<>(strings[n], n % 2 == 0);
        }
    });

    for (Tuple<String,Boolean> d : digitOddEvens){
        Log.d(""The digit "" + d.A + "" is "" + (d.B ? ""even"" : ""odd"") + ""."");
    }
}
```
#### Output

    The digit five is odd.
    The digit four is even.
    The digit one is odd.
    The digit three is odd.
    The digit nine is odd.
    The digit eight is even.
    The digit six is even.
    The digit seven is odd.
    The digit two is even.
    The digit zero is even.

### linq11: Select - Anonymous Types 3
```csharp
//c#
public void Linq11() 
{ 
    List<Product> products = GetProductList(); 
  
    var productInfos = 
        from p in products 
        select new { p.ProductName, p.Category, Price = p.UnitPrice }; 
  
    Console.WriteLine(""Product Info:""); 
    foreach (var productInfo in productInfos) 
    { 
        Console.WriteLine(""{0} is in the category {1} and costs {2} per unit."", productInfo.ProductName, productInfo.Category, productInfo.Price); 
    } 
}
```
```java
//java
public void linq11(){
    List<Product> products = getProductList();

    List<Tuple3<String,String,Double>> productInfos = map(products, new Function<Product, Tuple3<String, String, Double>>() {
        @Override
        public Tuple3<String, String, Double> apply(Product p) {
            return new Tuple3<>(p.productName, p.category, p.unitPrice);
        }
    });

    Log.d(""Product Info:"");
    for (Tuple3<String,String,Double> productInfo : productInfos){
        Log.d(productInfo.A + "" is in the category "" + productInfo.B + "" and costs "" + productInfo.C + "" per unit."");
    }
}
```
#### Output

    Product Info:
    Chai is in the category Beverages and costs 18.0 per unit.
    Chang is in the category Beverages and costs 19.0 per unit.
    Aniseed Syrup is in the category Condiments and costs 10.0 per unit.
    ...

### linq12: Select - Indexed
```csharp
//c#
public void Linq12() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var numsInPlace = numbers.Select((num, index) => new { Num = num, InPlace = (num == index) }); 
  
    Console.WriteLine(""Number: In-place?""); 
    foreach (var n in numsInPlace) 
    { 
        Console.WriteLine(""{0}: {1}"", n.Num, n.InPlace); 
    } 
}
```
```java
//java
public void linq12(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Tuple<Integer,Boolean>> numsInPlace = mapi(toList(numbers), new FunctionIndex<Integer, Tuple<Integer, Boolean>>() {
        @Override
        public Tuple<Integer, Boolean> apply(Integer num, int index) {
            return new Tuple<>(num, num == index);
        }
    });

    Log.d(""Number: In-place?"");
    for (Tuple<Integer,Boolean> n : numsInPlace){
        Log.d(n.A + "": "" + n.B);
    }
}
```
#### Output

    Number: In-place?
    5: false
    4: false
    1: false
    3: true
    9: false
    8: false
    6: true
    7: true
    2: false
    0: false

### linq13: Select - Filtered
```csharp
//c#
public void Linq13() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
    string[] digits = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    var lowNums = 
        from n in numbers 
        where n < 5 
        select digits[n]; 
  
    Console.WriteLine(""Numbers < 5:""); 
    foreach (var num in lowNums) 
    { 
        Console.WriteLine(num); 
    } 
}
```
```java
//java
public void linq13(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };
    final String[] digits = new String[] { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    List<String> lowNums = map(
        filter(toList(numbers), new Predicate<Integer>() {
            @Override
            public boolean apply(Integer n) {
                return n < 5;
            }
        }),
        new Function<Integer, String>() {
            @Override
            public String apply(Integer n){
                return digits[n];
            }
        });

    Log.d(""Numbers < 5:"");
    for (String num : lowNums){
        Log.d(num);
    }
}
```
#### Output

    Numbers < 5:
    four
    one
    three
    two
    zero

### linq14: SelectMany - Compound from 1
```csharp
//c#
public void Linq14() 
{ 
    int[] numbersA = { 0, 2, 4, 5, 6, 8, 9 }; 
    int[] numbersB = { 1, 3, 5, 7, 8 }; 
  
    var pairs = 
        from a in numbersA 
        from b in numbersB 
        where a < b 
        select new { a, b }; 
  
    Console.WriteLine(""Pairs where a < b:""); 
    foreach (var pair in pairs) 
    { 
        Console.WriteLine(""{0} is less than {1}"", pair.a, pair.b); 
    } 
}
```
```java
//java
public void linq14(){
    int[] numbersA = new int[] { 0, 2, 4, 5, 6, 8, 9 };
    final int[] numbersB = new int[] { 1, 3, 5, 7, 8 };

    List<Tuple<Integer,Integer>> pairs = expand(
        map(toList(numbersA), new Function<Integer,List<Tuple<Integer,Integer>>>() {
            @Override
            public List<Tuple<Integer,Integer>> apply(final Integer a) {
                return map(filter(toList(numbersB), new Predicate<Integer>() {
                    @Override
                    public boolean apply(Integer b) {
                        return a < b;
                    }
                }), new Function<Integer, Tuple<Integer,Integer>>() {
                    @Override
                    public Tuple<Integer, Integer> apply(Integer b) {
                        return new Tuple<>(a,b);
                    }
                });
            }
        })
    );

    Log.d(""Pairs where a < b:"");
    for (Tuple<Integer,Integer> pair : pairs){
        Log.d(pair.A + "" is less than "" + pair.B);
    }
}
```
#### Output

    Pairs where a < b:
    0 is less than 1
    0 is less than 3
    0 is less than 5
    0 is less than 7
    0 is less than 8
    2 is less than 3
    2 is less than 5
    2 is less than 7
    2 is less than 8
    4 is less than 5
    4 is less than 7
    4 is less than 8
    5 is less than 7
    5 is less than 8
    6 is less than 7
    6 is less than 8

### linq15: SelectMany - Compound from 2
```csharp
//c#
public void Linq15() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var orders = 
        from c in customers 
        from o in c.Orders 
        where o.Total < 500.00M 
        select new { c.CustomerID, o.OrderID, o.Total }; 
  
    ObjectDumper.Write(orders); 
}
```
```java
//java
public void linq15(){
    List<Customer> customers = getCustomerList();

    List<Tuple3<String, Integer, Double>> orders = expand(
        map(customers, new Function<Customer, List<Tuple3<String, Integer, Double>>>() {
            @Override
            public List<Tuple3<String, Integer, Double>> apply(final Customer c) {
                return map(filter(c.orders, new Predicate<Order>() {
                    @Override
                    public boolean apply(Order o) {
                        return o.total < 500;
                    }
                }), new Function<Order, Tuple3<String, Integer, Double>>() {
                    @Override
                    public Tuple3<String, Integer, Double> apply(Order o) {
                        return new Tuple3<>(c.customerId, o.orderId, o.total);
                    }
                });
            }
        })
    );

    for (Tuple3<?,?,?> o : orders){
        Log.d(o);
    }
}
```
#### Output

    (ALFKI, 10702, 330.0)
    (ALFKI, 10952, 471.2)
    (ANATR, 10308, 88.8)
    (ANATR, 10625, 479.75)
    ...

### linq16: SelectMany - Compound from 3
```csharp
//c#
public void Linq16() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var orders = 
        from c in customers 
        from o in c.Orders 
        where o.OrderDate >= new DateTime(1998, 1, 1) 
        select new { c.CustomerID, o.OrderID, o.OrderDate }; 
  
    ObjectDumper.Write(orders); 
}
```
```java
//java
public void linq16(){
    List<Customer> customers = getCustomerList();

    final Date date = new Date(98, 0, 1); //= 1998-01-01

    List<Tuple3<String, Integer, Date>> orders = expand(
        map(customers, new Function<Customer, List<Tuple3<String, Integer, Date>>>() {
            @Override
            public List<Tuple3<String, Integer, Date>> apply(final Customer c) {
                return map(filter(c.orders, new Predicate<Order>() {
                    @Override
                    public boolean apply(Order o) {
                        return o.orderDate.after(date);
                    }
                }), new Function<Order, Tuple3<String, Integer, Date>>() {
                    @Override
                    public Tuple3<String, Integer, Date> apply(Order o) {
                        return new Tuple3<>(c.customerId, o.orderId, o.orderDate);
                    }
                });
            }
        })
    );

    for (Tuple3<?,?,?> o : orders){
        Log.d(o);
    }
}
```
#### Output

    (ALFKI, 10835, Thu Jan 15 00:00:00 GMT+08:00 1998)
    (ALFKI, 10952, Mon Mar 16 00:00:00 GMT+08:00 1998)
    (ALFKI, 11011, Thu Apr 09 00:00:00 GMT+08:00 1998)
    (ANATR, 10926, Wed Mar 04 00:00:00 GMT+08:00 1998)
    (ANTON, 10856, Wed Jan 28 00:00:00 GMT+08:00 1998)
    ...

### linq17: SelectMany - from Assignment
```csharp
//c#
public void Linq17() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var orders = 
        from c in customers 
        from o in c.Orders 
        where o.Total >= 2000.0M 
        select new { c.CustomerID, o.OrderID, o.Total }; 
  
    ObjectDumper.Write(orders); 
}
```
```java
//java
public void linq17(){
    List<Customer> customers = getCustomerList();

    List<Tuple3<String, Integer, Double>> orders = expand(
            map(customers, new Function<Customer, List<Tuple3<String, Integer, Double>>>() {
                @Override
                public List<Tuple3<String, Integer, Double>> apply(final Customer c) {
                    return map(filter(c.orders, new Predicate<Order>() {
                        @Override
                        public boolean apply(Order o) {
                            return o.total >= 2000;
                        }
                    }), new Function<Order, Tuple3<String, Integer, Double>>() {
                        @Override
                        public Tuple3<String, Integer, Double> apply(Order o) {
                            return new Tuple3<>(c.customerId, o.orderId, o.total);
                        }
                    });
                }
            })
    );

    for (Tuple3<?,?,?> o : orders){
        Log.d(o);
    }
}
```
#### Output

    (ANTON, 10573, 2082.0)
    (AROUT, 10558, 2142.9)
    (AROUT, 10953, 4441.25)
    (BERGS, 10384, 2222.4)
    (BERGS, 10524, 3192.65)
    ...

### linq18: SelectMany - Multiple from
```csharp
//c#
public void Linq18() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    DateTime cutoffDate = new DateTime(1997, 1, 1); 
  
    var orders = 
        from c in customers 
        where c.Region == ""WA"" 
        from o in c.Orders 
        where o.OrderDate >= cutoffDate 
        select new { c.CustomerID, o.OrderID }; 
  
    ObjectDumper.Write(orders); 
}
```
```java
//java
public void linq18(){
    List<Customer> customers = getCustomerList();

    final Date cutoffDate = new Date(97,0,1); //1997-01-01

    List<Tuple<String, Integer>> orders = expand(
        map(
            filter(customers, new Predicate<Customer>() {
                @Override
                public boolean apply(Customer c) {
                    return ""WA"".equals(c.region);
                }
            })
            , new Function<Customer, List<Tuple<String, Integer>>>() {
            @Override
            public List<Tuple<String, Integer>> apply(final Customer c) {
                return map(filter(c.orders, new Predicate<Order>() {
                    @Override
                    public boolean apply(Order o) {
                        return o.orderDate.after(cutoffDate);
                    }
                }), new Function<Order, Tuple<String, Integer>>() {
                    @Override
                    public Tuple<String, Integer> apply(Order o) {
                        return new Tuple<>(c.customerId, o.orderId);
                    }
                });
            }
        })
    );

    for (Tuple<?,?> o : orders){
        Log.d(o);
    }
}
```
#### Output

    (LAZYK, 10482)
    (LAZYK, 10545)
    (TRAIH, 10574)
    (TRAIH, 10577)
    (TRAIH, 10822)
    (WHITC, 10469)
    (WHITC, 10483)
    (WHITC, 10504)
    (WHITC, 10596)
    (WHITC, 10693)
    (WHITC, 10696)
    (WHITC, 10723)
    (WHITC, 10740)
    (WHITC, 10861)
    (WHITC, 10904)
    (WHITC, 11032)
    (WHITC, 11066)

### linq19: SelectMany - Indexed
```csharp
//c#
public void Linq19() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var customerOrders = 
        customers.SelectMany( 
            (cust, custIndex) => 
            cust.Orders.Select(o => ""Customer #"" + (custIndex + 1) + 
                                    "" has an order with OrderID "" + o.OrderID)); 
  
    ObjectDumper.Write(customerOrders); 
}
```
```java
//java
public void linq19(){
    List<Customer> customers = getCustomerList();

    List<String> customerOrders = expand(
      mapi(customers, new FunctionIndex<Customer, List<String>>() {
          @Override
          public List<String> apply(Customer cust, final int custIndex) {
              return map(cust.orders, new Function<Order, String>() {
                  @Override
                  public String apply(Order o) {
                      return ""Customer #"" + (custIndex + 1) + "" has an order with OrderID "" + o.orderId;
                  }
              });
          }
      })
    );

    for (String x : customerOrders){
        Log.d(x);
    }
}
```
#### Output

    Customer #1 has an order with OrderID 10643
    Customer #1 has an order with OrderID 10692
    Customer #1 has an order with OrderID 10702
    Customer #1 has an order with OrderID 10835
    Customer #1 has an order with OrderID 10952
    Customer #1 has an order with OrderID 11011
    Customer #2 has an order with OrderID 10308
    Customer #2 has an order with OrderID 10625
    Customer #2 has an order with OrderID 10759
    Customer #2 has an order with OrderID 10926
    ...

LINQ - Partitioning Operators
-----------------------------

### linq20: Take - Simple
```csharp
//c#
public void Linq20() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 

    var first3Numbers = numbers.Take(3); 
  
    Console.WriteLine(""First 3 numbers:""); 
  
    foreach (var n in first3Numbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq20() {
    int[] numbers = new int[]{5, 4, 1, 3, 9, 8, 6, 7, 2, 0};

    List<Integer> first3Numbers = take(toList(numbers), 3);

    Log.d(""First 3 numbers:"");
    for (Integer n : first3Numbers) {
        Log.d(n);
    }
}
```
#### Output

    First 3 numbers:
    5
    4
    1

### linq21: Take - Nested
```csharp
//c#
public void Linq21()   
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var first3WAOrders = ( 
        from c in customers 
        from o in c.Orders 
        where c.Region == ""WA"" 
        select new { c.CustomerID, o.OrderID, o.OrderDate }) 
        .Take(3); 
  
    Console.WriteLine(""First 3 orders in WA:""); 
    foreach (var order in first3WAOrders) 
    { 
        ObjectDumper.Write(order); 
    } 
}
```
```java
//java
public void linq21() {
    List<Customer> customers = getCustomerList();

    List<Tuple3<String, Integer, Date>> first3WAOrders =
        take(
            expand(
                map(filter(customers, new Predicate<Customer>() {
                    @Override
                    public boolean apply(Customer c) {
                        return ""WA"".equals(c.region);
                    }
                }),
                new Function<Customer, List<Tuple3<String, Integer, Date>>>() {
                    @Override
                    public List<Tuple3<String, Integer, Date>> apply(final Customer c) {
                        return map(c.orders, new Function<Order, Tuple3<String, Integer, Date>>() {
                            @Override
                            public Tuple3<String, Integer, Date> apply(Order o) {
                                return new Tuple3<>(c.customerId, o.orderId, o.orderDate);
                            }
                        });
                    }
                })
            ),
        3);

    Log.d(""First 3 orders in WA:"");
    for (Tuple3<?, ?, ?> o : first3WAOrders) {
        Log.d(o);
    }
}
```
#### Output

    First 3 orders in WA:
    (LAZYK, 10482, Fri Mar 21 00:00:00 GMT+08:00 1997)
    (LAZYK, 10545, Thu May 22 00:00:00 GMT+08:00 1997)
    (TRAIH, 10574, Thu Jun 19 00:00:00 GMT+08:00 1997)


### linq22: Skip - Simple
```csharp
//c#
public void Linq22() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var allButFirst4Numbers = numbers.Skip(4); 
  
    Console.WriteLine(""All but first 4 numbers:""); 
    foreach (var n in allButFirst4Numbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq22() {
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> allButFirst4Numbers = skip(toList(numbers), 4);

    Log.d(""All but first 4 numbers:"");
    for (Integer n : allButFirst4Numbers){
        Log.d(n);
    }
}
```
#### Output

    All but first 4 numbers:
    9
    8
    6
    7
    2
    0

### linq23: Skip - Nested
```csharp
//c#
public void Linq23()   
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var waOrders = 
        from c in customers 
        from o in c.Orders 
        where c.Region == ""WA"" 
        select new { c.CustomerID, o.OrderID, o.OrderDate }; 
  
    var allButFirst2Orders = waOrders.Skip(2); 
  
    Console.WriteLine(""All but first 2 orders in WA:""); 
    foreach (var order in allButFirst2Orders) 
    { 
        ObjectDumper.Write(order); 
    } 
}
```
```java
//java
public void linq23() {
    List<Customer> customers = getCustomerList();

    List<Tuple3<String, Integer, Date>> allButFirst2Orders =
        skip(
            expand(
                map(filter(customers, new Predicate<Customer>() {
                        @Override
                        public boolean apply(Customer c) {
                            return ""WA"".equals(c.region);
                        }
                    }),
                    new Function<Customer, List<Tuple3<String, Integer, Date>>>() {
                        @Override
                        public List<Tuple3<String, Integer, Date>> apply(final Customer c) {
                            return map(c.orders, new Function<Order, Tuple3<String, Integer, Date>>() {
                                @Override
                                public Tuple3<String, Integer, Date> apply(Order o) {
                                    return new Tuple3<>(c.customerId, o.orderId, o.orderDate);
                                }
                            });
                        }
                    })
                ),
            2);

    Log.d(""All but first 2 orders in WA:"");
    for (Tuple3<?, ?, ?> o : allButFirst2Orders) {
        Log.d(o);
    }
}
```
#### Output

    All but first 2 orders in WA:
    (TRAIH, 10574, Thu Jun 19 00:00:00 GMT+08:00 1997)
    (TRAIH, 10577, Mon Jun 23 00:00:00 GMT+08:00 1997)
    (TRAIH, 10822, Thu Jan 08 00:00:00 GMT+08:00 1998)
    (WHITC, 10269, Wed Jul 31 00:00:00 GMT+08:00 1996)
    (WHITC, 10344, Fri Nov 01 00:00:00 GMT+08:00 1996)
    (WHITC, 10469, Mon Mar 10 00:00:00 GMT+08:00 1997)
    (WHITC, 10483, Mon Mar 24 00:00:00 GMT+08:00 1997)
    (WHITC, 10504, Fri Apr 11 00:00:00 GMT+08:00 1997)
    (WHITC, 10596, Fri Jul 11 00:00:00 GMT+08:00 1997)
    (WHITC, 10693, Mon Oct 06 00:00:00 GMT+08:00 1997)
    (WHITC, 10696, Wed Oct 08 00:00:00 GMT+08:00 1997)
    (WHITC, 10723, Thu Oct 30 00:00:00 GMT+08:00 1997)
    (WHITC, 10740, Thu Nov 13 00:00:00 GMT+08:00 1997)
    (WHITC, 10861, Fri Jan 30 00:00:00 GMT+08:00 1998)
    (WHITC, 10904, Tue Feb 24 00:00:00 GMT+08:00 1998)
    (WHITC, 11032, Fri Apr 17 00:00:00 GMT+08:00 1998)
    (WHITC, 11066, Fri May 01 00:00:00 GMT+08:00 1998)

### linq24: TakeWhile - Simple
```csharp
//c#
public void Linq24() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var firstNumbersLessThan6 = numbers.TakeWhile(n => n < 6); 
  
    Console.WriteLine(""First numbers less than 6:""); 
    foreach (var n in firstNumbersLessThan6) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq24() {
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> firstNumbersLessThan6 = takeWhile(toList(numbers), new Predicate<Integer>() {
        @Override
        public boolean apply(Integer n) {
            return n < 6;
        }
    });

    Log.d(""First numbers less than 6:"");
    for (Integer n : firstNumbersLessThan6){
        Log.d(n);
    }
}
```
#### Output

    First numbers less than 6:
    5
    4
    1
    3

### linq25: TakeWhile - Indexed
```csharp
//c#
public void Linq25() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var firstSmallNumbers = numbers.TakeWhile((n, index) => n >= index); 
  
    Console.WriteLine(""First numbers not less than their position:""); 
    foreach (var n in firstSmallNumbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq25() {
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> firstSmallNumbers = takeWhilei(toList(numbers), new PredicateIndex<Integer>() {
        @Override
        public boolean apply(Integer n, int index) {
            return n >= index;
        }
    });

    Log.d(""First numbers not less than their position:"");
    for (Integer n : firstSmallNumbers){
        Log.d(n);
    }
}
```
#### Output

    First numbers not less than their position:
    5
    4

### linq26: SkipWhile - Simple
```csharp
//c#
public void Linq26() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var allButFirst3Numbers = numbers.SkipWhile(n => n % 3 != 0); 
  
    Console.WriteLine(""All elements starting from first element divisible by 3:""); 
    foreach (var n in allButFirst3Numbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq26() {
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> allButFirst3Numbers = skipWhile(toList(numbers), new Predicate<Integer>() {
        @Override
        public boolean apply(Integer n) {
            return n % 3 != 0;
        }
    });

    Log.d(""All elements starting from first element divisible by 3:"");
    for (Integer n : allButFirst3Numbers){
        Log.d(n);
    }
}
```
#### Output

    All elements starting from first element divisible by 3:
    3
    9
    8
    6
    7
    2
    0

### linq27: SkipWhile - Indexed
```csharp
//c#
public void Linq27() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var laterNumbers = numbers.SkipWhile((n, index) => n >= index); 
  
    Console.WriteLine(""All elements starting from first element less than its position:""); 
    foreach (var n in laterNumbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq27() {
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Integer> laterNumbers = skipWhilei(toList(numbers), new PredicateIndex<Integer>() {
        @Override
        public boolean apply(Integer n, int index) {
            return n >= index;
        }
    });

    Log.d(""All elements starting from first element less than its position:"");
    for (Integer n : laterNumbers){
        Log.d(n);
    }
}
```
#### Output

    All elements starting from first element less than its position:
    1
    3
    9
    8
    6
    7
    2
    0


LINQ - Ordering Operators
-------------------------

### linq28: OrderBy - Simple 1
```csharp
//c#
public void Linq28() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    var sortedWords = 
        from w in words 
        orderby w 
        select w; 
  
    Console.WriteLine(""The sorted list of words:""); 
    foreach (var w in sortedWords) 
    { 
        Console.WriteLine(w); 
    } 
}
```
```java
//java
public void linq28(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    List<String> sortedWords = orderBy(words);

    Log.d(""The sorted list of words:"");
    for (String w : sortedWords){
        Log.d(w);
    }
}
```
#### Output

    The sorted list of words:
    apple
    blueberry
    cherry

### linq29: OrderBy - Simple 2
```csharp
//c#
public void Linq29() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    var sortedWords = 
        from w in words 
        orderby w.Length 
        select w; 
  
    Console.WriteLine(""The sorted list of words (by length):""); 
    foreach (var w in sortedWords) 
    { 
        Console.WriteLine(w); 
    } 
}
```
```java
//java
public void linq29(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    List<String> sortedWords = orderBy(words, new Function<String, Comparable>() {
        @Override
        public Comparable apply(String s) {
            return s.length();
        }
    });

    Log.d(""The sorted list of words (by length):"");
    for (String w : sortedWords){
        Log.d(w);
    }
}
```
#### Output

    The sorted list of words (by length):
    apple
    cherry
    blueberry

### linq30: OrderBy - Simple 3
```csharp
//c#
public void Linq30() 
{ 
    List<Product> products = GetProductList(); 
  
    var sortedProducts = 
        from p in products 
        orderby p.ProductName 
        select p; 
  
    ObjectDumper.Write(sortedProducts); 
}
```
```java
//java
public void linq30(){
    List<Product> products = getProductList();

    List<Product> sortedProducts = orderBy(products, new Function<Product, Comparable>() {
        @Override
        public Comparable apply(Product p) {
            return p.productName;
        }
    });

    for (Product p : sortedProducts){
        Log.d(p);
    }
}
```
#### Output

    (Product id=17, name=Alice Mutton, cat=Meat/Poultry, price=39.0, inStock=0)
    (Product id=3, name=Aniseed Syrup, cat=Condiments, price=10.0, inStock=13)
    (Product id=40, name=Boston Crab Meat, cat=Seafood, price=18.4, inStock=123)
    (Product id=60, name=Camembert Pierrot, cat=Dairy Products, price=34.0, inStock=19)
    (Product id=18, name=Carnarvon Tigers, cat=Seafood, price=62.5, inStock=42)
    ...

### linq31: OrderBy - Comparer
```csharp
//c#
public void Linq31() 
{ 
    string[] words = { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" }; 
  
    var sortedWords = words.OrderBy(a => a, new CaseInsensitiveComparer()); 
  
    ObjectDumper.Write(sortedWords); 
} 
```
```java
//java
public void linq31(){
    String[] words = new String[] { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" };

    List<String> sortedWords = orderBy(words, String.CASE_INSENSITIVE_ORDER);

    for (String w : sortedWords){
        Log.d(w);
    }
}
```
#### Output

    AbAcUs
    aPPLE
    BlUeBeRrY
    bRaNcH
    cHeRry
    ClOvEr

### linq32: OrderByDescending - Simple 1
```csharp
//c#
public void Linq32() 
{ 
    double[] doubles = { 1.7, 2.3, 1.9, 4.1, 2.9 }; 
  
    var sortedDoubles = 
        from d in doubles 
        orderby d descending 
        select d; 
  
    Console.WriteLine(""The doubles from highest to lowest:""); 
    foreach (var d in sortedDoubles) 
    { 
        Console.WriteLine(d); 
    } 
}
```
```java
//java
public void linq32(){
    double[] doubles = new double[] { 1.7, 2.3, 1.9, 4.1, 2.9 };

    List<Double> sortedDoubles = orderByDesc(toList(doubles));

    Log.d(""The doubles from highest to lowest:"");
    for (Double d : sortedDoubles){
        Log.d(d);
    }
}
```
#### Output

    The doubles from highest to lowest:
    4.1
    2.9
    2.3
    1.9
    1.7

### linq33: OrderByDescending - Simple 2
```csharp
//c#
public void Linq33() 
{ 
    List<Product> products = GetProductList(); 
  
    var sortedProducts = 
        from p in products 
        orderby p.UnitsInStock descending 
        select p; 
  
    ObjectDumper.Write(sortedProducts); 
}
```
```java
//java
public void linq33(){
    List<Product> products = getProductList();

    List<Product> sortedProducts = orderByDesc(products, new Function<Product, Integer>(){
        @Override
        public Integer apply(Product p) {
            return p.unitsInStock;
        }
    });

    for (Product p : sortedProducts){
        Log.d(p);
    }
}
```
#### Output

    (Product id=75, name=Rhönbräu Klosterbier, cat=Beverages, price=7.75, inStock=125)
    (Product id=40, name=Boston Crab Meat, cat=Seafood, price=18.4, inStock=123)
    (Product id=6, name=Grandma's Boysenberry Spread, cat=Condiments, price=25.0, inStock=120)
    (Product id=55, name=Pâté chinois, cat=Meat/Poultry, price=24.0, inStock=115)
    (Product id=61, name=Sirop d'érable, cat=Condiments, price=28.5, inStock=113)
    ...

### linq34: OrderByDescending - Comparer
```csharp
//c#
public void Linq34() 
{ 
    string[] words = { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" }; 
  
    var sortedWords = words.OrderByDescending(a => a, new CaseInsensitiveComparer()); 
  
    ObjectDumper.Write(sortedWords); 
} 
```
```java
//java
public void linq34(){
    String[] words = new String[] { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" };

    List<String> sortedWords = orderByDesc(words, String.CASE_INSENSITIVE_ORDER);

    for (String w : sortedWords){
        Log.d(w);
    }
}
```
#### Output

    ClOvEr
    cHeRry
    bRaNcH
    BlUeBeRrY
    aPPLE
    AbAcUs

### linq35: ThenBy - Simple
```csharp
//c#
public void Linq35() 
{ 
    string[] digits = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    var sortedDigits = 
        from d in digits 
        orderby d.Length, d 
        select d; 
  
    Console.WriteLine(""Sorted digits:""); 
    foreach (var d in sortedDigits) 
    { 
        Console.WriteLine(d); 
    } 
}
```
```java
//java
public void linq35(){
    String[] digits = new String[] { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    List<String> sortedDigits = orderBy(orderBy(digits), new Function<String, Comparable>() {
        @Override
        public Comparable apply(String s) {
            return s.length();
        }
    });

    Log.d(""Sorted digits:"");
    for (String d : sortedDigits){
        Log.d(d);
    }
}
```
#### Output

    Sorted digits:
    one
    six
    two
    five
    four
    nine
    zero
    eight
    seven
    three

### linq36: ThenBy - Comparer
```csharp
//c#
public void Linq36() 
{ 
    string[] words = { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" }; 
  
    var sortedWords = 
        words.OrderBy(a => a.Length) 
             .ThenBy(a => a, new CaseInsensitiveComparer()); 
  
    ObjectDumper.Write(sortedWords); 
} 
```
```java
//java
public void linq36(){
    String[] words = new String[] { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" };

    List<String> sortedWords = orderBy(orderBy(words, String.CASE_INSENSITIVE_ORDER), new Function<String, Comparable>() {
        @Override
        public Comparable apply(String s) {
            return s.length();
        }
    });

    for (String w : sortedWords){
        Log.d(w);
    }
}
```
#### Output

    aPPLE
    AbAcUs
    bRaNcH
    cHeRry
    ClOvEr
    BlUeBeRrY

### linq37: ThenByDescending - Simple
```csharp
//c#
public void Linq37() 
{ 
    List<Product> products = GetProductList(); 
  
    var sortedProducts = 
        from p in products 
        orderby p.Category, p.UnitPrice descending 
        select p; 
  
    ObjectDumper.Write(sortedProducts); 
}
```
```java
//java
public void linq37(){
    List<Product> products = getProductList();

    List<Product> sortedProducts = orderByAll(products,
        new Comparator<Product>() {
            @Override
            public int compare(Product a, Product b) {
                return a.category.compareTo(b.category);
            }
        },
        new Comparator<Product>() {
            @Override
            public int compare(Product a, Product b) {
                return b.unitPrice.compareTo(a.unitPrice);
            }
        }
    );

    for (Product p : sortedProducts){
        Log.d(p);
    }
}
```
#### Output

    (Product id=38, name=Côte de Blaye, cat=Beverages, price=263.5, inStock=17)
    (Product id=43, name=Ipoh Coffee, cat=Beverages, price=46.0, inStock=17)
    (Product id=2, name=Chang, cat=Beverages, price=19.0, inStock=17)
    (Product id=1, name=Chai, cat=Beverages, price=18.0, inStock=39)
    (Product id=35, name=Steeleye Stout, cat=Beverages, price=18.0, inStock=20)
    (Product id=39, name=Chartreuse verte, cat=Beverages, price=18.0, inStock=69)
    (Product id=76, name=Lakkalikööri, cat=Beverages, price=18.0, inStock=57)
    (Product id=70, name=Outback Lager, cat=Beverages, price=15.0, inStock=15)
    (Product id=34, name=Sasquatch Ale, cat=Beverages, price=14.0, inStock=111)
    ...

### linq38: ThenByDescending - Comparer
```csharp
//c#
public void Linq38() 
{ 
    string[] words = { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" }; 
  
    var sortedWords = 
        words.OrderBy(a => a.Length) 
             .ThenByDescending(a => a, new CaseInsensitiveComparer()); 
  
    ObjectDumper.Write(sortedWords); 
} 
```
```java
//java
public void linq38(){
    String[] words = new String[] { ""aPPLE"", ""AbAcUs"", ""bRaNcH"", ""BlUeBeRrY"", ""ClOvEr"", ""cHeRry"" };

    List<String> sortedWords = orderByAll(words,
        new Comparator<String>() {
            @Override
            public int compare(String a, String b) {
                return Integer.compare(a.length(), b.length());
            }
        },
        new Comparator<String>() {
            @Override
            public int compare(String a, String b) {
                return String.CASE_INSENSITIVE_ORDER.compare(b,a);
            }
        });

    for (String w : sortedWords){
        Log.d(w);
    }
}
```
#### Output

    aPPLE
    ClOvEr
    cHeRry
    bRaNcH
    AbAcUs
    BlUeBeRrY

### linq39: Reverse
```csharp
//c#
public void Linq39() 
{ 
    string[] digits = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    var reversedIDigits = ( 
        from d in digits 
        where d[1] == 'i' 
        select d) 
        .Reverse(); 
  
    Console.WriteLine(""A backwards list of the digits with a second character of 'i':""); 
    foreach (var d in reversedIDigits) 
    { 
        Console.WriteLine(d); 
    } 
}
```
```java
//java
public void linq39(){
    String[] digits = new String[] { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    List<String> reversedIDigits = reverse(filter(digits, new Predicate<String>() {
        @Override
        public boolean apply(String d) {
            return d.charAt(1) == 'i';
        }
    }));

    Log.d(""A backwards list of the digits with a second character of 'i':"");
    for (String d : reversedIDigits){
        Log.d(d);
    }
}
```
#### Output

    A backwards list of the digits with a second character of 'i':
    nine
    eight
    six
    five


LINQ - Grouping Operators
-------------------------

### linq40: GroupBy - Simple 1
```csharp
//c#
public void Linq40() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    var numberGroups = 
        from n in numbers 
        group n by n % 5 into g 
        select new { Remainder = g.Key, Numbers = g }; 
  
    foreach (var g in numberGroups) 
    { 
        Console.WriteLine(""Numbers with a remainder of {0} when divided by 5:"", g.Remainder); 
        foreach (var n in g.Numbers) 
        { 
            Console.WriteLine(n); 
        } 
    } 
}
```
```java
//java
public void linq40(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    List<Tuple<Integer, Group<Integer,Integer>>> numberGroups = map(
        groupBy(toList(numbers), new Function<Integer, Integer>() {
            @Override
            public Integer apply(Integer n){
                return n % 5;
            }
        }),
        new Function<Group<Integer, Integer>, Tuple<Integer, Group<Integer,Integer>>>() {
            @Override
            public Tuple<Integer, Group<Integer,Integer>> apply(Group<Integer, Integer> g){
                return new Tuple<>(g.key, g);
            }
        });

    for (Tuple<Integer, Group<Integer,Integer>> g : numberGroups){
        Log.d(""Numbers with a remainder of "" + g.A + "" when divided by 5:"");
        for (Integer n : g.B){
            Log.d(n);
        }
    }
}
```
#### Output

    Numbers with a remainder of 4 when divided by 5:
    4
    9
    Numbers with a remainder of 1 when divided by 5:
    1
    6
    Numbers with a remainder of 0 when divided by 5:
    5
    0
    Numbers with a remainder of 2 when divided by 5:
    7
    2
    Numbers with a remainder of 3 when divided by 5:
    3
    8

### linq41: GroupBy - Simple 2
```csharp
//c#
public void Linq41() 
{ 
    string[] words = { ""blueberry"", ""chimpanzee"", ""abacus"", ""banana"", ""apple"", ""cheese"" }; 
  
    var wordGroups = 
        from w in words 
        group w by w[0] into g 
        select new { FirstLetter = g.Key, Words = g }; 
  
    foreach (var g in wordGroups) 
    { 
        Console.WriteLine(""Words that start with the letter '{0}':"", g.FirstLetter); 
        foreach (var w in g.Words) 
        { 
            Console.WriteLine(w); 
        } 
    } 
}
```
```java
//java
public void linq41(){
    String[] words = new String[] { ""blueberry"", ""chimpanzee"", ""abacus"", ""banana"", ""apple"", ""cheese"" };

    List<Tuple<Character, Group<Character,String>>> wordGroups = map(
        groupBy(toList(words), new Function<String, Character>() {
            @Override
            public Character apply(String s){
                return s.charAt(0);
            }
        }),
        new Function<Group<Character, String>, Tuple<Character, Group<Character,String>>>() {
            @Override
            public Tuple<Character, Group<Character,String>> apply(Group<Character,String> g){
                return new Tuple<>(g.key, g);
            }
        });

    for (Tuple<Character, Group<Character,String>> g : wordGroups){
        Log.d(""Words that start with the letter '"" + g.A + ""':"");
        for (String w : g.B){
            Log.d(w);
        }
    }
}
```
#### Output

    Words that start with the letter 'a':
    abacus
    apple
    Words that start with the letter 'b':
    blueberry
    banana
    Words that start with the letter 'c':
    chimpanzee
    cheese

### linq42: GroupBy - Simple 3
```csharp
//c#
public void Linq42() 
{ 
    List<Product> products = GetProductList(); 
  
    var orderGroups = 
        from p in products 
        group p by p.Category into g 
        select new { Category = g.Key, Products = g }; 
  
    ObjectDumper.Write(orderGroups, 1); 
} 
```
```java
//java
public void linq42(){
    List<Product> products = getProductList();

    List<Tuple<String,Group<String,Product>>> orderGroups = map(
        groupBy(products, new Function<Product, String>() {
            @Override
            public String apply(Product p){
                return p.category;
            }
        }),
        new Function<Group<String,Product>, Tuple<String, Group<String,Product>>>() {
            @Override
            public Tuple<String, Group<String,Product>> apply(Group<String,Product> g){
                return new Tuple<>(g.key, g);
            }
        });

    for (Tuple<String,Group<String,Product>> x : orderGroups){
        Log.d(x.B);
    }
}
```
#### Output

    Confections:
    (Product id=16, name=Pavlova, cat=Confections, price=17.45, inStock=29)
    (Product id=19, name=Teatime Chocolate Biscuits, cat=Confections, price=9.2, inStock=25)
    (Product id=20, name=Sir Rodney's Marmalade, cat=Confections, price=81.0, inStock=40)
    (Product id=21, name=Sir Rodney's Scones, cat=Confections, price=10.0, inStock=3)
    (Product id=25, name=NuNuCa Nuß-Nougat-Creme, cat=Confections, price=14.0, inStock=76)
    (Product id=26, name=Gumbär Gummibärchen, cat=Confections, price=31.23, inStock=15)
    (Product id=27, name=Schoggi Schokolade, cat=Confections, price=43.9, inStock=49)
    (Product id=47, name=Zaanse koeken, cat=Confections, price=9.5, inStock=36)
    (Product id=48, name=Chocolade, cat=Confections, price=12.75, inStock=15)
    (Product id=49, name=Maxilaku, cat=Confections, price=20.0, inStock=10)
    (Product id=50, name=Valkoinen suklaa, cat=Confections, price=16.25, inStock=65)
    (Product id=62, name=Tarte au sucre, cat=Confections, price=49.3, inStock=17)
    (Product id=68, name=Scottish Longbreads, cat=Confections, price=12.5, inStock=6)
    
    Seafood:
    (Product id=10, name=Ikura, cat=Seafood, price=31.0, inStock=31)
    (Product id=13, name=Konbu, cat=Seafood, price=6.0, inStock=24)

### linq43: GroupBy - Nested
```csharp
//c#
public void Linq43() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var customerOrderGroups = 
        from c in customers 
        select 
            new 
            { 
                c.CompanyName, 
                YearGroups = 
                    from o in c.Orders 
                    group o by o.OrderDate.Year into yg 
                    select 
                        new 
                        { 
                            Year = yg.Key, 
                            MonthGroups = 
                                from o in yg 
                                group o by o.OrderDate.Month into mg 
                                select new { Month = mg.Key, Orders = mg } 
                        } 
            }; 
  
    ObjectDumper.Write(customerOrderGroups, 3); 
} 
```
```java
//java
public void linq43(){
    List<Customer> customers = getCustomerList();

    List<Tuple<String, ArrayList<Tuple<Integer, ArrayList<Group<Integer, Order>>>>>> customerOrderGroups =
        map(customers, new Function<Customer, Tuple<String, ArrayList<Tuple<Integer, ArrayList<Group<Integer, Order>>>>>>() {
            @Override
            public Tuple<String, ArrayList<Tuple<Integer, ArrayList<Group<Integer, Order>>>>> apply(Customer c) {
                return new Tuple<>( //Yay Type Inference!
                    c.companyName,
                    map(groupBy(c.orders, new Function<Order, Integer>() {
                            @Override
                            public Integer apply(Order o) {
                                return o.orderDate.getYear() + 1900;
                            }
                        }),
                        new Function<Group<Integer, Order>, Tuple<Integer, ArrayList<Group<Integer, Order>>>>() {
                            @Override
                            public Tuple<Integer, ArrayList<Group<Integer, Order>>> apply(Group<Integer, Order> yg) {
                                return new Tuple<>( //Yay Type Inference!
                                    yg.key,
                                    groupBy(yg.items, new Function<Order, Integer>() {
                                        @Override
                                        public Integer apply(Order o) {
                                            return o.orderDate.getMonth() + 1;
                                        }
                                    })
                                );
                            }
                        }
                    )
                );
            }
        });

    for (Tuple<String, ArrayList<Tuple<Integer, ArrayList<Group<Integer, Order>>>>> g : customerOrderGroups){
        Log.d(""\n# "" + g.A);
        for (Tuple<Integer, ArrayList<Group<Integer, Order>>> yg : g.B){
            Log.d(yg.A + "": "");
            for (Group<Integer, Order> mg : yg.B){
                Log.d(""  "" + mg.key + "": "");
                for (Order o : mg){
                    Log.d(""    "" + o);
                }
            }
        }
    }
}
```
#### Output

    # Alfreds Futterkiste
    1997: 
      8: 
        (Order id=10643, total=814.5)
      10: 
        (Order id=10692, total=878.0)
        (Order id=10702, total=330.0)
    1998: 
      4: 
        (Order id=11011, total=933.5)
      1: 
        (Order id=10835, total=845.8)
      3: 
        (Order id=10952, total=471.2)

### linq44: GroupBy - Comparer
```csharp
//c#
public void Linq44() 
{ 
    string[] anagrams = { ""from   "", "" salt"", "" earn "", ""  last   "", "" near "", "" form  "" }; 
  
    var orderGroups = anagrams.GroupBy(w => w.Trim(), new AnagramEqualityComparer()); 
  
    ObjectDumper.Write(orderGroups, 1); 
} 
```
```java
//java
public void linq44(){
    String[] anagrams = new String[] { ""from   "", "" salt"", "" earn "", ""  last   "", "" near "", "" form  "" };

    List<Group<String, String>> orderGroups = groupBy(toList(anagrams),
            new Function<String, String>() {
                @Override
                public String apply(String w) {
                    return w.trim();
                }
            },
            new Predicate2<String, String>() {
                @Override
                public boolean apply(String a, String b) {
                    char[] aChars = a.toCharArray();
                    char[] bChars = b.toCharArray();
                    Arrays.sort(aChars);
                    Arrays.sort(bChars);
                    return Arrays.equals(aChars, bChars);
                }
            });

    for (Group<String, String> g : orderGroups){
        StringBuilder sb = new StringBuilder();
        for (String w : g){
            if (sb.length() > 0)
                sb.append("", "");

            sb.append(""'"").append(w).append(""'"");
        }
        Log.d(""[ "" + sb + "" ]"");
    }
}
```
#### Output

    [ ' earn ', ' near ' ]
    [ ' salt', '  last   ' ]
    [ 'from   ', ' form  ' ]

### linq45: GroupBy - Comparer, Mapped    
```csharp
//c#
public void Linq45() 
{ 
    string[] anagrams = { ""from   "", "" salt"", "" earn "", ""  last   "", "" near "", "" form  "" }; 
  
    var orderGroups = anagrams.GroupBy( 
                w => w.Trim(), 
                a => a.ToUpper(), 
                new AnagramEqualityComparer() 
                ); 
  
    ObjectDumper.Write(orderGroups, 1); 
} 
```
```java
//java
public void linq45(){
    String[] anagrams = new String[] { ""from   "", "" salt"", "" earn "", ""  last   "", "" near "", "" form  "" };

    List<Group<String, String>> orderGroups = groupBy(toList(anagrams),
            new Function<String, String>() {
                @Override
                public String apply(String w) {
                    return w.trim();
                }
            },
            new Predicate2<String, String>() {
                @Override
                public boolean apply(String a, String b) {
                    char[] aChars = a.toCharArray();
                    char[] bChars = b.toCharArray();
                    Arrays.sort(aChars);
                    Arrays.sort(bChars);
                    return Arrays.equals(aChars, bChars);
                }
            },
            new Function<String, String>() {
                @Override
                public String apply(String s) {
                    return s.toUpperCase();
                }
            });

    for (Group<String, String> g : orderGroups){
        StringBuilder sb = new StringBuilder();
        for (String w : g){
            if (sb.length() > 0)
                sb.append("", "");

            sb.append(""'"").append(w).append(""'"");
        }
        Log.d(""[ "" + sb + "" ]"");
    }
}
```
#### Output

    [ ' EARN ', ' NEAR ' ]
    [ ' SALT', '  LAST   ' ]
    [ 'FROM   ', ' FORM  ' ]


LINQ - Set Operators
--------------------

### linq46: Distinct - 1
```csharp
//c#
public void Linq46() 
{ 
    int[] factorsOf300 = { 2, 2, 3, 5, 5 }; 
  
    var uniqueFactors = factorsOf300.Distinct(); 
  
    Console.WriteLine(""Prime factors of 300:""); 
    foreach (var f in uniqueFactors) 
    { 
        Console.WriteLine(f); 
    } 
}
```
```java
//java
public void linq46(){
    int[] factorsOf300 = new int[] { 2, 2, 3, 5, 5 };

    List<Integer> uniqueFactors = distinct(toList(factorsOf300));

    Log.d(""Prime factors of 300:"");
    for (Integer f : uniqueFactors){
        Log.d(f);
    }
}
```
#### Output

    Prime factors of 300:
    5
    3
    2

### linq47: Distinct - 2
```csharp
//c#
public void Linq47() 
{ 
    List<Product> products = GetProductList(); 
  
    var categoryNames = ( 
        from p in products 
        select p.Category) 
        .Distinct(); 
  
    Console.WriteLine(""Category names:""); 
    foreach (var n in categoryNames) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq47(){
    List<Product> products = getProductList();

    List<String> categoryNames = distinct(
        map(products, new Function<Product, String>() {
            @Override
            public String apply(Product p) {
                return p.category;
            }
        }));

    Log.d(""Category names:"");
    for (String n : categoryNames){
        Log.d(n);
    }
}
```
#### Output

    Category names:
    Confections
    Seafood
    Grains/Cereals
    Meat/Poultry
    Beverages
    Condiments
    Dairy Products
    Produce

### linq48: Union - 1
```csharp
//c#
public void Linq48() 
{ 
    int[] numbersA = { 0, 2, 4, 5, 6, 8, 9 }; 
    int[] numbersB = { 1, 3, 5, 7, 8 }; 
  
    var uniqueNumbers = numbersA.Union(numbersB); 
  
    Console.WriteLine(""Unique numbers from both arrays:""); 
    foreach (var n in uniqueNumbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq48(){
    int[] numbersA = new int[] { 0, 2, 4, 5, 6, 8, 9 };
    int[] numbersB = new int[] { 1, 3, 5, 7, 8 };

    List<Integer> uniqueNumbers = union(toList(numbersA), toList(numbersB));

    Log.d(""Unique numbers from both arrays:"");
    for (Integer n : uniqueNumbers){
        Log.d(n);
    }
}
```
#### Output

    Unique numbers from both arrays:
    0
    2
    4
    5
    6
    8
    9
    1
    3
    7

### linq49: Union - 2
```csharp
//c#
public void Linq49() 
{ 
    List<Product> products = GetProductList(); 
    List<Customer> customers = GetCustomerList(); 
  
    var productFirstChars = 
        from p in products 
        select p.ProductName[0]; 
    var customerFirstChars = 
        from c in customers 
        select c.CompanyName[0]; 
  
    var uniqueFirstChars = productFirstChars.Union(customerFirstChars); 
  
    Console.WriteLine(""Unique first letters from Product names and Customer names:""); 
    foreach (var ch in uniqueFirstChars) 
    { 
        Console.WriteLine(ch); 
    } 
}
```
```java
//java
public void linq49(){
    List<Product> products = getProductList();
    List<Customer> customers = getCustomerList();

    List<Character> productFirstChars = map(products, new Function<Product, Character>() {
        @Override
        public Character apply(Product p) {
            return p.productName.charAt(0);
        }
    });

    List<Character> customerFirstChars = map(customers, new Function<Customer, Character>() {
        @Override
        public Character apply(Customer c) {
            return c.companyName.charAt(0);
        }
    });

    List<Character> uniqueFirstChars = union(productFirstChars, customerFirstChars);

    Log.d(""Unique first letters from Product names and Customer names:"");
    for (Character ch : uniqueFirstChars){
        Log.d(ch);
    }
}
```
#### Output

    Unique first letters from Product names and Customer names:
    C
    A
    G
    U
    N
    M
    I
    Q
    K
    T
    P
    S
    R
    B
    J
    Z
    V
    F
    E
    W
    L
    O
    D
    H

### linq50: Intersect - 1
```csharp
//c#
public void Linq50() 
{ 
    int[] numbersA = { 0, 2, 4, 5, 6, 8, 9 }; 
    int[] numbersB = { 1, 3, 5, 7, 8 }; 
  
    var commonNumbers = numbersA.Intersect(numbersB); 
  
    Console.WriteLine(""Common numbers shared by both arrays:""); 
    foreach (var n in commonNumbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq50(){
    int[] numbersA = new int[] { 0, 2, 4, 5, 6, 8, 9 };
    int[] numbersB = new int[] { 1, 3, 5, 7, 8 };

    List<Integer> commonNumbers = intersect(toList(numbersA), toList(numbersB));

    Log.d(""Common numbers shared by both arrays:"");
    for (Integer n : commonNumbers){
        Log.d(n);
    }
}
```
#### Output

    Common numbers shared by both arrays:
    5
    8

### linq51: Intersect - 2
```csharp
//c#
public void Linq51() 
{ 
    List<Product> products = GetProductList(); 
    List<Customer> customers = GetCustomerList(); 
  
    var productFirstChars = 
        from p in products 
        select p.ProductName[0]; 
    var customerFirstChars = 
        from c in customers 
        select c.CompanyName[0]; 
  
    var commonFirstChars = productFirstChars.Intersect(customerFirstChars); 
  
    Console.WriteLine(""Common first letters from Product names and Customer names:""); 
    foreach (var ch in commonFirstChars) 
    { 
        Console.WriteLine(ch); 
    } 
}
```
```java
//java
public void linq51(){
    List<Product> products = getProductList();
    List<Customer> customers = getCustomerList();

    List<Character> productFirstChars = map(products, new Function<Product, Character>() {
        @Override
        public Character apply(Product p) {
            return p.productName.charAt(0);
        }
    });

    List<Character> customerFirstChars = map(customers, new Function<Customer, Character>() {
        @Override
        public Character apply(Customer c) {
            return c.companyName.charAt(0);
        }
    });

    List<Character> commonFirstChars = intersect(productFirstChars, customerFirstChars);

    Log.d(""Common first letters from Product names and Customer names:"");
    for (Character ch : commonFirstChars){
        Log.d(ch);
    }
}
```
#### Output

    Common first letters from Product names and Customer names:
    C
    A
    G
    N
    M
    I
    Q
    K
    T
    P
    S
    R
    B
    V
    F
    E
    W
    L
    O

### linq52: Except - 1
```csharp
//c#
public void Linq52() 
{ 
    int[] numbersA = { 0, 2, 4, 5, 6, 8, 9 }; 
    int[] numbersB = { 1, 3, 5, 7, 8 }; 
  
    IEnumerable<int> aOnlyNumbers = numbersA.Except(numbersB); 
  
    Console.WriteLine(""Numbers in first array but not second array:""); 
    foreach (var n in aOnlyNumbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq52(){
    int[] numbersA = new int[] { 0, 2, 4, 5, 6, 8, 9 };
    int[] numbersB = new int[] { 1, 3, 5, 7, 8 };

    List<Integer> aOnlyNumbers = difference(toList(numbersA), toList(numbersB));

    Log.d(""Numbers in first array but not second array:"");
    for(Integer n: aOnlyNumbers){
        Log.d(n);
    }
}
```
#### Output

    Numbers in first array but not second array:
    0
    2
    4
    6
    9

### linq53: Except - 2
```csharp
//c#
public void Linq53() 
{ 
    List<Product> products = GetProductList(); 
    List<Customer> customers = GetCustomerList(); 
  
    var productFirstChars = 
        from p in products 
        select p.ProductName[0]; 
    var customerFirstChars = 
        from c in customers 
        select c.CompanyName[0]; 
  
    var productOnlyFirstChars = productFirstChars.Except(customerFirstChars); 
  
    Console.WriteLine(""First letters from Product names, but not from Customer names:""); 
    foreach (var ch in productOnlyFirstChars) 
    { 
        Console.WriteLine(ch); 
    } 
}
```
```java
//java
public void linq53(){
    List<Product> products = getProductList();
    List<Customer> customers = getCustomerList();

    List<Character> productFirstChars = map(products, new Function<Product, Character>() {
        @Override
        public Character apply(Product p) {
            return p.productName.charAt(0);
        }
    });

    List<Character> customerFirstChars = map(customers, new Function<Customer, Character>() {
        @Override
        public Character apply(Customer c) {
            return c.companyName.charAt(0);
        }
    });

    List<Character> productOnlyFirstChars = difference(productFirstChars, customerFirstChars);

    Log.d(""First letters from Product names, but not from Customer names:"");
    for (Character ch : productOnlyFirstChars){
        Log.d(ch);
    }
}
```
#### Output

    First letters from Product names, but not from Customer names:
    U
    J
    Z


LINQ - Conversion Operators
---------------------------

### linq54: ToArray
```csharp
//c#
public void Linq54() 
{ 
    double[] doubles = { 1.7, 2.3, 1.9, 4.1, 2.9 }; 
  
    var sortedDoubles = 
        from d in doubles 
        orderby d descending 
        select d; 
    var doublesArray = sortedDoubles.ToArray(); 
  
    Console.WriteLine(""Every other double from highest to lowest:""); 
    for (int d = 0; d < doublesArray.Length; d += 2) 
    { 
        Console.WriteLine(doublesArray[d]); 
    } 
}
```
```java
//java
public void linq54(){
    double[] doubles = new double[] { 1.7, 2.3, 1.9, 4.1, 2.9 };

    List<Double> sortedDoubles = orderByDesc(toList(doubles));

    Double[] doublesArray = toArray(sortedDoubles, Double.class);

    Log.d(""Every other double from highest to lowest:"");
    for (int d = 0; d < doublesArray.length; d += 2){
        Log.d(doublesArray[d]);
    }
}
```
#### Output

    Every other double from highest to lowest:
    4.1
    2.3
    1.7

### linq55: ToList
```csharp
//c#
public void Linq55() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    var sortedWords = 
        from w in words 
        orderby w 
        select w; 
    var wordList = sortedWords.ToList(); 
  
    Console.WriteLine(""The sorted word list:""); 
    foreach (var w in wordList) 
    { 
        Console.WriteLine(w); 
    } 
}
```
```java
//java
public void linq55(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    List<String> sortedWords = orderBy(words);
    List<String> wordList = toList(sortedWords);

    Log.d(""The sorted word list:"");
    for (String w : wordList){
        Log.d(w);
    }
}
```
#### Output

    The sorted word list:
    apple
    blueberry
    cherry

### linq56: ToDictionary
```csharp
//c#
public void Linq56() 
{ 
    var scoreRecords = new[] { new {Name = ""Alice"", Score = 50}, 
                                new {Name = ""Bob""  , Score = 40}, 
                                new {Name = ""Cathy"", Score = 45} 
                            }; 
  
    var scoreRecordsDict = scoreRecords.ToDictionary(sr => sr.Name); 
  
    Console.WriteLine(""Bob's score: {0}"", scoreRecordsDict[""Bob""]); 
}
```
```java
//java
public void linq56(){
    List<Tuple<String,Integer>> scoreRecords = toList(
        new Tuple<>(""Alice"", 50),
        new Tuple<>(""Bob"", 40),
        new Tuple<>(""Cathy"", 45)
    );

    Map<String,Tuple<String,Integer>> scoreRecordsDict = toDictionary(scoreRecords, new Function<Tuple<String, Integer>, String>() {
        @Override
        public String apply(Tuple<String, Integer> t) {
            return t.A;
        }
    });

    Log.d(""Bob's score: "" + scoreRecordsDict.get(""Bob""));
}
```
#### Output

    Bob's score: (Bob, 40)

### linq57: OfType    
```csharp
//c#
public void Linq57() 
{ 
    object[] numbers = { null, 1.0, ""two"", 3, ""four"", 5, ""six"", 7.0 }; 
  
    var doubles = numbers.OfType<double>(); 
  
    Console.WriteLine(""Numbers stored as doubles:""); 
    foreach (var d in doubles) 
    { 
        Console.WriteLine(d); 
    } 
}
```
```java
//java
public void linq57(){
    Object[] numbers = new Object[] { null, 1.0, ""two"", 3, ""four"", 5, ""six"", 7.0 };

    List<Double> doubles = ofType(toList(numbers), Double.class);

    Log.d(""Numbers stored as doubles:"");
    for (Double d : doubles){
        Log.d(d);
    }
}
```
#### Output

    Numbers stored as doubles:
    1.0
    7.0


LINQ - Element Operators
------------------------

### linq58: First - Simple
```csharp
//c#
public void Linq58() 
{ 
    List<Product> products = GetProductList(); 
 
    Product product12 = ( 
        from p in products 
        where p.ProductID == 12 
        select p) 
        .First(); 
  
    ObjectDumper.Write(product12); 
}
```
```java
//java
public void linq58(){
    List<Product> products = getProductList();

    Product product12 = first(products, new Predicate<Product>() {
        @Override
        public boolean apply(Product p) {
            return p.productId == 12;
        }
    });

    Log.d(product12);
}
```
#### Output

    (Product id=12, name=Queso Manchego La Pastora, cat=Dairy Products, price=38.0, inStock=86)

### linq59: First - Condition
```csharp
//c#
public void Linq59() 
{ 
    string[] strings = { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" }; 
  
    string startsWithO = strings.First(s => s[0] == 'o'); 
  
    Console.WriteLine(""A string starting with 'o': {0}"", startsWithO); 
}
```
```java
//java
public void linq59(){
    String[] strings = new String[] { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"", ""nine"" };

    String startsWithO = first(strings, new Predicate<String>() {
        @Override
        public boolean apply(String s) {
            return s.charAt(0) == 'o';
        }
    });

    Log.d(""A string starting with 'o': "" + startsWithO);
}
```
#### Output

    A string starting with 'o': one

### linq61: FirstOrDefault - Simple
```csharp
//c#
public void Linq61() 
{ 
    int[] numbers = { }; 
  
    int firstNumOrDefault = numbers.FirstOrDefault(); 
  
    Console.WriteLine(firstNumOrDefault); 
}
```
```java
//java
public void linq61(){
    int[] numbers = { };

    int firstNumOrDefault = first(toList(numbers), 0);

    Log.d(firstNumOrDefault);
}
```
#### Output

    0

### linq62: FirstOrDefault - Condition
```csharp
//c#
public void Linq62() 
{ 
    List<Product> products = GetProductList(); 
  
    Product product789 = products.FirstOrDefault(p => p.ProductID == 789); 
 
    Console.WriteLine(""Product 789 exists: {0}"", product789 != null); 
}
```
```java
//java
public void linq62(){
    List<Product> products = getProductList();

    Product product789 = first(products, new Predicate<Product>() {
        @Override
        public boolean apply(Product p) {
            return p.productId == 789;
        }
    });

    Log.d(""Product 789 exists: "" + (product789 != null));
}
```
#### Output

    Product 789 exists: false

### linq64: ElementAt
```csharp
//c#
public void Linq64() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    int fourthLowNum = ( 
        from n in numbers 
        where n > 5 
        select n) 
        .ElementAt(1);  // second number is index 1 because sequences use 0-based indexing 
 
    Console.WriteLine(""Second number > 5: {0}"", fourthLowNum); 
}
```
```java
//java
public void linq64(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    Integer fourthLowNum = filter(toList(numbers), new Predicate<Integer>() {
            @Override
            public boolean apply(Integer n) {
                return n > 5;
            }
        })
        .get(1);  // second number is index 1 because sequences use 0-based indexing

    Log.d(""Second number > 5: "" + fourthLowNum);
}
```
#### Output

    Second number > 5: 8


LINQ - Generation Operators
---------------------------

### linq65: Range
```csharp
//c#
public void Linq65() 
{ 
    var numbers = 
        from n in Enumerable.Range(100, 50) 
  
        select new { Number = n, OddEven = n % 2 == 1 ? ""odd"" : ""even"" }; 
  
    foreach (var n in numbers) 
    { 
        Console.WriteLine(""The number {0} is {1}."", n.Number, n.OddEven); 
    } 
}
```
```java
//java
public void linq65(){
    List<Tuple<Integer, String>> numbers = map(toList(range(100, 150)), new Function<Integer, Tuple<Integer, String>>() {
        @Override
        public Tuple<Integer, String> apply(Integer n) {
            return new Tuple<>(n, n % 2 == 1 ? ""odd"" : ""even"");
        }
    });

    for (Tuple<Integer,String> n : numbers){
        Log.d(""The number "" + n.A + "" is "" + n.B);
    }
}
```
#### Output

    The number 100 is even
    The number 101 is odd
    The number 102 is even
    The number 103 is odd
    The number 104 is even
    The number 105 is odd
    The number 106 is even
    The number 107 is odd
    The number 108 is even
    The number 109 is odd
    The number 110 is even
    ...

### linq66: Repeat
```csharp
//c#
public void Linq66() 
{ 
    var numbers = Enumerable.Repeat(7, 10); 
  
    foreach (var n in numbers) 
    {  
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq66(){
    int[] numbers = repeat(7, 10);

    for (int n : numbers){
        Log.d(n);
    }
}
```
#### Output

    7
    7
    7
    7
    7
    7
    7
    7
    7
    7


LINQ - Quantifiers
------------------

### linq67: Any - Simple
```csharp
//c#
public void Linq67() 
{ 
    string[] words = { ""believe"", ""relief"", ""receipt"", ""field"" }; 
  
    bool iAfterE = words.Any(w => w.Contains(""ei"")); 
 
    Console.WriteLine(""There is a word that contains in the list that contains 'ei': {0}"", iAfterE); 
}
```
```java
//java
public void linq67(){
    String[] words = new String[] { ""believe"", ""relief"", ""receipt"", ""field"" };

    boolean iAfterE = any(words, new Predicate<String>() {
        @Override
        public boolean apply(String w) {
            return w.contains(""ei"");
        }
    });

    Log.d(""There is a word that contains in the list that contains 'ei': "" + iAfterE);
}
```
#### Output

    There is a word that contains in the list that contains 'ei': true

### linq69: Any - Grouped
```csharp
//c#
public void Linq69() 
{ 
    List<Product> products = GetProductList(); 
    var productGroups = 
        from p in products 
        group p by p.Category into g 
        where g.Any(p => p.UnitsInStock == 0) 
        select new { Category = g.Key, Products = g }; 
 
    ObjectDumper.Write(productGroups, 1);  
}
```
```java
//java
public void linq69(){
    List<Product> products = getProductList();

    List<Tuple<String, Group<String,Product>>> productGroups =
        map(
            filter(
                groupBy(products, new Function<Product, String>() {
                    @Override
                    public String apply(Product p) {
                        return p.category;
                    }
                }),
                new Predicate<Group<String, Product>>() {
                    @Override
                    public boolean apply(Group<String, Product> g) {
                        return any(g, new Predicate<Product>() {
                            @Override
                            public boolean apply(Product p) {
                                return p.unitsInStock == 0;
                            }
                        });
                    }
                })
            , new Function<Group<String, Product>, Tuple<String, Group<String, Product>>>() {
                @Override
                public Tuple<String, Group<String, Product>> apply(Group<String, Product> g) {
                    return new Tuple<>(g.key, g);
                }
            }
        );

    for (Tuple<String, Group<String,Product>> t : productGroups){
        Log.d(t.B);
    }
}
```
#### Output

    Meat/Poultry:
    (Product id=9, name=Mishi Kobe Niku, cat=Meat/Poultry, price=97.0, inStock=29)
    (Product id=17, name=Alice Mutton, cat=Meat/Poultry, price=39.0, inStock=0)
    (Product id=29, name=Thüringer Rostbratwurst, cat=Meat/Poultry, price=123.79, inStock=0)
    (Product id=53, name=Perth Pasties, cat=Meat/Poultry, price=32.8, inStock=0)
    (Product id=54, name=Tourtière, cat=Meat/Poultry, price=7.45, inStock=21)
    (Product id=55, name=Pâté chinois, cat=Meat/Poultry, price=24.0, inStock=115)
    
    Condiments:
    (Product id=3, name=Aniseed Syrup, cat=Condiments, price=10.0, inStock=13)
    (Product id=4, name=Chef Anton's Cajun Seasoning, cat=Condiments, price=22.0, inStock=53)
    ...

### linq70: All - Simple
```csharp
//c#
public void Linq70() 
{  
    int[] numbers = { 1, 11, 3, 19, 41, 65, 19 }; 
  
    bool onlyOdd = numbers.All(n => n % 2 == 1); 
  
    Console.WriteLine(""The list contains only odd numbers: {0}"", onlyOdd); 
}
```
```java
//java
public void linq70(){
    int[] numbers = new int[] { 1, 11, 3, 19, 41, 65, 19 };

    boolean onlyOdd = all(toList(numbers), new Predicate<Integer>() {
        @Override
        public boolean apply(Integer n) {
            return n % 2 == 1;
        }
    });

    Log.d(""The list contains only odd numbers: "" + onlyOdd);
}
```
#### Output

    The list contains only odd numbers: true

### linq72: All - Grouped    
```csharp
//c#
public void Linq72() 
{ 
    List<Product> products = GetProductList(); 
  
    var productGroups = 
        from p in products 
        group p by p.Category into g 
        where g.All(p => p.UnitsInStock > 0) 
        select new { Category = g.Key, Products = g }; 
     
    ObjectDumper.Write(productGroups, 1); 
}
```
```java
//java
public void linq72(){
    List<Product> products = getProductList();

    List<Tuple<String, Group<String,Product>>> productGroups =
        map(
            filter(
                groupBy(products, new Function<Product, String>() {
                    @Override
                    public String apply(Product p) {
                        return p.category;
                    }
                }),
                new Predicate<Group<String, Product>>() {
                    @Override
                    public boolean apply(Group<String, Product> g) {
                        return all(g, new Predicate<Product>() {
                            @Override
                            public boolean apply(Product p) {
                                return p.unitsInStock > 0;
                            }
                        });
                    }
                })
            , new Function<Group<String, Product>, Tuple<String, Group<String, Product>>>() {
                @Override
                public Tuple<String, Group<String, Product>> apply(Group<String, Product> g) {
                    return new Tuple<>(g.key, g);
                }
            }
        );

    for (Tuple<String, Group<String,Product>> t : productGroups){
        Log.d(t.B);
    }
}
```
#### Output

    Confections:
    (Product id=16, name=Pavlova, cat=Confections, price=17.45, inStock=29)
    (Product id=19, name=Teatime Chocolate Biscuits, cat=Confections, price=9.2, inStock=25)
    (Product id=20, name=Sir Rodney's Marmalade, cat=Confections, price=81.0, inStock=40)
    (Product id=21, name=Sir Rodney's Scones, cat=Confections, price=10.0, inStock=3)
    (Product id=25, name=NuNuCa Nuß-Nougat-Creme, cat=Confections, price=14.0, inStock=76)
    (Product id=26, name=Gumbär Gummibärchen, cat=Confections, price=31.23, inStock=15)
    (Product id=27, name=Schoggi Schokolade, cat=Confections, price=43.9, inStock=49)
    (Product id=47, name=Zaanse koeken, cat=Confections, price=9.5, inStock=36)
    (Product id=48, name=Chocolade, cat=Confections, price=12.75, inStock=15)
    (Product id=49, name=Maxilaku, cat=Confections, price=20.0, inStock=10)
    (Product id=50, name=Valkoinen suklaa, cat=Confections, price=16.25, inStock=65)
    (Product id=62, name=Tarte au sucre, cat=Confections, price=49.3, inStock=17)
    (Product id=68, name=Scottish Longbreads, cat=Confections, price=12.5, inStock=6)
    ...


LINQ - Aggregate Operators
--------------------------

### linq73: Count - Simple
```csharp
//c#
public void Linq73() 
{ 
    int[] factorsOf300 = { 2, 2, 3, 5, 5 }; 
  
    int uniqueFactors = factorsOf300.Distinct().Count(); 
  
    Console.WriteLine(""There are {0} unique factors of 300."", uniqueFactors); 
}
```
```java
//java
public void linq73(){
    int[] factorsOf300 = new int[] { 2, 2, 3, 5, 5 };

    int uniqueFactors = distinct(toList(factorsOf300)).size();

    Log.d(""There are "" + uniqueFactors + "" unique factors of 300."");
}
```
#### Output

    There are 3 unique factors of 300.

### linq74: Count - Conditional
```csharp
//c#
public void Linq74() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    int oddNumbers = numbers.Count(n => n % 2 == 1); 
  
    Console.WriteLine(""There are {0} odd numbers in the list."", oddNumbers); 
}
```
```java
//java
public void linq74(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    int oddNumbers = count(toList(numbers), new Predicate<Integer>() {
        @Override
        public boolean apply(Integer n) {
            return n % 2 == 1;
        }
    });

    Log.d(""There are "" + oddNumbers + "" odd numbers in the list."");
}
```
#### Output

    There are 5 odd numbers in the list.

### linq76: Count - Nested
```csharp
//c#
public void Linq76() 
{ 
    List<Customer> customers = GetCustomerList(); 
  
    var orderCounts = 
        from c in customers 
        select new { c.CustomerID, OrderCount = c.Orders.Count() }; 
  
    ObjectDumper.Write(orderCounts); 
}
```
```java
//java
public void linq76(){
    List<Customer> customers = getCustomerList();

    List<Tuple<String, Integer>> orderCounts =
        map(customers, new Function<Customer, Tuple<String, Integer>>() {
            @Override
            public Tuple<String, Integer> apply(Customer c) {
                return new Tuple<>(c.customerId, c.orders.size());
            }
        });

    for (Tuple<?,?> t : orderCounts){
        Log.d(t);
    }
}
```
#### Output

    (ALFKI, 6)
    (ANATR, 4)
    (ANTON, 7)
    (AROUT, 13)
    (BERGS, 18)
    (BLAUS, 7)
    (BLONP, 11)
    ...

### linq77: Count - Grouped
```csharp
//c#
public void Linq77() 
{ 
    List<Product> products = GetProductList(); 
  
    var categoryCounts = 
        from p in products 
        group p by p.Category into g 
        select new { Category = g.Key, ProductCount = g.Count() }; 
  
    ObjectDumper.Write(categoryCounts 
}
```
```java
//java
public void linq77(){
    List<Product> products = getProductList();

    List<Tuple<String,Integer>> categoryCounts =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            }),
            new Function<Group<String, Product>, Tuple<String,Integer>>() {
                @Override
                public Tuple<String, Integer> apply(Group<String, Product> g) {
                    return new Tuple<>(g.key, g.items.size());
                }
            }
        );

    for (Tuple<?,?> t : categoryCounts){
        Log.d(t);
    }
}
```
#### Output

    (Confections, 13)
    (Seafood, 12)
    (Grains/Cereals, 7)
    (Meat/Poultry, 6)
    (Beverages, 12)
    (Condiments, 12)
    (Dairy Products, 10)
    (Produce, 5)

### linq78: Sum - Simple
```csharp
//c#
public void Linq78() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    double numSum = numbers.Sum(); 
  
    Console.WriteLine(""The sum of the numbers is {0}."", numSum); 
}
```
```java
//java
public void linq78(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    double numSum = sum(numbers);

    Log.d(""The sum of the numbers is "" + numSum);
}
```
#### Output

    The sum of the numbers is 45.0

### linq79: Sum - Projection
```csharp
//c#
public void Linq79() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    double totalChars = words.Sum(w => w.Length); 
  
    Console.WriteLine(""There are a total of {0} characters in these words."", totalChars); 
}
```
```java
//java
public void linq79(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    Integer totalChars = sum(toList(words), new Function<String, Integer>() {
        @Override
        public Integer apply(String w) {
            return w.length();
        }
    });

    Log.d(""There are a total of "" + totalChars + "" characters in these words."");
}
```
#### Output

    There are a total of 20 characters in these words.

### linq80: Sum - Grouped
```csharp
//c#
public void Linq80() 
{ 
    List<Product> products = GetProductList(); 
  
    var categories = 
        from p in products 
        group p by p.Category into g 
        select new { Category = g.Key, TotalUnitsInStock = g.Sum(p => p.UnitsInStock) }; 
  
    ObjectDumper.Write(categories); 
}
```
```java
//java
public void linq80(){
    List<Product> products = getProductList();

    List<Tuple<String, Integer>> categories =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            })
            , new Function<Group<String,Product>, Tuple<String, Integer>>() {
                @Override
                public Tuple<String, Integer> apply(Group<String, Product> g) {
                    return new Tuple<>(g.key, sum(g, new Function<Product, Integer>() {
                        @Override
                        public Integer apply(Product p) {
                            return p.unitsInStock;
                        }
                    }));
                }
            }
        );

    for (Tuple<?,?> t : categories){
        Log.d(t);
    }
}
```
#### Output

    (Confections, 386)
    (Seafood, 701)
    (Grains/Cereals, 308)
    (Meat/Poultry, 165)
    (Beverages, 559)
    (Condiments, 507)
    (Dairy Products, 393)
    (Produce, 100)

### linq81: Min - Simple
```csharp
//c#
public void Linq81() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    int minNum = numbers.Min(); 
  
    Console.WriteLine(""The minimum number is {0}."", minNum); 
}
```
```java
//java
public void linq81(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    int minNum = min(numbers);

    Log.d(""The minimum number is "" +  minNum);
}
```
#### Output

    The minimum number is 0

### linq82: Min - Projection
```csharp
//c#
public void Linq82() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    int shortestWord = words.Min(w => w.Length); 
  
    Console.WriteLine(""The shortest word is {0} characters long."", shortestWord); 
}
```
```java
//java
public void linq82(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    int shortestWord = min(words, new Function<String, Integer>() {
        @Override
        public Integer apply(String w) {
            return w.length();
        }
    });

    Log.d(""The shortest word is "" + shortestWord + "" characters long."");
}
```
#### Output

    The shortest word is 5 characters long.

### linq83: Min - Grouped
```csharp
//c#
public void Linq83() 
{ 
    List<Product> products = GetProductList(); 
  
    var categories = 
        from p in products 
        group p by p.Category into g 
        select new { Category = g.Key, CheapestPrice = g.Min(p => p.UnitPrice) }; 
  
    ObjectDumper.Write(categories); 
}
```
```java
//java
public void linq83(){
    List<Product> products = getProductList();

    List<Tuple<String,Double>> categories =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            }),
            new Function<Group<String, Product>, Tuple<String, Double>>() {
                @Override
                public Tuple<String, Double> apply(Group<String, Product> g) {
                    return new Tuple<>(g.key, minDouble(g, new Function<Product, Double>() {
                        @Override
                        public Double apply(Product p) {
                            return p.unitPrice;
                        }
                    }));
                }
            }
        );

    for (Tuple<?,?> t : categories){
        Log.d(t);
    }
}
```
#### Output

    (Confections, 9.2)
    (Seafood, 6.0)
    (Grains/Cereals, 7.0)
    (Meat/Poultry, 7.45)
    (Beverages, 4.5)
    (Condiments, 10.0)
    (Dairy Products, 2.5)
    (Produce, 10.0)

### linq84: Min - Elements
```csharp
//c#
public void Linq84() 
{ 
    List<Product> products = GetProductList(); 
  
    var categories = 
        from p in products 
        group p by p.Category into g 
        let minPrice = g.Min(p => p.UnitPrice) 
        select new { Category = g.Key, CheapestProducts = g.Where(p => p.UnitPrice == minPrice) }; 
  
    ObjectDumper.Write(categories, 1); 
}
```
```java
//java
public void linq84(){
    List<Product> products = getProductList();

    List<Tuple<String,ArrayList<Product>>> categories =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            }),
            new Function<Group<String, Product>, Tuple<String, ArrayList<Product>>>() {
                @Override
                public Tuple<String, ArrayList<Product>> apply(Group<String, Product> g) {
                    final double minPrice = minDouble(g, new Function<Product, Double>() {
                        @Override
                        public Double apply(Product p) {
                            return p.unitPrice;
                        }
                    });
                    return new Tuple<>(
                        g.key,
                        filter(g.items, new Predicate<Product>() {
                            @Override
                            public boolean apply(Product p) {
                                return p.unitPrice == minPrice;
                            }
                        })
                    );
                }
            }
        );

    for (Tuple<String,ArrayList<Product>> t : categories){
        Log.d(t.A + "": "");
        Log.d(t.B);
    }
}
```
#### Output

    Confections: 
    [(Product id=19, name=Teatime Chocolate Biscuits, cat=Confections, price=9.2, inStock=25)]
    Seafood: 
    [(Product id=13, name=Konbu, cat=Seafood, price=6.0, inStock=24)]
    Grains/Cereals: 
    [(Product id=52, name=Filo Mix, cat=Grains/Cereals, price=7.0, inStock=38)]
    Meat/Poultry: 
    [(Product id=54, name=Tourtière, cat=Meat/Poultry, price=7.45, inStock=21)]
    Beverages: 
    [(Product id=24, name=Guaraná Fantástica, cat=Beverages, price=4.5, inStock=20)]
    Condiments: 
    [(Product id=3, name=Aniseed Syrup, cat=Condiments, price=10.0, inStock=13)]
    Dairy Products: 
    [(Product id=33, name=Geitost, cat=Dairy Products, price=2.5, inStock=112)]
    Produce: 
    [(Product id=74, name=Longlife Tofu, cat=Produce, price=10.0, inStock=4)]

### linq85: Max - Simple
```csharp
//c#
public void Linq85() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    int maxNum = numbers.Max(); 
  
    Console.WriteLine(""The maximum number is {0}."", maxNum); 
}
```
```java
//java
public void linq85(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    int maxNum = max(numbers);

    Log.d(""The maximum number is "" + maxNum);
}
```
#### Output

    The maximum number is 9

### linq86: Max - Projection
```csharp
//c#
public void Linq86() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    int longestLength = words.Max(w => w.Length); 
  
    Console.WriteLine(""The longest word is {0} characters long."", longestLength); 
}
```
```java
//java
public void linq86(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    int longestLength = max(words, new Function<String, Integer>() {
        @Override
        public Integer apply(String w) {
            return w.length();
        }
    });

    Log.d(""The longest word is "" + longestLength + "" characters long."");
}
```
#### Output

    The longest word is 9 characters long.

### linq87: Max - Grouped
```csharp
//c#
public void Linq87() 
{ 
    List<Product> products = GetProductList(); 
  
    var categories = 
        from p in products 
        group p by p.Category into g 
        select new { Category = g.Key, MostExpensivePrice = g.Max(p => p.UnitPrice) }; 
  
    ObjectDumper.Write(categories); 
}
```
```java
//java
public void linq87(){
    List<Product> products = getProductList();

    ArrayList<Tuple<String, Double>> categories =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            }),
            new Function<Group<String, Product>, Tuple<String, Double>>() {
                @Override
                public Tuple<String, Double> apply(Group<String, Product> g) {
                    return new Tuple<>(
                        g.key,
                        maxDouble(g, new Function<Product, Double>() {
                            @Override
                            public Double apply(Product p) {
                                return p.unitPrice;
                            }
                        })
                    );
                }
            }
        );

    for (Tuple<?,?> t : categories){
        Log.d(t);
    }
}
```
#### Output

    (Confections, 81.0)
    (Seafood, 62.5)
    (Grains/Cereals, 38.0)
    (Meat/Poultry, 123.79)
    (Beverages, 263.5)
    (Condiments, 43.9)
    (Dairy Products, 55.0)
    (Produce, 53.0)

### linq88: Max - Elements
```csharp
//c#
public void Linq88() 
{ 
    List<Product> products = GetProductList(); 
  
    var categories = 
        from p in products 
        group p by p.Category into g 
        let maxPrice = g.Max(p => p.UnitPrice) 
        select new { Category = g.Key, MostExpensiveProducts = g.Where(p => p.UnitPrice == maxPrice) }; 
  
    ObjectDumper.Write(categories, 1); 
}
```
```java
//java
public void linq88(){
    List<Product> products = getProductList();

    List<Tuple<String,ArrayList<Product>>> categories =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            }),
            new Function<Group<String, Product>, Tuple<String, ArrayList<Product>>>() {
                @Override
                public Tuple<String, ArrayList<Product>> apply(Group<String, Product> g) {
                    final double maxPrice = maxDouble(g, new Function<Product, Double>() {
                        @Override
                        public Double apply(Product p) {
                            return p.unitPrice;
                        }
                    });
                    return new Tuple<>(
                        g.key,
                        filter(g.items, new Predicate<Product>() {
                            @Override
                            public boolean apply(Product p) {
                                return p.unitPrice == maxPrice;
                            }
                        })
                    );
                }
            }
        );

    for (Tuple<String,ArrayList<Product>> t : categories){
        Log.d(t.A + "": "");
        Log.d(t.B);
    }
}
```
#### Output

    Confections: 
    [(Product id=20, name=Sir Rodney's Marmalade, cat=Confections, price=81.0, inStock=40)]
    Seafood: 
    [(Product id=18, name=Carnarvon Tigers, cat=Seafood, price=62.5, inStock=42)]
    Grains/Cereals: 
    [(Product id=56, name=Gnocchi di nonna Alice, cat=Grains/Cereals, price=38.0, inStock=21)]
    Meat/Poultry: 
    [(Product id=29, name=Thüringer Rostbratwurst, cat=Meat/Poultry, price=123.79, inStock=0)]
    Beverages: 
    [(Product id=38, name=Côte de Blaye, cat=Beverages, price=263.5, inStock=17)]
    Condiments: 
    [(Product id=63, name=Vegie-spread, cat=Condiments, price=43.9, inStock=24)]
    Dairy Products: 
    [(Product id=59, name=Raclette Courdavault, cat=Dairy Products, price=55.0, inStock=79)]
    Produce: 
    [(Product id=51, name=Manjimup Dried Apples, cat=Produce, price=53.0, inStock=20)]

### linq89: Average - Simple
```csharp
//c#
public void Linq89() 
{ 
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    double averageNum = numbers.Average(); 
  
    Console.WriteLine(""The average number is {0}."", averageNum); 
}
```
```java
//java
public void linq89(){
    int[] numbers = { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    double averageNum = avg(numbers);

    Log.d(""The average number is "" + averageNum);
}
```
#### Output

    The average number is 4.5

### linq90: Average - Projection
```csharp
//c#
public void Linq90() 
{ 
    string[] words = { ""cherry"", ""apple"", ""blueberry"" }; 
  
    double averageLength = words.Average(w => w.Length); 
  
    Console.WriteLine(""The average word length is {0} characters."", averageLength); 
}
```
```java
//java
public void linq90(){
    String[] words = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    double averageLength = avg(words, new Function<String, Integer>() {
        @Override
        public Integer apply(String w) {
            return w.length();
        }
    });

    Log.d(""The average word length is "" + averageLength + "" characters."");
}
```
#### Output

    The average word length is 6.666666666666667 characters.

### linq91: Average - Grouped
```csharp
//c#
public void Linq91() 
{ 
    List<Product> products = GetProductList(); 
  
    var categories = 
        from p in products 
        group p by p.Category into g 
        select new { Category = g.Key, AveragePrice = g.Average(p => p.UnitPrice) }; 
  
    ObjectDumper.Write(categories); 
}
```
```java
//java
public void linq91(){
    List<Product> products = getProductList();

    ArrayList<Tuple<String, Double>> categories =
        map(
            groupBy(products, new Function<Product, String>() {
                @Override
                public String apply(Product p) {
                    return p.category;
                }
            }),
            new Function<Group<String, Product>, Tuple<String, Double>>() {
                @Override
                public Tuple<String, Double> apply(Group<String, Product> g) {
                    return new Tuple<>(
                        g.key,
                        avgDouble(g, new Function<Product, Double>() {
                            @Override
                            public Double apply(Product p) {
                                return p.unitPrice;
                            }
                        })
                    );
                }
            }
        );

    for (Tuple<?,?> t : categories){
        Log.d(t);
    }
}
```
#### Output

    (Confections, 25.16)
    (Seafood, 20.6825)
    (Grains/Cereals, 20.25)
    (Meat/Poultry, 54.00666666666667)
    (Beverages, 37.979166666666664)
    (Condiments, 23.0625)
    (Dairy Products, 28.73)
    (Produce, 32.37)

### linq92: Aggregate - Simple
```csharp
//c#
public void Linq92() 
{ 
    double[] doubles = { 1.7, 2.3, 1.9, 4.1, 2.9 }; 
  
    double product = doubles.Aggregate((runningProduct, nextFactor) => runningProduct * nextFactor); 
  
    Console.WriteLine(""Total product of all numbers: {0}"", product); 
}
```
```java
//java
public void linq92(){
    double[] doubles = new double[]  { 1.7, 2.3, 1.9, 4.1, 2.9 };

    double product = reduce(toList(doubles), 1d, new Reducer<Double, Double>() {
        @Override
        public Double reduce(Double runningProduct, Double nextFactor) {
            return runningProduct * nextFactor;
        }
    });

    Log.d(""Total product of all numbers: "" + product);
}
```
#### Output

    Total product of all numbers: 88.33080999999999

### linq93: Aggregate - Seed
```csharp
//c#
public void Linq93() 
{ 
    double startBalance = 100.0; 
  
    int[] attemptedWithdrawals = { 20, 10, 40, 50, 10, 70, 30 }; 
  
    double endBalance = 
        attemptedWithdrawals.Aggregate(startBalance, 
            (balance, nextWithdrawal) => 
                ((nextWithdrawal <= balance) ? (balance - nextWithdrawal) : balance)); 
  
    Console.WriteLine(""Ending balance: {0}"", endBalance); 
}
```
```java
//java
public void linq93(){
    double startBalance = 100.0;

    int[] attemptedWithdrawals = new int[] { 20, 10, 40, 50, 10, 70, 30 };

    double endBalance =
        reduce(
            toList(attemptedWithdrawals),
            startBalance,
            new Reducer<Integer, Double>() {
                @Override
                public Double reduce(Double balance, Integer nextWithdrawal) {
                    return (nextWithdrawal <= balance) ? (balance - nextWithdrawal) : balance;
                }
            }
        );

    Log.d(""Ending balance: "" + endBalance);
}
```
#### Output

    Ending balance: 20.0


LINQ - Miscellaneous Operators
------------------------------

### linq94: Concat - 1
```csharp
//c#
public void Linq94() 
{ 
    int[] numbersA = { 0, 2, 4, 5, 6, 8, 9 }; 
    int[] numbersB = { 1, 3, 5, 7, 8 }; 
  
    var allNumbers = numbersA.Concat(numbersB); 
  
    Console.WriteLine(""All numbers from both arrays:""); 
    foreach (var n in allNumbers) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq94(){
    int[] numbersA = new int[] { 0, 2, 4, 5, 6, 8, 9 };
    int[] numbersB = new int[] { 1, 3, 5, 7, 8 };

    List<Integer> allNumbers = concat(toList(numbersA), toList(numbersB));

    Log.d(""All numbers from both arrays:"");
    for (Integer n : allNumbers){
        Log.d(n);
    }
}
```
#### Output

    All numbers from both arrays:
    0
    2
    4
    5
    6
    8
    9
    1
    3
    5
    7
    8

### linq95: Concat - 2
```csharp
//c#
public void Linq95() 
{ 
    List<Customer> customers = GetCustomerList(); 
    List<Product> products = GetProductList(); 
  
    var customerNames = 
        from c in customers 
        select c.CompanyName; 
    var productNames = 
        from p in products 
        select p.ProductName; 
  
    var allNames = customerNames.Concat(productNames); 
  
    Console.WriteLine(""Customer and product names:""); 
    foreach (var n in allNames) 
    { 
        Console.WriteLine(n); 
    } 
}
```
```java
//java
public void linq95(){
    List<Customer> customers = getCustomerList();
    List<Product> products = getProductList();

    List<String> customerNames = map(customers, new Function<Customer, String>() {
        @Override
        public String apply(Customer c) {
            return c.companyName;
        }
    });

    List<String> productNames = map(products, new Function<Product, String>() {
        @Override
        public String apply(Product p) {
            return p.productName;
        }
    });

    List<String> allNames = concat(customerNames, productNames);

    Log.d(""Customer and product names:"");
    for (String n : allNames){
        Log.d(n);
    }
}
```
#### Output

    Customer and product names:
    Alfreds Futterkiste
    Ana Trujillo Emparedados y helados
    Antonio Moreno Taquería
    Around the Horn
    Berglunds snabbköp
    Blauer See Delikatessen
    ...

### linq96: EqualAll - 1
```csharp
//c#
public void Linq96() 
{ 
    var wordsA = new string[] { ""cherry"", ""apple"", ""blueberry"" }; 
    var wordsB = new string[] { ""cherry"", ""apple"", ""blueberry"" }; 
  
    bool match = wordsA.SequenceEqual(wordsB); 
  
    Console.WriteLine(""The sequences match: {0}"", match); 
}
```
```java
//java
public void linq96(){
    String[] wordsA = new String[] { ""cherry"", ""apple"", ""blueberry"" };
    String[] wordsB = new String[] { ""cherry"", ""apple"", ""blueberry"" };

    boolean match = Arrays.equals(wordsA, wordsB);

    Log.d(""The sequences match: "" + match);
}
```
#### Output

    The sequences match: true

### linq97: EqualAll - 2
```csharp
//c#
public void Linq97() 
{ 
    var wordsA = new string[] { ""cherry"", ""apple"", ""blueberry"" }; 
    var wordsB = new string[] { ""apple"", ""blueberry"", ""cherry"" }; 
  
    bool match = wordsA.SequenceEqual(wordsB); 
  
    Console.WriteLine(""The sequences match: {0}"", match); 
}
```
```java
//java
public void linq97(){
    String[] wordsA = new String[] { ""cherry"", ""apple"", ""blueberry"" };
    String[] wordsB = new String[] { ""cherry"", ""blueberry"", ""cherry"" };

    boolean match = Arrays.equals(wordsA, wordsB);

    Log.d(""The sequences match: "" + match);
}
```
#### Output

    The sequences match: false

LINQ - Query Execution
----------------------

### linq99: Deferred Execution
```csharp
//c#
public void Linq99() 
{ 
    // Sequence operators form first-class queries that 
    // are not executed until you enumerate over them. 
  
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    int i = 0; 
    var q = 
        from n in numbers 
        select ++i; 
  
    // Note, the local variable 'i' is not incremented 
    // until each element is evaluated (as a side-effect): 
    foreach (var v in q) 
    { 
        Console.WriteLine(""v = {0}, i = {1}"", v, i); 
    } 
}
```
```java
//java
public void linq099(){
    final int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    final int[] i = {0};
    List<FunctionResult<Integer>> q =
        map(toList(numbers), new Function<Integer, FunctionResult<Integer>>() {
            @Override
            public FunctionResult<Integer> apply(Integer n) {
                return new FunctionResult<Integer>() {
                    @Override
                    public Integer apply() {
                        return ++i[0];
                    }
                };
            }
        });

    for (FunctionResult<Integer> f : q){
        Integer v = f.apply();
        Log.d(""v = "" + v + "", i = "" + i[0]);
    }
}
```
#### Output

    v = 1, i = 1
    v = 2, i = 2
    v = 3, i = 3
    v = 4, i = 4
    v = 5, i = 5
    v = 6, i = 6
    v = 7, i = 7
    v = 8, i = 8
    v = 9, i = 9
    v = 10, i = 10

### linq100: Immediate Execution
```csharp
//c#
public void Linq100() 
{ 
    // Methods like ToList() cause the query to be 
    // executed immediately, caching the results. 
  
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
  
    int i = 0; 
    var q = ( 
        from n in numbers 
        select ++i) 
        .ToList(); 
  
    // The local variable i has already been fully 
    // incremented before we iterate the results: 
    foreach (var v in q) 
    { 
        Console.WriteLine(""v = {0}, i = {1}"", v, i); 
    } 
} 
```
```java
//java
public void linq100(){
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    final int[] i = {0};
    List<Integer> q = map(toList(numbers), new Function<Integer, Integer>() {
        @Override
        public Integer apply(Integer n) {
            return ++i[0];
        }
    });

    for (Integer v : q){
        Log.d(""v = "" + v + "", i = "" + i[0]);
    }
}
```
#### Output

    v = 1, i = 10
    v = 2, i = 10
    v = 3, i = 10
    v = 4, i = 10
    v = 5, i = 10
    v = 6, i = 10
    v = 7, i = 10
    v = 8, i = 10
    v = 9, i = 10
    v = 10, i = 10

### linq101: Query Reuse
```csharp
//c#
public void Linq101() 
{ 
    // Deferred execution lets us define a query once 
    // and then reuse it later after data changes. 
  
    int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 }; 
    var lowNumbers = 
        from n in numbers 
        where n <= 3 
        select n; 
  
    Console.WriteLine(""First run numbers <= 3:""); 
    foreach (int n in lowNumbers) 
    { 
        Console.WriteLine(n); 
    } 
  
    for (int i = 0; i < 10; i++) 
    { 
        numbers[i] = -numbers[i]; 
    } 
  
    // During this second run, the same query object, 
    // lowNumbers, will be iterating over the new state 
    // of numbers[], producing different results: 
    Console.WriteLine(""Second run numbers <= 3:""); 
    foreach (int n in lowNumbers) 
    { 
        Console.WriteLine(n); 
    } 
} 
```
```java
//java
public void linq101(){
    final int[] numbers = new int[] { 5, 4, 1, 3, 9, 8, 6, 7, 2, 0 };

    FunctionResult<List<Integer>> lowNumbers =
        new FunctionResult<List<Integer>>() {
            @Override
            public List<Integer> apply() {
                return filter(toList(numbers), new Predicate<Integer>() {
                    @Override
                    public boolean apply(Integer n) {
                        return n <= 3;
                    }
                });
            }
        };

    Log.d(""First run numbers <= 3:"");
    for (Integer n : lowNumbers.apply()){
        Log.d(n);
    }

    for (int i = 0; i < 10; i++){
        numbers[i] = -numbers[i];
    }

    Log.d(""Second run numbers <= 3:"");
    for (Integer n : lowNumbers.apply()){
        Log.d(n);
    }
}
```
#### Output

    First run numbers <= 3:
    1
    3
    2
    0
    Second run numbers <= 3:
    -5
    -4
    -1
    -3
    -9
    -8
    -6
    -7
    -2
    0


LINQ - Join Operators
---------------------

### linq102: Cross Join
```csharp
//c#
public void Linq102() 
{ 
    string[] categories = new string[]{  
        ""Beverages"",   
        ""Condiments"",   
        ""Vegetables"",   
        ""Dairy Products"",   
        ""Seafood"" };  
  
    List<Product> products = GetProductList(); 
  
    var q = 
        from c in categories 
        join p in products on c equals p.Category 
        select new { Category = c, p.ProductName }; 
 
    foreach (var v in q) 
    { 
        Console.WriteLine(v.ProductName + "": "" + v.Category);  
    } 
}
```
```java
//java
public void linq102(){
    String[] categories = new String[]{
        ""Beverages"",
        ""Condiments"",
        ""Vegetables"",
        ""Dairy Products"",
        ""Seafood"" };

    List<Product> products = getProductList();

    List<Tuple<String, String>> q =
        map(
            join(toList(categories), products, new Predicate2<String, Product>() {
                @Override
                public boolean apply(String c, Product p) {
                    return c.equals(p.category);
                }
            }),
            new Function<Tuple<String, Product>, Tuple<String, String>>() {
                @Override
                public Tuple<String, String> apply(Tuple<String, Product> t) {
                    return new Tuple<>(t.A, t.B.productName);
                }
            }
        );

    for (Tuple<String,String> v : q){
        Log.d(v.A + "": "" + v.B);
    }
}
```
#### Output

    Beverages: Chai
    Beverages: Chang
    Beverages: Guaraná Fantástica
    Beverages: Sasquatch Ale
    Beverages: Steeleye Stout
    Beverages: Côte de Blaye
    Beverages: Chartreuse verte
    Beverages: Ipoh Coffee
    ...

### linq103: Group Join
```csharp
//c#
public void Linq103() 
{ 
    string[] categories = new string[]{  
        ""Beverages"",  
        ""Condiments"",  
        ""Vegetables"",  
        ""Dairy Products"",  
        ""Seafood"" }; 
  
    List<Product> products = GetProductList(); 
  
    var q = 
        from c in categories 
        join p in products on c equals p.Category into ps 
        select new { Category = c, Products = ps }; 
  
    foreach (var v in q) 
    { 
        Console.WriteLine(v.Category + "":""); 
        foreach (var p in v.Products) 
        { 
            Console.WriteLine(""   "" + p.ProductName); 
        } 
    } 
}
```
```java
//java
public void linq103(){
    String[] categories = new String[]{
        ""Beverages"",
        ""Condiments"",
        ""Vegetables"",
        ""Dairy Products"",
        ""Seafood"" };

    List<Product> products = getProductList();

    List<Tuple<String,ArrayList<Product>>> q =
        map(
            joinGroup(toList(categories), products, new Predicate2<String, Product>() {
                @Override
                public boolean apply(String c, Product p) {
                    return c.equals(p.category);
                }
            }),
            new Function<Group<String, Tuple<String, Product>>, Tuple<String, ArrayList<Product>>>() {
                @Override
                public Tuple<String, ArrayList<Product>> apply(Group<String, Tuple<String, Product>> g) {
                    return new Tuple<>(
                        g.key,
                        map(g.items, new Function<Tuple<String,Product>, Product>() {
                            @Override
                            public Product apply(Tuple<String, Product> t) {
                                return t.B;
                            }
                        })
                    );
                }
            }
        );

    for (Tuple<String,ArrayList<Product>> v : q){
        Log.d(v.A + "":"");
        for (Product p : v.B){
            Log.d(""   "" + p.productName);
        }
    }
}
```
#### Output

    Beverages:
       Chai
       Chang
       Guaraná Fantástica
       Sasquatch Ale
       Steeleye Stout
       Côte de Blaye
       Chartreuse verte
       Ipoh Coffee
       Laughing Lumberjack Lager
       Outback Lager
       Rhönbräu Klosterbier
       Lakkalikööri
    Seafood:
       Ikura
       Konbu
       Carnarvon Tigers
       Nord-Ost Matjeshering
       Inlagd Sill
       Gravad lax
       Boston Crab Meat
       Jack's New England Clam Chowder
       Rogede sild
       Spegesild
       Escargots de Bourgogne
       Röd Kaviar
    ...

### linq104: Cross Join with Group Join
```csharp
//c#
public void Linq104() 
{ 
    string[] categories = new string[]{   
        ""Beverages"",  
        ""Condiments"",  
        ""Vegetables"", 
        ""Dairy Products"",   
        ""Seafood"" }; 
  
    List<Product> products = GetProductList(); 
  
    var q = 
        from c in categories 
        join p in products on c equals p.Category into ps 
        from p in ps 
        select new { Category = c, p.ProductName }; 
  
    foreach (var v in q) 
    { 
        Console.WriteLine(v.ProductName + "": "" + v.Category); 
    } 
}
```
```java
//java
public void linq104(){
    String[] categories = new String[]{
        ""Beverages"",
        ""Condiments"",
        ""Vegetables"",
        ""Dairy Products"",
        ""Seafood"" };

    List<Product> products = getProductList();

    List<Tuple<String,String>> q =
        expand(
            map(
                joinGroup(toList(categories), products, new Predicate2<String, Product>() {
                    @Override
                    public boolean apply(String c, Product p) {
                        return c.equals(p.category);
                    }
                }),
                new Function<Group<String, Tuple<String, Product>>, List<Tuple<String, String>>>() {
                    @Override
                    public List<Tuple<String, String>> apply(Group<String, Tuple<String, Product>> g) {
                        return map(g.items, new Function<Tuple<String, Product>, Tuple<String, String>>() {
                            @Override
                            public Tuple<String, String> apply(Tuple<String, Product> t) {
                                return new Tuple<>(t.A, t.B.productName);
                            }
                        });
                    }
                }
            )
        );

    for (Tuple<String,String> v : q){
        Log.d(v.B + "": "" + v.A);
    }
}
```
#### Output

    Chai: Beverages
    Chang: Beverages
    Guaraná Fantástica: Beverages
    Sasquatch Ale: Beverages
    Steeleye Stout: Beverages
    Côte de Blaye: Beverages
    Chartreuse verte: Beverages
    Ipoh Coffee: Beverages
    Laughing Lumberjack Lager: Beverages
    Outback Lager: Beverages
    Rhönbräu Klosterbier: Beverages
    Lakkalikööri: Beverages
    Ikura: Seafood
    Konbu: Seafood
    Carnarvon Tigers: Seafood
    ...

### linq105: Left Outer Join
```csharp
//c#
public void Linq105()  
{ 
    string[] categories = new string[]{   
        ""Beverages"",  
        ""Condiments"",   
        ""Vegetables"",   
        ""Dairy Products"",  
        ""Seafood"" }; 
  
    List<Product> products = GetProductList(); 
  
    var q = 
        from c in categories 
        join p in products on c equals p.Category into ps 
        from p in ps.DefaultIfEmpty() 
        select new { Category = c, ProductName = p == null ? ""(No products)"" : p.ProductName }; 
  
    foreach (var v in q) 
    { 
        Console.WriteLine(v.ProductName + "": "" + v.Category); 
    } 
}
```
```java
//java
public void linq105(){
    String[] categories = new String[]{
        ""Beverages"",
        ""Condiments"",
        ""Vegetables"",
        ""Dairy Products"",
        ""Seafood"" };

    final List<Product> products = getProductList();

    List<Tuple<String,String>> q =
        expand(
            map(toList(categories), new Function<String, List<Tuple<String, String>>>() {
                @Override
                public List<Tuple<String, String>> apply(final String c) {
                    List<Product> catProducts = filter(products, new Predicate<Product>() {
                        @Override
                        public boolean apply(Product p) {
                            return c.equals(p.category);
                        }
                    });
                    return catProducts.isEmpty()
                        ? toList(new Tuple<>(c, ""(No products)""))
                        : map(catProducts, new Function<Product, Tuple<String, String>>() {
                        @Override
                        public Tuple<String, String> apply(Product p) {
                            return new Tuple<>(c, p.productName);
                        }
                    });
                }
            })
        );

    for (Tuple<String,String> v : q){
        Log.d(v.B + "": "" + v.A);
    }
}
```
#### Output

    Chai: Beverages
    Chang: Beverages
    Guaraná Fantástica: Beverages
    Sasquatch Ale: Beverages
    Steeleye Stout: Beverages
    Côte de Blaye: Beverages
    Chartreuse verte: Beverages
    Ipoh Coffee: Beverages
    Laughing Lumberjack Lager: Beverages
    Outback Lager: Beverages
    Rhönbräu Klosterbier: Beverages
    Lakkalikööri: Beverages
    Aniseed Syrup: Condiments
    Chef Anton's Cajun Seasoning: Condiments
    Chef Anton's Gumbo Mix: Condiments
    Grandma's Boysenberry Spread: Condiments
    Northwoods Cranberry Sauce: Condiments
    Genen Shouyu: Condiments
    Gula Malacca: Condiments
    Sirop d'érable: Condiments
    Vegie-spread: Condiments
    Louisiana Fiery Hot Pepper Sauce: Condiments
    Louisiana Hot Spiced Okra: Condiments
    Original Frankfurter grüne Soße: Condiments
    (No products): Vegetables
    ...


### Contributors

  - [mythz](https://github.com/mythz) (Demis Bellot)

"
cdklabs/aws-cdk-testing-examples,main,36,14,2021-11-05T17:50:10Z,1364,4,,,"## AWS CDK Testing Examples

This repository contains code examples in Python, Java, and TypeScript for the
Testing CDK Applications in Any Language blog post. These examples use the new
`assertions` module to unit test various parts of a CDK application.

To try these examples out yourself, follow the instructions for your language
in the [Getting started with the AWS CDK developer
guide](https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html), then
run the commands listed in the README.md of the appropriate subdirectory
(i.e. java/, python/, or typescript/).

For more information on the `assertions` module, refer to the [API
reference](https://docs.aws.amazon.com/cdk/api/latest/docs/assertions-readme.html).

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.

"
grro/stability,master,29,11,2014-09-11T14:06:58Z,428,0,code examples,,
Jerady/fontawesomefx-examples,master,56,8,2016-08-11T12:53:58Z,142,5,,,"# FontAwesomeFX Examples and Demo Applications

[Get the code here](https://github.com/Jerady/fontawesomefx-demoapps)

## Basic Usage

```
FontAwesomeIconView fontAwesomeIconView = 
  new FontAwesomeIconView(FontAwesomeIcon.ANGELLIST);
```
![](images/basic_1.png)

```
MaterialDesignIconView materialDesignIconView = 
  new MaterialDesignIconView(MaterialDesignIcon.THUMB_UP);
  materialDesignIconView.setSize(""4em"");
```

### Run BasicGlyphsApp demo

`./gradlew -PmainClass=de.jensd.fx.glyphs.demo.apps.BasicGlyphsApp execute`

## Basic Usage using Factories
```
Text fontAwesomeIcon =
  FontAwesomeIconFactory.get().createIcon(FontAwesomeIcon.ANGELLIST);
        root.getChildren().add(fontAwesomeIcon);
```
```
Text materialDesignIcon =
  MaterialDesignIconFactory.get().createIcon(MaterialDesignIcon.CHECK_ALL, ""4em"");
  root.getChildren().add(materialDesignIcon);
```

### Run BasicGlyphsFactoryApp demo

`./gradlew -PmainClass=de.jensd.fx.glyphs.demo.apps.BasicGlyphsApp execute`


## CSS Styled Glyphs

```
FontAwesomeIconView thumbsUpIcon = new FontAwesomeIconView();
thumbsUpIcon.setStyleClass(""thumbs-up-icon"");
root.getChildren().add(thumbsUpIcon);
```

```
FontAwesomeIconView thumbsDownIcon = new FontAwesomeIconView();
thumbsDownIcon.setStyleClass(""thumbs-down-icon"");
root.getChildren().add(thumbsDownIcon);
```

```
WeatherIconView blueskyIcon = new WeatherIconView();
blueskyIcon.setStyleClass(""bluesky-icon"");
root.getChildren().add(blueskyIcon);
```
![](images/css_style_2.png)

####styles/glyphs.css

```
.root{
    -icons-color: black;
}

.glyph-icon{
    -fx-text-fill: -icons-color;
    -fx-fill: -icons-color;
    -glyph-size: 48px;
}

.glyph-icon:hover{
    -fx-effect:  dropshadow(three-pass-box, rgba(0,0,0,0.2), 4, 0, 0, 0);
}

.bluesky-icon{
    -glyph-name: ""CLOUD"";
    -icons-color: blue;
    -fx-fill: linear-gradient(-icons-color 0%, 
        derive(-icons-color, 100%) 30%, derive(blueviolet, 30%) 85%);
}

.bluesky-icon:hover{
    -glyph-name: ""CLOUDY"";
    -icons-color: yellowgreen;
    -fx-effect:  dropshadow(three-pass-box, 
        rgba(156,115,241,0.6), 10, 0, 0, 0);
}

.bluesky-icon:pressed{
    -glyph-name: ""DAY_CLOUDY"";
    -icons-color: yellow;
    -fx-effect:  dropshadow(three-pass-box, 
        rgba(0,0,0,1.0), 10, 0, 0, 0);
}


.thumbs-up-icon{
    -glyph-name: ""THUMBS_UP"";
    -icons-color: yellowgreen;
}
.thumbs-up-icon:hover{
    -fx-effect:  dropshadow(three-pass-box, rgba(154,205,55,0.7), 10, 0, 0, 0);
}

.thumbs-up-icon:pressed{
    -fx-effect:  dropshadow(three-pass-box, rgba(0,0,0,1.0), 10, 0, 0, 0);
}

.thumbs-down-icon{
    -glyph-name: ""THUMBS_DOWN"";
    -icons-color: red;
}

.thumbs-down-icon:hover{
    -fx-effect:  dropshadow(three-pass-box, rgba(255,0,0,0.7), 10, 0, 0, 0);
}

.thumbs-down-icon:pressed{
    -fx-effect:  dropshadow(three-pass-box, rgba(0,0,0,1.0), 10, 0, 0, 0);
}

.android-icon{
    -icons-color: yellowgreen;
    -fx-fill: linear-gradient(-icons-color 0%, derive(yellowgreen, 30%) 85%);
    -fx-effect:  dropshadow(three-pass-box, rgba(0,0,0,1.0), 10, 0, 0, 0);
}
```
![](images/css_style_1.png)

### Run CssStyledGlyphsApp demo

`./gradlew -PmainClass=de.jensd.fx.glyphs.demo.apps.CssStyledGlyphsApp execute`

## CSS Styled Glyphs using Factories

```
Text thumbsUpIcon =
  FontAwesomeIconFactory.get().createIcon(FontAwesomeIcon.THUMBS_UP, ""4em"");
  thumbsUpIcon.getStyleClass().add(""thumbs-up-icon"");
  root.getChildren().add(thumbsUpIcon);
```
```
Text thumbsDownIcon =
  FontAwesomeIconFactory.get().createIcon(FontAwesomeIcon.THUMBS_DOWN, ""4em"");
  thumbsDownIcon.getStyleClass().add(""thumbs-down-icon"");
  root.getChildren().add(thumbsDownIcon);
```
```
Text blueskyIcon = 
  WeatherIconFactory.get().createIcon(WeatherIcon.CLOUDY, ""4em"");
  blueskyIcon.getStyleClass().add(""bluesky-icon"");
  root.getChildren().add(blueskyIcon);
```

### Run CssStylesBasicGlyphsFactoryApp demo

`./gradlew -PmainClass=de.jensd.fx.glyphs.demo.apps. CssStylesBasicGlyphsFactoryApp execute`"
lokeshgupta1981/Spring-Boot3-Demos,main,31,26,2022-11-17T12:44:14Z,178,0,Spring Boot 3 Demo Projects and Examples,,"# Spring Boot3 Demos
 Spring Boot 3 Demo Projects and Examples
"
vitaly-chibrikov/tp_java_2015_02,master,26,50,2015-02-13T16:32:08Z,320,1,"Code examples for course Java Programming"" in https://tech-mail.ru/""",,"# tp_java_2015_02
Code examples for course ""Java Programming"" in https://tech-mail.ru/
"
foo4u/keycloak-spring-demo,master,58,32,2015-04-28T19:02:04Z,208,1,Examples demonstrating how to use the Keycloak Spring Security adapter,,"# Keycloak Spring Security Examples

Demonstrates how to use the Keycloak Spring Security adapter, including:

* Login
* Distributed SSO
* Distributed Logout
* OAuth2 Bearer Tokens

## Requirements

The following examples are standalone Spring Boot applications.

They require the Keycloak appliance 1.2.0, running locally on port 8080 (the default for the
standalone appliance).

There are multiple Spring Boot projects.  These will all run on independently on the localhost
listening on differnt ports.

* **customer-app** A Spring Boot application that does remote login using OAuth2 browser redirects with the auth server
* **product-app** A Spring Boot application that does remote login using OAuth2 browser redirects with the auth server
* **database-service** A Spring Boot RESTful application service authenticated by bearer tokens only. The customer and product app invoke it to get data.


### Step 1: Make sure you've set up the Keycloak Server

The Keycloak Appliance Distribution comes with a preconfigured Keycloak server (based on Wildfly).  You must use it this server to run the Spring Security demos.  

### Step 2: Boot Keycloak Server

Where you go to start up the Keycloak Server depends on which distro you installed.

From appliance:

```
$ cd keycloak/bin
$ ./standalone.sh
```

### Step 3: Import the Test Realm

Import the test realm for the demo.  Clicking on the below link will bring you to the
create realm page in the Admin UI.  The username/password is admin/admin to login in.  Keycloak will ask you to create a new admin password before you can go to the create 
realm page.

http://localhost:8080/auth/admin/master/console/#/create/realm

Import the spring-demo-realm.json file that is in this project's root directory.


### Step 4: Build and deploy

Launch each application (use a new terminal for each application):

```
$ ./gradlew database-service:bootRun
$ ./gradlew customer-app:bootRun
$ ./gradlew product-app:bootRun
```

### Step 5: Login and Observe Apps

Try going to the customer app and view customer data:

http://localhost:9092/customer-portal/

This should take you to the auth-server login screen.  Enter username: srossillo and password: password.

If you click on the products link, you'll be taken to the products app and show a product listing.  The redirects
are still happening, but the auth-server knows you are already logged in so the login is bypassed.

If you click on the logout link of either of the product or customer app, you'll be logged out of all the applications.


## Admin Console

http://localhost:8080/auth/admin/index.html
"
ddd-by-examples/factory,master,1325,276,2017-12-04T07:53:57Z,9782,3,"The missing, complete example of Domain-Driven Design enterprise application backed by Spring stack",aggregate cqrs crud domain-driven-design domain-events domain-knowledge domain-model enterprise-applications event-storming hexagon invariants ports-and-adapters,"# The missing, complete example of Domain-Driven Design enterprise application

[![Licence MIT](http://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Build Status](https://travis-ci.org/ddd-by-examples/factory.svg?branch=master)](https://travis-ci.org/ddd-by-examples/factory)
[![Code Coverage](https://codecov.io/gh/ddd-by-examples/factory/branch/master/graph/badge.svg)](https://codecov.io/gh/ddd-by-examples/factory)

## Command Query CRUD Responsibility Segregation
Not every piece of software is equally important...
Not every piece will decide about company / product success or can cause not reversible
negative business consequences like materialise brand risk or money loses.
On the other hand scalability or non functional requirements are different for different activities in software.

To accommodate to those differences, separate architectural patterns are applied:

![Command Query CRUD Responsibility Segregation](command-query-crud.png)

**Simple Create Read Update Delete functionality** are exposed with leverage of CRUD framework.

Goals of that approach:
- fast initial development,
- fast respond to typical changes (ex. „please add another 2 fields on UI”),
- exposure of high quality API.

Examples in code:
- CRUD-able document [ProductDescription](product-management-adapters/src/main/java/io/dddbyexamples/factory/product/management/ProductDescription.java)
- persistence of document [ProductDescriptionEntity](product-management-adapters/src/main/java/io/dddbyexamples/factory/product/management/ProductDescriptionEntity.java)
- CRUD exposed as DAO and REST endpoint [ProductDescriptionDao](product-management-adapters/src/main/java/io/dddbyexamples/factory/product/management/ProductDescriptionDao.java)

**Complex Commands (business processing)** expressed in Domain Model which is embedded in hexagonal architecture.

Goals of that approach:
- enable approach with implementing the Domain Model in the first place, by adding infrastructure adapters later,
- keeping the Domain Model as simple as possible by protecting it from accidental complexity
caused by technological choices or transport models from external services / contexts,
- make the core business of application technology agnostic, enabling continues technology
migration and keeping long living projects up to date with fast evolving frameworks and libraries.

Examples of Domain Model in code:
- aggregate [ProductDemand](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/ProductDemand.java)
- entity [DailyDemand](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/DailyDemand.java)
- value object [Adjustment](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/Adjustment.java)
- policy [ReviewPolicy](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/ReviewPolicy.java)
- domain event [DemandedLevelsChanged](shared-kernel-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/DemandedLevelsChanged.java)

Examples of Ports in code:
- application service (primary port) [DemandService](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/DemandService.java)
- repository (secondary port) [ProductDemandRepository](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/ProductDemandRepository.java)
- domain events handling (secondary port) [DemandEvents](demand-forecasting-model/src/main/java/io/dddbyexamples/factory/demand/forecasting/DemandEvents.java)

Examples of Adapters in code:
- REST endpoint for complex command (driving adapter)
  - command resource [DemandAdjustmentDao](demand-forecasting-adapters/src/main/java/io/dddbyexamples/factory/demand/forecasting/command/DemandAdjustmentDao.java)
  - command handler [CommandsHandler](demand-forecasting-adapters/src/main/java/io/dddbyexamples/factory/demand/forecasting/command/CommandsHandler.java)
- repository implementation (driven adapter) [ProductDemandORMRepository](demand-forecasting-adapters/src/main/java/io/dddbyexamples/factory/demand/forecasting/ProductDemandORMRepository.java)
- events propagation (driven adapter) [DemandEventsPropagation](app-monolith/src/main/java/io/dddbyexamples/factory/demand/forecasting/DemandEventsPropagation.java)

**Complex Query** implemented as direct and simple as possible by:
- fetching persistent read model expected by consumer, the read model is a projection of past domain event,
- read model composed at query execution time build directly from persistent form of Domain Model,
- mix of above: read model composed at query execution time build from pre-calculated persistent projections of domain event.

Additional complex calculations or projections can be partially delegated to the Domain Model if desired.

Goals of that approach:
- encapsulation of the Domain Model complexity by providing (simpler) consumer driven or published language API,
- freeing the Domain Model from exposing data for reads making the Domain Model simpler,
- improves reads performance and enable horizontal scalability.

Examples in code:
- projection of domain events to persistent read model [DeliveryForecastProjection](demand-forecasting-adapters/src/main/java/io/dddbyexamples/factory/delivery/planning/projection/DeliveryForecastProjection.java)
- REST endpoint for persistent read model [DeliveryForecastDao](demand-forecasting-adapters/src/main/java/io/dddbyexamples/factory/delivery/planning/projection/DeliveryForecastDao.java)
- read model composed at query execution time [StockForecastQuery](app-monolith/src/main/java/io/dddbyexamples/factory/stock/forecast/StockForecastQuery.java)
- REST resource processor for NOT persistent read model [StockForecastResourceProcessor](app-monolith/src/main/java/io/dddbyexamples/factory/stock/forecast/ressource/StockForecastResourceProcessor.java)

## Hexagonal Architecture
Only the most valuable part of that enterprise software is embedded in hexagonal architecture -
complex business processing modeled in form of the Domain Model.

![Domain Model embedded in hexagonal architecture](hexagon.png)

**Application Services** - providing entry point to Domain Model functionality,
Application Services are ports for Primary / Driving Adapters like RESTfull endpoints.

**Domain Model** - Object Oriented (in that case) piece of software modeling business rules, invariants,
calculations and processing variants.
Thanks to hexagon can be as clean and simple as possible - separating essential complexity of pure business
from accidental complexity of technical choices, free of technical and convention constraints.

**Ports** - contract defined by Domain Model expressing expectations from external resources (services, database or other models).
Declared interfaces alongside with IN-OUT parameters are Ports for Secondary / Driven Adapters like repository implementation.

**Adapters** - integration of the technology (REST, database, external services, etc.) with the Domain Model.
Making useful application from the Domain Model and the technology.


## Implementing Domain Model in the first place
In most projects the biggest risk is lack of domain knowledge among developers. We all known Java,
databases and bunch of handy frameworks, but what about: Investment Banking, Automotive Manufacturing or even e-Commerce.

Let's face the risk at first, maintain and explore domain knowledge
with **Model Exploration Whirlpool** and build **Ubiquitous Language** with your executable **Domain Model**,
**Domain Stories** and **Specification by Examples** from day one.
Adding infrastructure and technology later is easy thanks to Hexagonal Architecture.

Simply starting from ZERO business knowledge through initial domain and opportunity exploration with **Big Picture Event Storming**:
![Big Picture Event Storming](es-big-picture-original.jpg)

after cleaning and trimming initial model to most valuable and needed areas: 
![Big Picture Event Storming](es-big-picture-cleaned.jpg)

Deep dive in **Demand Forecasting** sub-domain with **Design Level Event Storming**:
![Design Level Event Storming - Demand Forecasting](es-design-demand-forecasting.jpg)

is excellent canvas to cooperative exploration of:
- impacted and required actors,
- initial / desired system boundaries,
- actors interactions with system under design.

With use of **Domain Stories** and **Specification by Examples** it is easy to find:
- business rules and invariants,
- acceptance criteria,
- estimation of Domain Model depth,
- CRUD-suspected activities,
- missing parts.
"
sunrenjie/jpwh-2e-examples,master,25,17,2016-01-08T02:52:07Z,663,3,"Sample code from the book Java Persistence with Hibernate, Second Edition",,
shoothzj/pulsar-client-examples,main,37,11,2021-10-23T03:02:38Z,106,0,,,"# pulsar-client-examples
描述了一些Pulsar客户端编码相关的最佳实践，并提供了可商用的样例代码，供大家研发的时候参考，提升大家接入Pulsar的效率。在生产环境上，Pulsar的地址信息往往都通过配置中心或者是k8s域名发现的方式获得，这块不是这篇文章描述的重点，以`PulsarConstant.SERVICE_HTTP_URL`代替。本文中的例子均已上传到[github](https://github.com/Shoothzj/pulsar-client-examples)

## Client初始化和配置

### 初始化Client--demo级别

```java
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.PulsarClient;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarClientInit {

    private static final PulsarClientInit INSTANCE = new PulsarClientInit();

    private PulsarClient pulsarClient;

    public static PulsarClientInit getInstance() {
        return INSTANCE;
    }

    public void init() throws Exception {
        pulsarClient = PulsarClient.builder()
                .serviceUrl(PulsarConstant.SERVICE_HTTP_URL)
                .build();
    }

    public PulsarClient getPulsarClient() {
        return pulsarClient;
    }
}
```

demo级别的Pulsar client初始化的时候没有配置任何自定义参数，并且初始化的时候没有考虑异常，`init`的时候会直接抛出异常。

### 初始化Client--可上线级别

```java
import io.netty.util.concurrent.DefaultThreadFactory;
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.PulsarClient;

import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarClientInitRetry {

    private static final PulsarClientInitRetry INSTANCE = new PulsarClientInitRetry();

    private volatile PulsarClient pulsarClient;

    private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1, new DefaultThreadFactory(""pulsar-cli-init""));

    public static PulsarClientInitRetry getInstance() {
        return INSTANCE;
    }

    public void init() {
        executorService.scheduleWithFixedDelay(this::initWithRetry, 0, 10, TimeUnit.SECONDS);
    }

    private void initWithRetry() {
        try {
            pulsarClient = PulsarClient.builder()
                    .serviceUrl(PulsarConstant.SERVICE_HTTP_URL)
                    .build();
            log.info(""pulsar client init success"");
            this.executorService.shutdown();
        } catch (Exception e) {
            log.error(""init pulsar error, exception is "", e);
        }
    }

    public PulsarClient getPulsarClient() {
        return pulsarClient;
    }

}
```



在实际的环境中，我们往往要做到`pulsar client`初始化失败后不影响微服务的启动，即待微服务启动后，再一直重试创建`pulsar client`。<br/>
上面的代码示例通过`volatile`加不断循环重建实现了这一目标，并且在客户端成功创建后，销毁了定时器线程。

### 初始化Client--商用级别

```java
import io.netty.util.concurrent.DefaultThreadFactory;
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.PulsarClient;
import org.apache.pulsar.client.api.SizeUnit;

import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarClientInitUltimate {

    private static final PulsarClientInitUltimate INSTANCE = new PulsarClientInitUltimate();

    private volatile PulsarClient pulsarClient;

    private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1, new DefaultThreadFactory(""pulsar-cli-init""));

    public static PulsarClientInitUltimate getInstance() {
        return INSTANCE;
    }

    public void init() {
        executorService.scheduleWithFixedDelay(this::initWithRetry, 0, 10, TimeUnit.SECONDS);
    }

    private void initWithRetry() {
        try {
            pulsarClient = PulsarClient.builder()
                    .serviceUrl(PulsarConstant.SERVICE_HTTP_URL)
                    .ioThreads(4)
                    .listenerThreads(10)
                    .memoryLimit(64, SizeUnit.MEGA_BYTES)
                    .operationTimeout(5, TimeUnit.SECONDS)
                    .connectionTimeout(15, TimeUnit.SECONDS)
                    .build();
            log.info(""pulsar client init success"");
            this.executorService.shutdown();
        } catch (Exception e) {
            log.error(""init pulsar error, exception is "", e);
        }
    }

    public PulsarClient getPulsarClient() {
        return pulsarClient;
    }

}
```

商用级别的`Pulsar Client`新增了5个配置参数：

- **ioThreads** netty的ioThreads负责网络IO操作，如果业务流量较大，可以调高`ioThreads`个数；
- **listenersThreads** 负责调用以`listener`模式启动的消费者的回调函数，建议配置大于该client负责的`partition`数目；
- **memoryLimit** 当前用于限制`pulsar`生产者可用的最大内存，可以很好地防止网络中断、pulsar故障等场景下，消息积压在`producer`侧，导致java程序OOM；
- **operationTimeout** 一些元数据操作的超时时间，Pulsar默认为30s，有些保守，可以根据自己的网络情况、处理性能来适当调低；
- **connectionTimeout** 连接Pulsar的超时时间，配置原则同上。

### 客户端进阶参数（内存分配相关）

我们还可以通过传递java的property来控制Pulsar客户端内存分配的参数，这里列举几个重要参数

- **pulsar.allocator.pooled** 为true则使用堆外内存池，false则使用堆内存分配，不走内存池。默认使用高效的堆外内存池
- **pulsar.allocator.exit_on_oom** 如果内存溢出，是否关闭**jvm**，默认为false
- **pulsar.allocator.out_of_memory_policy** 在https://github.com/apache/pulsar/pull/12200 引入，用于配置当堆外内存不够使用时的行为，可选项为`FallbackToHeap`和`ThrowException`，默认为`FallbackToHeap`，如果你不希望消息序列化的内存影响到堆内存分配，则可以配置成`ThrowException`

## 生产者

### 初始化producer重要参数

#### maxPendingMessages
生产者消息发送队列，根据实际topic的量级合理配置，避免在网络中断、Pulsar故障场景下的OOM。建议和client侧的配置`memoryLimit`之间挑一个进行配置。

### messageRoutingMode

消息路由模式。默认为`RoundRobinPartition`。根据业务需求选择，如果需要保序，通常的做法是在向`Pulsar`发送消息时传递`key`值，这时就会根据`key`来选择要发送到的`partition`。如果有更复杂的保序场景，也可以自定义分发partition的策略。


#### autoUpdatePartition

自动更新partition信息。如`topic`中`partition`信息不变则不需要配置，降低集群的消耗。

#### batch相关参数

因为批量发送模式底层由定时任务实现，如果该topic上消息数较小，则不建议开启`batch`。尤其是大量的低时间间隔的定时任务会导致netty线程CPU飙高。

- **enableBatching** 是否启用批量发送
- **batchingMaxMessages** 批量发送最大消息条数
- **batchingMaxPublishDelay** 批量发送定时任务间隔

### 静态producer初始化

静态producer，指不会随着业务的变化进行producer的启动或关闭。那么就在微服务启动完成、client初始化完成之后，初始化producer，样例如下：

#### 一个生产者一个线程，适用于生产者数目较少的场景

```java
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.Producer;

import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarStaticProducerInit {

    private final ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(""pulsar-producer-init"").build();

    private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1, threadFactory);

    private final String topic;

    private volatile Producer<byte[]> producer;

    public PulsarStaticProducerInit(String topic) {
        this.topic = topic;
    }

    public void init() {
        executorService.scheduleWithFixedDelay(this::initWithRetry, 0, 10, TimeUnit.SECONDS);
    }

    private void initWithRetry() {
        try {
            final PulsarClientInit instance = PulsarClientInit.getInstance();
            producer = instance.getPulsarClient().newProducer().topic(topic).create();
            executorService.shutdown();
        } catch (Exception e) {
            log.error(""init pulsar producer error, exception is "", e);
        }
    }

    public Producer<byte[]> getProducer() {
        return producer;
    }

}
```

#### 多个生产者一个线程，适用于生产者数目较多的场景
```java
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.Producer;

import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarStaticProducersInit {

    private final ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(""pulsar-producers-init"").build();

    private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1, threadFactory);

    private final Map<String, Producer<byte[]>> producerMap = new ConcurrentHashMap<>();

    private int initIndex = 0;

    private final List<String> topics;

    public PulsarStaticProducersInit(List<String> topics) {
        this.topics = topics;
    }

    public void init() {
        executorService.scheduleWithFixedDelay(this::initWithRetry, 0, 10, TimeUnit.SECONDS);
    }

    private void initWithRetry() {
        if (initIndex == topics.size()) {
            executorService.shutdown();
            return;
        }
        for (; initIndex < topics.size(); initIndex++) {
            try {
                final PulsarClientInit instance = PulsarClientInit.getInstance();
                final Producer<byte[]> producer = instance.getPulsarClient().newProducer().topic(topics.get(initIndex)).create();
                producerMap.put(topics.get(initIndex), producer);
            } catch (Exception e) {
                log.error(""init pulsar producer error, exception is "", e);
                break;
            }
        }
    }

    public Producer<byte[]> getProducers(String topic) {
        return producerMap.get(topic);
    }

}
```

### 动态生成销毁的producer示例

还有一些业务，我们的producer可能会根据业务来进行动态的启动或销毁，如接收道路上车辆的数据，并发送给指定的topic。我们不会让内存里面驻留所有的producer，这会导致占用大量的内存，我们可以采用类似于LRU Cache的方式来管理producer的生命周期。

```java
/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarDynamicProducerFactory {

    /**
     * topic -- producer
     */
    private AsyncLoadingCache<String, Producer<byte[]>> producerCache;

    public PulsarDynamicProducerFactory() {
        this.producerCache = Caffeine.newBuilder()
                .expireAfterAccess(600, TimeUnit.SECONDS)
                .maximumSize(3000)
                .removalListener((RemovalListener<String, Producer<byte[]>>) (topic, value, cause) -> {
                    log.info(""topic {} cache removed, because of {}"", topic, cause);
                    try {
                        value.close();
                    } catch (Exception e) {
                        log.error(""close failed, "", e);
                    }
                })
                .buildAsync(new AsyncCacheLoader<>() {
                    @Override
                    public CompletableFuture<Producer<byte[]>> asyncLoad(String topic, Executor executor) {
                        return acquireFuture(topic);
                    }

                    @Override
                    public CompletableFuture<Producer<byte[]>> asyncReload(String topic, Producer<byte[]> oldValue,
                                                                           Executor executor) {
                        return acquireFuture(topic);
                    }
                });
    }

    private CompletableFuture<Producer<byte[]>> acquireFuture(String topic) {
        CompletableFuture<Producer<byte[]>> future = new CompletableFuture<>();
        try {
            ProducerBuilder<byte[]> builder = DemoPulsarClientInit.getInstance().getPulsarClient().newProducer().enableBatching(true);
            final Producer<byte[]> producer = builder.topic(topic).create();
            future.complete(producer);
        } catch (Exception e) {
            log.error(""create producer exception "", e);
            future.completeExceptionally(e);
        }
        return future;
    }

}
```

这个模式下，可以根据返回的`CompletableFuture<Producer<byte[]>>`来优雅地进行流式处理。

### 可以接受消息丢失的发送

```java
    public void sendMsg(String topic, byte[] msg) {
        final CompletableFuture<Producer<byte[]>> cacheFuture = producerCache.get(topic);
        cacheFuture.whenComplete((producer, e) -> {
            if (e != null) {
                log.error(""create pulsar client exception "", e);
                return;
            }
            try {
                producer.sendAsync(msg).whenComplete(((messageId, throwable) -> {
                    if (throwable == null) {
                        log.info(""topic {} send success, msg id is {}"", topic, messageId);
                        return;
                    }
                    log.error(""send producer msg error "", throwable);
                }));
            } catch (Exception ex) {
                log.error(""send async failed "", ex);
            }
        });
    }
```

以上为正确处理`Client`创建失败和发送失败的回调函数。但是由于在生产环境下，pulsar并不是一直保持可用的，会因为虚拟机故障、pulsar服务升级等导致发送失败。这个时候如果要保证消息发送成功，就需要对消息发送进行重试。

### 可以容忍极端场景下的发送丢失

```java
    private final Timer timer = new HashedWheelTimer();

    public void sendMsgWithRetry(String topic, byte[] msg, int retryTimes, int maxRetryTimes) {
        final CompletableFuture<Producer<byte[]>> cacheFuture = producerCache.get(topic);
        cacheFuture.whenComplete((producer, e) -> {
            if (e != null) {
                log.error(""create pulsar client exception "", e);
                return;
            }
            try {
                producer.sendAsync(msg).whenComplete(((messageId, throwable) -> {
                    if (throwable == null) {
                        log.info(""topic {} send success, msg id is {}"", topic, messageId);
                        return;
                    }
                    if (retryTimes < maxRetryTimes) {
                        log.warn(""topic {} send failed, begin to retry {} times exception is "", topic, retryTimes, throwable);
                        timer.newTimeout(timeout -> PulsarDynamicProducerFactory.this.sendMsgWithRetry(topic, msg, retryTimes + 1, maxRetryTimes), 1L << retryTimes, TimeUnit.SECONDS);
                    }
                    log.error(""send producer msg error "", throwable);
                }));
            } catch (Exception ex) {
                log.error(""send async failed "", ex);
            }
        });
    }
```

这里在发送失败后，做了退避重试，可以容忍`pulsar`服务端故障一段时间。比如退避7次、初次间隔为1s，那么就可以容忍`1+2+4+8+16+32+64=127s`的故障。这已经足够满足大部分生产环境的要求了。<br/>
因为理论上存在超过127s的故障，所以还是要在极端场景下，向上游返回失败。

### 生产者Partition级别严格保序

生产者严格保序的要点：一次只发送一条消息，确认发送成功后再发送下一条消息。实现上可以使用同步异步两种模式：

- 同步模式的要点就是循环发送，直到上一条消息发送成功后，再启动下一条消息发送
- 异步模式的要点是观测上一条消息发送的future，如果失败也一直重试，成功则启动下一条消息发送

值得一提的是，这个模式下，partition间是可以并行的，可以使用`OrderedExecutor`或`per partition per thread`

同步模式举例：

```java
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.MessageId;
import org.apache.pulsar.client.api.Producer;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarProducerSyncStrictlyOrdered {

    Producer<byte[]> producer;

    public void sendMsg(byte[] msg) {
        while (true) {
            try {
                final MessageId messageId = producer.send(msg);
                log.info(""topic {} send success, msg id is {}"", producer.getTopic(), messageId);
                break;
            } catch (Exception e) {
                log.error(""exception is "", e);
            }
        }
    }

}
```



## 消费者

### 初始化消费者重要参数

#### receiverQueueSize

注意：处理不过来时，消费缓冲队列会积压在内存中，合理配置防止OOM。如果服务的CPU比较健康，但是性能上不来，同时`receiverQueueSize`配置地也相对较小（如小于2*TPS），那么就可以考虑增大`receiverQueueSize`。

#### autoUpdatePartition

自动更新partition信息。如`topic`中`partition`信息不变则不需要配置，降低集群的消耗。

#### subscriptionType

订阅类型，根据业务需求决定。

#### subscriptionInitialPosition

订阅开始的位置，根据业务需求决定放到最前或者最后。

#### messageListener

使用listener模式消费，只需要提供回调函数，不需要主动执行`receive()`拉取。一般没有特殊诉求，建议采用listener模式。

#### ackTimeout

当服务端推送消息，但消费者未及时回复ack，经过ackTimeout后，会重新推送给消费者处理，即`redeliver`机制。<br/>
注意在利用`redeliver`机制的时候，一定要注意仅仅使用重试机制来重试可恢复的错误。举个例子，如果代码里面对消息进行解码，解码失败就不适合利用`redeliver`机制。这会导致客户端一直处于重试之中。

如果拿捏不准，还可以通过下面的`deadLetterPolicy`配置死信队列，防止消息一直重试。

#### negativeAckRedeliveryDelay

当客户端调用`negativeAcknowledge`时，触发`redeliver`机制的时间。`redeliver`机制的注意点同`ackTimeout`。

需要注意的是, `ackTimeout`和`negativeAckRedeliveryDelay`建议不要同时使用，一般建议使用`negativeAck`，用户可以有更灵活的控制权。一旦`ackTimeout`配置的不合理，在消费时间不确定的情况下可能会导致消息不必要的重试。

#### deadLetterPolicy

配置`redeliver`的最大次数和死信topic。


### 初始化消费者原则

消费者只有创建成功才能工作，不像生产者可以向上游返回失败，所以消费者要一直重试创建。示例代码如下：
注意：消费者和topic可以是一对多的关系，消费者可以订阅多个topic。

#### 一个消费者一个线程，适用于消费者数目较少的场景
```java
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.Consumer;

import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarConsumerInit {

    private final ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(""pulsar-consumer-init"").build();

    private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1, threadFactory);

    private final String topic;

    private volatile Consumer<byte[]> consumer;

    public PulsarConsumerInit(String topic) {
        this.topic = topic;
    }

    public void init() {
        executorService.scheduleWithFixedDelay(this::initWithRetry, 0, 10, TimeUnit.SECONDS);
    }

    private void initWithRetry() {
        try {
            final PulsarClientInit instance = PulsarClientInit.getInstance();
            consumer = instance.getPulsarClient().newConsumer().topic(topic).messageListener(new DummyMessageListener<>()).subscribe();
            executorService.shutdown();
        } catch (Exception e) {
            log.error(""init pulsar producer error, exception is "", e);
        }
    }

    public Consumer<byte[]> getConsumer() {
        return consumer;
    }
}
```

#### 多个消费者一个线程，适用于消费者数目较多的场景
```java
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import lombok.extern.slf4j.Slf4j;
import org.apache.pulsar.client.api.Consumer;

import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;

/**
 * @author hezhangjian
 */
@Slf4j
public class PulsarConsumersInit {

    private final ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(""pulsar-consumers-init"").build();

    private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1, threadFactory);

    private final Map<String, Consumer<byte[]>> consumerMap = new ConcurrentHashMap<>();

    private int initIndex = 0;

    private final List<String> topics;

    public PulsarConsumersInit(List<String> topics) {
        this.topics = topics;
    }

    public void init() {
        executorService.scheduleWithFixedDelay(this::initWithRetry, 0, 10, TimeUnit.SECONDS);
    }

    private void initWithRetry() {
        if (initIndex == topics.size()) {
            executorService.shutdown();
            return;
        }
        for (; initIndex < topics.size(); initIndex++) {
            try {
                final PulsarClientInit instance = PulsarClientInit.getInstance();
                final Consumer<byte[]> consumer = instance.getPulsarClient().newConsumer().topic(topics.get(initIndex)).messageListener(new DummyMessageListener<>()).subscribe();
                consumerMap.put(topics.get(initIndex), consumer);
            } catch (Exception e) {
                log.error(""init pulsar producer error, exception is "", e);
                break;
            }
        }
    }

    public Consumer<byte[]> getConsumer(String topic) {
        return consumerMap.get(topic);
    }
}
```

### 消费者达到至少一次语义

使用手动回复ack模式，确保处理成功后再ack。如果处理失败可以自己重试或通过`negativeAck`机制进行重试

#### 同步模式举例

这里需要注意，如果处理消息时长差距比较大，同步处理的方式可能会让本来可以很快处理的消息得不到处理的机会。

```java
/**
 * @author hezhangjian
 */
@Slf4j
public class MessageListenerSyncAtLeastOnce<T> implements MessageListener<T> {

    @Override
    public void received(Consumer<T> consumer, Message<T> msg) {
        try {
            final boolean result = syncPayload(msg.getData());
            if (result) {
                consumer.acknowledgeAsync(msg);
            } else {
                consumer.negativeAcknowledge(msg);
            }
        } catch (Exception e) {
            // 业务方法可能会抛出异常
            log.error(""exception is "", e);
            consumer.negativeAcknowledge(msg);
        }
    }

    /**
     * 模拟同步执行的业务方法
     * @param msg 消息体内容
     * @return
     */
    private boolean syncPayload(byte[] msg) {
        return System.currentTimeMillis() % 2 == 0;
    }

}
```

#### 异步模式举例

异步的话需要考虑内存的限制，因为异步的方式可以很快地从`broker`消费，不会被业务操作阻塞，这样 **inflight** 的消息可能会非常多。如果是`Shared`或`KeyShared`模式，可以通过`maxUnAckedMessage`进行限制。如果是`Failover`模式，可以通过下面的`消费者繁忙时阻塞拉取消息，不再进行业务处理`通过判断**inflight**消息数来阻塞处理。

```java
/**
 * @author hezhangjian
 */
@Slf4j
public class MessageListenerAsyncAtLeastOnce<T> implements MessageListener<T> {

    @Override
    public void received(Consumer<T> consumer, Message<T> msg) {
        try {
            asyncPayload(msg.getData(), new DemoSendCallback() {
                @Override
                public void callback(Exception e) {
                    if (e == null) {
                        consumer.acknowledgeAsync(msg);
                    } else {
                        log.error(""exception is "", e);
                        consumer.negativeAcknowledge(msg);
                    }
                }
            });
        } catch (Exception e) {
            // 业务方法可能会抛出异常
            consumer.negativeAcknowledge(msg);
        }
    }

    /**
     * 模拟异步执行的业务方法
     * @param msg 消息体
     * @param sendCallback 异步函数的callback
     */
    private void asyncPayload(byte[] msg, DemoSendCallback sendCallback) {
        if (System.currentTimeMillis() % 2 == 0) {
            sendCallback.callback(null);
        } else {
            sendCallback.callback(new Exception(""exception""));
        }
    }

}
```



### 消费者繁忙时阻塞拉取消息，不再进行业务处理

当消费者处理不过来时，通过阻塞`listener`方法，不再进行业务处理。避免在微服务积累太多消息导致OOM，可以通过RateLimiter或者Semaphore控制处理。

```java
/**
 * @author hezhangjian
 */
@Slf4j
public class MessageListenerBlockListener<T> implements MessageListener<T> {

    /**
     * Semaphore保证最多同时处理500条消息
     */
    private final Semaphore semaphore = new Semaphore(500);

    @Override
    public void received(Consumer<T> consumer, Message<T> msg) {
        try {
            semaphore.acquire();
            asyncPayload(msg.getData(), new DemoSendCallback() {
                @Override
                public void callback(Exception e) {
                    semaphore.release();
                    if (e == null) {
                        consumer.acknowledgeAsync(msg);
                    } else {
                        log.error(""exception is "", e);
                        consumer.negativeAcknowledge(msg);
                    }
                }
            });
        } catch (Exception e) {
            semaphore.release();
            // 业务方法可能会抛出异常
            consumer.negativeAcknowledge(msg);
        }
    }

    /**
     * 模拟异步执行的业务方法
     * @param msg 消息体
     * @param sendCallback 异步函数的callback
     */
    private void asyncPayload(byte[] msg, DemoSendCallback sendCallback) {
        if (System.currentTimeMillis() % 2 == 0) {
            sendCallback.callback(null);
        } else {
            sendCallback.callback(new Exception(""exception""));
        }
    }

}
```

### 消费者严格按partition保序

为了实现`partition`级别消费者的严格保序，需要对单`partition`的消息，一旦处理失败，在这条消息重试成功之前不能处理该`partition`的其他消息。示例如下：

```java
/**
 * @author hezhangjian
 */
@Slf4j
public class MessageListenerSyncAtLeastOnceStrictlyOrdered<T> implements MessageListener<T> {

    @Override
    public void received(Consumer<T> consumer, Message<T> msg) {
        retryUntilSuccess(msg.getData());
        consumer.acknowledgeAsync(msg);
    }

    private void retryUntilSuccess(byte[] msg) {
        while (true) {
            try {
                final boolean result = syncPayload(msg);
                if (result) {
                    break;
                }
            } catch (Exception e) {
                log.error(""exception is "", e);
            }
        }
    }

    /**
     * 模拟同步执行的业务方法
     *
     * @param msg 消息体内容
     * @return
     */
    private boolean syncPayload(byte[] msg) {
        return System.currentTimeMillis() % 2 == 0;
    }

}
```

## FAQ

### 消费者的性能上不去，微服务的CPU也比较低

如果服务的CPU比较健康，但是性能上不来，同时`receiverQueueSize`配置地也相对较小（如小于2*TPS），那么就可以考虑增大`receiverQueueSize`。

## 致谢

感谢 [鹏辉哥](https://github.com/codelipenghui)和 [罗天](https://github.com/fu-turer)的审稿。

## 作者简介
贺张俭，西安电子科技大学毕业，华为云物联网高级工程师
简书博客地址: https://www.jianshu.com/u/9e21abacd418
"
eliasnogueira/restassured-complete-basic-example,main,179,81,2020-07-24T10:47:09Z,239,0,A complete API Test Architecture example using Java and RestAssured providing a real-world example and continuous delivery ready.,apitesting java restassured testautomation,"# Rest-Assured Complete Basic Example
[![Actions Status](https://github.com/eliasnogueira/restassured-complete-basic-example/workflows/Build%20and%20Test/badge.svg)](https://github.com/eliasnogueira/restassured-complete-basic-example/actions)

Don't forget to give this project a ⭐

* [Required Software](#required-software)
* [How to execute the tests](#how-to-execute-the-tests)
   * [Running the backend API](#running-the-backend-api)
   * [Running the test suites](#running-the-test-suites)
   * [Generating the test report](#generating-the-test-report)
* [About the Project Structure](#about-the-project-structure)
* [Libraries](#libraries)
* [Patterns applied](#patterns-applied)
* [Pipeline](#pipeline)
* [Do you want to help?](#do-you-want-to-help)

This project was created to start the initial steps with test automation for a REST API using Rest-Assured.
It tests the API: [combined-credit-api](https://github.com/eliasnogueira/combined-credit-api)

> :warning: **Disclaimer**
> 
> This project has an educational objective and does not have the best practices that could be applied
>
> Some practices will help you to improve your test architecture, but the central point of this repository and 
> demonstrate an example of running tests for API in a pipeline
> some practices will help you to improve your test architecture, 
> but the central point of this repository and demonstrate an example of running tests for API in a pipeline

## Required software
* Java JDK 22+
* Maven installed and in your classpath
* Clone/download the backend API [combined-credit-api](https://github.com/eliasnogueira/combined-credit-api)

> :notebook: **Note**
>
> You can use Java 17 if you want


## How to execute the tests
You can open each test class on `src\test\java` and execute all of them, but I recommend you run it by the
command line. It enables us to run in different test execution strategies and, also in a pipeline, that is the repo purpose.

### Running the backend API
Please, before executing any tests, run the backend API.
After cloning this project:

1. Navigate to the project folder using the Terminal / Command prompt
2. Execute the following: `mvn spring-boot:run`
3. Wait until you see something like this: _Application has started! Happy tests!_
4. The API is ready and listen to all requests on `http://localhost:8088`

### Running the test suites

The test suites can be run directly by your IDE or by command line.
If you run `mvn test` all the tests will execute because it's the regular Maven lifecycle to run all the tests.

To run different suites based on the groups defined for each test you must inform the property `-Dgroups` and the group names.
The example below shows how to run the test for each pipeline stage:

| pipeline stage     | command                          |
|--------------------|----------------------------------|
| health check tests | `mvn test -Dgroups=""health""`     |
| contract tests     | `mvn test -Dgroups=""contract""`   |
| functional tests   | `mvn test -Dgroups=""functional""` |
| e2e tests          | `mvn test -Dgroups=""e2e""`        |

### Generating the test report

This project uses Allure Report to automatically generate the test report.
There are some configuration to make it happen:
* aspectj configuration on `pom.xml` file
* `allure.properties` file on `src/test/resources`

You can use the command line to generate it in two ways:
* `mvn allure:serve`: will open the HTML report into the browser
* `mvn allure:report`: will generate the HTML port at `target/site/allure-maven-plugin` folder

## About the Project Structure

### src/main/java

#### test
Base Test that sets the initial aspects to make the requests using RestAssured.
It also has the configuration to deal with `BigDecimal` returns and SSL configuration.

#### client
Classes that do some actions in their endpoints. It's used my the `FullSimulationE2ETest` to demonstrate and e2e
scenario.

#### commons
It contains a class where will format the URL expected when we create a new resource in the `simulation` endpoint.
You can add any class that can be used in the project.

#### config
The class `Configuration` is the connections between the property file `api.properties` located in `src/test/resources/`.

The `@Config.Sources` load the properties file and match the attributes with the `@Key`, so you automatically have the value.
You can see two sources.
The first one will get the property values from the system (as environment variables or from the command line) in the case you want to change it, for example, in a pipeline.
The second will load the `api.properties` file from the classpath.
```java
@Config.Sources({
    ""system:properties"",
    ""classpath:api.properties""})
```

The environment variable is read on the `ConfiguratorManager`.
This class reduces the amount of code necessary to get any information on the properties file.

This strategy uses [Owner](https://matteobaccan.github.io/owner/) library

#### data

##### factory
Test Data Factory classes using [java-faker](https://github.com/DiUS/java-faker) to generate fake data and [Lombok] to
create the objects using the Builder pattern.

In a few cases, there are custom data like:
 * the list of existent restrictions and simulations in the database
 * cpf generation
 * data generation returned by the API use

##### provider
JUnit 5 Arguments to reduce the amount of code and maintenance for the functional tests on `SimulationsFunctionalTest`

##### suite
It contains a class having the data related to the test groups.

##### support
Custom CPF (social security number) generator.

#### model
Model and Builder class to
[mapping objects thought serialization and deserialization](https://github.com/rest-assured/rest-assured/wiki/Usage#object-mapping) 
in use with Rest-Assured.

#### specs
Request and Response specifications used by the clients and e2e tests.
The class `InitialStepsSpec` set the basePath, baseURI, and port for the custom specs.
The classes `RestrictionsSpecs` and `SimulationsSpecs` contains the implementation of request and response specifications.

### src/test/java

#### e2e
End-to-End test using both endpoints to simulate the user journey thought the API.

#### general
Health check test to assure the endpoint is available.

#### restrictions
Contract and Functional tests to the Restriction endpoint.

#### simulations
Contract and Functional tests to the Simulations endpoint

### src/test/resources
It has a `schemas` folder with the JSON Schemas to enable Contract Testing using Rest-Assured. Also, the properties file to easily configure the API URI.

## Libraries
* [RestAssured](http://rest-assured.io/) library to test REST APIs
* [JUnit 5](https://junit.org/junit5/) to support the test creation
* [Owner](https://matteobaccan.github.io/owner/) to manage the property files
* [java-faker](https://github.com/DiUS/java-faker) to generate fake data
* [Log4J2](https://logging.apache.org/log4j/2.x/) as the logging strategy
* [Allure Report](https://docs.qameta.io/allure/) as the testing report strategy

## Patterns applied
* Test Data Factory
* Data Provider
* Builder
* Request and Response Specification
* Base Test

## Pipeline

This project uses [GitHub Actions](https://github.com/features/actions) to run the all the tests in a pipeline.
You can find it at https://github.com/eliasnogueira/restassured-complete-basic-example/blob/master/.github/workflows/test-execution.yml

We have the following pipeline steps:
```
build -> health check -> contract -> e2d -> funcional 
```

Except the build, that is the traditional Maven build, the other stages has some parameters to determine the test type and the SUT (System Under Test).
The parameters are:
* `-Dgroups`: specify which test type will be executed
* `-Dapi.base.uri`: specify a new base URI
* `-Dapi.base.path`: specify a new base path
* `-Dapi.port`: specify a new port
* `-Dapi.health.context`: specify a new health context

All the parameters, except the `-Dgroups` are pointing to Heroku because we can't run it locally.
It's a great example about how can you set different attribute values to run your tests.

## Do you want to help?

Please read the [Contribution guide](CONTRIBUTING.md)
"
mkyong/spring4-mvc-gradle-xml-hello-world,master,76,128,2014-08-29T00:11:12Z,233,6,Gradle + Spring 4 MVC hello world example (XML),,"Gradle - Spring 4 MVC Hello World
===============================
Template for Spring 4 MVC + JSP view + XML configuration, using Gradle build tool.

###1. Technologies used
* Gradle 2.0
* Spring 4.1.6.RELEASE
* JSTL 1.2
* Logback 1.1.3
* Boostrap 3

###2. To Run this project locally
```shell
$ git clone https://github.com/mkyong/spring4-mvc-gradle-xml-hello-world
$ gradle jettyRun
```
Access ```http://localhost:8080/spring4```

###3. To import this project into Eclipse IDE
1. ```$ gradle eclipse```
2. Import into Eclipse via **existing projects into workspace** option.
3. Done.

###4. Project Demo
Please refer to this article [Gradle - Spring 4 MVC Hello World ](http://www.mkyong.com/spring-mvc/gradle-spring-mvc-web-project-example/)

"
alanfgates/programmingpig,master,188,227,2011-04-16T03:01:29Z,1150,3,"Data and example code for Programming Pig, by Alan F. Gates",,
iansrobinson/graph-databases-use-cases,master,331,130,2013-04-25T08:55:28Z,388,2,Example use cases from the O'Reilly Graph Databases book,,"Graph Databases Use Cases
=========================

Example use case implementations from the O'Reilly book [Graph Databases](http://graphdatabases.com/) by [@iansrobinson](http://twitter.com/iansrobinson), [@jimwebber](http://twitter.com/jimwebber) and [@emileifrem](http://twitter.com/emileifrem).

Setup
-----

This repository contains a submodule, _neode_, which is used to build the performance datasets. After cloning the repository, you will need to initialize the submodule:

    git submodule init

and then:

    git submodule update

To run the use case queries:

    mvn clean install

Overview
--------

Queries are developed in a test-driven fashion against small, well-known representative graphs (as described pp.83-87 of the book). The queries can then be run against a much larger, randomly-generated graph (typically, 1-2 million nodes and several million relationships), to test their relative performance. (Note: these performance tests do not test production-like scenarios; rather, they act as a sanity check, ensuring that queries that run fast against a very small graph are still reasonably performant when run against a larger graph.)

The project contains 3 modules (in addition to the _neode_ submodule):

*  _queries_

   Contains the use case queries and the unit tests used to develop the queries.
* _dataset_builders_

   Builds larger, randomly-generated sample datasets.
* _performance_tests_

   Runs the queries against the large sample datasets.

Running the Performance Tests
-----------------------------

First, build the project as described in Setup.

Before you run the performance tests you will need to generate sample datasets. To create a sample dataset run:

    mvn test -pl data-generation -DargLine=""-Xms2g -Xmx2g"" -Dtest=AccessControl|Logistics|SocialNetwork

For example, to generate a sample dataset for the Logistics queries, run:

    mvn test -pl data-generation -DargLine=""-Xms2g -Xmx2g"" -Dtest=Logistics

*WARNING:* Building the sample datasets takes a long time (several tens of minutes in some cases).

To execute the performance tests against a sample dataset, run:

    mvn test -pl performance-testing -DargLine=""-Xms2g -Xmx2g"" -Dtest=AccessControl|Logistics|SocialNetwork
"
hifly81/kafka-examples,master,48,8,2018-08-17T13:13:03Z,125027,3,Practical examples with Apache Kafka®,avro avro-schema avroserializer confluent confluent-kafka flink kafka kafka-client kafka-consumer kafka-consumers kafka-events kafka-installation kafka-manager kafka-producer kafka-producers kafka-streams kafka-topic ksql ktable microprofile,
georgeberar/medium,main,43,25,2021-11-24T19:58:59Z,4837,1,Public repository containing examples for my Medium posts,,"Public repository containing examples for my Medium posts.

## Posts
| #  | Post | Folder |
| ------------- | ------------- | ------------- |
| 1  | [SpringBoot: Fall In Love with Enum Mapping](https://medium.com/@georgeberar.contact/springboot-fall-in-love-with-enum-mapping-aa212c5e2056)  | `dynamic-enum-mapping` |
| 2  | [SpringBoot: Standardized API Error Handling](https://medium.com/@georgeberar.contact/springboot-standardized-api-exception-handling-f31510861350)  | `error-handling` |
| 3  | [SpringBoot: Fuzzy Match With Postgres](https://medium.com/@georgeberar.contact/springboot-fuzzy-match-with-postgres-8eb6bfd17b58)  | `fuzzy-match-postgresql` |
| 4  | [SpringBoot: API Authentication Using OAuth2 With Google](https://medium.com/@georgeberar.contact/springboot-api-authentication-using-oauth2-with-google-655b8759f0ac) | `resource-server-oauth2-google` |
| 5  | [SpringBoot: Rule Engine For Classifying Celestial Objects](https://medium.com/@georgeberar.contact/springboot-rule-engine-for-classifying-celestial-objects-6af6d4f824a6) | `rule-engine` |
| 6  | [SpringBoot: Extract Text From PDF](https://medium.com/@georgeberar/springboot-extract-text-from-pdf-1d8d41b5adac) | `pdf-content-extractor` |
| 7  | [SpringBoot: Generate OpenAPI Document During Test Phase](https://medium.com/@georgeberar/springboot-generate-openapi-document-during-test-phase-a3a793a50dfe) | `openapi` |
| 8  | [Speed Up Backend Development With WireMock And Docker](https://medium.com/@georgeberar/speed-up-backend-development-with-wiremock-and-docker-5dc2eaadd9d9) | `wiremock-docker` |"
BroncBotz3481/YAGSL-Example,main,47,114,2023-01-30T22:42:04Z,1259,18,Yet Another General Swerve Library Example Project,frc java swerve swerve-drive yagsl,"# Yet Another Generic Swerve Library (YAGSL) Example project

YAGSL is intended to be an easy implementation of a generic swerve drive that should work for most
square swerve drives. The project is documented
on [here](https://github.com/BroncBotz3481/YAGSL/wiki). The JSON documentation can also be
found [here](docs/START.md)

This example is intended to be a starting place on how to use YAGSL. By no means is this intended to
be the base of your robot project. YAGSL provides an easy way to generate a SwerveDrive which can be
used in both TimedRobot and Command-Based Robot templates.


# Overview

### Installation

Vendor URL:

```
https://broncbotz3481.github.io/YAGSL-Lib/yagsl/yagsl.json
```

[Javadocs here](https://broncbotz3481.github.io/YAGSL/)  
[Library here](https://github.com/BroncBotz3481/YAGSL/)  
[Code here](https://github.com/BroncBotz3481/YAGSL/tree/main/swervelib)  
[WIKI](https://github.com/BroncBotz3481/YAGSL/wiki)  
[Config Generation](https://broncbotz3481.github.io/YAGSL-Example/)

# Create an issue if there is any errors you find!

We will be actively montoring this and fix any issues when we can!

## Development

* Development happens here on `YAGSL-Example`. `YAGSL` and `YAGSL-Lib` are updated on a nightly
  basis.

# Support our developers!
<a href='https://ko-fi.com/yagsl' target='_blank'><img height='35' style='border:0px;height:46px;' src='https://az743702.vo.msecnd.net/cdn/kofi3.png?v=0' border='0' alt='Buy Me a Robot at ko-fi.com'></a>

### TL;DR Generate and download your configuration [here](https://broncbotz3481.github.io/YAGSL-Example/) and unzip it so that it follows structure below:

```text
deploy
└── swerve
    ├── controllerproperties.json
    ├── modules
    │   ├── backleft.json
    │   ├── backright.json
    │   ├── frontleft.json
    │   ├── frontright.json
    │   ├── physicalproperties.json
    │   └── pidfproperties.json
    └── swervedrive.json
```

### Then create your SwerveDrive object like this.

```java
import java.io.File;
import edu.wpi.first.wpilibj.Filesystem;
import swervelib.parser.SwerveParser;
import swervelib.SwerveDrive;
import edu.wpi.first.math.util.Units;


SwerveDrive swerveDrive=new SwerveParser(new File(Filesystem.getDeployDirectory(),""swerve"")).createSwerveDrive(Units.feetToMeters(14.5));
```

# Migrating Old Configuration Files

1. Delete `wheelDiamter`, `gearRatio`, `encoderPulsePerRotation` from `physicalproperties.json`
2. Add `optimalVoltage` to `physicalproperties.json`
3. Delete `maxSpeed` and `optimalVoltage` from `swervedrive.json`
4. **IF** a swerve module doesn't have the same drive motor or steering motor as the rest of the
   swerve drive you **MUST** specify a `conversionFactor` for BOTH the drive and steering motor in
   the modules configuration JSON file. IF one of the motors is the same as the rest of the swerve
   drive and you want to use that `conversionFactor`, set the `conversionFactor` in the module JSON
   configuration to 0.
5. You MUST specify the maximum speed when creating a `SwerveDrive`
   through `new SwerveParser(directory).createSwerveDrive(maximumSpeed);`
6. IF you do not want to set `conversionFactor` in `swervedrive.json`. You can pass it into the
   constructor as a parameter like this

```java
double DriveConversionFactor = SwerveMath.calculateMetersPerRotation(Units.inchesToMeters(WHEEL_DIAMETER), GEAR_RATIO, ENCODER_RESOLUTION);
double SteeringConversionFactor = SwerveMath.calculateDegreesPerSteeringRotation(GEAR_RATIO, ENCODER_RESOLUTION);
SwerveDrive swerveDrive = new SwerveParser(directory).createSwerveDrive(maximumSpeed, SteeringConversionFactor, DriveConversionFactor);
```

### Falcon Support would not have been possible without support from Team 1466 Webb Robotics!

# Configuration Tips

### My Robot Spins around uncontrollably during autonomous or when attempting to set the heading!

* Invert the gyro scope.
* Invert the drive motors for every module. (If front and back become reversed when turning)

### Angle motors are erratic.

* Invert the angle motor.

### My robot is heavy.

* Implement momentum velocity limitations in SwerveMath.

### Ensure the IMU is centered on the robot

# Maintainers
- @thenetworkgrinch
- @Technologyman00 

# Special Thanks to Team 7900! Trial N' Terror
Without the debugging and aid of Team 7900 the project could never be as stable or active as it is. 
"
adamjshook/mapreducepatterns,master,235,196,2012-12-07T14:35:20Z,433,2,Repository for MapReduce Design Patterns (O'Reilly 2012) example source code,,"mapreducepatterns
=================

Repository for MapReduce Design Patterns (O'Reilly 2012) example source code"
flixel-gdx/flixel-gdx-examples,master,28,12,2013-02-22T08:03:08Z,9718,0,A collection of demos and examples for the flixel-gdx framework.,,"What is flixel-gdx?
-----------------------

flixel-gdx is a port of the AS3 game framework [flixel](http://flixel.org) to Java and Android. It’s built on top of the well-known libgdx framework which allows apps to be deployed to both Android and Desktop. With libgdx the nasty OpenGL ES stuff is all hidden. Like the original flixel, its primary function is to provide some useful base classes that you can easily extend to make your own basic game objects.


Get Started
-----------

https://github.com/flixel-gdx/flixel-gdx/wiki/Project-Setup


Forums
------

flixel-gdx doesn’t have its own message board, but you can use the forums of flixel and libgdx. Both have an active community. If you have any questions or feedback that are related to flixel please put it in the flixel community. They are more likely to help you out more quickly than at the libgdx. Questions about Android, OpenGL ES, rendering, etc. goes to libgdx.

[flixel forums](http://forums.flixel.org) | [libgdx forums](http://www.badlogicgames.com/forum)

[![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/flixel-gdx/flixel-gdx-examples/trend.png)](https://bitdeli.com/free ""Bitdeli Badge"")
"
hbaseinaction/twitbase,master,154,166,2012-07-02T20:37:34Z,819,7,TwitBase is a running example used throughout HBase In Action,,"# HBase In Action: TwitBase

[http://www.manning.com/dimidukkhurana][0]

## Compiling the project

Code is managed by maven. Be sure to install maven on your platform
before running these commands. Also be aware that HBase is not yet
supported on the OpenJDK platform, the default JVM installed on most
modern Linux distributions. You'll want to install the Oracle (Sun)
Java 6 runtime and make sure it's configured on your `$PATH` before
you continue. Again, on Ubuntu, you may find the [`oab-java6`][1]
utility to be of use.

To build a self-contained jar:

    $ mvn package

The jar created using this by default will allow you to interact with
HBase running in standalone mode on your local machine. If you want
to interact with a remote (possibly fully distributed) HBase
deployment, you can put your `hbase-site.xml` file in the
`src/main/resources` directory before compiling the jar.

## Using TwitBase

We have provided a launcher script to run TwitBase and the utilities
that the HBaseIA project comes with.

    $ bin/launcher

Just run the launcher without any arguments and it'll print out the
usage information.

TwitBase applications can also be run using java directly:

    $ java -cp target/twitbase-1.0.0.jar <app> [options...]

Utilities for interacting with TwitBase include:

 - `HBaseIA.TwitBase.InitTables` : create TwitBase tables
 - `HBaseIA.TwitBase.TwitsTool` : tool for managing Twits
 - `HBaseIA.TwitBase.UsersTool` : tool for managing Users
 - `HBaseIA.TwitBase.LoadUsers` : tool for loading random Users
 - `HBaseIA.TwitBase.LoadTwits` : tool for loading random Twits

The following MapReduce jobs can be launched the same way:

 - `HBaseIA.TwitBase.mapreduce.TimeSpent` : run TimeSpent log
   processing MR job
 - `HBaseIA.TwitBase.mapreduce.CountShakespeare` : run
   Shakespearean counter MR job
 - `HBaseIA.TwitBase.mapreduce.HamletTagger` : run
   hamlet-tagging MR job

## Other utilities and scripts

The following utilities are available for you to play with:

 - `utils.TablePreSplitter` : create pre-split table

## License

Copyright (C) 2012 Nick Dimiduk, Amandeep Khurana

Distributed under the [Apache License, version 2.0][2], the same as HBase.

[0]: http://www.manning.com/dimidukkhurana
[1]: https://github.com/flexiondotorg/oab-java6
[2]: http://www.apache.org/licenses/LICENSE-2.0.html
"
osmandapp/osmand-api-demo,master,85,43,2016-03-17T09:35:59Z,53786,10,Example of usage OsmAnd API,,"# osmand-api-demo
Examples of usage for OsmAnd API & SDK

- see https://osmand.net/docs/technical/osmand-api-sdk/ for instructions and differences
- you can use GitHub Actions to build projects in your fork (if you don't have Android build environment yourself)
"
alienrobotwizard/sounder,master,65,14,2010-06-01T20:17:46Z,4076,1,A grouping of Apache Pig examples.,,
adamldavis/hellojava8,master,31,27,2014-03-26T12:35:40Z,206,0,Code examples for java 8 talk and book,,"hellojava8
==========

Code examples for java 8 talk
"
oktadev/auth0-java-microservices-examples,main,26,15,2023-02-24T05:58:36Z,1292,5,Java Microservice Examples,java microservices spring-boot spring-cloud spring-cloud-gateway,"# Auth0 Java Microservice Examples

- [Reactive Java Microservices with Spring Boot and JHipster](reactive-jhipster#readme)
- [Java Microservices with Spring Boot and Spring Cloud - Gateway WebFlux](spring-boot-gateway-webflux#readme)
- [Java Microservices with Spring Boot and Spring Cloud - Gateway MVC](spring-boot-gateway-mvc#readme)

You can watch a demo of the WebFlux example in the screencast below.

[![Java Microservices with Spring Boot and Spring Cloud](static/java-microservices.webp)](https://youtu.be/m-lhymNdPBc)
"
alexjlockwood/adp-path-morph-submission-status,master,210,28,2015-03-19T23:56:57Z,146,0,Submission status path morphing example,,"# material-submission-status-icon-demo

<img alt=""Material exclamation mark to check mark animation"" src=""http://i.imgur.com/zVkc5lg.gif"" width=""336px"" height=""600px"" />
"
piomin/sample-spring-kafka-microservices,master,242,129,2022-01-21T15:21:34Z,470,1,Example microservices showing how to use Kafka and Kafka Streams with Spring Boot on the example of distributed transactions implementations with the SAGA pattern ,kafka kafka-streams spring-boot spring-kafka,
effective-software-testing/code,main,96,35,2021-10-17T09:47:49Z,44044,2,"The code examples of the Effective Software Testing: A Developer's Guide"" book""",,"# Effective software testing

![example workflow](https://github.com/effective-software-testing/code/actions/workflows/tests.yml/badge.svg)

This repository contains the code examples of the _Software Testing: A Developer's Guide_ book, by [Maurício Aniche](https://www.mauricioaniche.com).

Each folder contains the code examples of their respective chapter:

* Chapter 1: Effective and systematic software testing
* Chapter 2: Specification-based testing
* Chapter 3: Structural testing and code coverage
* Chapter 4: Design by Contracts
* Chapter 5: Property-based testing
* Chapter 6: Test doubles and mocks
* Chapter 7: Designing for testability
* Chapter 8: Test-Driven Development
* Chapter 9: Larger tests
* Chapter 10: Test code quality

Each folder is an independent maven project. You should be able to import the project directly in your favorite IDE (e.g., InteliiJ, Eclipse). You can also run all the tests via `mvn test`.

To run code coverage in chapter 3, go to the ch3 folder and type `mvn clean test jacoco:report`. Then, open the `target/site/jacoco/index.html` file to see the report. If you want to run the mutation coverage, type `mvn clean compile test-compile pitest:mutationCoverage`. The report will be generated in the `target/pit-reports/**/index.html`, where `**` is a string that represents the date time that you ran the report. For Linux or Mac users, I provide bash scripts `coverage.sh` and `mutation.sh` that run the commands above for you.

To run the web tests of chapter 9, you first should run the [Spring PetClinic](https://github.com/spring-projects/spring-petclinic) application. For convenience, we provide a compiled jar here. To run the web app, just go to the ch9 folder and type `java -jar *.jar`.

## Contributing to PRs

Maybe you found a test I missed or a better way to implement the code. You are most welcome to submit your PRs! 

If you do so, I ask you to create another file, with the same name as the original plus some suffix, and add a comment explaining what you did there. I do not want to touch the original files as they match with the code snippets in the book; we do not want readers to get lost.

## License and reuse

You are free to reuse and modify the code provided in this repository, for personal or business purposes, as long as the book is always explicitly mentioned as reference. For example, if you are providing training or workshops, you are required to have a dedicated slide with the picture of the book in each of the slide decks that make use of examples from here.
"
mahyoussef/ultimate-design-patterns,main,73,39,2024-02-20T13:51:31Z,1415,1,Mastering classical design patterns with practical examples in the ultimate design patterns bundle.,,"# ultimate-design-patterns

Mastering classical design patterns with practical examples in the ultimate design patterns bundle.
<p>
  <a href=""https://www.udemy.com/course/ultimate-design-patterns/?referralCode=C4486750B8FA2ABC3F46""><img src=""images/ultimate-design-patterns.png"" /> </a>
</p>

## How to Contribute

Feel free to contriubte by applying theses patterns in different programming languages as well as we are open for any enhancements through pull requests.

## Contributors

Thanks to all the people who already contributed!

| Name           | Contribution     | GitHub Avatar                                     |
|----------------|------------------|---------------------------------------------------|
| Hatem Hosny    | Typescript       | <img src=""https://github.com/hatemhosny.png"" alt=""Hatem Hosny"" width=""100"" height=""100""> |
| Mohamed Lotfy  | Typescript       | <img src=""https://github.com/mohamedlotfe.png"" alt=""Mohamed Lotfy"" width=""100"" height=""100"">|
| Menna          | Typescript       | <img src=""https://github.com/mennah4.png"" alt=""Menna"" width=""100"" height=""100"">|
| Amir Elsagan   | C#               | <img src=""https://github.com/amirosagan.png"" alt=""Amir Elsagan"" width=""100"" height=""100"">|
| Moamen Ashraf  | C#               | <img src=""https://github.com/moamen189.png"" alt=""Moamen Ashraf"" width=""100"" height=""100"">|
| Youssef Wael   | C#               | <img src=""https://github.com/YoussefWaelMohamedLotfy.png"" alt=""Youssef Wael"" width=""100"" height=""100"">|
| Mohamed Zidan  | C#               | <img src=""https://github.com/mazidan77.png"" alt=""Mohamed Zidan"" width=""100"" height=""100"">|
| Ahmed Mahdy    | Dart             | <img src=""https://github.com/elnaddar.png"" alt=""Ahmed Mahdy"" width=""100"" height=""100"">|
| Rodina Moamen  | Kotlin           | <img src=""https://github.com/rodinamomen.png"" alt=""Rodina Moamen"" width=""100"" height=""100"">|
| Abdelrahman Kosba  | Java           | <img src=""https://github.com/abdelrahamn-kosba.png"" alt=""Abeldrahman Kosba"" width=""100"" height=""100"">|

## License

This project is licensed under the terms of the MIT license.
"
heremaps/here-workspace-examples-java-scala,master,25,13,2020-03-11T17:00:00Z,5017,5,HERE Workspace Examples for Java and Scala Developers,examples here-workspace java scala,"# HERE Workspace Examples for Java and Scala Developers

## Introduction

This repository holds a series of Java and Scala examples, that demonstrate typical use cases for the HERE Workspace – a part of HERE platform. HERE Workspace is an environment to enrich, transform and deploy location-centric data.
Go to [HERE platform](https://developer.here.com/products/open-location-platform) to learn more. If you are interested in knowing what the platform offers specifically for Java and Scala developers, visit [this page](https://developer.here.com/documentation/sdk-developer-guide/dev_guide/index.html).

## Prerequisites

In order to run the examples, you need to have a HERE Workspace account. If you do not have an account, navigate to [Pricing and Plans](https://developer.here.com/pricing/open-location-platform) to apply for a free trial.

You need to get access credentials and prepare your environment. For more information on how to prepare your environment, see our [guide for Java and Scala developers](https://developer.here.com/documentation/sdk-developer-guide/dev_guide/topics/how-to-use-sdk.html).

## Code Examples

### Processing Sensor Data

The following documents illustrate two use cases around inferring real-world situations from sensor data. [Batch processing](https://developer.here.com/documentation/java-scala-dev/dev_guide/topics/example-use-cases.html#use-case-map-of-recommended-speed-based-on-sensor-observations-and-other-data) is useful when it is important to aggregate sensor input over a longer time period (that is hours and longer). [Stream processing](https://developer.here.com/documentation/java-scala-dev/dev_guide/topics/example-use-cases.html#use-case-turning-sensor-data-into-warnings) is recommended for time-critical use cases, like informing about road hazards.

| Name                                                          | Description                                                                                                                                                                                             | Source                                                      | Labels / Topics                                                    |
| ------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------------ |
| Infer Stop Sign Locations from Automotive Sensor Observations | The example takes archived sensor data, clusters and path-matches it in a distributed Spark batch environment, and creates a map layer with stop signs at the output.                                   | [Scala](location/scala/spark/infer-stop-signs-from-sensors) | Location Library, Data Client Library, Spark, Batch, GeoJSON, SDII |
| Stream Path Matcher                                           | The example stands for a similar but time critical use case. It does not hash out anything but map matching. It takes sensor data from a stream, map-matches it in Flink, and puts on an output stream. | [Java](location/java/flink/stream-path-matcher)             | Location Library, Data Client Library, Flink, Stream, SDII         |

### Incremental Map Processing & Validation

For more information, see a use case illustration of [keeping a client map up to date with incremental processing](https://developer.here.com/documentation/java-scala-dev/dev_guide/topics/example-use-cases.html#use-case-incremental-map-processing).

| Name                                                                         | Description                                                                                                                                                                                                     | Source                                                                                                                                            | Labels / Topics                                                   |
| ---------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |
| Geometry Lifter                                                              | An application that takes level 12 partitions of road topology and geometry and aggregates them to higher-level (i.e. bigger) partitions.                                                                       | [Java](data-processing/java/geometry-lifter) / [Scala](data-processing/scala/geometry-lifter)                                                     | Data Processing Library, Spark, Batch, Protobuf, HERE Map Content |
| Pedestrian Topologies Extraction to GeoJSON                                  | Topologies, accessible by pedestrians, are selected based on the segment attributes and then are transformed into GeoJSON file format and stored in a new catalog.                                              | [Java](data-processing/java/pedestrian-topologies-extraction-geojson) / [Scala](data-processing/scala/pedestrian-topologies-extraction-geojson)   | Data Processing Library, Spark, Batch, GeoJSON, HERE Map Content  |
| Pedestrian Topologies Extraction to Protobuf                                 | Topologies, accessible by pedestrians, are selected based on the segment attributes and then are transformed to a newly created proto schema format and stored in a new catalog layer that follows that schema. | [Java](data-processing/java/pedestrian-topologies-extraction-protobuf) / [Scala](data-processing/scala/pedestrian-topologies-extraction-protobuf) | Data Processing Library, Spark, Batch, Protobuf, HERE Map Content |
| Statistics creation across multiple processing runs with stateful processing | The application counts how often the node cardinality of the topology changes in each partition.                                                                                                                | [Java](data-processing/java/stateful-nodecardinality-extraction) / [Scala](data-processing/scala/stateful-nodecardinality-extraction)             | Data Processing Library, Spark, Batch, JSON, HERE Map Content     |
| Here Map Content Diff-Tool                                                   | An application to compare the content of two different versions of an input catalog.                                                                                                                            | [Java](data-processing/java/heremapcontent-difftool) / [Scala](data-processing/scala/heremapcontent-difftool)                                     | Data Processing Library, Spark, Batch, JSON, HERE Map Content     |
| Here Map Content Validation                                                  | An application to validate road topology and geometry content against a set of acceptance criteria using [scalatest](https://www.scalatest.org/).                                                               | [Scala](data-processing/scala/heremapcontent-validation)                                                                                          | Data Processing Library, Spark, Batch, JSON, HERE Map Content     |

### Archiving Stream Data

The HERE Workspace allows you to retain stream data for longer periods, which allows you to later query and process the retained data for non-real-time use cases.
For more information, see [Data Archiving Library Developer Guide](https://developer.here.com/documentation/data-archiving-library/dev_guide/index.html).

| Name                                       | Description                                                                                                                                      | Source                                              | Labels / Topics                                           |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------- | --------------------------------------------------------- |
| Archiving SDII stream data in Avro         | The example shows how to use the Data Archiving Library to quickly develop an archiving solution that archives data in Avro format.              | [Java](data-archive/java/avro-example)              | Data Archiving Library, Flink, Stream, Avro, SDII         |
| Archiving SDII stream data in Parquet      | The example shows how to use the Data Archiving Library to quickly develop an archiving solution that archives data in Parquet format.           | [Java](data-archive/java/parquet-example)           | Data Archiving Library, Flink, Stream, Parquet, SDII      |
| Archiving SENSORIS stream data in Protobuf | The example shows how to use the Data Archiving Library to quickly develop an archiving solution that archives SENSORIS data in Protobuf format. | [Java](data-archive/java/sensoris-protobuf-example) | Data Archiving Library, Flink, Stream, SENSORIS, Protobuf |

### Compacting Index Data

The HERE Workspace allows you to compact data files with the same index attribute values into one or more files based on the configuration.
Compaction reduces the index layer storage cost, improves query performance, and makes subsequent data processing more efficient.
For more information, see [Index Compaction Library Developer Guide](https://developer.here.com/documentation/index-compaction-library/dev_guide/index.html).

| Name                                    | Description                                                                                                                               | Source                                               | Labels / Topics                                       |
| --------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- | ----------------------------------------------------- |
| Compacting Parquet format indexed data  | The example shows how to use the Index Compaction Library to quickly develop a compaction application that compacts parquet format data.  | [Java](index-compaction-batch/java/parquet-example)  | Index Compaction Library, Spark, Batch, Parquet, SDII |
| Compacting Protobuf format indexed data | The example shows how to use the Index Compaction Library to quickly develop a compaction application that compacts protobuf format data. | [Java](index-compaction-batch/java/protobuf-example) | Index Compaction Library, Spark, Batch, Parquet, SDII |

### Small Examples Showing Usage of Location Library

The following examples demonstrate how to use the Location Library.

| Name                                                                                   | Description                                                                                                                                                                                                | Source                                                                                                                                                                                                                                              | Labels / Topics                            |
| -------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------ |
| Point Matching Example                                                                 | Takes probe points and matches each one against the closest geometry without consider the path.                                                                                                            | [Java](location/java/standalone#point-matching-example) / [Scala](location/scala/standalone#point-matching-example)                                                                                                                                 | Location Library, GeoJSON, CSV             |
| Traversing the Graph                                                                   | Shows how to create a traversable graph from the HERE Optimized Map for Location Library catalog.                                                                                                          | [Java](location/java/standalone#traversing-the-graph) / [Scala](location/scala/standalone#traversing-the-graph)                                                                                                                                     | Location Library, GeoJSON                  |
| Most Probable Path                                                                     | Navigates the graph along the most probable path based on simple assumptions like try to stay on same functional class.                                                                                    | [Java](location/java/standalone#most-probable-path) / [Scala](location/scala/standalone#most-probable-path)                                                                                                                                         | Location Library, GeoJSON                  |
| Path Matching Example                                                                  | Matches path probe points against the graph.                                                                                                                                                               | [Java](location/java/standalone#path-matching-example) / [Scala](location/scala/standalone#path-matching-example)                                                                                                                                   | Location Library, GeoJSON, CSV             |
| Path Matching with Restrictions                                                        | Matches path probe points against a graph that excludes segments that are not accessible by taxis.                                                                                                         | [Scala](location/scala/standalone#path-matching-with-restrictions)                                                                                                                                                                                  | Location Library, GeoJSON, CSV             |
| Turn Restrictions                                                                      | Shows how to check if turns on a road network are restricted or not.                                                                                                                                       | [Java](location/java/standalone#turn-restrictions) / [Scala](location/scala/standalone#turn-restrictions)                                                                                                                                           | Location Library, GeoJSON                  |
| Generic Range Based Attributes                                                         | Shows how to load a generic attribute that is not available in the HERE Optimized Map for Location Library using a Vertex reference as input.                                                              | [Java](location/java/standalone#generic-range-based-attributes) / [Scala](location/scala/standalone#generic-range-based-attributes)                                                                                                                 | Location Library                           |
| Path Matching Sparse Probe Data                                                        | Shows how to match sparse path points against the graph by traversing it using the most probable path assumptions.                                                                                         | [Java](location/java/standalone#path-matching-sparse-probe-data) / [Scala](location/scala/standalone#path-matching-sparse-probe-data)                                                                                                               | Location Library, GeoJSON, CSV             |
| Converting References from HERE Optimized Map for Location Library to HERE Map Content | Converts Vertex references to Topology Segments and vice versa.                                                                                                                                            | [Java](location/java/standalone#converting-references-from-here-optimized-map-for-location-library-to-here-map-content) / [Scala](location/scala/standalone#converting-references-from-here-optimized-map-for-location-library-to-here-map-content) | Location Library, HERE Map Content         |
| Converting References from TPEG2 to its Binary Representation                          | Shows how to read an OpenLR location reference that has been written in the TPEG2 XML encoding and convert it to its binary representation.                                                                | [Java](location/java/standalone#converting-references-from-tpeg2-to-its-binary-representation) / [Scala](location/scala/standalone#converting-references-from-tpeg2-to-its-binary-representation)                                                   | Location Library, TPEG2, OpenLR            |
| Extracting TPEG2 Document                                                              | Demonstrates how to load a TPEG2 document and extract its parts.                                                                                                                                           | [Java](location/java/standalone#extracting-tpeg2-document) / [Scala](location/scala/standalone#extracting-tpeg2-document)                                                                                                                           | Location Library, TPEG2                    |
| Creating and Resolving TMC Reference                                                   | Searches for a well-known vertex that is covered by TMC to define the input location.                                                                                                                      | [Java](location/java/standalone#creating-and-resolving-tmc-reference) / [Scala](location/scala/standalone#creating-and-resolving-tmc-reference)                                                                                                     | Location Library, TMC                      |
| Resolving TMC References in RTTI Message                                               | Demonstrates how TMC references in Real Time Traffic Incident (RTTI) messages can be converted to TPEG2 TMC references, and how the `location-referencing` module can be used to resolve those references. | [Java](location/java/standalone#resolving-tmc-references-in-rtti-message) / [Scala](location/scala/standalone#resolving-tmc-references-in-rtti-message)                                                                                             | Location Library, TPEG2                    |
| Creating OpenLR Reference from Road Segments                                           | Transforms a path given as segment references in HERE Map Content to OpenLR reference.                                                                                                                     | [Java](location/java/standalone#creating-openlr-reference-from-road-segments) / [Scala](location/scala/standalone#creating-openlr-reference-from-road-segments)                                                                                     | Location Library, HERE Map Content, OpenLR |
| Resolving OpenLR Reference from Road Segments                                          | Shows how to take an OpenLR reference given in XML and resolve this reference to segments in HERE Map Content                                                                                              | [Java](location/java/standalone#resolving-openlr-reference-from-road-segments) / [Scala](location/scala/standalone#resolving-openlr-reference-from-road-segments)                                                                                   | Location Library, HERE Map Content, OpenLR |
| Functional Class for a Vertex                                                          | Shows how you can get the functional class for a vertex.                                                                                                                                                   | [Java](location/java/standalone#functional-class-for-a-vertex) / [Scala](location/scala/standalone#functional-class-for-a-vertex)                                                                                                                   | Location Library, GeoJSON                  |
| ADAS Curvature Attribute                                                               | Shows how to fetch and use ADAS attributes in the HERE Optimized Map for Location Library using a Vertex or an Edge reference.                                                                             | [Java](location/java/standalone#adas-curvature-attribute) / [Scala](location/scala/standalone#adas-curvature-attribute)                                                                                                                             | Location Library, GeoJSON                  |

## License

Copyright (C) 2017-2024 HERE Europe B.V.

Unless otherwise noted in `LICENSE` files, source code files for specific files or directories, the [LICENSE](LICENSE) in the root applies to all content in this repository.
"
raeperd/realworld-springboot-java,master,182,75,2021-04-09T14:37:10Z,1393,0,Spring boot java implementation of realworld example.app,github-action jacoco-plugin java11 jib-gradle lombok-gradle sonarcloud spring-boot spring-data-jpa,"
![RealWorld example apps cover](./doc/image/realworld-cover.png)
[![Build](https://github.com/raeperd/realworld-springboot-java/actions/workflows/build.yml/badge.svg)](https://github.com/raeperd/realworld-springboot-java/actions/workflows/build.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[ReadWorld.io](https://github.com/gothinkster/realworld) backend project using spring boot java using `spring-security`, `spring-data-jpa`

# Insprired by

- [우아한형제들 기술 불로그 | Todo list 만들기는 이제 그만](https://woowabros.github.io/experience/2020/04/14/stop-making-todo-list.html)
- [우아한형제들 기술 블로그 | Gradle 프로젝트에 JaCoCo 설정하기](https://woowabros.github.io/experience/2020/02/02/jacoco-config-on-gradle-project.html)
- [우아한형제들 기술 블로그 | 우린 Git-flow를 사용하고 있어요](https://woowabros.github.io/experience/2017/10/30/baemin-mobile-git-branch-strategy.html)
- [Github | Realworld.io](https://github.com/gothinkster/realworld)


 # Getting started

 ## Build from scratch
 ``` shell
 $ ./gradlew build bootRun
 ```

 ## Using docker
 ``` shell
 $ docker run --rm -p 8080:8080 ghcr.io/raeperd/realworld-spring-boot-java:master
 ```

- Dockerhub registry is [here](https://hub.docker.com/repository/docker/raeperd/realworld-spring-boot-java)  
- Container tags are simply branch name of this repository following git-flow strategy



## How to test 

After run application, you can try one of followings

### using shell script

``` shell
$ ./doc/run-api-tests.sh
```

### using postman 

Import [`./doc/Conduit.postman_collection.json`](./doc/Conduit.postman_collection.json) in your postman application 



And also, pure `gradle test` covers almost every line of code.

More details can be found in [`./doc/README.md`](./doc/README.md) and  [original source](https://github.com/gothinkster/realworld/tree/master/spec)

# Overview

## Design Principal

- Always `final` whenever possible
- Always package private class whenever possible
- **Always test every package, class, method, instruction in codes**
  - Except for some boilerplate `equals` and `hashcode` method
  - This is validated by [jacoco-gradle-plugin](https://docs.gradle.org/current/userguide/jacoco_plugin.html).
  - Coverage verification in [`./test.gradle`](./test.gradle)
- Try to avoid including additional dependencies as much as possible
  - Implements JWT generation / validation logic without 3rd party library [#3](https://github.com/raeperd/realworld-springboot-java/issues/3)
- Try to maintain codes in domain package remain POJO
  - Except for special spring annotations like `@Service`, `@Repository`, `@Transactional`
  - Prohibit use of lombok in domain package
- Try to follow all modern best practices for spring-boot project
  
## Diagrams 

- You can open full diagram file in [`realworld.drawio`](./realworld.drawio) using [draw.io](https://app.diagrams.net/)

### User

![realworld-User](./doc/image/realworld-User.png)

- Separate password encoding logic out of User.
- User must be created with password encoder.

### Article

![realworld-Article](./doc/image/realworld-Article.png)

- Article contains other elements with `@Embedded` classes
- Try to reduce number of repositories.
- Prefer `@JoinTable` to `@JoinColumn`

### JWT 

![realworld-Jwt](./doc/image/realworld-Jwt.png)

- Try not to use 3rd party library
- Serialization and Deserialization are seperated with interfaces
- Domain package contains interface, infrastructure code provide implementation  
- Application package do stuff with spring-security logic

## Performance

![performance](./doc/image/performance.png)

- Result of [`./doc/run-api-tests.sh`](./doc/run-api-tests.sh)

# What can be done more

- User class doing so many things now. It can be improved someway.
- Service classes can be divided into smaller services
- Test cases order can be improved

# Contact

You can contact me with [email](raeperd117@gmail.com) or issue in this project

# License
[MIT License](./LICENSE)

# Referenced

- [JSON Web Token Introduction - jwt.io](https://jwt.io/introduction)  
- [Symmetric vs Asymmetric JWTs. What is JWT? | by Swayam Raina | Noteworthy - The Journal Blog](https://blog.usejournal.com/symmetric-vs-asymmetric-jwts-bd5d1a9567f6)
- [presentations/auth.md at master · alex996/presentations · GitHub](https://github.com/alex996/presentations/blob/master/auth.md)

"
ThomasVitale/spring-security-examples,main,27,11,2021-04-29T15:08:59Z,152,2,"Examples with Spring Security (OAuth2 and OpenID Connect, Authentication and Authorization)",,"# Spring Security Examples

Examples with Spring Security (OAuth2 and OpenID Connect, Authentication and Authorization)

## OAuth2 and OpenID Connect

* [Login - Custom authorities from UserInfo](https://github.com/ThomasVitale/spring-security-examples/tree/main/oauth2/login-user-authorities)

* [Login - Custom authorities from UserInfo (Reactive)](https://github.com/ThomasVitale/spring-security-examples/tree/main/oauth2/login-user-authorities-reactive)

* [Resource Server - Custom authorities from JWT](https://github.com/ThomasVitale/spring-security-examples/tree/main/oauth2/resource-server-jwt-authorities)

* [Resource Server - Custom authorities from JWT (Reactive)](https://github.com/ThomasVitale/spring-security-examples/tree/main/oauth2/resource-server-jwt-authorities-reactive)
"
pedroSG94/vlc-example-streamplayer,master,227,92,2017-06-25T00:17:49Z,50710,45,Example code how to play a stream with VLC,stream streamplayer vlc,"# vlc-example-streamplayer

[![Release](https://jitpack.io/v/pedroSG94/vlc-example-streamplayer.svg)](https://jitpack.io/#pedroSG94/vlc-example-streamplayer)

Example code how to play a stream with VLC.

Use this endpoint for test:

```
rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov
```


Consider using the latest official compiled VLC version:

https://mvnrepository.com/artifact/org.videolan.android/libvlc-all

https://code.videolan.org/videolan/vlc-android#build-application


## Gradle
Compile my wrapper:

```gradle
allprojects {
  repositories {
    maven { url 'https://jitpack.io' }
  }
}
dependencies {
  compile 'com.github.pedroSG94.vlc-example-streamplayer:pedrovlc:2.5.14v3'
}
```

Compile only VLC (version 2.5.14):

```gradle
allprojects {
  repositories {
    maven { url 'https://jitpack.io' }
  }
}
dependencies {
  compile 'com.github.pedroSG94.vlc-example-streamplayer:libvlc:2.5.14v3'
}
```
"
zhouyongtao/spring-cloud-microservice,master,48,35,2018-06-12T09:39:25Z,269,0,spring-cloud-microservice-example,microservice,"容器与微服务架构
=======================================================================

# docker&kubernetes
* https://www.cncf.io/projects/
* https://github.com/kubernetes/kubernetes
* https://github.com/kubernetes/examples
* https://kubernetes.io/docs/concepts/
* https://github.com/ramitsurana/awesome-kubernetes
* https://docs.docker.com/

# volume
* https://github.com/rook/rook
* https://github.com/ceph
* https://github.com/gluster

# monitor
* https://github.com/prometheus
* https://github.com/coreos/prometheus-operator
* https://github.com/kubernetes-incubator/metrics-server
* https://github.com/grafana/grafana

# maven repository
* https://www.jfrog.com/confluence/
* https://www.sonatype.com/nexus-repository-oss
* https://hub.docker.com/r/sonatype/nexus3/

# spring cloud config
* https://github.com/dyc87112/spring-cloud-config-admin
* https://github.com/alibaba/nacos
* https://github.com/ctripcorp/apollo
* https://nacos.io/en-us/blog/Nacos-is-Coming.html

# spring-cloud
* https://spring.io/projects/spring-cloud
* https://spring.io/projects/spring-cloud-gateway
* https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/
* http://cloud.spring.io/spring-cloud-static/Finchley.SR2/single/spring-cloud.html
* https://github.com/spring-projects/spring-boot/tree/master/spring-boot-project/spring-boot-starters
* https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Finchley-Release-Notes
* https://github.com/spring-cloud-samples/hystrix-dashboard

# env
```
sudo apt-get update
sudo apt-get upgrade
yum install -y redhat-lsb
uname -a
cat /proc/version
lsb_release -a

yum install epel-release
yum makecache
yum repolist

/opt/gitlab/embedded/bin/psql --version
sudo gitlab-ctl pg-upgrade
sudo yum install gitlab-ce
sudo gitlab-ctl reconfigure
sudo gitlab-ctl restart
sudo yum install -y gitlab-ce
sudo yum install -y gitlab-ee
netstat -lntup

sudo yum install java-1.8.0-openjdk
sudo apt-get install software-properties-common htop
sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update
sudo apt-get install oracle-java8-installer
java -version
```

# eureka
```
#nohup java -jar microsrv-eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1 &
java -jar microsrv-eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1
java -jar microsrv-eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2
java -jar microsrv-eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer3

vi /etc/hosts

10.255.131.162       microsrv-eureka-server-peer1
10.255.131.163       microsrv-eureka-server-peer2
10.255.131.164       microsrv-eureka-server-peer3

echo `hostname`
127.0.0.1       localhost                               iZuf60cj5pna5im3va46nkZ

netstat -tunlp
netstat -apn | grep 8000
```"
taes-k/spring-example,master,32,23,2019-03-13T03:30:02Z,257,0,spring-example,,"# Spring-Example

스프링 예제 소스를위한 Repository 입니다.

### - spring-boot-start-test 
스프링 부트 시작하기 예제


"
DiUS/pact-workshop-jvm,master,109,64,2017-01-26T22:29:21Z,678,1,Example JVM project for the Pact workshop,,"## ⚠️ Important note ⚠️

This repository has been archived, please use the latest workshop here: https://github.com/pact-foundation/pact-workshop-jvm-spring

## Introduction

This workshop is aimed at demonstrating core features and benefits of contract testing with Pact.

Whilst contract testing can be applied retrospectively to systems, we will follow the [consumer driven contracts](https://martinfowler.com/articles/consumerDrivenContracts.html) approach in this workshop - where a new consumer and provider are created in parallel to evolve a service over time, especially where there is some uncertainty with what is to be built.

This workshop should take from 1 to 2 hours, depending on how deep you want to go into each topic.

**Example project overview**

This workshop is setup with a number of steps that can be run through. Each step is in a branch, so to run through a
step of the workshop just check out the branch for that step (i.e. `git checkout step1`).

This project has 3 components, a consumer project and two service providers, one Dropwizard and one
Springboot service that the consumer will interact with.

**Workshop outline**:

- [step 1: **Simple Consumer calling Provider**](https://github.com/DiUS/pact-workshop-jvm#step-1---simple-consumer-calling-provider): Create our consumer before the Provider API even exists
- [step 2: **Client Tested but integration fails**](https://github.com/DiUS/pact-workshop-jvm#step-2---client-tested-but-integration-fails): Write a unit test for our consumer
- [step 3: **Pact to the rescue**](https://github.com/DiUS/pact-workshop-jvm#step-3---pact-to-the-rescue): Write a Pact test for our consumer
- [step 4: **Verify pact against provider**](https://github.com/DiUS/pact-workshop-jvm#step-4---verify-pact-against-provider): Verify the consumer pact with the Provider API (Gradle)
- [step 5: **Verify the provider with a test**](https://github.com/DiUS/pact-workshop-jvm#step-5---verify-the-provider-with-a-test): Verify the consumer pact with the Provider API (JUnit)
- [step 6: **Back to the client we go**](https://github.com/DiUS/pact-workshop-jvm#step-6---back-to-the-client-we-go): Fix the consumer's bad assumptions about the Provider
- [step 7: **Verify the providers again**](https://github.com/DiUS/pact-workshop-jvm#step-7---verify-the-providers-again): Update the provider  build
- [step 8: **Test for the missing query parameter**](https://github.com/DiUS/pact-workshop-jvm#step-8---test-for-the-missing-query-parameter): Test unhappy path of missing query string
- [step 9: **Verify the provider with the missing/invalid date query parameter**](https://github.com/DiUS/pact-workshop-jvm#step-9---verify-the-provider-with-the-missinginvalid-date-query-parameter): Verify provider's ability to handle the missing query string
- [step 10: **Update the providers to handle the missing/invalid query parameters**](https://github.com/DiUS/pact-workshop-jvm#step-10---update-the-providers-to-handle-the-missinginvalid-query-parameters): Update provider to handlre mising query string
- [step 11: **Provider states**](https://github.com/DiUS/pact-workshop-jvm#step-11---provider-states): Write a pact test for the `404` case
- [step 12: **provider states for the providers**](https://github.com/DiUS/pact-workshop-jvm#step-12---provider-states-for-the-providers): Update API to handle `404` case
- [step 13: **Using a Pact Broker**](https://github.com/DiUS/pact-workshop-jvm#step-13---using-a-pact-broker): Implement a broker workflow for integration with CI/CD

_NOTE: Each step is tied to, and must be run within, a git branch, allowing you to progress through each stage incrementally. For example, to move to step 2 run the following: `git checkout step2`_

## Learning objectives

If running this as a team workshop format, you may want to take a look through the [learning objectives](./LEARNING.md).

## Requirements

- [Java](https://java.com/en/download/) (version 1.8+)
- [Docker Compose](https://docs.docker.com/compose/install/)

## Step 1 - Simple Consumer calling Provider

Given we have a client that needs to make a HTTP GET request to a provider service, and requires a response in JSON format.


![Simple Consumer](diagrams/workshop_step1.png)


The client is quite simple and looks like this

*consumer/src/main/java/au/com/dius/pactworkshop/consumer/Client.java:*

```java
public class Client {
  public Object loadProviderJson() throws UnirestException {
    return Unirest.get(""http://localhost:8080/provider.json"")
      .queryString(""validDate"", LocalDateTime.now().toString())
      .asJson().getBody();
  }
}
```

and the dropwizard provider resource

*providers/dropwizard-provider/src/main/java/au/com/dius/pactworkshop/dropwizardprovider/RootResource.java:*

```java
@Path(""/provider.json"")
@Produces(MediaType.APPLICATION_JSON)
public class RootResource {

  @GET
  public Map<String, Object> providerJson(@QueryParam(""validDate"") Optional<String> validDate) {
    LocalDateTime valid_time = LocalDateTime.parse(validDate.get());
    Map<String, Object> result = new HashMap<>();
    result.put(""test"", ""NO"");
    result.put(""validDate"", LocalDateTime.now().toString());
    result.put(""count"", 1000);
    return result;
  }

}
```

The springboot provider controller is similar

*providers/springboot-provider/src/main/java/au/com/dius/pactworkshop/springbootprovider/RootController.java:*

```java
@RestController
public class RootController {

  @RequestMapping(""/provider.json"")
  public Map<String, Serializable> providerJson(@RequestParam(required = false) String validDate) {
    LocalDateTime validTime = LocalDateTime.parse(validDate);
    Map<String, Serializable> map = new HashMap<>(3);
    map.put(""test"", ""NO"");
    map.put(""validDate"", LocalDateTime.now().toString());
    map.put(""count"", 1000);
    return map;
  }

}
```

This providers expects a `validDate` parameter in HTTP date format, and then return some simple json back.


![Sequence Diagram](diagrams/sequence_diagram.png)


Running the client with either provider works nicely. For example, start the dropwizard-provider in one terminal:

```console
$ ./gradlew :providers:dropwizard-provider:run
```

_NOTE_: this task won't complete, it will get to 75% and remain that way until you shutdown the process: `<=========----> 75% EXECUTING [59s]`)

(to start the Spring boot provider instead, you would run `./gradlew :providers:springboot-provider:bootRun`).

Once the provider has successfully initialized, open another terminal session and run the consumer:

```console
$ ./gradlew :consumer:run

> Task :consumer:run
{""test"":""NO"",""validDate"":""2018-04-10T10:59:41.122"",""count"":1000}


BUILD SUCCESSFUL in 1s
2 actionable tasks: 2 executed

```

Don't forget to stop the dropwizard-provider that is running in the first terminal when you have finished this step.

## Step 2 - Client Tested but integration fails

Now lets get the client to use the data it gets back from the provider. Here is the updated client method that uses the returned data:

*consumer/src/main/java/au/com/dius/pactworkshop/consumer/Client.java:*

```java
  public List<Object> fetchAndProcessData() throws UnirestException {
      JsonNode data = loadProviderJson();
      System.out.println(""data="" + data);

      JSONObject jsonObject = data.getObject();
      int value = 100 / jsonObject.getInt(""count"");
      ZonedDateTime date = ZonedDateTime.parse(jsonObject.getString(""date""));

      System.out.println(""value="" + value);
      System.out.println(""date="" + date);
      return Arrays.asList(value, date);
  }
```

![Sequence 2](diagrams/step2_sequence_diagram.png)

Let's now test our updated client. We're using [Wiremock](http://wiremock.org/) here to mock out the provider.

*consumer/src/test/java/au/com/dius/pactworkshop/consumer/ClientTest.java:*

```java
public class ClientTest {

  @Rule
  public WireMockRule wireMockRule = new WireMockRule(8080);

  @Test
  public void canProcessTheJsonPayloadFromTheProvider() throws UnirestException {

    String date = ""2013-08-16T15:31:20+10:00"";

    stubFor(get(urlPathEqualTo(""/provider.json""))
      .withQueryParam(""validDate"", matching("".+""))
      .willReturn(aResponse()
        .withStatus(200)
        .withHeader(""Content-Type"", ""application/json"")
        .withBody(""{\""test\"": \""NO\"", \""date\"": \"""" + date + ""\"", \""count\"": 100}"")));

    List<Object> data = new Client().fetchAndProcessData();

    assertThat(data, hasSize(2));
    assertThat(data.get(0), is(1));
    assertThat(data.get(1), is(ZonedDateTime.parse(date)));
  }

}
```

![Unit Test With Mocked Response](diagrams/step2_unit_test.png)

Let's run this spec and see it all pass:

```console
$ ./gradlew :consumer:check

BUILD SUCCESSFUL in 0s
3 actionable tasks: 3 up-to-date
```

However, there is a problem with this integration point. Running the actual client against any of the providers results in
 a runtime exception!

```console
$ ./gradlew :consumer:run

> Task :consumer:run FAILED
data={""test"":""NO"",""validDate"":""2018-04-10T11:48:36.838"",""count"":1000}
Exception in thread ""main"" org.json.JSONException: JSONObject[""date""] not found.
        at org.json.JSONObject.get(JSONObject.java:471)
        at org.json.JSONObject.getString(JSONObject.java:717)
        at au.com.dius.pactworkshop.consumer.Client.fetchAndProcessData(Client.java:26)
        at au.com.dius.pactworkshop.consumer.Consumer.main(Consumer.java:7)


FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':consumer:run'.
> Process 'command '/usr/lib/jvm/java-8-oracle/bin/java'' finished with non-zero exit value 1

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 1s
2 actionable tasks: 1 executed, 1 up-to-date
```

The provider returns a `validDate` while the consumer is trying to use `date`, which will blow up when run for
real even with the tests all passing. Here is where Pact comes in.

## Step 3 - Pact to the rescue

Let us add Pact to the project and write a consumer pact test.

*consumer/src/test/java/au/com/dius/pactworkshop/consumer/ClientPactTest.java*

```java
public class ClientPactTest {

  // This sets up a mock server that pretends to be our provider
  @Rule
  public PactProviderRule provider = new PactProviderRule(""Our Provider"", ""localhost"", 1234, this);

  private LocalDateTime dateTime;
  private String dateResult;

  // This defines the expected interaction for out test
  @Pact(provider = ""Our Provider"", consumer = ""Our Little Consumer"")
  public RequestResponsePact pact(PactDslWithProvider builder) {
    dateTime = LocalDateTime.now();
    dateResult = ""2013-08-16T15:31:20+10:00"";
    return builder
      .given(""data count > 0"")
      .uponReceiving(""a request for json data"")
      .path(""/provider.json"")
      .method(""GET"")
      .query(""validDate="" + dateTime.toString())
      .willRespondWith()
      .status(200)
      .body(
          new PactDslJsonBody()
              .stringValue(""test"", ""NO"")
              .stringValue(""date"", dateResult)
              .numberValue(""count"", 100)
      )
      .toPact();
  }

  @Test
  @PactVerification(""Our Provider"")
  public void pactWithOurProvider() throws UnirestException {
    // Set up our HTTP client class
    Client client = new Client(provider.getUrl());

    // Invoke out client
    List<Object> result = client.fetchAndProcessData(dateTime);

    assertThat(result, hasSize(2));
    assertThat(result.get(0), is(1));
    assertThat(result.get(1), is(ZonedDateTime.parse(dateResult)));
  }
}
```


![Test using Pact](diagrams/step3_pact.png)


This test starts a mock server on a random port that pretends to be our provider. To get this to work we needed to update
our consumer to pass in the URL of the provider. We also updated the `fetchAndProcessData` method to pass in the
query parameter.

Running this spec still passes, but it creates a pact file which we can use to validate our assumptions on the provider side.

```console
$ ./gradlew :consumer:check
Starting a Gradle Daemon, 1 incompatible and 3 stopped Daemons could not be reused, use --status for details

BUILD SUCCESSFUL in 8s
4 actionable tasks: 1 executed, 3 up-to-date
```

Generated pact file (*consumer/build/pacts/Our Little Consumer-Our Provider.json*):

```json
{
  ""provider"": {
    ""name"": ""Our Provider""
  },
  ""consumer"": {
    ""name"": ""Our Little Consumer""
  },
  ""interactions"": [
    {
      ""description"": ""a request for json data"",
      ""request"": {
        ""method"": ""GET"",
        ""path"": ""/provider.json"",
        ""query"": {
          ""validDate"": [
            ""2020-06-16T11:49:49.485""
          ]
        }
      },
      ""response"": {
        ""status"": 200,
        ""headers"": {
          ""Content-Type"": ""application/json; charset=UTF-8""
        },
        ""body"": {
          ""date"": ""2013-08-16T15:31:20+10:00"",
          ""test"": ""NO"",
          ""count"": 100
        },
        ""matchingRules"": {
          ""header"": {
            ""Content-Type"": {
              ""matchers"": [
                {
                  ""match"": ""regex"",
                  ""regex"": ""application/json(;\\s?charset=[\\w\\-]+)?""
                }
              ],
              ""combine"": ""AND""
            }
          }
        }
      },
      ""providerStates"": [
        {
          ""name"": ""data count > 0""
        }
      ]
    }
  ],
  ""metadata"": {
    ""pactSpecification"": {
      ""version"": ""3.0.0""
    },
    ""pact-jvm"": {
      ""version"": ""4.1.2""
    }
  }
}
```

## Step 4 - Verify pact against provider

There are two ways of validating a pact file against a provider. The first is using a build tool (like Gradle) to
execute the pact against the running service. The second is to write a pact verification test. We will be doing both
in this step.

First, we need to **publish** the pact file from the consumer project. For this workshop, we have a `publishWorkshopPact` task in the
main project to do this.

```console
$ ./gradlew publishWorkshopPact

BUILD SUCCESSFUL in 0s
2 actionable tasks: 2 up-to-dat
```

The Pact file from the consumer project will now exist in the build directory of the two provider projects.

![Pact Verification](diagrams/step4_pact.png)


### Verifying the springboot provider

For the springboot provider, we are going to use Gradle to verify the pact file for us. We need to add the pact gradle
plugin and the spawn plugin to the project and configure them.

**NOTE: This will not work on Windows, as the Gradle spawn plugin will not work with Windows.**

*providers/springboot-provider/build.gradle:*

```groovy
plugins {
  id ""au.com.dius.pact"" version ""4.1.7""
  id ""com.wiredforcode.spawn"" version ""0.8.2""
}
```

```groovy
task startProvider(type: SpawnProcessTask, dependsOn: 'assemble') {
  command ""java -jar ${jar.archivePath}""
  ready 'Started MainApplication'
}

task stopProvider(type: KillProcessTask) {

}

pact {
  serviceProviders {
    'Our_Provider' {
      port = 8080

      startProviderTask = startProvider
      terminateProviderTask = stopProvider

      hasPactWith('Our Little Consumer') {
        pactFile = file(""$buildDir/pacts/Our Little Consumer-Our Provider.json"")
      }
    }
  }
}
```

Now if we copy the pact file from the consumer project and run our pact verification task, it should fail.

```console
$ ./gradlew :providers:springboot-provider:pactVerify

> Task :providers:springboot-provider:startProvider

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.0.0.RELEASE)
```

... omitting lots of logs ...

```console
2018-04-10 13:55:19.709  INFO 7912 --- [           main] a.c.d.p.s.MainApplication                : Started MainApplication in 3.311 seconds (JVM running for 3.774)
java -jar /home/ronald/Development/Projects/Pact/pact-workshop-jvm/providers/springboot-provider/build/libs/springboot-provider.jar is ready.

> Task :providers:springboot-provider:pactVerify_Our_Provider FAILED

Verifying a pact between Our Little Consumer and Our_Provider
  [Using File /home/ronald/Development/Projects/Pact/pact-workshop-jvm/providers/springboot-provider/build/pacts/Our Little Consumer-Our Provider.json]
  Given data count > 0
         WARNING: State Change ignored as there is no stateChange URL
  a request for json data
    returns a response which
      has status code 200 (OK)
      has a matching body (FAILED)

NOTE: Skipping publishing of verification results as it has been disabled (pact.verifier.publishResults is not 'true')


Failures:

1) Verifying a pact between Our Little Consumer and Our_Provider - a request for json data Given data count > 0

    1.1) BodyMismatch: $ BodyMismatch: Expected date='2013-08-16T15:31:20+10:00' but was missing

        {
        -  ""date"": ""2013-08-16T15:31:20+10:00"",
          ""test"": ""NO"",
        -  ""count"": 100
        +  ""count"": 1000,
        +  ""validDate"": ""2020-06-16T12:08:04.314696""
        }


    1.2) BodyMismatch: $.count BodyMismatch: Expected 100 (Integer) but received 1000 (Integer)




FAILURE: Build failed with an exception.

* What went wrong:
There were 2 non-pending pact failures for provider Our_Provider

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 6s
5 actionable tasks: 5 executed
```

The test has failed for 2 reasons. Firstly, the count field has a different value to what was expected by the consumer.
Secondly, and more importantly, the consumer was expecting a `date` field while the provider generates a `validDate`
field. Also, the date formats are different.

## Step 5 - Verify the provider with a test

In this step we will verify the same pact file against the Dropwizard provider using a JUnit test. If you need to,
re-run the `publishWorkshopPact` to get the pact file in the provider project.

We add the pact provider junit jar and the dropwizard testing jar to our project dependencies, and then we can create a
simple test to verify our provider.

```java
@RunWith(PactRunner.class)
@Provider(""Our Provider"")
@PactFolder(""build/pacts"")
public class PactVerificationTest {
  @ClassRule
  public static final DropwizardAppRule<ServiceConfig> RULE = new DropwizardAppRule<ServiceConfig>(MainApplication.class,
    ResourceHelpers.resourceFilePath(""main-app-config.yaml""));

  @TestTarget
  public final Target target = new HttpTarget(8080);

  @State(""data count > 0"")
  public void dataCountGreaterThanZero() {

  }
}
```

This test will start the dropwizard app (using the class rule), and then execute the pact requests (defined by the
`@PactFolder` annotation) against the test target.

Running this test will fail for the same reasons as in step 4.

```console
$ ./gradlew :providers:dropwizard-provider:test
Starting a Gradle Daemon, 1 incompatible and 2 stopped Daemons could not be reused, use --status for details

> Task :providers:dropwizard-provider:test

au.com.dius.pactworkshop.dropwizardprovider.PactVerificationTest > Our Little Consumer - a request for json data FAILED
    java.lang.AssertionError

1 test completed, 1 failed


FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':providers:dropwizard-provider:test'.
> There were failing tests. See the report at: file:///home/ronald/Development/Projects/Pact/pact-workshop-jvm/providers/dropwizard-provider/build/reports/tests/test/index.html

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 12s
4 actionable tasks: 4 executed
```

The JUnit build report has the expected failures.

```
java.lang.AssertionError: 
Failures:

1) a request for json data

    1.1) BodyMismatch: $ BodyMismatch: Expected date='2013-08-16T15:31:20+10:00' but was missing

        {
        -  ""date"": ""2013-08-16T15:31:20+10:00"",
          ""test"": ""NO"",
        -  ""count"": 100
        +  ""count"": 1000,
        +  ""validDate"": ""2020-06-16T12:29:52.836""
        }


    1.2) BodyMismatch: $.count BodyMismatch: Expected 100 (Integer) but received 1000 (Integer)
```

## Step 6 - Back to the client we go

Let's correct the consumer test to handle any integer for `count` and use the correct field for the `date`. Then we need
to add a type matcher for `count` and change the field for the date to be `validDate`. We can also add a date expression
to make sure the `validDate` field is a valid date. This is important because we are parsing it.

The consumer test is now updated to:

```java
          .body(
              new PactDslJsonBody()
                  .stringValue(""test"", ""NO"")
                  .datetime(""validDate"", ""yyyy-MM-dd'T'HH:mm:ssXX"", dateResult.toInstant())
                  .integerType(""count"", 100)
          )
```

Running this test will fail until we fix the client. Here is the correct client function:

```java
  public List<Object> fetchAndProcessData(LocalDateTime dateTime) throws UnirestException {
      JsonNode data = loadProviderJson(dateTime);
      System.out.println(""data="" + data);

      JSONObject jsonObject = data.getObject();
      int value = 100 / jsonObject.getInt(""count"");
      TemporalAccessor date = DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ssXX"")
              .parse(jsonObject.getString(""validDate""));
      System.out.println(""value="" + value);
      System.out.println(""date="" + date);
      return Arrays.asList(value, OffsetDateTime.from(date));
  }
```

Now the test passes. But we still have a problem with the date format, which we must fix in the provider. Running the
client now fails because of that.

```console
$ ./gradlew consumer:run
Starting a Gradle Daemon, 1 busy and 1 incompatible and 2 stopped Daemons could not be reused, use --status for details

> Task :consumer:run FAILED
data={""test"":""NO"",""validDate"":""2018-04-10T14:39:50.419"",""count"":1000}
Exception in thread ""main"" java.time.format.DateTimeParseException: Text '2018-04-10T14:39:50.419' could not be parsed at index 19
        at java.time.format.DateTimeFormatter.parseResolved0(DateTimeFormatter.java:1949)
        at java.time.format.DateTimeFormatter.parse(DateTimeFormatter.java:1851)
        at java.time.OffsetDateTime.parse(OffsetDateTime.java:402)
        at au.com.dius.pactworkshop.consumer.Client.fetchAndProcessData(Client.java:34)
        at au.com.dius.pactworkshop.consumer.Consumer.main(Consumer.java:9)


FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':consumer:run'.
> Process 'command '/usr/lib/jvm/java-8-oracle/bin/java'' finished with non-zero exit value 1

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 5s
2 actionable tasks: 1 executed, 1 up-to-date
```

We need to **publish** the consumer pact file to the provider projects again. Then, running the provider verification
tests we get the expected failure about the date format.

```
Failures:

1) Verifying a pact between Our Little Consumer and Our_Provider - a request for json data Given data count > 0

    1.1) BodyMismatch: $.validDate BodyMismatch: Expected ""2020-06-16T13:01:21.675150"" to match a datetime of 'yyyy-MM-dd'T'HH:mm:ssXX': Text '2020-06-16T13:01:21.675150' could not be parsed at index 19

```

## Step 7 - Verify the providers again

Lets fix the providers and then re-run the verification tests. Here is the corrected Dropwizard resource:

```java
@RestController
public class RootController {

  @RequestMapping(""/provider.json"")
  public Map<String, Serializable> providerJson(@RequestParam(required = false) String validDate) {
    LocalDateTime validTime = LocalDateTime.parse(validDate);
    Map<String, Serializable> map = new HashMap<>(3);
    map.put(""test"", ""NO"");
    map.put(""validDate"", OffsetDateTime.now().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ssXX"")));
    map.put(""count"", 1000);
    return map;
  }

}
```


![Verification Passes](diagrams/step7_pact.png)


Running the verification against the providers now pass. Yay!

## Step 8 - Test for the missing query parameter

In this step we are going to add a test for the case where the query parameter is missing or invalid. We do this by 
adding additional tests and expectations to the consumer pact test. Our client code needs to be modified slightly to
be able to pass invalid dates in, and if the date parameter is null, don't include it in the request.

Here are the two additional tests:

*consumer/src/test/java/au/com/dius/pactworkshop/consumer/ClientPactTest.java:*

```java
  @Pact(provider = ""Our Provider"", consumer = ""Our Little Consumer"")
  public RequestResponsePact pactForMissingDateParameter(PactDslWithProvider builder) {
    dateTime = LocalDateTime.now();
    dateResult = OffsetDateTime.now().truncatedTo(ChronoUnit.SECONDS);
    return builder
            .given(""data count > 0"")
            .uponReceiving(""a request with a missing date parameter"")
            .path(""/provider.json"")
            .method(""GET"")
            .willRespondWith()
            .status(400)
            .body(
                new PactDslJsonBody().stringValue(""error"", ""validDate is required"")
            )
            .toPact();
  }

  @Test
  @PactVerification(value = ""Our Provider"", fragment = ""pactForMissingDateParameter"")
  public void handlesAMissingDateParameter() throws UnirestException {
    // Set up our HTTP client class
    Client client = new Client(provider.getUrl());

    // Invoke out client
    List<Object> result = client.fetchAndProcessData(null);

    assertThat(result, hasSize(2));
    assertThat(result.get(0), is(0));
    assertThat(result.get(1), nullValue());
  }

  @Pact(provider = ""Our Provider"", consumer = ""Our Little Consumer"")
  public RequestResponsePact pactForInvalidDateParameter(PactDslWithProvider builder) {
    dateTime = LocalDateTime.now();
    dateResult = OffsetDateTime.now().truncatedTo(ChronoUnit.SECONDS);
    return builder
            .given(""data count > 0"")
            .uponReceiving(""a request with an invalid date parameter"")
            .path(""/provider.json"")
            .method(""GET"")
            .query(""validDate=This is not a date"")
            .willRespondWith()
            .status(400)
            .body(
                 new PactDslJsonBody().stringValue(""error"", ""'This is not a date' is not a date"")
            )
            .toPact();
  }

  @Test
  @PactVerification(value = ""Our Provider"", fragment = ""pactForInvalidDateParameter"")
  public void handlesAInvalidDateParameter() throws UnirestException {
    // Set up our HTTP client class
    Client client = new Client(provider.getUrl());

    // Invoke out client
    List<Object> result = client.fetchAndProcessData(""This is not a date"");

    assertThat(result, hasSize(2));
    assertThat(result.get(0), is(0));
    assertThat(result.get(1), nullValue());
  }
```

After running our specs, the pact file will have 2 new interactions.

*consumer/build/pacts/Our Little Consumer-Our Provider.json:*

```json
[
  {
    ""description"": ""a request with a missing date parameter"",
    ""request"": {
      ""method"": ""GET"",
      ""path"": ""/provider.json""
    },
    ""response"": {
      ""status"": 400,
      ""headers"": {
        ""Content-Type"": ""application/json; charset=UTF-8""
      },
      ""body"": {
        ""error"": ""validDate is required""
      },
      ""matchingRules"": {
        ""header"": {
          ""Content-Type"": {
            ""matchers"": [
              {
                ""match"": ""regex"",
                ""regex"": ""application/json(;\\s?charset=[\\w\\-]+)?""
              }
            ],
            ""combine"": ""AND""
          }
        }
      }
    },
    ""providerStates"": [
      {
        ""name"": ""data count > 0""
      }
    ]
  },
  {
    ""description"": ""a request with an invalid date parameter"",
    ""request"": {
      ""method"": ""GET"",
      ""path"": ""/provider.json"",
      ""query"": {
        ""validDate"": [
          ""This is not a date""
        ]
      }
    },
    ""response"": {
      ""status"": 400,
      ""headers"": {
        ""Content-Type"": ""application/json; charset=UTF-8""
      },
      ""body"": {
        ""error"": ""'This is not a date' is not a date""
      },
      ""matchingRules"": {
        ""header"": {
          ""Content-Type"": {
            ""matchers"": [
              {
                ""match"": ""regex"",
                ""regex"": ""application/json(;\\s?charset=[\\w\\-]+)?""
              }
            ],
            ""combine"": ""AND""
          }
        }
      }
    },
    ""providerStates"": [
      {
        ""name"": ""data count > 0""
      }
    ]
  }
]
```

## Step 9 - Verify the provider with the missing/invalid date query parameter
   
Let us run this updated pact file with our providers (first run the `publishWorkshopPact` task). We get a 500 response as the provider can't handle the missing
or incorrect date.

Here is the springboot test output:

```console
Verifying a pact between Our Little Consumer and Our_Provider
  [Using File /home/ronald/Development/Projects/Pact/pact-workshop-jvm/providers/springboot-provider/build/pacts/Our Little Consumer-Our Provider.json]
  Given data count > 0
         WARNING: State Change ignored as there is no stateChange URL
  a request for json data
    returns a response which
      has status code 200 (OK)
      has a matching body (OK)
  Given data count > 0
         WARNING: State Change ignored as there is no stateChange URL
  a request with a missing date parameter
    returns a response which
      has status code 400 (FAILED)
      has a matching body (FAILED)
  Given data count > 0
         WARNING: State Change ignored as there is no stateChange URL
  a request with an invalid date parameter
    returns a response which
      has status code 400 (FAILED)
      has a matching body (FAILED)

NOTE: Skipping publishing of verification results as it has been disabled (pact.verifier.publishResults is not 'true')


Failures:

1) Verifying a pact between Our Little Consumer and Our_Provider - a request with a missing date parameter Given data count > 0

    1.1) StatusMismatch: expected status of 400 but was 500

    1.2) BodyMismatch: $.error BodyMismatch: Expected 'validDate is required' (String) but received 'Internal Server Error' (String)

    1.3) StatusMismatch: expected status of 400 but was 500

    1.4) BodyMismatch: $.error BodyMismatch: Expected ''This is not a date' is not a date' (String) but received 'Internal Server Error' (String)

```

Time to update the providers to handle these cases.

## Step 10 - Update the providers to handle the missing/invalid query parameters

Let's fix our providers so they generate the correct responses for the query parameters.

### Dropwizard provider

The Dropwizard root resource gets updated to check if the parameter has been passed, and handle the date parse exception
if it is invalid. Two new exceptions get thrown for these cases.

```java
  @GET
  public Map<String, Serializable> providerJson(@QueryParam(""validDate"") Optional<String> validDate) {
    if (validDate.isPresent()) {
      try {
        LocalDateTime validTime = LocalDateTime.parse(validDate.get());
        Map<String, Serializable> result = new HashMap<>(3);
        result.put(""test"", ""NO"");
        result.put(""validDate"", OffsetDateTime.now().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ssXX"")));
        result.put(""count"", 1000);
        return result;
      } catch (DateTimeParseException e) {
        throw new InvalidQueryParameterException(""'"" + validDate.get() + ""' is not a date"", e);
      }
    } else {
      throw new QueryParameterRequiredException(""validDate is required"");
    }
  }
```

Next step is to create exception mappers for the new exceptions, and register them with the Dropwizard environment.

```java
public class InvalidQueryParameterExceptionMapper implements ExceptionMapper<InvalidQueryParameterException> {
  @Override
  public Response toResponse(InvalidQueryParameterException exception) {
    return Response.status(Response.Status.BAD_REQUEST)
      .type(MediaType.APPLICATION_JSON_TYPE)
      .entity(""{\""error\"": \"""" + exception.getMessage() + ""\""}"")
      .build();
  }
}
```

The main provider run method becomes:

```groovy
  void run(ServiceConfig configuration, Environment environment) {
    environment.jersey().register(new InvalidQueryParameterExceptionMapper())
    environment.jersey().register(new QueryParameterRequiredExceptionMapper())
    environment.jersey().register(new RootResource())
  }
```

Now running the `PactVerificationTest` will pass.

### Springboot provider

The Springboot root controller gets updated in a similar way to the Dropwizard resource.

```java
  @RequestMapping(""/provider.json"")
  public Map<String, Serializable> providerJson(@RequestParam(required = false) String validDate) {
    if (StringUtils.isNotEmpty(validDate)) {
      try {
        LocalDateTime validTime = LocalDateTime.parse(validDate);
        Map<String, Serializable> map = new HashMap<>(3);
        map.put(""test"", ""NO"");
        map.put(""validDate"", OffsetDateTime.now().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ssXX"")));
        map.put(""count"", 1000);
        return map;
      } catch (DateTimeParseException e) {
        throw new InvalidQueryParameterException(""'"" + validDate + ""' is not a date"", e);
      }
    } else {
      throw new QueryParameterRequiredException(""validDate is required"");
    }
  }
```

Then, to get the exceptions mapped to the correct response, we need to create a controller advice.

```java
@ControllerAdvice(basePackageClasses = RootController.class)
public class RootControllerAdvice extends ResponseEntityExceptionHandler {
  @ExceptionHandler({InvalidQueryParameterException.class, QueryParameterRequiredException.class})
  @ResponseBody
  public ResponseEntity<String> handleControllerException(HttpServletRequest request, Throwable ex) {
    HttpHeaders headers = new HttpHeaders();
    headers.setContentType(MediaType.APPLICATION_JSON);
    return new ResponseEntity<>(""{\""error\"": \"""" + ex.getMessage() + ""\""}"", headers, HttpStatus.BAD_REQUEST);
  }
}
```

Now running the `pactVerify` is all successful.

## Step 11 - Provider states

We have one final thing to test for. If the provider ever returns a count of zero, we will get a division by
zero error in our client. This is an important bit of information to add to our contract. Let us start with a
consumer test for this.

```java
    @Pact(provider = ""Our Provider"", consumer = ""Our Little Consumer"")
    public RequestResponsePact pactForWhenThereIsNoData(PactDslWithProvider builder) {
      dateTime = LocalDateTime.now();
      return builder
              .given(""data count == 0"")
              .uponReceiving(""a request for json data"")
              .path(""/provider.json"")
              .method(""GET"")
              .query(""validDate="" + dateTime.toString())
              .willRespondWith()
              .status(404)
              .toPact();
    }
  
    @Test
    @PactVerification(value = ""Our Provider"", fragment = ""pactForWhenThereIsNoData"")
    public void whenThereIsNoData() throws UnirestException {
      // Set up our HTTP client class
      Client client = new Client(provider.getUrl());
  
      // Invoke out client
      List<Object> result = client.fetchAndProcessData(dateTime.toString());
  
      assertThat(result, hasSize(2));
      assertThat(result.get(0), is(0));
      assertThat(result.get(1), nullValue());
    }
```

This adds a new interaction to the pact file:

```json

  {
        ""description"": ""a request for json data"",
        ""request"": {
          ""method"": ""GET"",
          ""path"": ""/provider.json"",
          ""query"": {
            ""validDate"": [
              ""2020-06-16T13:56:47.303""
            ]
          }
        },
        ""response"": {
          ""status"": 404
        },
        ""providerStates"": [
          {
            ""name"": ""data count == 0""
          }
        ]
  }

```

## Step 12 - provider states for the providers

To be able to verify our providers, we need to be able to change the data that the provider returns. There are different
ways of doing this depending on how the provider is being verified.


### Dropwizard provider

The dropwizard provider is being verified by a test, so we can setup methods annotated with the state and then modify the
controller appropriately. First, we need some data store that we could manipulate. For out case, we are just going to
use a singleton class, but in a real project you would probably use a database.

```java
public class DataStore {
  public static final DataStore INSTANCE = new DataStore();
  private int dataCount = 1000;

  private DataStore() { }

  public int getDataCount() {
    return dataCount;
  }

  public void setDataCount(int dataCount) {
    this.dataCount = dataCount;
  }
}
```

Next, we update our root resource to use the value from the data store, and throw an exception if there is no data.

```java
  @GET
  public Map<String, Serializable> providerJson(@QueryParam(""validDate"") Optional<String> validDate) {
    if (validDate.isPresent()) {
      if (DataStore.INSTANCE.getDataCount() > 0) {
        try {
          LocalDateTime validTime = LocalDateTime.parse(validDate.get());
          Map<String, Serializable> result = new HashMap<>(3);
          result.put(""test"", ""NO"");
          result.put(""validDate"", OffsetDateTime.now().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ssXX"")));
          result.put(""count"", DataStore.INSTANCE.getDataCount());
          return result;
        } catch (DateTimeParseException e) {
          throw new InvalidQueryParameterException(""'"" + validDate.get() + ""' is not a date"", e);
        }
      } else {
        throw new NoDataException();
      }
    } else {
      throw new QueryParameterRequiredException(""validDate is required"");
    }
  }
```

We do the same exception mapping for the new exception as we did before.

```java
public class NoDataExceptionMapper implements ExceptionMapper<NoDataException> {
  @Override
  public Response toResponse(NoDataException exception) {
    return Response.status(Response.Status.NOT_FOUND).build();
  }
}
```

Now we can change the data store value in our test based on the provider state.

```java
  @State(""data count > 0"")
  public void dataCountGreaterThanZero() {
    DataStore.INSTANCE.setDataCount(1000);
  }

  @State(""data count == 0"")
  public void dataCountZero() {
    DataStore.INSTANCE.setDataCount(0);
  }
```

Running the test now passes.

### Springboot provider

Our Springboot provider is being verified by the Pact Gradle verification task, which requires the provider to be
running in the background. We can not directly manipulate it. The Gradle task has a state change URL feature that can
help us here. This is basically a special URL that will receive the state that the provider needs to be in.

First, lets enable the state change URL handling in the build gradle file.

```groovy
pact {
  serviceProviders {
    'Our_Provider' {
      port = 8080

      startProviderTask = startProvider
      terminateProviderTask = stopProvider
      stateChangeUrl = url('http://localhost:8080/pactStateChange')

      hasPactWith('Our Little Consumer') {
        pactFile = file(""$buildDir/pacts/Our Little Consumer-Our Provider.json"")
      }
    }
  }
}
```

Now we create a new controller to handle this. As this controller is only for our test, we make sure it is only available
in the test profile. We also need to make sure the app runs in the test profile by adding a parameter to the start task.

```groovy
task startProvider(type: SpawnProcessTask, dependsOn: 'assemble') {
  command ""java -Dspring.profiles.active=test -jar ${jar.archivePath}""
  ready 'Started MainApplication'
}
```

Here is the state change controller:

```java
@RestController
@Profile(""test"")
public class StateChangeController {
  @RequestMapping(value = ""/pactStateChange"", method = RequestMethod.POST)
  public void providerState(@RequestBody Map body) {
    if (body.get(""state"").equals(""data count > 0"")) {
      DataStore.INSTANCE.setDataCount(1000);
    } else if (body.get(""state"").equals(""data count == 0"")) {
      DataStore.INSTANCE.setDataCount(0);
    }
  }
}
```

This controller will change the value of the datastore. We then use the datastore in our normal controller.

```java
  @RequestMapping(""/provider.json"")
  public Map<String, Serializable> providerJson(@RequestParam(required = false) String validDate) {
    if (StringUtils.isNotEmpty(validDate)) {
      if (DataStore.INSTANCE.getDataCount() > 0) {
        try {
          LocalDateTime validTime = LocalDateTime.parse(validDate);
          Map<String, Serializable> map = new HashMap<>(3);
          map.put(""test"", ""NO"");
          map.put(""validDate"", OffsetDateTime.now().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ssXX"")));
          map.put(""count"", DataStore.INSTANCE.getDataCount());
          return map;
        } catch (DateTimeParseException e) {
          throw new InvalidQueryParameterException(""'"" + validDate + ""' is not a date"", e);
        }
      } else {
        throw new NoDataException();
      }
    } else {
      throw new QueryParameterRequiredException(""validDate is required"");
    }
  }
```

and update our controller advice to return the 404 response when a `NoDataException` is raised.

```java
@ControllerAdvice(basePackageClasses = RootController.class)
public class RootControllerAdvice extends ResponseEntityExceptionHandler {
  @ExceptionHandler({InvalidQueryParameterException.class, QueryParameterRequiredException.class})
  @ResponseBody
  public ResponseEntity<String> handleControllerException(HttpServletRequest request, Throwable ex) {
    HttpHeaders headers = new HttpHeaders();
    headers.setContentType(MediaType.APPLICATION_JSON);
    return new ResponseEntity<>(""{\""error\"": \"""" + ex.getMessage() + ""\""}"", headers, HttpStatus.BAD_REQUEST);
  }

  @ExceptionHandler(NoDataException.class)
  @ResponseBody
  ResponseEntity handleNoDataException(HttpServletRequest request, Throwable ex) {
    return new ResponseEntity(HttpStatus.NOT_FOUND);
  }
}
```

Running the Gradle pact verification now passes.

# Step 13 - Using a Pact Broker

We've been publishing our pacts from the consumer project by coping the files over to the provider project, but we can
use a Pact Broker to do this instead.

### Running the Pact Broker locally or against a hosted broker (e.g. Pactflow)

If you'd like to play along locally we have a docker-compose example you can use. Start it by running:

```
docker-compose up
```

Afterwards, it should be running on port `9292`. Head to `http://localhost:9292` and you should see the OSS pact broker running.

The credentials are `pact_workshop` / `pact_workshop`.

The project properties (`gradle.properties`) defaults to using this with the relevant credentials. Update as required to your own hosted platform such as
or your pactflow.io account.

### Consumer

First, in the consumer project we need to add the Gradle Pact plugin and tell it about our broker.

```groovy
plugins {
  id ""au.com.dius.pact"" version ""4.1.7""
}

... omitted ...

pact {
  publish {
    pactBrokerUrl = 'https://test.pact.dius.com.au'
    pactBrokerUsername = project.pactBrokerUser
    pactBrokerPassword = project.pactBrokerPassword
  }
}

```

Now, we can run `./gradlew consumer:pactPublish` after running the consumer tests to have the generated pact file 
published to the broker. Afterwards, you can navigate to the Pact Broker URL and see the published pact against
the consumer and provider names setup in our consumer test.

![Our Pact Is Published](diagrams/published.png)

### Dropwizard provider

In the `PactVerificationTest` we can change the source we fetch pacts from by using a `@PactBroker` annotation instead
of the `@PactFolder` one. We also need to pass the username and property through to the test.

Updated gradle build file:

```groovy
test {
  systemProperty 'pactBrokerUser', pactBrokerUser
  systemProperty 'pactBrokerPassword', pactBrokerPassword
}
```

Updated test:

```java
@RunWith(PactRunner.class)
@Provider(""Our Provider"")
@PactBroker(host = ""test.pact.dius.com.au"", protocol = ""https"", port = ""443"",
  authentication = @PactBrokerAuth(username = ""${pactBrokerUser}"", password = ""${pactBrokerPassword}""))
public class PactVerificationTest {
  @ClassRule
  public static final DropwizardAppRule<ServiceConfig> RULE = new DropwizardAppRule<ServiceConfig>(MainApplication.class,
    ResourceHelpers.resourceFilePath(""main-app-config.yaml""));

  @TestTarget
  public final Target target = new HttpTarget(8080);

  @State(""data count > 0"")
  public void dataCountGreaterThanZero() {
    DataStore.INSTANCE.setDataCount(1000);
  }

  @State(""data count == 0"")
  public void dataCountZero() {
    DataStore.INSTANCE.setDataCount(0);
  }
}
```

### Springboot provider

The springboot provider is using the Gradle plugin, so we can just configure its build to fetch the pacts from the 
broker.

Updated build file:

```groovy
pact {
  serviceProviders {
    'Our Provider' {
      port = 8080

      startProviderTask = startProvider
      terminateProviderTask = stopProvider
      stateChangeUrl = url('http://localhost:8080/pactStateChange')

      hasPactsFromPactBroker(""https://test.pact.dius.com.au"", authentication: ['Basic', pactBrokerUser, pactBrokerPassword])
    }
  }
}
```

Running either of the verification tests will now publish the result back to the broker. If you refresh the index page in the broker,
you will see the pacts marked as verified.

![Our Pact Is Verified](diagrams/verified.png)
"
mstahv/jpa-invoicer,jakarta-ee-10,82,51,2015-02-10T11:58:33Z,599,8,"Jakarta EE, JPA, Vaadin example app",,"# Invoicing example application

Note: This project is currently beeing upgraded to Vaadin 24 & Jakarta EE 10. The old Vaadin 7 version is available in a [separate branch](https://github.com/mstahv/jpa-invoicer/tree/vaadin-7). This version misses certain things, like authentication has not been upgraded/tested.

Simple app to collaboratively create invoices. This application is built as an example application for Vaadin UI framework and various Java EE technologies. Still it should be perfectly usable as such in a real use.

Features:

 * Based on Java EE stack, persistency with JPA to RDBMS, UI built with Vaadin
 * Multiple organisations that can send invoices, shareable with other users
 * Customer registry, used fluently via invoice view
 * PDF/ODT export for invoices, configurable ODT template
 * User backups via XML export
 * Google OAuth2 based login

This is a suitable basis for small to medium sized apps. For larger applications,
consider using MVP to structure your UI code. See e.g. [this example 
application](https://github.com/peterl1084/cdiexample).

## Quickstart

<del>
Start the application with an embedded wildfly:
```
mvn clean package wildfly:run
```

</del>

Current version does not make the latest Wildfly/Hibernate happy. Try with e.g.
Payara 6 that works well 👍

After startup the application is available here: [http://localhost:8080/invoicer](http://localhost:8080/invoicer)
"
jcasbin/casbin-spring-boot-starter,master,179,69,2019-04-06T15:27:18Z,255,2,"Spring Boot 2.x & 3.x Starter for Casbin, see example at: https://github.com/jcasbin/casbin-spring-boot-example",abac acl auth authorization authz casbin java jcasbin rbac spring spring-boot spring-boot-2 spring-boot-3 springboot springbootstarter,"# Casbin Spring Boot Starter

[![Codecov branch](https://img.shields.io/codecov/c/github/jcasbin/casbin-spring-boot-starter/master.svg?logo=codecov&style=flat-square)](https://codecov.io/gh/jcasbin/casbin-spring-boot-starter)
[![GitHub Actions](https://github.com/jcasbin/casbin-spring-boot-starter/workflows/build/badge.svg)](https://github.com/jcasbin/casbin-spring-boot-starter/actions)
[![Maven Central](https://img.shields.io/maven-central/v/org.casbin/casbin-spring-boot-starter.svg?style=flat-square&color=brightgreen)](https://mvnrepository.com/artifact/org.casbin/casbin-spring-boot-starter/latest)
[![License](https://img.shields.io/github/license/jcasbin/casbin-spring-boot-starter.svg?style=flat-square&color=blue)](http://www.apache.org/licenses/LICENSE-2.0.txt)
[![SpringBootVersion](https://img.shields.io/badge/SpringBoot-2.3.5-heightgreen.svg?style=flat-square)](https://spring.io/projects/spring-boot)
[![JCasbinVersion](https://img.shields.io/badge/JCasbinVersion-1.9.2-heightgreen.svg?style=flat-square)](https://casbin.org)

[![](https://raw.githubusercontent.com/casbin/jcasbin/master/casbin-logo.png)](https://casbin.org)

Casbin Spring Boot Starter is designed to help you easily integrate [jCasbin](https://github.com/casbin/jcasbin) into
your Spring Boot project.

## how to use

1. Add ```casbin-spring-boot-starter``` to the Spring Boot project.

```Maven```

```xml

<dependency>
    <groupId>org.casbin</groupId>
    <artifactId>casbin-spring-boot-starter</artifactId>
    <version>version</version>
</dependency>
```

```Gradle```

```groovy
implementation 'org.casbin:casbin-spring-boot-starter:version'
```

2. Inject the Enforcer where you need to use it

```java

@Component
public class Test {
    @Autowired
    private Enforcer enforcer;
}
```

3. Add configuration

```yaml
casbin:
  #Whether to enable Casbin, it is enabled by default.
  enableCasbin: true
  #Whether to use thread-synchronized Enforcer, default false
  useSyncedEnforcer: false
  #Whether to enable automatic policy saving, if the adapter supports this function, it is enabled by default.
  autoSave: true
  #Storage type [file, jdbc], currently supported jdbc database [mysql (mariadb), h2, oracle, postgresql, db2]
  #Welcome to write and submit the jdbc adapter you are using, see: org.casbin.adapter.OracleAdapter
  #The jdbc adapter will actively look for the data source information you configured in spring.datasource
  #Default use jdbc, and use the built-in h2 database for memory storage
  storeType: jdbc
  #Customized policy table name when use jdbc, casbin_rule as default.
  tableName: casbin_rule
  #Data source initialization policy [create (automatically create data table, no longer initialized if created), never (always do not initialize)]
  initializeSchema: create
  #Local model configuration file address, the default reading location: classpath: casbin/model.conf
  model: classpath:casbin/model.conf
  #If the model configuration file is not found in the default location and casbin.model is not set correctly, the built-in default rbac model is used, which takes effect by default.
  useDefaultModelIfModelNotSetting: true
  #Local policy configuration file address, the default reading location: classpath: casbin/policy.csv
  #If the configuration file is not found in the default location, an exception will be thrown.
  #This configuration item takes effect only when casbin.storeType is set to file.
  policy: classpath:casbin/policy.csv
  #Whether to enable the CasbinWatcher mechanism, the default is not enabled.
  #If the mechanism is enabled, casbin.storeType must be jdbc, otherwise the configuration is invalid.
  enableWatcher: false
  #CasbinWatcher notification mode, defaults to use Redis for notification synchronization, temporarily only supports Redis
  #After opening Watcher, you need to manually add spring-boot-starter-data-redis dependency.
  watcherType: redis
  exception:
    ... See Schedule A for exception settings.
```

4. The simplest configuration

- Do not use other add-on configurations

```yaml
casbin:
  #If you are using a model profile at this address, no configuration is required
  model: classpath:casbin/model.conf
```

- Turn on Watcher

```yaml
casbin:
  #If the model profile you are using is located at this address, you do not need this configuration
  model: classpath:casbin/model.conf
  #When you open Watcher, the default use of RedisWatcher requires manual addition of spring-boot-starter-data-redis dependency.
  enableWatcher: true
```

5. Use custom independent data sources

- Only increase ```@CasbinDataSource``` annotation when injecting custom data source

```java

@Configuration
public class CasbinDataSourceConfiguration {
    @Bean
    @CasbinDataSource
    public DataSource casbinDataSource() {
        return DataSourceBuilder.create().url(""jdbc:h2:mem:casbin"").build();
    }
}
```

##### Schedule A

- ExceptionSettings(casbin.exception)

| name               | description                                      | default |
|--------------------|--------------------------------------------------|---------|
| removePolicyFailed | Throws an exception when the delete policy fails | false   |

##### Note: If you do not set another data source, or set the storage file location for H2, the data is stored in memory by default using H2.

#### Notice:

Since version 0.0.11, casbin-spring-boot-starter adds an id field to the database table structure by default.

The version before 0.0.11 is upgraded to version 0.0.11 and later requires the user to manually add the id field.

See https://github.com/jcasbin/casbin-spring-boot-starter/issues/21 for details
"
thecodinglive/JPub-JavaWebService,master,37,37,2015-04-13T15:49:55Z,483,4,here is  book example,,"# 스프링부트로 배우는 자바 웹 서비스
here is  book example

<img src=""https://i.imgur.com/yfYoywG.jpg""  width=""350"" height=""450""/>

## download
[zip파일로 소스코드 전체 다운로드](https://github.com/thecodinglive/JPub-JavaWebService/archive/master.zip)

목차
CHAPTER 1 개발 환경의 변화와 자바 · 1 

CHAPTER 2 서블릿 · 11 


CHAPTER 3 스프링 프레임워크 · 49 


CHAPTER 4 스프링 부트 웹 개발 · 81 


CHAPTER 5 REST API 서버 만들기 · 117 


CHAPTER 6 스프링 부트와 데이터 · 149 


CHAPTER 7 커스텀 스프링 부트 스타터 · 221 

CHAPTER 8 예외 처리 및 테스트 · 249 


CHAPTER 9 배포 · 281 


CHAPTER 10 모니터링 · 299 


CHAPTER 11 캐시 · 311 


CHAPTER 12 회원 관리 · 341 "
timothyrenner/kafka-streams-ex,master,64,23,2016-03-14T04:03:59Z,351,0,A collection of examples and use-cases for Kafka Streams,,"# Kafka Streams Examples

This repository contains examples of use cases (ranging from trivial to somewhat complex) of Kafka Streams.

Each example is in it's own directory.
The repository contains the following examples:

* [Exclamation](https://github.com/timothyrenner/kafka-streams-ex/tree/master/exclamation): Trivial example that reads from the console consumer and appends two exclamation points.
* [Exclamation Advanced](https://github.com/timothyrenner/kafka-streams-ex/tree/master/exclamation-advanced): Slightly more complicated version of Exclamation that ""alerts"" on highly exclamated messages.
* [Hopping Windows](https://github.com/timothyrenner/kafka-streams-ex/tree/master/hopping-window): Example demonstrating the behavior of hopping windows by counting the elements on a single key.
* [Tumbling Windows](https://github.com/timothyrenner/kafka-streams-ex/tree/master/tumbling-window): Example demonstrating the behavior of tumbling windows by counting the elements on a single key.
* [Processor](https://github.com/timothyrenner/kafka-streams-ex/tree/master/processor): Example demonstrating the processor API, state stores, and custom serializers.
* [Instrumented Processor](https://github.com/timothyrenner/kafka-streams-ex/tree/master/processor-instrumented): A stripped down version of the processor example that logs the values in the state store - designed to run in two nodes (or just two terminals) to show what happens under failover conditions.
* [Not Looking at Facebook](https://github.com/timothyrenner/kafka-streams-ex/tree/master/not-looking-at-facebook): Implementation of a streaming pipeline for notifying users when they aren't looking at Facebook.
* [KTable](https://github.com/timothyrenner/kafka-streams-ex/tree/master/ktable): Literally a KTable.
* [Windowed Delay](https://github.com/timothyrenner/kafka-streams-ex/tree/master/windowed-delay): Demonstration of event-time ordering.
"
graalvm/graalvm-demos,master,538,140,2018-04-02T09:50:42Z,82826,10,This repository contains example applications to illustrate the different capabilities of GraalVM,graalvm graalvm-demos native-image,"# GraalVM Demos

This repository contains demo applications and benchmarks written in Java, JavaScript, Python, and other languages.
These applications illustrate the diverse capabilities of [GraalVM](http://graalvm.org). 

The demos are sorted by a framework, by a programming language, or by a technology.
Each directory contains demo sources; the instructions on how to run a particular demo are in its _README.md_ file.
To get started, clone or download this repository, enter the demo directory, and follow steps in the _README.md_ file.


```
git clone https://github.com/graalvm/graalvm-demos.git
cd graalvm-demos
```

### GraalVM JDK and Native Image

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/tiny-java-containers/"">tiny-java-containers</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/tiny-java-containers.yml""><img alt=""tiny-java-containers"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/tiny-java-containers.yml/badge.svg"" /></a>
      <td align=""left"" width=""70%"">Demonstrates how to build very small Docker container images with GraalVM Native Image and various lightweight base images. <br><strong>Technologies: </strong> Native Image, musl libc<br><strong>Reference: </strong><a href=""https://www.graalvm.org/22.0/reference-manual/native-image/StaticImages/"">Static and Mostly Static Images</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/hello-graal/"">hello-graal</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/hello-graal.yml""><img alt=""hello-graal"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/hello-graal.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to build native executables from a class file and a JAR file from the command line <br><strong>Technologies: </strong> Native Image <br><strong>Reference: </strong><a href=""https://www.graalvm.org/dev/reference-manual/native-image/#build-a-native-executable"">Native Image Getting Started</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/java-hello-world-maven/"">java-hello-world-maven</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/java-hello-world-maven.yml""><img alt=""java-hello-world-maven"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/java-hello-world-maven.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to generate a native executable using the Native Build Tools Maven plugin <br><strong>Technologies: </strong>Native Image, Native Build Tools Maven plugin<br><strong>Reference: </strong><a href=""https://docs.oracle.com/en/graalvm/jdk/21/docs/getting-started/oci/code-editor/"">Oracle GraalVM in OCI Code Editor</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-hello-module/"">native-hello-module</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-hello-module.yml""><img alt=""native-hello-module"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-hello-module.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to build a modular Java application into a native executable<br><strong>Technologies: </strong>Native Image, Maven<br><strong>Reference: </strong><a href=""https://www.graalvm.org/dev/reference-manual/native-image/guides/build-java-modules-into-native-executable/"">Build Java Modules into a Native Executable</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-list-dir/"">native-list-dir</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-list-dir.yml""><img alt=""native-list-dir"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-list-dir.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to compile a CLI application into a native executable and then apply Profile-Guided Optimizations (PGO) for more performance gains<br><strong>Technologies: </strong>Native Image, PGO
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/java-simple-stream-benchmark/"">java-simple-stream-benchmark</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/java-simple-stream-benchmark.yml""><img alt=""java-simple-stream-benchmark"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/java-simple-stream-benchmark.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how the Graal compiler can achieve better performance for highly abstracted programs like those using Streams, Lambdas<br><strong>Technologies: </strong>Graal compiler, C2<br><strong>Reference: </strong><a href=""https://luna.oracle.com/lab/d502417b-df66-45be-9fed-a3ac8e3f09b1/steps#task-2-run-demos-java-microbenchmark-harness-jmh"">Simple Java Stream Benchmark</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/streams/"">streams</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/streams.yml""><img alt=""streams"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/streams.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demontrates how GraalVM efficiently optimizes the Java Streams API application and how to apply PGO<br><strong>Technologies: </strong>Native Image, Native Build Tools Maven Plugin <br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/optimize-native-executable-with-pgo/"">Optimize a Native Executable with Profile-Guided Optimizations</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/fortune-demo/"">fortune-demo</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/fortune-demo.yml""><img alt=""fortune-demo"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/fortune-demo.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">A fortune teller Unix program. Run it in JIT, build a native executable, or build a mostly-static native executable, using Gradle or Maven build tools.<br><strong>Technologies: </strong>Native Image, Native Build Tools<br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/use-graalvm-dashboard/"">Use GraalVM Dashboard to Optimize the Size of a Native Executable</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/multithreading-demo/"">multithreading-demo</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/streams.yml""><img alt=""streams"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/streams.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to optimize a Java application that does synchronous and asynchronous threads execution<br><strong>Technologies: </strong>Native Image, Native Build Tools Maven plugin, GraalVM Dashboard <br><strong>Reference: </strong><a href=""https://medium.com/graalvm/making-sense-of-native-image-contents-741a688dab4d"">Making sense of Native Image contents</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-image-configure-examples/"">native-image-configure-examples</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/streams.yml""><img alt=""streams"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/streams.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how you can influence the classes initialization at the image build time<br><strong>Technologies: </strong>Native Image, Maven<br><strong>Reference: </strong><a href=""https://medium.com/graalvm/understanding-class-initialization-in-graalvm-native-image-generation-d765b7e4d6ed"">Understanding Class Initialization in GraalVM Native Image Generation</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-netty-plot/"">native-netty-plot</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-netty-plot.yml""><img alt=""native-netty-plot"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-netty-plot.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">A web server application, using the Netty framework, to demonstrate the use of isolates with Native Image<br><strong>Technologies: </strong>Native Image, Maven, Netty<br><strong>Reference: </strong><a href=""https://medium.com/graalvm/instant-netty-startup-using-graalvm-native-image-generation-ed6f14ff7692"">Instant Netty Startup using GraalVM Native Image Generation</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/javagdbnative/"">javagdbnative</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/javagdbnative.yml""><img alt=""javagdbnative"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/javagdbnative.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to debug a Java application, built into a native executable in VS Code<br><strong>Technologies: </strong>Native Image, Maven, GraalVM Tools for Java<br><strong>Reference: </strong><a href=""https://medium.com/graalvm/native-image-debugging-in-vs-code-2d5dda1989c1"">Native Image Debugging in VS Code</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-image-logging-examples/"">native-image-logging-examples</a><br><a href=""https://github.com/graalvm/graalvm-demos/blob/ni-logging-demo/.github/workflows/native-image-logging-examples.yml""><img alt=""native-image-logging-examples"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-image-logging-examples.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to initialize Loggers with Native Image at the executable build or run time<br><strong>Technologies: </strong> Native Image<br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/add-logging-to-native-executable/"">Add Logging to a Native Executable</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-jfr-demo/"">native-jfr-demo</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/ni-native-executable-jfr-demo/.github/workflows/native-jfr-demo.yml""><img alt=""native-jfr-demo"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-jfr-demo.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to create a custom JDK Flight Recorder (JFR) event and use that in a native executable<br><strong>Technologies: </strong> Native Image, JFR, VisualVM <br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/build-and-run-native-executable-with-jfr/"">Build and Run Native Executables with JFR</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-shared-library/"">native-shared-library</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-shared-library.yml""><img alt=""native-shared-library"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-shared-library.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to create a Java class library, use Native Image to create a native shared library, and then create a small C application that uses that shared library<br><strong>Technologies: </strong> Native Image, LLVM toolchain <br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/build-native-shared-library/"">Build a Native Shared Library</a></td>
    </tr>  
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-image-reflection-example/"">native-image-reflection-example</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-image-reflection-example.yml""><img alt=""native-image-reflection-example"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-image-reflection-example.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to provide metadata for Native Image in the form of JSON configuration files using a tracing agent<br><strong>Technologies: </strong> Native Image</td>
    </tr>  
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-static-images/"">native-static-images</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-static-images.yml""><img alt=""native-static-images"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-static-images.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to build a fully static and a mostly-static native executable.<br><strong>Technologies: </strong> Native Image <br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/build-static-executables/"">Build a Statically Linked or Mostly-Statically Linked Native Executable</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-heapdump-examples/"">native-heapdump-examples</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-heapdump-examples.yml""><img alt=""native-heapdump-examples"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-heapdump-examples.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">Demonstrates different ways to generate a heap dump from a running native executable.<br><strong>Technologies: </strong> Native Image, VisualVM <br><strong>Reference: </strong><a href=""https://www.graalvm.org/latest/reference-manual/native-image/guides/create-heap-dump/"">Create a Heap Dump from a Native Executable</a></td>
    </tr>  
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-image-jmx-demo/"">native-image-jmx-demo</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-image-jmx-demo.yml""><img alt=""nnative-image-jmx-demo"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-image-jmx-demo.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">This demo covers the steps required to build, run, and interact with a native executable using JMX.<br><strong>Technologies: </strong> Native Image, JMX, VisualVM <br><strong>Reference: </strong><a href=""https://www.graalvm.org/dev/reference-manual/native-image/guides/build-and-run-native-executable-with-remote-jmx/"">Build and Run Native Executables with Remote JMX</a></td>
    </tr>
  </tbody>
</table>

### Native Image on Cloud Platforms

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-aws-fargate/"">native-aws-fargate</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-aws-fargate.yml""><img alt=""native-aws-fargate"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-aws-fargate.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">This demo covers the steps required to create a container image of a native executable application and deploy the image on AWS Fargate.<br><strong>Technologies: </strong> Native Image, Apache Maven, Docker, AWS Fargate <br>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-aws-lambda/"">native-aws-lambda</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-aws-lambda.yml""><img alt=""native-aws-lambda"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-aws-lambda.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">This demo covers the steps required to deploy a native executable application on AWS Lambda.<br><strong>Technologies: </strong> Native Image, Apache Maven, Docker, AWS Lambda <br>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-google-cloud-run/"">native-google-cloud-run</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-google-cloud-run.yml""><img alt=""native-google-cloud-run"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-google-cloud-run.yml/badge.svg""/></a></td>
      <td align=""left"" width=""70%"">This demo covers the steps required to create a container image of a native executable application and deploy the image on Google Cloud Run.<br><strong>Technologies: </strong> Native Image, Apache Maven, Docker, Google Cloud CLI, Google Cloud Run <br>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/native-oci-container-instances/"">native-oci-container-instances</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-oci-container-instances.yml""><img alt=""native-oci-container-instances"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/native-oci-container-instances.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">This demo covers the steps required to create a container image of a native executable application and deploy the image on OCI Container Instances.<br><strong>Technologies: </strong> Native Image, Apache Maven, Docker, OCI Container Instances<br></td>
    </tr>   
  </tbody>
</table>

### Java on Truffle (Espresso)

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/espresso-jshell/"">espresso-jshell</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/espresso-jshell.yml""><img alt=""espresso-jshell"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/espresso-jshell.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to build a native executable of JShell, that executes the dynamically generated bytecodes on Espresso<br><strong>Technologies: </strong>Java on Truffle, Native Image, JShell<br><strong>Reference: </strong><a href=""https://www.graalvm.org/dev/reference-manual/java-on-truffle/demos/#mixing-aot-and-jit-for-java"">Mixing AOT and JIT for Java</a>, <a href=""https://medium.com/graalvm/java-on-truffle-going-fully-metacircular-215531e3f840"">Java on Truffle — Going Fully Metacircular</a></td>
    </tr>
  </tbody>
</table>

### Micronaut

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/micronaut-hello-rest-maven/"">micronaut-hello-rest-maven</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/micronaut-hello-rest-maven.yml""><img alt=""micronaut-hello-rest-maven"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/micronaut-hello-rest-maven.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to package a Micronaut REST application into a native executable with Native Build Tools Maven plugin<br><strong>Technologies: </strong>Native Image, Micronaut, Native Build Tools Maven plugin<br><strong>Reference: </strong><a href=""https://github.com/oracle-devrel/oci-code-editor-samples/tree/main/java-samples/graalvmee-java-micronaut-hello-rest"">Try in OCI Code Editor</a></td>
    </tr>
  </tbody>
</table>

### Spring Boot

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/spring-native-image/"">spring-native-image</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/spring-native-image.yml""><img alt=""spring-native-image"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/spring-native-image.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to compile a Spring Boot application into a native executable using the Native Build Tools Maven plugin and a Maven profile <br> <strong>Technologies: </strong>Spring Boot, Native Image, Native Build Tools Maven plugin <br><strong>Reference: </strong><a href=""https://luna.oracle.com/lab/fdfd090d-e52c-4481-a8de-dccecdca7d68/steps"">GraalVM Native Image, Spring and Containerisation</a>, <a href=""https://docs.oracle.com/en/graalvm/jdk/21/docs/getting-started/oci/cloud-shell/"">Oracle GraalVM in OCI Cloud Shell</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/spring-r/"">spring-r</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/spring-r.yml""><img alt=""spring-r"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/spring-r.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates GraalVM's polyglot feature by loading an R script into a Java host application 
      <br><strong>Technologies: </strong> Spring, FastR <br><strong>Reference: </strong><a href=""https://medium.com/graalvm/enhance-your-java-spring-application-with-r-data-science-b669a8c28bea"">Enhance your Java Spring application with R data science</a></td>
    </tr>
  </tbody>
</table>

### Helidon

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/js-java-async-helidon/"">js-java-async-helidon</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/js-java-async-helidon.yml""><img alt=""js-java-async-helidon"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/js-java-async-helidon.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">An HTTP web service that demonstrates how multiple JavaScript contexts can be executed in parallel to handle asynchronous operations with Helidon in Java <br><strong>Technologies: </strong>Native Image, Helidon, Native Build Tools Maven plugin <br><strong>Reference: </strong><a href=""https://medium.com/graalvm/asynchronous-polyglot-programming-in-graalvm-javascript-and-java-2c62eb02acf0"">Asynchronous Polyglot Programming in GraalVM Using Helidon and JavaScript</a></td>
    </tr>
  </tbody>
</table>

### Scala

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/scalac-native/"">scalac-native</a></td>
      <td align=""left"" width=""70%"">Demonstrates how to build a native executable of the Scala compiler. The resulting binary has no dependencies on the JDK. <br><strong>Technologies: </strong>Scala 2.12.x, Native Image <br><strong>Reference: </strong><a href=""https://medium.com/graalvm/compiling-scala-faster-with-graalvm-86c5c0857fa3"">Compiling Scala Faster with GraalVM</a></td>
    </tr>
  </tbody>
</table>

### Kotlin

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/java-kotlin-aot/"">java-kotlin-aot</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/java-kotlin-aot.yml""><img alt=""java-kotlin-aot"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/java-kotlin-aot.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to interoperate between Java and Kotlin and build a native executable <br><strong>Technologies: </strong>Native Image, Kotlin, Maven</td>
    </tr>
  </tbody>
</table>

### Python

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/graalpy-notebook-example/"">graalpy-notebook-example</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/graalpy-notebook-example.yml""><img alt=""graalpy-notebook-example"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/graalpy-notebook-example.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to embed Python in a Java application. It creates a Python `venv`, and installs required Python packages through a Maven configuration. <br><strong>Technologies: </strong>GraalPy</td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/graalpy-embedding-demo/"">graalpy-embedding-demo</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/graalpy-embedding-demo.yml""><img alt=""graalpy-embedding-demo"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/graalpy-embedding-demo.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to embed GraalPy in a Java application using Maven. <br><strong>Technologies: </strong>GraalPy</td>
    </tr>
  </tbody>
</table>

### Polyglot

<table>
  <thead>
    <tr>
      <th align=""left"">Name</th>
      <th align=""left"">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align=""left"" width=""30%""><a href=""/polyglot-chat-app/"">polyglot-chat-app</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/polyglot-chat-app.yml""><img alt=""polyglot-chat-app"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/polyglot-chat-app.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to build a polyglot chat application by embedding Python and R into the Java host language <br><strong>Technologies: </strong>Java, GraalPy, FastR, Micronaut</td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/polyglot-debug/"">polyglot-debug</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/polyglot-debug.yml""><img alt=""polyglot-debug"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/polyglot-debug.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to debug a polyglot Java and JavaScript application using GraalVM Tools for Java in VS Code <br><strong>Technologies: </strong>Java, JavaScript, Maven, GraalVM Extension Pack</td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/polyglot-javascript-java-r/"">polyglot-javascript-java-r</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/polyglot-javascript-java-r.yml""><img alt=""polyglot-javascript-java-r"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/polyglot-javascript-java-r.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates the polyglot capabilities of GraalVM and how to run a JavaScript-Java-R application <br><strong>Technologies: </strong>JavaScript, Node.js, Java, R <br><strong>Reference: </strong><a href=""https://medium.com/graalvm/graalvm-ten-things-12d9111f307d#656f"">Top 10 Things To Do With GraalVM</a></td>
    </tr>
    <tr>
      <td align=""left"" width=""30%""><a href=""/functionGraphDemo/"">functionGraphDemo</a><br><a href=""https://github.com/graalvm/graalvm-demos/actions/workflows/functionGraphDemo.yml""><img alt=""functionGraphDemo"" src=""https://github.com/graalvm/graalvm-demos/actions/workflows/functionGraphDemo.yml/badge.svg"" /></a></td>
      <td align=""left"" width=""70%"">Demonstrates how to run a polyglot JavaScript-Java-R application on the GraalVM Node.js runtime <br><strong>Technologies: </strong>JavaScript, Node.js, Java, R</td>
    </tr>
  </tbody>
</table>

## Compatibility

The demos are normal applications and benchmarks written in Java, JavaScript, Python, etc., so they are compatible with any virtual machine capable of running Java, JavaScript and so on. 
These demos are [tested against the latest GraalVM release using GitHub Actions](https://github.com/graalvm/graalvm-demos/actions/workflows/main.yml). If you come accross an issue, please submit it [here](https://github.com/graalvm/graalvm-demos/issues).

## License

Unless specified otherwise, all code in this repository is licensed under the [Universal Permissive License (UPL)](http://opensource.org/licenses/UPL).
Note that the submodule `fastR-examples` which is a reference to the [graalvm/examples](https://github.com/graalvm/examples) repository has a separate license.

## Learn More

* [GraalVM website](https://www.graalvm.org)
* [Graal project on GitHub](https://github.com/oracle/graal/tree/master/compiler)
* [GraalVM blog](https://medium.com/graalvm)
"
PacktPublishing/Spring-5.0-By-Example,master,70,97,2017-11-27T07:17:18Z,4568,1,"Spring 5.0 By Example, published by Packt",,"


# Spring 5.0 By Example
This is the code repository for [Spring 5.0 By Example](https://www.packtpub.com/application-development/spring-50-example?utm_source=github&utm_medium=repository&utm_campaign=9781788624398), published by [Packt](https://www.packtpub.com/?utm_source=github). It contains all the supporting project files necessary to work through the book from start to finish.
## About the Book
Spring makes application development extremely simple and also improves developer productivity by reducing initial configuration time and providing tools to increase efficiency.

In the first part of the book, we will learn how to construct a CMS Portal using Spring's support for building REST APIs. We will also integrate these APIs with AngularJS. We will later develop this application in a reactive fashion by using Project Reactor, Spring WebFlux and Spring Data.

In the second part, we will build an amazing messaging application, which will consume the Twitter API and perform some filtering and transformations. We will then play around with Server Sent Events and explore Spring’s support for Kotlin which makes application development quick and efficient.

In the last part, we will build a real microservice application by using the most important techniques and patterns such as service discovery, circuit breakers, security, data streams, monitoring, and a lot more from this architectural style.

By the end of the book, you will be comfortable with the concepts of spring boot and spring cloud.
## Instructions and Navigation
All of the code is organized into folders. Each folder starts with a number followed by the application name. For example, Chapter02.

Chapter01 does not contain code files.
All the remaining chapters contains code files pressent in their respective folders. 

The code will look like the following:
```
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

The readers are expected to have a basic knowledge of Java. Notion about Distributed
Systems is an added advantage.
To execute code files in this book, you would need to have the following
software/dependencies:
* IntelliJ IDEA Community Edition
* Docker CE
* pgAdmin
* Docker Compose
You will be assisted with installation processes, and so on through this book.

## Related Products
* [Mastering Spring 5.0](https://www.packtpub.com/application-development/mastering-spring-50?utm_source=github&utm_medium=repository&utm_campaign=9781787123175)

* [Spring 5.0 Microservices - Second Edition](https://www.packtpub.com/application-development/spring-50-microservices-second-edition?utm_source=github&utm_medium=repository&utm_campaign=9781787127685)

* [Spring 5.0 Cookbook](https://www.packtpub.com/application-development/spring-50-cookbook?utm_source=github&utm_medium=repository&utm_campaign=9781787128316)


### Download a free PDF

 <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>
<p align=""center""> <a href=""https://packt.link/free-ebook/9781788624398"">https://packt.link/free-ebook/9781788624398 </a> </p>"
odnoklassniki/jvm-serviceability-examples,master,27,10,2014-10-10T09:53:51Z,1845,0,Sample code for the presentation on JVM Serviceability Tools,,
mianshenglee/spring-batch-example,master,45,34,2019-06-04T08:09:40Z,1884,9,example for spring batch,,"
## 项目说明
由于需要对数据进行批处理，使用`Spring Batch `进行学习与开发，本项目（`spring-batch-example `）旨在提供基于`Spring Batch`进行批处理的示例，每个示例都以解决某一问题为目标，以帮助`Spring Batch`使用者更方便学习，以实践带动学习，欢迎大家可以一起交流学习，欢迎`fork`和添加更多的示例。

## 示例列表

当前示例列表如下：

- [spring-batch-helloworld](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-helloworld)
- [spring-batch-file2db](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-file2db)
- [spring-batch-db2db](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-db2db)
- [spring-batch-beetlsql](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-beetlsql)
- [spring-batch-increment](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-increment)
- [spring-batch-xxl-executor](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-xxl-executor) 与 [xxl-job](https://github.com/mianshenglee/spring-batch-example/tree/master/xxl-job)
- [spring-batch-mysql2mongo](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-mysql2mongo)
- [spring-batch-param](https://github.com/mianshenglee/spring-batch-example/tree/master/spring-batch-param)

示例说明如下：

### `spring-batch-helloworld`

示例功能：很简单的示例，读字符串数组，转为大写，输出到控制，示例虽小，五脏俱全，通过此示例，可以对`Spring Batch`作一个基础的了解。

- 配套文章：[快速了解组件-spring batch(2)之helloworld][2]

### `spring-batch-file2db`

示例功能：从文本读数据，转为`User`实体，输出到数据库中进行存储，通过此示例，可以对`Spring Batch`的默认组件（读文件、写数据库）有一定的了解。

- 配套文章：[快速使用组件-spring batch(3)读文件数据到数据库][3]



### `spring-batch-db2db`

示例功能：从数据库读数据，转为`User`实体，输出到数据库中进行存储，通过此示例，可以对多数据源配置、`Spring Batch`的默认组件（读数据库、写数据库）有一定的了解。


- 配套文章：[决战数据库-spring batch(4)数据库到数据库][4]

### `spring-batch-beetlsql`

示例功能：与`spring-batch-db2db`一致，只是更改了读数据库和写数据库的组件，改为使用`BeetlSql`，更简单，更灵活。


- 配套文章：[便捷的数据读写-spring batch(5)结合beetlSql进行数据读写][5]

### `spring-batch-increment`

示例功能：对数据同步实现增量同步，结合`Spring Batch`和`BeetlSql`，实现基于时间戳实现数据的增量同步。

- 配套文章：[增量同步-spring batch(6)动态参数绑定与增量同步][6]

### `spring-batch-xxl-executor` 和 `xxl-job`

示例功能：在增量同步的基础上，实现企业级的数据同步和调度框架结合，结合`xxl-job`，实现任务调度，并查看数据同步结果。

- 配套文章：[调度与监控-spring batch(7)结合xxl-job进行批处理][7]

### `spring-batch-mysql2mongo`

示例功能: 使用Mongo相组件，实现mysql --> mongodb 的数据同步。

- 配套文章：[mongo同步-spring batch(8)的mongo读写组件使用][8]

### `spring-batch-param`

示例功能: 在 Spring Batch 中进行数据及参数传递的方法。

- 配套文章：[数据共享-spring batch(9)上下文处理][9]

## 示例使用

示例都是基于spring boot建立的java工程，使用maven进行包管理。因此直接使用开发工具如`eclipse`或`idea`导入maven工程即可使用，有几点需要注意：

1. 使用开发工具导入工程后，需要使用maven进行依赖管理，下载相应的jar包，特别是spring batch相关的包。
2. 示例结合文章的说明一起使用，可以先文章，再运行示例。
3. 有一些示例是需要结合数据脚本来运行的，因此运行前请先按提供的sql脚本进行建库，建表，添加测试数据。

## 文章列表

本项目中的示例代码，与我写的[`Spring Batch`系列文章](https://mianshenglee.github.io/)有对应关系，每个示例均可独立运行，学习者可直接阅读文章，结合代码示例进行学习。

- [数据批处理神器-Spring Batch(1)简介及使用场景][1]
- [快速了解组件-spring batch(2)之helloworld][2]
- [快速使用组件-spring batch(3)读文件数据到数据库][3]
- [决战数据库-spring batch(4)数据库到数据库][4]
- [便捷的数据读写-spring batch(5)结合beetlSql进行数据读写][5]
- [增量同步-spring batch(6)动态参数绑定与增量同步][6]
- [调度与监控-spring batch(7)结合xxl-job进行批处理][7]
- [mongo同步-spring batch(8)的mongo读写组件使用][8]
- [数据共享-spring batch(9)上下文处理][9]

## 与我交流

可以使用以下几种方式一起交流：

- [在项目中提issue](https://github.com/mianshenglee/spring-batch-example/issues)：`https://github.com/mianshenglee/spring-batch-example/issues`

- 微信公众号：![mason技术记录](https://mianshenglee.github.io/public/img/wx-qrcode.jpg)
- [我的博客](https://mianshenglee.github.io/)：`https://mianshenglee.github.io/`

[1]: https://mianshenglee.github.io/2019/06/04/springbatch(1).html
[2]: https://mianshenglee.github.io/2019/06/07/spring-batch(2).html
[3]: https://mianshenglee.github.io/2019/06/08/spring-batch(3).html
[4]: https://mianshenglee.github.io/2019/06/09/spring-batch(4).html
[5]: https://mianshenglee.github.io/2019/06/10/spring-batch(5).html
[6]: https://mianshenglee.github.io/2019/06/11/spring-batch(6).htm
[7]: https://mianshenglee.github.io/2019/06/12/spring-batch(7).html
[8]: https://mianshenglee.github.io/2019/08/09/spring-batch(8).html
[9]: https://mianshenglee.github.io/2020/11/30/spring-batch(9).html"
readlearncode/Java-EE-8-Sampler,master,36,28,2017-09-03T15:31:33Z,191,0,Code examples demonstrating the new capabilities of Java EE 8,javaee8,"# Java-EE-8-Sampler
Code examples demonstrating the new capabilities of Java EE 8
"
healenium/healenium-example-maven,master,25,23,2021-01-14T08:44:35Z,14456,3,Test automation examples on Java with Maven.,,"# healenium-example-maven
Java + Maven + Junit5 project with healenium usage example 

### To setup Healenium see the tutorial: https://www.youtube.com/watch?v=Ed5HyfwZhq4

## How to start
### 1.Start Healenium backend from infra folder

```cd infra```

```docker-compose up -d```

To download this file into your project use this command:

```$ curl https://raw.githubusercontent.com/healenium/healenium-example-maven/master/infra/docker-compose.yml -o docker-compose.yml```

Create /db/sql folder on the same level in your project. Add init.sql file into ./db/sql/init.sql folder in your project via command:

```$ curl https://raw.githubusercontent.com/healenium/healenium-client/master/example/init.sql -o init.sql```

Verify that images ```healenium/hlm-backend:3.4.1``` and ```postgres:11-alpine```  and ```healenium/hlm-selector-imitator:1.2``` are up and running

### 2. Project structure
```
|__infra
    |__db/sql
        |__init.sql
    |__docker-compose.yml
|__src/main/java/
|__src/test/java/
|__pom.xml
``` 
			   
### 3.Run test in terminal with maven

In ```BaseTest.java``` class select necessary driver: **LOCAL**, **PROXY** or **REMOTE** and browser to run: chrome, firefox or edge.

```driver = new DriverContext(DriverType.LOCAL).getDriver(BrowserType.CHROME);```

**LOCAL** - used for local run. It's been set by default in BaseTest.java class. For this driver should be used docker-compose file from test example.

**PROXY** - used if you're running tests using healenium-proxy. For this driver you need to set docker-compose containers as in example by link:
https://github.com/healenium/healenium-example-dotnet/blob/master/infra/docker-compose.yml

**REMOTE** - used if you-re running test on remote machine. Do not forget to provide necessary host. In this test example it's been used remote machine with Selenoid.

In ```BaseTest.java``` class select necessary framework: **SELENIUM** or **SELENIDE**.

```pages = new FrameworkContext(FrameworkType.SELENIDE, driver).setFramework();```

If you want to execute all tests, please use the command: ```mvn clean test```
 

### 4.After test execution you should see generated report link in command line logs

![img.png](img.png)

Report contains only healed locators with old-new values and a button that tells if healing was successful for further algorithm corrections

![img_1.png](img_1.png)

### 5. Screenshots 

Also you could take a screenshots for your com.epam.healenium.tests like it implements here: BaseTest.screenshot
```
  public byte[] screenshot() {
      return ((TakesScreenshot) driver.getDelegate()).getScreenshotAs(OutputType.BYTES);
  }
```
### 6. @DisableHealing annotation

If don't want to use Healenium in some methods just use @DisableHealing annotation. 
> The example of usage you can find here: MainPageWithFindBy.checkLocatorTestButtonDontHealing 

![img_2.png](img_2.png)

### 7. Plugin Healenium for Intellij IDE

For updating broken locators you could use Plugin ""Healenium"" for Intellij IDE (https://plugins.jetbrains.com/plugin/14178-healenium).

With this plugin you can update your locators:
* on class level

![update_on_class_level](img_6.png)
* or on variable level

![update_on_class_level](img_5.png)

![element_update](img_4.png)
"
ttulka/ddd-example-ecommerce,main,304,68,2020-04-11T07:23:36Z,651,1,Domain-driven design example in Java with Spring framework,architecture ddd design domain-driven-design event-driven example hexagonal-architecture high-cohesion java low-coupling modular-monolith ood oop rich-domain-model screaming-architecture service-oriented-architecture services soa spring spring-boot,"# DDD Example Project in Java: eCommerce

The purpose of this project is to provide a sample implementation of an e-commerce product following **Domain-Driven Design (DDD)** and **Service-Oriented Architecture (SOA)** principles.

Programming language is Java with heavy use of Spring framework.

```sh
# build
./mvnw clean install

# run 
./mvnw spring-boot:run

# open in browser http://localhost:8080
```

## Table of Contents

- [Domains](#domains)
  + [Core Domain](#core-domain)
  + [Supporting Subdomains](#supporting-subdomains)
  + [Event Workflow](#event-workflow)
  + [Services Dependencies](#services-dependencies)
- [Architectural Overview](#architectural-overview)
  + [Screaming Architecture](#screaming-architecture)
  + [Packaging](#packaging)
  + [Assembling](#assembling)
  + [Anatomy of a Service](#anatomy-of-a-service)
- [Conclusion](#conclusion)
  + [Where to Next](#where-to-next)

## Domains

Several [Business Capabilities][vcha] have been identified:

[vcha]: http://bill-poole.blogspot.com/2008/07/value-chain-analysis.html

### Core Domain

- **Sales**
  - put a product for sale
  - categorize a product
  - update a product
  - change a product price
  - validate an order
  - place an order
  
### Supporting Subdomains
  
- **Warehouse**
  - stack goods
  - fetch goods for shipping
  
- **Billing**
  - collect a payment

- **Shipping**
  - dispatch a delivery

Later, we can think about more supporting domains (not implemented in this project):

- **Marketing**
  - discount a product
  - promote a product
  
- **User Reviews**
  - add a product review
  
- **Customer Care**
  - resolve a complain
  - answer a question
  - provide help
  - loyalty program
  
The e-commerce system is a web application using a **Portal** component implementing the [Backends For Frontends (BFF)][bff] pattern.

The idea of [Microfrontends][microf] is implemented in an [alternative branch](https://github.com/ttulka/ddd-example-ecommerce/tree/microfrontend).

[bff]: https://samnewman.io/patterns/architectural/bff/
[microf]: https://martinfowler.com/articles/micro-frontends.html

### Event Workflow

The communication among domains is implemented via events:

![Event Workflow](doc/event-workflow.png)

When the customer places an order the following process starts up (the happy path):

1. Shipping prepares a new delivery.
1. Sales creates a new order and publishes the `OrderPlaced` event.
1. Shipping accepts the delivery.
1. Billing collects payment for the order and publishes the `PaymentCollected` event.
1. Warehouse fetches goods from the stock and publishes the `GoodsFetched` event.
1. Shipping dispatches the delivery and publishes the `DeliveryDispatched` event.
1. Warehouse updates the stock.

There is only the basic ""happy path"" workflow implemented with a big room for improvement, for example when Shipping doesn't get bot Events within a time period, the delivery process should be cancelled etc.. 

### Services Dependencies

Services cooperate together to work out the Business Capabilities: sale and deliver goods.

The actual dependencies come only from Listeners which fulfill the role of the Anti-Corruption Layer and depend only on Domain Events.

![Event and Listener](doc/event-listener.png)

Events contain no Domain Objects. 

For communication across Services an Event Publisher abstraction is used, located in the package `..ecommerce.common.events`. The interface is an Output Port (in the Hexagonal Architecture) and as a cross-cutting concern is its implementation injected by the Application.  

## Architectural Overview

While no popular architecture ([Onion][onion], [Clean][clean], [Hexagonal][hexagonal], [Trinity][trinity]) was strictly implemented, the used architectural style follows principles and good practices found over all of them.
- Low coupling, high cohesion
- Implementation hiding
- Rich domain model
- Separation of concerns
- The Dependency Rule

The below proposed architecture tries to solve one problem often common for these architectural styles: [exposing internals of objects](https://blog.ttulka.com/object-oriented-design-vs-persistence) and breaking their encapsulation. The proposed architecture employs full object encapsulation and rejects anti-patterns like Anemic Domain Model or JavaBean. An Object is a solid unit of behavior. A Service is an Object on higher level of architectural abstraction. 

[onion]: http://jeffreypalermo.com/blog/the-onion-architecture-part-1
[clean]: https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html
[hexagonal]: https://alistair.cockburn.us/hexagonal-architecture/
[trinity]: https://github.com/oregor-projects/trinity-demo-java

### Screaming Architecture

The architecture ""screams"" its intentions just by looking at the code structure:
```
..ecommerce
    billing
        payment
    sales
        category
        order
        product
    shipping
        delivery
    warehouse
```

Going deeper the technical concepts are visible too:
```
..ecommerce
    billing
        payment
            jdbc
        listeners
        rest
```

### Packaging

As shown in the previous section, the code is structured by the domain together with packages for technical concerns (`jdbc`, `rest`, `web`, etc.).

Such a packaging style is the first step for a further modularization. 

The semantic of a package is following: `company.product.domain.service.[entity|impl]`, where `entity` and `impl` are optional. Full example: `com.ttulka.ecommerce.billing.payment.jdbc`. 

### Assembling

While a physically monolithic deployment is okay for most cases, a logically monolithic design, where everything is coupled with everything, is evil.

To show that the Monolith architectural pattern is not equal to the Big Ball Of Mud, a modular monolithic architecture was chosen as the start point.

The services can be further cut into separate modules (eg. Maven artifacts) by feature:
```
com.ttulka.ecommerce:ecommerce-application
com.ttulka.ecommerce.sales:catalog-service
com.ttulka.ecommerce.sales:cart-service
com.ttulka.ecommerce.sales:order-service
com.ttulka.ecommerce.billing:payment-service
com.ttulka.ecommerce.shipping:delivery-service
com.ttulka.ecommerce.warehouse:warehouse-service
```

Or by [component](https://blog.ttulka.com/package-by-component-with-clean-modules-in-java):
```
com.ttulka.ecommerce.billing:payment-domain
com.ttulka.ecommerce.billing:payment-jdbc
com.ttulka.ecommerce.billing:payment-rest
com.ttulka.ecommerce.billing:payment-events
com.ttulka.ecommerce.billing:payment-listeners
```

In detail:
```
com.ttulka.ecommerce.billing:payment-domain
    ..billing
        payment
            Payment
            PaymentId
            CollectPayment
            FindPayments
com.ttulka.ecommerce.billing:payment-jdbc
    ..billing.payment.jdbc
        PaymentJdbc
        CollectPaymentJdbc   
        FindPaymentsJdbc     
com.ttulka.ecommerce.billing:payment-rest
    ..billing.payment.rest
        PaymentController
com.ttulka.ecommerce.billing:payment-events
    ..billing.payment
        PaymentCollected
com.ttulka.ecommerce.billing:payment-listeners
    ..billing.payment.listeners
        OrderPlacedListener
```

Which can be brought together with a Spring Boot Starter, containing only Configuration classes and dependencies on other modules:
```
com.ttulka.ecommerce.billing:payment-spring-boot-starter
    ..billing.payment
        jdbc
            PaymentJdbcConfig
        listeners
            PaymentListenersConfig
    META-INF
        spring.factories
```

Note: Events are actually part of the domain, that's why they are in the package `..ecommerce.billing.payment` and not in `..ecommerce.billing.payment.events`. They are in a separate module to break the build cyclic dependencies: a dependent module (Listener) needs to know only Events and not the entire Domain. 

See this approach in an alternative branch: [modulith](https://github.com/ttulka/ddd-example-ecommerce/tree/modulith).

### Anatomy of a Service 

**[Service](http://udidahan.com/2010/11/15/the-known-unknowns-of-soa/)** is the technical authority for a specific business capability.
- There is a one-to-one mapping between a Bounded Context and a Subdomain (ideal case).
- A Bounded Context defines the boundaries of the biggest services possible.
- A Bounded Context can be decomposed into multiple service boundaries.
    - For example, Sales domain contains Catalog, Cart and Order services.
- A service boundaries are based on service responsibilities and behavior.
- A service is defined by its logical boundaries, not a physical deployment unit.

**Application** is a deployment unit. A monolithic Application can have more Services.
- Bootstrap (application container etc.). 
- Cross-cutting concerns (security, transactions, messaging, logging, etc.).

![Application and Services](doc/application-services.png)

**Configuration** assemblies the Service as a single component.
- Has dependencies to all inner layers.
- Can be implemented by Spring's context `@Configuration` or simply by object composition and Dependency Injection.
- Implements the Dependency Inversion Principle.  

**Gateways** create the published API of the Service.
 - Driving Adapters in the Hexagonal Architecture.
 - REST, SOAP, or web Controllers,
 - Event Listeners,
 - CLI.
 
**Use-Cases** are entry points to the service capabilities and together with **Entities** form the _Domain API_.
- Ports in the Hexagonal Architecture.
- No implementation details.
- None or minimal dependencies.
 
_Domain Implementation_ fulfills the Business Capabilities with particular technologies.
- Driven Adapters in the Hexagonal Architecture.
- Tools and libraries,
- persistence,
- external interfaces access.

Source code dependencies point always inwards and, except Configuration, are strict: allows coupling only to the one layer below it (for example, Gateways mustn't call Entities directly, etc.).
 
![Service Anatomy](doc/service-anatomy.png)

#### Example of a Service Anatomy 

As a concrete example consider the Business Capability to find payments in Billing service:

- Application is implemented via Spring Boot Application.
- `PaymentJdbcConfig` configures the JDBC implementations for the Domain. 
- Gateway is implemented as a REST Controller.
- Use-Case interface  `FindPayments` is implemented with `PaymentsJdbc` in Use-Cases Implementation.  
- Entity `Payment` is implemented with `PaymentJdbc` in Entities Implementation.

![Service Anatomy](doc/service-anatomy-example.png)

There is no arrow from Configuration to Gateways because `PaymentController` is annotated with Spring's `@Component` which makes it available for component scanning the application is based on. This is only one possible approach. Another option would be to put the Controller as a Bean into the Configuration, etc..

## Conclusion

The goal of this project is to demonstrate basic principles of Domain-Driven Design in a simple but non-trivial example.

For the sake of simplicity a very well-known domain (e-commerce) was chosen. As every domain differs in context of business, several assumption must have been made.

Although all fundamental use-case were implemented, there is still a room for improvement. Cross-cutting concerns like authentication, authorization or monitoring are not implemented.

### Where to Next

Check out the alternative branches and repos to see additional concepts and technologies in action:

- [Modulith](https://github.com/ttulka/ddd-example-ecommerce/tree/modulith): A separate Maven module per service.
- [Microfrontends](https://github.com/ttulka/ddd-example-ecommerce/tree/microfrontend): Service Web Components as part of the service codebase.
- [Microservices](https://github.com/ttulka/ddd-example-ecommerce-microservices): Deployments with Docker and Kubernetes.
- [Kotlin](https://github.com/ttulka/ddd-example-ecommerce-kotlin): The same project again, this time in Kotlin.

"
Perfecto-Quantum/Quantum-Starter-Kit,master,56,79,2016-11-03T08:44:59Z,17240,9,"Get started with Quantum! Clone or download this repository to start, contains examples of tests and step definitions.",,"<img src=""https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/blob/master/DOC/image/perfecto.jpg"" height=""75"" width=""300""/>

![CircleCI status](https://circleci.com/gh/Perfecto-Quantum/Quantum-Starter-Kit.svg?style=shield ""CircleCI status"")

# Quantum Starter Kit
This Quantum starter kit is designed to get you up and running using the Quantum framework (sponsored by [Perfecto](https://www.perfecto.io) and powered by [QAF](https://github.com/qmetry/qaf)) within few simple steps, and enable you to start writing your tests using simple [Cucumber](https://cucumber.io/).

Begin with installing the dependencies below, and continue with the Getting Started procedure below.

### Dependencies
There are several prerequisite dependencies you should install on your machine prior to starting to work with Quantum:

* [Java 8](https://www.oracle.com/in/java/technologies/javase/javase8-archive-downloads.html)

* An IDE to write your tests on - [Eclipse IDE for Java Developers](https://www.eclipse.org/downloads/packages/) or [IntelliJ](https://www.jetbrains.com/idea/download/#)

* [Maven](https://maven.apache.org/) (Optional - Needed only for command line executions as IDEs have Maven in-built.)

* Download the necessary app files from [here](https://github.com/PerfectoMobileSA/PerfectoJavaSample/tree/master/libs), upload it to your Perfecto Media Repository and configure that locator path to driver.capabilities.app capability in your testng xml file.

Eclipse users should also install:

1. Eclipse has in-built Maven plugin 
    - Optional - [Maven Plugin](http://marketplace.eclipse.org/content/m2e-connector-maven-dependency-plugin)

2. [TestNG Plugin](http://testng.org/doc/download.html)

3. QAF BDD Plugin - Or go to install new software option in eclipse, and download from this url https://qmetry.github.io/qaf/editor/bdd/eclipse/
    In case, of network constraints, one can follow the instruction mentioned in [QAF BDD Offline](https://developers.perfectomobile.com/display/PD/Quantum+framework+introduction#expand-InstallanofflineversionoftheQAFBDDplugininEclipse)

IntelliJ IDEA users should also install:

1. [Cucumber Plugin (Community version only)](https://plugins.jetbrains.com/plugin/7212)
    - In case after installing the above plugin you are still not able to navigate to the step definition code then install this plugin -               [Cucumber for Groovy Plugin](https://plugins.jetbrains.com/plugin/7213-cucumber-for-groovy)

TestNG Plugin is built-in in the IntelliJ IDEA, from version 7 onwards.
 
#### Optional Installations
* For source control management, you can install [git](https://git-scm.com/downloads).

## Downloading the Quantum Project

[Download](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/archive/master.zip) the Quantum-Started-Kit repository.

After downloading and unzipping the project to your computer, open it from your IDE by choosing the folder containing the pom.xml file (_Quantum-Starter-Kit-master_, you might consider renaming it).

Project directory structure is documented in the end of this page.

**********************
# Getting Started

This procedure leads you through the various Quantum framework's aspects:

* [Running one of the samples](README.md#running-sample-as-is) in the Quantum project as is.
* [Creating your first test](README.md#creating-your-first-test) using the Quantum-Starter-Kit
* [Parallel execution](README.md#parallel-execution) of all Quantum samples.
* [Diversifying test execution](README.md#diversifying-test-execution) by manipulating test suites.
* [Viewing test execution results](README.md#viewing-test-execution-results-in-perfecto-reporting)
* [Advanced Quantum features](README.md#advanced-quantum-features)

## Running sample as is
Run a single Quantum sample from the samples provided in the Starter Kit.

The samples are located under the _src/main/resources/scenarios_ folder.

1. Configure your cloud and credentials in the _application.properties_ file (under the top _resources/_ folder).
2. Run your test via the right-click menu while hovering on the TestNG.xml file in the project pane (on the left).

The sample opens device browser at Google, searches for Perfecto Mobile, enters the site, and searches for Perfecto Object Spy.

## Creating your first test

1. Download the Quantum-Starter-Kit as zip to your computer, and rename it.
2. Open the project from its _pom.xml_ file, to open it as a Maven project with all the required dependencies.
3. Update your CQ Lab name under remote.server, and your Perfecto's security token in the _application.properties_ file.
4. Add a _.feature_ file under the _scenarios/_ folder, and proceed to create your test using the [test writing guidelines](README.md#test-writing-guidelines).
5. Add a _.loc_ file under the _common/_ folder, and proceed to create the Object Repository using the [Object Repository creation guidelines](README.md#object-repository-creation-guidelines).
6. Clean your test from the object definitions until all lines become syntax highlighted.
7. [Configure the testng file](README.md#testng-guidelines), and run your test from it.


### Test writing guidelines

* Begin with @featuretagname, Feature: name of feature, @scenariotagname (can be the same as the feature's tag).
* Write your scenario using [Given/When/Then/And](https://github.com/cucumber/cucumber/wiki/Given-When-Then) BDD statements. Use the commands in the pull-down list for accurate steps syntax, and easy step insertion.
* Write your first scenario for the app's initial starting point, and later create scenarios for other cases; name them differently to enable easy identification in execution report, and name their tags differently if you want to run them separately.
* Name your app's objects as _functionality.purpose_, for example _button.route_, _edit.start_, etc.
* If you have a Perfecto plugin - use Perfecto's [Object Spy](https://community.perfectomobile.com/series/18628-object-spy) to obtain smart object locators for your app's objects; if you do not - use other tools, such as Firebug or Chrome's Developer Tools, for that purpose. Put each object locator at the end of the line using that object - it will be used later for creating the Object Repository.<br>When using Object Spy, remember to set your object type to _DOM_ or _Native_ depending on your app's type being Web or Native, respectively. 
* If you want to run your app's steps using the Object Spy, check the _Execute on Add_ checkbox.
* Add steps for taking screenshots to allow close examination of test results later on.
* Add steps for waiting a few seconds upon app's page loading.

### Object Repository creation guidelines
1. Copy-Paste your test to the _.loc_ file.
2. Remove lines unrelated to objects. 
3. From each object related line, create a line formatted as <br>`objectname = locatortype=objectlocator`<br>For example <br>`edit.start = xpath=//*[@label=""Start location""]`

### Testng guidelines

1. Under the _config/_ folder, open the _testng_appium.xml_ or _testng_web.xml_ file, depending on your app type.
2. Copy the first test suite, and verify it's the only one with a **true** _enabled_ property, to prevent the other test suites from running in parallel.
3. Copy your feature/scenario tag to the _name_ property in the _include_ clause. Use a space-separated tags' list to include more scenarios and features.
4. Add a parameter specifying the type of device, or naming a specific one, to be used for your test execution, for example, <br>`<parameter name=""driver.capabilities.model"" value=""iPhone.*""></parameter>`


## Parallel execution
To run all samples in parallel, you need to configure the _TestNG.xml_ file, which is located under the _src/test/resources/config/_ folder.

1. For each of the test suites (enclosed within <test>...</test>), set the _enabled_ property value to **_true_**.
2. Run your test as before.

This results in running 2 additional samples, both searching terms in Perfecto Community; one uses hard coded search terms, and the other retrieves them from an external input file.

## Diversifying test execution
You can set each of the test suites to run on a different type of device, and to include different scenarios. For that, you need to manipulate the contents of the various test suites in the _TestNG.xml_ file.
Modify **only** the test suites not related to the Google sample we started with.

1. Replace the current tag in the community samples, so that in the _CommunityExample.feature_ sample all tags are **@sampletag**, and in the _CommunityDataDrivenExample.feature_ sample - **@sampletagdd**. <br>You may of course use other values, or leave the tags as is, but use these tag values for demonstration's sake.
2. In the _TestNG.xml_ file, set the tag parameter value in one suite to **@sampletag**, and in the other - to **@sampletagdd**.<br>That means, that the first test suite runs the CommunityExample sample, and the second - the CommunityDataDrivenExample sample.
3. To vary the devices used for each of the test suites, replace the capability parameter (""driver.capabilities.someCapability"") in both suites with<br>`<parameter name=""driver.capabilities.platformName"" value=""Android""/>`.<br>Set the value to ""iOS"" in the second test suite.<br>By that, you specify that the CommunityExample sample will run on an Android device (randomly allocated), and the CommunityDataDrivenExample sample - on an iOS device.<br>**Note:** Generally, you can use any of the numerous device selection capabilities.
4. Run your test in the same manner as before.<br>You can follow your test execution on Perfecto Dashboard and see the three samples running on the specified device types.

## Viewing test execution results in Perfecto Reporting

All the previous executions were recorded, and may be viewed in Perfecto execution center, Reporting.

Let's proceed to naming your tests, so you can easily detect them in Perfecto Reporting and drill down to examine them in more detail.

1. In each of the feature files (the samples), set the Feature line at the top to<br>`Feature: community search sample`
2. Run your test as before.
3. To view the test execution report within Perfecto Reporting:
   * Enter your CQ Lab at https://\<your CQ Lab\>.perfectomobile.com.
   * Select the Reporting tab, and click the link to Perfecto Reporting (on the right).
   * Login using your CQ Lab credentials.<br><br>
All the last execution tests are listed in the Reporting execution center. The feature name you set in the sample before, appears as the test name on the left. 
4. To drill down into any of the specific test executions, click the test to view its Single Test Report for more execution details.


## Advanced Quantum features

Quantum has additional features to allow better customization to your specific application:
* Understanding driver names and capabilities - [Link](https://developers.perfectomobile.com/display/PD/Quantum+driver+names+and+capabilities)
* Understand configuration manager - [Managing Configuration Manager](https://developers.perfectomobile.com/display/PD/ConfigurationManager+%7C+Pass+elements+across+steps+and+test+cases)
* Create your own [Object Repository](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/Object%20Repository) file to match your application objects. 
* Create a [[customized steps|Creating customized steps]] file to ease performing actions common in your application operation.
* Write tests using either [BDD](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/BDD-Implementation) or [Java](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/Java-Implementation).
* Configure the [TestNG.xml](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/Quantum%20TestNG%20File) to filter the tests to execute and the devices used in the test.
* Configuration of the [application properties](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/The%20application.properties%20file) and the [TestNG.xml file](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/Quantum%20TestNG%20File), as well as creating object definitions in the [Object Repository](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/Object%20Repository) and [creating customized steps](https://github.com/Perfecto-Quantum/Quantum-Starter-Kit/wiki/Creating%20customized%20steps), require knowledge of Java, TestNG, and XPath.


## Quantum Course
Automation Architects and developers should go through this Quantum Course as it deep dives in technical depth of Quantum features and discusses samples of advanced features of Quantum. 
[Course Link](https://developers.perfectomobile.com/display/PSC/Quantum)



**********************

# Project Directory Structure
```
.
│   pom.xml                                                 # Maven pom file for build and dependencies  
│   README.md                                               # The current readme file  
│  
├───resources                                               # Default resources dir  
│       application.properties                              # set credentials and other project properties  
│  
└───src												   		
    └───main  
        ├───java                                            # All code for project inside java directory  
        │   └───com  
        │       └───quantum                                 # com.quantum namespace  
        │           ├───java                                # Package namespace for pure java tests  
        │           │   └───pages                           # Package for Java test Page Object Models  
        │           │           MainscreenTestPage.java     # Example POM  
        │           │  
        │           └───steps                               # Package namespace for Gherkin/Cucumber step definitions  
        │                   ExpenseTrackerSteps.java        # Step definitions for appium feature file  
        │                   GoogleStepDefs.java             # Step definitions for webSearch feature file  
        │  
        └───resources                                       # All project specific files here  
            │   assertMessages.properties                   # Property definitions used in qaf library AssertionService class  
            │   log4j.properties                            # Controls all logging to console and log files  
            │  
            ├───android                                     # Additional Android properties. Specified in testng_appium file.  
            │       env.properties                          # Android specific additional environment variables  
            │       expensetracker.loc                      # Android specific object locators for appium test objects  
            │  
            ├───common                                      # Common resources dir. Set with env.resources in application.properties  
            │       search.loc                              # Common object locators used in webSearch feature file  
            │       testdata.xml                            # Data used in xml scenario in webSearch feature  
            │  
            ├───config                                      # TestNG xml test file directory  
            │       testng_appium.xml                       # TestNG file that runs appium feature file with @appium tag  
            │       testng_web.xml                          # TestNG file that runs webSearch feature file with @Web tag  
            │  
            ├───data                                        # Data used in data driven tests stored here  
            │       testData.csv                            # csv data file used in csv webSearch scenario  
            │       testData.json                           # example of json data file  
            │       testData.xls                            # example of Excel data file  
            │  
            ├───ios                                         # Addition iOS properties. Specified in testng_appium file.  
            │       env.properties                          # iOS specific additional environment properties  
            │       expensetracker.loc                      # Android specific object locators for appium test objects  
            │  
            └───scenarios                                   # Cucumber/Gherkin feature files directory  
                    appium.feature                     	   # Appium test feature file called by testng_appium xml file  
                    webSearch.feature                       # Web Google Search feature file driven by testng_web xml file  
``` 
"
tvd12/master-design-patterns,master,40,26,2015-08-25T07:21:17Z,178,0,design patterns example,design-pattern desing-patterns java-design-pattern java-examples oop-design,
tipsy/spark-basic-structure,master,124,134,2016-02-06T15:12:47Z,135,8,Example of one possible way of structuring a Spark application,,"# spark-basic-structure
This is an example of one possible way of structuring a Spark application

The application has filters, controllers, views, authentication, localization, error handling, and more. 
It contains the source code for the tutorial found at https://sparktutorials.github.io/2016/06/10/spark-basic-structure.html

## Critique welcome
If you find anything you disagree with, please feel free to create an issue.

## Screenshot
![Application Screenshot](https://sparktutorials.github.io/img/posts/sparkBasicStructure/screenshot.png)
"
malmstein/MaterialAnimations,master,41,9,2015-01-31T00:45:20Z,223,0,Material Animations examples,,"# MaterialAnimations
Material Animations examples 
"
codurance/task-list,master,40,171,2014-06-05T12:52:43Z,118,10,This is an example of code obsessed with primitives.,,"# Task List &nbsp; [![Build Status](https://travis-ci.org/codurance/task-list.png)](https://travis-ci.org/codurance/task-list)

This is an example of code obsessed with primitives.

A *primitive* is any concept technical in nature, and not relevant to your business domain. This includes integers, characters, strings, and collections (lists, sets, maps, etc.), but also things like threads, readers, writers, parsers, exceptions, and anything else purely focused on technical concerns. By contrast, the business concepts in this project, ""task"", ""project"", etc. should be considered part of your *domain model*. The domain model is the language of the business in which you operate, and using it in your code base helps you avoid speaking different languages, helping you to avoid misunderstandings. In our experience, misunderstandings are the biggest cause of bugs.

## Exercise

Try implementing the following features, refactoring primitives away as you go. Try not to implement any new behaviour until the code you're about to change has been completely refactored to remove primitives, i.e. **_Only refactor the code you're about to change, then make your change. Don't refactor unrelated code._**

One set of criteria to identify when primitives have been removed is to only allow primitives in constructor parameter lists, and as local variables and private fields. They shouldn't be passed into methods or returned from methods. The only exception is true infrastructure code—code that communicates with the terminal, the network, the database, etc. Infrastructure requires serialisation to primitives, but should be treated as a special case. You could even consider your infrastructure as a separate domain, technical in nature, in which primitives *are* the domain.

You should try to wrap tests around the behaviour you're refactoring. At the beginning, these will mostly be high-level system tests, but you should find yourself writing more unit tests as you proceed.

### Features

  1. Deadlines
      1. Give each task an optional deadline with the `deadline <ID> <date>` command.
      2. Show all tasks due today with the `today` command.
  2. Customisable IDs
      1. Allow the user to specify an identifier that's not a number.
      2. Disallow spaces and special characters from the ID.
  3. Deletion
      1. Allow users to delete tasks with the `delete <ID>` command.
  4. Views
      1. View tasks by date with the `view by date` command.
      2. View tasks by deadline with the `view by deadline` command.
      3. Don't remove the functionality that allows users to view tasks by project, but change the command to `view by project`.

### Considerations and Approaches

Think about *behaviour attraction*. Quite often, you can reduce the amount of behaviour that relies upon primitives from the outside world (as opposed to internal primitives stored as private fields or locals) simply by moving the behaviour to a *value object* which holds the primitives. If you don't have a value object, create one. These value objects are known as *behaviour attractors* because once they're created, they make it far more obvious where behaviour should live.

A related principle is to consider the type of object you've created. Is it a true value object (or *record*), which simply consists of `getFoo` methods that return their internal primitives (to be used only with infrastructure, of course), or is it an object with behaviour? If it's the latter, you should avoid exposing any internal state at all. The former should not contain any behaviour. Treating something as both a record and an object generally leads to disaster.

Your approach will depend on whether you learn toward a functional or an object-oriented style for modelling your domain. Both encourage encapsulation, but *information hiding* techniques are generally only used in object-oriented code. They also differ in the approach used to extract behaviour; functional programming often works with closed sets of behaviour through *tagged unions*, whereas in object-oriented code, we use *polymorphism* to achieve the same ends in an open, extensible manner.

Separate your commands and queries. Tell an object to do something, or ask it about something, but don't do both.

Lastly, consider SOLID principles when refactoring:

  * Aim to break large chunks of behaviour into small ones, each with a single responsibility.
  * Think about the dimensions in which it should be easy to extend the application.
  * Don't surprise your callers. Conform to the interface.
  * Segregate behaviour based upon the needs.
  * Depend upon abstractions.
"
robinhuy/react-native-typescript-examples,main,31,11,2020-11-25T04:39:27Z,1552,0,Learn React Native by examples.,react-native typescript,"# React Native Typescript examples

Learn React Native (version 0.70 with Typescript) by easy-to-difficult examples.

_For more basic examples, see [React Native Expo examples](https://github.com/robinhuy/react-native-expo-examples)_

## Run project in development

- Setting up the development environment: https://reactnative.dev/docs/environment-setup.

- Install dependencies: `yarn` (or `npm install`). On iOS run: `npx pod-install`.

- Run on Android: `yarn android` (or `npm run android`).

- Run on iOS: `yarn ios` (or `npm run ios`).

## Change example

Modify code in `App.tsx`, each example is an application.

## Preview

### 1. Quiz Game

Learn how to use: **Type Script static type checking**, **React Hook useEffect + Timer**

<img src=""https://user-images.githubusercontent.com/12640832/101762123-9842e080-3b0f-11eb-951a-82fae0c2481b.gif"" width=""250"" alt=""Quiz Game"" />

### 2. Booking Car

Learn how to use: **Native Base + React Native Vector Icons**, **React Native Maps + React Native Maps Directions**, **Google Map API**, **Keyboard + Keyboard Event**

<img src=""https://user-images.githubusercontent.com/12640832/101765164-85320f80-3b13-11eb-8066-a5d4436ebd90.gif"" width=""250"" alt=""Booking Car"" />

Note: To run this example, you must get & config Google Map API KEY for [Android](https://developers.google.com/maps/documentation/android-sdk/get-api-key) or [iOS](https://developers.google.com/maps/documentation/ios-sdk/get-api-key)

### 3. Gmail clone

Learn how to use: **API Sauce**, **MobX + MobX React Lite**, **React Context**, **React Navigation Authentication flows + useFocusEffect**, **React Native Web View**

<img src=""https://user-images.githubusercontent.com/12640832/102325797-2d355600-3fb6-11eb-9975-dd8849782b48.gif"" width=""250"" alt=""Gmail clone"" />

Note: To run this example, you must start the server ([https://github.com/robinhuy/fake-api-nodejs](https://github.com/robinhuy/fake-api-nodejs)) in folder `server`:

```
  cd server
  yarn
  yarn start
```
"
natanfudge/fabric-example-mod-kotlin,1.18,100,23,2019-07-27T08:35:41Z,143,2,Example Kotlin Fabric Mod,,"# Fabric Example Mod - Kotlin
![Gradle build](https://github.com/natanfudge/fabric-example-mod-kotlin/workflows/Gradle%20build/badge.svg)
## Setup

0. Create a new mod repository by pressing the ""Use this template"" button and clone the created repository.

1. Import build.gradle file with IntelliJ IDEA

2. Edit build.gradle and mod.json to suit your needs.
    * The ""mixins"" object can be removed from mod.json if you do not need to use mixins.
    * Please replace all occurences of ""modid"" with your own mod ID - sometimes, a different string may also suffice.
3. Run!

## License

This template is available under the CC0 license. Feel free to learn from it and incorporate it in your own projects.
"
rolandkrueger/vaadin-by-example,master,61,50,2012-08-21T11:08:17Z,5483,2,Learn Vaadin by working example projects.,vaadin,"Welcome to _vaadin-by-example_
==============================

__Learn Vaadin by working example projects.__
- - - - - - - - - - - - - - - - - - - - - - - - - - - 

The goal of this project is to provide learners of the  [Vaadin](http://www.vaadin.com/ ""Vaadin"") toolkit with working example projects for various problems which one might encounter while coding with Vaadin. The idea behind this is to complement articles and tutorials on Vaadin topics with code examples that will work out of the box.

Oftentimes, tutorials only provide code snippets to illustrate how the things they describe will work. These snippets only focus on the described problem. Beginners often have difficulties transferring these excerpts into a working piece of code.

This project aims at fixing that. It will provide working examples for tutorials that can be found either in the example project itself or at some given location in the web. To make understanding the concepts easier, the examples contain as much code as necessary and as litte code as possible.

Licensing
---------
Since the main intention of this project is to offer people example code that actually works, this code should also be usable as a template for copy & pasting parts of the examples into own projects. Therefore, the licensing for the examples' source code should be as unrestrictive as possible. People shall be able to use parts of the code as they see fit without having to bother with the requisites of more or less restrictive software licenses. The examples should therefore be licensed under unrestrictive licenses, such as the MIT license or similar.

Contribute!
-----------

Contributions to this project are welcome! This is not planned as a one-man-show, so go ahead and fork this project. There are some things to take into consideration, though, when contributing example projects.

* __Licensing__
You should use a license that is as unrestrictive as possible. See the section above about licensing for an explanation of the reason for that. Each example should contain the license text in a text file named 'LICENSE'.

* __Example Size__
Example projects should be kept as concise as possible so as to not distract learners too much from the core intention of the example code.

* __Working Out Of The Box__
Examples should be runnable without requiring a complex setup. Ideally, they should be accompanied with portable build mechanisms, such as a Maven pom.xml making the example quickly accessible with a simple _mvn jetty:run_.

* __No JAR Dependencies__
Examples should not contain the necessary dependencies as binary JAR files. These should be obtainable by users through other channels. Again, using Apache Maven or Ivy builds will facilitate that.

* __Accompanying Tutorials__
An example project should not stand all by itself. Every example should be accompanied by one or more tutorials that illustrate the background of the code. These tutorials could be contained directly in the example. Another option would be to provide a hyperlink to the location of the tutorial on the web in some read-me file. Besides that link, such a read-me file should contain an abstract of the respective tutorial.

* __Project Naming__
Names for example projects should be chosen such that the example's intention becomes clear already from the name. That said, refrain from generic project names such as 'HelloWorld' or 'VaadinExample'.

Disclaimer
----------
The name Vaadin and related trademarks/trade names are the property of Vaadin Ltd. and may not be used other than stated in [Vaadin's Terms of Service](https://vaadin.com/terms-of-service). Copyright to the Vaadin Framework is owned by Vaadin Ltd."
gxercavins/dataflow-samples,master,35,17,2018-07-31T18:03:36Z,390,59,Examples using Google Cloud Dataflow - Apache Beam,,"# Dataflow-samples

This repository contains some Google Cloud Dataflow / Apache Beam samples.

## Quickstart

Each folder contains specific instructions for the corresponding example.

Use the below button to clone this repository into Cloud Shell and start right away:

[![Open this project in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.png)](https://console.cloud.google.com/cloudshell/open?git_repo=https://github.com/gxercavins/dataflow-samples&page=editor&tutorial=README.md)

## Examples

Currently, these are the examples available:

* **Adaptive triggers (Java)**: modify the behavior of triggers at the start and end of the same window so that you can have some degree of control on the output rate.
* **Assign sessions (Java)**: assign timestamped events into a given list of all possible sessions. 
* **Batch Schema auto-detect (Java)**: how to load multiple JSON files with disparate schemas into BigQuery.
* **BigQuery dead letters (Python)**: how to handle rows that could not be correctly streamed into BigQuery.
* **BigQuery Storage API (Java)**: how to read directly from a BigQuery table using the new Storage API.
* **Data-driven Triggers (Java)**: how to use the State API to simulate data-driven triggers.
* **Dynamic destinations (Java)**: write dynamically to different BigQuery tables according to the schema of the processed record.
* **Empty windows (Java)**: how to log/emit information even when the input source has no data for that window.
* **Filename match (Python)**: read from multiple files and prepend to each record the name of the matching file (optionally enrich with BigQuery).
* **Lag function (Python)**: how to compare an event with the equivalent one from the previous window.
* **Logging GroupByKey (Java)**: some ideas to log information about grouped elements using Stackdriver and BigQuery.
* **Normalize values (Python)**: normalize all PCollection values after calculating the maximum and minimum per each key.
* **Quick, Draw! dataset (Python)**: download raw data from a public dataset, convert to images and save them in `png` format.
* **RegEx pattern (Java)**: tag every path pattern and be able to associate each matched file with it.
* **Session windows (Python)**: example to demonstrate how to group events per user and session.
* **Timestamps in path (Java)**: process hourly files where timestamp needs to be inferred from folder structure.
* **Top10 distinct combiner (Python)**: we'll modify `TopCombineFn` to have unique keys when accumulating fired panes.
* **When are Pub/Sub messages ACKed? (Java)**: example to see what happens with `PubsubIO` in Dataflow.
* **With Timestamps (Java)**: assign processing time as element timestamp and shift to the past if needed.

In addition, the `UTILS` folder contains simple Dataflow snippets: adding labels, stopping jobs programmatically, process files selectively according to their format, understanding wall time, ensuring custom options are globally available, retrieving job ID or SDK version, writing BigQuery results in CSV format, enrich a PCollection with data from a BigQuery table, processing files using Pub/Sub notifications for GCS, etc.

The `BEAM-PATTERNS` folder contains common usage patterns that have been contributed to the Beam documentation.

The `TEMPLATES` folder groups examples that make for some convenient template use cases.

The `PLAYGROUND` folder recaps other more experimental examples that can be interesting to share such as trying to zip a PCollection, throttling a step or BeamSQL tests.

## License

These examples are provided under the Apache License 2.0.

## Issues

Report any issue to the GitHub issue tracker.
"
hantsy/spring-graphql-sample,master,85,21,2021-06-10T11:58:58Z,9892,39,"Spring GraphQL examples using Netflix DGS, GraphQL Java and  Spring GraphQL",graphql graphql-java netflix-dgs spring spring-boot spring-graphql,"# spring-graphql-sample

Spring GraphQL examples using the following frameworks and libraries:

* [Netflix DGS(Domain Graph Service) framework](https://netflix.github.io/dgs/) 
* [Spring GraphQL](https://github.com/spring-projects/spring-graphql)
* [GraphQL Java Kickstart](https://www.graphql-java-kickstart.com/)
* [GraphQL Java](https://www.graphql-java.com/)
* [GraphQL SPQR(GraphQL Schema Publisher & Query Resolver, pronounced like speaker)](https://github.com/leangen/graphql-spqr)
* [ExpediaGroup GraphQL Kotlin](https://opensource.expediagroup.com/graphql-kotlin/docs)

Other GraphQL Java integration examples with Java frameworks.

* [GraphQL with Quarkus](https://github.com/hantsy/quarkus-sandbox)
* [GraphQL with Vertx](https://github.com/hantsy/vertx-sandbox)

## Guide

TBD

## Example Codes
|  Example name       | Description     |
| ---- | ---- |
|[dgs](./dgs)  | Simple Netflix DGS example|
|[dgs-webflux](./dgs-webflux)| Simple Netflix DGS example with Spring WebFlux|
|[dgs-subscription-ws](./dgs-subscription-ws) | Simple Netflix DGS Subscription example using WebSocket protocol|
|[dgs-subscription-ui](./dgs-subscription-ui)  | Angular Client app for dgs-subscription-ws|
|[dgs-subscription-sse](./dgs-subscription-sse)  | Simple Netflix DGS Subscription example using Http/SSE protocol|
|[dgs-codegen](./dgs-codegen) | Netflix DGS example with Spring Jdbc and Gradle codegen plugin|
|[dgs-fileupload](./dgs-fileupload) | Netflix DGS file upload example|
|[dgs-client](./dgs-client) | Netflix DGS Typesafe Client example|
|[dgs-kotlin-co](./dgs-kotlin-co) | **A complete Netflix DGS example** with WebFlux, Kotlin Coroutines, Spring Data R2dbc and Spring Security|
|[dgs-kotlin](./dgs-kotlin) | **A complete Netflix DGS example** with WebMvc/Kotlin, Spring Data Jdbc, Spring Security and Spring Session/Spring Data Redis|
|[graphql-kotlin](./graphql-kotlin) |  ExpediaGroup Graphql Kotlin Spring Boot example|
|[spring-graphql](./spring-graphql) | Spring GraphQL example|
|[spring-graphql-webmvc](./spring-graphql-webmvc) | Spring GraphQL with WebMvc Controller annotation example|
|[spring-graphql-querydsl](./spring-graphql-querydsl)| Spring GraphQL/JPA/QueryDSl Data Fetchers example|
|[spring-graphql-webflux](./spring-graphql-webflux) | Spring GraphQL/WebFlux example with WebSocket transport protocol |
|[spring-graphql-rsocket-kotlin-co](./spring-graphql-rsocket-kotlin-co) | Spring GraphQL/WebFlux/Kotlin Coroutines example with RSocket transport protocol |


### Legacy Codes

Some example codes are moved to legacy folder, because the upstream project is discontinued or under an inactive development status.

|  Example name       | Description     |
| ---- | ---- |
|[graphql-java](./legacy/graphql-java) | GraphQL Java vanilla Spring Boot example, upstream project is discontinuned, replaced by Spring GraphQL|
|[graphql-spqr](./legacy/graphql-spqr)| GraphQL SPQR Spring example, inactive|
|[graphql-java-kickstart](./graphql-java-kickstart)  | GraphQL Java Kickstart Spring Boot example|
|[graphql-java-kickstart-webclient](./graphql-java-kickstart-webclient) | GraphQL Java Kickstart Spring WebClient example|
|[graphql-java-kickstart-annotations](./graphql-java-kickstart-annotations) | GraphQL Java Kickstart Spring Boot example(Code first)|

## Prerequisites

Make sure you have installed the following software.

* Java 21
* Apache Maven 3.8.x / Gradle 7.x
* Docker

Some sample codes are written in Kotlin. If you are new to Kotlin, start to learn it from the [the Kotlin homepage](https://kotlinlang.org/).

## Build 

Clone the source codes from Github.

```bash
git clone https://github.com/hantsy/spring-graphql-sample/
```

Open a terminal, and switch to the root folder of the project, and run the following command to build the whole project.

```bash
docker-compose up postgres // start up a postgres it is required
cd examplename // change to the example folder
mvn clean install // build the project
//or
./gradlew build
```

Run the application.

```bash
mvn spring-boot:run 
//or 
./gradlew bootRun
// or from command line after building
java -jar target/xxx.jar
```


## Contribution

Any suggestions are welcome, filing an issue or submitting a PR is also highly recommended.  

## References

* [Getting started with GraphQL Java and Spring Boot](https://www.graphql-java.com/tutorials/getting-started-with-spring-boot/)
* [Getting Started with GraphQL and Spring Boot](https://www.baeldung.com/spring-graphql)
* [Open Sourcing the Netflix Domain Graph Service Framework: GraphQL for Spring Boot](https://netflixtechblog.com/open-sourcing-the-netflix-domain-graph-service-framework-graphql-for-spring-boot-92b9dcecda18)
* [Netflix Open Sources Their Domain Graph Service Framework: GraphQL for Spring Boot ](https://www.infoq.com/news/2021/02/netflix-graphql-spring-boot/)
* [Netflix Embraces GraphQL Microservices for Rapid Application Development ](https://www.infoq.com/news/2021/03/netflix-graphql-microservices/)
* [GraphQL Reference Guide: Building Flexible and Understandable APIs ](https://www.infoq.com/articles/GraphQL-ultimate-guide/)
"
jboss-developer/jboss-picketlink-quickstarts,master,95,191,2013-08-12T14:18:51Z,2396,12,"The quickstarts demonstrate PicketLink and a few additional technologies. They provide small, specific, working examples that can be used as a reference for your own project.",,"# PicketLink Quickstarts

## Introduction

These quickstarts run JBoss Enterprise Application Platform 6 and WildFly.

We recommend using the ZIP distribution file for both JBoss Enterprise Application Platform 6 and WildFly.

You can also run PicketLink in Apache TomEE or Glassfish. In this case, you may need some additional configuration in order to get them
up and running. For PicketLink JEE Security examples, you must ship JBoss Logging jars in your deployments. 

## System Requirements

To run these quickstarts with the provided build scripts, you need the following:

1. Java 1.6 or Java 1.7, depending if you're using JBoss EAP or WildFly to run the quickstarts. You can choose from the following:
    * OpenJDK
    * Oracle Java SE
    * Oracle JRockit

2. Maven 3.0.0 or newer, to build and deploy the examples
    * If you have not yet installed Maven, see the [Maven Getting Started Guide](http://maven.apache.org/guides/getting-started/index.html) for details.
    * If you have installed Maven, you can check the version by typing the following in a command line:

            mvn --version

3. The JBoss Enterprise Application Platform 6 distribution ZIP or the WildFly distribution ZIP.
    * For information on how to install and run those servers, refer to the their documentation.

## Check Out the Source

1. To clone this Git repository, use the following command:

        git clone git@github.com:jboss-developer/jboss-picketlink-quickstarts.git

2. If you want the quickstarts for a particular version (eg.: 2.5.2.Final) execute the following command:

        cd jboss-picketlink-quickstarts
        git checkout v2.5.2.Final

The command above will checkout a TAG corresponding to the version you want to use. For each release of PicketLink we also release and TAG
a version for the quickstarts. Each TAG uses a specific PicketLink version. Make sure you're using the TAG for the version you're looking for.

We recommend to always consider the latest version of the quickstarts, so you can check the latest changes and updates to PicketLink.

## Run the Quickstarts

The root folder of each individual quickstart contains a README file with specific details on how to build and run the example. In most cases you do the following:

* [Start the JBoss server](#start-the-jboss-server)
* [Build and deploy the quickstarts](#build-and-deploy-the-quickstarts)

## About the PicketLink Federation Quickstarts

The *PicketLink Federation Quickstarts* provide a lot of examples about how to use *PicketLink Federation SAML Support* to enable SSO for your applications.
Before running them you need to understand how they are related with each other. Basically, each Identity Provider is meant to be used by a group of Service Providers.
In order to get the whole Single Sing-On functionality demonstrated, you need to deploy them together.

| SAML Configuration                        | Identity Provider                                 | Service Provider(s)                                                                                      |
| -------------                             |:-------------------------------------------------:| --------------------------------------------------------------------------------------------------------:|
| Basic                                     | picketlink-federation-saml-idp-basic              | picketlink-federation-saml-sp-post-basic, picketlink-federation-saml-sp-redirect-basic                   |
| Encryption                                | picketlink-federation-saml-idp-with-encryption    | picketlink-federation-saml-sp-with-encryption                                                            |
| Metadata                                  | picketlink-federation-saml-idp-with-metadata      | picketlink-federation-saml-sp-with-metadata                                                              |
| Signatures                                | picketlink-federation-saml-idp-with-signature     | picketlink-federation-saml-sp-post-with-signature, picketlink-federation-saml-sp-redirect-with-signature |
| HTTP CLIENT_CERT and FORM Authentication  | picketlink-federation-saml-idp-ssl                | picketlink-federation-saml-sp-post-basic, picketlink-federation-saml-sp-redirect-basic                   |
| IDP Servlet Filter                        | picketlink-federation-saml-idp-servlet-filter     | picketlink-federation-saml-sp-post-with-signature, picketlink-federation-saml-sp-redirect-with-signature |

The table above describes what are the Identity Provider and Service Providers required to test a specific configuration. It is important that you respect these dependencies to get the
functionality properly working.

### Using SAML Tracer Firefox Add-On to Debug the SAML SSO Flow

If you want to understand even better how IdPs and SPs communicate with each other, you may want to configure the [SAML Tracer Add-On](https://addons.mozilla.org/en-US/firefox/addon/saml-tracer/) to your Mozilla Firefox.
This is a nice way to debug and view SAML Messages, so you can take a look on how the IdP and SP exchange messages when establishing a SSO session.

### Start the JBoss Server

Before you deploy a quickstart, in most cases you need a running JBoss Enterprise Application Platform 6 or WildFlyserver. A few of the Arquillian tests do not require a running server. This will be noted in the README for that quickstart.

The JBoss server can be started a few different ways.

* [Start the JBoss Server With the _web_ profile](#start-the-jboss-server-with-the-web-profile): This is the default configuration. It defines minimal subsystems and services.
* [Start the JBoss Server with the _full_ profile](#start-the-jboss-server-with-the-full-profile): This profile configures many of the commonly used subsystems and services.
* [Start the JBoss Server with a custom configuration](#start-the-jboss-server-with-custom-configuration-options): Custom configuration parameters can be specified on the command line when starting the server.

The README for each quickstart will specify which configuration is required to run the example.

#### Start the JBoss Server with the Web Profile

To start JBoss Enterprise Application Platform 6 or WildFly with the Web Profile:

1. Open a command line and navigate to the root of the JBoss server directory.
2. The following shows the command line to start the JBoss server with the web profile:

        For Linux:   JBOSS_HOME/bin/standalone.sh
        For Windows: JBOSS_HOME\bin\standalone.bat

#### Start the JBoss Server with the Full Profile

To start JBoss Enterprise Application Platform 6 or WildFly with the Full Profile:

1. Open a command line and navigate to the root of the JBoss server directory.
2. The following shows the command line to start the JBoss server with the full profile:

        For Linux:   JBOSS_HOME/bin/standalone.sh -c standalone-full.xml
        For Windows: JBOSS_HOME\bin\standalone.bat -c standalone-full.xml

#### Start the JBoss Server with Custom Configuration Options

To start JBoss Enterprise Application Platform 6 or WildFly with custom configuration options:

1. Open a command line and navigate to the root of the JBoss server directory.
2. The following shows the command line to start the JBoss server. Replace the CUSTOM_OPTIONS with the custom optional parameters specified in the quickstart.

        For Linux:   JBOSS_HOME/bin/standalone.sh CUSTOM_OPTIONS
        For Windows: JBOSS_HOME\bin\standalone.bat CUSTOM_OPTIONS

### Build and Deploy the Quickstarts

See the README file in each individual quickstart folder for specific details and information on how to run and access the example.

#### Build the Quickstart Archive

In some cases, you may want to build the application to test for compile errors or view the contents of the archive.

1. Open a command line and navigate to the root directory of the quickstart you want to build.
2. Use this command if you only want to build the archive, but not deploy it:

        For EAP 6:     mvn clean package
        For WildFly:   mvn -Pwildfly clean package

#### Build and Deploy the Quickstart Archive

1. Make sure you [start the JBoss server](#start-the-jboss-server) as described in the README.
2. Open a command line and navigate to the root directory of the quickstart you want to run.
3. Use this command to build and deploy the archive:

        For EAP 6:     mvn clean package jboss-as:deploy
        For WildFly:   mvn -Pwildfly clean package wildfly:deploy

#### Undeploy an Archive

The command to undeploy the quickstart is simply:

        For EAP 6:     mvn jboss-as:undeploy
        For WildFly:   mvn -Pwildfly wildfly:undeploy

PicketLink Documentation
------------

The documentation is available from the following [link](http://docs.jboss.org/picketlink/2/latest/).
"
patniemeyer/learningjava,master,91,136,2013-06-25T15:05:03Z,13973,5,"Example Code for Learning Java, O'Reilly & Associates, 4th Edition",,"learningjava
============

Example Code for Learning Java, O'Reilly &amp; Associates, 4th Edition
"
find-sec-bugs/juliet-test-suite,master,47,67,2017-09-11T20:25:17Z,15558,0,:microscope: A collection of test cases in the Java language. It contains examples for 112 different CWEs.,application code sample vulnerable,"# Juliet Test Suite

A collection of test cases in the Java language. It contains examples for 112 different CWEs. 
The test suite is taken from [NIST website](https://samate.nist.gov/SRD/testsuite.php)

This repository add alternative build integration : Gradle and Maven

## Gradle

```
gradle build
```

## Maven

```
mvn compile
```
"
v5tech/dubbo-example,master,26,21,2015-08-05T16:07:30Z,17613,0,dubbo example,dubbo dubbo-example,"# dubbo-example

dubbo 分布式服务配置案例

升级到dubbox 2.8.4

dubbox 2.8.4编译安装

```
https://github.com/dangdangdotcom/dubbox/archive/dubbox-2.8.4.zip
修改根pom中curator_version版本为<curator_version>2.6.0</curator_version>
mvn install -Dmaven.test.skip=true
```

### 1. 项目结构介绍

dubbo-service 公共接口服务

dubbo-provider 公共接口服务实现(dubbo provider) 服务提供者

dubbo-consumer (dubbo consumer) dubbo服务消费者

### 2. 具体描述

* dubbo-service 为公共服务接口，在该模块中只声明对外提供的接口,在dubbo provider和 dubbo consumer均有引用

* dubbo-provider 公共接口服务实现,服务提供者.为dubbo consumer提供服务。

* 示例代码如下

```java
import net.aimeizi.dubbo.entity.User;
import net.aimeizi.dubbo.service.UserService;

import com.alibaba.dubbo.config.annotation.Service;

@Service
public class UserServiceImpl implements UserService {

	@Override
	public User save(User user) {
		user.setUserId(++UserIdGenerator.id);
		return user;
	}

}
```
* dubbo provider 核心配置

```xml
<!-- 提供方应用信息，用于计算依赖关系 -->
<dubbo:application name=""dubbo-provider"" />
<!-- 使用zookeeper注册中心暴露服务地址 -->
<dubbo:registry address=""zookeeper://127.0.0.1:2181"" />
<!-- 用dubbo协议在20880端口暴露服务 -->
<dubbo:protocol name=""dubbo"" port=""20880"" />
<!-- 扫描注解包路径，多个包用逗号分隔，不填pacakge表示扫描当前ApplicationContext中所有的类 -->
<dubbo:annotation package=""net.aimeizi.dubbo.service""/>
```
注:`<dubbo:annotation package=""net.aimeizi.dubbo.service""/>`配置会扫描该包下的@Service(com.alibaba.dubbo.config.annotation.Service)注解. 这里的服务注入使用dubbo @Service注解

* maven依赖

```xml
<dependency>
    <groupId>net.aimeizi</groupId>
    <artifactId>dubbo-service</artifactId>
    <version>1.0-SNAPSHOT</version>
</dependency>

<dependency>
    <groupId>org.springframework</groupId>
    <artifactId>spring-context</artifactId>
    <version>${spring.version}</version>
</dependency>

<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>dubbo</artifactId>
    <version>2.8.4</version>
    <exclusions>
	<exclusion>
	    <artifactId>spring</artifactId>
	    <groupId>org.springframework</groupId>
	</exclusion>
    </exclusions>
</dependency>

<dependency>
    <groupId>org.apache.zookeeper</groupId>
    <artifactId>zookeeper</artifactId>
    <version>3.4.6</version>
    <exclusions>
	<exclusion>
	    <groupId>com.sun.jmx</groupId>
	    <artifactId>jmxri</artifactId>
	</exclusion>
	<exclusion>
	    <groupId>com.sun.jdmk</groupId>
	    <artifactId>jmxtools</artifactId>
	</exclusion>
	<exclusion>
	    <groupId>javax.jms</groupId>
	    <artifactId>jms</artifactId>
	</exclusion>
    </exclusions>
</dependency>

<dependency>
    <groupId>com.github.sgroschupf</groupId>
    <artifactId>zkclient</artifactId>
    <version>0.1</version>
</dependency>
```

* dubbo-consumer 消费者.这里只依赖公共服务接口，不需要直接依赖dubbo provider

* 示例代码如下

```java
import com.alibaba.dubbo.config.annotation.Reference;
import net.aimeizi.dubbo.service.DemoService;
import net.aimeizi.dubbo.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;

import javax.annotation.Resource;

/**
 *
 * dubbo 消费者
 *
 * @Reference 注解需要在 dubbo consumer中做如下配置
 *
 * <dubbo:annotation/>
 *	<context:component-scan base-package=""net.aimeizi.dubbo.controller"">
 *	<context:include-filter type=""annotation"" expression=""com.alibaba.dubbo.config.annotation.Reference""/>
 * </context:component-scan>
 *
 * 若要使用@Autowired或@Resource注解需要显式声明bean
 *
 * 使用@Autowired或@Resource注解时需要使用dubbo:reference来声明
 * <dubbo:reference interface=""net.aimeizi.dubbo.service.UserService"" id=""userService""/>
 * <dubbo:reference interface=""net.aimeizi.dubbo.service.DemoService"" id=""demoService""/>
 *
 * 以上的配置均需要在spring mvc的DispatcherServlet配置中显式配置dubbo consumer的配置.如/WEB-INF/applicationContext-dubbo-consumer.xml 否则在Controller中服务报NullPointException
 * <servlet>
 *	<servlet-name>mvc-dispatcher</servlet-name>
 *		<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
 *	<init-param>
 *	<param-name>contextConfigLocation</param-name>
 *		<param-value>/WEB-INF/applicationContext*.xml,/WEB-INF/mvc-dispatcher-servlet.xml</param-value>
 *	</init-param>
 *	<load-on-startup>1</load-on-startup>
 * </servlet>
 *
 */
@Controller
public class HelloController {

	@Reference
	//@Autowired
	//@Resource
	private DemoService demoService;

	@Reference
	//@Autowired
	//@Resource
	private UserService userService;

	@RequestMapping(value = ""/test"", method = RequestMethod.GET)
	public String printWelcome(ModelMap model) {
		model.addAttribute(""message"", ""Hello world!"");
		return ""hello"";
	}
}
```

注意:

① @Reference 注解需要在 dubbo consumer配置文件中做如下配置
```xml
<dubbo:annotation/>
<context:component-scan base-package=""net.aimeizi.dubbo.controller"">
	<context:include-filter type=""annotation"" expression=""com.alibaba.dubbo.config.annotation.Reference""/>
</context:component-scan>
```

② 若要使用@Autowired或@Resource注解需要显式声明bean

```xml
<!-- 使用@Resource注解时需要使用dubbo:reference来声明 -->
<dubbo:reference interface=""net.aimeizi.dubbo.service.UserService"" id=""userService""/>
<dubbo:reference interface=""net.aimeizi.dubbo.service.DemoService"" id=""demoService""/>
```

③ 以上的配置均需要在spring mvc的DispatcherServlet配置中显式配置dubbo consumer的配置.如/WEB-INF/applicationContext-dubbo-consumer.xml 否则在Controller中服务报NullPointException

```xml
<servlet>
	<servlet-name>mvc-dispatcher</servlet-name>
	<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
	<init-param>
		<param-name>contextConfigLocation</param-name>
		<param-value>/WEB-INF/applicationContext*.xml,/WEB-INF/mvc-dispatcher-servlet.xml</param-value>
	</init-param>
	<load-on-startup>1</load-on-startup>
</servlet>
```

### 3. 演示

完整演示

![](Screenshots/1.gif)

错误演示Controller中服务报NullPointException

![](Screenshots/2.gif)

使用@Autowired或@Resource注解

![](Screenshots/3.gif)

dubbo管理控制台演示

![](Screenshots/dubbo.gif)


# 与我联系

* QQ:*184675420*

* Email:*sxyx2008#gmail.com*(#替换为@)

* HomePage:*[aimeizi.net](http://aimeizi.net)*

* Weibo:*[http://weibo.com/qq184675420](http://weibo.com/qq184675420)*(荧星诉语)

* Twitter:*[https://twitter.com/sxyx2008](https://twitter.com/sxyx2008)*


# License

MIT

Copyright (c) 2015 雪山飞鹄"
ElanYoung/spring-boot-learning-examples,master,32,12,2022-09-01T01:48:56Z,336,1,🤖 Spring Boot 2.x 实践案例（实用）,actuator druid easy-excel jasypt jwt minio quartz spring-boot spring-security websocket,"<h1 align=""center""><a href=""https://github.com/ElanYoung"" target=""_blank"">🤖 Spring Boot 2.x 实践案例</a></h1>
<p align=""center"">
  <a href=""https://travis-ci.com/ElanYoung/spring-boot-learning-examples""><img alt=""Travis-CI"" src=""https://travis-ci.com/xkcoding/spring-boot-demo.svg?branch=master""/></a>
  <a href=""https://www.codacy.com/app/ElanYoung/spring-boot-learning-examples?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=xkcoding/spring-boot-demo&amp;utm_campaign=Badge_Grade""><img alt=""Codacy"" src=""https://api.codacy.com/project/badge/Grade/1f2e3d437b174bfc943dae1600332ec1""/></a>
  <a href=""https://doc.starimmortal.com""><img alt=""author"" src=""https://img.shields.io/badge/author-ElanYoung-blue.svg""/></a>
  <a href=""https://www.oracle.com/technetwork/java/javase/downloads/index.html""><img alt=""JDK"" src=""https://img.shields.io/badge/JDK-1.8.0_312-orange.svg""/></a>
  <a href=""https://docs.spring.io/spring-boot/docs/2.7.11/reference/html/""><img alt=""Spring Boot"" src=""https://img.shields.io/badge/Spring Boot-2.7.11-brightgreen.svg""/></a>
  <a href=""https://github.com/ElanYoung/spring-boot-learning-examples/blob/master/LICENSE""><img alt=""LICENSE"" src=""https://img.shields.io/github/license/ElanYoung/spring-boot-learning-examples.svg""/></a>
</p>

<p align=""center"">
  <a href=""https://github.com/ElanYoung/spring-boot-learning-examples/stargazers""><img alt=""star"" src=""https://img.shields.io/github/stars/ElanYoung/spring-boot-learning-examples.svg?label=Stars&style=social""/></a>
  <a href=""https://github.com/ElanYoung/spring-boot-learning-examples/network/members""><img alt=""star"" src=""https://img.shields.io/github/forks/ElanYoung/spring-boot-learning-examples.svg?label=Fork&style=social""/></a>
  <a href=""https://github.com/ElanYoung/spring-boot-learning-examples/watchers""><img alt=""star"" src=""https://img.shields.io/github/watchers/ElanYoung/spring-boot-learning-examples.svg?label=Watch&style=social""/></a>
</p>

<p align=""center"">
  <span>English | <a href=""./README.zh-CN.md"">简体中文</a></span>
</p>

## Introduction

`spring-boot-learning-examples` is developed based on the `Spring Boot 2.7.x` version. It integrates the technology
stack and middleware commonly used in development. It is a project for deep learning and actual combat
with `Spring Boot`.

> If you have an example to contribute or needs to meet, it is very welcome to submit
> a [issue](https://github.com/ElanYoung/spring-boot-learning-examples/issues/new).

## Environment

- **JDK 1.8 +**
- **Maven 3.5 +**
- **Mysql 5.7 +**
- **IntelliJ IDEA 2018.2 +** (*Note: Please use IDEA and make sure plugin `lombok` installed.*)

## Getting Started

### Get Project

```bash
git clone https://github.com/ElanYoung/spring-boot-learning-examples.git
```

### Import Project

> Open `spring-boot-learning-examples` project in `IntelliJ IDEA`.

### Run Project

> Find the `Application` class in each module, right-click `Run 'Application'` to run each practice case.

## Learning Examples

| Module                       | Description                                | Code                                                                                                                                | Article                                                                                                  |
|------------------------------|--------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| spring-boot-banner           | Spring  Boot 自定义 Banner                    | [spring-boot-banner](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-banner)                     | [《Spring Boot 自定义 Banner》](https://blog.csdn.net/qq991658923/article/details/121302050)                  |
| spring-boot-actuator         | Spring Boot 集成 Actuator 监控工具               | [spring-boot-actuator](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-actuator)                 | [《Spring Boot 集成 Actuator 监控工具》](https://blog.csdn.net/qq991658923/article/details/127112107)            |
| spring-boot-druid            | Spring Boot 集成 Druid 连接池                   | [spring-boot-druid](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-druid)                       | [《Spring Boot 集成 Druid 连接池》](https://blog.csdn.net/qq991658923/article/details/127112527)                |
| spring-boot-jasypt           | Spring Boot 集成 jasypt 实现敏感信息加密             | [spring-boot-jasypt](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-jasypt)                     | [《Spring Boot 集成 jasypt 实现敏感信息加密》](https://blog.csdn.net/qq991658923/article/details/127112431)          |
| spring-boot-websocket-native | Spring Boot 集成 WebSocket（原生注解）             | [spring-boot-websocket-native](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-websocket-native) | [《Spring Boot 集成 WebSocket（原生注解与Spring封装）》](https://blog.csdn.net/qq991658923/article/details/127022522) |
| spring-boot-websocket-spring | Spring Boot 集成 WebSocket（Spring封装）         | [spring-boot-websocket-spring](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-websocket-spring) | [《Spring Boot 集成 WebSocket（原生注解与Spring封装）》](https://blog.csdn.net/qq991658923/article/details/127022522) |
| spring-boot-jwt              | Spring Boot 集成 JWT                         | [spring-boot-jwt](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-jwt)                           | [《Spring Boot 集成 JWT》](https://blog.csdn.net/qq991658923/article/details/127027528)                      |
| spring-boot-minio            | Spring Boot 集成 MinIO（分布式文件存储系统）            | [spring-boot-minio](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-minio)                       | [《Spring Boot 集成 MinIO》](https://blog.csdn.net/qq991658923/article/details/124623495)                    |
| spring-boot-quartz           | Spring Boot 集成 Quartz（定时任务）                | [spring-boot-quartz](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-quartz)                     | [《Spring Boot 集成 Quartz》](https://blog.csdn.net/qq991658923/article/details/127078993)                   |
| spring-boot-easy-excel       | Spring Boot 集成 EasyExcel                   | [spring-boot-easy-excel](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-easy-excel)             | [《Spring Boot 集成 EasyExcel》](https://blog.csdn.net/qq991658923/article/details/128153012)                |
| spring-boot-h2               | Spring Boot 集成 H2（轻量级数据库）                  | [spring-boot-h2](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-h2)                             |                                                                                                          |
| spring-boot-spring-security  | Spring Boot 集成 Spring Security 5.7.x（安全框架） | [spring-boot-spring-security](https://github.com/ElanYoung/spring-boot-learning-examples/tree/master/spring-boot-spring-security)   | [《Spring Boot 优雅集成 Spring Security 5.7.x（安全框架）》](https://juejin.cn/post/7244089396567982136)             |

## Stargazers over time

[![Stargazers over time](https://starchart.cc/ElanYoung/spring-boot-learning-examples.svg)](https://starchart.cc/ElanYoung/spring-boot-learning-examples)

## License

[MIT](http://opensource.org/licenses/MIT)

Copyright (c) 2022 ElanYoung
"
yida-lxw/solr-book,master,53,28,2016-10-02T01:12:16Z,267119,12,Solr book Example Code,,"# solr-book
Solr book Example Code
"
appiumbook/appiumbook,master,26,32,2018-11-19T10:04:20Z,25162,2,This repository contains all the sample examples discussed on Appium Book.,,
Mikuu/Pact-JVM-Example,master,69,58,2017-11-19T13:14:01Z,1590,0,Example Consumer & Provider projects for Pact JVM,consumer-driven-contract-testing contract-testing pact pact-jvm,
eip-work/kuboard-example,master,44,28,2019-07-12T06:10:54Z,2831,26,eip-service-dashboard-example,,"# kuboard-example

kuboard 的主要特点：
* 面向运维场景的设计
* 微服务分层显示
* 关联到微服务上下文的监控

详细文档请参考 Kuboard 官网，
[https://kuboard.cn](https://kuboard.cn)

kuboard-example 完成部署后的效果如下所示：

<p>
  <a href=""http://demo.eip.work/#/login?isReadOnly=true&token=eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJvYXJkLXZpZXdlci10b2tlbi1mdGw0diIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJvYXJkLXZpZXdlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImE1YWFiMmQxLTQxMjYtNDU5Yi1hZmNhLTkyYzMwZDk0NTQzNSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJvYXJkLXZpZXdlciJ9.eYqN3FLIT6xs0-lm8AidZtaiuHeX70QTn9FhJglhEyh5dlyMU5lo8UtR-h1OY8sTSeYdYKJAS83-9SUObKQhp6XNmRgOYAfZblKUy4mvbGVQ3dn_qnzxYxt6zdGCwIY7E34eNNd9IjMF7G_Y4eJLWE7NvkSB1O8zbdn8En9rQXv_xJ9-ugCyr4CYB1lDGuZl3CIXgQ1FWcQdUBrxTT95tzcNTB0l6OUOGhRxOfw-RyIOST83GV5U0iVzxnD4sjgSaJefvCU-BmwXgpxAwRVhFyHEziXXa0CuZfBfJbmnQW308B4wocr4QDm6Nvmli1P3B6Yo9-HNF__d2hCwZEr7eg"">在线演示</a>
</p>

![image-20190730212117628](README.assets/image-20190730212117628.png)



"
paulcwarren/spring-content-examples,main,25,9,2016-09-22T02:05:32Z,66296,6,Examples projects showing how to use Spring Content,,"[![Build Status](https://travis-ci.org/paulcwarren/spring-content-examples.svg?branch=master)](https://travis-ci.org/paulcwarren/spring-content-examples)

# Spring Content Examples

Examples projects showing how to use each Spring Content module.

While each `boot-starter` example does not specify a meta-data store, the standard examples always specify HSQL.


## Spring-Eg-Content-FS
- This example stores content on the local file system, under your temp directory (OS dependent) followed by `/spring-content-CURRENTTIME-INSTANCENUM/`.
- No environment variables are need to run this example. If you desire to change the location of files being stored add the following bean to your class and change the return value.

```java
  @Bean
  public File fileSystemRoot() throws IOException {
  return //MY_DIRECTORY_PATH;
  }
```

## Spring-Eg-Content-Jpa
- This example stores content in a JPA compatible database which in this case is HSQL.
- No environment variables are need to run this example.
- To change the underlying content database the `dataSource()` method must be changed to return a DataSource handler to your database. See `ClaimTestConfig.java` for the HSQL example.

## Spring-Eg-Content-Mongo
- This example stores content in a MongoDB.
- If no environment variables are specified when running this example, we assume you have a MongoDB running locally without username/password.
- You can change the mongoDB host / username / password with the following ENV variables:
  - `spring_eg_content_mongo_host` -> MongoDB host
  - `spring_eg_content_mongo_port` ->  MongoDB host port
  - `spring_eg_content_mongo_username` -> MongoDB username
  - `spring_eg_content_mongo_password` -> MongoDB password

## Spring-Eg-Content-S3
- This example stores content in a S3 Bucket
- The following ENV variables need to be set when running this example:
 - `AWS_BUCKET` -> AWS S3 bucket that has been previously setup for storing content
 - `AWS_REGION` -> AWS Region in which the bucket above is provisioned.

    > Availability Zones:
    - us-gov-west-1
    - us-east-1
    - us-west-1
    - us-west-2
    - eu-west-1
    - eu-central-1
    - ap-south-1
    - ap-southeast-1
    - ap-southeast-2
    - ap-northeast-1
    - ap-northeast-2
    - sa-east-1
    - cn-north-1
  - `AWS_ACCESS_KEY_ID` -> AWS Key ID that has access to the bucket above
  - `AWS_SECRET_KEY` -> AWS Secret Key that corresponds the ID above

## Spring-Eg-Content-Solr
- This example:
  - by default is used in conjunction with the JPA interface as well as HSQL, this can be changed for your own scenario.
  - indexes your content when storing, later allowing for querying.
- The following ENV variables need to be set:
  - Solr Server with Basic Auth (SSL inclusive):
    - `EXAMPLES_AUTH_URL` -> https/http url of solr server including port.
    - `EXAMPLES_USERNAME` -> Username with access to create new entries and run queries.
    - `EXAMPLES_PASSWORD` -> Password for username above.
  - Insecure Solr Server:
    - `EXAMPLES_SOLR_URL` -> http url of solr server including port.
"
pact-foundation/pact-workshop-jvm-spring,main,101,65,2020-10-12T23:21:31Z,810,4,Example Spring Boot project for the Pact workshop,hacktoberfest,"# Example Spring Boot project for the Pact workshop

This workshop should take about 2 hours, depending on how deep you want to go into each topic.

This workshop is setup with a number of steps that can be run through. Each step is in a branch, so to run through a
step of the workshop just check out the branch for that step (i.e. `git checkout step1`).

## Requirements

* JDK 8+
* Docker for step 11

## Workshop outline:

* [step 1: **Simple Consumer calling Provider**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step1#step-1---simple-consumer-calling-provider)
* [step 2: **Client Tested but integration fails**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step2#step-2---client-tested-but-integration-fails)
* [step 3: **Pact to the rescue**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step3#step-3---pact-to-the-rescue)
* [step 4: **Verify the provider**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step4#step-4---verify-the-provider)
* [step 5: **Back to the client we go**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step5#step-5---back-to-the-client-we-go)
* [step 6: **Consumer updates contract for missing products**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step6#step-6---consumer-updates-contract-for-missing-products)
* [step 7: **Adding the missing states**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step7#step-7---adding-the-missing-states)
* [step 8: **Authorization**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step8#step-8---authorization)
* [step 9: **Implement authorisation on the provider**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step9#step-9---implement-authorisation-on-the-provider)
* [step 10: **Request Filters on the Provider**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step10#step-10---request-filters-on-the-provider)
* [step 11: **Using a Pact Broker**](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step11#step-11---using-a-pact-broker)

_NOTE: Each step is tied to, and must be run within, a git branch, allowing you to progress through each stage incrementally. For example, to move to step 2 run the following: git checkout step2_

## Scenario

There are two components in scope for our workshop.

1. Product Catalog application (Consumer). It provides a console interface to query the Product service for product information.
1. Product Service (Provider). Provides useful things about products, such as listing all products and getting the details of an individual product.

## Step 1 - Simple Consumer calling Provider

We need to first create an HTTP client to make the calls to our provider service:

![Simple Consumer](diagrams/workshop_step1.svg)

The Consumer has implemented the product service client which has the following:

- `GET /products` - Retrieve all products
- `GET /products/{id}` - Retrieve a single product by ID

The diagram below highlights the interaction for retrieving a product with ID 10:

![Sequence Diagram](diagrams/workshop_step1_class-sequence-diagram.svg)

You can see the client interface we created in `consumer/src/main/au/com/dius/pactworkshop/consumer/ProductService.java`:

```java
@Service
public class ProductService {

    private final RestTemplate restTemplate;

    @Autowired
    public ProductService(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    public List<Product> getAllProducts() {
        return restTemplate.exchange(""/products"",
                HttpMethod.GET,
                null,
                new ParameterizedTypeReference<List<Product>>(){}).getBody();
    }

    public Product getProduct(String id) {
        return restTemplate.getForEntity(""/products/{id}"", Product.class, id).getBody();
    }
}
```

We can run the client with `./gradlew consumer:bootRun` - it should fail with the error below, because the Provider is not running.

```console
Caused by: org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8085/products"": Connection refused: connect; nested exception is java.net.ConnectException: Connection refused: connect
```

Move on to [step 2](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step2#step-2---client-tested-but-integration-fails)

## Step 2 - Client Tested but integration fails

Now let's create a basic test for our API client. We're going to check 2 things:

1. That our client code hits the expected endpoint
1. That the response is marshalled into an object that is usable, with the correct ID

You can see the client interface test we created in `consumer/src/test/java/au/com/dius/pactworkshop/consumer/ProductServiceTest.java`:

```java
class ProductServiceTest {

  private WireMockServer wireMockServer;
  private ProductService productService;

  @BeforeEach
  void setUp() {
    wireMockServer = new WireMockServer(options().dynamicPort());

    wireMockServer.start();

    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(wireMockServer.baseUrl())
      .build();

    productService = new ProductService(restTemplate);
  }

  @AfterEach
  void tearDown() {
    wireMockServer.stop();
  }

  @Test
  void getAllProducts() {
    wireMockServer.stubFor(get(urlPathEqualTo(""/products""))
      .willReturn(aResponse()
        .withStatus(200)
        .withHeader(""Content-Type"", ""application/json"")
        .withBody(""["" +
          ""{\""id\"":\""9\"",\""type\"":\""CREDIT_CARD\"",\""name\"":\""GEM Visa\"",\""version\"":\""v2\""},""+
          ""{\""id\"":\""10\"",\""type\"":\""CREDIT_CARD\"",\""name\"":\""28 Degrees\"",\""version\"":\""v1\""}""+
          ""]"")));

    List<Product> expected = Arrays.asList(new Product(""9"", ""CREDIT_CARD"", ""GEM Visa"", ""v2""),
      new Product(""10"", ""CREDIT_CARD"", ""28 Degrees"", ""v1""));

    List<Product> products = productService.getAllProducts();

    assertEquals(expected, products);
  }

  @Test
  void getProductById() {
    wireMockServer.stubFor(get(urlPathEqualTo(""/products/50""))
      .willReturn(aResponse()
        .withStatus(200)
        .withHeader(""Content-Type"", ""application/json"")
        .withBody(""{\""id\"":\""50\"",\""type\"":\""CREDIT_CARD\"",\""name\"":\""28 Degrees\"",\""version\"":\""v1\""}"")));

    Product expected = new Product(""50"", ""CREDIT_CARD"", ""28 Degrees"", ""v1"");

    Product product = productService.getProduct(""50"");

    assertEquals(expected, product);
  }
}
```



![Unit Test With Mocked Response](diagrams/workshop_step2_unit_test.svg)



Let's run this test and see it all pass:

```console
> ./gradlew consumer:test

BUILD SUCCESSFUL in 2s
```

Meanwhile, our provider team has started building out their API in parallel. Let's run our website against our provider (you'll need two terminals to do this):


```console
# Terminal 1
❯ ./gradlew provider:bootRun

...
...
Tomcat started on port(s): 8085 (http) with context path ''
Started ProviderApplication in 1.67 seconds (JVM running for 2.039)
```

```console
# Terminal 2
> ./gradlew consumer:bootRun --console plain

...
...
Started ConsumerApplication in 1.106 seconds (JVM running for 1.62)


Products
--------
1) Gem Visa
2) MyFlexiPay
3) 28 Degrees
Select item to view details: 
```

You should now see 3 different products. Choosing an index number should display detailed product information.

Let's see what happens!

![Failed page](diagrams/workshop_step2_failed_page.png)

Doh! We are getting 404 every time we try to view detailed product information. On closer inspection, the provider only knows about `/product/{id}` and `/products`.

We need to have a conversation about what the endpoint should be, but first...

Move on to [step 3](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step3#step-3---pact-to-the-rescue)

## Step 3 - Pact to the rescue

Unit tests are written and executed in isolation of any other services. When we write tests for code that talk to other services, they are built on trust that the contracts are upheld. There is no way to validate that the consumer and provider can communicate correctly.

> An integration contract test is a test at the boundary of an external service verifying that it meets the contract expected by a consuming service — [Martin Fowler](https://martinfowler.com/bliki/IntegrationContractTest.html)

Adding contract tests via Pact would have highlighted the `/product/{id}` endpoint was incorrect.

Let us add Pact to the project and write a consumer pact test for the `GET /products/{id}` endpoint.

*Provider states* is an important concept of Pact that we need to introduce. These states help define the state that the provider should be in for specific interactions. For the moment, we will initially be testing the following states:

- `product with ID 10 exists`
- `products exist`

The consumer can define the state of an interaction using the `given` property.

Note how similar it looks to our unit test:

In `consumer/src/test/java/au/com/dius/pactworkshop/consumer/ProductConsumerPactTest.java`:

```java
@ExtendWith(PactConsumerTestExt.class)
public class ProductConsumerPactTest {
  
      @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
      RequestResponsePact getAllProducts(PactDslWithProvider builder) {
        return builder.given(""products exist"")
          .uponReceiving(""get all products"")
          .method(""GET"")
          .path(""/products"")
          .willRespondWith()
          .status(200)
          .headers(headers())
          .body(newJsonArrayMinLike(2, array ->
            array.object(object -> {
              object.stringType(""id"", ""09"");
              object.stringType(""type"", ""CREDIT_CARD"");
              object.stringType(""name"", ""Gem Visa"");
            })
          ).build())
          .toPact();
      }
    
      @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
      RequestResponsePact getOneProduct(PactDslWithProvider builder) {
        return builder.given(""product with ID 10 exists"")
          .uponReceiving(""get product with ID 10"")
          .method(""GET"")
          .path(""/products/10"")
          .willRespondWith()
          .status(200)
          .headers(headers())
          .body(newJsonBody(object -> {
            object.stringType(""id"", ""10"");
            object.stringType(""type"", ""CREDIT_CARD"");
            object.stringType(""name"", ""28 Degrees"");
          }).build())
          .toPact();
      }
    
      @Test
      @PactTestFor(pactMethod = ""getAllProducts"")
      void getAllProducts_whenProductsExist(MockServer mockServer) {
        Product product = new Product();
        product.setId(""09"");
        product.setType(""CREDIT_CARD"");
        product.setName(""Gem Visa"");
        List<Product> expected = Arrays.asList(product, product);
    
        RestTemplate restTemplate = new RestTemplateBuilder()
          .rootUri(mockServer.getUrl())
          .build();
        List<Product> products = new ProductService(restTemplate).getAllProducts();
    
        assertEquals(expected, products);
      }
    
      @Test
      @PactTestFor(pactMethod = ""getOneProduct"")
      void getProductById_whenProductWithId10Exists(MockServer mockServer) {
        Product expected = new Product();
        expected.setId(""10"");
        expected.setType(""CREDIT_CARD"");
        expected.setName(""28 Degrees"");
    
        RestTemplate restTemplate = new RestTemplateBuilder()
          .rootUri(mockServer.getUrl())
          .build();
        Product product = new ProductService(restTemplate).getProduct(""10"");
    
        assertEquals(expected, product);
      }
    
      private Map<String, String> headers() {
        Map<String, String> headers = new HashMap<>();
        headers.put(""Content-Type"", ""application/json; charset=utf-8"");
        return headers;
      }
}
```


![Test using Pact](diagrams/workshop_step3_pact.svg)

This test starts a mock server on a random port that acts as our provider service. To get this to work we update the URL in the `Client` that we create, after initialising Pact.

To run only the Pact tests:

```console
> ./gradlew consumer:test --tests '*PactTest'

```

Running this test still passes, but it creates a pact file which we can use to validate our assumptions on the provider side, and have conversation around.

```console
❯ ./gradlew consumer:test --tests '*PactTest'
  
  BUILD SUCCESSFUL in 6s
```

A pact file should have been generated in *consumer/build/pacts/FrontendApplication-ProductService.json*

*NOTE*: even if the API client had been graciously provided for us by our Provider Team, it doesn't mean that we shouldn't write contract tests - because the version of the client we have may not always be in sync with the deployed API - and also because we will write tests on the output appropriate to our specific needs.

Move on to [step 4](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step4#step-4---verify-the-provider)

## Step 4 - Verify the provider

We will need to copy the Pact contract file that was produced from the consumer test into the Provider module. This will help us verify that the provider can meet the requirements as set out in the contract.

Copy the contract located in `consumer/build/pacts/FrontendApplication-Productservice.json` to `provider/src/test/resources/pacts/FrontendApplication-Productservice.json`. Or run the Gradle task
```console
> ./gradlew consumer:copyPacts

BUILD SUCCESSFUL in 1s
```

Now let's make a start on writing Pact tests to validate the consumer contract:

In `provider/src/test/java/au/com/dius/pactworkshop/provider/ProductPactProviderTest.java`:

```java
@Provider(""ProductService"")
@PactFolder(""pacts"")
@ExtendWith(SpringExtension.class)
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
public class ProductPactProviderTest {

    @LocalServerPort
    int port;

    @BeforeEach
    void setUp(PactVerificationContext context) {
        context.setTarget(new HttpTestTarget(""localhost"", port));
    }

    @TestTemplate
    @ExtendWith(PactVerificationInvocationContextProvider.class)
    void verifyPact(PactVerificationContext context) {
        context.verifyInteraction();
    }

    @State(""products exist"")
    void toProductsExistState() {

    }

    @State(""product with ID 10 exists"")
    void toProductWithIdTenExistsState() {

    }
}
```

To run only the verification tests:

```console
> ./gradlew provider:test --tests '*Pact*Test'
```

We now need to validate the pact generated by the consumer is valid, by executing it against the running service provider, which should fail:

```console
❯ ./gradlew provider:test --tests '*Pact*Test'

...
...
au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get product with ID 10 FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:33
2020-10-09 06:21:52.555  INFO 6404 --- [extShutdownHook] o.s.s.concurrent.Thread
2 tests completed, 1 failed

> Task :provider:test FAILED
```

![Pact Verification](diagrams/workshop_step4_pact.svg)

The test has failed, as the expected path `/products/{id}` is returning 404. We incorrectly believed our provider was following a RESTful design, but the authors were too lazy to implement a better routing solution 🤷🏻‍♂️.

The correct endpoint which the consumer should call is `/product/{id}`.

Move on to [step 5](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step5#step-5---back-to-the-client-we-go)

## Step 5 - Back to the client we go

We now need to update the consumer client and tests to hit the correct product path.

First, we need to update the GET route for the client:

In `consumer/src/main/au/com/dius/pactworkshop/consumer/ProductService.java`:

```java
...

public Product getProduct(String id) {
    return restTemplate.getForEntity(""/product/{id}"", Product.class, id).getBody();
}
```

Then we need to update the Pact test `ID 10 exists` to use the correct endpoint in `path`.

In `consumer/src/test/java/au/com/dius/pactworkshop/consumer/ProductConsumerPactTest.java`:

```java
@Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
RequestResponsePact getOneProduct(PactDslWithProvider builder) {
    return builder.given(""product with ID 10 exists"")
            .uponReceiving(""get product with ID 10"")
            .method(""GET"")
            .path(""/product/10"")
            .willRespondWith()
            .status(200)
            .headers(headers())
            .body(newJsonBody(object -> {
                object.stringType(""id"", ""10"");
                object.stringType(""type"", ""CREDIT_CARD"");
                object.stringType(""name"", ""28 Degrees"");
            }).build())
            .toPact();
}
...
```

![Pact Verification](diagrams/workshop_step5_pact.svg)

Let's run and generate an updated pact file on the client:

```console
❯ ./gradlew consumer:test --tests *PactTest
  
  BUILD SUCCESSFUL in 7s
```



Now we run the provider tests again with the updated contract

Copy the updated contract located in `consumer/build/pacts/FrontendApplication-ProductService.json` to `provider/src/test/resources/pacts/FrontendApplication-Productservice.json` by running the command:
```console
> ./gradlew consumer:copyPacts
  
  BUILD SUCCESSFUL in 1s
```

Run the command:

```console
❯ ./gradlew provider:test --tests '*Pact*Test'

...
...

BUILD SUCCESSFUL in 10s
```

Yay - green ✅!

Move on to [step 6](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step6#step-6---consumer-updates-contract-for-missing-products)

## Step 6 - Consumer updates contract for missing products

We're now going to add 2 more scenarios for the contract

- What happens when we make a call for a product that doesn't exist? We assume we'll get a `404`.

- What happens when we make a call for getting all products but none exist at the moment? We assume a `200` with an empty array.

Let's write a test for these scenarios, and then generate an updated pact file.

In `consumer/src/test/java/au/com/dius/pactworkshop/consumer/ProductConsumerPactTest.java`:

```java
    @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
    RequestResponsePact noProductsExist(PactDslWithProvider builder) {
        return builder.given(""no products exist"")
                .uponReceiving(""get all products"")
                .method(""GET"")
                .path(""/products"")
                .willRespondWith()
                .status(200)
                .headers(headers())
                .body(""[]"")
                .toPact();
    }

    @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
    RequestResponsePact productDoesNotExist(PactDslWithProvider builder) {
        return builder.given(""product with ID 11 does not exist"")
                .uponReceiving(""get product with ID 11"")
                .method(""GET"")
                .path(""/product/11"")
                .willRespondWith()
                .status(404)
                .toPact();
    }

    @Test
    @PactTestFor(pactMethod = ""noProductsExist"")
    void getAllProducts_whenNoProductsExist(MockServer mockServer) {
        RestTemplate restTemplate = new RestTemplateBuilder()
                .rootUri(mockServer.getUrl())
                .build();
        List<Product> products = new ProductService(restTemplate).getAllProducts();

        assertEquals(Collections.emptyList(), products);
    }

    @Test
    @PactTestFor(pactMethod = ""productDoesNotExist"")
    void getProductById_whenProductWithId11DoesNotExist(MockServer mockServer) {
        RestTemplate restTemplate = new RestTemplateBuilder()
                .rootUri(mockServer.getUrl())
                .build();

        HttpClientErrorException e = assertThrows(HttpClientErrorException.class,
                () -> new ProductService(restTemplate).getProduct(""11""));
        assertEquals(404, e.getStatusCode().value());
    }
```

Notice that our new tests look almost identical to our previous tests, and only differ on the expectations of the _response_ - the HTTP request expectations are exactly the same.

```console
❯ ./gradlew consumer:test --tests '*PactTest'
  
  BUILD SUCCESSFUL in 1s
```

What does our provider have to say about this new test. Again, copy the updated pact file into the provider's pact directory:

```console
> ./gradlew consumer:copyPacts
  
  BUILD SUCCESSFUL in 1s
```

and run the command:

```console
❯ ./gradlew provider:test --tests '*Pact*Test'

...
...

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get all products FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:33

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get product with ID 11 FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:33
2020-10-09 08:27:31.030  INFO 18048 --- [extShutdownHook] o.s.s.concurrent.Threa
4 tests completed, 2 failed

> Task :provider:test FAILED

FAILURE: Build failed with an exception.

```

We expected this failure, because the product we are requesting does in fact exist! What we want to test for, is what happens if there is a different *state* on the Provider. This is what is referred to as ""Provider states"", and how Pact gets around test ordering and related issues.

We could resolve this by updating our consumer test to use a known non-existent product, but it's worth understanding how Provider states work more generally.

Move on to [step 7](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step7#step-7---adding-the-missing-states)

## Step 7 - Adding the missing states

Our code already deals with missing users and sends a `404` response, however our test data fixture always has product ID 10 and 11 in our database.

In this step, we will add state handlers to our provider Pact verifications, which will update the state of our data store depending on which states the consumers require.

States are invoked prior to the actual test function being invoked. You can see the full [lifecycle here](https://github.com/pact-foundation/pact-go#lifecycle-of-a-provider-verification).

We're going to add handlers for all our states:

- products exist
- no products exist
- product with ID 10 exists
- product with ID 11 does not exist

Let's open up our provider Pact verifications in `provider/src/test/java/au/com/dius/pactworkshop/provider/ProductPactProviderTest.java`:

```java
    @State(""products exist"")
    void toProductsExistState() {
      when(productRepository.fetchAll()).thenReturn(
          Arrays.asList(new Product(""09"", ""CREDIT_CARD"", ""Gem Visa"", ""v1""),
              new Product(""10"", ""CREDIT_CARD"", ""28 Degrees"", ""v1"")));
    }

    @State({
            ""no products exist"",
            ""product with ID 11 does not exist""
    })
    void toNoProductsExistState() {
        when(productRepository.fetchAll()).thenReturn(Collections.emptyList());
    }

    @State(""product with ID 10 exists"")
    void toProductWithIdTenExistsState() {
        when(productRepository.getById(""10"")).thenReturn(Optional.of(new Product(""10"", ""CREDIT_CARD"", ""28 Degrees"", ""v1"")));
    }
```

Let's see how we go now:

```console
❯ ./gradlew provider:test --tests *Pact*Test

BUILD SUCCESSFUL in 11s
```

_NOTE_: The states are not necessarily a 1 to 1 mapping with the consumer contract tests. You can reuse states amongst different tests. In this scenario we could have used `no products exist` for both tests which would have equally been valid.

Move on to [step 8](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step8#step-8---authorization)

## Step 8 - Authorization

It turns out that not everyone should be able to use the API. After a discussion with the team, it was decided that a time-bound bearer token would suffice. The token must be in `yyyy-MM-ddTHHmm` format and within 1 hour of the current time.

In the case a valid bearer token is not provided, we expect a `401`. Let's update the consumer to pass the bearer token, and capture this new `401` scenario.

In `consumer/src/main/au/com/dius/pactworkshop/consumer/ProductService.java`:

```java
@Service
public class ProductService {

    private final RestTemplate restTemplate;

    @Autowired
    public ProductService(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    public List<Product> getAllProducts() {
        return restTemplate.exchange(""/products"",
                HttpMethod.GET,
                getRequestEntity(),
                new ParameterizedTypeReference<List<Product>>(){}).getBody();
    }

    public Product getProduct(String id) {
        return restTemplate.exchange(""/product/{id}"",
                HttpMethod.GET,
                getRequestEntity(),
                Product.class, id).getBody();
    }

    private HttpEntity<String> getRequestEntity() {
        HttpHeaders headers = new HttpHeaders();
        headers.add(HttpHeaders.AUTHORIZATION, generateAuthToken());
        return new HttpEntity<>(headers);
    }

    private String generateAuthToken() {
        return ""Bearer "" +  new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm"").format(new Date());
    }
}
```

In `consumer/src/test/java/au/com/dius/pactworkshop/consumer/ProductConsumerPactTest.java`:

```java
@ExtendWith(PactConsumerTestExt.class)
public class ProductConsumerPactTest {

  @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
  RequestResponsePact getAllProducts(PactDslWithProvider builder) {
    return builder.given(""products exist"")
      .uponReceiving(""get all products"")
      .method(""GET"")
      .path(""/products"")
      .matchHeader(""Authorization"", ""Bearer (19|20)\\d\\d-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T([01][1-9]|2[0123]):[0-5][0-9]"")
      .willRespondWith()
      .status(200)
      .headers(headers())
      .body(newJsonArrayMinLike(2, array ->
        array.object(object -> {
          object.stringType(""id"", ""09"");
          object.stringType(""type"", ""CREDIT_CARD"");
          object.stringType(""name"", ""Gem Visa"");
        })
      ).build())
      .toPact();
  }

  @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
  RequestResponsePact noProductsExist(PactDslWithProvider builder) {
    return builder.given(""no products exist"")
      .uponReceiving(""get all products"")
      .method(""GET"")
      .path(""/products"")
      .matchHeader(""Authorization"", ""Bearer (19|20)\\d\\d-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T([01][1-9]|2[0123]):[0-5][0-9]"")
      .willRespondWith()
      .status(200)
      .headers(headers())
      .body(""[]"")
      .toPact();
  }

  @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
  RequestResponsePact allProductsNoAuthToken(PactDslWithProvider builder) {
    return builder.given(""products exist"")
      .uponReceiving(""get all products with no auth token"")
      .method(""GET"")
      .path(""/products"")
      .willRespondWith()
      .status(401)
      .toPact();
  }

  @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
  RequestResponsePact getOneProduct(PactDslWithProvider builder) {
    return builder.given(""product with ID 10 exists"")
      .uponReceiving(""get product with ID 10"")
      .method(""GET"")
      .path(""/product/10"")
      .matchHeader(""Authorization"", ""Bearer (19|20)\\d\\d-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T([01][1-9]|2[0123]):[0-5][0-9]"")
      .willRespondWith()
      .status(200)
      .headers(headers())
      .body(newJsonBody(object -> {
        object.stringType(""id"", ""10"");
        object.stringType(""type"", ""CREDIT_CARD"");
        object.stringType(""name"", ""28 Degrees"");
      }).build())
      .toPact();
  }

  @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
  RequestResponsePact productDoesNotExist(PactDslWithProvider builder) {
    return builder.given(""product with ID 11 does not exist"")
      .uponReceiving(""get product with ID 11"")
      .method(""GET"")
      .path(""/product/11"")
      .matchHeader(""Authorization"", ""Bearer (19|20)\\d\\d-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T([01][1-9]|2[0123]):[0-5][0-9]"")
      .willRespondWith()
      .status(404)
      .toPact();
  }

  @Pact(consumer = ""FrontendApplication"", provider = ""ProductService"")
  RequestResponsePact singleProductnoAuthToken(PactDslWithProvider builder) {
    return builder.given(""product with ID 10 exists"")
      .uponReceiving(""get product by ID 10 with no auth token"")
      .method(""GET"")
      .path(""/product/10"")
      .willRespondWith()
      .status(401)
      .toPact();
  }

  @Test
  @PactTestFor(pactMethod = ""getAllProducts"")
  void getAllProducts_whenProductsExist(MockServer mockServer) {
    Product product = new Product();
    product.setId(""09"");
    product.setType(""CREDIT_CARD"");
    product.setName(""Gem Visa"");
    List<Product> expected = Arrays.asList(product, product);

    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(mockServer.getUrl())
      .build();
    List<Product> products = new ProductService(restTemplate).getAllProducts();

    assertEquals(expected, products);
  }

  @Test
  @PactTestFor(pactMethod = ""noProductsExist"")
  void getAllProducts_whenNoProductsExist(MockServer mockServer) {
    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(mockServer.getUrl())
      .build();
    List<Product> products = new ProductService(restTemplate).getAllProducts();

    assertEquals(Collections.emptyList(), products);
  }

  @Test
  @PactTestFor(pactMethod = ""allProductsNoAuthToken"")
  void getAllProducts_whenNoAuth(MockServer mockServer) {
    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(mockServer.getUrl())
      .build();

    HttpClientErrorException e = assertThrows(HttpClientErrorException.class,
      () -> new ProductService(restTemplate).getAllProducts());
    assertEquals(401, e.getStatusCode().value());
  }

  @Test
  @PactTestFor(pactMethod = ""getOneProduct"")
  void getProductById_whenProductWithId10Exists(MockServer mockServer) {
    Product expected = new Product();
    expected.setId(""10"");
    expected.setType(""CREDIT_CARD"");
    expected.setName(""28 Degrees"");

    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(mockServer.getUrl())
      .build();
    Product product = new ProductService(restTemplate).getProduct(""10"");

    assertEquals(expected, product);
  }

  @Test
  @PactTestFor(pactMethod = ""productDoesNotExist"")
  void getProductById_whenProductWithId11DoesNotExist(MockServer mockServer) {
    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(mockServer.getUrl())
      .build();

    HttpClientErrorException e = assertThrows(HttpClientErrorException.class,
      () -> new ProductService(restTemplate).getProduct(""11""));
    assertEquals(404, e.getStatusCode().value());
  }

  @Test
  @PactTestFor(pactMethod = ""singleProductnoAuthToken"")
  void getProductById_whenNoAuth(MockServer mockServer) {
    RestTemplate restTemplate = new RestTemplateBuilder()
      .rootUri(mockServer.getUrl())
      .build();

    HttpClientErrorException e = assertThrows(HttpClientErrorException.class,
      () -> new ProductService(restTemplate).getProduct(""10""));
    assertEquals(401, e.getStatusCode().value());
  }

  private Map<String, String> headers() {
    Map<String, String> headers = new HashMap<>();
    headers.put(""Content-Type"", ""application/json; charset=utf-8"");
    return headers;
  }
}
```

Generate a new Pact file:

```console
❯ ./gradlew consumer:test --tests *PactTest

BUILD SUCCESSFUL in 9s
```

We should now have two new interactions in our pact file.

Let's test the provider. Copy the updated pact file into the provider's pact directory and run the command:

```console
> ./gradlew consumer:copyPacts
  
  BUILD SUCCESSFUL in 1s

❯  ./gradlew provider:test --tests *Pact*Test

...
...

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get product by ID 10 with no auth token FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:43

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get all products with no auth token FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:43
2020-10-09 15:07:37.909  INFO 17464 --- [extShutdownHook] o.s.s.concurrent.Threa
6 tests completed, 2 failed

> Task :provider:test FAILED

FAILURE: Build failed with an exception.
```

Now with the most recently added interactions where we are expecting a response of 401 when no authorization header is sent, we are getting 200...

Move on to [step 9](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step9#step-9---implement-authorisation-on-the-provider)

## Step 9 - Implement authorisation on the provider

We will add a filter to check the Authorization header and deny the request with `401` if the token is older than 1 hour.

In `provider/src/main/java/au/com/dius/pactworkshop/provider/AuthFilter.java`

```java
@Component
public class AuthFilter implements Filter {

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        String authHeader = ((HttpServletRequest) request).getHeader(""Authorization"");
        if (authHeader == null) {
            ((HttpServletResponse) response).sendError(401, ""Unauthorized"");
            return;
        }
        authHeader = authHeader.replaceAll(""Bearer "", """");
        if (!isValidAuthTimestamp(authHeader)) {
            ((HttpServletResponse) response).sendError(401, ""Unauthorized"");
            return;
        }

        chain.doFilter(request, response);
    }

    private boolean isValidAuthTimestamp(String timestamp) {
        SimpleDateFormat formatter = new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm"");
        try {
            Date headerDate = formatter.parse(timestamp);
            long diff = (System.currentTimeMillis() - headerDate.getTime()) / 1000;
            return diff >= 0 && diff <= 3600;
        } catch (ParseException e) {
            e.printStackTrace();
        }
            return false;
    }
}
```

This means that a client must present an HTTP `Authorization` header that looks as follows:

```
Authorization: Bearer 2006-01-02T15:04
```

Let's test this out:

```console
❯ ./gradlew provider:test --tests *Pact*Test

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get all products FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:43

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get product with ID 10 FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:43

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get product with ID 11 FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:43

au.com.dius.pactworkshop.provider.ProductPactProviderTest > FrontendApplication - get all products FAILED
    java.lang.AssertionError at ProductPactProviderTest.java:43
2020-10-12 10:28:12.744  INFO 17984 --- [extShutdownHook] o.s.s.concurrent.Threa
6 tests completed, 4 failed

> Task :provider:test FAILED

FAILURE: Build failed with an exception.
```

Oh, dear. _More_ tests are failing. Can you understand why?

Move on to [step 10](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step10#step-10---request-filters-on-the-provider)

## Step 10 - Request Filters on the Provider

Because our pact file has static data in it, our bearer token is now out of date, so when Pact verification passes it to the Provider we get a `401`. There are multiple ways to resolve this - mocking or stubbing out the authentication component is a common one. In our use case, we are going to use a process referred to as _Request Filtering_, using a `RequestFilter`.

_NOTE_: This is an advanced concept and should be used carefully, as it has the potential to invalidate a contract by bypassing its constraints. See https://docs.pact.io/implementation_guides/jvm/provider/junit5/#modifying-the-requests-before-they-are-sent for more details on this.

The approach we are going to take to inject the header is as follows:

1. If we receive any Authorization header, we override the incoming request with a valid (in time) Authorization header, and continue with whatever call was being made
1. If we don't receive an Authorization header, we do nothing

_NOTE_: We are not considering the `403` scenario in this example.

In `provider/src/test/java/au/com/dius/pactworkshop/provider/ProductPactProviderTest.java`:

```java
    @TestTemplate
    @ExtendWith(PactVerificationInvocationContextProvider.class)
    void verifyPact(PactVerificationContext context, HttpRequest request) {
        replaceAuthHeader(request);
        context.verifyInteraction();
    }

    private void replaceAuthHeader(HttpRequest request) {
        if (request.containsHeader(""Authorization"")) {
            String header = ""Bearer "" + new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm"").format(new Date());
            request.removeHeaders(""Authorization"");
            request.addHeader(""Authorization"", header);
        }
    }
```

We can now run the Provider tests

```console
❯ ./gradlew provider:test --tests *Pact*Test

BUILD SUCCESSFUL in 1s
```

Move on to [step 11](https://github.com/pact-foundation/pact-workshop-jvm-spring/tree/step11#step-11---using-a-pact-broker)

## Step 11 - Using a Pact Broker

![Broker collaboration Workflow](diagrams/workshop_step10_broker.svg)

We've been publishing our pacts from the consumer project by essentially sharing the file system with the provider. But this is not very manageable when you have multiple teams contributing to the code base, and pushing to CI. We can use a [Pact Broker](https://pactflow.io) to do this instead.

Using a broker simplifies the management of pacts and adds a number of useful features, including some safety enhancements for continuous delivery which we'll see shortly.

In this workshop we will be using the open source Pact broker.

### Running the Pact Broker with docker-compose

In the root directory, run:

```console
docker-compose up
```

### Publish contracts from consumer

First, in the consumer project we need to tell Pact about our broker.

In `consumer/build.gradle`:

```groovy
...
...

def getGitHash = { ->
	def stdout = new ByteArrayOutputStream()
	exec {
		commandLine 'git', 'rev-parse', '--short', 'HEAD'
		standardOutput = stdout
	}
	return stdout.toString().trim()
}

def getGitBranch = { ->
	def stdout = new ByteArrayOutputStream()
	exec {
		commandLine 'git', 'rev-parse', '--abbrev-ref', 'HEAD'
		standardOutput = stdout
	}
	return stdout.toString().trim()
}

static def getOrDefault(env, defaultVal) {
	def val = System.getenv(env)
	if (val == null || val.isEmpty()) {
		val = defaultVal
	}
	return val
}

pact {
	publish {
		pactDirectory = 'consumer/build/pacts'
		pactBrokerUrl = 'http://localhost:8000/'
		pactBrokerUsername = getOrDefault('PACT_BROKER_USERNAME', 'pact_workshop')
		pactBrokerPassword = getOrDefault('PACT_BROKER_PASSWORD', 'pact_workshop')
		consumerBranch = getGitBranch()
		consumerVersion = getGitHash()
	}
}
```

Now run

```console
❯ ./gradlew consumer:test --tests '*PactTest*' pactPublish
  
  > Task :consumer:pactPublish
  Publishing 'FrontendApplication-ProductService.json'
  OK
  
  BUILD SUCCESSFUL in 11s

```
*NOTE*: For real projects, you should only publish pacts from CI builds

Have a browse around the broker on http://localhost:8000 (with username/password: `pact_workshop`/`pact_workshop`) and see your newly published contract!

### Verify contracts on Provider

All we need to do for the provider is update where it finds its pacts, from local URLs, to one from a broker.

In `provider/src/test/java/au/com/dius/pactworkshop/provider/ProductPactProviderTest.java`:

```java
//replace
@PactFolder(""pacts"")

// with
@PactBroker(
        host = ""localhost"",
        port = ""8000"",
        authentication = @PactBrokerAuth(username = ""pact_workshop"", password = ""pact_workshop"")
)
```
In `provider/build.gradle`:

```groovy
...
...


def getGitHash = { ->
    def stdout = new ByteArrayOutputStream()
    exec {
        commandLine 'git', 'rev-parse', '--short', 'HEAD'
        standardOutput = stdout
    }
    return stdout.toString().trim()
}

def getGitBranch = { ->
    def stdout = new ByteArrayOutputStream()
    exec {
        commandLine 'git', 'rev-parse', '--abbrev-ref', 'HEAD'
        standardOutput = stdout
    }
    return stdout.toString().trim()
}

test {
    useJUnitPlatform()

    systemProperty 'pact.provider.branch', getGitBranch()
    if (System.getProperty('pactPublishResults') == 'true') {
        systemProperty 'pact.provider.version', getGitHash()
        systemProperty 'pact.verifier.publishResults', 'true'
    }
}
```

Let's run the provider verification one last time after this change:

```console
❯ ./gradlew -DpactPublishResults=true provider:test --tests *Pact*Test

BUILD SUCCESSFUL in 16s
```
*NOTE*: For real projects, you should only publish verification results from CI builds

As part of this process, the results of the verification - the outcome (boolean) and the detailed information about the failures at the interaction level - are published to the Broker also.

This is one of the Broker's more powerful features. Referred to as [Verifications](https://docs.pact.io/pact_broker/advanced_topics/provider_verification_results), it allows providers to report back the status of a verification to the broker. You'll get a quick view of the status of each consumer and provider on a nice dashboard. But, it is much more important than this!

### Can I deploy?

With just a simple use of the `pact-broker` [can-i-deploy tool](https://docs.pact.io/pact_broker/advanced_topics/provider_verification_results) - the Broker will determine if a consumer or provider is safe to release to the specified environment.

You can run the `pact-broker can-i-deploy` checks as follows:

```console
❯ docker run --rm --network host \
  	-e PACT_BROKER_BASE_URL=http://localhost:8000 \
  	-e PACT_BROKER_USERNAME=pact_workshop \
  	-e PACT_BROKER_PASSWORD=pact_workshop \
  	pactfoundation/pact-cli:latest \
  	broker can-i-deploy \
  	--pacticipant FrontendApplication \
  	--latest


Computer says yes \o/

CONSUMER            | C.VERSION | PROVIDER       | P.VERSION | SUCCESS?
--------------------|-----------|----------------|-----------|---------
FrontendApplication | 2955ca5   | ProductService | 2955ca5   | true

All required verification results are published and successful


----------------------------

❯ docker run --rm --network host \
  	-e PACT_BROKER_BASE_URL=http://localhost:8000 \
  	-e PACT_BROKER_USERNAME=pact_workshop \
  	-e PACT_BROKER_PASSWORD=pact_workshop \
  	pactfoundation/pact-cli:latest \
  	broker can-i-deploy \
  	--pacticipant ProductService \
  	--latest

Computer says yes \o/

CONSUMER            | C.VERSION | PROVIDER       | P.VERSION | SUCCESS?
--------------------|-----------|----------------|-----------|---------
FrontendApplication | 2955ca5   | ProductService | 2955ca5   | true

All required verification results are published and successful
```



That's it - you're now a Pact pro. Go build 🔨
"
mzgreen/HideOnScrollExample,master,620,176,2015-02-09T17:06:11Z,252,5,This is an example on how to show/hide views when scrolling a list.,,"HideOnScrollExample
=============

This example shows how to show/hide views (i.e. Toolbar or FAB) when a list is scrolled up/down.

There is a blog post explaining the code: 

[part 1 - outdated](http://mzgreen.github.io/2015/02/15/How-to-hideshow-Toolbar-when-list-is-scroling%28part1%29/)

[part 2 - outdated](http://mzgreen.github.io/2015/02/28/How-to-hideshow-Toolbar-when-list-is-scrolling%28part2%29/)

[part 3](https://mzgreen.github.io/2015/06/23/How-to-hideshow-Toolbar-when-list-is-scrolling%28part3%29/)

"
rakeshcusat/Code4Reference,master,205,1215,2011-10-11T06:04:48Z,25775,2,This repo has code which  can be referred as example code. These code have been written for learning purpose.,,
fhopf/akka-crawler-example,master,120,58,2012-08-23T04:51:29Z,204,0,Some example code of using Akka from Java,,"# Simple Producer Consumer example for Akka in Java

This repository contains 3 examples of a simple web crawler:
* A sequential example
* An example where the logic is split in 3 Actors
* An example where the retrieval of the pages is handled by multiple Actors in parallel.
* An example where retrieval fails and the application hangs
* A supervised example where failing messages are resend

To start the sequential execution run gradle runSequential

To start the simple actor execution run gradle runActors

To start the parallel page fetching run gradle runParallelActors

To start the failing or supervised examples run gradle runFA or gradle runSA

The code is only meant as an example on how to implement a producer consumer example in Akka. More information: 

* http://blog.florian-hopf.de/2012/08/getting-rid-of-synchronized-using-akka.html
* http://blog.florian-hopf.de/2013/10/cope-with-failure-actor-supervision-in.html

*Please don't use the crawler as it is on sites where you didn't contact the site owner*
"
DNBbank/getting-started,master,36,27,2018-08-29T14:16:23Z,683,15,Code examples to get your first working request to DNB APIs,,"# Getting started examples for DNB Open Banking

In this repo you will find code sorted by languages to get you started with DNB's
Open Banking APIs. The aim of this repo is to provide code that can just be used once
the developer's credentials are setup in each file. You will find a readme file in
each subfolder that will add complementary information about the language-specific code.

## tldr;

1. Register an application at [developer.dnb.no][].
2. Configure credentials in `.env` file for running code examples. If you want
   to run postman please follow the [postman readme][].
3. Run one of the examples and check out the code to see what is happening. Make sure that you have attached all API's at [developer.dnb.no][] for the examples to run correctly.

### Getting API key

In order to call the api, you will need API key. It
can be obtained from [developer.dnb.no][]. Register and login to create an example
app and you will get the credentials needed. Each of the examples has documentation
on how to configure it with the credentials.

_Never store your API key available publicly!_

### Configuring the credentials

If you put the credentials in a `.env` file in the root directory it will work
for all the examples except postman. It is also possible to put the `.env` file
in the directory of the example you want to run. See [.env.example][] for a template
for the `.env` file.

### Running the examples

Each example contains a readme with documentation on how to run them. There is also
script that is helpful for running the examples:

```shell
./run <example>  # e.g. ./run nodejs
```

[developer.dnb.no]: https://developer.dnb.no
[postman readme]: ./postman/README.md

All the examples are licensed under MIT license.
"
giltene/GilExamples,master,39,6,2013-07-21T03:13:47Z,576,10,,,
trishagee/mongodb-getting-started,master,45,33,2014-05-06T07:36:29Z,336,1,"Some examples of how to use the MongoDB Java driver, via unit tests.",,"Getting started with MongoDB and Java
=======================


Step by step examples (via unit tests) of how to do simple operations with the 2.12 version of the MongoDB Java driver.  Use this code to play along with the Getting Started guides:

[Getting Started with MongoDB and Java: Part I](http://blog.mongodb.org/post/94065240033/getting-started-with-mongodb-and-java-part-i)  
[Getting Started with MongoDB and Java: Part II](http://blog.mongodb.org/post/94724924068/getting-started-with-mongodb-and-java-part-ii)
"
nats-io/java-nats-examples,main,29,8,2017-06-19T15:21:35Z,655,2,Repo for java-nats-examples,,"![NATS](images/large-logo.png)

# NATS - Java Examples

A [Java](http://java.com) examples for the [NATS messaging system](https://nats.io).

[![License Apache 2](https://img.shields.io/badge/License-Apache2-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)
[![Build Badge](https://github.com/nats-io/java-nats-examples/actions/workflows/build.yml/badge.svg)](https://github.com/nats-io/java-nats-examples/actions/workflows/build.yml)


## Introduction

These Java examples of using the NATS Java client [nats.java project](https://github.com/nats-io/nats.java)

In addition to this repository, there are also more examples in the [examples directory](https://github.com/nats-io/nats.java/tree/main/src/examples) of the NATS Java client project.

There is also [NATS by Example](https://natsbyexample.com) - An evolving collection of runnable, cross-client reference examples for NATS.
The [nats-by-example](nats-by-example/README.md) directory contains the same examples. 

### Starters

The starters projects are provided to give you a jump start to adding the NATS Java client to your project.

* starter-maven [pom.xml](starter-maven/pom.xml) for maven users
* starter-gradle-groovy [build.gradle](starter-gradle-groovy/build.gradle) for gradle users who like the Groovy DSL
* starter-gradle-kotlin [build.gradle.kts](starter-gradle-kotlin/build.gradle.kts) for gradle users who like the Kotlin DSL

As a side note for Kotlin users, there is a small example in the [kotlin-nats-examples](https://github.com/nats-io/kotlin-nats-examples) project.

### Hello World

The [Hello World](hello-world/README.md) examples does things like create streams, publish and subscribe.

### Core Request Reply
The [Core Request Reply](core-request-reply-patterns/README.md)
is an example demonstrating that using core nats, there are multiple ways to do request reply.

### JS Multi Tool

The [JS Multi Tool](js-multi-tool/README.md) is a tool to assist exercising and benchmarking of the NATS Java client in your own environment.

### Example Dev Cluster Configs

The files in the [Example Dev Cluster Configs](example-dev-cluster-configs/README.md) directory are templates for building a simple dev cluster.

### OCSP
The [OCSP](ocsp/README.md) project has instructions and examples for building a OCSP aware SSL Context.

### SSL Context Factory 
The [SSL Context Factory](ssl-context-factory/README.md) example demonstrates how to implement the SSLContextFactory,
an alternative way to provide an SSL Context to the Connection Options.

### Auth Callout

The [Auth Callout](auth-callout/README.md) example demonstrates a basic Auth Callout handler

### Recreate Consumer
The [Recreate Consumer](recreate-consumer/README.md) example demonstrates creating a durable consumer that will start where another one left off.

### Robust Push Subscription
The [Robust Push Subscription](robust-push-subscription/README.md) is an application with more robust error handler including recreating the consumer if heartbeat alarm occurs.

### Encoding 

The [Encoding](encoding/README.md) project has examples that encoded/decode message payload.

### Chain Of Command

The [Chain Of Command](chain-of-command/README.md) example shows subscribing with wildcard subjects to form a chain of command.
Both ""publish style"" and ""request style"" workflow are demonstrated. 

The ""publish style"" does not know if messages were received. 
The ""request style"" knows if the request was received, so it could handle the case when it is not.

### Object Store / File Transfer

The [Manual File Transfer](file-transfer-manual/README.md) project was a proof of concept project was done
as part of the design of Object Store. 

The [File Transfer Object Store](file-transfer-object-store/README.md) project demonstrates 
transferring a file using the completed Object Store API.

### Error and Heartbeat Experiments

The [Error and Heartbeat Experiments](error-and-heartbeat-experiments/README.md) project
are experiments to demonstrate how heartbeats and error listening works.

### Js Over Core
The [Js Over Core](js-over-core/README.md) uses core nats to publish (with Publish Acks!) and subscribe.

### Server Pool
The [Server Pool](server-pool/README.md) is an example how the developer can provide the connection/reconnection info themselves / dynamically.

### Multi Subject Worker
The [Multi Subject Worker](multi-subject-worker/README.md) is an example that processes multiple subjects.

### Original Functional Examples

The [Original Functional Examples](functional-examples/README.md) where the original examples
for the JNATS client and demonstrate one feature at a time.

## License

Unless otherwise noted, the NATS source files are distributed
under the Apache Version 2.0 license found in the LICENSE file.
"
bezkoder/spring-boot-security-postgresql,master,154,67,2020-11-29T09:57:27Z,152,1,"Spring Boot, Spring Security, PostgreSQL: JWT Authentication & Authorization example",authentication authorization jwt-authentication postgresql spring-boot spring-data-jpa spring-security,"# Spring Boot, Spring Security, PostgreSQL: JWT Authentication & Authorization example

## User Registration, User Login and Authorization process.
The diagram shows flow of how we implement User Registration, User Login and Authorization process.

![spring-boot-spring-security-postgresql-jwt-authentication-flow](spring-boot-spring-security-postgresql-jwt-authentication-flow.png)

## Spring Boot Server Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-spring-security-postgresql-jwt-authentication-architecture](spring-boot-spring-security-postgresql-jwt-authentication-architecture.png)

## Configure Spring Datasource, JPA, App properties
Open `src/main/resources/application.properties`

```
spring.datasource.url= jdbc:postgresql://localhost:5432/testdb
spring.datasource.username= postgres
spring.datasource.password= 123

spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation= true
spring.jpa.properties.hibernate.dialect= org.hibernate.dialect.PostgreSQLDialect

# Hibernate ddl auto (create, create-drop, validate, update)
spring.jpa.hibernate.ddl-auto= update

# App Properties
bezkoder.app.jwtSecret= ======================BezKoder=Spring===========================
bezkoder.app.jwtExpirationMs= 86400000
```

## Run Spring Boot application
```
mvn spring-boot:run
```

## Run following SQL insert statements
```
INSERT INTO roles(name) VALUES('ROLE_USER');
INSERT INTO roles(name) VALUES('ROLE_MODERATOR');
INSERT INTO roles(name) VALUES('ROLE_ADMIN');
```

For more detail, please visit:
> [Spring Boot, Spring Security, PostgreSQL: JWT Authentication & Authorization example](https://bezkoder.com/spring-boot-security-postgresql-jwt-authentication/)

> [For MySQL](https://bezkoder.com/spring-boot-jwt-authentication/)

> [For MongoDB](https://bezkoder.com/spring-boot-jwt-auth-mongodb/)

## Refresh Token

![spring-boot-refresh-token-jwt-example-flow](spring-boot-refresh-token-jwt-example-flow.png)

For instruction: [Spring Boot Refresh Token with JWT example](https://bezkoder.com/spring-boot-refresh-token-jwt/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Rest Controller Unit Test with @WebMvcTest](https://www.bezkoder.com/spring-boot-webmvctest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Associations:
> [Spring Boot One To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-one-to-many/)

> [Spring Boot Many To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA One To One example with Spring Boot](https://www.bezkoder.com/jpa-one-to-one/)

## Fullstack Authentication

> [Spring Boot + Vue.js JWT Authentication](https://bezkoder.com/spring-boot-vue-js-authentication-jwt-spring-security/)

> [Spring Boot + Angular 8 JWT Authentication](https://bezkoder.com/angular-spring-boot-jwt-auth/)

> [Spring Boot + Angular 10 JWT Authentication](https://bezkoder.com/angular-10-spring-boot-jwt-auth/)

> [Spring Boot + Angular 11 JWT Authentication](https://bezkoder.com/angular-11-spring-boot-jwt-auth/)

> [Spring Boot + Angular 12 JWT Authentication](https://www.bezkoder.com/angular-12-spring-boot-jwt-auth/)

> [Spring Boot + Angular 13 JWT Authentication](https://www.bezkoder.com/angular-13-spring-boot-jwt-auth/)

> [Spring Boot + Angular 14 JWT Authentication](https://www.bezkoder.com/angular-14-spring-boot-jwt-auth/)

> [Spring Boot + Angular 15 JWT Authentication](https://www.bezkoder.com/angular-15-spring-boot-jwt-auth/)

> [Spring Boot + Angular 16 JWT Authentication](https://www.bezkoder.com/angular-16-spring-boot-jwt-auth/)

> [Spring Boot + Angular 17 JWT Authentication](https://www.bezkoder.com/angular-17-spring-boot-jwt-auth/)

> [Spring Boot + React JWT Authentication](https://bezkoder.com/spring-boot-react-jwt-auth/)

## Fullstack CRUD App

> [Vue.js + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-vue-js-postgresql/)

> [Angular 8 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-spring-boot-postgresql/)

> [Angular 10 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-10-spring-boot-postgresql/)

> [Angular 11 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-11-spring-boot-postgresql/)

> [Angular 12 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-12-spring-boot-postgresql/)

> [Angular 13 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-13-postgresql/)

> [Angular 14 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-14-postgresql/)

> [Angular 15 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-15-postgresql/)

> [Angular 16 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-16-postgresql/)

> [Angular 17 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-17-postgresql/)

> [React + Spring Boot + PostgreSQL example](https://bezkoder.com/spring-boot-react-postgresql/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React.js with Spring Boot Rest API](https://bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue.js with Spring Boot Rest API](https://bezkoder.com/integrate-vue-spring-boot/)
"
fpj/zookeeper-book-example,master,398,251,2013-09-17T09:37:57Z,101,3,This is a code example that complements the material in the ZooKeeper O'Reilly book.,,"# Apache ZooKeeper - O'Reilly Book Example

This is some code example we have developed for the Apache ZooKeeper book. 
This code constitutes complementary material to the book and it has been 
written to illustrate how to implement an application with ZooKeeper. It
hasn't been heavily tested or debugged, and it misses features, so don't 
take it as production-ready code. In fact, if you're able to fix bugs and
extend this implementation, it probably means that you have learned how
to program with ZooKeeper!


## Components

This example implements a simple master-worker system. There is a primary
master assigning tasks and it supports backup masters to replace the primary
in the case it crashes. Workers execute tasks assigned to it. The task
consists of reading the content of the task znode, nothing more. A real app
will most likely do something more complex than that. Finally, clients 
submit tasks and wait for a status znode.

Here is a summary of the code flow for each of the components:

### Master:

  1. Before taking leadership 
    1. Try to create the master znode
    2. If it goes through, then take leadership
    3. Upon connection loss, needs to check if znode is there and who owns it
    4. Upon determining that someone else owns it, watch the master znode
  2. After taking leadership 
    1. Get workers
      1. Set a watch on the list of workers
      2. Check for dead workers and reassign tasks
      3. For each dead worker
        1. Get assigned tasks
        2. Get task data
        3. Move task to the list of unassigned tasks
        4. Delete assignment
    2. Recover tasks (tasks assigned to dead workers)
    3. Get unassigned tasks and assign them
    4. For each unassigned task
    5. 
      1. Get task data
      2. Choose worker
      3. Assign to worker
      4. Delete task from the list of unassigned

### Worker:


  1. Creates /assign/worker-xxx znode
  2. Creates /workers/worker-xxx znode
  3. Watches /assign/worker-xxx znode
  4. Get tasks upon assignment
  5. For each task, get task data
  6. Execute task data
  7. Create status
  8. Delete assignment


### Client


  1. Create task
  2. Watch for status znode
  3. Upon receiving a notification for the status znode, get status data
  4. Delete status znode 


## Compile and run it

We used maven for this little project. Install maven if you don't have it
and run ""mvn install"" to generate the jar file and to run tests. We have a
few tests that check for basic functionality. For the C master, you'll need
to compile the ZooKeeper C client to use the client library.

To run it, follow these steps:

### Step 1: Start ZooKeeper by running `bin/zkServer.sh start` from a copy 
of the distribution package.

### Step 2: Start the master
```
java -cp .:/usr/local/zookeeper-3.4.8/zookeeper-3.4.8.jar:/usr/local/slf4j-1.7.2/slf4j-api-1.7.2.jar:/usr/local/slf4j-1.7.2/slf4j-ext-1.7.2.jar:/usr/local/slf4j-1.7.2/slf4j-log4j12-1.7.2.jar:/usr/local/apache-log4j-1.2.17/log4j-1.2.17.jar:/path/to/book/repo/target/ZooKeeper-Book-0.0.1-SNAPSHOT.jar org.apache.zookeeper.book.Master localhost:2181
```

### Step 3: Start a couple of workers
```
java -cp .:/usr/local/zookeeper-3.4.8/zookeeper-3.4.8.jar:/usr/local/slf4j-1.7.2/slf4j-api-1.7.2.jar:/usr/local/slf4j-1.7.2/slf4j-ext-1.7.2.jar:/usr/local/slf4j-1.7.2/slf4j-log4j12-1.7.2.jar:/usr/local/apache-log4j-1.2.17/log4j-1.2.17.jar:/path/to/book/repo/target/ZooKeeper-Book-0.0.1-SNAPSHOT.jar org.apache.zookeeper.book.Worker localhost:2181
```

### Step 4: Run a client
```
java -cp .:/usr/local/zookeeper-3.4.8/zookeeper-3.4.8.jar:/usr/local/slf4j-1.7.2/slf4j-api-1.7.2.jar:/usr/local/slf4j-1.7.2/slf4j-ext-1.7.2.jar:/usr/local/slf4j-1.7.2/slf4j-log4j12-1.7.2.jar:/usr/local/apache-log4j-1.2.17/log4j-1.2.17.jar:/path/to/book/repo/target/ZooKeeper-Book-0.0.1-SNAPSHOT.jar org.apache.zookeeper.book.Client localhost:2181
```

For the C master, we do the following:

### Compile

```
gcc -I/usr/local/zookeeper-3.4.8/src/c/include -I/usr/local/zookeeper-3.4.8/src/c/generated -DTHREADED -L/usr/local/lib -l zookeeper_mt master.c
```
### Run it

./a.out 127.0.0.1:2181

Have fun!
"
gurkanucar/spring-security-examples,all-examples,40,7,2023-11-05T09:49:14Z,189,0,spring security 6,,"# spring-security-examples

## 1) In Memory Auth

### With this example, you will understand the spring security mechanism. No need to database. Just we are adding some users and authorities (roles). In this example we used Basic Authentication (username, password)
```java
@Bean
  public UserDetailsService users() {
    UserDetails user =
        User.builder()
            .username(""user"")
            .password(""pass"")
            .passwordEncoder(passwordEncoder::encode)
            // .password(passwordEncoder.encode(""pass""))
            .roles(""USER"")
            .build();
        ...
        return new InMemoryUserDetailsManager(user, admin, mod);
}
```

- to allow endpoints we can use:
```java

  @Bean
  public WebSecurityCustomizer webSecurityCustomizer() {
    return (web) ->
        web.ignoring()
            .requestMatchers(
                new AntPathRequestMatcher(""/auth/**""),
                new AntPathRequestMatcher(""/public/**""));
  }
```
- also we can configure http security options:

```java
  @Bean
  public SecurityFilterChain filterChain(HttpSecurity httpSecurity) throws Exception {
    httpSecurity
        .headers(x -> x.frameOptions(HeadersConfigurer.FrameOptionsConfig::disable))
        .csrf(AbstractHttpConfigurer::disable)
        .cors(Customizer.withDefaults())
        // authenticate any request except web.ignoring()
        // also you can allow some endpoints here:
        // x.requestMatchers(new AntPathRequestMatcher(""/auth/**"")).permitAll()
        .authorizeHttpRequests(x -> x.anyRequest().authenticated())
        .httpBasic(Customizer.withDefaults());
    return httpSecurity.build();
  }
```

## 2 - 3 ) Basic Authentication with Hardcoded Enum Roles

### With this example, you will able to add hardcoded roles to user. Many projects we don't need to add dynamic roles and store them via different table in database.

#### NOTE: After first example, if we want to retrieve users from database we have to implement our custom user details service, and use spring-security's UserDetails class instead our User class:

```java

@Service
@RequiredArgsConstructor
public class UserDetailsServiceImpl implements UserDetailsService {

  private final UserService userService;

  @Override
  public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
    var user = userService.getByUsername(username);
    if (user.isEmpty()) {
      throw new EntityNotFoundException();
    }
    return new CustomUserDetails(user.get());
  }
}



public class CustomUserDetails implements UserDetails {

    private final User user;

    public CustomUserDetails(User user) {
        this.user = user;
    }

    @Override
    public Collection<? extends GrantedAuthority> getAuthorities() {
        return this.user.getRoles();
    }

    @Override
    public String getPassword() {
        return this.user.getPassword();
    }

    @Override
    public String getUsername() {
        return this.user.getUsername();
    }

    @Override
    public boolean isAccountNonExpired() {
        return true;
    }

    @Override
    public boolean isAccountNonLocked() {
        return true;
    }

    @Override
    public boolean isCredentialsNonExpired() {
        return true;
    }

    @Override
    public boolean isEnabled() {
        return this.user.isEnabled();
    }
}



```


## 4 ) Basic Authentication with Dynamic Roles

### With this example, you will able to add dynamic roles to user and store these roles in database.

```java
.....
public class User extends BaseEntity {

    .....

  @ManyToMany(fetch = FetchType.EAGER, cascade = CascadeType.MERGE)
  @JoinTable(
      name = ""user_role"",
      joinColumns = @JoinColumn(name = ""user_id"", referencedColumnName = ""id""),
      inverseJoinColumns = @JoinColumn(name = ""role_id"", referencedColumnName = ""id""))
  private Set<Role> roles;

}

....
public class Role extends BaseEntity implements GrantedAuthority {

    @Column(name = ""role_name"")
    private String name;

    @ManyToMany(
            fetch = FetchType.LAZY,
            cascade = {CascadeType.PERSIST, CascadeType.MERGE},
            mappedBy = ""roles"")
    @JsonIgnore
    private Set<User> users = new HashSet<>();

    @Override
    public String getAuthority() {
        return getName();
    }
}



```



## 5 ) Give Access or Block to endpoints Dynamically By Role

### With this example, you will able to allow or block access to endpoints by Roles. We are using AuthorizationManager (AccessDecisionVoter is deprecated) to decide.

```java


@Component
@RequiredArgsConstructor
public class RoleBasedVoter implements AuthorizationManager<RequestAuthorizationContext> {

  private final RoleRepository roleRepository;

  @Override
  public AuthorizationDecision check(
      Supplier<Authentication> authentication, RequestAuthorizationContext object) {
    if (authentication.get().getPrincipal() instanceof UserDetails) {
      UserDetails userDetails = (UserDetails) authentication.get().getPrincipal();
      String requestUrl = object.getRequest().getRequestURI();

      List<Role> roles = roleRepository.findByUsers_Username(userDetails.getUsername());

      for (Role role : roles) {
        if (role.getRestrictedEndpoints().contains(requestUrl)) {
          return new AuthorizationDecision(false);
        }
      }
    }

    return new AuthorizationDecision(true);
  }
}

@Configuration
@EnableWebSecurity
@EnableMethodSecurity
@RequiredArgsConstructor
public class SecurityConfig {

    private final UserDetailsServiceImpl userDetailsService;
    private final RoleBasedVoter roleBasedVoter;

    @Bean
    public SecurityFilterChain filterChain(HttpSecurity httpSecurity) throws Exception {
        httpSecurity
                ....
                .userDetailsService(userDetailsService)
                .authorizeHttpRequests(x -> x.anyRequest().access(roleBasedVoter))
                ....

```


## 6 7 8 9 ) JWT examples

- JWT is a token based authentication mechanism. Once you got token, you can use it until expire. Also we use refresh token to get new token after your access token get expired


-------------------------------------------------------------------

### Demo video:
[https://www.youtube.com/watch?v=BoioooM1vL8](https://www.youtube.com/watch?v=BoioooM1vL8)

-------------------------------------------------------------------


### Special thanks to `Ivan Franchin` for oauth2 example below:
[https://github.com/ivangfr/springboot-react-social-login](https://github.com/ivangfr/springboot-react-social-login)"
wimdeblauwe/blog-example-code,master,73,38,2019-10-27T12:01:07Z,1399,1,Example code for my blog entries,,
bezkoder/spring-boot-refresh-token-jwt,master,242,134,2021-04-21T00:00:33Z,149,5,Spring Boot Refresh Token using JWT example - Expire and Renew JWT Token,jwt jwt-auth jwt-authentication jwt-authorization spring-boot spring-boot-2 spring-boot-security spring-data spring-security,"# Spring Boot Refresh Token with JWT example

Build JWT Refresh Token in the Java Spring Boot Application. You can know how to expire the JWT, then renew the Access Token with Refresh Token.

The instruction can be found at:
[Spring Boot Refresh Token with JWT example](https://bezkoder.com/spring-boot-refresh-token-jwt/)

## User Registration, User Login and Authorization process.
The diagram shows flow of how we implement User Registration, User Login and Authorization process.

![spring-boot-spring-security-jwt-authentication-flow](spring-boot-spring-security-jwt-authentication-flow.png)

And this is for Refresh Token:

![spring-boot-refresh-token-jwt-example-flow](spring-boot-refresh-token-jwt-example-flow.png)

## Spring Boot Server Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-jwt-authentication-spring-security-architecture](spring-boot-jwt-authentication-spring-security-architecture.png)

## Configure Spring Datasource, JPA, App properties
Open `src/main/resources/application.properties`

```properties
spring.datasource.url= jdbc:mysql://localhost:3306/testdb?useSSL=false
spring.datasource.username= root
spring.datasource.password= 123456

spring.jpa.properties.hibernate.dialect= org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.hibernate.ddl-auto= update

# App Properties
bezkoder.app.jwtSecret= bezKoderSecretKey
bezkoder.app.jwtExpirationMs= 3600000
bezkoder.app.jwtRefreshExpirationMs= 86400000
```

## Run Spring Boot application
```
mvn spring-boot:run
```

## Run following SQL insert statements
```
INSERT INTO roles(name) VALUES('ROLE_USER');
INSERT INTO roles(name) VALUES('ROLE_MODERATOR');
INSERT INTO roles(name) VALUES('ROLE_ADMIN');
```

Related Posts:
> [Spring Boot JWT Refresh Token using HttpOnly Cookies](https://www.bezkoder.com/spring-security-refresh-token/)

> [Spring Boot, Spring Security, MySQL: JWT Authentication & Authorization example](https://bezkoder.com/spring-boot-jwt-authentication/)

> [For PostgreSQL](https://bezkoder.com/spring-boot-security-postgresql-jwt-authentication/)

> [For MongoDB](https://bezkoder.com/spring-boot-jwt-auth-mongodb/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

Associations:
> [Spring Boot One To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-one-to-many/)

> [Spring Boot Many To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA One To One example with Spring Boot](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)

## Fullstack Authentication

> [Spring Boot + Vue.js JWT Authentication](https://bezkoder.com/spring-boot-vue-js-authentication-jwt-spring-security/)

> [Spring Boot + Angular 8 JWT Authentication](https://bezkoder.com/angular-spring-boot-jwt-auth/)

> [Spring Boot + Angular 10 JWT Authentication](https://bezkoder.com/angular-10-spring-boot-jwt-auth/)

> [Spring Boot + Angular 11 JWT Authentication](https://bezkoder.com/angular-11-spring-boot-jwt-auth/)

> [Spring Boot + Angular 12 JWT Authentication](https://www.bezkoder.com/angular-12-spring-boot-jwt-auth/)

> [Spring Boot + Angular 13 JWT Authentication](https://www.bezkoder.com/angular-13-spring-boot-jwt-auth/)

> [Spring Boot + Angular 14 JWT Authentication](https://www.bezkoder.com/angular-14-spring-boot-jwt-auth/)

> [Spring Boot + Angular 15 JWT Authentication](https://www.bezkoder.com/angular-15-spring-boot-jwt-auth/)

> [Spring Boot + Angular 16 JWT Authentication](https://www.bezkoder.com/angular-16-spring-boot-jwt-auth/)

> [Spring Boot + Angular 17 JWT Authentication](https://www.bezkoder.com/angular-17-spring-boot-jwt-auth/)

> [Spring Boot + React JWT Authentication](https://bezkoder.com/spring-boot-react-jwt-auth/)

## Fullstack CRUD App

> [Vue.js + Spring Boot + H2 Embedded database example](https://www.bezkoder.com/spring-boot-vue-js-crud-example/)

> [Vue.js + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-vue-js-mysql/)

> [Vue.js + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-vue-js-postgresql/)

> [Angular 8 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + MySQL example](https://bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-spring-boot-postgresql/)

> [Angular 10 + Spring Boot + MySQL example](https://bezkoder.com/angular-10-spring-boot-crud/)

> [Angular 10 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-10-spring-boot-postgresql/)

> [Angular 11 + Spring Boot + MySQL example](https://bezkoder.com/angular-11-spring-boot-crud/)

> [Angular 11 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-11-spring-boot-postgresql/)

> [Angular 12 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-12-spring-boot-crud/)

> [Angular 12 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-12-spring-boot-mysql/)

> [Angular 12 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-12-spring-boot-postgresql/)

> [Angular 13 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-13-crud/)

> [Angular 13 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-13-mysql/)

> [Angular 13 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-13-postgresql/)

> [Angular 14 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-14-crud/)

> [Angular 14 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-14-mysql/)

> [Angular 14 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-14-postgresql/)

> [Angular 15 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-15-mysql/)

> [Angular 15 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-15-postgresql/)

> [Angular 15 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-15-mongodb/)

> [Angular 16 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-16-crud/)

> [Angular 16 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-16-mysql/)

> [Angular 16 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-16-postgresql/)

> [Angular 16 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-16-mongodb/)

> [Angular 17 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-17-crud/)

> [Angular 17 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-17-mysql/)

> [Angular 17 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-17-postgresql/)

> [Angular 17 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-17-mongodb/)

> [React + Spring Boot + MySQL example](https://bezkoder.com/react-spring-boot-crud/)

> [React + Spring Boot + PostgreSQL example](https://bezkoder.com/spring-boot-react-postgresql/)

> [React + Spring Boot + MongoDB example](https://bezkoder.com/react-spring-boot-mongodb/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React.js with Spring Boot Rest API](https://bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue.js with Spring Boot Rest API](https://bezkoder.com/integrate-vue-spring-boot/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

Associations:
> [JPA/Hibernate One To Many example](https://www.bezkoder.com/jpa-one-to-many/)

> [JPA/Hibernate Many To Many example](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA/Hibernate One To One example](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)
"
saturnism/docker-kubernetes-by-example-java,master,162,113,2015-04-30T21:29:10Z,7215,7,An end-to-end Spring Boot example w container and Kubernetes,docker google-cloud-platform java kubernetes microservices spring-boot,"Spring Boot with Kubernetes
---------------------------
Ray used this repository for many of his demos during his talks around the world in conferences. You can find a list of Ray's videos on how to run the demos in his [YouTube playlist](https://www.youtube.com/playlist?list=PL4uYfigiauVYH4OwOyq8FGbPQOn-JueEf).

But specifically, checkout the one from [Jfokus](https://www.youtube.com/watch?v=R2l-tL_1els&index=6&list=PL4uYfigiauVYH4OwOyq8FGbPQOn-JueEf).

To set everything up, see [Kubernetes Code Lab](http://bit.ly/k8s-lab)
To learn about running this in Istio, see [Istio Code Lab](http://bit.ly/istio-lab)
"
cuiyungao/JavaCodeExamples,master,28,8,2022-03-07T14:51:40Z,3778,0,,,"# JavaCodeExamples
The repository includes some examples of the Java course. You're welcome to modify and add examples.

第二章：java语言基础[src](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src)

第三章：类和对象[src3](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src3)

第四章：接口与继承[src4](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src4)

第五章：设计模式导论(单例模式，三种工厂模式)[src5](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src5)

第六章：软件测试及代码质量保障[src6](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src6)

第七章：集合与策略模式、迭代器模式[src7](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src7)

第八章：数据访问对象模式、输入输出流[src8](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src8)

第九章：MVC、Swing图形用户界面[src9](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src9)

第十章：Thread、生产者与消费者模式[src10](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src10)

第十一章：泛型与反射、模板模式[src11](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src11)

第十二章：网络编程、观察者模式[src12](https://github.com/cuiyungao/JavaCodeExamples/tree/master/src12)

Good luck!
"
chanjarster/spring-mvc-error-handling-example,master,73,28,2017-06-28T07:02:07Z,866,1,Spring MVC error handling example,,"# Spring Boot & Spring MVC 异常处理的N种方法

参考文档：

* Spring Boot 1.5.4.RELEASE [Documentation][spring-boot-doc]
* Spring framework 4.3.9.RELEASE [Documentation][spring-mvc-doc]
* [Exception Handling in Spring MVC][blog-exception-handling-in-spring-mvc]


## 默认行为

根据Spring Boot官方文档的说法：

> For machine clients it will produce a JSON response with details of the error, the HTTP status and the exception message. For browser clients there is a ‘whitelabel’ error view that renders the same data in HTML format

也就是说，当发生异常时：

* 如果请求是从浏览器发送出来的，那么返回一个`Whitelabel Error Page`
* 如果请求是从machine客户端发送出来的，那么会返回相同信息的`json`

你可以在浏览器中依次访问以下地址：

1. http://localhost:8080/return-model-and-view
1. http://localhost:8080/return-view-name
1. http://localhost:8080/return-view
1. http://localhost:8080/return-text-plain
1. http://localhost:8080/return-json-1
1. http://localhost:8080/return-json-2

会发现[FooController][def-foo]和[FooRestController][def-foo-rest]返回的结果都是一个`Whitelabel Error Page`也就是html。

但是如果你使用`curl -i -s -X GET`访问上述地址，那么返回的都是如下的`json`：

```json
{
  ""timestamp"": 1498886969426,
  ""status"": 500,
  ""error"": ""Internal Server Error"",
  ""exception"": ""me.chanjar.exception.SomeException"",
  ""message"": ""..."",
  ""trace"": ""..."",
  ""path"": ""...""
}
```

但是有一个URL除外：`http://localhost:8080/return-text-plain`，它不会返回任何结果，原因稍后会有说明。

本章节代码在[me.chanjar.boot.def][pkg-me.chanjar.boot.def]，使用[DefaultExample][boot-DefaultExample]运行。

注意：我们必须在`application.properties`添加`server.error.include-stacktrace=always`才能够得到stacktrace。

### Spring MVC处理请求的总体流程

![总体流程](doc/RequestMapping及异常处理流程/1-总体流程.png)

### 分析为何浏览器访问都`Whitelabel Error Page`

![浏览器访问](doc/RequestMapping及异常处理流程/2-默认行为-浏览器.png)

### 分析为何curl text/plain资源却没有返回结果

如果你在[logback-spring.xml][logback-spring.xml]里一样配置了这么一段：

```xml
<logger name=""org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod"" level=""TRACE""/>
```

那么你就能在日志文件里发现这么一个异常：

```
... TRACE 13387 --- [nio-8080-exec-2] .w.s.m.m.a.ServletInvocableHandlerMethod : Invoking 'org.springframework.boot.autoconfigure.web.BasicErrorController.error' with arguments [org.apache.catalina.core.ApplicationHttpRequest@1408b81]
... TRACE 13387 --- [nio-8080-exec-2] .w.s.m.m.a.ServletInvocableHandlerMethod : Method [org.springframework.boot.autoconfigure.web.BasicErrorController.error] returned [<500 Internal Server Error,{timestamp=Thu Nov 09 13:20:15 CST 2017, status=500, error=Internal Server Error, exception=me.chanjar.exception.SomeException, message=No message available, trace=..., path=/return-text-plain, {}>]
... TRACE 13387 --- [nio-8080-exec-2] .w.s.m.m.a.ServletInvocableHandlerMethod : Error handling return value [type=org.springframework.http.ResponseEntity] [value=<500 Internal Server Error,{timestamp=Thu Nov 09 13:20:15 CST 2017, status=500, error=Internal Server Error, exception=me.chanjar.exception.SomeException, message=No message available, trace=..., path=/return-text-plain, {}>]
HandlerMethod details: 
Controller [org.springframework.boot.autoconfigure.web.BasicErrorController]
Method [public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)]
org.springframework.web.HttpMediaTypeNotAcceptableException: Could not find acceptable representation
...
```

要理解这个异常是怎么来的，那我们来简单分析以下Spring MVC的处理过程：

![curl访问](doc/RequestMapping及异常处理流程/3-默认行为-curl.png)

那么这个问题怎么解决呢？我会在*自定义ErrorController*里说明。

## 自定义Error页面

前面看到了，Spring Boot针对浏览器发起的请求的error页面是`Whitelabel Error Page`，下面讲解如何自定义error页面。

注意2：自定义Error页面不会影响machine客户端的输出结果

### 方法1

根据Spring Boot官方文档，如果想要定制这个页面只需要：

> to customize it just add a `View` that resolves to ‘error’

这句话讲的不是很明白，其实只要看`ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration`的代码就知道，只需注册一个名字叫做`error`的`View`类型的`Bean`就行了。

本例的[CustomDefaultErrorViewConfiguration][boot-CustomDefaultErrorViewConfiguration]注册将`error`页面改到了[templates/custom-error-page/error.html][boot-custom-error-page-error-html]上。

本章节代码在[me.chanjar.boot.customdefaulterrorview][pkg-me.chanjar.boot.customdefaulterrorview]，使用[CustomDefaultErrorViewExample][boot-CustomDefaultErrorViewExample]运行。

### 方法2

方法2比方法1简单很多，在Spring官方文档中没有说明。其实只需要提供`error` `View`所对应的页面文件即可。

比如在本例里，因为使用的是Thymeleaf模板引擎，所以在classpath `/templates`放一个自定义的`error.html`就能够自定义error页面了。

本章节就不提供代码了，有兴趣的你可以自己尝试。

## 自定义Error属性

前面看到了不论error页面还是error json，能够得到的属性就只有：timestamp、status、error、exception、message、trace、path。

如果你想自定义这些属性，可以如Spring Boot官方文档所说的：

> simply add a bean of type `ErrorAttributes` to use the existing mechanism but replace the contents

在`ErrorMvcAutoConfiguration.errorAttributes`提供了[DefaultErrorAttributes][spring-DefaultErrorAttributes-javadoc]，我们也可以参照这个提供一个自己的[CustomErrorAttributes][boot-CustomErrorAttributes]覆盖掉它。

如果使用`curl -i -s -X GET`访问相关地址可以看到，返回的json里的出了修改过的属性，还有添加的属性：

```json
{
  ""exception"": ""customized exception"",
  ""add-attribute"": ""add-attribute"",
  ""path"": ""customized path"",
  ""trace"": ""customized trace"",
  ""error"": ""customized error"",
  ""message"": ""customized message"",
  ""timestamp"": 1498892609326,
  ""status"": 100
}
```

本章节代码在[me.chanjar.boot.customerrorattributes][pkg-me.chanjar.boot.customerrorattributes]，使用[CustomErrorAttributesExample][boot-CustomErrorAttributesExample]运行。

## 自定义ErrorController

在前面提到了`curl -i -s -X GET http://localhost:8080/return-text-plain`得不到error信息，解决这个问题有两个关键点：

1. 请求的时候指定`Accept`头，避免匹配到[BasicErrorController.error][BasicErrorController_error]方法。比如：`curl -i -s -X GET -H 'Accept: text/plain' http://localhost:8080/return-text-plain`
1. 提供自定义的``ErrorController``提供一个`path=/error procudes=text/plain`的方法。

其实还有另一种方式：提供一个Object->String转换的HttpMessageConverter，这个方法本文不展开。

下面将如何提供自定义的``ErrorController``。按照Spring Boot官方文档的说法：

> To do that just extend ``BasicErrorController`` and add a public method with a ``@RequestMapping`` that has a ``produces`` attribute, and create a bean of your new type.

所以我们提供了一个[CustomErrorController][boot-CustomErrorController]，并且通过[CustomErrorControllerConfiguration][boot-CustomErrorControllerConfiguration]将其注册为Bean。

本章节代码在[me.chanjar.boot.customerrorcontroller][pkg-me.chanjar.boot.customerrorcontroller]，使用[CustomErrorControllerExample][boot-CustomErrorControllerExample]运行。

## ControllerAdvice定制特定异常返回结果

根据Spring Boot官方文档的例子，可以使用[@ControllerAdvice][spring-ControllerAdvice]和[@ExceptionHandler][spring-ExceptionHandler]对特定异常返回特定的结果。

我们在这里定义了一个新的异常：AnotherException，然后在[BarControllerAdvice][boot-BarControllerAdvice]中对SomeException和AnotherException定义了不同的[@ExceptionHandler][spring-ExceptionHandler]：

* SomeException都返回到`controlleradvice/some-ex-error.html`上
* AnotherException统统返回`ResponseEntity`

在[BarController][boot-BarController]中，所有`*-a`都抛出``SomeException``，所有`*-b`都抛出``AnotherException``。下面是用浏览器和curl访问的结果：

| url                                    | Browser                                  | curl -i -s -X GET  |
| -------------------------------------- |------------------------------------------| -------------------|
| http://localhost:8080/bar/html-a       | some-ex-error.html                       | some-ex-error.html |
| http://localhost:8080/bar/html-b       | error(json)                              | error(json)        |
| http://localhost:8080/bar/json-a       | some-ex-error.html                       | some-ex-error.html |
| http://localhost:8080/bar/json-b       | error(json)                              | error(json)        |
| http://localhost:8080/bar/text-plain-a | some-ex-error.html                       | some-ex-error.html |
| http://localhost:8080/bar/text-plain-b | Could not find acceptable representation(White Error Page) | Could not find acceptable representation(无输出) |

注意上方表格的``Could not find acceptable representation``错误，产生这个的原因前面已经讲过。

不过需要注意的是流程稍微有点不同，在前面的例子里的流程是这样的：

1. 访问url
1. 抛出异常
1. forward到 /error
1. BasicErrorController.error方法返回的ResponseEntity没有办法转换成String

本章节例子的异常是这样的：

1. 访问url
1. 抛出异常
1. 被`@ExceptionHandler`处理
1. AnotherException的`@ExceptionHander`返回的ResponseEntity没有办法转换成String，被算作没有被处理成功
1. forward到 /error
1. BasicErrorController.error方法返回的ResponseEntity没有办法转换成String

所以你会发现如果使用[@ExceptionHandler][spring-ExceptionHandler]，那就得自己根据请求头``Accept``的不同而输出不同的结果了，办法就是定义一个``void @ExceptionHandler``，具体见[@ExceptionHandler javadoc][spring-ExceptionHandler-javadoc]。

## 定制不同Status Code的错误页面

Spring Boot 官方文档提供了一种简单的根据不同Status Code跳到不同error页面的方法，见[这里][spring-boot-status-code-error-page]。

我们可以将不同的Status Code的页面放在`classpath: public/error`或`classpath: templates/error`目录下，比如`400.html`、`5xx.html`、`400.ftl`、`5xx.ftl`。

打开浏览器访问以下url会获得不同的结果：

| url                                    |  Result                                    |
|----------------------------------------|--------------------------------------------|
| http://localhost:8080/loo/error-403    | static resource: public/error/403.html     |
| http://localhost:8080/loo/error-406    | thymeleaf view: templates/error/406.html   |
| http://localhost:8080/loo/error-600    | Whitelabel error page                      |
| http://localhost:8080/loo/error-601    | thymeleaf view: templates/error/6xx.html   |


注意`/loo/error-600`返回的是Whitelabel error page，但是`/loo/error-403`和`loo/error-406`能够返回我们期望的错误页面，这是为什么？先来看看代码。

在`loo/error-403`中，我们抛出了异常``Exception403``：

```java
@ResponseStatus(HttpStatus.FORBIDDEN)
public class Exception403 extends RuntimeException
```

在`loo/error-406`中，我们抛出了异常``Exception406``：

```java
@ResponseStatus(NOT_ACCEPTABLE)
public class Exception406 extends RuntimeException
```

注意到这两个异常都有[@ResponseStatus][spring-ResponseStatus-javadoc]注解，这个是注解标明了这个异常所对应的Status Code。
但是在`loo/error-600`中抛出的[SomeException][SomeException]没有这个注解，而是尝试在``Response.setStatus(600)``来达到目的，但结果是失败的，这是为什么呢？：

```java
@RequestMapping(""/error-600"")
public String error600(HttpServletRequest request, HttpServletResponse response) throws SomeException {
  request.setAttribute(WebUtils.ERROR_STATUS_CODE_ATTRIBUTE, 600);
  response.setStatus(600);
  throw new SomeException();
}
```

要了解为什么就需要知道Spring MVC对于异常的处理机制，下面简单讲解一下：

Spring MVC处理异常的地方在[DispatcherServlet.processHandlerException][DispatcherServlet_L1216]，这个方法会利用[HandlerExceptionResolver][spring-HandlerExceptionResolver]来看异常应该返回什么`ModelAndView`。

目前已知的[HandlerExceptionResolver][spring-HandlerExceptionResolver]有这么几个：

1. [DefaultErrorAttributes][spring-DefaultErrorAttributes-javadoc]，只负责把异常记录在Request attributes中，name是`org.springframework.boot.autoconfigure.web.DefaultErrorAttributes.ERROR`
1. [ExceptionHandlerExceptionResolver][spring-ExceptionHandlerExceptionResolver-javadoc]，根据[@ExceptionHandler][spring-ExceptionHandler] resolve
1. [ResponseStatusExceptionResolver][spring-ResponseStatusExceptionResolver-javadoc]，根据[@ResponseStatus][spring-ResponseStatus-javadoc] resolve
1. [DefaultHandlerExceptionResolver][spring-DefaultHandlerExceptionResolver-javadoc]，负责处理Spring MVC标准异常

``Exception403``和``Exception406``都有被[ResponseStatusExceptionResolver][spring-ResponseStatusExceptionResolver-javadoc]处理了，而``SomeException``没有任何Handler处理，这样``DispatcherServlet``就会将这个异常往上抛至到容器处理（见[DispatcherServlet#L1243][DispatcherServlet_L1243]），以Tomcat为例，它在[StandardHostValve#L317][StandardHostValve_L317]、[StandardHostValve#L345][StandardHostValve_L345]会将Status Code设置成500，然后forward到`/error`，结果就是[BasicErrorController][BasicErrorController]处理时就看到Status Code=500，然后按照500去找error page找不到，就只能返回White error page了。


实际上，从Request的attributes角度来看，交给[BasicErrorController][BasicErrorController]处理时，和容器自己处理时，有几个相关属性的内部情况时这样的：

| Attribute name                  | When throw up to Tomcat | Handled by HandlerExceptionResolver  |
|---------------------------------|-------------------------|--------------------------------------|
| `DefaultErrorAttributes.ERROR`  | Has value               | Has Value                            |
| `DispatcherServlet.EXCEPTION`   | No value                | Has Value                            |
| `javax.servlet.error.exception` | Has value               | No Value                             |

PS. `DefaultErrorAttributes.ERROR` = `org.springframework.boot.autoconfigure.web.DefaultErrorAttributes.ERROR`

PS. `DispatcherServlet.EXCEPTION` = `org.springframework.web.servlet.DispatcherServlet.EXCEPTION`

解决办法有两个：

1. 给``SomeException``添加``@ResponseStatus``，但是这个方法有两个局限：
    1. 如果这个异常不是你能修改的，比如在第三方的Jar包里
    1. 如果``@ResponseStatus``使用[HttpStatus][HttpStatus-javadoc]作为参数，但是这个枚举定义的Status Code数量有限
1. 使用[@ExceptionHandler][spring-ExceptionHandler]，不过得注意自己决定view以及status code。
   这个办法很麻烦，因为你得小心的处理请求头里的`Accept`，以此返回相应的结果，并且因为它的处理方式脱离了框架，容易造成返回信息不一致。


第二种解决办法的例子`loo/error-601`，对应的代码：

```java
@RequestMapping(""/error-601"")
public String error601(HttpServletRequest request, HttpServletResponse response) throws AnotherException {
  throw new AnotherException();
}

@ExceptionHandler(AnotherException.class)
String handleAnotherException(HttpServletRequest request, HttpServletResponse response, Model model)
    throws IOException {
  // 需要设置Status Code，否则响应结果会是200
  response.setStatus(601);
  model.addAllAttributes(errorAttributes.getErrorAttributes(new ServletRequestAttributes(request), true));
  return ""error/6xx"";
}
```

补充：从Spring Framework 5.0开始，提供了`ResponseStatusException`，你可以直接在抛出异常处定义Status Code、Reason，能够很好的解决第三方Jar包的问题。用法类似于这样：

```java
@PutMapping(""/actor/{id}/{name}"")
public String updateActorName(
  @PathVariable(""id"") int id, 
  @PathVariable(""name"") String name) {
  
    try {
        return actorService.updateActor(id, name);
    } catch (ActorNotFoundException ex) {
        throw new ResponseStatusException(
          HttpStatus.BAD_REQUEST, ""Provide correct Actor Id"", ex);
    }
}
```	

总结：

1. 没有被[HandlerExceptionResolver][spring-HandlerExceptionResolver]resolve到的异常会交给容器处理。已知的实现有（按照顺序）：
    1. [DefaultErrorAttributes][spring-DefaultErrorAttributes-javadoc]，只负责把异常记录在Request attributes中，name是`org.springframework.boot.autoconfigure.web.DefaultErrorAttributes.ERROR`
    1. [ExceptionHandlerExceptionResolver][spring-ExceptionHandlerExceptionResolver-javadoc]，根据[@ExceptionHandler][spring-ExceptionHandler] resolve
    1. [ResponseStatusExceptionResolver][spring-ResponseStatusExceptionResolver-javadoc]，根据[@ResponseStatus][spring-ResponseStatus-javadoc] resolve
    1. [DefaultHandlerExceptionResolver][spring-DefaultHandlerExceptionResolver-javadoc]，负责处理Spring MVC标准异常
1. [@ResponseStatus][spring-ResponseStatus-javadoc]用来规定异常对应的Status Code，其他异常的Status Code由容器决定，在Tomcat里都认定为500（[StandardHostValve#L317][StandardHostValve_L317]、[StandardHostValve#L345][StandardHostValve_L345]）
1. [@ExceptionHandler][spring-ExceptionHandler]处理的异常不会经过[BasicErrorController][BasicErrorController]，需要自己决定如何返回页面，并且设置Status Code（如果不设置就是200）
1. [BasicErrorController][BasicErrorController]会尝试根据Status Code找error page，找不到的话就用Whitelabel error page

本章节代码在[me.chanjar.boot.customstatuserrorpage][pkg-me.chanjar.boot.customstatuserrorpage]，使用[CustomStatusErrorPageExample][boot-CustomStatusErrorPageExample]运行。

## 利用ErrorViewResolver来定制错误页面

前面讲到[BasicErrorController][BasicErrorController]会根据Status Code来跳转对应的error页面，其实这个工作是由[DefaultErrorViewResolver][DefaultErrorViewResolver-javadoc]完成的。

实际上我们也可以提供自己的[ErrorViewResolver][ErrorViewResolver-javadoc]来定制特定异常的error页面。

```java
@Component
public class SomeExceptionErrorViewResolver implements ErrorViewResolver {

  @Override
  public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map<String, Object> model) {
    return new ModelAndView(""custom-error-view-resolver/some-ex-error"", model);
  }

}
```

不过需要注意的是，无法通过[ErrorViewResolver][ErrorViewResolver-javadoc]设定Status Code，Status Code由[@ResponseStatus][spring-ResponseStatus-javadoc]或者容器决定（Tomcat里一律是500）。

本章节代码在[me.chanjar.boot.customerrorviewresolver][pkg-me.chanjar.boot.customerrorviewresolver]，使用[CustomErrorViewResolverExample][boot-CustomErrorViewResolverExample]运行。


## @ExceptionHandler 和 @ControllerAdvice

前面的例子中已经有了对[@ControllerAdvice][spring-ControllerAdvice]和[@ExceptionHandler][spring-ExceptionHandler]的使用，这里只是在做一些补充说明：

1. ``@ExceptionHandler``配合``@ControllerAdvice``用时，能够应用到所有被``@ControllerAdvice``切到的Controller
2. ``@ExceptionHandler``在Controller里的时候，就只会对那个Controller生效

## 最佳实践

前面讲了那么多种方式，那么在Spring MVC中处理异常的最佳实践是什么？在回答这个问题前我先给出一个好的异常处理应该是什么样子的：

1. 返回的异常信息能够适配各种`Accept`，比如`Accept:text/html`返回html页面，`Accept:application/json`返回json。
1. 统一的异常信息schema，且可自定义，比如只包含`timestamp`、`error`、`message`等信息。
1. 能够自定义部分信息，比如可以自定义`error`、`message`的内容。

要达成以上目标我们可以采取的方法：

1. 达成第1条：自定义`ErrorController`，扩展`BasicErrorController`，支持更多的`Accept`类型。
1. 达成第2条：自定义`ErrorAttributes`
1. 达成第3条：
   1. 使用`@ResponseStatus`或`ResponseStatusException`(since 5.0)
   2. 前一种方式不适用时，自定义`ErrorAttributes`，在里面写代码，针对特定异常返回特定信息。推荐使用配置的方式来做，比如配置文件里写XXXException的message是YYYY。

Spring MVC对于从Controller抛出的异常是不打印到console的，解决办法是提供一个`HandlerExceptionResolver`，比如这样：

```
@Order(Ordered.HIGHEST_PRECEDENCE)
public class ErrorLogger implements HandlerExceptionResolver {

  private static final Logger LOGGER = LoggerFactory.getLogger(ErrorLogger.class);

  @Override
  public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler,
      Exception ex) {
    LOGGER.error(""Exception happened at [{}]: {}"", request.getRequestURI(), ExceptionUtils.getStackTrace(ex));
    return null;
  }

}
```

## 附录I

下表列出哪些特性是Spring Boot的，哪些是Spring MVC的：

| Feature                    | Spring Boot          | Spring MVC         |
|----------------------------|----------------------|--------------------|
| BasicErrorController       | Yes                  |                    |
| ErrorAttributes            | Yes                  |                    |
| ErrorViewResolver          | Yes                  |                    |
| @ControllerAdvice          |                      | Yes                |
| @ExceptionHandler          |                      | Yes                |
| @ResponseStatus            |                      | Yes                |
| HandlerExceptionResolver   |                      | Yes                |


  [spring-boot-doc]: http://docs.spring.io/spring-boot/docs/1.5.4.RELEASE/reference/htmlsingle/#boot-features-error-handling
  [spring-mvc-doc]: http://docs.spring.io/spring/docs/4.3.9.RELEASE/spring-framework-reference/htmlsingle/#mvc-exceptionhandlers
  [blog-exception-handling-in-spring-mvc]: https://spring.io/blog/2013/11/01/exception-handling-in-spring-mvc
  [RequestMapping]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-web/src/main/java/org/springframework/web/bind/annotation/RequestMapping.java
  [RequestMappingHandlerMapping]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/RequestMappingHandlerMapping.java
  [AbstractHandlerMethodMapping_L341]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/handler/AbstractHandlerMethodMapping.java#L341
  [AbstractHandlerMethodMapping_L352]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/handler/AbstractHandlerMethodMapping.java#L352 
  [BasicErrorController]: https://github.com/spring-projects/spring-boot/blob/v1.5.4.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/BasicErrorController.java
  [BasicErrorController_errorHtml]: https://github.com/spring-projects/spring-boot/blob/v1.5.4.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/BasicErrorController.java#L86
  [BasicErrorController_error]: https://github.com/spring-projects/spring-boot/blob/v1.5.4.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/BasicErrorController.java#L98
  [RequestMappingInfo_L266]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/RequestMappingInfo.java#L266
  [ProducesRequestCondition_L235]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/condition/ProducesRequestCondition.java#L235
  [HttpEntityMethodProcessor_L159]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/HttpEntityMethodProcessor.java#L159
  [HttpEntityMethodProcessor]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/HttpEntityMethodProcessor.java
  [AbstractMessageConverterMethodProcessor]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/AbstractMessageConverterMethodProcessor.java
  [AbstractMessageConverterMethodProcessor_L259]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/AbstractMessageConverterMethodProcessor.java#L259
  [AbstractMessageConverterMethodProcessor_L163]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/AbstractMessageConverterMethodProcessor.java#L163
  [AbstractMessageConverterMethodProcessor_L187]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/mvc/method/annotation/AbstractMessageConverterMethodProcessor.java#L187
  [HttpMessageConverter]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-web/src/main/java/org/springframework/http/converter/HttpMessageConverter.java
  [RequestMapping_produces]: https://github.com/spring-projects/spring-framework/blob/master/spring-web/src/main/java/org/springframework/web/bind/annotation/RequestMapping.java#L396
  
  [SomeException]: src/main/java/me/chanjar/exception/SomeException.java
  
  [def-foo]: src/main/java/me/chanjar/controllers/FooController.java
  [def-foo-rest]: src/main/java/me/chanjar/controllers/FooRestController.java
  
  [pkg-me.chanjar.boot.def]: src/main/java/me/chanjar/boot/def
  [boot-CustomDefaultErrorViewConfiguration]: src/main/java/me/chanjar/boot/customdefaulterrorview/CustomDefaultErrorViewConfiguration.java
  [boot-DefaultExample]: src/main/java/me/chanjar/boot/def/DefaultExample.java
  
  [pkg-me.chanjar.boot.customdefaulterrorview]: src/main/java/me/chanjar/boot/customdefaulterrorview
  [boot-custom-error-page-error-html]: src/main/resources/templates/custom-error-page/error.html
  [boot-CustomDefaultErrorViewExample]: src/main/java/me/chanjar/boot/customdefaulterrorview/CustomDefaultErrorViewExample.java
  
  [pkg-me.chanjar.boot.customerrorattributes]: src/main/java/me/chanjar/boot/customerrorattributes
  [boot-CustomErrorAttributes]: src/main/java/me/chanjar/boot/customerrorattributes/CustomErrorAttributes.java
  [boot-CustomErrorAttributesExample]: src/main/java/me/chanjar/boot/customerrorattributes/CustomErrorAttributesExample.java

  [pkg-me.chanjar.boot.customerrorcontroller]: src/main/java/me/chanjar/boot/customerrorcontroller
  [boot-CustomErrorController]: src/main/java/me/chanjar/boot/customerrorcontroller/CustomErrorController.java
  [boot-CustomErrorControllerConfiguration]: src/main/java/me/chanjar/boot/customerrorcontroller/CustomErrorControllerConfiguration.java
  [boot-CustomErrorControllerExample]: src/main/java/me/chanjar/boot/customerrorcontroller/CustomErrorControllerExample.java
  
  [pkg-me.chanjar.boot.controlleradvice]: src/main/java/me/chanjar/boot/controlleradvice/
  [boot-BarController]: src/main/java/me/chanjar/boot/controlleradvice/BarController.java
  [boot-BarControllerAdvice]: src/main/java/me/chanjar/boot/controlleradvice/BarControllerAdvice.java
  
  [logback-spring.xml]: src/main/resources/logback-spring.xml
  
  [pkg-me.chanjar.boot.customstatuserrorpage]: src/main/java/me/chanjar/boot/customstatuserrorpage
  [boot-CustomStatusErrorPageExample]: src/main/java/me/chanjar/boot/customstatuserrorpage/CustomStatusErrorPageExample.java
  
  [pkg-me.chanjar.boot.customerrorviewresolver]: src/main/java/me/chanjar/boot/customerrorviewresolver
  [boot-CustomErrorViewResolverExample]: src/main/java/me/chanjar/boot/customerrorviewresolver/CustomErrorViewResolverExample.java
  
  [spring-ExceptionHandler]: http://docs.spring.io/spring/docs/4.3.9.RELEASE/spring-framework-reference/htmlsingle/#mvc-ann-exceptionhandler
  [spring-ControllerAdvice]: http://docs.spring.io/spring/docs/4.3.9.RELEASE/spring-framework-reference/htmlsingle/#mvc-ann-controller-advice
  [spring-ExceptionHandler-javadoc]: https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ExceptionHandler.html
  [spring-boot-status-code-error-page]: http://docs.spring.io/spring-boot/docs/1.5.4.RELEASE/reference/htmlsingle/#boot-features-error-handling-custom-error-pages
  [spring-ResponseStatus-javadoc]: https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/web/bind/annotation/ResponseStatus.html
  [spring-HandlerExceptionResolver]: http://docs.spring.io/spring/docs/4.3.9.RELEASE/spring-framework-reference/htmlsingle/#mvc-exceptionhandlers-resolver
  [spring-DefaultErrorAttributes-javadoc]: http://docs.spring.io/spring-boot/docs/1.5.4.RELEASE/api/org/springframework/boot/autoconfigure/web/DefaultErrorAttributes.html
  [spring-ExceptionHandlerExceptionResolver-javadoc]: https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/web/servlet/mvc/method/annotation/ExceptionHandlerExceptionResolver.html
  [spring-ResponseStatusExceptionResolver-javadoc]: https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/web/servlet/mvc/annotation/ResponseStatusExceptionResolver.html
  [spring-DefaultHandlerExceptionResolver-javadoc]: https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/web/servlet/mvc/support/DefaultHandlerExceptionResolver.html
  [StandardHostValve_L317]: https://github.com/apache/tomcat/blob/TONCAT_9_0_0_M23/java/org/apache/catalina/core/StandardHostValve.java#L317
  [StandardHostValve_L345]: https://github.com/apache/tomcat/blob/TONCAT_9_0_0_M23/java/org/apache/catalina/core/StandardHostValve.java#L345
  [DispatcherServlet_L1216]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/DispatcherServlet.java#L1216
  [DispatcherServlet_L1243]: https://github.com/spring-projects/spring-framework/blob/v4.3.9.RELEASE/spring-webmvc/src/main/java/org/springframework/web/servlet/DispatcherServlet.java#L1243
  [HttpStatus-javadoc]: https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/http/HttpStatus.html
  [DefaultErrorViewResolver-javadoc]: http://docs.spring.io/spring-boot/docs/1.5.4.RELEASE/api/org/springframework/boot/autoconfigure/web/DefaultErrorViewResolver.html
  [ErrorViewResolver-javadoc]: http://docs.spring.io/spring-boot/docs/1.5.4.RELEASE/api/org/springframework/boot/autoconfigure/web/ErrorViewResolver.html
"
philipsorst/angular-rest-springsecurity,master,622,369,2013-02-13T16:03:58Z,1008,9,An example AngularJS Application that uses a Spring Security protected Jersey REST backend based on Hibernate/JPA,,"angular-rest-springsecurity
===========================

[![Build Status](https://travis-ci.org/philipsorst/angular-rest-springsecurity.svg?branch=master)](https://travis-ci.org/philipsorst/angular-rest-springsecurity)
[![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=W9NAXW8YAZ4D6&item_name=Angular+REST+SpringSecurity+Example+Donation&currency_code=EUR)

An example AngularJS Application that uses a Spring Security protected Jersey REST backend based on Hibernate/JPA.

About
-----

The projects aim is to demonstrate the Java implementation of a simple REST interface which is used by an AngularJS application. The following topics are covered:

* A relational database that holds blog posts and users.
* A REST service that exposes the data in the database.
* Authentication and authorization against the REST service.
* A Simple AngularJS application that allows users to view or edit news entries depending on their role.
* A responsive design.
 
This project is just meant to be a demonstration, therefore it is neither well documented nor well tested. Use it to learn about the technologies used, but do not use it for productive applications.

Any feedback is welcome, and I will incorporate useful pull requests.

Technologies
------------

* [AngularJS](http://angularjs.org/)
* [Bootstrap](http://getbootstrap.com/)
* [Jersey](https://jersey.java.net/)
* [Spring Security](http://projects.spring.io/spring-security/)
* [Hibernate](http://hibernate.org/)

Running
-------

Make sure Java >= 8 and [Maven](http://maven.apache.org/) >= 3.0 is installed on your system. Go into the project dir and type `mvn jetty:run`, then point your browser to `http://localhost:8080`.

License
-------

[The Apache Software License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0.txt)"
FirelyTeam/fhirstarters,master,184,259,2015-10-27T09:01:03Z,20407,16,A collection of example projects to get you up to speed with HL7 FHIR,,"# fhirstarters

This repository contains samples to get you started at playing with FHIR!

* [Browser/Postman Tutorial](./postman/): First introduction, requires no coding
* [Java/HAPI](./java/): Sample client and server projects in Java
* [.NET](./dotnet/): Sample project in .NET/C#
* [iOS](./ios/): Sample client project in iOS/Swift 4
* [Beginner's Track](./BeginnersTrack.md): Exercises used for the hands-on track during the FHIR Developer Days"
ellucianEthos/java-examples,master,25,7,2018-04-02T00:14:18Z,3690,0,Set of sample code for invoking Ethos APIs and publishing/consuming change-notifications.,,"# java-examples
This is a set of sample code for performing the following actions against the Ethos Integration services:
- getting an access token
- invoking the proxy API
- consuming change-notifications
- publishing change-notifications

This folder can be imported into eclipse as a java project.
"
janlindblad/bookzone,master,45,14,2018-01-19T10:14:21Z,2242,5,Bookzone example,,"BookZone Example Project
========================

This project is an open source network programmability tutorial 
accompanying the book ""Network Programmability with YANG: 
The Structure of Network Automation with YANG, NETCONF, RESTCONF, 
and gNMI"". We hope you will find this project useful whether you
are reading the book or not. For the deeper insights, we would
certainly recommend reading the book, however.

The book can be ordered online from a variety of sources. The ISBN
is 978-0135180396 (or 0135180392 in the older ISBN format). Here are 
links to the [YANG book Amazon page] and the [BookZone project page].

[YANG book Amazon page]: https://www.amazon.com/Network-Programmability-YANG-Modeling-driven-Management/dp/0135180392
[BookZone project page]: https://github.com/janlindblad/bookzone


Software you will need
----------------------

The project is using a variety of tools. If you would like to run
everything, you will need to download and install the following
YANG, NETCONF, RESTCONF and gNXI software development kits (SDKs):

+ [ConfD Basic]
+ [gNXI]
+ [NSO]

[ConfD Basic]: https://www.tail-f.com/confd-basic/
[gNXI]: https://github.com/google/gnxi
[NSO]: https://developer.cisco.com/docs/nso/#!getting-nso/getting-nso

Once you have installed ConfD or NSO, you need to set a collection of
environment variables in order for the system to find the commands, 
sources and files necessary. The easiest way to do that is to source
the resource (rc) file that comes with each installation. This also
allows easily switching from one installed version to another or back
again within seconds.

If a bash user installed ConfD basic in \~/confd-basic/6.7/ the 
following command would set up the environment correctly:

> source \~/confd-basic/6.7/confdrc

Similarly, for an NSO user with NSO installed in \~/nso/4.7/ the
following command would set up the environment correctly:

> source \~/nso/4.7/ncsrc

Depending on your interests, you may not need all of these SDKs. The 
example descriptions in ""The YANG Journey"" below list the SDKs you 
will need for each one. Apart from these SDKs, you will also need the
following tools. Many of them are often already installed on a 
developer's machine, but you may want to make sure.

### make

Essential build tool, included in most development environments. How
to install depends on your system, but you could try one of these:

> sudo apt-get install build-essential
> yum install make

### curl

URL fetching tool. Here is the [curl] home page.
[curl]: https://github.com/curl/curl

You could also try one of these commands:
> sudo apt-get install curl
> yum install curl

### netconf-console

Basic NETCONF client. Here is the [netconf-console] home page.
[netconf-console]: https://pypi.org/project/netconf-console/

With some luck, you could also install it using
> pip install netconf-console

### Paramiko

Python SSH implementation. Here is the [Paramiko] installation page.
[Paramiko]: http://www.paramiko.org/installing.html

With some luck, you could also install it using
> pip install paramiko

### Pyang

Basic (extensible) YANG compiler. Here is the [Pyang] home page.
[Pyang]: https://pypi.org/project/pyang/

With some luck, you could also install it using
> pip install pyang


The YANG Joureney
-----------------

There are seven stages of YANG models in this project. If you are new
to YANG, you can start from the beginning and work your way through
to more complex modules. Or you can jump in at any particular step 
and start playing around and making your own changes and experiments.

### 1-intro/

This is the first, small and simple step towards a YANG module and 
running server. The module is tiny, just 30 lines, but complete 
enough to compile and allow starting a server and get to configure a 
few things on it. The system doesn't actually do anything based on 
what is configured, so you can feel safe experimenting. This section 
requires [ConfD Basic].

### 2-config/

The module from 1-intro is expanded with a couple of additional 
lists, and uses some more specific types, such as uses enumerations 
and identities and a typedef. This section requires [ConfD Basic].

### 3-action-notif/

This module adds actions and notifications to the system, and uses 
the leafref type. The project also provides some backend code for 
implementing the actions and notifications. This section requires
[ConfD Basic].

### 4-oper/

This version of the module adds operational data (read only status)
to the mix, and introduces a grouping. The module has now grown to 
just over 250 lines. This section requires [ConfD Basic].

### 5-precision/

In this version of the module, the existing leafs are refined with
more exact types, ranges, patterns and contstraints like properly 
linked leafrefs, must and when statements. At this point, the module 
is about 350 lines. This section requires [ConfD Basic].

### 6-augment/

Here the exact same bookzone-example.yang module is used as in
5-precision/, but an additional module audiozone-example.yang 
augments the former with additional elements. This allows a
different organization to evolve and tailor an externally sourced 
YANG module to their needs. This section requires [ConfD Basic].

### 7-service/

This section uses a completely different YANG module, working on the 
service level (not on the device level). The aim is to understand
service orchestration, and how that maps to device configuration.
This section requires [NSO].


The NETCONF, RESTCONF, and gNMI journey
---------------------------------------

These examples also allow testing out the details of NETCONF, 
RESTCONF and gNMI. In order to have a server to play with, these 
examples piggy-back on the YANG examples above.

### NETCONF

To play with NETCONF towards the ConfD server, go into 6-augment/ 
above and type

> make nc

To see a menu of specific operations you could run. This section
requires [ConfD Basic]. 

### RESTCONF

Similarly, for RESTCONF, type

> make rc

Unfortunately the RESTCONF functionality available in ConfD is not
currently included in the ConfD Basic package. In order to play with
RESTCONF, a ConfD Premium evaluation would be required.

### gNMI/gRPC

In order to play with gNMI, it is necessary to go into the 2-config/ 
directory. This is because the gNXI implementation currently does not
support YANG 1.1, which the higher YANG modules leverage. Once in 
that directory, type

> make gnmi

This will show a menu of commands you can run. This section requires 
the [gNXI] SDK.


Contributions
-------------

You are most welcome to contribute to this project with suggestions, 
bug reports and pull requests. Keep in mind that the examples have to 
stay very close to the contents of the book, however.

Jan Lindblad
"
dehora/nakadi-java,main,30,19,2016-11-06T17:23:01Z,1386,23,"🌀 Client library for the Nakadi Event Broker  (examples: http://bit.ly/njc-examples, site: https://dehora.github.io/nakadi-java/)",gson java nakadi rxjava,"
**Status**

- Build: [![CircleCI](https://circleci.com/gh/dehora/nakadi-java.svg?style=svg)](https://circleci.com/gh/dehora/nakadi-java)
- Source Release: [0.19.0](https://github.com/zalando-incubator/nakadi-java/releases/tag/0.19.0)
- Contact: [maintainers](https://github.com/zalando-incubator/nakadi-java/blob/master/MAINTAINERS)



# nakadi-java

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *[DocToc](https://github.com/thlorenz/doctoc)*

- [About](#about)
  - [Background](#background)
- [Requirements and Getting Started](#requirements-and-getting-started)
- [Status](#status)
- [Usage](#usage)
  - [Available Resources](#available-resources)
  - [Creating a client](#creating-a-client)
    - [Authorization](#authorization)
    - [OAuth Scopes](#oauth-scopes)
    - [HTTPS Security](#https-security)
    - [Metric Collector](#metric-collector)
    - [JSON](#json)
    - [Using TypeLiterals](#using-typeliterals)
    - [Resource Classes](#resource-classes)
    - [Retries](#retries)
  - [Event Types](#event-types)
  - [Producing Events](#producing-events)
    - [Publishing Compression](#publishing-compression)
  - [Compacting Events](#compacting-events)
  - [Subscriptions](#subscriptions)
  - [Consuming Events](#consuming-events)
    - [Named Event Type Streaming](#named-event-type-streaming)
    - [Subscription Streaming](#subscription-streaming)
    - [Streaming and Compression](#streaming-and-compression)
    - [Backpressure and Buffering](#backpressure-and-buffering)
  - [Healthchecks](#healthchecks)
  - [Registry](#registry)
  - [Metrics](#metrics)
- [Installation](#installation)
  - [Maven](#maven)
  - [Gradle](#gradle)
  - [SBT](#sbt)
- [Idioms](#idioms)
  - [Fluent](#fluent)
  - [Iterable pagination](#iterable-pagination)
  - [HTTP Requests](#http-requests)
  - [Exceptions](#exceptions)
- [Build and Development](#build-and-development)
- [Internals](#internals)
- [Contributing](#contributing)
- [License](#license)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->
----


## About

Nakadi-java is a client driver for the [Nakadi Event Broker](https://github.com/zalando/nakadi). It was created for the following reasons:

- Completeness. Provide a full reference implementation of the Nakadi API for producers and consumers.

- Minimise dependencies. The client doesn't force a dependency on frameworks or libraries. The sole dependency is on the SLF4J API.

- Robust HTTP handling. Request/response behaviour and consumer stream handling are given the same importance as functionality. 

- Operational visibility. Error handling, stream retries, logging and instrumentation are given the same importance as functionality. 

- Be easy to use. The client should be straightforward to use as is, or as an engine for higher level abstractions.

### Background

A number of JVM clients already exist and are in use - nakadi-java is not meant 
to compete with or replace them. In certain respects they solve different 
goals. The existing JVM clients looked at as a whole, provide partial 
implementations with larger dependencies, but which are idiomatic to certain 
frameworks, whereas the aim of nakadi-java is to provide a full client with a 
reduced dependency footprint to allow portability. 

Nakadi-java is designed for application development. If you're just looking  
for a quick way to browse and examine streams, take a look at the excellent 
[Peek library](https://github.com/zalando-incubator/peek).

## Requirements and Getting Started

See the [installation section](#installation) on how to add the client library 
to your project as a jar dependency. The client uses Java 1.8 or later. 

## Status

The client is pre 1.0.0, with the aim of getting to 1.0.0 quickly. 

The client API is relatively stable and unlikely to see massive sweeping 
changes, though some changes should be expected. The entire Nakadi API is 
implemented.

The client's had some basic testing to verify it can handle things like 
consumer stream connection/network failures and retries. It should not be 
deemed robust yet, but it is a goal to produce a well-behaved production 
level client especially for producing and consuming events for 1.0.0. 
See also:

- The [open issues](https://github.com/zalando-incubator/nakadi-java/issues) section has a 
list of bugs and things to get done. 

- The [help-wanted](https://github.com/zalando-incubator/nakadi-java/issues?q=is%3Aissue+is%3Aopen+label%3Aenhancement) has a list of things that would be pretty cool to have.

As a client that aims to provide a full implementation, it will post 1.0.0 
continue to track the development of the Nakadi Event Broker's API.

## Usage

This section summarizes what you can do with the client. The [nakadi-java-examples](https://github.com/zalando-incubator/nakadi-java-examples) project provides runnable examples for most of what you see here.

### Available Resources

The API resources this client supports are:

- [Event Types](#event-types)
- [Events](#producing-events)
- [Subscriptions](#subscriptions)
- [Streams](#consuming-events)
- [Registry](#registry)
- [Healthchecks](#healthchecks)
- [Metrics](#metrics)

### Creating a client

A new client can be created via a builder: 

```java
NakadiClient client = NakadiClient.newBuilder()
  .baseURI(""http://localhost:9080"")
  .build();
```

You can create multiple clients if you wish. Every client must have a base URI 
set and can optionally have other values set (notably for token providers and 
metrics collection). 

Here's a fuller configuration:

```java
NakadiClient client = NakadiClient.newBuilder()
  .baseURI(""http://localhost:9080"")
  .metricCollector(myMetricsCollector)
  .tokenProvider(myResourceTokenProvider)
  .readTimeout(60, TimeUnit.SECONDS)
  .connectTimeout(30, TimeUnit.SECONDS)
  .build();
```

#### Authorization

By default the client does not send an authorization header with each request.
This is useful for working with a development Nakadi server, which will try 
and resolve bearer tokens if they are sent but will accept requests with no 
bearer token present. 

You can define a token provider by implementing the `TokenProvider` 
interface, which will supply the client with a string that will be 
sent to the server as the value of an Authorization header. The 
`TokenProvider` is  called on each request and thus can be implemented as 
a dynamic provider to handle token refreshes and recycling.

```java
NakadiClient client = NakadiClient.newBuilder()
  .baseURI(""http://localhost:9080"")
  .tokenProvider(new MyTokenProvider())
  .build();
```

There's a `ZignTokenProvider` that can connect to the zign process and run in 
the background in the 
[nakadi-java-zign](https://github.com/zalando-incubator/nakadi-java/tree/master/nakadi-java-zign) 
sub-project.

#### OAuth Scopes

Some resources support use of OAuth scopes (where the API documents them, it's incomplete as of 
2016-11-15):

- `StreamProcessor`: can be set via `StreamProcessor.Builder.scope()` before calling `start()`.
- `EventTypeResource`: can be set via `EventTypeResource.scope()` before making an API call.
- `EventResource`: can be set via `EventResource.scope` before making an API call.
- `SubscriptionResource`: can be set via `EventResource.scope` before making an API call.

On each request the client will resolve the scope to a token by asking the `TokenProvider` to 
supply a token via `authHeaderValue`. If a custom scope has been applied on the request it will 
be used, otherwise the default scope documented by the API will be used. 

The scope set on resource instances is stateful, not one-shot, and will be re-used across requests. 
To change the scope, call `scope()` again will a new scope value, or if you wish to clear the 
 custom scope and revert to defaults, call `scope()` with `null`. However the `StreamProcessor` 
 scope is fixed once streaming begins after `start()` is called and can't be changed.
 
 
#### HTTPS Security

The client checks certificates. If your target server is using a self-signed 
certificate and for some reason you can't install that cert into the system 
trust store using something like keytool, you can supply the cert via 
the builder's `certificatePath` method: 

```java
NakadiClient client = NakadiClient.newBuilder()
  .baseURI(""http://localhost:9080"")
  .certificatePath(""file:///var/certs"")
  .build();
```

This will cause the client to install any certificates it finds. There are three 
loading options

- A path beginning with `""file:///""` will load from the supplied directory any 
files with `*.crt` and `*.pem` extensions

- A path beginning with `""classpath:""` and ending with `*.crt` or `*.pem` will 
load that resource item from the classpath. 
 
- A path beginning with `""classpath:""` will load from the supplied classpath 
directory any files with `*.crt` and `*.pem` extensions.


The classpath option targeting a directory is for local development and not meant 
for production/deployed situations. If you must use the classpath for deployed apps, 
use the cert resource option as that will allow the classpath resolver to work more 
 generally.

If no `certificatePath` is supplied, the system defaults are used. This is the 
strongly recommended option for deployments.

#### Metric Collector

The client emits well known metrics as meters and timers (see `MetricCollector` 
for the available metrics). 

By default the client ignores metrics, but you can supply your own collector. 
For example, this sets the client to use `MetricsCollectorDropwizard`, from 
the support library that integrates with 
[Dropwizard Metrics](http://metrics.dropwizard.io/3.1.0/):

```java
MetricRegistry metricRegistry = new MetricRegistry();
MetricsCollectorDropwizard metrics =
    new MetricsCollectorDropwizard(""mynamespace"", metricRegistry);
 
NakadiClient client = NakadiClient.newBuilder()
  .baseURI(""http://localhost:9080"")
  .metricCollector(metrics)
  .build();
```

To provide your own collector implement the `MetricCollector` interface. Each 
emitted metric is based on an enum. Implementations can look at the enum and 
record as they wish. They can also work with them generally and ask any enum 
for its path, which will be a dotted string.

Please note that calls to the collector are currently blocking. This may be 
changed to asynchronous for 1.0.0, but in the meantime if your collector is 
making network calls or hitting disk, you might want to hand off them off 
as Callables or send them to a queue.

#### JSON

Some calls return `Response` objects that contain raw json. You can serialize 
these using the `JsonSupport` helper, available from the client. `JsonSupport` 
accepts classes, and for generic bindings you can supply it with a `TypeLiteral`.

#### Using TypeLiterals

When using a `TypeLiteral`, please note the following:

- TypeLiterals must be an actual subclass. This means declaring the TypeLiteral with a 
pair of braces `new TypeLiteral<Map<String, Object>>() {};` and not just 
`new TypeLiteral<Map<String, Object>>();`. The latter won't work and can cause hard to debug 
 errors.

- TypeLiterals for the 3 category classes can't be declared with a String. For example 
`DataChangeEvent<String>` will cause marshalling errors, because the underlying JSON 
processing treats `String` as a JSON String type and not escaped JSON. The parser then 
fails when it sees structured JSON instead of a JSOn String. Typically you want to declare 
something like `DataChangeEvent<Map<String, Object>>` to destructure the data properly. The 
client might add a stringified option for 1.0.0.

#### Resource Classes

Once you have a client, you can access server resources via the `resources()` 
method. Here's an example that gets an events resource:

```java 
EventResource resource = client.resources().events();
```

All calls you make to the server will be done via these resource classes to 
make network calls distinct from local requests.

#### Retries

A number of the non streaming resource classes support a backoff policy:

- `EventTypeResource`
- `SubscriptionResource`
- `EventResource`
- `RegistryResource`
- `MetricsResource`
- `HealthCheckResource`

They each take a `RetryPolicy` via a `retryPolicy()` method; there is an inbuilt `ExponentialRetry` 
that can be used to define a maximum number of requests or maximum total time elapsed. Note that 
the retry policy object is stateful and must be reset between results. You can disable the retries
 (the default behavior) by setting `retryPolicy` to null, or to start a new retry supplying a fresh 
 `RetryPolicy` instance.  

**Please be careful with EventTypeResource**: the ordering and general delivery behaviour for event 
delivery is **undefined** under retries. That is, a delivery retry may result in out of order 
batches being sent to the server. Also retrying a partially delivered (207) batch may result 
in one or more events being delivered multiple times. 

### Event Types

You can create, edit and delete event types as well as list them:

```java
// grab an event type resource
EventTypeResource eventTypes = client.resources().eventTypes();
 
// create a new event type, using an escaped string for the schema
EventType requisitions = new EventType()
  .category(EventType.Category.data)
  .name(""priority-requisitions"")
  .owningApplication(""weyland"")
  .partitionStrategy(EventType.PARTITION_HASH)
  .enrichmentStrategy(EventType.ENRICHMENT_METADATA)
  .partitionKeyFields(""id"")
  .cleanupPolicy(""delete"")
  .schema(new EventTypeSchema().schema(
      ""{ \""properties\"": { \""id\"": { \""type\"": \""string\"" } } }""));
Response response = eventTypes.create(requisitions);
 
// read the partitions for an event type
PartitionCollection partitions = eventTypes.partitions(""priority-requisitions"");
partitions.iterable().forEach(System.out::println);
 
// read a particular partition
Partition partition = eventTypes.partition(""priority-requisitions"", ""0"");
System.out.println(partition);
 
// list event types
EventTypeCollection list = client.resources().eventTypes().list();
list.iterable().forEach(System.out::println);
 
// find by name 
EventType byName = eventTypes.findByName(""priority-requisitions"");
 
// update 
Response update = eventTypes.update(byName);
 
// remove 
Response delete = eventTypes.delete(""priority-requisitions"");
```

### Producing Events

You can send one or more events to the server:

```java
EventResource resource = client.resources().events();
 
// nb: EventMetadata.newPreparedEventMetadata sets defaults for eid, occurred at and flow id fields
EventMetadata em = EventMetadata.newPreparedEventMetadata();

// you can send flowids as strings and tracing spans as Map<String, String> 
EventMetadata em1 = new EventMetadata()
  .eid(UUID.randomUUID().toString())
  .occurredAt(OffsetDateTime.now())
  .spanCtx(tracingSpan)
  .flowId(""decafbad"");
  
// create our domain event inside a typesafe DataChangeEvent  
PriorityRequisition pr = new PriorityRequisition(""22"");
DataChangeEvent<PriorityRequisition> dce = new DataChangeEvent<PriorityRequisition>()
  .metadata(em)
  .op(DataChangeEvent.Op.C)
  .dataType(""priority-requisitions"")
  .data(pr);
 
Response response = resource.send(""priority-requisitions"", dce);
 
// send a batch of two events
 
DataChangeEvent<PriorityRequisition> dce1 = new DataChangeEvent<PriorityRequisition>()
  .metadata(EventMetadata.newPreparedEventMetadata())
  .op(DataChangeEvent.Op.C)
  .dataType(""priority-requisitions"")
  .data(new PriorityRequisition(""23""));
 
DataChangeEvent<PriorityRequisition> dce2 = new DataChangeEvent<PriorityRequisition>()
  .metadata(EventMetadata.newPreparedEventMetadata())
  .op(DataChangeEvent.Op.C)
  .dataType(""priority-requisitions"")
  .data(new PriorityRequisition(""24""));

ArrayList list = new ArrayList();
list.add(dce1);
list.add(dce2);
 
Response batch = resource.send(""priority-requisitions"", list);
``` 

#### Publishing Compression

Event posting can be compressed by configuring the client 
with `.enablePublishingCompression()`:

```java
NakadiClient client = NakadiClient.newBuilder()
  .baseURI(""http://localhost:9080"")
  .enablePublishingCompression()  
  .build();
```

### Compacting Events

Events can be sent with compaction information by setting their metadata. 
This is required when the `cleanup_policy` of event type is set to `compact`. 

```java
// create metadata with compaction information for an event

EventMetadata compacted = EventMetadata.newPreparedEventMetadata()
  .partitionCompactionKey(""329ed3d2-8366-11e8-adc0-fa7ae01bbebc"");

PriorityRequisition pr = new PriorityRequisition(""23"");
DataChangeEvent<PriorityRequisition> dce = new DataChangeEvent<PriorityRequisition>()
  .metadata(compacted)
  .op(DataChangeEvent.Op.C)
  .dataType(""priority-requisitions"")
  .data(pr);
 
Response response = resource.send(""priority-requisitions"", dce);
```

### Subscriptions

You can create, edit and delete subscriptions as well as list them:

```java
// grab a subscription resource
SubscriptionResource resource = client.resources().subscriptions();
 
// create a new subscription
Subscription subscription = new Subscription()
    .consumerGroup(""mccaffrey-cg"")
    .eventType(""priority-requisitions"")
    .owningApplication(""shaper"");
 
Response response = resource.create(subscription);

// create a subscription from a given offset
Cursor c0 = new Cursor(""0"", ""000000000000002009"", ""priority-requisitions"");
Cursor c1 = new Cursor(""1"", ""000000000000002008"", ""priority-requisitions"");

Subscription offsetSubscription = new Subscription()
    .consumerGroup(""roja-cg"")
    .eventType(""priority-requisitions"")
    .owningApplication(""anarch"")
    .readFrom(""cursors"")
    .initialCursors(Lists.newArrayList(c0, c1));    

// find a subscription
Subscription found = resource.find(""a2ab0b7c-ee58-48e5-b96a-d13bce73d857"");
 
// get the cursors and iterate them
SubscriptionCursorCollection cursors = resource.cursors(found.id());
cursors.iterable().forEach(System.out::println);
 
// get the stats and iterate them
SubscriptionEventTypeStatsCollection stats = resource.stats(found.id());
stats.iterable().forEach(System.out::println);
 
// list subscriptions
SubscriptionCollection list = resource.list();
list.iterable().forEach(System.out::println);
 
// list for an owner
list = resource.list(new QueryParams().param(""owning_application"", ""shaper""));
list.iterable().forEach(System.out::println);
 
// delete a subscription
Response delete = resource.delete(found.id());
```

### Consuming Events

You can consume events via stream. Both the named event type and newer 
subscription stream APIs are available via the `StreamProcessor` class.

A `StreamProcessor` accepts a `StreamObserverProvider` which is a factory for 
creating the `StreamObserver` class the events will be sent to. The 
`StreamObserver` accepts one or more `StreamBatchRecord` objects  where each 
item in the batch has been marshalled to an instance of `T` as defined by 
it and the `StreamObserverProvider`.  

A `StreamObserver` implements a number of callback methods that are invoked 
by the underlying stream processor:

- `onStart()`:  Called before stream connection begins and before a retry is attempted.

- `onStop()`: Called after the stream is completed and when a retry is needed.

- `onCompleted()`: Called when the client is finished sending batches.

- `onError(Throwable t)`: Called when there's been an error.

- `onNext(StreamBatchRecord<T> record)`: Called for each batch of events. Also contains the current offset observer and the batch cursor.

- `requestBackPressure()`: request a maximum number of emitted items from the stream. 

- `requestBuffer()`: Ask to have batches buffered before emitting them from the stream.

The interface is influenced by [RxJava](https://github.com/ReactiveX/RxJava) 
and the general style of `onX`  callback APIs. You can see an example in the 
source called `LoggingStreamObserverProvider` which maps the events in a 
batch to plain strings.

The API also supports a `StreamOffsetObserver` - the offset observer is given 
to the `StreamObserver` object with each `onNext` call. Typically the offset 
observer is used to provide checkpointing of a consumer's partition in the 
stream. 

#### Named Event Type Streaming

To consume a named event type stream, configure a `StreamProcessor` and run it:

```java

// configure a stream for an event type from a given cursor; 
// all api settings are available
StreamConfiguration sc = new StreamConfiguration()
    .eventTypeName(""priority-requisitions"")
    .cursors(new Cursor(""0"", ""450""));

// set up a processor with an event observer provider
StreamProcessor processor = client.resources().streamBuilder()
    .streamConfiguration(sc)
    .streamObserverFactory(new LoggingStreamObserverProvider())
    .build();

// consume in the background until the app exits or stop() is called
processor.start(); 

// configure a stream with a bounded number of events retries, keepalives, plus custom timeouts
StreamConfiguration sc1 = new StreamConfiguration()
    .eventTypeName(""priority-requisitions"")
    .cursors(new Cursor(""0"", ""450""))
    .batchLimit(15)
    .batchFlushTimeout(2, TimeUnit.SECONDS)
    .maxRetryAttempts(256)
    .maxRetryDelay(30, TimeUnit.SECONDS)
    .streamLimit(1024)
    .connectTimeout(8, TimeUnit.SECONDS)
    .readTimeout(3, TimeUnit.MINUTES)
    .streamKeepAliveLimit(2048)
    .streamTimeout(1, TimeUnit.DAYS);
 
// create a processor with an observer and an offset observer  
StreamProcessor boundedProcessor = client.resources().streamBuilder()
    .streamConfiguration(sc1)
    .streamObserverFactory(new LoggingStreamObserverProvider())
    .streamOffsetObserver(new LoggingStreamOffsetObserver())
    .build();
 
/*
 start in the background, stopping when the criteria are reached,
 the app exits, or stop() is called
*/
boundedProcessor.start(); 
```

If no offset observer is given, the default observer used is 
`LoggingStreamOffsetObserver` which simply logs when it is invoked.


#### Subscription Streaming

Subscription stream consumers allow consumers to store offsets with the server 
and work much like named event type streams:

```java
// configure a stream from a subscription id; 
// all api settings are available
StreamConfiguration sc = new StreamConfiguration()
    .subscriptionId(""27302800-bc68-4026-a9ff-8d89372f8473"")
    .maxUncommittedEvents(20L);

// create a processor with an observer
StreamProcessor processor = client.resources().streamBuilder(sc)
    .streamObserverFactory(new LoggingStreamObserverProvider())
    .build();

// consume in the background until the app exits or stop() is called
processor.start();
```

There are some notable differences: 

- The `StreamConfiguration` is configured with a `subscriptionId`  instead of an `eventTypeName`.

- The inbuilt offset observer for a subscription stream will call Nakadi's checkpointing API to update the offset. You can replace this with your own implementation if you wish.

- A subscription stream also allows setting the `maxUncommittedEvents` as defined by the Nakadi API.

#### Streaming and Compression

The default behaviour for all streaming consumers is to request a gzipped stream. This can 
be changed to a plain stream by setting the `Accept-Encoding` header to `identity` on 
 `StreamConfiguration` as follows:

```java
StreamConfiguration sc = new StreamConfiguration()
    //  ask the server for unencoded data
    .requestHeader(""Accept-Encoding"", ""identity"")
    ...;
```

#### Backpressure and Buffering

A `StreamObserver` can signal for backpressure via the `requestBackPressure` 
method. This is applied with each `onNext` call to the `StreamObserver` and 
so can be used to adjust backpressure dynamically. The client's underlying 
stream processor will make a  best effort attempt to honor backpressure.

If the user wants events buffered into contiguous batches it can set a buffer 
size using `requestBuffer`. This is independent of the underlying HTTP 
stream - the stream will be consumed off the wire based on the API request 
settings - the batches are buffered in memory by the underlying processor. 
This is applied during setup and is fixed for the processor's lifecycle.

Users that don't care about backpresure controls can subclass the
 `StreamObserverBackPressure` class.


### Healthchecks

You can make healthcheck requests to the server:

```java
HealthCheckResource health = client.resources().health();
 
// check returning a response object, regardless of status
Response healthcheck = health().healthcheck();
 
// ask to throw if the check failed (non 2xx code)
Response throwable = health.healthcheckThrowing();

// check with an expoential backoff retry

RetryPolicy retry = ExponentialRetry.newBuilder()
        .initialInterval(1000, TimeUnit.MILLISECONDS)
        .maxAttempts(5)
        .maxInterval(3000, TimeUnit.MILLISECONDS)
        .build();
health.retryPolicy(retry).healthcheckThrowing();
```

### Registry

You can view the service registry:

```java
RegistryResource resource = client.resources().registry();
 
// get and iterate available enrichments
EnrichmentStrategyCollection enrichments = resource.listEnrichmentStrategies();
enrichments.iterable().forEach(System.out::println);
 
// get and iterate available validations
ValidationStrategyCollection validations = resource.listValidationStrategies();
validations.iterable().forEach(System.out::println);        
```

### Metrics

You can view service metrics:

```java
MetricsResource metricsResource = client.resources().metrics();
 
// print service metrics
MetricsResource metricsResource = client.resources().metrics();
Metrics metrics = metricsResource.get();
Map<String, Object> items = metrics.items();
System.out.println(items);
```

Note that the structure of metrics is not defined by the server, hence it's 
returned as as map within the `Metrics` object.

## Installation

### Maven

Add sonatype to the repositories element in `pom.xml` or `settings.xml` to access snapshots:

```xml
<repositories>
  <repository>
    <id>sonatype-nexus-snapshots</id>
    <name>sonatype-nexus-snapshots</name>
    <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    <snapshots>
      <enabled>true</enabled>
    </snapshots>
  </repository>
</repositories>
```  

and add the project declaration to `pom.xml`:

```xml
<dependency>
  <groupId>net.dehora.nakadi</groupId>
  <artifactId>nakadi-java-client</artifactId>
  <version>0.19.0</version>
</dependency>
```
### Gradle

Add sonatype to the `repositories` block for snapshots:

```groovy
repositories {
  maven {
    url = 'https://oss.sonatype.org/content/repositories/snapshots/'
  }
}
```

```kotlin
repositories {
  maven {
    url = uri(""https://oss.sonatype.org/content/repositories/snapshots"")
  }
}
```

and add the project to the `dependencies` block in `build.gradle`:

```groovy
dependencies {
  implementation 'net.dehora.nakadi:nakadi-java-client:0.19.0'
}  
```

```kotlin
dependencies {
  implementation(""net.dehora.nakadi:nakadi-java-client:0.19.0"")
}  
```

### SBT

Add sontaype to `resolvers` in `build.sbt` to access snapshots:

```scala
resolvers += Opts.resolver.sonatypeSnapshots
```

and add the project to `libraryDependencies` in `build.sbt`:

```scala
libraryDependencies += ""net.dehora.nakadi"" % ""nakadi-java-client"" % ""0.19.0""
```


## Idioms

### Fluent

The client prefers a fluent style, setters return `this` to allow chaining. 
Complex constructors use a builder pattern where needed. The JavaBeans 
get/set prefixing idiom is not used by the API, as is increasingly typical 
with modern Java code.

### Iterable pagination

Any API call that returns a collection, including ones that could be paginated 
expose Iterable contracts, allowing `forEach` or `iterator` access:

```java 
EventTypeCollection list = client.resources().eventTypes().list();
list.iterable().forEach(System.out::println);
 
Iterator<EventType> iterator = list.iterable().iterator();
while (iterator.hasNext()) {
  EventType next = iterator.next();
  System.out.println(next);
}
```

Pagination if it happens, is done automatically by the collection's backing 
iterable by following the `next` relation sent back by the server. 

You can if wish work with pages and hypertext links directly via the methods 
on `ResourceCollection` which each collection implements.

### HTTP Requests

Calls that result in HTTP requests are performed using resource classes. The 
results can be accessed as HTTP level responses or mapped to API objects.

You don't have to deal with HTTP responses from the API directly. If there 
is a failure then a `NakadiException` or a subclass will be thrown. The 
exception will have `Problem` information that can be examined. 

### Exceptions

Client exceptions are runtime exceptions by default. They extend from 
`NakadiException` which allows you to catch all errors under one type. The 
`NakadiException` embeds a `Problem` object which can be examined. Nakadi's 
API uses Problem JSON ([RFC7807](https://tools.ietf.org/html/rfc7807)) to 
describe errors. Local errors also contain Problem descriptions. 

The client will also throw an `IllegalArgumentException` in a number of places 
where null fields are not accepted or sensible as values, such as required 
parameters for builder classes. However the client performs no real data 
validation for API requests, leaving that to the server. Invalid server 
requests resulting in 422s will cause an `InvalidException` to be thrown 
instead.

In a handful of circumstances the API exposes a checked exception where 
it's neccessary the user handles the error; for example some exceptions 
from `StreamOffsetObserver` are checked.

## Build and Development

The project is built with [Gradle](http://gradle.org/) and uses the 
[Netflix Nebula](https://nebula-plugins.github.io/) plugins. The `./gradlew` 
wrapper script will bootstrap the right Gradle version if it's not already 
installed. 

The main client jar file is build using the shadow plugin.

The main tasks are:

- `./gradlew build` : run a build and test
- `./gradlew clean` : clean down the build 
- `./gradlew clean shadow` : builds the client jar

## Internals

The wiki page [Internals](https://github.com/dehora/nakadi-java/wiki/Internals)
has details on how the client works under the hood.

## Contributing

Please see the [issue tracker](https://github.com/zalando-incubator/nakadi-java/issues) 
for things to work on. The [help-wanted](https://github.com/zalando-incubator/nakadi-java/issues?q=is%3Aissue+is%3Aopen+label%3Aenhancement) has a list of things that would be 
pretty cool to have.

Before making a contribution, please let us know by posting a comment to the 
relevant issue. If you would like to propose a new feature, create a new issue 
first explaining the feature you’d like to contribute or bug you want to fix.

The codebase follows [Square's code style](https://github.com/square/java-code-styles) 
for Java and Android projects.

----

## License

MIT License

Copyright (c) 2016 Zalando SE, https://tech.zalando.com

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


"
nielsutrecht/jwt-angular-spring,master,357,195,2015-01-21T19:19:38Z,545,0,JSON Web Token example that integrates both a Spring backend with an AngularJS frontend.,blogs java spring spring-boot,"# JSON Web Token / AngularJS / Spring Boot example

[Blog post on this subject](http://niels.nu/blog/2015/json-web-tokens.html)

This is an example project where a Spring REST API is secured using JSON Web Tokens. Since there are relatively few examples available for Java and there are some pitfalls (such as most sources pointing to a Java lib that's not straightforward to use) I decided to extract my proof of concept into a stand-alone example and publish it for all to see.

## JSON Web Tokens

JSON Web Tokens have a few benefits over just sending a 'regular' token over the line. The more common approach to securing a REST API (outside of normal HTTP Basic Auth) is to send a random string as a token on succesful login from the server to the client. The client then sends this token on every request, and the server does an internal lookup on that token (in for example a REDIS cache or a simple Hashtable) to retrieve the corresponding user data.

With JSON Web Tokens the latter part isn't needed: the token itself contains a representation of the 'claims' of client: this can be just a username, but can also be extended to include any data you wish. This token is transmitted from the client on every request. The contents of the token are encrypted and a hash is added to prevent tampering: this way the content is secure: the server is the one signing and encrypting the token and is also the only one who had the key needed to decrypt the token. 

In this example this key is fixed (""secretkey"") but in a real life situations the secret key would simply be an array of bytes randomly generated on application startup. This has the added benefit that any tokens get automatically invalidated when you restart the service. If this behaviour is undesired you can persist the keys in for example REDIS.

## Server side: Spring Boot

I like using Spring (Boot) to create RESTful services. On the server side, the JWT signing is done in the user/login REST call in UserController. It contains a tiny 'database' of 2 users, one of which has the 'admin' rights. The verification is done in a Filter (JwtFilter): it filters every request that matches ""/api/*"". If a correct token isn't found an exception is thrown. If a correct token is found, the claims object is added to the Http Request object and can be used in any REST endpoint (as shown in ApiController).

The heavy lifting for JWT signing is done by the more than excellent [Java JWT](https://github.com/jwtk/jjwt) library.

## Client Side: AngularJS

The simple Angular app shows a login page. On successful login it checks with 'the API' which roles are available (of which the 'foo' role doesn't exist for any user).

## Running

It is a standard Maven project and can be imported into your favorite IDE. You run the example by starting the WebApplication class (it has a main) and navigating to http://localhost:8080/. If everything is correct you should see a ""Welcome to the JSON Web Token / AngularJR / Spring example!"" message and a login form.
"
bclozel/spring-resource-handling,master,132,37,2014-04-24T14:13:01Z,278,3,Spring Framework 4.1 Resource Handling example,,"Spring Resource Handling
========================

[![Build Status](https://travis-ci.org/bclozel/spring-resource-handling.svg?branch=master)](https://travis-ci.org/bclozel/spring-resource-handling)

This application demonstrates new resource handling features in Spring Framework 4.1.
It was originally developed for the talk [Resource Handling in Spring MVC 4.1](https://2014.event.springone2gx.com/schedule/sessions/resource_handling_in_spring_mvc_4_1.html) talk at SpringOne2GX 2014.


This projects requires a local install of node+npm (see [nvm](https://github.com/creationix/nvm)).

The easiest way to get started - from the project root - development version:

    SPRING_PROFILES_ACTIVE=development ./gradlew :server:bootRun
     
Or the production version (more optimizations):

    SPRING_PROFILES_ACTIVE=production ./gradlew :server:bootRun
    
Then go to:

* http://localhost:8080/ for an example with JMustache templating
* http://localhost:8080/groovy for an example with Groovy Template Engine
* http://localhost:8080/app for an example with an [HTML5 AppCache Manifest](http://www.html5rocks.com/en/tutorials/appcache/beginner/) 
(you can check this in Chrome with chrome://appcache-internals/ )
* http://localhost:8080/less for an example with a LESS stylesheet; this page uses less files and the LESS JS transpiler
in development mode, and a transpiled version in production
* http://localhost:8080/jsp for a JSP example
* http://localhost:8080/velocity for a Velocity example

Interesting parts of the application:

* [configuring resource handlers with resource resolvers and resource transformers](https://github.com/bclozel/spring-resource-handling/blob/master/server/src/main/resources/application-production.properties)
* [a sample template file using JMustache](https://github.com/bclozel/spring-resource-handling/blob/master/server/src/main/resources/mustache/index.html)
and a [custom Mustache lambdas](https://github.com/bclozel/spring-resource-handling/blob/master/server/src/main/java/org/springframework/samples/resources/support/MustacheViewResolverCustomizer.java) to resolve URLs to static resources
"
dteleguin/beercloak,master,131,28,2016-10-31T10:53:01Z,332,2,BeerCloak: a comprehensive Keycloak extension example,keycloak,"# BeerCloak: a comprehensive Keycloak extension example

BeerCloak is a collection of different techniques for building custom admin resources in Keycloak.

* `BeerEntity` JPA entity + LiquiBase changelog;
* `BeerResource` realm REST resource with CRUD operations & more;
* Authorization:
  * roles: `view-beer` and `manage-beer`;
  * automatically created for each existing realm;
  * automatically created for each newly added realm;
  * automatically included into the master `admin` role;
  * used for authorization on `BeerResource` and sub-resources;
* Event logging:
  * AdminEventBuilder instance;
  * custom resource and action types (not yet implemented)
* GUI extensions to the admin console.

The `beercloak.resources.AbstractAdminResource` is ready to be used as a base class for admin resources. It contains the code necessary to setup authorization and logging.

### Structure

`beercloak-core`: ""core"" module with some ""business logic"", to demonstrate packaging with dependencies  
`beercloak-module`: main module actually containing providers and everything (depends on `beercloak-core`)  
`beercloak-ear`: EAR packaging module to combine all the above into a deployable EAR 

## Requirements

* Keycloak 3.4.0.Final

## Build

`mvn install`

## Installation

1. Copy `beercloak-ear/target/beercloak-XXX.ear` into Keycloak's `standalone/deployments` directory.

**Warning!** While Keycloak generally supports hot deployment of providers, this is *not supported* for EntityProviders.
That means, BeerCloak shouldn't be hot (re)deployed, otherwise you'll get exceptions and non-working code.  
See [KEYCLOAK-5782](https://issues.jboss.org/browse/KEYCLOAK-5782) for more info.

2. Configure theme in your `standalone/configuration/standalone.xml`:
```xml
        <subsystem xmlns=""urn:jboss:domain:keycloak-server:1.1"">
            ...
            <theme>
                <staticMaxAge>2592000</staticMaxAge>
                <cacheThemes>true</cacheThemes>
                <cacheTemplates>true</cacheTemplates>
                <dir>${jboss.home.dir}/themes</dir>
                <!-- Here we go -->
                <modules>
                    <module>
                        deployment.beercloak
                    </module>
                </modules>
                <default>beer</default>
            </theme>
            ...
        </subsystem>
 ```
 
 You can omit `<default>beer</default>`, but then you'll have to manually choose the ""beer"" theme in realm configuration → Themes → Admin console theme.
 
(Currently, if you ship a theme inside your module, you have to configure it manually in the XML config. This may change in the future with automatic deployment of themes, you can track progress under [KEYCLOAK-4547](https://issues.jboss.org/browse/KEYCLOAK-4547))

## Running example

Run Keycloak and log into the admin console. You should be able to access the ""Beer"" menu item.
"
jfaster/mango-example,master,32,28,2014-05-01T15:37:59Z,122,8,Example of Mango Framework,,"[![Build Status](https://travis-ci.org/jfaster/mango-example.svg?branch=master)](https://travis-ci.org/jfaster/mango-example)

mango-doc示例代码"
HUPO-PSI/mzML,master,25,16,2015-09-23T14:59:17Z,6161,4,Repository for mzML and the corresponding examples,,"## mzML - Reporting Spectra Information in MS-based experiments


## General

Mass spectrometry is a popular method to analyse bio-molecules by measuring the intact mass-to-charge ratios of their in-situ generated ionised forms or the mass-to-charge ratios of in-situ-generated fragments of these ions. The resulting mass spectra are used for a variety of purposes, among which is the identification, characterization, and absolute or relative quantification of the analysed molecules. The processing steps to achieve these goals typically involve semi-automatic computational analysis of the recorded mass spectra and sometimes also of the associated metadata (e.g., elution characteristics if the instrument is coupled to a chromatography system). The result of the processing can be assigned a score, rank or confidence measure.

Differences inherent in the use of a variety of instruments, different experimental conditions under which analyses are performed, and potential automatic data preprocessing steps by the instrument software can influence the actual measurements and therefore the results after processing. Additionally, most instruments output their acquired data in a very specific and often proprietary format. These proprietary formats are then typically transformed into so-called peak lists to be analysed by identification and characterisation software. Data reduction such as peak centroiding and deisotoping is often performed during this transformation from proprietary formats to peak lists. In addition, these peak list file formats lack information about the precursor MS signals and about the associated metadata (i.e., instrument settings and description, acquisition mode, etc) compared to the files they were derived from. The peak lists are then used as inputs for subsequent analysis. The many different and often proprietary formats make integration or comparison of mass spectrometer output data difficult or impossible, and the use of the heavily processed and data-poor peak lists is often suboptimal.

This document addresses this problem with the presentation of the mzML XML format, which is designed to hold the data output of a mass spectrometer as well as a systematic description of the conditions under which this data was acquired and transformed. The following target objectives can be defined for the format:

     1- The discovery of relevant results, so that, for example, data sets in a database or public repository that use a
        particular technique or combination of techniques can be identified and studied by experimentalists during experiment
         design or data analysis.

     2- The sharing of best practice, whereby, for example, approaches that have been successful at analysing low abundance
        analytes can be captured alongside the results produced.
     
     3- The evaluation of results, whereby, for example, the number and quality of the spectra recorded from a sample can be
        assessed in the light of the experimental conditions.

     4-	The sharing of data sets, so that, for example, public repositories can import or export data, multi-site projects
        can share results to support integrated analysis, or meta-analyses can be performed by third parties from previously
        published data.
     
     5- The most comprehensive support of the instruments output, so that data can be captured in profile mode, centroid
        mode, and other relevant forms of biomolecular mass spectrometry data representation

The primary focus of the model is to support long-term archiving and sharing, rather than day-to-day laboratory management, although the model is extensible to support context-specific details.

The description of mass spectrometry data output and its experimental context requires that models include: (i) the actual data acquired, to a sufficient precision, as well as its associated metadata; and (ii) an adequate description of the instrument characteristics, its configuration and possible preprocessing steps applied. This document details both these parts, as they are required to support the tasks T1 to T5 above.
 
This document defines a specification and is not a tutorial. As such, the presentation of technical details is deliberately direct. The role of the text is to describe the schema model and justify design decisions made. This document does not provide comprehensive examples of the schema in use. Example documents are provided separately and should be examined in conjunction with this document. It is anticipated that tutorial material will be developed in the future to aid implementation. Although the present specification document describes constraints and guidelines related to the content of an mzML document as well as the availability of tools helping to read and write mzML, it does not describe any implementation constraints or specifications such as coding language or operating system for software that will generate and/or read mzML data. 

When you use mzML format, please cite the following publication:

Martens L., Chambers M., Sturm M., Kessner D., Levander F., Shofstahl J., Tang W.H., Römpp A., Neumann S., Pizarro A.D., Montecchi-Palazzi L., Tasman N., Coleman M., Reisinger F., Souda P., Hermjakob H., Binz P.A., Deutsch E.W..mzML--a community standard for mass spectrometry data. Mol Cell Proteomics. 2011 Jan;10(1):R110.000133

## Specification documents

**Version 1.1.0 (June 2014):**

  > Specification document [docx](https://github.com/HUPO-PSI/mzML/blob/master/specification_document/mzML1.1.0_specificationDocument.doc),


## Example Files
Several example of the format can be download from the next link [Examples](https://github.com/HUPO-PSI/mzML/tree/master/examples)

## Tools, Libraries, readers and exporters

1- [jmzML](http://github.com/PRIDE-UTILITIES/jmzML/): Java API for reading and writing mzML (**IMPORT AND EXPORT**) 

2- [ms-data-core-api](http://github.com/PRIDE-UTILITIES/ms-data-core-api/): Java API for reading PSI standard file formats.


"
hamen/rxjava-essentials,master,108,27,2015-11-13T11:17:48Z,77684,3,This repo is a reference for the topics and the examples in my RxJava Essentials,,"# RxJava Essentials by Ivan Morgillo

This repo is a reference for the topics and the examples in my RxJava Essentials by [Packt Publishing](http://bit.ly/rxjava-essentials).

## Slides ##

The slides provided here are free to use, but I'd like to be mentioned somehow if you use them for your talks.

## App ##

The app is the one used in the book examples. It provides a few basic scenarios for a few common RxJava operators.
"
eventuate-tram-examples/eventuate-tram-examples-micronaut-customers-and-orders,master,39,13,2019-07-09T16:00:07Z,992,10,"Microservices, Sagas, Choreography, Eventuate Tram, Micronaut",,
marcojakob/tutorial-javafx-8,master,67,36,2014-08-27T10:09:30Z,1758,0,Example Sources for JavaFX 8 Tutorial,,"# JavaFX 8 Tutorial - Sources

These are example sources for the [JavaFX 8 Tutorial](http://code.makery.ch/java/javafx-8-tutorial-intro/)."
jgasmi/jhipster-mt,master,36,20,2015-04-16T11:52:39Z,8680,2,JHipster Multitenant Example,,"README for JHipster Multitenant Example
==========================
This JHipster multi-tenant example is based on:
- Bien évidemment on JHipster: https://jhipster.github.io/
- https://www.youtube.com/watch?v=nBSHiUTHjWA
- https://code.google.com/p/ddd-cqrs-base-project/
- http://www.insaneprogramming.be/blog/2012/01/30/spring-liquibase/

You should modify the Jadira usertype version to 3.1.0.GA, because of the below bug:
        https://jadira.atlassian.net/browse/JDF-81
        
"
fengcunhan/Hotpatch-Sample,master,48,23,2015-08-03T13:52:45Z,359,2,The example of Hotpatch ,,
architjn/SharePanel,master,66,20,2017-01-31T16:03:52Z,8127,0,A small Behavior Example ,,"# SharePanel
[![API](https://img.shields.io/badge/API-15%2B-orange.svg)](https://developer.android.com/about/versions/android-4.0.3.html)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)]()

A small library to show share buttons panel with coordinatorLayout with behaviour
Library supports OS on API 15 and above.

![Showcase Video](demo.gif)

Try APK : [Download](demo.apk)

Add it in your root build.gradle at the end of repositories:

```groovy
allprojects {
	repositories {
		...
		maven { url ""https://jitpack.io"" }
	}
}
```	
and then add dependency

```groovy
dependencies {
	compile 'com.github.architjn:SharePanel:1.0'
}
```


##Usage

###XML

```xml

    <com.architjn.sharepanel.SharePanel
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        app:app_layout_anchor=""@id/collapsing_toolbar""
        app:app_layout_anchorGravity=""bottom|right|end"">

        <LinearLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content"">
	    <!-- Your Images Here -->
            <com.varunest.sparkbutton.SparkButton
                android:id=""@+id/twitter_button""
                android:layout_width=""50dp""
                android:layout_height=""50dp""
                app:sparkbutton_activeImage=""@drawable/ic_twitter""
                app:sparkbutton_iconSize=""20dp""
                app:sparkbutton_primaryColor=""@color/twitter_primary_color""
                app:sparkbutton_secondaryColor=""@color/twitter_secondary_color"" />

            <com.varunest.sparkbutton.SparkButton
                android:id=""@+id/fb_button""
                android:layout_width=""50dp""
                android:layout_height=""50dp""
                app:sparkbutton_activeImage=""@drawable/ic_facebook""
                app:sparkbutton_iconSize=""20dp""
                app:sparkbutton_primaryColor=""@color/fb_primary_color""
                app:sparkbutton_secondaryColor=""@color/fb_secondary_color"" />
        </LinearLayout>
    </com.architjn.sharepanel.SharePanel>
```
##Buttons Used
SparkButton : [https://github.com/varunest/SparkButton](https://github.com/varunest/SparkButton)


##License
Library falls under [Apache 2.0] (LICENSE.md)

"
Jaouan/Carousel-Browsing-Example,master,281,33,2016-08-22T11:08:38Z,6081,0,It's just an example of carousel browsing.,,"Android - Carousel browsing example
========

It's just an example of carousel browsing, a bit inspired by [Frank Lau's animation](https://dribbble.com/shots/2906536-animation).

![demo](art/demo.gif)


License
========

[Apache License Version 2.0](LICENSE)"
indrabasak/spring-gateway-example,master,37,25,2019-09-01T05:30:57Z,1100,0,Spring Cloud Gateway Example,auth0-jwt oauth2-authentication okta spring-cloud-gateway,"[![Build Status][travis-badge]][travis-badge-url]
[![Quality Gate][sonarqube-badge]][sonarqube-badge-url] 
[![Technical debt ratio][technical-debt-ratio-badge]][technical-debt-ratio-badge-url] 
[![Coverage][coverage-badge]][coverage-badge-url]

![](./img/spring-cloud-gateway.svg)
 
Spring Cloud Gateway Example 
==============================
This project is example of using [Spring Cloud Gateway](https://spring.io/projects/spring-cloud-gateway) as an edge 
service with a Spring Boot application. Spring Cloud Gateway provides means for routing an incoming request to a 
matching downstream service.

Gateway is a suitable replacement for [Spring Cloud Netflix Zuul](https://spring.io/projects/spring-cloud-netflix) since 
the latter module is now in maintenance mode starting Spring Cloud Greenwich (2.1.0) release train. Spring Cloud will 
continue to support Zuul for a period of at least a year from the general availability of the Greenwich release train. 
Putting a module in the maintenance mode means that the Spring Cloud will no longer add any new feature but will fix 
blocker bugs and security issues.

## Introduction
  - A **route** is the fundamental concept of Spring Cloud Gateway framework. A route contains a destination URL and a
collection of predicates and filters. An request is forwarded to a route if the result of logical _AND_ operation on 
all its predicates is _true_.

  - A **predicate** is boolean valued function.
  
  - A **filter** provides a way of modifying incoming HTTP requests and outgoing HTTP responses.

### A Route Example
Here's a simple example of a route used in this project,

```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: book-id
          uri: http://localhost:8080
          predicates:
            - Path=/books/**
          filters:
            - PrefixPath=/public
            - AddRequestHeader=X-Request-Foo, Bar
            - AddRequestTimeHeaderPreFilter
            - AddResponseHeader=X-Response-Bye, Bye
            - AddResponseTimeHeaderPostFilter
```

## Project Synopsis 

This example project consists of two modules:
  - A **book-service** is a Spring Boot based REST service which provides creation and retrieval operation on a book 
  resource. It uses Basic Auth for authentication.
  
  - An **edge-service** is a Spring Cloud Gateway and Spring Boot based Edge service. It routes incoming requests to the 
  backend book service. It uses both Basic Auth and OAuth2 for authenticating a request. Once the request is authenticated, 
  it forwards the request to the book service after replacing the authorization header with book service's basic 
  auth credentials. 
  
Here is the flow of an incoming request and outgoing response in the example edge service.

![](./img/gateway-example-flow-2.png)

### Types of Filter
Gateway filters can be classified into 3 groups:
  
  - **Global Filters**: They are special filters that are conditionally applied to all routes. A good use of a global
    filter can be authentication of an incoming request. Here are the global filters used in this example:
    
    - **Authorization Filter**: A custom filter for authenticating a request. Authentication can be Basic Auth or OAuth2.
    
    - **Basic Auth Token Relay Filter**: A custom filter whi h replaces the authorization header with basic auth credentials 
    specific to a route.
    
  - **Pre Filters**: These filters are applied to incoming requests and are usually specific to a route. Here are the 
  pre filters used in this example:
  
    - **Prefix Filter**: A built-in filter which adds a prefix to the incoming request before being forwarded.
    
    - **Add Request Header Filter**: A built-in filter which adds a header to the incoming request before being forwarded.
    
    - **Add Request Time Header Pre Filter**: A custom filter which add a timestamp header to the incoming request before being forwarded.
  
  - **Post Filters**: These filters are applied to outgoing request and are usually specific to a route. Here are the 
  post filters used in this example:
  
    - **Add Response Header Filter**: A built-in filter which adds a header to the outgoing response.
      
    - **Add Response Time Header Post Filter**: A custom filter which add a timestamp header to the outgoing response.
  
  
## Security
This example didn't use Spring Security framework directly as typically used in a Spring Boot application by configuring the
 service. However, it took advantage of the classes provided in the Spring Security libraries to come up with a custom security
 framework. This example uses both **Basic Authentication** and **OAuth 2.0** for authentication. 
 
### Basic Authentication
The basic authorization credentials are configured using `security.auth.user` and `security.auth.password` in the 
 `application.yml`.
 
### OAuth2 Authentication
The OAuth2 uses `JSON Web Token` (`JWT`) for authentication. The client of the Edge service uses `Client Credentials` 
grant type to obtain an access token from an auth server. In this example, we used Auth0 server and Okta server for 
obtaining an access token.
                                                         
#### Auth0 Authorization Server                                                      
Here's an example to obtain an access token from an `Auth0` server:

```
curl --request POST \
  --url https://ibasak.auth0.com/oauth/token \
  --header 'content-type: application/json' \
  --data '{
	""client_id"":""yHJiJecLn3bd8A2oummRa08jp9t0y1UL"",
	""client_secret"":""YAeV4cYudc2Gyro6sR416-ehmiyxnJc7ErLDwDxNDaBmvGgCu1Y8hyG6Sa-tyfAY"",
	""audience"":""https://quickstarts/api"",
	""grant_type"":""client_credentials""
}'
```

A response usually looks something similar to this:

```json
{
  ""access_token"": ""eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IlEwWXlRVGMyTWpGRVJEQXhOa0ZHTVRGQlJqZzJNRVZGTUVFd01UZENOREV6TmpJd1JqTTFOQSJ9.eyJpc3MiOiJodHRwczovL2liYXNhay5hdXRoMC5jb20vIiwic3ViIjoieUhKaUplY0xuM2JkOEEyb3VtbVJhMDhqcDl0MHkxVUxAY2xpZW50cyIsImF1ZCI6Imh0dHBzOi8vcXVpY2tzdGFydHMvYXBpIiwiaWF0IjoxNTY3Nzg5MDQ2LCJleHAiOjE1Njc4NzU0NDYsImF6cCI6InlISmlKZWNMbjNiZDhBMm91bW1SYTA4anA5dDB5MVVMIiwiZ3R5IjoiY2xpZW50LWNyZWRlbnRpYWxzIn0.aFzEvDwsNvUge5yAkzLJfrlpjtxffO2M7V0q0sGF9udi99KVEK3vQ2KXZm_N7v-ASrm-LF7twgPzdiln6tVMWkGtvFmpKx2YQwmXsEDYZGfrHOwb5XjY2AF8eXXsiJQEyI_SOSb-CzoAxFL34eIPeFa77zR6nmcIZAJyCdTtrMd1S4XIENPW1aWvwK5BVqFk6VpJ33LdemQYthQkNMYJF_v8dgXHbqSIAkdOfg4CUKXRObABTc4LnARMiFGFa-c2aQBMj1vP6PRE7h41Fr6MTHkUSVfFFayyVUFI3mH3tfiNHTqQiUZIpNJNknRYCTXDJq2V4mLgWfH9BFjelP65dg"",
  ""expires_in"": 86400,
  ""token_type"": ""Bearer""
}
```

You need to configure the `application.yml` before using the `Auth0` JWT. You have to set the following properties:

```yaml
spring:
  security:
    oauth2:
      resourceserver:
        jwt:
          issuer-uri: https://ibasak.auth0.com/
          audience: https://quickstarts/api
```

#### Okta Authorization Server                                                      
Here's an example to obtain an access token from an `Okta` server:

```
curl --request POST \
  --url https://dev-461512.okta.com/oauth2/default/v1/token \
  --header 'accept: application/json' \
  --header 'authorization: Basic MG9hMWFhMXI0MzB3NEFLajczNTc6b0gwOTB0RlZFVG5iV0o4eElQX3BMOXV6SWRmV2h0MWNISjdWb1d0VQ==' \
  --header 'cache-control: no-cache' \
  --header 'content-type: application/x-www-form-urlencoded' \
  --data grant_type=client_credentials \
  --data scope=customScope
```

A response usually looks something similar to this:

```json
{
  ""token_type"":""Bearer"",
  ""expires_in"":3600,
  ""access_token"":""eyJraWQiOiItM1N6UVhjWDNYc0lFMmNOSnZ6NGRZRzBZemdXVS1Od091THpxYmZ1cWQ0IiwiYWxnIjoiUlMyNTYifQ.eyJ2ZXIiOjEsImp0aSI6IkFULkluNHlfNVJQd0N4eHBURkVmVThGRERiSEQyZHF6Q1RiNjBreGxPaDhpMjgiLCJpc3MiOiJodHRwczovL2Rldi00NjE1MTIub2t0YS5jb20vb2F1dGgyL2RlZmF1bHQiLCJhdWQiOiJhcGk6Ly9kZWZhdWx0IiwiaWF0IjoxNTY3ODA2OTk0LCJleHAiOjE1Njc4MTA1OTQsImNpZCI6IjBvYTFhYTFyNDMwdzRBS2o3MzU3Iiwic2NwIjpbImN1c3RvbVNjb3BlIl0sInN1YiI6IjBvYTFhYTFyNDMwdzRBS2o3MzU3IiwiQ2xhaW0xIjpmYWxzZX0.TShTVtfRp8wU39NY40KpTo1PCLB8N2x3kuVdkgJVYvU5zd5yBkz3RZZLksqsWQEfirAKduBdSkF4aMQhBUo3tdDYefQ6TNqnun_Ung1f3TdUAalyqeUgpGGlbN2J93jv-djtF5O7ylElpKqvwXhZcwXhJb1HPJqLB_LP0XtaxDb5R8uPP56IhE6JEC8PCIvpMOM0gr9mYsJWxwTe-tVd5NHUTSIaDBtMCsFbcx8MkG6YXN0N-B1ZsyZJMHBA8nwWk1Fx7EbIyxTmpUQdnBmwP-YM1XNCvBZQkX9BhId6YnaAjmLhJ_SQB1VWew28oAHpeax9Lkj-R49rzqxsjcTvVA"",
  ""scope"":""customScope""
}
```

You need to configure the `application.yml` before using the `Okta` JWT. You have to set the following properties:

```yaml
spring:
  security:
    oauth2:
      resourceserver:
        jwt:
          issuer-uri: https://dev-461512.okta.com/oauth2/default
          audience: api://default
```

## [Build]
To build the Spring JArs and as well as docker images, execute `mvn clean install` command from the parent directory:

```bash
$ mvn clean install
[INFO] Scanning for projects...
[INFO] 
[INFO] ----------------------< com.basaki:edge-service >-----------------------
[INFO] Building edge-service 1.0.0
[INFO] --------------------------------[ jar ]---------------------------------
Downloading from iovation.central: https://maven.iovationnp.com/repository/public/net/minidev/json-smart/maven-metadata.xml
Downloading from maven-central: http://repo1.maven.org/maven2/net/minidev/json-smart/maven-metadata.xml
Downloaded from maven-central: http://repo1.maven.org/maven2/net/minidev/json-smart/maven-metadata.xml (849 B at 3.6 kB/s)
Downloaded from iovation.central: https://maven.iovationnp.com/repository/public/net/minidev/json-smart/maven-metadata.xml (895 B at 642 B/s)
[WARNING] The POM for com.sun.xml.bind:jaxb-osgi:jar:2.2.10 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ edge-service ---
[INFO] Deleting /Users/jdoe/examples/spring-gateway-example/edge-service/target

...
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  19.569 s
[INFO] Finished at: 2019-09-06T15:04:05-07:00
[INFO] ------------------------------------------------------------------------
```

If the build is successful, it should create the following:

  - Spring Boot Jars
  
    - `edge-service-1.0.0.jar`
    
    - `book-service-1.0.0.jar`
  
  - Docker Images
  
    - `basaki/spring-gateway-edge:1.0.0 ` 
    
    - `basaki/spring-gateway-book:1.0.0` 
    
 You can list all the docker images in your computer by typing `docker images` command.
 
 ```
REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE
basaki/spring-gateway-edge           1.0.0               000e04f2ae53        2 minutes ago       530MB
basaki/spring-gateway-book           1.0.0               c27215b6c3b3        3 days ago          564MB

```

## Starting Applications
You can start both the applications from the terminal by typing the following command:

```yaml
java -jar edge-service-1.0.0.jar
```

The edge service should start up at port `9080`

```
java -jar book-service-1.0.0.jar
```

The book service should start up  at port `8080`


## Usage

### Basic Authentication
To create a book using basic authentication:

```
curl --request POST \
  --url http://localhost:9080/books \
  --header 'authorization: Basic amRvZTpoZWxsbw==' \
  --header 'content-type: application/json' \
  --data '{
  ""title"": ""Indra"",
  ""author"": ""Indra'\''s Chronicle""
}'
```

### OAuth2 Authentication

```
curl --request POST \
  --url http://localhost:9080/books \
  --header 'authorization: Bearer eyJraWQiOiItM1N6UVhjWDNYc0lFMmNOSnZ6NGRZRzBZemdXVS1Od091THpxYmZ1cWQ0IiwiYWxnIjoiUlMyNTYifQ.eyJ2ZXIiOjEsImp0aSI6IkFULmFIVU5iUHkyU0ZVN1NlOEF2VE5kOGtSQlBvdy1CSGVyQmo2VGZfcENfR2siLCJpc3MiOiJodHRwczovL2Rldi00NjE1MTIub2t0YS5jb20vb2F1dGgyL2RlZmF1bHQiLCJhdWQiOiJhcGk6Ly9kZWZhdWx0IiwiaWF0IjoxNTY3NjQxODYyLCJleHAiOjE1Njc2NDU0NjIsImNpZCI6IjBvYTFhYTFyNDMwdzRBS2o3MzU3Iiwic2NwIjpbImN1c3RvbVNjb3BlIl0sInN1YiI6IjBvYTFhYTFyNDMwdzRBS2o3MzU3IiwiQ2xhaW0xIjpmYWxzZX0.cxKztd_NIOBBHDoC0h6LFYUDCeevc_-DQrrUMrJ9K5tKKuzqtSJoVMCWcmreypsGf6fD7UTFX74FduVnR4sKShzvmB6PsrzGon0AOiJFJPvYYwUEl97sIGENbUHkkufcNubdTMk2D2OrHvdsxMk8f6vnB0min_X1d1tK1kCd5Pd0c-388soWSjfE_mjvYosqZFmRUR8e-MBBP2ZDp5wrP_rmqWEhze7uSk08KS6N9j3R2mZzUTjtNmX7Jf1KbvtFtsAlY_HvSSahf0dUDnwNeMaRrVeTJt5nToaa85Po44P1oKx4f9o3nAvkMO-OiU3PNFt7TlfT8MHt3nnoeupC_g' \
  --header 'content-type: application/json' \
  --data '{
  ""title"": ""Indra"",
  ""author"": ""Indra'\''s Chronicle""
}'
```

Your response should look like this:

```json
{
  ""id"": ""d4c962fe-386d-4344-a2f4-6209dfac9382"",
  ""title"": ""Indra"",
  ""author"": ""Indra's Chronicle""
}
```

## Deploying in Kubernetes Cluster
Scripts for deploying the `book service` are located in `book-service/src/docker` folder while the scripts for the
`edge service` are located in `edge-service/src/docker` folder.

### Deploying Book Service

#### Create Namespace
```
$ kubectl create -f book-service/src/docker/namespace.yml 
namespace/gateway-example created
```

#### Create Config Map
```
k$ kubectl create -f book-service/src/docker/config.yml 
configmap/spring-gateway-book-config created
```

#### Create Deployment
```
$ kubectl create -f book-service/src/docker/deployment.yml 
deployment.apps/spring-gateway-book created
```

#### Create Service
```
$ kubectl create -f book-service/src/docker/service.yml 
service/spring-gateway-book-service created
```

If the book service is deployed successfully, you can access it at `http://localhost:30080/public/books`

### Deploying Edge Service
You can skip the namespace creation as it's already created in the earlier step.

#### Create Config Map
```
k$ kubectl create -f edge-service/src/docker/config.yml 
configmap/spring-gateway-edge-config created
```

#### Create Deployment
```
$ kubectl create -f edge-service/src/docker/deployment.yml 
deployment.apps/spring-gateway-edge created
```

#### Create Service
```
$ kubectl create -f edge-service/src/docker/service.yml 
service/spring-gateway-edge-service created
```

If the edge service is deployed successfully, you can access it at `http://localhost:31080/books`

[travis-badge]: https://travis-ci.org/indrabasak/spring-gateway-example.svg?branch=master
[travis-badge-url]: https://travis-ci.org/indrabasak/spring-gateway-example/

[sonarqube-badge]: https://sonarcloud.io/api/project_badges/measure?project=com.basaki%3Aspring-gateway-example&metric=alert_status
[sonarqube-badge-url]: https://sonarcloud.io/dashboard/index/com.basaki:spring-gateway-example

[technical-debt-ratio-badge]: https://sonarcloud.io/api/project_badges/measure?project=com.basaki%3Aspring-gateway-example&metric=sqale_index
[technical-debt-ratio-badge-url]: https://sonarcloud.io/dashboard/index/com.basaki:spring-gateway-example

[coverage-badge]: https://sonarcloud.io/api/project_badges/measure?project=com.basaki%3Aspring-gateway-example&metric=coverage
[coverage-badge-url]: https://sonarcloud.io/dashboard/index/com.basaki:spring-gateway-example

"
varvet/BarcodeReaderSample,master,68,62,2016-08-09T13:41:02Z,113,2,A barcode scanner example using Google Play services. ,,"# BarcodeReaderSample
A barcode scanner example using Google Play services.

[This tutorial](https://www.varvet.com/blog/android-qr-code-reader-made-easy/) should be of interest :). 
"
alejandro-du/vaadin-microservices-demo,master,125,62,2016-11-02T23:16:16Z,966,12,A microservices example developed with Spring Cloud and Vaadin,demo eureka fault-tolerance high-availability java load-balancing microservice netflix-ribbon spring-boot vaadin zuul,"# Microservices with Vaadin demo

A microservices demo implemented with [Spring Cloud Netflix](http://cloud.spring.io/spring-cloud-netflix/) and [Vaadin](https://vaadin.com).

If you are using Vaadin 8, checkout the [vaadin-8](https://github.com/alejandro-du/vaadin-microservices-demo/tree/vaadin-8) branch. 

## Building the demo

Run the following from the command line:
```
git clone https://github.com/alejandro-du/vaadin-microservices-demo.git
cd vaadin-microservices-demo
mvn package
```

## Running the demo

Use multiple (seven) terminals to perform the following steps:

**1) Start the `discovery-server` application (Eureka app):**
```
cd vaadin-microservices-demo/discovery-server
java -jar target/discovery-server-0.0.1-SNAPSHOT.jar
```

**2) Start the `config-server` application (Spring Cloud Config app):**
```
cd vaadin-microservices-demo/config-server
java -jar target/config-server-0.0.1-SNAPSHOT.jar
```

**3) Start an instance of the `biz-application` microservice (REST app):**
```
cd vaadin-microservices-demo/biz-application
java -jar target/biz-application-0.0.1-SNAPSHOT.jar
```

**4) Start an instance of the `admin-application` microservice (Vaadin app):**
```
cd vaadin-microservices-demo/admin-application
java -jar target/admin-application-0.0.1-SNAPSHOT.jar
```

**5) Start an instance of the `news-application` microservice (Vaadin app):**
```
cd vaadin-microservices-demo/news-application
java -jar target/news-application-0.0.1-SNAPSHOT.jar
```

**6) Start an instance of the `website-application` microservice (Vaadin app):**
```
cd vaadin-microservices-demo/website-application
java -jar target/website-application-0.0.1-SNAPSHOT.jar
```

**7) Start the `proxy-server` application (Zuul app):**
```
cd vaadin-microservices-demo/proxy-server
java -jar target/proxy-server-0.0.1-SNAPSHOT.jar
```

## Using the demo

**1) Point your browser to <http://localhost:8080>.**

You'll see the `website-application` embedding the `admin-application` and the `news-application` microservices.

This is the ""edge service"" implemented with Netflix Zuul. It acts as a reverse proxy, redirecting requests to the `website-application`, `news-application`, and `admin-application` instances using a load balancer provided by Netflix Ribbon with a _round robin_ strategy.

If you get a ""Server not available"" message, please wait until all the services are registered with the `discovery-server` (implemented with Netflix Eureka).

**2) Add, update, or delete data.**

Latest tweets from the companies you enter on the left (the `admin-application`) will be rendered on the right (the `news-application`).

The `admin-application`, and `news-application` instances (implemented with Vaadin) delegate CRUD operations to the `biz-application` (implemented with Spring Data Rest) using a load balancer (provided by Netflix Ribbon) with a _round robin_ strategy.

**3) Add microservice instances.**

You can horizontally scale the system by starting more instances of the `biz-application`, `admin-application`, `news-application`, and `website-application` microservices. Remember to specify an available port (using `-Dserver.port=NNNN`) when you start a new instance.

**4) Test high-availability.**

Make sure you are running two instances of the `admin-application`. Click the _+_ (Add) button and enter `Vaadin`
as the _name_, and `vaadin` as the _Twitter Username_. Don't click the _Add_ button yet.

Stop one of the instances of the `admin-application` and click the _Add_ button. The web application should remain functional and save the data you entered without losing the state of the UI thanks to the externalized HTTP Session (implemented with Spring Session and Hazelcast).

**5) Test system resilience.**

Stop all the instances of the `biz-application` microservice and refresh the browser to see the fallback mechanisms (implemented with Netflix Hystrix) in the `admin-application` and `news-application` microservices.

## Developing

You don't need to have all the infrastructure services running (`discovery-server`, `config-server`, and `proxy-server`) in order to develop individual microservices (`biz-application`, `admin-application`, `news-application`, and `website-application`). Activate the `development` Spring profile to use a local configuration (`application-development.properties`) that excludes external orchestration services.

For example, during development you can run the `biz-application` microservice using:

```
cd vaadin-microservices-demo/biz-application
java -Dspring.profiles.active=development -jar target/biz-application-0.0.1-SNAPSHOT.jar
```

With the `admin-application`, and `news-application` you need the REST web-service provided by the `biz-application`. You can either, run the `biz-application` in `development` mode or create a _mock_ REST web service. You can configure the end point with the `biz-application.url` property in the `application-development.properties`.
"
openjfx/samples,master,564,1525,2018-11-02T10:44:22Z,582,32,JavaFX samples to run with different options and build tools,documentation eclipse examples gradle ide intellij java java-11 java-12 javafx javafx-11 javafx-12 maven modular netbeans non-modular openjfx,"OpenJFX Docs Samples
===



Description
---

This repository contains a collection of HelloFX samples. Each one is a very simple 
HelloWorld sample created with JavaFX that can be run with different options and build tools.

The related documentation for each sample can be found [here](https://openjfx.io/openjfx-docs/).

For more information go to https://openjfx.io.



Content
---

* [HelloFX samples](#HelloFX-Samples)
* [Command Line](#Command-Line)
    - [_Modular samples_](#CLI-Modular-Samples)
    - [_Non-modular samples_](#CLI-Non-Modular-Samples)
* [IDEs](#IDEs)
    - [IntelliJ](#IntelliJ)  
      [_Modular samples_](#IntelliJ-Modular-Samples)  
      [_Non-modular samples_](#IntelliJ-Non-Modular-Samples)
    - [NetBeans](#NetBeans)  
      [_Modular samples_](#NetBeans-Modular-Samples)  
      [_Non-modular samples_](#NetBeans-Non-Modular-Samples)
    - [Eclipse](#Eclipse)  
      [_Modular samples_](#Eclipse-Modular-Samples)  
      [_Non-modular samples_](#Eclipse-Non-Modular-Samples)
    - [Visual Studio Code](#VSCode)  
      [_Modular samples_](#VSCode-Modular-Samples)  
      [_Non-modular samples_](#VSCode-Non-Modular-Samples)
* [License](#License)
* [Contributing](#Contributing)



HelloFX samples<a name=""HelloFX-Samples"" />
---

Contains samples of a simple HelloFX class that can be run from command line, with 
or without build tools.

Build Tool | Sample | Description
---------- | ------ | -----------
None | [HelloFX project](HelloFX/CLI) | Simple HelloFX class to run on command line.
Maven | [HelloFX project](HelloFX/Maven) | Simple HelloFX class to run with Maven.
Gradle | [HelloFX project](HelloFX/Gradle) | Simple HelloFX class to run with Gradle.



Command Line<a name=""Command-Line"" />
---

Contains samples of modular and non-modular projects that can be run from command 
line, with or without build tools.

### _Modular samples_<a name=""CLI-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
None | [HelloFX project](CommandLine/Modular/CLI) | Modular project to run on command line.
Maven | [HelloFX project](CommandLine/Modular/Maven) | Modular project to run with Maven.
Gradle | [HelloFX project](CommandLine/Modular/Gradle) |  Modular project to run with Gradle.

### _Non-modular samples_<a name=""CLI-Non-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
None | [HelloFX project](CommandLine/Non-modular/CLI) | Non-modular project to run on command line.
Maven | [HelloFX project](CommandLine/Non-modular/Maven) | Non-modular project to run with Maven.
Gradle | [HelloFX project](CommandLine/Non-modular/Gradle) | Non-modular project to run with Gradle.



IDEs<a name=""IDEs"" />
---

Contains samples of modular and non-modular projects that can be run from an IDE, 
with or without build tools.

### IntelliJ<a name=""IntelliJ"" />

#### _Modular samples_<a name=""IntelliJ-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/IntelliJ/Modular/Java) | Modular project to run from IntelliJ.
Maven | [HelloFX project](IDE/IntelliJ/Modular/Maven) | Modular project to run from IntelliJ, with Maven.
Gradle | [HelloFX project](IDE/IntelliJ/Modular/Gradle) | modular project to run from IntelliJ, with Gradle.

#### _Non-modular samples_<a name=""IntelliJ-Non-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/IntelliJ/Non-Modular/Java) | Non-modular project to run from IntelliJ.
Maven | [HelloFX project](IDE/IntelliJ/Non-Modular/Maven) | Non-modular project to run from IntelliJ, with Maven.
Gradle | [HelloFX project](IDE/IntelliJ/Non-Modular/Gradle) | Non-modular project to run from IntelliJ, with Gradle.


### NetBeans<a name=""NetBeans"" />

#### _Modular samples_<a name=""NetBeans-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/NetBeans/Modular/Java) | Modular project to run from NetBeans.
Maven | [HelloFX project](IDE/NetBeans/Modular/Maven) | Modular project to run from NetBeans, with Maven.
Gradle | [HelloFX project](IDE/NetBeans/Modular/Gradle) | Modular project to run from NetBeans, with Gradle.

#### _Non-modular samples_<a name=""NetBeans-Non-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/NetBeans/Non-Modular/Java) | Non-modular project to run from NetBeans.
Maven | [HelloFX project](IDE/NetBeans/Non-Modular/Maven) | Non-modular project to run from NetBeans, with Maven.
Gradle | [HelloFX project](IDE/NetBeans/Non-Modular/Gradle) | Non-modular project to run from NetBeans, with Gradle.


### Eclipse<a name=""Eclipse"" />

#### _Modular samples_<a name=""Eclipse-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/Eclipse/Modular/Java) | Modular project to run from Eclipse.
Maven | [HelloFX project](IDE/Eclipse/Modular/Maven) | Modular project to run from Eclipse, with Maven.
Gradle | [HelloFX project](IDE/Eclipse/Modular/Gradle) | Modular project to run from Eclipse, with Gradle.

#### _Non-modular samples_<a name=""Eclipse-Non-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/Eclipse/Non-Modular/Java) | Non-modular project to run from Eclipse.
Maven | [HelloFX project](IDE/Eclipse/Non-Modular/Maven) | Non-modular project to run from Eclipse, with Maven.
Gradle | [HelloFX project](IDE/Eclipse/Non-Modular/Gradle) | Non-modular project to run from Eclipse, with Gradle.


### Visual Studio Code<a name=""VSCode"" />

#### _Modular samples_<a name=""VSCode-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Maven | [HelloFX project](IDE/VSCode/Modular/Maven) | Modular project to run from Visual Studio Code, with Maven.
Gradle | [HelloFX project](IDE/VSCode/Modular/Gradle) | Modular project to run from Visual Studio Code, with Gradle.

#### _Non-modular samples_<a name=""VSCode-Non-Modular-Samples"" />

Build Tool | Sample | Description
---------- | ------ | -----------
Java | [HelloFX project](IDE/VSCode/Non-Modular/Java) | Non-modular project to run from Visual Studio Code.
Maven | [HelloFX project](IDE/VSCode/Non-Modular/Maven) | Non-modular project to run from Visual Studio Code, with Maven.
Gradle | [HelloFX project](IDE/VSCode/Non-Modular/Gradle) | Non-modular project to run from Visual Studio Code, with Gradle.



License<a name=""License"" />
---

This project is licensed under [BSD 3-Clause](LICENSE).


Contributing<a name=""Contributing"" />
---

This project welcomes all types of contributions and suggestions. 
We encourage you to report issues, create suggestions and submit 
pull requests.

Contributions can be submitted via [pull requests](https://github.com/openjfx/samples/pulls/), 
providing you have signed the [Gluon Individual Contributor License Agreement (CLA)](https://docs.google.com/forms/d/16aoFTmzs8lZTfiyrEm8YgMqMYaGQl0J8wA0VJE2LCCY).

Please go through the [list of issues](https://github.com/openjfx/samples/issues) 
to make sure that you are not duplicating an issue.
"
dataArtisans/kafka-example,master,55,62,2015-09-02T12:13:09Z,115,1,Simple example for reading and writing into Kafka,,"# kafka-example
Simple example for reading and writing into Kafka


# Set up Kafka

```bash
#get kafka
wget http://mirror.softaculous.com/apache//kafka/0.8.2.1/kafka_2.10-0.8.2.1.tgz
# unpack
tar xf kafka_2.10-0.8.2.1.tgz
cd kafka_2.10-0.8.2.1

# start zookeeper server
./bin/zookeeper-server-start.sh ./config/zookeeper.properties

# start broker
./bin/kafka-server-start.sh ./config/server.properties 

# create topic “test”
 ./bin/kafka-topics.sh --create --topic test --zookeeper localhost:2181 --partitions 1 --replication-factor 1

# consume from the topic using the console producer
./bin/kafka-console-consumer.sh --topic test --zookeeper localhost:2181

# produce something into the topic (write something and hit enter)
./bin/kafka-console-producer.sh --topic test --broker-list localhost:9092
```

Watch this YouTube video to see how this code is working with Kafka: https://www.youtube.com/watch?v=7RPQUsy4qOM
"
la-team/lightadmin-springboot,master,59,35,2014-09-10T15:31:58Z,228,6,LightAdmin and Spring Boot integration example,,"LightAdmin and Spring Boot integration example

This application is a usual spring-boot application, where lightadmin was added.
Applying this to your own, existent project/applications means:

* add lightadmin, tomcat and jasper to your pom
* add some lightadmin init code in (or around) your main code

It is really trivial.

Note: the ideal (and spring-boot like) solution would be to simply add a
`spring-boot-starter-lightadmin` to your POM. We are aware of this, but it's not
yet implemented.
"
jmgarridopaz/bluezone,master,114,25,2020-05-05T06:37:15Z,12434,2,An example application implementing Hexagonal Architecture,hexagonal-architecture java modules,"# BlueZone
## An example application implementing Hexagonal Architecture

See the article series: [https://jmgarridopaz.github.io/content/hexagonalarchitecture-ig/intro.html]

![BlueZone: Hexagonal Application Figure](bluezone.png)

__BlueZone__ allows car drivers to pay remotely for parking cars at zones in a city, instead of paying with coins using parking meters.

- Users (driver actors) of the application are _car drivers_ and _parking inspectors_.

  - Car drivers will access the application using a Web UI (User Interface), and they can do the following:
    
    - Query all the available rates in the city, in order to choose the one of the zone he wants to park the at.
    - Purchase a parking ticket, paying an amount of money for parking a car at a zone, during a period of time. This period starts at current date-time. The ending date-time is calculated from the paid amount, according to the rate of the zone.

  - Parking inspectors will access the application using a terminal with a CLI (Command Line Interface), and they can do the following:
  
    - Check whether a car is illegally parked at a zone. This will happen if there is no valid ticket for the car and the rate of the zone. A ticket is valid if current date-time is between the starting and ending date-time of the ticket period.
    
- Driven actors needed by the application are: a rate repository, a ticket repository, and a payment service.

### Development environment:

- Java 11 (version ""11.0.15.1"" 2022-04-22 LTS)

- Maven 3.8.6

- IntelliJ IDEA 2021.3.3 (Community Edition)

- Ubuntu 20.04.4 LTS (Linux 5.13.0-40-generic)

### Instructions:

- Download and extract this github repo to a local directory on your computer ( `<bluezone_dir>` )

- Compile all modules (you need to do this just the first time before running):

    ~~~
    cd <bluezone_dir>
    ./scripts/build.sh
    ~~~

- Select the adapters to be plugged-in at each port, editing the ""ports-adapters.properties"" file, located in the ""<bluezone_dir>/scripts"" directory.


- Run the entry point to the app:

    ~~~
    cd <bluezone_dir>
    ./scripts/run_bluezone.sh
    ~~~
"
vladimirvivien/workbench,master,32,20,2011-10-07T09:14:37Z,440,1,"My code collection for testing new ideas, blog examples, etc",,
tomsquest/java-agent-asm-javassist-sample,master,56,36,2014-01-30T13:43:13Z,132,0,Sample maven project containing a Java agent and examples of bytecode manipulation with ASM and Javassist,,"# Sample Java Agent and Bytecode manipulation 

Sample maven project containing a Java agent and examples of bytecode manipulation with ASM and Javassist.

See article on my blog : http://tomsquest.com/blog/2014/01/intro-java-agent-and-bytecode-manipulation/


## Build

```
$ # From the root dir
$ mvn package
```

## Run

```
$ # From the root dir
$ java -javaagent:agent/target/agent-0.1-SNAPSHOT.jar -jar other/target/other-0.1-SNAPSHOT.jar
```
"
gemiusz/gatling-examples-maven-java,master,30,8,2022-08-06T23:14:54Z,172,2,GeMi Gatling Examples in JAVA,gatling gatling-maven-plugin java load-testing maven performance-testing,"GeMi Gatling Examples in JAVA [![Build Status](https://github.com/gemiusz/gatling-examples-maven-java/actions/workflows//gatling_test_all_mine_after_push.yml/badge.svg?branch=master)](https://github.com/gemiusz/gatling-examples-maven-java/actions/workflows/gatling_test_all_mine_after_push.yml?query=branch%3Amaster)
============================================

Gatling project in JAVA 21 showing working examples and solutions - Inspired by [Gatling Community](https://community.gatling.io)
<br><br>

It includes:
* [Maven Wrapper](https://maven.apache.org/wrapper/), so that you can immediately run Maven with `./mvnw` without having
  to install it on your computer
* minimal `pom.xml`
* latest version of `io.gatling.highcharts:gatling-charts-highcharts`applied - [Maven Central Repository Search](https://search.maven.org/artifact/io.gatling.highcharts/gatling-charts-highcharts)
* latest version of `io.gatling:gatling-maven-plugin` applied - [Maven Central Repository Search](https://search.maven.org/artifact/io.gatling/gatling-maven-plugin)
* official examples: [ComputerDatabaseSimulation](src/test/java/computerdatabase/ComputerDatabaseSimulation.java), [BasicSimulation](src/test/java/computerdatabase/BasicSimulation.java), [AdvancedSimulationStep01](src/test/java/computerdatabase/advanced/AdvancedSimulationStep01.java), [AdvancedSimulationStep02](src/test/java/computerdatabase/advanced/AdvancedSimulationStep02.java), [AdvancedSimulationStep03](src/test/java/computerdatabase/advanced/AdvancedSimulationStep03.java), [AdvancedSimulationStep04](src/test/java/computerdatabase/advanced/AdvancedSimulationStep04.java), [AdvancedSimulationStep05](src/test/java/computerdatabase/advanced/AdvancedSimulationStep05.java)
* mine examples and solutions mostly based on cases from [Gatling Community](https://community.gatling.io)
* auto run using GitHub Actions ([push](https://github.com/gemiusz/gatling-examples-maven-java/actions/workflows/gatling_test_all_mine_after_push.yml), [pull](https://github.com/gemiusz/gatling-examples-maven-java/actions/workflows/gatling_test_all_mine_after_pull_request.yml)) of all mine examples after `push` and during `pull_request`
<br><br><br>

### Mine examples and solutions divided into cases:
* [**Case0001JMESPathSimulation**](src/test/java/pl/gemiusz/Case0001JMESPathSimulation.java) => [JmesPath is not finding a JSON Object](https://community.gatling.io/t/jmespath-is-not-finding-a-json-object/6995)
* [**Case0002PDFdownloadSimulation**](src/test/java/pl/gemiusz/Case0002PDFdownloadSimulation.java) => [How to ensure a pdf is downloaded during a loadtest?](https://community.gatling.io/t/how-to-ensure-a-pdf-is-downloaded-during-a-loadtest/3927)
* [**Case0003UnzipJsonForFeederSimulation**](src/test/java/pl/gemiusz/Case0003UnzipJsonForFeederSimulation.java) => [Unzipping json file for feeders](https://community.gatling.io/t/unzipping-json-file-for-feeders/6996)
* [**Case0004StatusCodeSimulation**](src/test/java/pl/gemiusz/Case0004StatusCodeSimulation.java) => [withDefault Check Transforming feature](https://community.gatling.io/t/withdefault-check-transforming-feature/7008)
* [**Case0005UUIDfeederSimulation**](src/test/java/pl/gemiusz/Case0005UUIDfeederSimulation.java) => [Is there an EL function to generate uuid using java in gatling](https://community.gatling.io/t/is-there-an-el-function-to-generate-uuid-using-java-in-gatling/7028)
* [**Case0006CommandLineParametersSimulation**](src/test/java/pl/gemiusz/Case0006CommandLineParametersSimulation.java) => [Cannot Grab Command Line Arguments](https://community.gatling.io/t/cannot-grab-command-line-arguments/7025) & [Assertion in parameter](https://community.gatling.io/t/assertion-in-parameter/7970)
* [**Case0007AsyncReqSimulation**](src/test/java/pl/gemiusz/Case0007AsyncReqSimulation.java) - using `repeat` => [How to simulate an asynchronous request executing many times?](https://community.gatling.io/t/how-to-simulate-an-asynchronous-request-executing-many-times/7031)
* [**Case0008AsyncReqResourcesSimulation**](src/test/java/pl/gemiusz/Case0008AsyncReqResourcesSimulation.java) - using `resources` => [How to simulate an asynchronous request executing many times?](https://community.gatling.io/t/how-to-simulate-an-asynchronous-request-executing-many-times/7031)
* [**Case0009SessionValuesSimulation**](src/test/java/pl/gemiusz/Case0009SessionValuesSimulation.java) => [Dynamically generating param values for an API and setting it using session](https://community.gatling.io/t/dynamically-generating-param-values-for-an-api-and-setting-it-using-session/7041)
* [**Case0010JsonEditVariableSimulation**](src/test/java/pl/gemiusz/Case0010JsonEditVariableSimulation.java) => [Java - edit variable received in JSON](https://community.gatling.io/t/java-edit-variable-received-in-json/7046)
* [**Case0011ProxyCommandLineParametersSimulation**](src/test/java/pl/gemiusz/Case0011ProxyCommandLineParametersSimulation.java) => [Gatling proxy configuration from command line](https://community.gatling.io/t/gatling-proxy-configuration-from-command-line/7072)
* [**Case0012DenySomeResourcesSimulation**](src/test/java/pl/gemiusz/Case0012DenySomeResourcesSimulation.java) => [Gatling Java - HttpProtocolBuilder DenyList](https://community.gatling.io/t/gatling-java-httpprotocolbuilder-denylist/7099)
* [**Case0013RequestBeforeSimulation**](src/test/java/pl/gemiusz/Case0013RequestBeforeSimulation.java) => [Best way of calling another API before the performance test](https://community.gatling.io/t/best-way-of-calling-another-api-before-the-performance-test/7116)
* [**Case0014Loop5times1RPSand3sPauseSimulation**](src/test/java/pl/gemiusz/Case0014Loop5times1RPSand3sPauseSimulation.java) => [Emulate load with few requests simultaneously that repeated after some period of time](https://community.gatling.io/t/emulate-load-with-few-requests-simultaneously-that-repeated-after-some-period-of-time/7155)
* [**Case0015UUIDfeederTwoRecordsAtTheSameTimeSimulation**](src/test/java/pl/gemiusz/Case0015UUIDfeederTwoRecordsAtTheSameTimeSimulation.java) => [Feed multiple n-rows from CSV to json payload](https://community.gatling.io/t/feed-multiple-n-rows-from-csv-to-json-payload/7160)
* [**Case0016ScenarioDurationSimulation**](src/test/java/pl/gemiusz/Case0016ScenarioDurationSimulation.java) => [How to get the duration of a specific scnario?](https://community.gatling.io/t/how-to-get-the-duration-of-a-specific-scnario/7220)
* [**Case0017ForeachAfterForeachSimulation**](src/test/java/pl/gemiusz/Case0017ForeachAfterForeachSimulation.java) => [Foreach loop after a foreach loop does not execute](https://community.gatling.io/t/foreach-loop-after-a-foreach-loop-does-not-execute/7277)
* [**Case0018GetTokenWhenStatus401Simulation**](src/test/java/pl/gemiusz/Case0018GetTokenWhenStatus401Simulation.java) => [Using a .doIf when token expired and need refresh](https://community.gatling.io/t/using-a-doif-when-token-expired-and-need-refresh/7303)
* [**Case0019WhenStatusCode400ThenFailSimulation**](src/test/java/pl/gemiusz/Case0019WhenStatusCode400ThenFailSimulation.java) => [Assertion on the HTTP status code](https://community.gatling.io/t/assertion-on-the-http-status-code/7355)
* [**Case0020ExitBlockOnFailSimulation**](src/test/java/pl/gemiusz/Case0020ExitBlockOnFailSimulation.java) => [Stop the current Iteration/loop and start the next Iteration/loop when request failed](https://community.gatling.io/t/stop-the-current-iteration-loop-and-start-the-next-iteration-loop-when-request-failed/7492)
* [**Case0021CheckResourcesResponseTimeSimulation**](src/test/java/pl/gemiusz/Case0021CheckResourcesResponseTimeSimulation.java) => [Track which queries are executed within specified time frame and which outside it](https://community.gatling.io/t/track-which-queries-are-executed-within-specified-time-frame-and-which-outside-it/7910)
* [**Case0022SetOrRefreshTokenSimulation**](src/test/java/pl/gemiusz/Case0022SetOrRefreshTokenSimulation.java) => [Token Refresh - Java - Example](https://community.gatling.io/t/token-refresh-java-example/7935)
* [**Case0023foreachFromUUIDfeederFiveRecordsAtTheSameTimeSimulation**](src/test/java/pl/gemiusz/Case0023foreachFromUUIDfeederFiveRecordsAtTheSameTimeSimulation.java) => [Feeder reading multiple lines and foreach](https://community.gatling.io/t/feeder-reading-multiple-lines-and-foreach/7947)
* [**Case0024IterationLoopCondition**](src/test/java/pl/gemiusz/Case0024IterationLoopCondition.java) => [Iteration and Looping conditions](https://community.gatling.io/t/iteration-and-looping-conditions/7984)
* [**Case0025JSONfeederRandomSimulation**](src/test/java/pl/gemiusz/Case0025JSONfeederRandomSimulation.java) => [JSON feeder with nested arrays; how to randomly select a record from the parent](https://community.gatling.io/t/json-feeder-with-nested-arrays-how-to-randomly-select-a-record-from-the-parent/8059)
* [**Case0026ResponseHeaderRegexSimulation**](src/test/java/pl/gemiusz/Case0026ResponseHeaderRegexSimulation.java) => [How to capture request params generated dynamically from GET request to correlate next POST request](https://community.gatling.io/t/how-to-capture-request-params-generated-dynamically-from-get-request-to-correlate-next-post-request/8276)
"
cescoffier/vertx-microservices-examples,master,28,7,2016-03-22T14:07:33Z,335,2,Vert.x Microservices examples,,"# Vert.x Microservices examples

This repository demonstrates how to build two common microservice patterns with vert.x:
 
1. aggregation
2. pipeline

It uses vert.x discovery, circuit breaker and if you run them on Openshift Origin, Kubernetes discovery.
 
In an aggregation, a microservice aggregates the results from other microservices. In this example, A calls B, C
 and D and returns the aggregated answer to the client.
  
In a pipeline, a microservice is calling another one, calling another one... In this example, A calls B, B calls C 
and C calls D. The client get the whole result.

In these examples, microservice communicates using HTTP. However this is not requires and you can use asynchronous 
service proxies, events, SOAP or whatever protocol you like.
  
## Run the demos locally
  
First, you need to build the projects, with:
  
```
mvn clean install
```

Be aware that the microservices are going to open the port: 8080 (A), 8081 (B), 8082 (C), and 8083 (D). This is 
configurable in the configuration files.
  
### Aggregation example
   
First go in the `aggregation-http` directory, and open 4 terminals (one for each microservice)

```
cd aggregation-http
```

Then, launch the microservices:

```
cd A
java -Djava.net.preferIPv4Stack=true -jar target/aggregation-http-A-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json 
```

```
cd B
java -Djava.net.preferIPv4Stack=true -jar target/aggregation-http-B-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json
```

```
cd C
java -Djava.net.preferIPv4Stack=true -jar target/aggregation-http-C-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json
```

```
cd D
java -Djava.net.preferIPv4Stack=true -jar target/aggregation-http-D-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json
```

Let's analyses these command lines:

* it uses IPv4 just to avoid some networking issues
* it launches the microservice (vert.x application) using the _fat jar_ build during the Maven build
* the vert.x application is started in cluster mode and get some configuration data

The cluster is using Hazelcast and is configured in the `../etc/cluster.xml` file. By default it uses `127.0.0.1`.
 
Once launch, open a browser to `http://localhost:8080/assets/index.html`. You should get a web page inviting you to 
submit a form that will execute the application:

![the aggregation application page](img/aggregation-page.png ""The aggregation application page"")

If everything is launched, you should get: `{""A"":""Hello vert.x"",""B"":""Hola vert.x"",""C"":""No service available (no 
record)"",""D"":""Aloha vert.x""}`.

Now shutdown one of the application (B, C or D), by hitting `CTRL+C` in the right terminal. Re-submit the form. You 
should get: `{""A"":""Hello vert.x"",""B"":""Hola vert.x"",""C"":""No service available (no record)"",""D"":""Aloha vert.x""}` or 
something similar.
 
When shutting down a microservice, it does not reply to the request anymore. The circuit breaker intercepts the error
 and execute a fallback. If you restarts it, the output should be back to _normal_. This is because the circuit 
 breaker tries periodically to reset its state and check whether or not things are back to _normal_.
         
         
### Pipeline example
   
First go in the `pipeline-http` directory, and open 4 terminals (one for each microservice)

```
cd pipeline-http
```

Then, launch the microservices:

```
cd A
java -Djava.net.preferIPv4Stack=true -jar target/pipeline-http-A-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json 
```

```
cd B
java -Djava.net.preferIPv4Stack=true -jar target/pipeline-http-B-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json
```

```
cd C
java -Djava.net.preferIPv4Stack=true -jar target/pipeline-http-C-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json
```

```
cd D
java -Djava.net.preferIPv4Stack=true -jar target/pipeline-http-D-1.0-SNAPSHOT-fat.jar -cluster -cp ../etc -conf src/main/config/config.json
```

Let's analyses these command lines:

* it uses IPv4 just to avoid some networking issues
* it launches the microservice (vert.x application) using the _fat jar_ build during the Maven build
* the vert.x application is started in cluster mode and get some configuration data
         
The cluster is using Hazelcast and is configured in the `../etc/cluster.xml` file. By default it uses `127.0.0.1`.
 
Once launch, open a browser to `http://localhost:8080/assets/index.html`. You should get a web page inviting you to 
submit a form that will execute the application:

![the pipeline application page](img/pipeline-page.png ""The pipeline application page"")


If everything is launched, you should get: `{""D"":""Aloha vert.x"",""C"":""Olá vert.x"",""B"":""Hola vert.x"",""A"":""Hello vert.x""}`.

Now shutdown one of the application (B, C or D), by hitting `CTRL+C` in the right terminal. Re-submit the form. You 
should get: `{""C"":""No service available (fallback)"",""B"":""Hola vert.x"",""A"":""Hello vert.x""}` or 
something similar.
 
When shutting down a microservice, it does not reply to the request anymore. The circuit breaker intercepts the error
 and execute a fallback. If you restarts it, the output should be back to _normal_. This is because the circuit 
 breaker tries periodically to reset its state and check whether or not things are back to _normal_.         

## Run the demos in Openshift Origin (v3)

These demos can also be executed in Openshift.

### Prerequisites

You will need to have Openshift on your machine to run them demo.

Here is how to start Openshift using Docker on Linux: 

```
docker rm origin
sudo docker run -d --name ""origin"" \
        --privileged --pid=host --net=host \
        -v /:/rootfs:ro -v /var/run:/var/run:rw -v /sys:/sys -v /var/lib/docker:/var/lib/docker:rw \
        -v /var/lib/origin/openshift.local.volumes:/var/lib/origin/openshift.local.volumes \
        openshift/origin start
docker logs -f origin
```

You would need the `oc` command line tool too. Download it form the Openshift web site.

### Login to openshift

Once launched, execute:

```
oc login
# credentials are admin / admin
```

Also connect with your browser on https://0.0.0.0:8443. The certificates are not valid, just force the access. You 
should arrive on a page similar to that one:

![Openshift login](img/openshift-login.png ""The Openshift login page"")

### Aggregation example


**Step 1: Project creation**

You first need to create the Openshift project, and give some permissions:

```
oc new-project vertx-microservice-example-aggregation-http
oc policy add-role-to-user admin admin -n vertx-microservice-example-aggregation-http
oc policy add-role-to-group view system:serviceaccounts -n vertx-microservice-example-aggregation-http
```

Do **not** change the project name, the configuration of the application is made for this name. See details below.

**Runs the microservice**

First go in the `aggregation-http` directory. Then for each project (A, B, C and D) runs:

```
mvn clean package docker:build fabric8:json fabric8:apply -Popenshift
```

It uses the Docker Maven plugin and the Fabric8 Maven plugin to build a docker image containing the microservice. It 
pushes it to the docker registry and creates the application in Openshift (using Kubernetes).
 
When you have deployed all components, you should have 4 pods in openshift, one for each service:
 
![the Openshift pod and service list](img/openshift-pods.png ""The Openshift pod and service list"")

To access the application page, you need to get the IP of the service `A`. To get this IP, click on the service `A` 
and get the IP in the right side panel:

![the Openshift pod and service list](img/openshift-pods.png ""The Openshift pod and service list"")

Once you have the IP, open the page: http://$ip/assets/index.html

You can use the application as the _local_ version. Then, go back to the Openshift overview page and scale down one 
of the service pod (B, C or D):

![scaling down a pod](img/openshift-scaling-down.png ""Scaling down a pod"")

Try to reuse the application, the circuit breaker should detect the failure and use a fallback. If you restore the 
destroyed pod, the application should act _normally_ again.

**Kubernetes and service discovery**

When running in Openshift, the Kubernetes services are imported in the vert.x discovery service, so they are 
retrieved as _regular_ services by the application. 

### Pipeline example

**Step 1: Project creation**

You first need to create the Openshift project, and give some permissions:

```
oc new-project vertx-microservice-example-pipeline-http
oc policy add-role-to-user admin admin -n vertx-microservice-example-pipeline-http
oc policy add-role-to-group view system:serviceaccounts -n vertx-microservice-example-pipeline-http
```

Do **not** change the project name, the configuration of the application is made for this name. See details below.

**Runs the microservice**

First go in the `pipeline-http` directory. Then for each project (A, B, C and D) runs:

```
mvn clean package docker:build fabric8:json fabric8:apply -Popenshift
```

It uses the Docker Maven plugin and the Fabric8 Maven plugin to build a docker image containing the microservice. It 
pushes it to the docker registry and creates the application in Openshift (using Kubernetes).
 
When you have deployed all components, you should have 4 pods in openshift, one for each service:
 
![the Openshift pod and service list](img/openshift-pods.png ""The Openshift pod and service list"")

To access the application page, you need to get the IP of the service `A`. To get this IP, click on the service `A` 
and get the IP in the right side panel:

![the Openshift pod and service list](img/openshift-pods.png ""The Openshift pod and service list"")

Once you have the IP, open the page: http://$ip/assets/index.html

You can use the application as the _local_ version. Then, go back to the Openshift overview page and scale down one 
of the service pod (B, C or D):

![scaling down a pod](img/openshift-scaling-down.png ""Scaling down a pod"")

Try to reuse the application, the circuit breaker should detect the failure and use a fallback. If you restore the 
destroyed pod, the application should act _normally_ again.


### Trick to shutdown everything

To shutdown openshift and the deployed pods use:

```
# On bash
docker stop `docker ps -qa`
docker rm -f `docker ps -qa` 
# Fish
docker stop (docker ps -qa)
docker rm -f (docker ps -qa)
```
"
TheThinMatrix/OpenGL-Animation,master,254,57,2017-03-27T18:48:36Z,577,3,A simple example of skeletal animation using OpenGL (and LWJGL).,,"A simple example of skeletal animation using OpenGL (and LWJGL).

To get the code working in an Eclipse project you need to set up a project with the lwjgl, lwjgl_utils,and PNGDecoder jars added to the build path, along with the relevant LWJGL natives.

In case you’ve forgotten how to set up a LWJGL project, you can find a tutorial on how to do that here: https://youtu.be/Jdkq-aSFEA0

You can download PNGDecoder here: http://twl.l33tlabs.org/dist/PNGDecoder.jar
"
OpenSharding/opensharding-spi-impl-example,master,27,27,2019-08-15T10:14:06Z,104,4,ShardingSphere spi-impl example,,"# sharding-spi-impl-example
"
lievendoclo/cleanarch,master,90,28,2016-10-17T21:17:45Z,248,1,Java example of the Clean Architecture ,,"![Build status](https://travis-ci.org/lievendoclo/cleanarch.svg?branch=master)

# Clean Architecture in Java
 
Some time ago Robert C. Martin published an interesting article about how
software architecture should be designed in such a way that technological
decisions can be deferred to a much later stage and to the edge of a system.

The concept of Clean Architecture was born.

## Why Clean Architecture?
> The center of your application is not the database. Nor is it one or more of the frameworks you may be using. **The center of your application is the use cases of your application**  -  _Unclebob_ ([source](https://blog.8thlight.com/uncle-bob/2012/05/15/NODB.html ""NODB""))

Clean architecture helps us solve, or at least mitigate, these common problems with architecture:
* **Decisions are taken too early**, often at the beginning of a project, when we know the least about the problem that we have to solve
* **It's hard to change**, so when we discover new requirements we have to decide if we want to hack them in or go through an expensive and painful re-design. We all know which one usually wins. _The best architectures are the ones that allow us to defer commitment to a particular solution and let us change our mind_
* **It's centered around frameworks**. Frameworks are tools to be used, not architectures to be conformed to. Frameworks often require commitments from you, but they don’t commit to you. They can evolve in different directions, and then you’ll be stuck following their rules and quirks
* **It's centered around the database**. We often think about the database first, and then create a CRUD system around it. We end up using the database objects everywhere and treat everything in terms of tables, rows and columns
* **We focus on technical aspects** and when asked about our architecture we say things like “it’s servlets running in tomcat with an oracle db using spring”
* **It's hard to find things** which makes every change longer and more painful
* **Business logic is spread everywhere**, scattered across many layers, so when checking how something works our only option is to debug the whole codebase. Even worse, often it's duplicated in multiple places
* **Forces/Encourages slow, heavy tests**. Often our only choice for tests is to go through the GUI, either because the GUI has a lot of logic, or because the architecture doesn't allow us to do otherwise. This makes tests slow to run, heavy and brittle. It results in people not running them and the build beind broken often
* **Infrequent deploys** because it's hard to make changes without breaking existing functionalities. People resort to long-lived feature branches that only get integrated at the end and result in big releases, rather than small incremental ones

Clean architecture gives us all these benefits:
* **Effective testing strategy** that follows the [testing pyramid](http://martinfowler.com/bliki/TestPyramid.html) and gives us a fast and reliable build
* **Frameworks are isolated** in individual modules so that when (not if) we change our mind we only have to change one place, with the rest of the app not even knowing about it
* **Independent from Database**, which is treated just like any other data provider. Our app has real use cases rather than being a CRUD system
* **Screaming architecture** a.k.a. it screams its intended usage. When you look at the package structure you get a feel for what the application does rather than seeing technical details
* **All business logic is in a use case** so it's easy to find and it's not duplicated anywhere else
* **Hard to do the wrong thing** because modules enforce compilation dependencies. If you try to use something that you're not meant to, the app doesn't compile
* **We're always ready to deploy** by leaving the wiring up of the object for last or by using feature flags, so we get all the benefits of continuous integration (no need for feature branches)
* **Swarming on stories** so that different pairs can easily work on the same story at the same time to complete it quicker
* **Good monolith** with clear use cases that you can split in microservices later one, once you've learnt more about them

Of course, it comes at a cost:
* **Perceived duplication of code**. Entities might be represented differently when used in business logic, when dealing with the database and when presenting them in a json format. You might feel like you're duplicating code, but you're actually favouring _decoupling over DRY_
* **You need interesting business logic** to ""justify"" the structure. If all you do in your use case is a one-line method to read or save from a database, then maybe you can get away with something simpler

## Graphical representation of Clean Architecture

![Clean architecture](https://8thlight.com/blog/assets/posts/2012-08-13-the-clean-architecture/CleanArchitecture-8b00a9d7e2543fa9ca76b81b05066629.jpg)

![Clean architecture](http://i.imgur.com/WkBAATy.png)

## What this implementation is trying to achieve

This implementation is far from perfect. What I'm trying to do here is to
 provide code that adheres as close as possible to the tenets of Clean Architecture.
 
The package names have been chosen to represent the concepts of Clean Architecture
so that it becomes clear what is being implemented.

## Where I don't agree

Well, there is one part where I don't agree. I chose not to have the Presenter extend
a Boundary, because I believe this is a concept that just doesn't implement well.
Instead, my Boundary objects that return something accept a Consumer. This consumer
can then be implemented by a Presenter (in my case Presenter implementations are
just stateful Consumer implementations). This feels much more logical to me and 
provides flexibility towards asynchronicity (queueing, reactive) that would otherwise leak into
the interfaces.

## Acknowledgements

https://github.com/mattia-battiston/clean-architecture-example"
nicolasgramlich/AndEngineRobotiumExtensionExample,GLES2,26,27,2012-02-15T19:03:16Z,155,0,AndEngine - Robotium Extension Example,,
JJBRT/advanced-java-tutorials,master,35,14,2020-12-15T20:09:52Z,547,0,A collection of examples about advanced Java programming,advanced collection example examples java tutorial,"# Advanced Java tutorials
<a href=""https://jjbrt.github.io/advanced-java-tutorials/"">
<img src=""https://raw.githubusercontent.com/JJBRT/advanced-java-tutorials/master/docs/Java-logo.png"" alt=""Java-logo.png"" height=""180px"" align=""right""/>
</a>

A collection of examples about advanced Java programming. Here you will find tutorials about:

* [how to create your own dependency injection framework](https://jim-jerald-burton.medium.com/how-to-create-your-own-dependency-injection-framework-in-java-12a6e52aeff9)
* [how to make applications created with old Java versions work on Java 9 and later versions](https://dev.to/bw_software/making-applications-created-with-old-java-versions-work-on-java-9-and-later-versions-19ld)
* [how to make reflection fully work on Java 9 and later](https://jim-jerald-burton.medium.com/making-reflection-fully-work-on-java-9-and-later-767320344d1d)
* [how to export all modules to all modules at runtime on Java 9 and later](https://jim-jerald-burton.medium.com/exporting-all-modules-to-all-modules-at-runtime-on-java-9-and-later-3517eb479701)
* [how to iterate collections and arrays in parallel by setting thread priority](https://dev.to/bw_software/iterating-collections-and-arrays-in-parallel-5acg)
* [how to configure host name resolution to use a universal custom host name resolver](https://dev.to/jjbrt/how-to-configure-hostname-resolution-to-use-a-universal-custom-hostname-resolver-in-java-14p0)
* [how to query and validate a JSON document](https://dev.to/jjbrt/querying-and-validating-a-json-document-in-java-323i)

<br/>

**Any instructions to make each project work are indicated in the possible README.md file inside it**.
"
jsvazic/GAHelloWorld,master,193,83,2011-01-25T22:58:29Z,210,6,"A simple example of a Genetic Algorithm that generates Hello world!""""",,"# Genetic Algorithm Hello World!

This is a simple project intended to showcase genetic algorithms with a well 
known example for all new developers; namely the classic ""Hello, world!"" 
example!

## Overview

The application simply ""evolves"" the string ""Hello, world!"" from a population 
of random strings.  It is intended to be a gentle introduction into the world
of genetic algorithms, using Java, Clojure, Common Lisp, Haskell,
Scala, Python and OCaml.  The programs themselves are really quite
simple, and more complex topics like crossover selection using
roulette wheel algorithms, insertion/deletion mutation, etc, have not
been included.

### History

I've been working with Genetic Algorithms for a little while now and I
stubmled across a 
[C++ implemetation](http://www.generation5.org/content/2003/gahelloworld.asp) 
a while ago.  I decided to bring it back to life and migrate it to Java with 
my own enhancements.  This is far from ideal code, but it was designed to be 
a gentle introduction for newcomers to genetic algorithms.

### But why the <i>net.auxesia</i> package/namespace?

[Auxesia](http://www.theoi.com/Ouranios/HoraAuxesia.html) is the greek
goddess of spring growth, so when dealing with evolutionary programming like
genetic algorithms, the name just seemed to fit.  That and I was trying to be
witty with my naming, and [Dalek](http://en.wikipedia.org/wiki/Dalek) just 
didn't seem right.

## Architecture

The overall architecture for each language is the same.  The genetic algorithm
is broken up between two logical units: a <i>Chromsome</i> and a 
<i>Population</i>.  In some cases a separate driver is also added, but this is
just to keep the logic for the other two components separate and clean.

### Population

The Population has 3 key attributes (a crossover ratio, an
elitism ratio and a mutation ratio), along with a collection of Chromosome 
instances, up to a pre-defined population size.  There is also an evolve() 
function that is used to ""evolve"" the members of the population.

#### Evolution

The evolution algorithm is simple in that it uses the various ratios during
the evolution process.  First, the elitism ratio is used to copy over a 
certain number of chromosomes unchanges to the new generation.  The remaining
chromosomes are then either mated with other chromosomes in the population, or
copied over directly, depending on the crossover ratio.  In either case, each
of these chromosomes is subject to random mutation, which is based on the 
mutation ration metioned earlier.

The crossover algorithm used for mating is a very basic tournament selection
algorithm.  See 
[Tournament Selection](http://en.wikipedia.org/wiki/Tournament_selection) for
more details.

### Chromosome
Each chromosome has a gene that represents one possible solution to the given 
problem.  In our case, each gene represents a string that strives to match
""Hello, world!"".  Each chromosome also has a fitness attribute that is a 
measure of how close the gene is to the target of ""Hello, world!"".  This 
measurement is just a simple sun of the absolute difference of each character
in the gene to the corresponding character in the target string above.  Each
gene is simply a string of 13 ASCII characters from ASCII 32 to ASCII 121 
inclusive.

The functions operating on Chromsome include <i>mutate()</i> and 
<i>mate()</i>, amongst others as necessary for the various language 
implementations.

#### mutate()
The mutate() function will randomly replace one character in the given gene.

#### mate()
The mate() function will take another chromosome instance and return two new
chromosome instances.  The algorithm is as follows:

1.  Select a random pivot point for the genes.
2.  For the first child, select the first n < pivot characters from the first 
    parent, then the remaining pivot <= length characters from the second 
    parent.
3.  For the second child, repeate the same process, but use the first n < pivot
    characters from the second parent and the remaining characters from the
    first parent.

### Driver

The driver code simply instantiates a new Population instance with a set of
values for the population size, crossover ratio, elitism ratio and mutation
ratio, as well as a maximum number of generations to create before exiting
the simulation, in order to prevent a potential infinite execution.

Depending on the implementation, this code may reside in its own source file.
   
## Usage

Take a look at the README files in:

*   [Java](GAHelloWorld/tree/master/java)
*   [Clojure](GAHelloWorld/tree/master/clojure)
*   [Common Lisp](GAHelloWorld/tree/master/common-lisp)
*   [Scala](GAHelloWorld/tree/master/scala)
*   [Python](GAHelloWorld/tree/master/python)
*   [OCaml](GAHelloWorld/tree/master/ocaml)
*   [PHP](GAHelloWorld/tree/master/php)

for the specifics for each language.

### Unit tests

Each source implementation has unit tests to go along with the source code.

## Copyright and License

The MIT License

Copyright &copy; 2011 John Svazic

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
"
vrudas/spring-framework-examples,main,38,6,2021-01-21T19:53:22Z,3368,1,An educational project with Spring Framework examples. Used for lectures at courses.,java jwt-authentication oauth2-client remember-me spring spring-boot spring-framework spring-framework-5 spring-guides spring-mvc spring-security,"<p align=""center"">
    <img src=""https://github.com/vrudas/spring-framework-examples/assets/8240025/9d664274-e5b0-431b-8c09-9c29d9b92fa0"" alt=""Spring Logo"" width=""256""/>
</p>

<h1 align=""center"">
    Spring Framework Examples
</h1>
<p align=""center"">
    An educational project with Spring Framework examples. Used for lectures at courses.
</p>

## Related links
- [Spring Framework Documentation](https://docs.spring.io/spring-framework/docs/current/reference/html/)
- [Spring Core Technologies](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html)
- [Spring Guides](https://spring.io/guides)
- [Spring Quickstart Guide](https://spring.io/quickstart)
- [Properties with Spring and Spring Boot](https://www.baeldung.com/properties-with-spring)
- [An Intro to the Spring DispatcherServlet](https://www.baeldung.com/spring-dispatcherservlet)
- [Design Pattern - Front Controller Pattern](https://www.tutorialspoint.com/design_pattern/front_controller_pattern.htm)
- [Introduction to Using Thymeleaf in Spring](https://www.baeldung.com/thymeleaf-in-spring-mvc)
- [Servlet Filter and Handler Interceptor](https://medium.com/techno101/servlet-filter-and-handler-interceptor-spring-boot-implementation-b58d397d9dbd)
- [Error Handling for REST with Spring](https://www.baeldung.com/exception-handling-for-rest-with-spring)
- [Spring 5, Embedded Tomcat 8, and Gradle: a Quick Tutorial](https://auth0.com/blog/spring-5-embedded-tomcat-8-gradle-tutorial/)
- [Spring Boot Reference Documentation](https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/)

## Spring Security 6 Migration links
- [Migrating to 6.0](https://docs.spring.io/spring-security/reference/migration/index.html)
- [Spring Security without the WebSecurityConfigurerAdapter](https://spring.io/blog/2022/02/21/spring-security-without-the-websecurityconfigureradapter)

## Important information
- The module [example-17-authorization](example-17-authorization) has an issue https://github.com/vrudas/spring-framework-examples/issues/101 that was caused because of update to Spring Security 6

## Example 21 - JWT Instructions

Please note that IntelliJ IDEA [HTTP Client](https://blog.jetbrains.com/idea/2020/09/at-your-request-use-the-http-client-in-intellij-idea-for-spring-boot-restful-web-services/) was used to perform requests in code snippets

Please follow the steps to perform a demo of how to get a JWT token for an existing user:

- Perform login action
```HTTP request
POST http://localhost:8080/login?username=user&password=user
Accept: application/json
```

- Extract the generated Bearer token from a response header `Authorization: Bearer <token>`
```
HTTP/1.1 200
Vary: Origin
Vary: Access-Control-Request-Method
Vary: Access-Control-Request-Headers
Authorization: Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNjc4ODM2OTY1fQ.Afagk8no-r2kUiDOdtjWMT06gYPHkrhCoOSoK5_X6k8BC8Lr6k5rB-9gyoE72-lkd0rx1sEPET-3Uf7KP-7BrQ
X-Content-Type-Options: nosniff
X-XSS-Protection: 0
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
X-Frame-Options: DENY
Content-Length: 0
Date: Tue, 14 Mar 2023 23:35:05 GMT
Keep-Alive: timeout=60
Connection: keep-alive

<Response body is empty>
```

- Use the generated Bearer token to perform the call to an endpoint by providing the `Authorization: Bearer <token>` header
```HTTP request
GET http://localhost:8080/users/me
Accept: application/json
Authorization: Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNjc4ODM1NjE5fQ.cRZ1ob4XZfG5RnU0jl2kdPihc9Ln-BlEOe7hbuwZJWp-UuQSGukI_57pWrBcdaCWPN-8luCF08YWU74tUErOFg
```

<h2 align=""center"">
    Contribution statistic
</h2>
<p align=""center"">
    <img src=""https://repobeats.axiom.co/api/embed/ea96de66d99f0b7879faf1dd630824e3b2339f78.svg"" alt=""Repobeats analytics image""/>
</p>
"
eliostvs/clean-architecture-delivery-example,master,393,104,2018-06-04T14:51:54Z,525,4,A example of clean architecture in Java 8 and Spring Boot 2.0,clean-architecture java java-8 jwt-authentication spring-boot spring-security,"[![Build Status](https://travis-ci.org/eliostvs/clean-architecture-delivery-example.svg?branch=master)](https://travis-ci.org/eliostvs/clean-architecture-delivery-example)

# Clean Architecture Example

## Description

The architecture of the project follows the principles of Clean Architecture. It is a simple food delivery app. One can list stores, cousines, products and create food orders. JWT it is used for authentication.

## Running

`./gradlew bootRun`

## Architecture

The project consists of 3 packages: *core*, *data* and *presenter*.

### *core* package

This module contains the domain entities and use cases.
This module contains the business rules that are essential for our application.
In this module, gateways for the repositories are also being defined.
There are no dependencies to frameworks and/or libraries and could be extracted to its own module.

### *data* package

### *presenter* package

## Diagram

Here is a flow diagram of the payment of an order.

![c4 component](./docs/c4-component.png)
"
mstahv/spring-boot-spatial-example,master,139,55,2016-11-09T22:29:19Z,3147,4,A Spring Boot example editing spatial data in MySQL,,"# A Spring Boot example editing spatial data in relational database

![Alt text](./screenshot.png?raw=true ""Screenshot"")

This is a small example app that shows how one can use:

 * [Spring Boot](http://projects.spring.io/spring-boot/) and [Spring Data](https://spring.io/projects/spring-data)
 * Latest [Hibernate](http://hibernate.org/orm/) with spatial features. At the application API, only standard JPA stuff (and Spring Data) is used.
 * ~~The example also uses [QueryDSL](http://www.querydsl.com) spatial query as an example. QueryDSL contain excellent support for spatial types.~~ QueryDSL example replaced with plain JPQL(with Hibernate spatial extensions) as the latest version is not compatible with latest JTS/Hibernate. See https://github.com/querydsl/querydsl/issues/2404. If you want to see the example of QueryDSL usage in this setup, check out a bit older version of the example.
 * Relational database, like PostGis (default, Postgres + extentiosn), H2GIS or MySQL, which supports basic spatial types. The example automatically launches Docker image with PostGis for the demo using TestContainers, if run via TestApp class in src/test/java/org/vaadin/example. Not that Hibernate might need tiny adjustments for other databases.
 * [Vaadin](https://vaadin.com/) and [MapLibreGL }> add-on](https://vaadin.com/directory/component/maplibregl--add-on) to build the UI layer. MapLibre add-on is a Vaadin wrapper for [MapLibre GL JS](https://github.com/maplibre/maplibre-gl-js) slippy map widget and [mapbox-gl-draw](https://github.com/mapbox/mapbox-gl-draw). Its Vaadin field implementations which make it dead simple to edit [JTS](https://locationtech.github.io/jts/) data types directly from the JPA entities.
 * As base layer for maps, crisp vector format [OpenStreetMap](https://www.openstreetmap.org/) data via [MapTiler](https://www.maptiler.com) is used, but naturally any common background map can be used.

...to build a full-stack web app handling spatial data efficiently.

As the data is in an optimized form in the DB, it is possible to create efficient queries to the backend and e.g. only show features relevant to the current viewport of the map visualizing features or what ever you can with the spatial queries.

Enjoy!
"
microsoft/flink-on-azure,main,45,8,2022-08-18T05:40:08Z,943,8,Examples of Flink on Azure,azure azuredatafactory azuredatalakegen2 azuresqldb big-data cdc client-go flink flink-examples flink-stream-processing golang hdfs helm java kubeflow kubernetes tensorflow,"# Flink on Azure

Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.

This repo provides examples of Flink integration with Azure, like Azure Kubernetes, Azure SQL Server, Azure Data Factory, etc.

## Examples

Outline the examples in the repository.

| Example | Description | Pipeline Status |
|-|-|-|
| [Flink Streaming Examples](flink-streaming-example) |  Examples for Flink Streaming, including custom source & sink |  |
| [Flink Stream Batch Unified Examples](flink-stream-batch-unified-example) |  Examples for Flink Stream Batch Unified Connector |  |
| [Flink History Server](flink-history-server) |  Examples for Flink History Server |  |
| [Flink CDC SQL Server Examples](flink-cdc-sql-server-example) |  Examples for Flink CDC SQL Server Connector |  |
| [Flink on Native Azure Kubernetes](flink-on-native-azure-kubernetes) |  Examples for Flink Job on Native Azure Kubernetes |  |
| [Flink Azure Data Factory Cloud Native Extension](flink-adf-cloud-native-extension) |  Flink Azure Data Factory Cloud Native Extension |  |
| [Flink Deep Learning Tensorflow](flink-dl-tensorflow) |  Flink Online & Offline Training, Tensorflow Integration |  |

## Prerequisites

Basic:

* [Git](https://www.git-scm.com/downloads)
* [Java Development Kit (JDK) 1.8](https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html)
* [Apache Maven](http://maven.apache.org/download.cgi) and [install](http://maven.apache.org/install.html) a Maven binary archive
* [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli)

Azure:

* [Azure Container Registry](https://azure.microsoft.com/en-us/services/container-registry/)
* [Azure Kubernetes](https://azure.microsoft.com/en-us/services/kubernetes-service/)
* [Azure SQL Server](https://azure.microsoft.com/en-us/services/sql-database/)
* [Azure Data Factory](https://azure.microsoft.com/en-us/services/data-factory/)
* [Azure Data Lake Storage Gen2](https://azure.microsoft.com/en-us/services/storage/data-lake-storage/#overview)
* [Azure Blob Storage NFS Support](https://learn.microsoft.com/en-us/azure/storage/blobs/network-file-system-protocol-support)
* [Azure Storage Fuse](https://github.com/Azure/azure-storage-fuse)

Flink:

* [Flink](https://downloads.apache.org/flink)

Deep Learning:

* [Tensorflow](https://www.tensorflow.org/)
* [Kubeflow](https://www.kubeflow.org/)

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
"
mploed/event-driven-spring-boot,master,264,125,2017-05-18T12:10:05Z,419,2,Example Application to demo various flavours of handling domain events in Spring Boot,atom event-driven event-sourcing events feed rest-api spring spring-boot spring-cloud-stream spring-data-jpa,"# Event Driven Applications with Spring Boot

This projects tries to capture various options you have when dealing with Event Driven Spring Boot applications.
The follwing Spring Technologies are being used:
- Spring Boot
- Spring Cloud Stream Rabbit
- Spring Data JPA

These examples contain various different ways to model and deal with events:
- Complete aggregates / entities in the events
- REST Resource URLs in events
- Partial parsing / handling of events in consumers
- Events as Atom Feeds

## Prerequisites
- You need to have Docker installed

## How to run and install the example
In the root directory you need to
1. Compile everything with ./mvnw package
2. Start everything up with docker-compose up --build

## Running on Kubernetes
Mind the KubernetesSetup.md file in the kubernetes directory

## URLs and Ports
Each of the modules is it's own Spring Boot Application which can be accessed as follows:

<table>
    <tr>
        <th>Name</th>
        <th>Application / Enpoint Type</th>
        <th>URL</th>
    </tr>
    <tr>
        <td>Application Process</td>
        <td>9000</td>
        <td>http://localhost:9000</td>
    </tr>
    <tr>
        <td>Credit Application</td>
        <td>9001</td>
        <td>http://localhost:9001/credit-application</td>
    </tr>
    <tr>
        <td>Customer</td>
        <td>9002</td>
        <td>http://localhost:9002/customer and http://localhost:9002/customer/feed</td>
    </tr>
    <tr>
        <td>Scoring</td>
        <td>9003</td>
        <td>No UI</td>
    </tr>
     <tr>
        <td>CreditDecision</td>
        <td>9004</td>
        <td>http://localhost:9004/credit-decision and http://localhost:9004/credit-decision/feed</td>
    </tr>
      
    
</table>

## Messaging Infrastructure & Domain Events

### Public Events

#### CreditApplicationNumberGeneratedEvent
Source: application-process

Persisted in source: no

Consumers:
- credit-application
- credit-decision

Topic: CreditApplicationNumberGeneratedTopic


#### CreditApplicationEnteredEvent
Source: credit-application

Persisted in source: yes in its own Table via JPA

Consumers:
- application-process
- credit-decision

Topic: CreditApplicationEnteredTopic


#### CustomerCreatedEvent
Source: customer

Persisted in source: no

Consumers:
- application-process
- credit-decision

Topic: CustomerCreatedTopic

#### ScoringPositiveEvent
Source: scoring

Persisted in source: no

Consumers:
- application-process
- credit-decision

Topic: ScoringPositiveTopic

#### ScoringNegativeEvent
Source: scoring

Persisted in source: no

Consumers:
- application-process
- credit-decision

Topic: ScoringNegativeTopic

#### ApplicationDeclinedEvent
Source: credit-decision

Persisted in source: not as an event

Consumers:
- application-process

Topic: ApplicationDeclinedTopic

### Internal Events

#### Credit-Application
- CreditDetailsEnteredEvent
- FinancialSituationEnteredEvent

Both events are stored
Source: credit-application
Storage: Own Table via JPA


### Feeds

#### Customer Feed
Url: http://localhost:9002/customer/feed

Contains URLs to Customer Resources

#### Credit Decision Feed
Url: http://localhost:9004/credit-decision/feed

Contains Application Numbers that have been confirmed


## Event Types being used
This demo shows various types of event types: Events with all the data, Events with Resource Urls and ""Events"" as Feeds

#### Events with all the data
Especially the CreditApplicationEnteredEvent falls into this category: it contains all of the data for the credit application
such as the financial situation and the details of the actual credit. By consuming this event you will not need additional
roundtrips to upstream systems

Other events that fall into this category are:
- ApplicationNumberGeneratedEvent
- ScoringNegativeEvent
- ScoringPositiveEvent
- ApplicationDeclinedEvent

##### Idea of Bounded Context:
Please take a close look at how the CreditApplicationEnteredEvent is being reflected in the scoring application. Yes, we
take in all the payload from the broker but the public model of the event has a clear focus on the scoring context's view 
  on the data.

#### Events with a Resource URL
These Events do not contain a lot of information. They may contian something like a business process identifier such as
the applicationNumber in this example but for the purpose of this demo I refrained from doing that. So the CustomerCreatedEvent
only contians the URL to the Customer REST Resource from which interested contexts can obtain the payload from.


#### ""Events"" via Feeds
Althoug the usage of feeds is no plain and pure event driven processing style I think that they come in handy when you
are dealing with situations like these:
- you have issues with your message broker and firewalls and these issues can't be resolved easily
- you need to have an event replay functionality in place that enables consumers to restore their replicated data

You can find ""Events via Feeds"" in the customer and the credit-decision (see Feeds) applications. "
peterl1084/cdiexample,master,44,21,2014-04-08T12:13:31Z,635,10,Vaadin CDI example project,,"# Vaadin Java EE app example

This is a work in progress Vaadin CDI example project that could be a starting point for a larger Java EE app.

Stuff that this app is built on:

 * [Vaadin](https://vaadin.com/)
 * [Java EE](http://www.oracle.com/technetwork/java/javaee/overview/index.html)
 * [JPA](http://en.wikipedia.org/wiki/Java_Persistence_API)
 * [Apache Shiro](http://shiro.apache.org)
 * [Vaadin CDI](http://vaadin.com/addon/vaadin-cdi)
 * [CDI events](http://docs.oracle.com/javaee/6/tutorial/doc/gkhic.html)
 * [MVP](http://en.wikipedia.org/wiki/Model–view–presenter)
 * The [new Valo theme for Vaadin](https://vaadin.com/blog/-/blogs/7-series) to make it look modern
 
TODO:

 * Limited UI for customers to edit their own details
 * Localization
 * Clean up, blog posts etc.

## To get started (plaining with this app in your dev environment):

Build should be IDE/platform indendent. So just

 * Checkout the the project with `git clone https://github.com/peterl1084/cdiexample.git`.
 * (OPTIONAL) define a datasource and configure it in ```backend/src/main/resources/META-INF/persistence.xml```. Development friendly Java EE servers like TomEE, WildFly and GlassFish will do this automatically for you, as we haven't defined ```<jta-data-source>``` in ```persistence.xml```
 * Build + Run/Debug in your favorite IDE
 * ... or use ```mvn install; cd ui; mvn tomee:run``` to launch it in TomEE without any configuration


"
wkrzywiec/library-hexagonal,master,251,54,2020-04-29T18:41:36Z,10405,46,An example application written in Hexagonal (Ports and Adapter) architecture,cqrs ddd docker docker-compose domain-driven-design hexagonal-architecture java-11 ports-and-adapters postgres spring-boot tdd,"# Library 
> written in *Hexagonal (Ports & Adapters) Architecture*

![Master Branch](https://github.com/wkrzywiec/library-hexagonal/workflows/Master%20Branch/badge.svg?branch=master) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=wkrzywiec_library-hexagonal&metric=alert_status)](https://sonarcloud.io/dashboard?id=wkrzywiec_library-hexagonal) [![Coverage](https://sonarcloud.io/api/project_badges/measure?project=wkrzywiec_library-hexagonal&metric=coverage)](https://sonarcloud.io/dashboard?id=wkrzywiec_library-hexagonal) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This is a small application that provides basic REST endpoints for managing library (add new book, reserve, borrow it, etc.). 

The technology behind it: 
* Java 11
* Postgres
* Spring Boot 

## Installing / Getting started

#### Using `docker-compose`

In the terminal run the following command:
```console
$ docker-compose up
``` 

#### Using Maven (with H2 or local Postgres database)

First compile an application:

```console
$ mvn clean package
```

Then, you have two options either run it with H2 database or with local Postgres database. For first approach just run:

```console
$ mvn spring-boot:run 
```

For a second option, check in the configuration file - `src/main/resources/application.yml` for profile *local-postgres* if connection details are correct and if so, run the command:
```console
$ mvn spring-boot:run -P local-postgres
```

#### Inside IntelliJ (with H2 or Postgres database)

First configure how you run the `LibraryHexagonalApplication.java` by adding `--spring.profiles.active=h2` (for H2 database) or `--spring.profiles.active=postgres` (for Postgres database) as a **Program argument**.

Then just run the `LibraryHexagonalApplication.java` class so it will use H2 database (you don't need to have postgres database up and running).

"
mapr-demos/finserv-application-blueprint,master,83,63,2016-09-26T19:42:54Z,16649,2,Example blueprint application for processing high-speed trading data.,,"BY USING THIS SOFTWARE, YOU EXPRESSLY ACCEPT AND AGREE TO THE TERMS OF THE AGREEMENT CONTAINED IN THIS GITHUB REPOSITORY.  See the file EULA.md for details.

#  An Example Application for Processing Stock Market Trade Data on the MapR Converged Data Platform

Stock exchanges offer real-time streams of information about the state of the market and trading activity. These data feeds channel a firehose of information that can be used to analyze market activity. However, these applications require a highly performant and reliable streaming infrastructure with accompanying services to process and store unbounded datasets. It can be challenging to build such infrastructures without incurring untenable operational expense and administrative burden.

This demo application focuses on interactive market analysis with a graphical user interface in Apache Zeppelin, however our goal is to use this application to tell a larger story about how the MapR Converged Data Platform can be used to *cost effectively* explore other stream processing use-cases, such as analyzing stock exchange data feeds for algorithmic trading or automated market surveillance. 

The intent of the application is to serve as a ""blueprint"" for building high-speed streaming applications on the MapR Converged Data Platform.  You can use the code as a base for developing your own workflow, including producers, consumers and analytical engines, and run queries against the indexed topics.  

## Overview

This project provides an engine for processing real time streams trading data from stock exchanges. The application consists of the following components:
- A Producer microservice that streams trades using the NYSE TAQ format.  The data source is the Daily Trades dataset described [here](http://www.nyxdata.com/Data-Products/Daily-TAQ). The schema for our data is detailed in Table 6, ""Daily Trades File Data Fields"", on page 26 of [Daily TAQ Client Specification (from December 1st, 2013)](http://www.nyxdata.com/doc/212759).  
- A multi-threaded Consumer microservice that indexes the trades by receiver and sender.
- Example Spark code for querying the indexed streams at interactive speeds, enabling Spark SQL queries.  
- Example code for persisting the streaming data to MapR-DB 
- Performance tests for benchmarking different configurations
- A supplementary python script to enhance the above TAQ dataset with ""level 2"" bid and ask data at a user-defined rate.

There are several beneficial aspects of the application that are worth highlighting:

- The Consumer microservice, performing the indexing, can be arbitrarily scaled simply by running more instances.  See below in this README for how to start the application.
- Jackson annotations are provided for easy translation of the data structures to JSON and persistence to MapR-DB.
- The application can handle 300,000 entries/second on a 3-node cluster, which is suitable for testing.  It does not require a large cluster, and takes advantage of the scaling properties of MapR Streams.
- The resulting index topics are small, and can be queried fast enough such that they can be used for interactive dashboards, such as in a Zeppelin notebook.

## Architecture

The application provides a financial intermediary service, running *bids* and *asks* between traders.  Traders are identified with a unique ID and each bid and ask is sent from one trader to a set of N receiving traders.

The following diagram shows how data moves through the architecture. The rounded rectangles represent processes that produce and/or consume data from MapR Streams topics. Java based microservices are used to ingest and manipulate streaming data using the Kafka API. Spark and Apache Zeppelin are used to provide streaming analytics and batch oriented visualization.

<img src=""https://github.com/mapr-demos/finserv-application-blueprint/blob/master/images/dataflow.gif"" width=""70%"">

## Prerequisites

This application requires MapR 5.2 and Spark 2.0, which can be easily installed with the [MapR Ecosystem Pack 2.0](http://maprdocs.mapr.com/home/InteropMatrix/r_MEP_52.html).
You can use MapR's free [Converged Community Edition](http://mapr.com/download) or the [Converged Enterprise Edition](https://www.mapr.com/products/mapr-distribution-editions).   

You will also need Git and Apache Maven in order to download and compile the provided source code.

## Building the application

Clone this repo and build the application with Maven.  A pom.xml file is included in the base directory. The remainder of this guide will assume that you clone the package to /home/mapr/.

```
cd /home/mapr/
git clone http://github.com/mapr-demos/finserv-application-blueprint.git
cd finserv-application-blueprint
mvn clean install
```
At this point you should see the resulting jar file in the target/ directory:  ```nyse-taq-streaming-1.0.jar```

Copy that jar package to the /home/mapr/ directory on each of your cluster nodes:

```
scp ./target/nyse-taq-streaming-1.0.jar mapr@<YOUR_MAPR_CLUSTER>:/home/mapr
```

### Step 1: Create the stream

A *stream* is a logical grouping of topics. They give us a way to group together topics and protect those topics with a single set of security permissions and other properties. MapR supports the Kafka API for interacting with streams.  For more information on Streams, see [https://www.mapr.com/products/mapr-streams](https://www.mapr.com/products/mapr-streams).

Run the following command from any node in your MapR cluster:

```
maprcli stream create -path /user/mapr/taq -produceperm p -consumeperm p -topicperm p -ttl 900
```

In that command we created the topic with public permission since we want to be able to run producers and consumers from remote computers. Verify the stream was created with this command:

```
maprcli stream info -path /user/mapr/taq
```

### Step 2: Create the topics

We only need to create one topic to get started, the rest are created by the application. Topics are created with the `maprcli` tool.  Run this command on a single node in the cluster:

```
maprcli stream topic create -path /user/mapr/taq -topic trades -partitions 3
```

Verify the topic was created successfully with this command:

```
maprcli stream topic list -path /user/mapr/taq
```

This enables 3 partitions in the topic for scaling across threads, more information on how partitions work can be found [here](http://maprdocs.mapr.com/51/MapR_Streams/concepts.html).

### Step 3: Start the ""Fan Out"" Consumer

We use a multi-threaded microservice that indexes the incoming information into separate topics by receiver and sender. We call this a ""fan out"" consumer, because it consumes tick data from incoming stock exchange stream and copies each tick record into topics belonging to all the participants of a trade. So for example, if this consumer sees an offer by Sender X to sell shares to recipients A, B, and C, then this consumer will copy that tick to four new topics, identified as sender_X, receiver_A, receiver_B, and receiver_C. This relationship is illustrated below:

<img src=""https://github.com/mapr-demos/finserv-application-blueprint/blob/master/images/fanout.png"" width=""40%"">

A ""tick"" of this data consists of:
```
{time, sender, id, symbol, prices, ..., [recipient*]}
```
For each message in the stream there is a single sender and multiple possible receipients.  The consumer will index these into separate topics so they can be queried.

Run the following command to start the consumer:

```
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar:/home/mapr/finserv-application-blueprint/src/test/resources com.mapr.demo.finserv.Run consumer /user/mapr/taq:trades 3
```

In this example we are starting 3 threads to handle the 3 partitions in topic, ```/user/mapr/taq:trades```.

### Step 4: Run the Producer

Run the producer with the following command. This will send all the trades contained in files under finserv-application-blueprint/data/ to `/user/mapr/taq:trades`, where '/user/mapr/taq' is the stream and 'trades' is the topic. 

```
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar com.mapr.demo.finserv.Run producer /home/mapr/finserv-application-blueprint/data/080449 /user/mapr/taq:trades
```

A small data file representing one second of trades, bids and asks (```data/080449```) is provided for convenience.  To generate more data, see the section 'Generating Data' below.


You should see the producer running and printing throughput numbers:
```
Throughput = 0.00 Kmsgs/sec published. Threads = 1. Total published = 2.
Throughput = 202.78 Kmsgs/sec published. Threads = 1. Total published = 411107.
Throughput = 377.08 Kmsgs/sec published. Threads = 1. Total published = 1139858.
Throughput = 463.34 Kmsgs/sec published. Threads = 1. Total published = 1865937.
Throughput = 478.99 Kmsgs/sec published. Threads = 1. Total published = 2406537.
```

This simulates ""live"" bids, asks and trades streaming from an exchange.

### Step 5: Persist stream data in a database

We'll explain two ways in which streaming data can be persisted into long-term storage. First we'll see how this can be done with MapR-DB, then we'll see how this can be done with Apache Hive.  

#### Persist stream data with MapR-DB

The ```Persister.java``` class uses Spark SQL to persist JSON records from MapR Streams into MapR-DB.

This class can be run with the following command:

```
java -cp `mapr classpath`:/home/mapr/finserv-application-blueprint/target/nyse-taq-streaming-1.0.jar com.mapr.demo.finserv.Persister -topics /user/mapr/taq:sender_0310,/user/mapr/taq:sender_0410 -table /user/mapr/ticktable -droptable -verbose
```
This creates a stream consumer that persists trades from senders #0310 and #0410 to MapR-DB in a table located at /mapr/my.cluster.com/user/mapr/ticktable (which will be overwritten if it already exists, per the ```-droptable``` option). That command will only see *new* messages in the trades topic because it tails the log, so run the following command to put more trade data into the stream:
```
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar:/home/mapr/finserv-application-blueprint/src/test/resources com.mapr.demo.finserv.Run consumer /user/mapr/taq:trades 3 &
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar com.mapr.demo.finserv.Run producer /home/mapr/finserv-application-blueprint/data/ /user/mapr/taq:trades
```

Here are some examples of how you can query the table created by the Persister:

Query the MapR-DB table with dbshell:

```
mapr dbshell
  maprdb mapr:> find /user/mapr/ticktable
```

Query the MapR-DB table from the Apache Drill command line:

	/opt/mapr/drill/drill-*/bin/sqlline -u jdbc:drill:
	0: jdbc:drill:> SELECT * FROM dfs.`/user/mapr/ticktable` LIMIT 10;

Query the MapR-DB table from the Apache Drill web interface, as shown below:

<img src = ""images/drill_query.png"" width=600px>


#### Persist stream data with Apache Hive

The ```SparkStreamingToHive``` class uses the Spark Streaming API to copy messages from the tail of streaming topics to Hive tables that can be analyzed in Zeppelin. Zeppelin can't directly access stream topics, so we use this utility to access streaming data from Zeppelin. Here's how to run this class:

```
/opt/mapr/spark/spark-2.0.1/bin/spark-submit --class com.mapr.demo.finserv.SparkStreamingToHive /home/mapr/nyse-taq-streaming-1.0-jar-with-dependencies.jar --topics <topic1>,<topic2>... --table <destination Hive table>
```

That command will only see *new* messages in the taq:trades topic because it tails the log, so when it says ""Waiting for messages"" then run the following command to put more trade data into the stream. This command was described in [step 4](https://github.com/mapr-demos/finserv-application-blueprint#step-4-run-the-producer):

```
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar com.mapr.demo.finserv.Run producer /home/mapr/finserv-application-blueprint/data/ /user/mapr/taq:trades
```

In the previous command, we consumed from the trades topic, which is the raw stream for every trader. If you want to save only trades from a specific trader, then run the following command. This will read messages from the topic associated with the trader called ```sender_0410``` and copy those messages to Hive. Remember, this tail operation so it will wait for new messages on that topic. 

```
/opt/mapr/spark/spark-2.0.1/bin/spark-submit --class com.mapr.demo.finserv.SparkStreamingToHive /home/mapr/nyse-taq-streaming-1.0-jar-with-dependencies.jar --topics /user/mapr/taq:sender_0410 --table ticks_from_0410
```

### Step 6: Build a Dashboard in Apache Zeppelin

There are many frameworks we could use to build an operational dashboard. [Apache Zeppelin](https://zeppelin.apache.org/) is a good choice because it supports a variety of ways to access data. Our goal is to build a dashboard that looks like this:

<img src = ""images/zepdash.png"" width=400px>

Here's what you need to do to setup a dashboard like that:

#### Install and Configure Zeppelin

We're going to assume you've already installed Apache Zeppelin and configured its Spark SQL interpretter to access Hive tables. If you haven't done that, then follow the instructions for installing Zeppelin in this blog post:

https://community.mapr.com/docs/DOC-2029-how-to-use-spark-pyspark-with-zeppelin-on-mapr-cdp-draft

#### Create Hive tables

Import the bank company names into a new hive table. Later, we'll map these names to bank IDs with a table join in Zeppelin. 

```
hive
  hive> CREATE TABLE banks(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
  hive> LOAD DATA LOCAL INPATH '/home/mapr/finserv-application-blueprint/resources/bank_list.csv' INTO TABLE banks;
```

Run this command to load streaming data into a Hive table:

```
/opt/mapr/spark/spark-2.0.1/bin/spark-submit --class com.mapr.demo.finserv.SparkStreamingToHive /home/mapr/nyse-taq-streaming-1.0.jar --topics /user/mapr/taq:trades --table streaming_ticks
```

That command will only see *new* messages in the trades topic because it tails the log, so when it says ""Waiting for messages"" then run the following command to put more trade data into the stream:

```
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar com.mapr.demo.finserv.Run producer /home/mapr/finserv-application-blueprint/data/ /user/mapr/taq:trades
```


#### Create a Zeppelin notebook

Open Zeppelin in a web browser.

Zeppelin divides notebooks into subsections called *paragraphs*. Create a new notebook in Zeppelin, then in a new paragraph enter the following and press the 'Play' icon (or keyboard shortcut, Shift+Enter):

```
%sql show tables
```

You should see the ```banks``` and ```streaming_ticks``` tables in the list. If not, look for an error in the logs under `/opt/zeppelin/logs/`.

We've provided a sample Zeppelin notebook which includes some sample SQL queries and charts to get you started. Load the `finserv-application-blueprint/resources/sample_zeppelin_notebook.json` file with the Import feature in the Zeppelin web UI. After you've imported it, you should see a new notebook called ""Stock Exchange Analysis"" in Zeppelin, which looks like this:

<img src = ""images/zepdash2.png"" width=600px>

## (Optional) Generate More Data

You can download 500MB more trade data with the following commands. Note, these data files are kept in a separate GitHub repository in order to keep this one to a manageable size.      

```
git clone https://github.com/mapr-demos/finserv-data-files
cd finserv-data-files
mkdir data
tar xvfz starter_datafiles.tar.gz -C data
```

You can then pass this ```data``` directory to the producer command described in [step 4](https://github.com/mapr-demos/finserv-application-blueprint#step-4-run-the-producer):

```
java -cp `mapr classpath`:/home/mapr/nyse-taq-streaming-1.0.jar com.mapr.demo.finserv.Run producer ./data/ /user/mapr/taq:trades
```

## (Optional) Clean Up

To save disk space, its a good idea to remove the stream and Hive tables that you created in prior steps.

Here's how to delete a stream and all the associated topics:

```
maprcli stream delete -path /user/mapr/taq
```

Here's how to delete a Hive table:

```
rm -rf /mapr/my.cluster.com/user/hive/warehouse/streaming_ticks/
```


# Get Community Support!

Visit the [MapR Community](https://community.mapr.com/) pages where you can post questions and discuss your use case.





"
huaweicse/ServiceComb-Company-WorkShop,master,83,47,2017-06-07T08:31:37Z,1350,1,MicroSerivce WorkShop Example for user to use ServiceComb,,"# ServiceComb Demo - Company [![Build Status](https://travis-ci.org/ServiceComb/ServiceComb-Company-WorkShop.svg?branch=master)](https://travis-ci.org/ServiceComb/ServiceComb-Company-WorkShop)[![Coverage Status](https://coveralls.io/repos/github/ServiceComb/ServiceComb-Company-WorkShop/badge.svg)](https://coveralls.io/github/ServiceComb/ServiceComb-Company-WorkShop)

## Purpose
In order for users to better understand how to develop microservices using ServiceComb, an easy to
understand demo is provided.

## Architecture of Company
* Manager (API gateway) 
* Doorman (authentication service)
* Worker (computing service)
* Beekeeper (computing service)
* Bulletin board (service registry)
* Project archive (request cache)
* Human resource (service governance)

Please read the [blog post](http://servicecomb.io/docs/linuxcon-workshop-demo/) on the detailed explanation of this project.

## Prerequisites
You will need:
1. [Oracle JDK 1.8+][jdk]
2. [Maven 3.x][maven]
3. [Docker][docker]
4. [Docker compose(optional)][docker_compose]
5. [Docker machine(optional)][docker_machine]
6. [curl][curl]
7. [MySQL][mysql]

[jdk]: http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
[maven]: https://maven.apache.org/install.html
[docker]: https://www.docker.com/get-docker
[docker_compose]: https://docs.docker.com/compose/install/
[docker_machine]: https://docs.docker.com/machine/install-machine/
[curl]: https://curl.haxx.se
[mysql]: https://dev.mysql.com/downloads/

## Run Services
A `docker-compose.yaml` file is provided to start all services and their dependencies as docker containers.
1. Build all service images using command `mvn package -Pdocker`
2. Run all service images using command `docker-compose up`

If you are using [Docker Toolbox](https://www.docker.com/products/docker-toolbox), please add an extra profile `-Pdocker-machine`.

```mvn package -Pdocker -Pdocker-machine```

## Run Integration Tests

```
mvn verify -Pdocker -Pdocker-machine
```

## Verify services
You can verify the services using curl by the following steps:
1. Retrieve manager's ip address
  * If you use docker compose:
    ```bash
    export HOST=""127.0.0.1:8083""
    ```
  * If you use docker machine(supposed your docker machine name is `default`):
    ```bash
    export HOST=$(docker-machine ip default):8083
    ```
2. Log in and retrieve token from `Authorization` section
    ```bash
    curl -v -H ""Content-Type: application/x-www-form-urlencoded"" -d ""username=jordan&password=password"" -XPOST ""http://$HOST/doorman/rest/login""
    ```  
    Then you can copy the token from the `Authorization` section and use it to replace the `Authorization` header in the following requests.
3. Get the sixth fibonacci number from the worker service
    ```bash
    curl -H ""Authorization: replace_with_the_authorization_token"" -XGET ""http://$HOST/worker/fibonacci/term?n=6""
    ```
4. Get the number of drone's ancestors at the 30th generation from the beekeeper service
    ```bash
    curl -H ""Authorization: replace_with_the_authorization_token"" -XGET ""http://$HOST/beekeeper/rest/drone/ancestors/30""
    ```
5. Get the number of queen's ancestors at the 30th generation from the beekeeper service
    ```bash
    curl -H ""Authorization: replace_with_the_authorization_token"" -XGET ""http://$HOST/beekeeper/rest/queen/ancestors/30""
    ```

## Auto deploy on [Huawei Cloud][huawei_cloud]
To auto compile, build, deploy and run this workshop demo on Huawei Cloud's [Service Stage Platform][service_stage], you need the following steps:

1. A registered [Service Stage][service_stage] account.
2. Auto build and publish your docker image to Huawei's Image Warehouse, details can refer to [auto publish guide][publish_guide].
3. Auto deploy using Huawei Cloud's orchestration feature, details can refer to [orchestration guide][orchestration_guide]. 

[huawei_cloud]: http://www.hwclouds.com
[publish_guide]: docs/how-to-auto-publish-images-to-huawei-cloud.md
[orchestration_guide]: docs/how-to-auto-deploy-on-huawei-cloud.md

## Auto deploy on kubernetes cluster      
To auto pull images from servicecomb in docker hub, run on kubernetes cluster whether on gce or bare-metal.      
Reference to [Run Company on Kubernetes Cluster](kubernetes/README.md)

## 在华为云上自动部署

本章节介绍基于华为微服务云应用平台[Service Stage ][service_stage]，实现自动编译、构建、部署和运行的步骤。

1. 一个已注册的[Service Stage][service_stage]帐号。
2. 自动编译、构建和发布Docker镜像到华为的镜像仓库，详情可见[自动发布指南][publish_guide_cn] 。
3. 使用华为云的编排功能自动部署微服务，详情可见[自动部署指南][orchestration_guide_cn] 。

[service_stage]: https://servicestage.hwclouds.com/servicestage
[publish_guide_cn]: docs/how-to-auto-publish-images-to-huawei-cloud-cn.md
[orchestration_guide_cn]: docs/how-to-auto-deploy-on-huawei-cloud-cn.md
"
bduncavage/recyclerViewToTheRescue,master,72,15,2015-06-04T06:45:55Z,214,1,Examples of how to use RecyclerView to achieve complex list UIs,,"# RecyclerView to The Rescue
Examples of how to use RecyclerView to achieve complex list UIs

RecyclerView is the evolution of the legacy ListView and GridView in Android. If you aren't using it yet, you should be.
This repository contains a simple sample project that illustrates how to use RecyclerView to achieve simple and complex list UIs.

## Simple List
![Simple List Example](http://i.imgur.com/FltQVqF.gif)

## Complex Grid
![Complex Grid Example](http://i.imgur.com/2PoeB4X.gif)
"
k33ptoo/JavaFX-MySQL-Login,master,105,57,2018-09-12T12:27:48Z,3501,1,A JavaFX example SignIn/SignUp with MySQL database intergration.,java javafx scenebuilder,"# JAVAFX LOGIN UI DESIGN WITH MYSQL DB INTERGRATION

Focus areas

- UI Design
- DB integration
- Insert - Retrieve

A simple sample to get you started.

![](https://github.com/k33ptoo/JavaFX-MySQL-Login/blob/master/img.png)

![](https://github.com/k33ptoo/JavaFX-MySQL-Login/blob/master/img2.png)"
minhthuy30197/LearnSpringBoot,master,30,73,2020-01-17T02:33:15Z,275,0,My example course code when learning Spring Boot,,"# TUTORIAL HƯỚNG DẪN HỌC SPRING BOOT
"
sdaschner/coffee,master,42,36,2018-06-26T05:33:33Z,1223,0,Yet another coffee shop example project,istio javaee kubernetes microprofile,
gradle/gradle-build-scan-quickstart,main,140,271,2016-03-02T00:39:24Z,936,0,An example project to experience the Build Scan® service of Develocity with Gradle builds.,,"# Build Scan® quickstart

This is an example project that you can use to experience the [Build Scan® service of Develocity][gradle.com].

It is a small Java project that has the [Develocity Gradle Plugin][manual] already applied.

## Create a Build Scan®

Follow these simple steps to create and publish a Build Scan® on [scans.gradle.com][scans.gradle.com]:

1. Clone this project
1. Run `./gradlew build --scan`
1. Agree to the [Terms of Service][terms-of-service] on the command line

The build should end with something similar to:

    Publishing build scan...
    https://gradle.com/s/ria2s2x5oaazq

Follow the green link shown at the end of the build to view your Build Scan® on [scans.gradle.com][scans.gradle.com].

Note: If you run a build without the `--scan` flag, no Build Scan® will be created and
no information will be sent.

## Experiment with Build Scans

Create different kinds of Build Scans by locally modifying this quickstart project. Here are some ideas:

- Edit `src/main/java/example/Example.java` to introduce compile errors
- Edit `src/test/java/example/ExampleTest.java` to introduce test failures
- Add more dependencies, more plugins, and more projects

Alternatively, enable one of your own builds to produce Build Scans by following the [step-by-step instructions][scans.gradle.com].

## Learn more

Read the [Develocity Gradle Plugin User Manual][manual] to learn more about the Build Scan® service of Develocity and the Develocity Gradle Plugin.

## Need help?

Talk to us on the [Gradle forum][gradle-forum].

If you are completely new to the Gradle Build Tool, start [here][gradle-download].

## License

The Build Scan™ quickstart project is open-source software released under the [Apache 2.0 License][apache-license].

[apache-license]: https://www.apache.org/licenses/LICENSE-2.0.html
[gradle-download]: https://gradle.org/install/
[manual]: https://docs.gradle.com/enterprise/gradle-plugin/
[gradle.com]: https://www.gradle.com
[terms-of-service]: https://gradle.com/terms-of-service
[scans.gradle.com]: https://scans.gradle.com/
[gradle-forum]: https://discuss.gradle.org/c/help-discuss/scans"
quux00/hive-json-schema,master,227,70,2013-07-07T22:56:30Z,306,14,Tool to generate a Hive schema from a JSON example doc,,"# Overview

The best tool for using JSON docs with Hive is [rcongui's openx Hive-JSON-Serde](https://github.com/rcongiu/Hive-JSON-Serde).  When using that JSON Serde, you define your Hive schema based on the contents of the JSON.

Hive schemas understand arrays, maps and structs.  You can map a JSON array to a Hive array and a JSON ""object"" to either a Hive map or struct.  I prefer to map JSON objects to structs.

This tool will take a curated JSON document and generate the Hive schema (CREATE TABLE statement) for use with the openx Hive-JSON-Serde.  I say ""curated"" because you should ensure that every possible key is present (with some arbitrary value of the right data type) and that all arrays have at least one entry.

If the curated JSON example you provide has more than one entry in an array, *only the first one will be examined*, so you should ensure that it has all the fields.

For more information on using the openx Hive-JSON-SerDe, see my [blog post entry](http://thornydev.blogspot.com/2013/07/querying-json-records-via-hive.html).


# Build

    mvn package

Creates `json-hive-schema-1.0.jar` and `json-hive-schema-1.0-jar-with-dependencies.jar` in the `target` directory.



# Usage

#### with the non-executable jar

    java -cp target/json-hive-schema-1.0.jar net.thornydev.JsonHiveSchema file.json

    # optionally specify the name of the table
    java -cp target/json-hive-schema-1.0.jar net.thornydev.JsonHiveSchema file.json my_table_name


#### with the executable jar

    java -jar target/json-hive-schema-1.0-jar-with-dependencies.jar file.json

    java -jar target/json-hive-schema-1.0-jar-with-dependencies.jar file.json my_table_name


Both print the Hive schema to stdout.


#### Example:

Suppose I have the JSON document:

    {
      ""description"": ""my doc"",
      ""foo"": {
        ""bar"": ""baz"",
        ""quux"": ""revlos"",
        ""level1"" : {
          ""l2string"": ""l2val"",
          ""l2struct"": {
            ""level3"": ""l3val""
          }
        }
      },
      ""wibble"": ""123"",
      ""wobble"": [
        {
          ""entry"": 1,
          ""EntryDetails"": {
            ""details1"": ""lazybones"",
            ""details2"": 414
          }
        },
        {
          ""entry"": 2,
          ""EntryDetails"": {
            ""details1"": ""entry 123""
          }
        }
      ]
    }


I recommend distilling it down to a doc with a single entry in each array and one that has all possible keys filled in - the values don't matter as long as they are present and a type can be determined.

So for the curated version of the JSON I've removed one of the entries from the ""wobble"" array and ensured that the remaining one has all the fields:

    {
      ""description"": ""my doc"",
      ""foo"": {
        ""bar"": ""baz"",
        ""quux"": ""revlos"",
        ""level1"" : {
          ""l2string"": ""l2val"",
          ""l2struct"": {
            ""level3"": ""l3val""
          }
        }
      },
      ""wibble"": ""123"",
      ""wobble"": [
        {
          ""entry"": 1,
          ""EntryDetails"": {
            ""details1"": ""lazybones"",
            ""details2"": 414
          }
        }
      ]
    }



Now generate the schema:

    $ java -jar target/json-hive-schema-1.0-jar-with-dependencies.jar in.json TopQuark
    CREATE TABLE TopQuark (
      description string,
      foo struct<bar:string, level1:struct<l2string:string, l2struct:struct<level3:string>>, quux:string>,
      wibble string,
      wobble array<struct<entry:int, entrydetails:struct<details1:string, details2:int>>>)
    ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe';



You can then load your data into Hive and run queries like this:

    hive > select wobble.entry, wobble.EntryDetails.details1, wobble.EntryDetails[0].details2 from TopQuark;
    entry   details1                    details2
    [1,2]   [""lazybones"",""entry 123""]   414
    Time taken: 15.665 seconds
"
mark-watson/java_practical_semantic_web,master,77,25,2010-03-25T21:30:50Z,38262,1,Code examples for my book Practical Semantic Web Programming (Java, Scala,
ozlerhakan/java9-module-examples,master,25,8,2017-11-24T11:17:04Z,677,0,a list of Java 9 module samples to dive into the modular world ,java java9 java9-jigsaw jigsaw modularity module serviceloader,
link-intersystems/blog,master,32,68,2014-08-22T05:53:19Z,615,1,Example code and projects used in our blogs.,,"Travis CI
=========
[![Build Status](https://travis-ci.org/link-intersystems/blog.svg?branch=master)](https://travis-ci.org/link-intersystems/blog)


blog
====

This repository contains example code and projects used in our blogs:

- [Clean Architecture Example In Pure Java](https://github.com/link-intersystems/clean-architecture-example)
- [Anemic vs. Rich Domain Models](http://www.link-intersystems.com/blog/2011/10/01/anemic-vs-rich-domain-models/)
- [The MVC pattern implemented with java swing](http://www.link-intersystems.com/blog/2013/07/20/the-mvc-pattern-implemented-with-java-swing/)
- [A plug-in architecture implemented with java](https://www.link-intersystems.com/blog/2016/01/02/a-plug-in-architecture-implemented-with-java/)
- [Separation of api and implementation](http://www.link-intersystems.com/blog/2012/02/26/separation-of-api-and-implementation/)
- [Custom swing component renderers](http://www.link-intersystems.com/blog/2014/10/19/custom-swing-component-renderers/)
- [Singleton implementation pitfalls](http://www.link-intersystems.com/blog/2015/05/01/singleton-implementation-pitfalls/)




"
gorbin/ASNETutorial,master,100,74,2014-09-02T11:32:56Z,281,11,Simple example project for https://github.com/gorbin/ASNE library,,"ASNETutorial    [![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-ASNETutorial-brightgreen.svg?style=flat)](https://android-arsenal.com/details/3/921) [![Codeproject](https://img.shields.io/badge/Codeproject-article-ff9900.svg?style=flat)](http://www.codeproject.com/Articles/815900/Android-social-network-integration)
============
![](https://raw.githubusercontent.com/gorbin/ASNE/master/resources/recomended.png)
Simple example project for https://github.com/gorbin/ASNE library

Today social network integration to your android application is common practice - it makes user easily login to your app and share their actions. There are a lot of ways to do it - usually developers add native social network SDK or use API for every network. It provides login via installed social network application or native dialogs. You have to spend time and nerves to learn and use different social network SDKs.

What if you need to add one more social network for your application? Sometimes you have to reorganize or redo all your integrations. This leads to idea to create and implement common interface for all social networks. Fortunately there is an open source modular library [ASNE](https://github.com/gorbin/ASNE) that allows you to choose necessary social network and provides full sdk and common interface for most oftenly used requests(login, share, friendslist & etc) It saves your time and simplifies adding another networks in the future. Moreover you can easily add any other social network as new module - the similar way as it's done in other modules. 

In this tutorial you can learn how easily integrate Facebook, Twitter in android application using [ASNE modules](https://github.com/gorbin/ASNE). This is very basic tutorial with login, sharing link and showing friends list.
 

##Registering app - getting keys for your application
In order to implement Social networks in your application you need keys to make API calls. So register a new social network application and get the keys. Check small tutorial how to get it:

 - [Facebook](https://github.com/gorbin/ASNE/wiki/Create-Facebook-App)
 - [Twitter](https://github.com/gorbin/ASNE/wiki/Create-Twitter-App)
 - [LInkedIn](https://github.com/gorbin/ASNE/wiki/Create-LinkedIn-App)

To continue you need 
- Facebook App ID 
- Twitter consumer key and consumer secret
- LinkedIn consumer key and consumer secret

##Integrating Facebook, Twitter and LinkedIn to your application

1. Create new Project in Android Studio
2. Let's save our social network keys in `values/strings.xml`
    	
    **strings.xml**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/res/values/strings.xml))
     ```xml
    <?xml version=""1.0"" encoding=""utf-8""?>
        <resources>
            <string name=""app_name"">ASNE-tutorial</string>
        
            <string name=""facebook_app_id"">
    	        1646388738920557
            </string>
            <string name=""twitter_consumer_key"">
    	        BBQAUAVKYzmYtvEcNhUEvGiKd
            </string>
    			byZzHPxE1tkGmnPEj5zUyc7MG464Q1LgNRcwbBJV1Ap86575os
    		</string>
            <string name=""linkedin_consumer_key"">
    	        75ubsp337ll7sf
    	    </string>
            <string name=""linkedin_consumer_secret"">
    	        8DVk4hi3wvEyzjbh
    	    </string>
        </resources>
    ```	
3. Add permissions and meta data - open `AndroidManifest.xml` file and add uses-permission for INTERNET, ACCESS_NETWORK_STATE and add meta-data for facebook(add appId key)
    
    **AndroidManifest.xml**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/AndroidManifest.xml))
    ```xml
    <?xml version=""1.0"" encoding=""utf-8""?>
    <manifest xmlns:android=""http://schemas.android.com/apk/res/android""
        package=""asne_tutorial.githubgorbin.com.asne_tutorial"" >
    
        <uses-permission android:name=""android.permission.INTERNET"" />
        <uses-permission android:name=""android.permission.ACCESS_NETWORK_STATE""/>
    
        <application
            android:allowBackup=""true""
            android:icon=""@drawable/ic_launcher""
            android:label=""@string/app_name""
            android:theme=""@style/AppTheme"" >
            <activity
                android:name="".MainActivity""
                android:label=""@string/app_name"" >
                <intent-filter>
                    <action android:name=""android.intent.action.MAIN"" />
                    <category android:name=""android.intent.category.LAUNCHER"" />
                </intent-filter>
            </activity>
    
            <meta-data
                android:name=""com.facebook.sdk.ApplicationId""
                android:value=""@string/facebook_app_id""/>
        </application>
    
    </manifest>
    ```
4. Set dependencies for [asne-modules](https://github.com/gorbin/ASNE):
    
    Open _Project Structure_ => choose your module and open _Dependencies_ => _Add new library dependency_

 ![add library dependecy](http://i.imgur.com/4k62Ux1.png)
    
 Then search for `asne` and add **asne-facebook, asne-twitter, asne-linkedin**
    
 ![search asne](http://i.imgur.com/gYou0Uf.png)
    
 or just add them manually to `build.gradle`
    
 **build.gradle**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/build.gradle))
    
 ```
 apply plugin: 'com.android.application'

     android {
        compileSdkVersion 19
        buildToolsVersion '20.0.0'
        
        defaultConfig {
            applicationId ""asne_tutorial.githubgorbin.com.asne_tutorial""
            minSdkVersion 10
            targetSdkVersion 19
            versionCode 1
            versionName ""1.0""
        }
        buildTypes {
            release {
                runProguard false
                proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
            }
        }
     }
    
    dependencies {
        compile fileTree(include: ['*.jar'], dir: 'libs')
        compile 'com.android.support:appcompat-v7:20.0.0'
        compile 'com.github.asne:asne-facebook:0.3.1'
        compile 'com.github.asne:asne-linkedin:0.3.1'
        compile 'com.github.asne:asne-twitter:0.3.1'
    }
 ```
5. Lets create some layouts
  Just login buttons in main fragment
 **main_fragment.xml**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/res/layout/main_fragment.xml))
    ```xml
    <?xml version=""1.0"" encoding=""utf-8""?>
    <LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
        android:orientation=""vertical"" android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:background=""#FFCCCCCC"">
    
        <Button
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:text=""Login via Facebook""
            android:id=""@+id/facebook""
            android:layout_gravity=""center_horizontal""
            android:background=""#3b5998""
            android:layout_margin=""8dp""
            android:textColor=""#ffffffff"" />
        <Button
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:text=""Login via Twitter""
            android:id=""@+id/twitter""
            android:layout_gravity=""center_horizontal""
            android:background=""#55ACEE""
            android:layout_margin=""8dp""
            android:textColor=""#ffffffff""/>
        <Button
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:text=""Login via LinkedIn""
            android:id=""@+id/linkedin""
            android:layout_gravity=""center_horizontal""
            android:background=""#287bbc""
            android:layout_margin=""8dp""
            android:textColor=""#ffffffff""/>
    </LinearLayout>
    ```
 Create simple profile card for user
    **profile_fragment.xml**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/res/layout/profile_fragment.xml))
    ```xml
    <?xml version=""1.0"" encoding=""utf-8""?>
    <ScrollView
        xmlns:android=""http://schemas.android.com/apk/res/android""
        android:layout_width=""fill_parent""
        android:layout_height=""fill_parent""
        android:background=""@color/grey_light"">
    
        <RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_alignParentTop=""true""
            android:layout_alignParentLeft=""true""
            android:layout_alignParentStart=""true""
            android:layout_margin=""8dp""
            android:id=""@+id/frame""
            android:background=""@color/dark"">
    
            <RelativeLayout
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:layout_alignParentTop=""true""
                android:layout_alignParentLeft=""true""
                android:layout_alignParentStart=""true""
                android:layout_margin=""3dp""
                android:id=""@+id/card""
                android:background=""#FFFFFF"">
    
                <ImageView
                    android:layout_width=""100dp""
                    android:layout_height=""100dp""
                    android:id=""@+id/imageView""
                    android:layout_margin=""8dp""
                    android:padding=""2dp""
                    android:background=""@color/grey_light""
                    android:layout_alignParentTop=""true""
                    android:layout_alignParentLeft=""true""
                    android:layout_alignParentStart=""true""
                    android:src=""@drawable/user""
                    android:adjustViewBounds=""true""
                    android:cropToPadding=""true""
                    android:scaleType=""centerCrop""/>
    
                <TextView
                    android:layout_width=""wrap_content""
                    android:layout_height=""wrap_content""
                    android:textAppearance=""?android:attr/textAppearanceLarge""
                    android:text=""NoName""
                    android:maxLines=""3""
                    android:singleLine=""false""
                    android:id=""@+id/name""
                    android:padding=""8dp""
                    android:layout_alignTop=""@+id/imageView""
                    android:layout_toRightOf=""@+id/imageView""
                    android:layout_toEndOf=""@+id/imageView""
                    android:layout_alignParentRight=""true""
                    android:layout_alignParentEnd=""true"" />
    
                <TextView
                    android:layout_width=""wrap_content""
                    android:layout_height=""wrap_content""
                    android:text=""null""
                    android:maxLines=""3""
                    android:singleLine=""false""
                    android:id=""@+id/id""
                    android:padding=""8dp""
                    android:layout_below=""@+id/name""
                    android:layout_alignLeft=""@+id/name""
                    android:layout_alignStart=""@+id/name"" />
    
                <TextView
                    android:layout_width=""wrap_content""
                    android:layout_height=""wrap_content""
                    android:text=""""
                    android:id=""@+id/info""
                    android:padding=""8dp""
                    android:layout_marginBottom=""4dp""
                    android:layout_below=""@+id/imageView""
                    android:layout_alignParentLeft=""true""
                    android:layout_alignParentStart=""true"" />
    
            </RelativeLayout>
            <LinearLayout
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:id=""@+id/buttonLayout""
                android:layout_below=""@+id/card""
                android:layout_alignParentLeft=""true""
                android:layout_alignParentRight=""true""
                android:gravity=""center""
                android:background=""@color/grey_light"">
    
                <Button
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:text=""Friends""
                    android:id=""@+id/friends""
                    android:padding=""8dp""
                    android:background=""@color/dark""
                    android:layout_marginRight=""1dp""
                    android:layout_weight=""1""
                    android:textColor=""#ffffffff""/>
                <Button
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:text=""Share""
                    android:id=""@+id/share""
                    android:padding=""8dp""
                    android:background=""@color/dark""
                    android:layout_weight=""1""
                    android:textColor=""#ffffffff""/>
            </LinearLayout>
        </RelativeLayout>
    
    </ScrollView>
    ```

 and save social networks colors to

 **color.xml**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/res/values/colors.xml))
    ```xml
    <?xml version=""1.0"" encoding=""utf-8""?>
    <resources>
        <color name=""grey_light"">#FFCCCCCC</color>
        <color name=""dark"">#4b4b4b</color>
        <color name=""facebook"">#3b5998</color>
        <color name=""twitter"">#55ACEE</color>
        <color name=""linkedin"">#287bbc</color>
    </resources>
    ```
    
6. Let's setup `MainActivity.java` We should set up `onActivityResult` method to catch responses after requesting login

    **MainActivity.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/MainActivity.java))
    
 ```java
    public static final String SOCIAL_NETWORK_TAG = ""SocialIntegrationMain.SOCIAL_NETWORK_TAG"";
    
    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        super.onActivityResult(requestCode, resultCode, data);
        Fragment fragment = getSupportFragmentManager().findFragmentByTag(SOCIAL_NETWORK_TAG);
        if (fragment != null) {
            fragment.onActivityResult(requestCode, resultCode, data);
        }
    }
 ```
 After every login form social networks send `onActivityResult` and we should check it and send to our `SocialNetworkManager` which deliver it to right `SocialNetwork`
 
7. Create `MainFragment.java` and begin transaction of this fragmetn in `MainActivity.java`

    **MainActivity.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/MainActivity.java))
    
    ```java
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        
        if (savedInstanceState == null) {
            getSupportFragmentManager().beginTransaction()
                .add(R.id.container, new MainFragment())
                .commit();
        }
    
    }
    ```
    
8. Integrating of any social network is simple:

    * Get `SocialNetworkManager`
    
    ```java
    mSocialNetworkManager = (SocialNetworkManager) getFragmentManager().findFragmentByTag(MAinActivity.SOCIAL_NETWORK_TAG);
    ```
    
    * Get keys from `values.xml` - note Facebook appId we used in `AndroidManifest.xml`
    
    ```java
    String TWITTER_CONSUMER_KEY = getActivity().getString(R.string.twitter_consumer_key);
    String TWITTER_CONSUMER_SECRET = getActivity().getString(R.string.twitter_consumer_secret);
    String TWITTER_CALLBACK_URL = ""oauth://ASNE"";
    String LINKEDIN_CONSUMER_KEY = getActivity().getString(R.string.linkedin_consumer_key);
    String LINKEDIN_CONSUMER_SECRET = getActivity().getString(R.string.linkedin_consumer_secret);
    String LINKEDIN_CALLBACK_URL = ""https://asneTutorial"";
    ```
    * Create chosen `SocialNetworks` with permissions
    
    ```java
    ArrayList<String> fbScope = new ArrayList<String>();
    fbScope.addAll(Arrays.asList(""public_profile, email, user_friends""));
    FacebookSocialNetwork fbNetwork = new FacebookSocialNetwork(this, fbScope);

    // permissions for twitter in developer twitter console
    TwitterSocialNetwork twNetwork = new TwitterSocialNetwork(this, TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET, TWITTER_CALLBACK_URL);

    String linkedInScope = ""r_basicprofile+r_fullprofile+rw_nus+r_network+w_messages+r_emailaddress+r_contactinfo"";
    LinkedInSocialNetwork liNetwork = new LinkedInSocialNetwork(this, LINKEDIN_CONSUMER_KEY, LINKEDIN_CONSUMER_SECRET, LINKEDIN_CALLBACK_URL, linkedInScope);
        
    ```
    
    * Check if `SocialNetworkManager` is null init it and add `SocialNetworks` to it
    
    ```java
    mSocialNetworkManager = new SocialNetworkManager();
    
    mSocialNetworkManager.addSocialNetwork(fbNetwork);
    mSocialNetworkManager.addSocialNetwork(twNetwork);
    mSocialNetworkManager.addSocialNetwork(liNetwork);
    
    //Initiate every network from mSocialNetworkManager
    getFragmentManager().beginTransaction().add(mSocialNetworkManager, MAinActivity.SOCIAL_NETWORK_TAG).commit();
    mSocialNetworkManager.setOnInitializationCompleteListener(this);
    ```
    don't forget to implement `SocialNetworkManager.OnInitializationCompleteListener`
     
    * If `SocialNetworkManager` - come from another fragment where we already init it - get all initialized social networks and add to them necessary listeners 
    
    ```java
    if(!mSocialNetworkManager.getInitializedSocialNetworks().isEmpty()) {
        List<SocialNetwork> socialNetworks = mSocialNetworkManager.getInitializedSocialNetworks();
        for (SocialNetwork socialNetwork : socialNetworks) {
            socialNetwork.setOnLoginCompleteListener(this);
        }
    ```
    don't forget to implement `OnLoginCompleteListener`
    * Now we need to catch callback after initializing of `SocialNetworks`
    
    ```java
    @Override
    public void onSocialNetworkManagerInitialized() {
        for (SocialNetwork socialNetwork : mSocialNetworkManager.getInitializedSocialNetworks()) {
            socialNetwork.setOnLoginCompleteListener(this);
            initSocialNetwork(socialNetwork);
        }
    }
    ```
    don't forget to implement `OnLoginCompleteListener`
    
 Full `onCreateView` and `onSocialNetworkManagerInitialized` from MainFragment with initializing and setting listener to buttons
    
    **MainFragment.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/MainFragment.java))
    
    ```java
    public static SocialNetworkManager mSocialNetworkManager;
    /**
     * SocialNetwork Ids in ASNE:
     * 1 - Twitter
     * 2 - LinkedIn
     * 3 - Google Plus
     * 4 - Facebook
     * 5 - Vkontakte
     * 6 - Odnoklassniki
     * 7 - Instagram
     */
    public static final int TWITTER = 1;
    public static final int LINKEDIN = 2;
    public static final int FACEBOOK = 4;
    
    private Button facebook;
    private Button twitter;
    private Button linkedin;

    public MainFragment() {
    }

    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container,
                             Bundle savedInstanceState) {
        View rootView = inflater.inflate(R.layout.main_fragment, container, false);
        ((MainActivity)getActivity()).getSupportActionBar().setTitle(R.string.app_name);
        // init buttons and set Listener
        facebook = (Button) rootView.findViewById(R.id.facebook);
        facebook.setOnClickListener(loginClick);
        twitter = (Button) rootView.findViewById(R.id.twitter);
        twitter.setOnClickListener(loginClick);
        linkedin = (Button) rootView.findViewById(R.id.linkedin);
        linkedin.setOnClickListener(loginClick);

        //Get Keys for initiate SocialNetworks
        String TWITTER_CONSUMER_KEY = getActivity().getString(R.string.twitter_consumer_key);
        String TWITTER_CONSUMER_SECRET = getActivity().getString(R.string.twitter_consumer_secret);
        String LINKEDIN_CONSUMER_KEY = getActivity().getString(R.string.linkedin_consumer_key);
        String LINKEDIN_CONSUMER_SECRET = getActivity().getString(R.string.linkedin_consumer_secret);

        //Chose permissions
        ArrayList<String> fbScope = new ArrayList<String>();
        fbScope.addAll(Arrays.asList(""public_profile, email, user_friends""));
        String linkedInScope = ""r_basicprofile+rw_nus+r_network+w_messages"";

        //Use manager to manage SocialNetworks
        mSocialNetworkManager = (SocialNetworkManager) getFragmentManager().findFragmentByTag(SOCIAL_NETWORK_TAG);

        //Check if manager exist
        if (mSocialNetworkManager == null) {
            mSocialNetworkManager = new SocialNetworkManager();

            //Init and add to manager FacebookSocialNetwork
            FacebookSocialNetwork fbNetwork = new FacebookSocialNetwork(this, fbScope);
            mSocialNetworkManager.addSocialNetwork(fbNetwork);

            //Init and add to manager TwitterSocialNetwork
            TwitterSocialNetwork twNetwork = new TwitterSocialNetwork(this, TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET);
            mSocialNetworkManager.addSocialNetwork(twNetwork);

            //Init and add to manager LinkedInSocialNetwork
            LinkedInSocialNetwork liNetwork = new LinkedInSocialNetwork(this, LINKEDIN_CONSUMER_KEY, LINKEDIN_CONSUMER_SECRET, linkedInScope);
            mSocialNetworkManager.addSocialNetwork(liNetwork);

            //Initiate every network from mSocialNetworkManager
            getFragmentManager().beginTransaction().add(mSocialNetworkManager, SOCIAL_NETWORK_TAG).commit();
            mSocialNetworkManager.setOnInitializationCompleteListener(this);
        } else {
            //if manager exist - get and setup login only for initialized SocialNetworks
            if(!mSocialNetworkManager.getInitializedSocialNetworks().isEmpty()) {
                List<SocialNetwork> socialNetworks = mSocialNetworkManager.getInitializedSocialNetworks();
                for (SocialNetwork socialNetwork : socialNetworks) {
                    socialNetwork.setOnLoginCompleteListener(this);
                    initSocialNetwork(socialNetwork);
                }
            }
        }
        return rootView;
    }

    private void initSocialNetwork(SocialNetwork socialNetwork){
        if(socialNetwork.isConnected()){
            switch (socialNetwork.getID()){
                case FACEBOOK:
                    facebook.setText(""Show Facebook profile"");
                    break;
                case TWITTER:
                    twitter.setText(""Show Twitter profile"");
                    break;
                case LINKEDIN:
                    linkedin.setText(""Show LinkedIn profile"");
                    break;
            }
        }
    }
    
    @Override
    public void onSocialNetworkManagerInitialized() {
        //when init SocialNetworks - get and setup login only for initialized SocialNetworks
        for (SocialNetwork socialNetwork : mSocialNetworkManager.getInitializedSocialNetworks()) {
            socialNetwork.setOnLoginCompleteListener(this);
            initSocialNetwork(socialNetwork);
        }
    }
    ```
![MainFragment](http://imgur.com/i22fMz3.png)
    
9. Request login for every social networks
    
    ```java
    SocialNetwork socialNetwork = mSocialNetworkManager.getSocialNetwork(networkId);
    socialNetwork.requestLogin();
    
    ```
    
 Full `OnClickListener` loginClick with checking connection of social network and if social network connected - show `ProfileFragment.java` on click
 
     **MainFragment.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/MainFragment.java))

    ```java
    private View.OnClickListener loginClick = new View.OnClickListener() {
        @Override
        public void onClick(View view) {
            int networkId = 0;
            switch (view.getId()){
                case R.id.facebook:
                    networkId = FACEBOOK;
                    break;
                case R.id.twitter:
                    networkId = TWITTER;
                    break;
                case R.id.linkedin:
                    networkId = LINKEDIN;
                    break;
            }
            SocialNetwork socialNetwork = mSocialNetworkManager.getSocialNetwork(networkId);
            if(!socialNetwork.isConnected()) {
                if(networkId != 0) {
                    socialNetwork.requestLogin();
                    MainActivity.showProgress(socialNetwork, ""Loading social person"");
                } else {
                    Toast.makeText(getActivity(), ""Wrong networkId"", Toast.LENGTH_LONG).show();
                }
            } else {
                startProfile(socialNetwork.getID());
            }
        }
    };
    
    ```

10. After social network login form we got callback `onLoginSuccess(int networkId)` or `onError(int networkId, String requestID, String errorMessage, Object data)` - lets show profile if login success and show Toast on error
    
 **MainFragment.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/MainFragment.java))

    ```java
    @Override
    public void onLoginSuccess(int networkId) {
        MainActivity.hideProgress();
        startProfile(networkId);
    }

    @Override
    public void onError(int networkId, String requestID, String errorMessage, Object data) {
        MainActivity.hideProgress();
        Toast.makeText(getActivity(), ""ERROR: "" + errorMessage, Toast.LENGTH_LONG).show();
    }

    private void startProfile(int networkId){
        ProfileFragment profile = ProfileFragment.newInstannce(networkId);
        getActivity().getSupportFragmentManager().beginTransaction()
                .addToBackStack(""profile"")
                .replace(R.id.container, profile)
                .commit();
    }
    
    ```
    
11. In `ProfileFragment.java` get networkId from `MainFragment.java`  

 **ProfileFragment.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/ProfileFragment.java))
    ```java
    public static ProfileFragment newInstannce(int id) {
        ProfileFragment fragment = new ProfileFragment();
        Bundle args = new Bundle();
        args.putInt(NETWORK_ID, id);
        fragment.setArguments(args);
        return fragment;
    }
    
    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {
        
        networkId = getArguments().containsKey(NETWORK_ID) ? getArguments().getInt(NETWORK_ID) : 0;
        
    }
    ```
    
12. Now via `networkId` we can get social network and request current user profile like:

    ```java
    socialNetwork = MainFragment.mSocialNetworkManager.getSocialNetwork(networkId);
    socialNetwork.setOnRequestCurrentPersonCompleteListener(this);
    socialNetwork.requestCurrentPerson();
    ```
 don't forget to implement `OnRequestSocialPersonCompleteListener` 
13. After completing request we can use SocialPerson dadta to fill our profile view

 **ProfileFragment.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/ProfileFragment.java))
    ```java
    @Override
    public void onRequestSocialPersonSuccess(int i, SocialPerson socialPerson) {
        MainActivity.hideProgress();
        name.setText(socialPerson.name);
        id.setText(socialPerson.id);
        String socialPersonString = socialPerson.toString();
        String infoString = socialPersonString.substring(socialPersonString.indexOf(""{"")+1, socialPersonString.lastIndexOf(""}""));
        info.setText(infoString.replace("", "", ""\n""));
        Picasso.with(getActivity())
            .load(socialPerson.avatarURL)
            .into(photo);
    }
    
    @Override
    public void onError(int networkId, String requestID, String errorMessage, Object data) {
        MainActivity.hideProgress();
        Toast.makeText(getActivity(), ""ERROR: "" + errorMessage, Toast.LENGTH_LONG).show();
    }
    ```
![MainFragment](http://imgur.com/b9c0VZr.png)    
14. For logout you just need to use 
```java
socialNetwork.logout();
getActivity().getSupportFragmentManager().popBackStack();
```
15. Truly, that's all - we integrate Facebook, Twitter and Linkedin and get user profile. You can add other social networks like Instagram or Google Plus just adding dependency for them and adding them to `SocialNetworkManager` like in step 8:
 ```java
    GooglePlusSocialNetwork gpNetwork = new GooglePlusSocialNetwork(this);
    mSocialNetworkManager.addSocialNetwork(gpNetwork);

    InstagramSocialNetwork instagramNetwork = new InstagramSocialNetwork(this, INSTAGRAM_CLIENT_KEY, INSTAGRAM_CLIENT_SECRET, instagramScope);
    mSocialNetworkManager.addSocialNetwork(instagramNetwork);
 ```
 And of course you can use any other request which we use bellow for them
 
14. In this tutorial we make some more requests **Share link** and **Get user friendslist**
 
 Let's **share** simple link via social network:
 * Setup share button
 
     ```java
     share = (Button) rootView.findViewById(R.id.share);
     share.setOnClickListener(shareClick);
     ```

 * To share we need fill bundle and  just request post link

      ```java
      Bundle postParams = new Bundle();
      postParams.putString(SocialNetwork.BUNDLE_LINK, link);
      socialNetwork.requestPostLink(postParams, message, postingComplete);
      ```
 * And of course some actions to callback

        ```java
        private OnPostingCompleteListener postingComplete = new OnPostingCompleteListener() {
            @Override
            public void onPostSuccessfully(int socialNetworkID) {
                Toast.makeText(getActivity(), ""Sent"", Toast.LENGTH_LONG).show();
            }
    
            @Override
            public void onError(int socialNetworkID, String requestID, String errorMessage, Object data) {
                Toast.makeText(getActivity(), ""Error while sending: "" + errorMessage, Toast.LENGTH_LONG).show();
            }
        };
        ```
 * So `OnClickListener` shareClick is
 
        **ProfileFragment.java**(full [source](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/ProfileFragment.java))
      ```java
        private View.OnClickListener shareClick = new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                AlertDialog.Builder ad = alertDialogInit(""Would you like to post Link:"", link);
                ad.setPositiveButton(""Post link"", new DialogInterface.OnClickListener() {
                    public void onClick(DialogInterface dialog, int id) {
                        if(networkId != MainFragment.TWITTER){
                            Bundle postParams = new Bundle();
                            postParams.putString(SocialNetwork.BUNDLE_LINK, link);
                            socialNetwork.requestPostLink(postParams, message, postingComplete);
                        } else {
                            socialNetwork.requestPostMessage(message + "" "" + link, postingComplete);
                        }
                    }
                });
                ad.setNegativeButton(""Cancel"", new DialogInterface.OnClickListener() {
                    @Override
                    public void onClick(DialogInterface dialog, int i) {
                        dialog.cancel();
                    }
                });
                ad.setOnCancelListener(new DialogInterface.OnCancelListener() {
                    public void onCancel(DialogInterface dialog) {
                        dialog.cancel();
                    }
                });
                ad.create().show();
            }
        };

        private AlertDialog.Builder alertDialogInit(String title, String message){
            AlertDialog.Builder ad = new AlertDialog.Builder(getActivity());
            ad.setTitle(title);
            ad.setMessage(message);
            ad.setCancelable(true);
            return ad;
        }
      ```
      
  ![Share](http://imgur.com/DX5oj68.png)

  Here we make standard alert dialog to notify user that we want to share link and in PositiveButton we check if it is not Twitter(there are no method in twitter api to post link, but we can post message as message + link)

  Let's get **friendslist** via social network:   
  * Get social network id
  * Get `SocialNetwork` from Id and request get freinds

        ```java
        SocialNetwork socialNetwork = MainFragment.mSocialNetworkManager.getSocialNetwork(networkId);
        socialNetwork.setOnRequestGetFriendsCompleteListener(this);
        socialNetwork.requestGetFriends();
        ```
    don't forget to implement `OnRequestGetFriendsCompleteListener` 
 * Get response

        ```java
        @Override
        public void OnGetFriendsIdComplete(int id, String[] friendsID) {
            ((MainActivity)getActivity()).getSupportActionBar().setTitle(friendsID.length + "" Friends"");
        }
    
        @Override
        public void OnGetFriendsComplete(int networkID, ArrayList<SocialPerson> socialPersons) {
            MainActivity.hideProgress();
            FriendsListAdapter adapter = new FriendsListAdapter(getActivity(), socialPersons, networkID);
            listView.setAdapter(adapter);
        }
    
        @Override
        public void onError(int networkId, String requestID, String errorMessage, Object data) {
            MainActivity.hideProgress();
            Toast.makeText(getActivity(), ""ERROR: "" + errorMessage, Toast.LENGTH_LONG).show();
        }
        ```

 ![Friends](http://imgur.com/VvOfgAN.png)
 
 More detailed you can read in [**FriendsFragment.java**](https://github.com/gorbin/ASNETutorial/blob/master/app/src/main/java/com/github/gorbin/asnetutorial/FriendsFragment.java)

##Conclusion
Using ASNE modules you can easily and quickly integrate any popular social networks and use common requests in your app. Of course library got [more methods](https://github.com/gorbin/ASNE/wiki/SocialNetwork-methods) which you can use in your application. But in case if you want to use social network methods from SDK or API you can easily get accesstokens or get instancesof main object in your App

This is simple tutorial demom if you need more complex - [check ASNE demo app](https://github.com/gorbin/ASNE)

[Codeproject article](http://www.codeproject.com/Articles/815900/Android-social-network-integration)

Source code: 
[Zip](https://github.com/gorbin/ASNETutorial/archive/master.zip)
    
    
"
anvil-ui/anvil-examples,master,34,5,2015-07-27T11:55:02Z,614,2,Short and descriptive examples for the Anvil MVC framework,,"# Anvil samples

[Anvil][1] is a tiny reactive UI library for Android. Inspired by [React][2]
and [Mithril][3], it brings declarative data binding, unidirectional data flow
and componentization and other things that would make your code look cleaner
and easier to maintain.

This repository contains small examples of how Anvil can be used.

## Example projects

* [Hello][4] - simple static layout with a classical text message
	- how to start Anvil project
	- how to write layouts without XML
* [Counter][5] - simple click counter
	- how to bind variables to views
	- how to bind event listeners to views
	- how easy is to to keep UI in sync with data (automatic rendering)
* [Login form][6] - two input fields, push button and some logic behind them
	- how to use text watcher bindings
	- how to use Java 8 method references as event bindings
* [Item picker][7] - animated item picker component with next/prev buttons
	- how to use animations
	- how to use states
	- how to use currentView() to get access to the real View object
	- how to use Java8 lambdas in Anvil
* [Currency exchange app][8] - fetches latest currency rates from the backend, calculates converted values as you type.
	- how to separate model logic from the view logic
	- how to separate view styling from view hierarchy
	- how to bind adapters
	- how to get two-directional data binding for text input
* [Countdone clone][9] (current Anvil example) - pomodoro-like app: define how long the task should take and see if you finish it in time
	- how to use backstack having just one activity
	- how to save component state
	- how to use custom fonts and icon fonts
* [Todo app][11] - classical MVC example: add tasks, check tasks, remove checked tasks
	- how to use list adapters
	- how the same app would look with [Java 7][10], [Java 8][11] and [Kotlin][12]

[1]: https://github.com/zserge/anvil/
[2]: http://facebook.github.io/react/
[3]: http://mithril.js.org/

[4]: ./hello/
[5]: ./counter/
[6]: ./login/
[7]: ./anim-picker/
[8]: ./currency/
[9]: ./countdone/
[10]: ./todo/
[11]: ./todo-java8/
[12]: ./todo-kotlin/
"
springapidev/java-certification,master,42,45,2017-07-15T16:58:22Z,106832,0,The examples are based on JAVA certification possible questions and It will also increase anyone skils of JAVA,java,"# java-certification
The examples are based on JAVA certification possible questions and It will also increase anyone skils of JAVA
"
kpbird/fused-location-provider-example,master,38,20,2013-06-05T09:22:11Z,626,0,Fused Location Provider Example,,"fused-location-provider-example
===============================

Fused Location Provider Example
"
fernandospr/spring-jetty-example,master,41,24,2015-09-16T03:21:17Z,128,0,Spring MVC 4 example application,,"Spring MVC Embedded Jetty Example
=================================

Basic Spring MVC 4 application using embedded Jetty 9 server. No-xml configuration.

Includes API REST service, Freemarker and JSP examples.

Integration with Mongo DB.


Requirements
------------
* [Java Platform (JDK) 8](http://www.oracle.com/technetwork/java/javase/downloads/index.html)
* [Apache Maven 3.x](http://maven.apache.org/)
"
matsim-org/matsim-maas,master,32,39,2018-08-30T07:59:38Z,50351,5,This project contains a collection of examples to run (Autonomous) Mobility as a Service in MATSim.,,"![100,000 robo-taxis driving in Berlin (10% sample)](docs/header_big.png ""100,000 robo-taxis driving in Berlin (10% sample)"")

# MATSim – Mobility as a Service
[![Build Status](https://travis-ci.org/matsim-org/matsim-maas.svg?branch=master)](https://travis-ci.org/matsim-org/matsim-maas)

This project contains a collection of examples to simulate Mobility as a Service (MaaS) and Mobility on Demand (MoD) in MATSim. All services may be simulated with a driver or using Autonomous Vehicles (AVs). The basic framework for these services are the [Dynamic Vehicle Routing Problem (DVRP)](https://github.com/matsim-org/matsim/tree/master/contribs/dvrp), [Autonomous Vehicles](https://github.com/matsim-org/matsim/tree/master/contribs/av), [Taxi](https://github.com/matsim-org/matsim/tree/master/contribs/taxi) and [Demand Responsive Transport (DRT)](https://github.com/matsim-org/matsim/tree/master/contribs/drt) extensions. This means, vehicles will be dispatched on-line while the MATSim Mobility Simulation is running.

![Integration of DVRP into MATSim](docs/figure-matsim-dvrp.jpg ""Integration of DVRP into MATSim"")

The main goal of the code in this repository is to provide examples of different usage scenarios for MaaS / AV services and make them easy to access in one single place, while the actual optimizer code remains in the MATSim contributions. All the examples run on the current MATSim Snapshot, as there are continuous improvement to the functionality. 

## Functionality

The following extensions might be of particular interest:

### Taxi
The centralized dispatched of Taxi services may be simulated using different algorithms, which may be set in the Config file. An overview of different Taxi dispatch strategies and their performance is provided in: 

*M. Maciejewski; J. Bischoff, & K. Nagel* **An Assignment-Based Approach to Efficient Real-Time City-Scale Taxi Dispatching**, IEEE Intelligent Systems, 2016, 31, 68-77 [Available here](http://svn.vsp.tu-berlin.de/repos/public-svn/publications/vspwp/2016/16-12/)


### Robotaxi / Shared Autonomous Vehicles

Shared Autonomous Vehicles provide the capability to simulate large fleets of automated taxi vehicles. This is done by combining a fast, rule-based dispatch algorithm with the possibility to adjust the consumed road capacity of Autonomous Vehicles. 

The algorithm and results are presented in 
*J. Bischoff, M. Maciejewski* **Simulation of city-wide replacement of private cars with autonomous taxis in Berlin**, Procedia Computer Science, 2016, 83, https://doi.org/10.1016/j.procs.2016.04.121

The effects of different road capacity use are described in 
*M. Maciejewski, J. Bischoff* **Congestion Effects of Autonomous Taxi Fleets**; Transport, 2017, 0, 1-10, [Full text available here](http://dx.doi.org/10.14279/depositonce-7693)

### Demand Responsive Transport (DRT)

Demand Responsive Transport allows the pooling of several passengers into a single vehicle. Several constraints, such as maximum travel times and maximum waiting times, can be taken into account when organizing the vehicle dispatch. 
Please find a full documentation [here](drt.md).

### Autonomous Vehicles

All MaaS extensions may be simulated with and without drivers. Arguably, the biggest influence of AV operations are road capacity and pricing.
* Road capacity can be influenced using the *AVCapacityModule*
* Pricing of MaaS modes can be influenced using Standard MATSim scoring parameters.

## Common infrastructure

With DVRP being the common base to all the modules described here, there is some common infrastructure all of the MaaS modules share:
* The *DVRP config* group. In this, both the Leg mode of an agent using MaaS can be defined (such as ""taxi"") as well as the network mode vehicles are using (such as ""car""). Furthermore, the on-line Travel Time Calculator can be adapted, if required.
* The *Vehicles Container*. This is a file containing information about the fleet used by any MaaS extension. Fleet vehicle files can be created using the *CreateFleetVehicles* script.

## Test scenarios

The [scenarios](scenarios/) folder contains several test scenarios. These are roughly derived from existing MATSim scenarios, but often depict only the excerpt with relevance to MaaS of the scenario. 

## How to use

1) Check out this project using your favorite git client or just download as a zip. As for the latter, you can download:
    - the [development version](https://github.com/matsim-org/matsim-maas/archive/master.zip), which is running using the latest MATSim development snapshot
    - one of the [releases](https://github.com/matsim-org/matsim-maas/releases), which is running using the official MATSim releases
    Using the latest is release will give you relatively stable results, whereas using the master will provide more features, though some of them not thoroughly tested.
  
2) Import the folder as a new Maven project to Eclipse (Import --> Maven --> Existing project) or intelliJ (New --> Module from existing sources --> Select the folder --> Maven)

3) Run the example classes and start editing them according to your taste. You can also run `RunMaasGui` to launch a simple GUI application for running MaaS simulations.
"
imotov/elasticsearch-native-script-example,master,131,47,2013-02-12T20:48:07Z,253,3,Example of Now Deprecated Native Script Plugin for Elasticsearch,,
akka/alpakka-samples,main,66,36,2018-08-14T15:15:46Z,1244,9,Example projects building Reactive Integrations using Alpakka ,akka akka-streams alpakka reactive-streams,"# Alpakka samples

[Alpakka documentation](https://docs.akka.io/docs/alpakka/)

Akka is licensed under the Business Source License 1.1, please see the [Akka License FAQ](https://www.lightbend.com/akka/license-faq)."
mkuthan/example-spring,master,38,15,2012-07-25T10:41:44Z,1215,0,Example Spring project,bdd ddd spring tdd,
erikrozendaal/cqrs-lottery,master,118,45,2009-11-29T10:09:16Z,256,0,Java example Domain-Driven-Design Command-Query Responsibility Separation ,,
bezkoder/spring-boot-security-jwt-auth-mongodb,master,185,119,2020-02-18T09:21:34Z,118,5,"Build Spring Boot MongoDB JWT Authentication & Authorization example with Spring Security, Spring Data",authentication authorization jwt-authentication mongodb rest-api restful-api spring-boot spring-data spring-data-mongodb spring-jwt-authentication spring-security,"# Spring Boot, Spring Security, MongoDB - JWT Authentication & Authorization example

- Appropriate Flow for User Signup & User Login with JWT Authentication
- Spring Boot Application Architecture with Spring Security
- How to configure Spring Security to work with JWT
- How to define Data Models and association for Authentication and Authorization
- Way to use Spring Data MongoDB to interact with MongoDB Database

## User Registration, Login and Authorization process.

![spring-boot-mongodb-jwt-authentication-flow](spring-boot-mongodb-jwt-authentication-flow.png)

## Spring Boot Rest API Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-mongodb-jwt-authentication-spring-security-architecture](spring-boot-mongodb-jwt-authentication-spring-security-architecture.png)

For more detail, please visit:
> [Spring Boot, MongoDB: JWT Authentication with Spring Security](https://bezkoder.com/spring-boot-jwt-auth-mongodb/)

> [Using HttpOnly Cookie](https://www.bezkoder.com/spring-boot-mongodb-login-example/)

Working with Front-end:
> [Vue](https://www.bezkoder.com/jwt-vue-vuex-authentication/)

> [Angular 8](https://www.bezkoder.com/angular-jwt-authentication/) / [Angular 10](https://www.bezkoder.com/angular-10-jwt-auth/) / [Angular 11](https://www.bezkoder.com/angular-11-jwt-auth/) / [Angular 12](https://www.bezkoder.com/angular-12-jwt-auth/) / [Angular 13](https://www.bezkoder.com/angular-13-jwt-auth/)

> [React](https://www.bezkoder.com/react-jwt-auth/) / [React Redux](https://www.bezkoder.com/react-redux-jwt-auth/)

More Practice:
> [Spring Boot with MongoDB CRUD example using Spring Data](https://www.bezkoder.com/spring-boot-mongodb-crud/)

> [Spring Boot MongoDB Pagination & Filter example](https://www.bezkoder.com/spring-boot-mongodb-pagination/)

> [Spring Boot + GraphQL + MongoDB example](https://www.bezkoder.com/spring-boot-graphql-mongodb-example-graphql-java/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Rest Controller Unit Test with @WebMvcTest](https://www.bezkoder.com/spring-boot-webmvctest/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Fullstack:
> [Vue.js + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-vue-mongodb/)

> [Angular 8 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-spring-boot-mongodb/)

> [Angular 10 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-10-spring-boot-mongodb/)

> [Angular 11 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-11-spring-boot-mongodb/)

> [Angular 12 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-12-spring-boot-mongodb/)

> [Angular 13 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-13-spring-boot-mongodb/)

> [Angular 14 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-14-mongodb/)

> [Angular 15 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-15-mongodb/)

> [Angular 16 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-16-mongodb/)

> [React + Spring Boot + MongoDB example](https://www.bezkoder.com/react-spring-boot-mongodb/)


Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://www.bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React with Spring Boot Rest API](https://www.bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue with Spring Boot Rest API](https://www.bezkoder.com/integrate-vue-spring-boot/)

## Run Spring Boot application
```
mvn spring-boot:run
```
"
damico/OpenPgp-BounceCastle-Example,master,76,56,2014-05-04T20:34:04Z,2509,7,"This is an OpenPgp + BounceCastle, Java Example, for education.",,"OpenPgp-BounceCastle-Example
============================

This is an OpenPgp + BounceCastle, Java Example, for education. Check the 3 test methods inside the class org.jdamico.bc.openpgp.tests.TestBCOpenPGP:

* genKeyPair()
* encrypt()
* decrypt()

------

This source code was based on the examples found inside BounceCastle API and in the demonstration found here: http://sloanseaman.com/wordpress/2011/08/11/pgp-encryptiondecryption-in-java/

"
crnk-project/crnk-example,master,28,22,2017-12-22T17:24:55Z,415,15,example application from crnk,,"# crnk example application

[![Build Status](https://travis-ci.org/crnk-project/crnk-example.svg?branch=master)](https://travis-ci.org/crnk-project/crnk-example)
[![Gitter](https://img.shields.io/gitter/room/crkn-io/lobby.svg)](https://gitter.im/crnk-io/Lobby)
[![License](https://img.shields.io/badge/License-Apache%202.0-yellowgreen.svg)](https://github.com/crnk-project/crnk-framework/blob/master/LICENSE.txt)

This is a Spring-based showcasing the use of [Crnk](https://github.com/crnk-project/crnk-framework).
Further smaller example applications integrating into various frameworks can be found at
[crnk-integration-examples](https://github.com/crnk-project/crnk-framework/tree/master/crnk-integration-examples).

*WARNING: this example project is still in development and subject to various improvements, see roadmap*

## Requirements

Crnk requires Java 8 or later.

## Licensing

Crnk is licensed under the Apache License, Version 2.0.
You can grab a copy of the license at http://www.apache.org/licenses/LICENSE-2.0.


## Building from Source

Crnk make use of Gradle for its build. To build the project run

    gradlew build


## Running the application

In order to run this example do:

	gradlew run

or

    docker run --name=crnk -p 8080:8080 crnk/example

The JSON API endpoint will be available at:

 	http://localhost:8080/api/

Some further URLs to play around that show the power of Crnk:

    http://127.0.0.1:8080/api/movie
    http://127.0.0.1:8080/api/movie/44cda6d4-1118-3600-9cab-da760bfd678c
    http://127.0.0.1:8080/api/movie/44cda6d4-1118-3600-9cab-da760bfd678c
    http://127.0.0.1:8080/api/movie/44cda6d4-1118-3600-9cab-da760bfd678c/project
    http://127.0.0.1:8080/api/movie/44cda6d4-1118-3600-9cab-da760bfd678c/relationships/project
    http://127.0.0.1:8080/api/movie?sort=-name
    http://127.0.0.1:8080/api/movie?sort=-id,name
    http://127.0.0.1:8080/api/movie?sort=id&page[offset]=0&page[limit]=2
    http://127.0.0.1:8080/api/movie?filter[name]=Iron Man
    http://127.0.0.1:8080/api/movie?filter[name][EQ]=Iron Man
    http://127.0.0.1:8080/api/movie?filter[name][LIKE]=Iron
    http://127.0.0.1:8080/api/schedule
    http://127.0.0.1:8080/api/meta/resource
    http://127.0.0.1:8080/api/vote?fields=name // demos fields set & performance issues
    http://127.0.0.1:8080/api/secrets // demos error
    http://127.0.0.1:8080/api/facet?filter[resourceType]=movie // get movie facets


## IDE

Make sure to enable annotation processing support when using IntelliJ IDEA. Otherwise it will
not be able to find the generated sources from the Crnk annotation processor (type-safe Query objects).

## Build Setup

The project makes use of https://github.com/rmee/gradle-plugins/ for the build setup.

- if no JAVA_HOME is configured (recommended), a suitable JDK will be downloaded automatically
  by the `jdk-bootstrap` plugin.
- `src/main/helm` holds a Helm chart to deploy to Kubernetes.
- Deployment to Kubernetes is triggered by the `deploy` task. All the deployment is confined
  to Docker images and a project-specific home directory located in `build/home`. No installation
  of any tooling necessary thanks to the plugins in use. Further wrapper scripts like `./kubectl`
  allow to use this deployment setup from a shell (GitBash, Linux, etc.). For deployment
  `CRNK_GCLOUD_REGION`, `CRNK_GCLOUD_PROJECT`, `CRNK_GCLOUD_CLUSTER` environment variables must
  be set and credentials be available in `crnk-example-service/secrets/gcloud.key`.


## Pointers


The `crnk-example-service` project showcases:

- Use of Lombok to avoid getter/setter boiler-plate.
- Integration of Crnk into Spring Boot
- `io.crnk:crnk-format-plain-json` has been applied for slightly simplified version of JSON:API without
  `attributes`, `relationships`, `includes` section.
- A simple in-memory repository with`ScreeningRepository` that keeps all resources in a map.
- Exposing entities with crnk-jpa using `MovieRepository`, `PersonRepository`, etc. extending `JpaEntityRepositoryBase`.
  Behind the scenes the `QuerySpec` is translated to an efficient JPA Criteria query.
- A manually written repository with `VoteRepository`. It makes use of Thread.sleep to simulate heavy work.
- A custom exception is introduced with `CustomExceptionMapper` that is mapped to a JSON API error and HTTP status code.
- using `@JsonApiRelationId` with `ScreeningRepository` to
  handle use cases where the related ID is easy to get, which in turn allows
  to omit having to implement relationship repositories.
- implementing a relationship repository with`AttributeChangeRelationshipRepository`.
- implementing a multi-valued nested resource with `Secret` and its identifier `SecretId`.
- implementing a single-valued nested resource with `SecreeningStatus`. Shared the same ID as the screening itself
  and make use of `SerializeType.EAGER` to directly be shown with the screening (see
  http://127.0.0.1:8080/api/screening)
- introducing new relationships to existing resources
  without touching those resources with `AttributeChangeFieldProvider`.
- `PersonEntity` as dynamic resource by annotating a `Map`-based field with `@JsonAnyGetter` and `@JsonAnySetter`
- `SecurityConfiguration` performs a OAuth setup with GitHub as provider.
  `LoginRepository` gives access to information about the logged-in user through http://localhost:8080/api/user.
  *Enable spring security in the `application.yaml`* to make use of the security features.
  *Security is disabled by default* to facilitate playing with the example app.
   The security setup is still work in progress.
- `CSRF` (resp. `XSRF` in Angular terminology) protection through `SpringSecurityConfiguration`.
- `ExampleSecurityConfigurer` to setup role-based access control.
- `ScheduleDecoratorFactory` to intercept and modify requests to repositories.
- The documentation gets generated to `build/asciidoc` upon executing `gradlew build`. Have a look at the
  `build.gradle` file and the capturing based on `AsciidocCaptureModule` within the test cases.
- Support for facetted search by applying `crnk-data-facets`. `MovieEntity.year` as been marked as being facetted with `@Facet`.
  See `http://127.0.0.1:8080/api/facet?filter[resourceType]=movie`.
- `MovieRepository` provides an interface for the `MovieRepositoryImpl` which allows type-safe access
  to movie result lists in `CrnkClient`.
- `MovieRepository` makes use of `HasMoreResourcesMetaInformation` through a custom `MovieList` type. This
   triggers the use of a previous/next paging strategy, rather than always computing the total count
   in a second, potentially expensive query.

The `TestDataLoader` will automatically setup some test data upon start.

The project itself makes use of an number of third-party plugins to bootstrap a JDK, build Helm packages and
allow a Kubernetes installation to Google Cloud. For more information see https://github.com/rmee/gradle-plugins/.

Feedback and PRs very welcomed!


## Links

* [Homepage](http://www.crnk.io)
* [Documentation](http://www.crnk.io/releases/stable/documentation/)
* [Source code](https://github.com/crnk-project/crnk-example/)
* [Issue tracker](https://github.com/crnk-project/crnk-example/issues)
* [Forum](https://gitter.im/crnk-io/Lobby)
* [Build](https://travis-ci.org/crnk-project/crnk-example/)
"
infinum/Dagger-2-Example,master,43,18,2015-05-12T19:59:09Z,169,1,Dagger 2 example project,,"# Dagger 2 example

An example project showing how to use Dagger 2.

It uses [Pokeapi](http://pokeapi.co/docs/) to show a list of pokemons with details.

# Credits

Maintained and sponsored by
[Infinum] (http://www.infinum.co).

<img src=""https://infinum.co/infinum.png"" width=""264"">
"
soyjuanmalopez/clean-architecture,master,271,96,2020-03-26T14:17:50Z,145,2,A example of clean architecture in Java 8 and Spring Boot 2.0,actors arquitecture clean clean-arch clean-architecture clean-code hibernate java-8 lombok maven multiproject spring spring-boot template video,"Clean Architecture example

Multiporject maven.

Explain

https://medium.com/swlh/clean-architecture-java-spring-fea51e26e00

My other artichels

Recillence in Java Aplication 
https://medium.com/swlh/future-proofing-your-java-applications-understanding-the-power-of-resilience-patterns-with-cfbafdcfdc86

Concurrency Java Application with examples
https://medium.com/swlh/conquering-concurrency-in-spring-boot-strategies-and-solutions-152f41dd9005

*Compile* </br>
mvn clean install

*Run* </br>
mvn spring-boot:run

"
mschwartau/keycloak-custom-protocol-mapper-example,master,100,37,2018-11-11T20:34:23Z,527,0,An example for building custom keycloak protocol mappers,,"# Keycloak custom protocol mapper example / customize JWT tokens

Per default [Keycloak](https://www.keycloak.org/) writes a lot of things into the [JWT tokens](https://tools.ietf.org/html/rfc7519),
e.g. the preferred username. If that is not enough, a lot of additional built in protocol mappers can be added to customize
the [JWT token](https://tools.ietf.org/html/rfc7519) created by [Keycloak](https://www.keycloak.org/) even further. They can be added in the client
section via the mappers tab (see the [documentation](https://www.keycloak.org/docs/latest/server_admin/index.html#_protocol-mappers)). But sometimes the build
in protocol mappers are not enough. If this is the case, an own protocol mapper can be added to [Keycloak](https://www.keycloak.org/) via an (not yet)
official [service provider API](https://www.baeldung.com/java-spi). This project shows how this can be done.

## Entrypoints into this project

1. [data-setup](data-setup): Project to configure [Keycloak](https://www.keycloak.org/) via its REST API. Configures a realm so that it uses the example
   protocol mapper. Contains a [main method](data-setup/src/main/java/hamburg/schwartau/datasetup/bootstrap/DataSetupMain.java) which can be executed against a
   running [Keycloak](https://www.keycloak.org/) instance. Doesn't need to be executed manually because it's executed automatically by
   the `docker-entrypoint.sh` during startup.
2. [protocol-mapper](protocol-mapper): Contains the protocol mapper code. The resulting jar file will be deployed to [Keycloak](https://www.keycloak.org/). I
   tried to explain things needed in comments in the [protocol-mapper project](protocol-mapper)
3. [Dockerfile](Dockerfile): Adds the jar file containing the [protocol mapper](protocol-mapper/src/main/java/hamburg/schwartau/HelloWorldMapper.java), created
   by the [protocol-mapper project](protocol-mapper), to the keycloak instance.

## Try it out

To try it out do the following things:

### Konfiguration of keycloak

1. If you have already started this project and changed something, execute `docker-compose down -v` so
   that the volumes and so on are destroyed. Otherwise the old keycloak in memory
   database might be reused or you might not see your changed data.
2. Start build and start keycloak using docker: `docker-compose up --build`.
3. After the keycloak has been started, the [main class `DataSetupMain`](data-setup/src/main/java/hamburg/schwartau/datasetup/bootstrap/DataSetupMain.java) in
   our [data-setup](data-setup) module should be started automatically by the `docker-entrypoint.sh` in the Dockerfile and should add some example data to the
   keycloak instance. You should see the message `The data has been imported` in the console if it has been executed successfully.
3. Now you can open the [Keycloak admin console](http://localhost:11080/auth/admin/) and login with username / password: admin / password.
   This initial password for the admin user were configured in our [docker-compose](docker-compose.yml) file.
4. You should see that the master and an example realm, which was added by the [data-setup](data-setup) module automatically, exists currently. For this example
   realm the [hello world mapper](protocol-mapper/src/main/java/hamburg/schwartau/HelloWorldMapper.java) is
   configured (in [clients=>example-realm-client=>Client scopes=>dedicated](http://localhost:11080/auth/admin/master/console/#/example-realm/clients/example-realm-client/clientScopes/dedicated)): ![Keycloak screenshot](images/keycloak_mapper.png?raw=true ""Keycloak screenshot"")

Now [Keycloak](https://www.keycloak.org/) is configured. As a next step we want to check the token.

### Checking the access token

To check the token, we need to login. To get the tokens using the direct flow (not recommended for production usage, just for easy demo purposes. See
this [page](https://auth0.com/docs/api-auth/which-oauth-flow-to-use)) execute the following curl command:

    curl -d 'client_id=example-realm-client' -d 'username=jdoe' -d 'password=password' -d 'grant_type=password' 'http://localhost:11080/auth/realms/example-realm/protocol/openid-connect/token'

Note that using the direct flow is only possible because we configured keycloak to allow it in
the [`RealmSetup` class](data-setup/src/main/java/hamburg/schwartau/datasetup/bootstrap/RealmSetup.java).
Response should be like:

    {
      ""access_token"": ""eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJYbl9PXzN6VHJpSjBzOE5RUzlpMVpBcF9pZVN2YXRwOHRIWmtpTGNwM1RrIn0.eyJleHAiOjE2NzExMzMzMjMsImlhdCI6MTY3MTEzMzAyMywianRpIjoiYTcwYjA4NjQtNmI3Mi00MjljLTliMDEtZWIzNzBhMTE5YTgzIiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDoxMTA4MC9hdXRoL3JlYWxtcy9leGFtcGxlLXJlYWxtIiwiYXVkIjoiYWNjb3VudCIsInN1YiI6IjkxMmNkZmJhLWNlNGQtNDgzMS04NjA3LWQzM2VmOTkzOTdmYyIsInR5cCI6IkJlYXJlciIsImF6cCI6ImV4YW1wbGUtcmVhbG0tY2xpZW50Iiwic2Vzc2lvbl9zdGF0ZSI6ImRlMzljN2M2LTM0ZWMtNGM4MC1iZTM2LWIyODE4YTkxMjMyYyIsImFjciI6IjEiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiZGVmYXVsdC1yb2xlcy1leGFtcGxlLXJlYWxtIiwib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsInNpZCI6ImRlMzljN2M2LTM0ZWMtNGM4MC1iZTM2LWIyODE4YTkxMjMyYyIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6IkpvaG4gRG9lIiwiZ3JvdXBzIjpbXSwicHJlZmVycmVkX3VzZXJuYW1lIjoiamRvZSIsImdpdmVuX25hbWUiOiJKb2huIiwiZmFtaWx5X25hbWUiOiJEb2UiLCJleGFtcGxlIjp7Im1lc3NhZ2UiOiJoZWxsbyB3b3JsZCJ9fQ.wZI33cy6X2yxnsz1HeU3snrPi8xg1Pq8TiNIxPfP-RLtPQm5-3of9kTFXNvtZkA2Om3rzlI_NfyYy8eq4VArujVvvkKx5oxGZ0Q9Tv6LU0ufS4YfW0t0oAbEdNmONBXUszcl_HKX_5Pnvbs7DwR04ErAmzguECnky9hdYy0nJREnfrTwr6Ss270H8HaQ-DJ1T4x-iFzuwRkQZTg_PUfRxts0tjsIRehFPxadLujj4ZpsguvfXqCD11Gb4a2xXSm6S2iDP8sa_zwaWCbRDraBUCcEy192hADDNVDBQPYgUe-0Sj7z_mPNviEiMagAmBFCj8W-czkEWwnX_WodeVThWA"",
      ""expires_in"": 300,
      ""refresh_expires_in"": 1800,
      ""refresh_token"": ""eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICIzODE5NTdiZi1jMzI0LTQ3M2UtOTA4MS1lN2MxODVmMzllYjUifQ.eyJleHAiOjE2NzExMzQ4MjMsImlhdCI6MTY3MTEzMzAyMywianRpIjoiYWM4Njk0NzktYzY2Yi00YWIwLWIzYzQtZDc1ZjU0NWZmOTk3IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDoxMTA4MC9hdXRoL3JlYWxtcy9leGFtcGxlLXJlYWxtIiwiYXVkIjoiaHR0cDovL2xvY2FsaG9zdDoxMTA4MC9hdXRoL3JlYWxtcy9leGFtcGxlLXJlYWxtIiwic3ViIjoiOTEyY2RmYmEtY2U0ZC00ODMxLTg2MDctZDMzZWY5OTM5N2ZjIiwidHlwIjoiUmVmcmVzaCIsImF6cCI6ImV4YW1wbGUtcmVhbG0tY2xpZW50Iiwic2Vzc2lvbl9zdGF0ZSI6ImRlMzljN2M2LTM0ZWMtNGM4MC1iZTM2LWIyODE4YTkxMjMyYyIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsInNpZCI6ImRlMzljN2M2LTM0ZWMtNGM4MC1iZTM2LWIyODE4YTkxMjMyYyJ9.AKWuXIuq__KzZC32GrGlhbDe_gZkyQsqKRSIDBKSgJQ"",
      ""token_type"": ""Bearer"",
      ""not-before-policy"": 0,
      ""session_state"": ""de39c7c6-34ec-4c80-be36-b2818a91232c"",
      ""scope"": ""email profile""
    }

Then copy the `access_token` value and decode it, e.g. by using [jwt.io](https://jwt.io/). You'll
get something like the following:

      {
         ""exp"": 1671133323,
         ""iat"": 1671133023,
         ""jti"": ""a70b0864-6b72-429c-9b01-eb370a119a83"",
         ""iss"": ""http://localhost:11080/auth/realms/example-realm"",
         ""aud"": ""account"",
         ""sub"": ""912cdfba-ce4d-4831-8607-d33ef99397fc"",
         ""typ"": ""Bearer"",
         ""azp"": ""example-realm-client"",
         ""session_state"": ""de39c7c6-34ec-4c80-be36-b2818a91232c"",
         ""acr"": ""1"",
         ""realm_access"": {
            ""roles"": [
               ""default-roles-example-realm"",
               ""offline_access"",
               ""uma_authorization""
            ]
         },
         ""resource_access"": {
            ""account"": {
               ""roles"": [
                  ""manage-account"",
                  ""manage-account-links"",
                  ""view-profile""
               ]
            }
         },
         ""scope"": ""email profile"",
         ""sid"": ""de39c7c6-34ec-4c80-be36-b2818a91232c"",
         ""email_verified"": false,
         ""name"": ""John Doe"",
         ""groups"": [],
         ""preferred_username"": ""jdoe"",
         ""given_name"": ""John"",
         ""family_name"": ""Doe"",
         ""example"": {
            ""message"": ""hello world""
         }
      }

The value auf our own [Hello World Token mapper](protocol-mapper/src/main/java/hamburg/schwartau/HelloWorldMapper.java) got added to the token because
the message 'hello world' appears in the example.message field.

## Acknowledgements

- Examples for [Keycloak](https://www.keycloak.org/): https://github.com/keycloak/keycloak/tree/master/examples
- I got the idea for how to add a custom protocol mapper to [Keycloak](https://www.keycloak.org/) from
  this [jboss mailing list entry](http://lists.jboss.org/pipermail/keycloak-user/2016-February/004891.html)

## Links

- To use keycloak with an angular app, I found this example app to be helpful: https://github.com/manfredsteyer/angular-oauth2-oidc
- Login Page for the users: Login Url: [http://localhost:11080/auth/realms/example-realm/account](http://localhost:11080/auth/realms/example-realm/account)


"
joshlong-attic/spring-and-kafka,master,68,72,2015-04-14T10:55:26Z,120,6,Example code for my blog introducing Spring and Apache Kafka,,"# Apache Kafka and Spring Integration, Spring XD, and the Lattice Distributed Runtime

Applications generated more and more data than ever before and a huge part of the challenge - before it can even be analyzed - is accommodating the load in the first place. [Apache's Kafka](http://kafka.apache.org) meets this challenge. It was originally designed by LinkedIn and subsequently open-sourced in 2011. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. The design is heavily influenced by transaction logs.  It is a messaging system, similar to traditional messaging systems like RabbitMQ, ActiveMQ, MQSeries, but it's ideal for log aggregation, persistent messaging, fast (_hundreds_ of megabytes per second!) reads and writes, and can accommodate numerous clients. Naturally, this makes it _perfect_ for cloud-scale architectures!

Kafka [powers many large production systems](https://cwiki.apache.org/confluence/display/KAFKA/Powered+By). LinkedIn uses it for activity data and operational metrics to  power  the LinkedIn news feed, and LinkedIn Today, as well as  offline analytics going into Hadoop. Twitter uses it as part of their stream-processing infrastructure. Kafka powers online-to-online and online-to-offline messaging at Foursquare. It is used to integrate Foursquare monitoring and production systems with  Hadoop-based offline infrastructures. Square uses Kafka as a bus to move all system events through Square's various data centers. This includes metrics, logs, custom events, and so on. On the consumer side, it outputs into Splunk, Graphite, or Esper-like real-time alerting. Netflix uses it for 300-600BN messages per day. It's also used by Airbnb, Mozilla, Goldman Sachs, Tumblr, Yahoo, PayPal, Coursera, Urban Airship, Hotels.com, and a seemingly endless list of other big-web stars. Clearly, it's earning its keep in some powerful systems!

## Installing Apache Kafka
There are many different ways to get Apache Kafka installed. If you're on OSX, and you're using Homebrew, it can be as simple as `brew install kafka`. You can also [download the latest distribution from Apache](http://kafka.apache.org/downloads.html). I downloaded `kafka_2.10-0.8.2.1.tgz`, unzipped it, and then within you'll find there's a distribution of [Apache Zookeeper](https://zookeeper.apache.org/) as well as Kafka, so nothing else is required. I installed Apache Kafka in my `$HOME` directory, under another directory, `bin`, then I created an environment variable, `KAFKA_HOME`, that points to `$HOME/bin/kafka`.

Start Apache Zookeeper first, specifying where the configuration properties file it requires is:

```
$KAFKA_HOME/bin/zookeeper-server-start.sh  $KAFKA_HOME/config/zookeeper.properties

```  

The Apache Kafka distribution comes with default configuration files for both Zookeeper and Kafka, which makes getting started easy. You will in more advanced use cases need to customize these files.

Then start Apache Kafka. It too requires a configuration file, like this:

```
$KAFKA_HOME/bin/kafka-server-start.sh  $KAFKA_HOME/config/server.properties
```

The `server.properties` file  contains, among other things, default values for where to connect to Apache Zookeeper (`zookeeper.connect`), how much data should be sent across sockets, how many partitions there are by default, and the broker ID (`broker.id` - which must be unique across a cluster).

There are other scripts in the same directory that can be used to send and receive dummy data, very handy in establishing that everything's up and running!

Now that Apache Kafka is up and running, let's look at  working with Apache Kafka from our application.

## Some High Level Concepts..

A Kafka _broker_ cluster consists of one or more servers where each may have one or more broker processes running. Apache Kafka is designed to be highly available; there are no _master_ nodes. All nodes are interchangeable. Data is replicated from one node to another to ensure that it is still available in the event of a failure.

In Kafka, a _topic_ is a category, similar to a JMS destination or both an AMQP exchange and queue. Topics are partitioned, and the choice of which of a topic's partition a message should be sent to is made by the message producer. Each message in the partition is assigned a unique sequenced ID, its  _offset_. More partitions allow greater parallelism for consumption, but this will also result in more files across the brokers.


_Producers_ send messages to Apache Kafka broker topics and specify the partition to use for every message they produce. Message production may be synchronous or asynchronous. Producers also specify what sort of replication guarantees they want.

_Consumers_ listen for messages on topics and process the feed of published messages. As you'd expect if you've used other messaging systems, this is usually (and usefully!) asynchronous.

Like [Spring XD](http://spring.io/projects/spring-xd) and numerous other distributed system, Apache Kafka uses Apache Zookeeper to coordinate cluster information. Apache Zookeeper provides a shared hierarchical namespace (called _znodes_) that nodes can share to understand cluster topology and availability (yet another reason that [Spring Cloud](https://github.com/spring-cloud/spring-cloud-zookeeper) has forthcoming support for it..).

Zookeeper is very present in your interactions with Apache Kafka. Apache Kafka has, for example, two different APIs for acting as a consumer. The higher level API is simpler to get started with and it handles all the nuances of handling partitioning and so on. It will need a reference to a Zookeeper instance to keep the coordination state.  

Let's turn now turn to using Apache Kafka with Spring.

## Using Apache Kafka with Spring Integration
The recently released [Apache Kafka 1.1 Spring Integration adapter]() is very powerful, and provides inbound adapters for working with both the lower level Apache Kafka API as well as the higher level API.

The adapter, currently, is XML-configuration first, though work is already underway on a Spring Integration Java configuration DSL for the adapter and milestones are available. We'll look at both here, now.

To make all these examples work, I added the [libs-milestone-local Maven  repository](http://repo.spring.io/simple/libs-milestone-local) and used the following dependencies:

- org.apache.kafka:kafka_2.10:0.8.1.1
- org.springframework.boot:spring-boot-starter-integration:1.2.3.RELEASE
- org.springframework.boot:spring-boot-starter:1.2.3.RELEASE
- org.springframework.integration:spring-integration-kafka:1.1.1.RELEASE
- org.springframework.integration:spring-integration-java-dsl:1.1.0.M1

### Using the Spring Integration Apache Kafka with the Spring Integration XML DSL

First, let's look at how to use the Spring Integration outbound adapter to send `Message<T>` instances from a Spring Integration flow to an external Apache Kafka instance. The example is fairly  straightforward: a Spring Integration `channel` named `inputToKafka` acts as a conduit that forwards `Message<T>` messages to the outbound adapter, `kafkaOutboundChannelAdapter`. The adapter itself can take its configuration from the defaults specified in the `kafka:producer-context` element or it from the adapter-local configuration overrides. There may be one or many configurations in a given `kafka:producer-context` element.

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<beans xmlns=""http://www.springframework.org/schema/beans""
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
       xmlns:int=""http://www.springframework.org/schema/integration""
       xmlns:int-kafka=""http://www.springframework.org/schema/integration/kafka""
       xmlns:task=""http://www.springframework.org/schema/task""
       xsi:schemaLocation=""http://www.springframework.org/schema/integration/kafka http://www.springframework.org/schema/integration/kafka/spring-integration-kafka.xsd
		http://www.springframework.org/schema/integration http://www.springframework.org/schema/integration/spring-integration.xsd
		http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd"">

    <int:channel id=""inputToKafka"">
        <int:queue/>
    </int:channel>

    <int-kafka:outbound-channel-adapter
            id=""kafkaOutboundChannelAdapter""
            kafka-producer-context-ref=""kafkaProducerContext""
            channel=""inputToKafka"">
        <int:poller fixed-delay=""1000"" time-unit=""MILLISECONDS"" receive-timeout=""0"" task-executor=""taskExecutor""/>
    </int-kafka:outbound-channel-adapter>

    <task:executor id=""taskExecutor"" pool-size=""5"" keep-alive=""120"" queue-capacity=""500""/>

    <int-kafka:producer-context id=""kafkaProducerContext"">
        <int-kafka:producer-configurations>
            <int-kafka:producer-configuration broker-list=""localhost:9092""
                                              topic=""event-stream""
                                              compression-codec=""default""/>
        </int-kafka:producer-configurations>
    </int-kafka:producer-context>

</beans>
```

Here's the Java code from a Spring Boot application to trigger message sends using the outbound adapter by sending messages into the incoming `inputToKafka` `MessageChannel`.

```java
package xml;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.DependsOn;
import org.springframework.context.annotation.ImportResource;
import org.springframework.integration.config.EnableIntegration;
import org.springframework.messaging.MessageChannel;
import org.springframework.messaging.support.GenericMessage;

@SpringBootApplication
@EnableIntegration
@ImportResource(""/xml/outbound-kafka-integration.xml"")
public class DemoApplication {

    private Log log = LogFactory.getLog(getClass());

    @Bean
    @DependsOn(""kafkaOutboundChannelAdapter"")
    CommandLineRunner kickOff(@Qualifier(""inputToKafka"") MessageChannel in) {
        return args -> {
            for (int i = 0; i < 1000; i++) {
                in.send(new GenericMessage<>(""#"" + i));
                log.info(""sending message #"" + i);
            }
        };
    }

    public static void main(String args[]) {
        SpringApplication.run(DemoApplication.class, args);
    }
}

```

### Using the New  Apache Kafka Spring Integration Java Configuration DSL

Shortly after the Spring Integration 1.1 release, Spring Integration rockstar [Artem Bilan](https://spring.io/team/artembilan) got to work [on adding a Spring Integration Java Configuration DSL analog](http://repo.spring.io/simple/libs-milestone-local/org/springframework/integration/spring-integration-java-dsl/1.1.0.M1/) and the result is a thing of beauty! It's not yet GA (you need to add the `libs-milestone` repository for now), but I encourage you to try it out and kick the tires. It's working well for me and the Spring Integration team are always keen on getting early feedback whenever possible! Here's an example that demonstrates both sending messages and consuming them from two different `IntegrationFlow`s. The producer is similar to the example XML above.

New in this example is the polling consumer. It is batch-centric, and will pull down all the messages it sees at a fixed interval. In our code, the message received will be a map that contains as its keys the topic and as its value another map with the partition ID and the batch (in this case, of 10 records), of records read.  There is a `MessageListenerContainer`-based alternative that processes messages as they come.  

```java
package jc;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.DependsOn;
import org.springframework.integration.IntegrationMessageHeaderAccessor;
import org.springframework.integration.config.EnableIntegration;
import org.springframework.integration.dsl.IntegrationFlow;
import org.springframework.integration.dsl.IntegrationFlows;
import org.springframework.integration.dsl.SourcePollingChannelAdapterSpec;
import org.springframework.integration.dsl.kafka.Kafka;
import org.springframework.integration.dsl.kafka.KafkaHighLevelConsumerMessageSourceSpec;
import org.springframework.integration.dsl.kafka.KafkaProducerMessageHandlerSpec;
import org.springframework.integration.dsl.support.Consumer;
import org.springframework.integration.kafka.support.ZookeeperConnect;
import org.springframework.messaging.MessageChannel;
import org.springframework.messaging.support.GenericMessage;
import org.springframework.stereotype.Component;

import java.util.List;
import java.util.Map;

/**
 * Demonstrates using the Spring Integration Apache Kafka Java Configuration DSL.
 * Thanks to Spring Integration ninja <a href=""http://spring.io/team/artembilan"">Artem Bilan</a>
 * for getting the Java Configuration DSL working so quickly!
 *
 * @author Josh Long
 */
@EnableIntegration
@SpringBootApplication
public class DemoApplication {

  public static final String TEST_TOPIC_ID = ""event-stream"";

  @Component
  public static class KafkaConfig {

    @Value(""${kafka.topic:"" + TEST_TOPIC_ID + ""}"")
    private String topic;

    @Value(""${kafka.address:localhost:9092}"")
    private String brokerAddress;

    @Value(""${zookeeper.address:localhost:2181}"")
    private String zookeeperAddress;

    KafkaConfig() {
    }

    public KafkaConfig(String t, String b, String zk) {
        this.topic = t;
        this.brokerAddress = b;
        this.zookeeperAddress = zk;
    }

    public String getTopic() {
        return topic;
    }

    public String getBrokerAddress() {
        return brokerAddress;
    }

    public String getZookeeperAddress() {
        return zookeeperAddress;
    }
  }

  @Configuration
  public static class ProducerConfiguration {

    @Autowired
    private KafkaConfig kafkaConfig;

    private static final String OUTBOUND_ID = ""outbound"";

    private Log log = LogFactory.getLog(getClass());

    @Bean
    @DependsOn(OUTBOUND_ID)
    CommandLineRunner kickOff( 
           @Qualifier(OUTBOUND_ID + "".input"") MessageChannel in) {
        return args -> {
            for (int i = 0; i < 1000; i++) {
                in.send(new GenericMessage<>(""#"" + i));
                log.info(""sending message #"" + i);
            }
        };
    }

    @Bean(name = OUTBOUND_ID)
    IntegrationFlow producer() {

      log.info(""starting producer flow.."");
      return flowDefinition -> {

        Consumer<KafkaProducerMessageHandlerSpec.ProducerMetadataSpec> spec =
          (KafkaProducerMessageHandlerSpec.ProducerMetadataSpec metadata)->
            metadata.async(true)
              .batchNumMessages(10)
              .valueClassType(String.class)
              .<String>valueEncoder(String::getBytes);

        KafkaProducerMessageHandlerSpec messageHandlerSpec =
          Kafka.outboundChannelAdapter(
               props -> props.put(""queue.buffering.max.ms"", ""15000""))
            .messageKey(m -> m.getHeaders().get(IntegrationMessageHeaderAccessor.SEQUENCE_NUMBER))
            .addProducer(this.kafkaConfig.getTopic(), 
                this.kafkaConfig.getBrokerAddress(), spec);
        flowDefinition
            .handle(messageHandlerSpec);
      };
    }
  }

  @Configuration
  public static class ConsumerConfiguration {

    @Autowired
    private KafkaConfig kafkaConfig;

    private Log log = LogFactory.getLog(getClass());

    @Bean
    IntegrationFlow consumer() {

      log.info(""starting consumer.."");

      KafkaHighLevelConsumerMessageSourceSpec messageSourceSpec = Kafka.inboundChannelAdapter(
          new ZookeeperConnect(this.kafkaConfig.getZookeeperAddress()))
            .consumerProperties(props ->
                props.put(""auto.offset.reset"", ""smallest"")
                     .put(""auto.commit.interval.ms"", ""100""))
            .addConsumer(""myGroup"", metadata -> metadata.consumerTimeout(100)
              .topicStreamMap(m -> m.put(this.kafkaConfig.getTopic(), 1))
              .maxMessages(10)
              .valueDecoder(String::new));

      Consumer<SourcePollingChannelAdapterSpec> endpointConfigurer = e -> e.poller(p -> p.fixedDelay(100));

      return IntegrationFlows
        .from(messageSourceSpec, endpointConfigurer)
        .<Map<String, List<String>>>handle((payload, headers) -> {
            payload.entrySet().forEach(e -> log.info(e.getKey() + '=' + e.getValue()));
            return null;
        })
        .get();
    }
  }

  public static void main(String[] args) {
      SpringApplication.run(DemoApplication.class, args);
  }
}

```

The example makes heavy use of Java 8 lambdas. 

The producer spends a bit of time establishing how many messages will be sent in a single send operation, how keys and values are encoded (Kafka only knows about `byte[]` arrays, after all) and whether messages should be sent synchronously or asynchronously. In the next line, we configure the outbound adapter itself and then define an `IntegrationFlow` such that all messages get sent out via the Kafka outbound adapter. 

The consumer spends a bit of time establishing which Zookeeper instance to connect to, how many messages to receive (10) in a batch, etc. Once the message batches are recieved, they're handed to the `handle` method where I've passed in a lambda that'll enumerate the payload's body and print it out. Nothing fancy. 

## Using Apache Kafka with Spring XD

Apache Kafka is a message bus and it can be very powerful when used as an integration bus. However, it really comes into its own because it's fast enough and scalable enough that it can be used to route big-data through processing pipelines. And if you're doing data processing, you really want [Spring XD](http://projects.spring.io/spring-xd/)! Spring XD makes it dead simple to use Apache Kafka (as the support is built on the Apache Kafka Spring Integration adapter!) in complex stream-processing pipelines. Apache Kafka is exposed as a Spring XD _source_ - where data comes from - and a sink - where data goes to.

<img src =""http://projects.spring.io/spring-xd/img/spring-xd-unified-platform-for-big-data.png"" />

Spring XD exposes a super convenient DSL for creating `bash`-like pipes-and-filter flows. Spring XD is a centralized runtime that manages, scales, and monitors data processing jobs. It builds on top of Spring Integration, Spring Batch, Spring Data and Spring for Hadoop to be a one-stop data-processing shop. Spring XD Jobs read data from _sources_, run them through processing components that may count, filter, enrich or transform the data, and then write them to sinks.

 Spring Integration and Spring XD ninja [Marius Bogoevici](https://twitter.com/mariusbogoevici), who did a lot of the recent work in the Spring Integration  and Spring XD implementation of Apache Kafka, put together a really nice example demonstrating [how to get a full working Spring XD and Kafka flow working](https://github.com/spring-projects/spring-xd-samples/tree/master/kafka-source). The `README` walks you through getting Apache Kafka, Spring XD and the requisite topics all setup. The essence, however, is when you use the Spring XD shell and the shell DSL to compose a stream. Spring XD components are named components that are pre-configured but have lots of parameters that you can override with `--..` arguments via the XD shell and DSL. (That DSL, by the way, is written by  the amazing [Andy Clement](https://spring.io/team/aclement) of Spring Expression language fame!) Here's an example that configures a stream to read data from an Apache Kafka source and then write the message a component called `log`, which is a sink. `log`, in this case, could be syslogd, Splunk, HDFS, etc.



```bash
xd> stream create kafka-source-test --definition ""kafka --zkconnect=localhost:2181 --topic=event-stream | log"" --deploy

```

And that's it! Naturally, this is just a tase of Spring XD, but hopefully you'll agree the possibilities are tantalizing.

## Deploying a Kafka Server with Lattice and Docker
It's easy to get an example Kafka installation all setup using [Lattice](http://lattice.cf), a distributed runtime that supports, among other container formats, the very popular Docker image format. [There's a Docker image provided by Spotify that sets up a collocated Zookeeper and Kafka image](https://github.com/spotify/docker-kafka). You can easily deploy this to a Lattice cluster, as follows:

```bash
ltc create --run-as-root m-kafka spotify/kafka
```
From there, you can easily scale the Apache Kafka instances and even more easily still consume Apache Kafka from your cloud-based services.  

## Next Steps

You can find the code [for this blog on my GitHub account](https://github.com/joshlong/spring-and-kafka).

We've only scratched the surface! 

If you want to learn more (and why wouldn't you?), then be sure to check out Marius Bogoevici and Dr. Mark Pollack's upcoming [webinar on Reactive data-pipelines using Spring XD and Apache Kafka](https://spring.io/blog/2015/03/17/webinar-reactive-data-pipelines-with-spring-xd-and-kafka) where they'll demonstrate how easy it can be to use RxJava, Spring XD and Apache Kafka!
"
Jaouan/Article-Details-Transition-Example,master,140,31,2016-08-07T18:58:48Z,4597,0,It's just an example of material transition.,,"Android - Article details transition example
========
[![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-Article--Details--Transition--Example-green.svg?style=true)](https://android-arsenal.com/details/3/4114)

It's just some examples of material transitions.

Pop from top|Pop from item
-------------|-------------
![demo](art/popfromtop.gif)|![demo](art/popfromitem.gif)

References
========
 - ""Pop from top"" transition is inspired (more or less) by [Ivan Bjelajac's transition](http://www.materialup.com/posts/article-details-transition).
 - The project uses [ButterKnife](http://jakewharton.github.io/butterknife/).

License
========

[Apache License Version 2.0](LICENSE)
"
khanhnguyenj/huongdanjava.com,master,32,44,2017-01-04T03:05:58Z,14109,194,All example projects from https://huongdanjava.com.,,# huongdanjava.com
JonathanM2ndoza/Hexagonal-Architecture-DDD,master,72,24,2020-05-22T21:12:47Z,2351,0,Example of Hexagonal Architecture and DDD,hexagonal-architecture,"# Hexagonal-Architecture-DDD

Ports and Adapters or also known as Hexagonal Architecture, is a popular architecture invented by Alistair Cockburn in 2005.

Example of how to use Hexagonal Architecture and the basic of Domain Driven Design (DDD) 

This example is made with Spring Boot, MongoDB, PostgreSQL

## Domain Driven Design (DDD)

Domain-Driven Design is an approach to software development that centers the development on programming a domain model that has a rich understanding of the processes and rules of a domain.

Bounded Context is a central pattern in Domain-Driven Design. It is the focus of DDD's strategic design section which is all about dealing with large models and teams. DDD deals with large models by dividing them into different Bounded Contexts and being explicit about their interrelationships.

![Screenshot](prtsc/Hexa-Arch-DDD-1.png)

*Reference:*
- https://martinfowler.com/tags/domain%20driven%20design.html

## Hexagonal Architecture

The hexagonal architecture, or ports and adapters architecture, is an architectural pattern used in software design. It aims at creating loosely coupled application components that can be easily connected to their software environment by means of ports and adapters. This makes components exchangeable at any level and facilitates test automation.

The business logic interacts with other components through ports and adapters. This way, we can change the underlying technologies without having to modify the application core.

**The hexagonal architecture is based on three principles and techniques:**

1. Explicitly separate Application, Domain, and Infrastructure
2. Dependencies are going from Application and Infrastructure to the Domain
3. We isolate the boundaries by using Ports and Adapters

Note: The words Application, Domain and Infrastructure do not come from the original article but from the frequent use of hexagonal architecture by Domain-Driven Design practitioners. 

![Screenshot](prtsc/Hexa-Arch-DDD-2.png)

**Note: A port in Java is an interface. An adapter is one implementation of that interface.**

### Domain Layer, in the center

- The domain layer represents the inside of the application and provides ports to interact with application use cases (business logic).

- This is the part that we want to isolate from both left and right sides. It contains all the code that concerns and implements business logic (use cases).
 
- Because domain objects have no dependencies on other layers of the application, changes in other layers don’t affect them.

### Application Layer, on the left

- The application layer provides different adapters for outside entities to interact with the domain through the port.

- This is the side through which the user or external programs will interact with the application. It contains the code that allows these interactions. Typically, your user interface code, your HTTP routes for an API, your JSON serializations to programs that consume your application are here.

### Infrastructure Layer, on the right

- Provide adapters and server-side logic to interact with the application from the right side. Server-side entities, such as a database or other run-time devices, use these adapters to interact with the domain.

- It contains essential infrastructure details such as the code that interacts with your database, makes calls to the file system, or code that handles HTTP calls to other applications on which you depend for example.

*Reference:*
- https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)
- https://dzone.com/articles/hexagonal-architecture-in-java-2
- https://blog.octo.com/en/hexagonal-architecture-three-principles-and-an-implementation-example/#principles

## Microservices Architecture

![Screenshot](prtsc/Hexagonal-Architecture-Microservices.jpg)

In our example we will use the basic architecture above without API Gateway. Customer, Product, Order do not necessarily have to be in different databases, it depends on the bounded context. The main objective is to highlight the use of Hexagonal Architecture in the microservices code. 

All microservices are implemented with Spring Boot, however microservices can be implemented with different technologies.
"
redhat-cop/businessautomation-cop,master,59,52,2020-02-13T16:42:25Z,17122,0,"All examples related to business automation processes such as jbpm, drools, dmn, optaplanner, cloud native kogito(quarkus), quickstart, pipelines, runtimes, etc.",buisness-automation businessautomation-cop dmn dmn-examples drools drools-example jbpm jbpm-example jbpm-process jbpm-springboot kogito kogito-example kogito-quickstart optaplanner quarkus rhdm rhpam rhpam-setup rhpam-springboot rhpam7,"[![License](https://img.shields.io/hexpm/l/plug.svg?maxAge=2592000)]()

# Business Automation Community of Practice
Business Automation or Red Hat Process Automation Manager is a portfolio that includes a web tool for authoring, rules management application and building business processes (Workbench/Business Central).

This repository is meant to help bootstrap users of the Red Hat Process Automation Manager Portfolio to get started in building and using Red Hat Process Automation Manager (PAM) and Red Hat Decision Manager (DM) to build applications to run in different runtimes such as JBoss enterprise platform, spring boot and cloud-native using Kogito(Quarkus implementation for JBPM and drools).

# Red Hat Process Automation Manager (PAM)
PAM is a platform for developing business process management (BPM),
business rules management (BRM), Decision Model and Notation (DMN), and business resource optimization and complex event processing (CEP).

# Red Hat Decision Manager (DM)
DM is a platform for developing and authoring business rules management (BRM), business resource optimization and complex event processing (CEP).

## Decision Model and Notation (DMN) 
It is a standard established by the Object Management Group (OMG) for describing and modelling operational decisions.

## Business Process Management (BPM)
It's a tool to help model, analyze, measure, improve, automate business processes and decisions based on the JBPM framework.

## Business rules management (BRM)
It provides a core Business Rules Engine (BRE) and full runtime support for Decision Model and Notation (DMN) models.

## Cloud Native - Kogito
Kogito is a framework that compiles your business process and business rules in a more cloud-native approach taking advantage of the latest technologies (Quarkus, Knative, etc.), you get amazingly fast boot times and instant scaling on orchestration platforms like Kubernetes.


## What's In This Repo?

This repo contains process automation(JBPM) and business rules(Drools and DMN) related quickstarts of several different flavours.


"
srecon/the-apache-ignite-book,master,76,46,2018-05-09T09:07:54Z,59035,0,"All code samples, scripts and more in-depth examples for The Apache Ignite Book. Include Apache Ignite 2.6 or above",bigdata distributed-database gridgain hadoop hibernate hibernate-ogm hive ignite in-memory-caching in-memory-computations in-memory-database java memoization nosql-database spark spring-data sql streaming streaming-data,"# The Apache Ignite Book

<a href=""http://leanpub.com/ignitebook""><img src=""https://github.com/srecon/the-apache-ignite-book/blob/master/3D_mini.png"" alt=""he Apache Ignite Book"" height=""256px"" align=""right""></a>

This is the code repository (code samples, scripts and more in-depth examples) for [The Apache Ignite Book](https://leanpub.com/ignitebook).

> [!IMPORTANT] 
> Note that, updated examples with Apache Ignite version 2.14.x are located on **chapters-java11x** folder.
> Folder **chapters** supports older Ignite version like 2.6.0.
> Use the following JVM options to run the examples on JVM 17 or later, for instance,
> 
> java --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.misc=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens=jdk.internal.jvmstat/sun.jvmstat.monitor=ALL-UNNAMED --add-opens=java.base/sun.reflect.generics.reflectiveObjects=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED -jar ./target/HelloIgnite-runnable.jar


## Naming conventions

Each chapter in the book has a corresponding folder within the repository. Each folder contains a set of files or folders related to each section of the chapter. For an example, the listing of the _memoization_ section is placed in the folder _chapters/chapter-5/memoization_.

## What is this book about?

Apache Ignite is one of the most widely used open source memory-centric distributed, caching, and processing platform. This allows the users to use the platform as an in- memory computing framework or a full functional persistence data stores with SQL and ACID transaction support. On the other hand, Apache Ignite can be used for accelerating existing Relational and NoSQL databases, processing events & streaming data or developing Microservices in fault-tolerant fashion.

This book addressed anyone interested in learning in-memory computing and distributed database. This book intends to provide someone with little to no experience of Apache Ignite with an opportunity to learn how to use this platform effectively from scratch taking a practical hands-on approach to learning.

This book covers the following exciting features:

* Apache Ignite architecture in depth such as data distributing technics (DHT), Rendezvous hashing, durable memory architecture, various cluster topologies, Ignite native persistence, Baseline topology and much more.
* Apache Ignite proven use cases as a memory-centric distributed database, caching and computing platforms.
* Getting started with Apache Ignite by using different tools and technics.
* Caching strategies by examples and how to use Apache Ignite for improving application performance including Hibernate L2 cache, MyBatis, memoization and web session cluster.
* Using Spring Data with Apache Ignite for developing high-performance web applications.
* Ignite query (SQL, API, Text and Scan queries) capabilities in depth.
* Using Spark RDD and Data frames for improving performance on processing fast data.
* Developing and executing distributed computations in a parallel fashion to gain high performance, low latency, and linear scalability. 
* Developing distributed Microservices in fault-tolerant fashion.
* Processing events & streaming data for IoT projects, integrate Apache Ignite with other frameworks like Kafka, Storm, Camel, etc.
* Configuring, management and monitoring Ignite cluster with built-in and 3rd party tools such.

If you feel this book is for you, get your [copy](https://leanpub.com/ignitebook) today!

> [!TIP]
> If you are not sure if this book is for you, I suggest you read the sample chapter of the book. The sample chapter is available in different formats including [HTML](https://leanpub.com/ignitebook/read_sample). Anyway, I encourage you to try it out, and if you don't like the book, you can always ask a 100% refund within 45 days.

## build and install

Run the following command from the **chapters-java11x** directory

```
mvn clean install
```

We recommend a workstation with the following configurations for working with the repository:

| № | Name         | Value                                                        |
|---|--------------|--------------------------------------------------------------|
| 1 | JDK          | Oracle/Open JDK 11.x and above.              |
| 2 | OS           | Linux, MacOS (10.8.3 and above), Windows Vista SP2 and above |
| 3 | Network      | No restriction                                               |
| 4 | RAM          | Minimum 4GB of RAM                                           |
| 5 | CPU          | Minimum 2 core                                               |
| 5 | IDE          | Eclipse, IntelliJ Idea, NetBeans or JDeveloper               |
| 6 | Apache Maven | Version 3.6.3 or above                                       |

## Conventions

The code will look like the following:
```
public class MySuperExtractor implements StreamSingleTupleExtractor<SinkRecord, String, String> {

  @Override public Map.Entry<String, String> extract(SinkRecord msg) {
      String[] parts = ((String)msg.value()).split(""_"");
      return new AbstractMap.SimpleEntry<String, String>(parts[1], parts[2]+"":""+parts[3]);
  }
}
```
Any command-line input or output is written as follows:
```
[2018-12-30 15:39:04,479] INFO Kafka version : 2.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2018-12-30 15:39:04,479] INFO Kafka commitId : 3402a8361b734732 (org.apache.kafka.common.utils.AppInfoParser)
[2018-12-30 15:39:04,480] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
```
## This Github repository contains the following examples:

- Ignite example in pure Java
- Ignite example in Spring
- Ignite thinclient example
- Ignite isolated cluster example
- Ignite with Hibernate example
- Ignite with MyBatis example
- Memoization example in Ignite
- Ignite web session clustering example
- Ignite SQL examples
- Ignite QueryApI example
- Ignite text query example
- Ignite distributed SQL JOINs example
- Ignite Spring data example
- Ignite compute grid examples
- Microservices with Ignite examples
- Ignite camel integration example
- Ignite flume integration example
- Ignite kafka integration example
- Ignite Storm integration example
- Ignite Spark RDD example
- Ignite Spark Data frame example
- Ignite Zookeeper discovery example
- Ignite Baseline by examples
- Ignite monitoring by VisualVM/Grafana example
- and much more ...
"
ITHit/WebDAVServerSamplesJava,master,52,21,2017-06-08T03:24:13Z,28292,5,WebDAV server examples in Java based on IT Hit WebDAV Server Library for Java,amazon-s3 java kotlin ms-ofba oracle samples server spring spring-boot springboot sql webdav,"
<h1>WebDAV Server Examples, Java</h1>
<div class=""description""><p style=""line-height: 22px; font-size: 15px; font-weight: normal;"">IT Hit WebDAV Server Library for Java is provided with several examples that demonstrate how to build a WebDAV server with SQL back-end or with file system storage. You can adapt these samples to utilize almost any back-end storage including storing data in CMS/DMS/CRM, Azure or Amazon storage.</p>
<p style=""line-height: 22px; font-size: 15px; font-weight: normal;"">A sample HTML page included with samples demonstrates how to use <a title=""IT Hit WebDAV Ajax Libray"" href=""https://www.webdavsystem.com/ajax/"" target=""_blank"">IT Hit WebDAV Ajax Libray</a>&nbsp;to open documents from a web page for editing, list documents and navigate folder structure as well as build search capabilities.</p>
<h2>Online Demo Server</h2>
<p style=""line-height: 22px; font-size: 15px; font-weight: normal;""><a title=""https://www.WebDAVServer.com"" href=""https://www.WebDAVServer.com"" target=""_blank"">https://www.WebDAVServer.com</a></p>
<h2>&nbsp;Requirements</h2>
<p style=""line-height: 22px; font-size: 15px; font-weight: normal;"">The samples are tested with <strong><span>Java 1.8</span></strong> in the following environments:</p>
<ul>
<li style=""margin-bottom: 16px;"">Tomcat 7 or later</li>
<li style=""margin-bottom: 16px;"">Glassfish 4.1.1 or later</li>
<li style=""margin-bottom: 16px;"">JBoss Wildfly 9 or later or respective EAP</li>
<li style=""margin-bottom: 16px;"">WebLogic 12c or later</li>
<li style=""margin-bottom: 16px;"">WebSphere 8.5.5.11 or later</li>
<li style=""margin-bottom: 16px;"">Jetty 9.3.13 or later</li>
</ul>
<h2>Full-text Search and indexing</h2>
<p style=""line-height: 22px; font-size: 15px; font-weight: normal;"">The samples are provided with full-text search and indexing based on use Apache Lucene as indexing engine and Apache Tika as content analysis toolkit.</p>
<p style=""line-height: 22px; font-size: 15px; font-weight: normal;"">The server implementation searches both file names and file content including content of Microsoft Office documents as well as any other documents which format is supported by Apache Tika, such as LibreOffice, OpenOffice, PDF, etc.</p></div>
<ul class=""list"">
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/jakarta/springboot3fsstorage"">
<h2>Spring Boot WebDAV Server Example with File System Back-end, Java</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/jakarta/springboot3fsstorage"">
<p>
This sample provides a WebDAV server running on the Spring Boot framework with files being stored in the file system. The WebDAV requests are processed in a dedicated context, while the rest of the website processes regular HTTP requests, serving web                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/springbootoraclestorage"">
<h2>Spring Boot WebDAV Server Example with Oracle Back-end, Java</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/springbootoraclestorage"">
<p>
This sample provides a WebDAV server running on the Spring Boot framework.&nbsp;All data including file content, document structure, and custom attributes are stored in the Oracle database.&nbsp;The&nbsp;IT Hit WebDAV Ajax Library&nbsp;is used to display and browse serv                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/springboots3storage"">
<h2>Spring Boot WebDAV Server Example with Amazon S3 Back-end, Java</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/springboots3storage"">
<p>
This sample&nbsp;is a fully functional Class 2 WebDAV server that runs on the Spring Boot framework and stores all data in the Amazon S3 bucket.&nbsp;The WebDAV requests are processed on a /DAV/ context, while the rest of the website processes regular HTTP req                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/oraclestorage"">
<h2>WebDAV Server Example with Oracle Back-end, Java</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/oraclestorage"">
<p>
The sample provides Class 2 WebDAV server implementation that can be hosted in Apache Tomcat, GlassFish, JBoss,&nbsp;WebLogic,&nbsp;WebSphere or other compliant application server. All data including file content, documents structure and custom attributes is s                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/jakarta/filesystemstorage"">
<h2>WebDAV Server Example with File System Back-end, Java and Kotlin</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/jakarta/filesystemstorage"">
<p>
This sample&nbsp;is a fully functional Class 2 WebDAV server that stores all data in the file system. It utilizes file system Extended Attributes (in case of Linux and macOS) or Alternate Data&nbsp;Streams (in case of Windows/NTFS) to store locks and custom pr                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/jakarta/collectionsync"">
<h2>WebDAV Server Example with Collection Synchronization Support</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/jakarta/collectionsync"">
<p>
This sample&nbsp;is a fully functional Class 2 WebDAV server with&nbsp;collection synchronization support (RFC 6578) that stores all data in the file system.&nbsp;This sample is similar to what is provided by the Java demo WebDAV server at: https://webdavserver.com                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/android/androidfsstorage"">
<h2>Java WebDAV Server Example for Android</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/android/androidfsstorage"">
<p>
This sample is a Class 2 WebDAV server that runs on Android. It uses modified&nbsp;NanoHTTPD as an application server and publishes files from a mobile application folder or from media folder. Locks and properties in SQLite database.
To see the documents                                             <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/deltav"">
<h2>WebDAV Server Example with Versioning, Java</h2>
</a>

<a href=""https://github.com/ITHit/WebDAVServerSamplesJava/tree/master/Java/javax/deltav"">
<p>
The sample provides&nbsp;DeltaV WebDAV server implementation that can be hosted in Apache Tomcat, GlassFish, JBoss,&nbsp;WebLogic or&nbsp;WebSphere. The data is stored in Oracle database.&nbsp;The IT Hit WebDAV Ajax Library is used to display and browse server content o                                            <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://www.webdavsystem.com/javaserver/server_examples/running_webdav_samples/"">
<h2>Running the WebDAV Samples</h2>
</a>

<a href=""https://www.webdavsystem.com/javaserver/server_examples/running_webdav_samples/"">
<p>
Once your&nbsp;sample is configured&nbsp;and running you will see the following web page (note that&nbsp;the port that the sample is using may be different from the one on the screenshots):

This web page is a MyCustomHandlerPage.html&nbsp;included in&nbsp;each sample&nbsp;and                                             <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://www.webdavsystem.com/javaserver/server_examples/search/"">
<h2>Configuring Full-Text Search for Files Stored in File System or in Oracle Database</h2>
</a>

<a href=""https://www.webdavsystem.com/javaserver/server_examples/search/"">
<p>
The&nbsp;samples provided with SDK&nbsp;use Apache Lucene&nbsp;as indexing engine and Apache Tika&nbsp;as content analysis toolkit.
The server implementation searches both file names and file content including content of Microsoft Office documents as well as any other                                             <span>...</span>
</p>
</a>
</li>
<li>
<a class=""link-header"" href=""https://www.webdavsystem.com/javaserver/server_examples/troubleshooting/"">
<h2>WebDAV Server Samples Problems and Troubleshooting</h2>
</a>

<a href=""https://www.webdavsystem.com/javaserver/server_examples/troubleshooting/"">
<p>
Examining Logs
If things are not going as planned and you run into issues the first place to look would be the log file&nbsp;&amp;lt;Your Tomcat location&amp;gt;\Tomcat x.x\logs\localhost.xxxx-xx-xx.log&nbsp;. The logs will reflect as to what is going on and it will                                             <span>...</span>
</p>
</a>
</li>
</ul>

"
mphasize/FullDome,master,30,6,2011-04-01T08:52:04Z,2094,0,Tools and Examples,,"FullDome: Tools and Examples
============================


This is a collection of tools and code I came across or I modified for displaying interactive content in a fulldome environment.
I do this as part of a class I'm taking called ""Immersive Data Visualisation"" at the FH Potsdam.
[Workspace](http://incom.org/workspace/2755)


Tools:
======

Processing / FullDomeTemplate
---
Amazing Tool by Christopher Warnow! Warps your Processing Sketch into a dome master with some really nice OpenGL magic.
For [more details and instructions](https://github.com/mphasize/FullDome/tree/master/Processing/FullDomeTemplate) on usage (german only so far...) click the link and scroll down to README...



Processing / SimulationTemplate
---

The SimulationTemplate creates a movable Dome and projects your interactive Sketches into it.  
For [more details and instructions](https://github.com/mphasize/FullDome/tree/master/Processing/SimulationTemplate) on usage (german only so far...) click the link and scroll down to README...

"
viglucci/app-jcef-example,master,74,40,2015-12-21T01:59:42Z,4562,2,Example application for using Java Chrome Embedded Framework,,"# app-jcef-example

Example application for using Java Chrome Embedded Framework

## Prerequisites

### JCEF

A build of JCEF to be available via your PATH environment variable.

https://bitbucket.org/chromiumembedded/java-cef/wiki/BranchesAndBuilding

Add the `some_directory/jcef_build/native/Release` directory to your PATH environment variable.

### Java JDK

Java 1.8

## Maven Build

1. mvn clean package

## IntelliJ IDEA Build

Setup:

1. File -> Project Structure -> Artifacts 
2. Green + -> Jar -> from module with dependencies
3. Select SimpleFrameExample

Build:

1. Build -> Build Artifacts

## Run from run.bat

1. From IntelliJ project explorer -> right click run.bat -> Run 'run'

"
alexaverbuch/akka_chat_java,master,39,30,2010-11-15T16:01:38Z,687,0,Akka chat example using Java API,,
ewolff/microservice-istio,master,186,102,2019-01-13T19:09:10Z,458,0,Example for a microservices system based in Kubernetes and the service mesh Istio,,"Microservice Istio Sample
=====================

[Deutsche Anleitung zum Starten des Beispiels](WIE-LAUFEN.md)

This demo uses [Kubernetes](https://kubernetes.io/) as Docker
environment. Kubernetes also support service discovery and load
balancing. An Apache httpd as a reverse proxy routes the calls to the
services.

Also the demo uses [Istio](https://istio.io/) for features like
monitoring, tracing, fault injection, and circuit breaking.

This project creates a complete microservice demo system in Docker
containers. The services are implemented in Java using Spring Boot and
Spring Cloud.


It uses three microservices:
- `Order` to accept orders.
- `Shipping` to ship the orders.
- `Invoicing` to ship invoices.

How to run
---------

See [How to run](HOW-TO-RUN.md).


Remarks on the Code
-------------------

The microservices are: 
- [microservice-istio-order](microservice-istio-demo/microservice-istio-order) to create the orders
- [microserivce-istio-shipping](microservice-istio-demo/microservice-istio-shipping) for the shipping
- [microservice-istio-invoicing](microservice-istio-demo/microservice-istio-invoicing) for the invoices

The microservices have an Java main application in `src/test/java` to
run them stand alone. microservice-demo-shipping and
microservice-demo-invoicing both use a stub for the
other order service for the tests.

The data of an order is copied - including the data of the customer
and the items. So if a customer or item changes in the order system
this does not influence existing shipments and invoices. It would be
odd if a change to a price would also change existing invoices. Also
only the information needed for the shipment and the invoice are
copied over to the other systems.

The job to poll the order feed is run every 30 seconds.

"
oktadev/jhipster-microservices-example,master,126,89,2017-05-03T01:53:47Z,32598,3,"JHipster Microservices Example using Spring Cloud, Spring Boot, Angular, Docker, and Kubernetes",angular docker google-cloud jhipster jhipster-microservices kubernetes minikube spring-boot spring-cloud webpack,"# JHipster Microservices Example

> A microservice architecture created with JHipster. Uses Spring Cloud, Spring Boot, Angular, and MongoDB for a simple blog/store applications. 

Please read [Develop and Deploy Microservices with JHipster](https://developer.okta.com/blog/2017/06/20/develop-microservices-with-jhipster) to see how this example was created.

**Prerequisites:** [Java 8](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html), [Node.js](https://nodejs.org/) 6.11, [Yarn](https://yarnpkg.com/lang/en/docs/install/), and [Docker](https://docs.docker.com/engine/installation/).

**NOTE:** If you're not on Mac or Windows, you may need to [install Docker Compose](https://docs.docker.com/compose/install/) as well.

> [Okta](https://developer.okta.com/) has Authentication and User Management APIs that reduce development time with instant-on, scalable user infrastructure. Okta's intuitive API and expert support make it easy for developers to authenticate, manage and secure users and roles in any application.

* [Getting Started](#getting-started)
* [Links](#links)
* [Help](#help)
* [License](#license)

## Getting Started

To install this example application, run the following commands:

```bash
git clone https://github.com/oktadeveloper/jhipster-microservices-example.git
cd jhipster-microservices-example
```

1. Start the registry by running `./mvnw -Pprod` in the `registry` directory.
2. Install dependencies in the `blog` directory, build the UI, and run the Spring Boot app.
 
    ```
    yarn
    ./mvnw 
    ``` 
    
3. Start MongoDB using Docker Compose in the `store` directory.
    
    ```bash
    docker-compose -f src/main/docker/mongodb.yml up
    ```
    
4. Install dependencies in the `store` directory, build the UI, and run the Spring Boot app.
 
    ```
    yarn
    ./mvnw 
    ``` 
    
You should be able to see the `blog` app at <http://localhost:8080> and edit products (from the `store` app)

### Run with Docker Compose

You can use Docker Compose to start everything if you don't want to start applications manually with Maven.

1. Make sure Docker is running.
2. Build Docker images for the `blog` and `store` applications by running the following command in both directories.

    ```
    ./mvnw package -Pprod docker:build
    ```
    
3. Open a terminal, navigate to the `docker` directory of this project, and run the following command. If you have a lot
of RAM on your machine, you might want to adjust Docker's default setting (2 GB).

    ```
    docker-compose up -d
    ````
    
    TIP: Remove `-d` from the end of the command above if you want to see logs from all containers in the current window.
    
4. Use [Kitematic](https://kitematic.com/) to view the ports and logs for the services deployed.

To create activity in JHipster Console's charts, you run the Gatling tests in the `blog` and `store` projects.

```bash
./mvnw gatling:execute
```

To remove all Docker containers, run the following commands or do it manually using Kitematic.

```bash
docker stop $(docker ps -a -q)
docker rm $(docker ps -a -q)
```

To find what's running on a port on macOS, use `sudo lsof -i :9092 # checks port 9092`.

### Run with Kubernetes and Minikube

1. Install [kubectl](https://kubernetes.io/docs/tasks/kubectl/install/), [VirtualBox](https://www.virtualbox.org/wiki/Downloads), and [Minikube](https://github.com/kubernetes/minikube/releases).
2. Start Minikube using `minikube start`.
3. To be able to work with the docker daemon, make sure Docker is running, then run the following command in your terminal:

    ```bash
    eval $(minikube docker-env)
    ```

4. Create Docker images of the `blog` and `store` applications:

   ```bash
   ./mvnw package -Pprod docker:build
   ```

5. Navigate to the `kubernetes` directory in your terminal and re-generate the files so they match your Docker repository name.

   ```
   jhipster kubernetes
   ```
   
   Follow the instructions for tagging and pushing the Docker images.

   ```bash
   docker image tag blog {yourRepoName}/blog
   docker push {yourRepoName}/blog
   docker image tag store {yourRepoName}/store
   docker push {yourRepoName}/store
   ```
   
6. Use `kubectl` to deploy to Minikube. 

    ```
    kubectl apply -f registry
    kubectl apply -f blog
    kubectl apply -f store
    ```
    
    The deployment process can take several minutes to complete. Run `minikube dashboard` to see the deployed containers.
    You can also run `kubectl get po -o wide --watch` to see the status of each pod.

6. Run `minikube service blog` to view the blog application. You should be able to login and add blogs, entries, and products.

To remove all deployed containers, run the following command:

    kubectl delete deployment --all
    
To stop Minikube, run `minikube stop`.

**NOTE:** If you run `minikube delete` and have trouble running `minikube start` afterward, run `rm -rf ~/.minikube`. 
See [this issue](https://github.com/kubernetes/minikube/issues/290) for more information.

### Google Cloud

1. Create a Google Cloud project at [console.cloud.google.com](https://console.cloud.google.com/).
2. Navigate to <https://console.cloud.google.com/kubernetes/list> to initialize the Container Engine for your project. 
3. Install [Google Cloud SDK](https://cloud.google.com/sdk/) and set project using:
  
       gcloud config set project <project-name>

4. Create a cluster:
  
       gcloud container clusters create <cluster-name> --machine-type=n1-standard-2 --scopes cloud-platform --zone us-west1-a
       
   To see a list of possible zones, run `gcloud compute zones list`.
   
5. Push the `blog` and `store` docker images to [Docker Hub](https://hub.docker.com/). You will need to create an account 
and run `docker login` to push your images. The images can be run from any directory.

    ```bash
    docker image tag blog mraible/blog
    docker push mraible/blog
    docker image tag store mraible/store
    docker push mraible/store
    ```

6. Run `kubectl` commands to deploy.

    ```bash
    kubectl apply -f registry
    kubectl apply -f blog
    kubectl apply -f store
    ```

7. Use port-forwarding to see the registry app locally.

       kubectl port-forward jhipster-registry-0 8761:8761
    
8. Run `kubectl svc blog` to view the blog application on Google Cloud.

9. Scale microservice apps as needed with `kubectl`:

       kubectl scale --replicas=3 deployment/store
    
To see a screencast of this process, [watch this YouTube video](https://youtu.be/dgVQOYEwleA).

### AWS

If you know how to deploy this architecture to AWS, I'd love to hear about it! I [tried in anger](https://groups.google.com/forum/#!msg/jhipster-dev/NNA3TScENVE/WmbG2Qt_AwAJ), but ultimately failed.

## Links

This example uses [JHipster](https://www.jhipster.tech), and awesome project that allows you to generate a microservices architecture with [Spring Boot](https://projects.spring.io/spring-boot/). See [Develop a Microservices Architecture with OAuth 2.0 and JHipster](https://developer.okta.com/blog/2018/03/01/develop-microservices-jhipster-oauth) for an example that uses OAuth and Okta.

## Help

Please post any questions as comments on the [blog post](https://developer.okta.com/blog/2018/03/01/develop-microservices-jhipster-oauth), or visit our [Okta Developer Forums](https://devforum.okta.com/). You can also email developers@okta.com if would like to create a support ticket.

## License

Apache 2.0, see [LICENSE](LICENSE).
"
brainhubeu/react-native-opencv-tutorial,master,315,105,2018-03-20T15:22:24Z,1093,21,👩‍🏫Fully working example of the OpenCV library used together with React Native,camera computer-vision java javascript jest objective-c objective-c-plus-plus opencv react react-native react-native-camera reactnative,"<br/>
<h1 align=""center"">
  react-native-opencv-tutorial
</h1>

<p align=""center"">
  A fully working example of the OpenCV library used together with React Native.
</p>

<p align=""center"">
  <strong>
    <a href=""https://brainhub.eu/blog/opencv-react-native-image-processing/"">Blog post</a> | 
    <a href=""https://brainhub.eu/contact/"">Hire us</a>
  </strong>
</p>

<div align=""center"">

  [![license](https://img.shields.io/badge/License-MIT-green)](https://github.com/brainhubeu/react-native-opencv-tutorial/blob/master/LICENSE.MD)
  [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)
</div>

## What this tutorial is about
This tutorial is how to use React Native together with OpenCV for image processing. This example uses native Java and Objective-C bindings for OpenCV. In this example we use the device's camera to take a photo and detect whether the taken photo is clear or blurred.

## Demo

The examples below show the situation right after taking a photo. The first one shows what happens if we take a blurry photo and the second one is the situation after we took a clear photo and are able to proceed with it to do whatever we want.

![Blurred photo](./images/blurred_photo.png)
![Clear photo](./images/clear_photo.png)

## Blog post

https://brainhub.eu/blog/opencv-react-native-image-processing/

## Prerequisites

1. XCode
2. Android Studio

## How to run the project

1. Clone the repository.
2. `cd cloned/repository/path`
3. `npm i` or `yarn`
4. `react-native link`
5. Run `./downloadAndInsertOpenCV.sh`.
6. Download manually the Android pack from https://opencv.org/releases.html (version 3.4.1).
7. Unzip the package.
8. Import OpenCV to Android Studio, From File -> New -> Import Module, choose sdk/java folder in the unzipped opencv archive.
9. Update build.gradle under imported OpenCV module to update 4 fields to match your project's `build.gradle`<br/>

	a) compileSdkVersion<br/>
	b) buildToolsVersion<br/>
	c) minSdkVersion<br/>
	d) targetSdkVersion.

10. Add module dependency by Application -> Module Settings, and select the Dependencies tab. Click + icon at bottom, choose Module Dependency and select the imported OpenCV module. For Android Studio v1.2.2, to access to Module Settings : in the project view, right-click the dependent module -> Open Module Settings.
11. `react-native run-ios` or `react-native run-android`.

### Additional notes
In case of any `downloadAndInsertOpenCV.sh ` script related errors, please, check the paths inside this file and change them if they do not match yours.
If this script does not run at all since it has no permissions, run `chmod 777 downloadAndInsertOpenCV.sh`.

If you do not have `React Native` installed, type `npm i -g react-native-cli` in the terminal.

### License

reactNativeOpencvTutorial is copyright © 2018-2020 [Brainhub](https://brainhub.eu/?utm_source=github) It is free software, and may be redistributed under the terms specified in the [license](LICENSE.MD).

### About

reactNativeOpencvTutorial is maintained by the Brainhub development team. It is funded by Brainhub and the names and logos for Brainhub are trademarks of Brainhub Sp. z o.o.. You can check other open-source projects supported/developed by our teammates here. 

[![Brainhub](https://brainhub.eu/brainhub.svg)](https://brainhub.eu/?utm_source=github)

We love open-source JavaScript software! See our other projects or hire us to build your next web, desktop and mobile application with JavaScript.
"
juhahinkula/StudentListFinal,master,51,34,2016-07-31T16:43:27Z,238,1,Spring Boot CRUD example with Spring security,crud spring-boot spring-data-jpa spring-security,"# StudentList
Simple CRUD application made with Spring Boot

- Spring Boot
- Spring Security
- Thymeleaf
- H2 database
- Bootstrap

Usage:<br>
1) Clone the project <br>```git clone https://github.com/juhahinkula/StudentListFinal.git```<br>
2) run the following command in a terminal window (in the complete) directory:<br>
```./mvnw spring-boot:run```<br>
3) Navigate to localhost:8080<br>

If using Eclipse, you can also run the project in the following way:<br>
1) Eclipse: File -> Import -> Maven -> Existing Maven Projects<br>
2) Run<br>
3) Navigate to localhost:8080<br>

Application contains two demo users: <br>
user/user (role=USER) <br>
admin/admin (role=ADMIN)<br>

## Screenshot

![Screenshot](https://github.com/juhahinkula/juhahinkula.github.io/raw/master/img/crudboot.png)


"
raycad/stream-processing,master,35,16,2019-08-21T09:23:34Z,3721,1,Stream processing guidelines and examples using Apache Flink and Apache Spark,apache-flink apache-spark batch-processing data-analysis streaming,"## 1. Big Data Analysis Overview

![Big Data Analysis Overview](./docs/images/bigdata_analysis_overview.png)

## 2. Batch Processing vs Stream Processing
### 2.1. Batch Processing
In batch processing, newly arriving data elements are collected into a group. The whole group is then processed at a future time (as a batch, hence the term “batch processing”). Exactly when each group is processed can be determined in a number of ways–for example, it can be based on a scheduled time interval (e.g. every five minutes, process whatever new data has been collected) or on some triggered condition (e.g. process the group as soon as it contains five data elements or as soon as it has more than 1MB of data).

![Batch Processing](./docs/images/batch_processing.png)

**Micro-Batch** is frequently used to describe scenarios where batches are small and/or processed at small intervals. Even though processing may happen as often as once every few minutes, data is still processed a batch at a time.

### 2.2. Stream Processing
In stream processing, each new piece of data is processed when it arrives. Unlike batch processing, there is no waiting until the next batch processing interval and data is processed as individual pieces rather than being processed a batch at a time.

![Stream Processing](./docs/images/streaming_processing.png)

**Use cases:**
* Algorithmic Trading, Stock Market Surveillance
* Monitoring a production line
* Intrusion, Surveillance and Fraud Detection ( e.g. Uber)
* Predictive Maintenance, (e.g. Machine Learning Techniques for Predictive Maintenance)

<H3>Batch Processing vs Streaming Processing</H3>

| | Batch Processing | Stream Processing |
|-|-|-|
| **Data Scope** | Queries or processing over all or most of the data in the dataset | Queries or processing over data within a rolling time window, or on just the most recent data record |
| **Data Size** | Large batches of data | Individual records or micro batches consisting of a few records |
| **Performance** | Latencies in minutes to hours | Requires latency in the order of seconds or milliseconds |
| **Analyses** | Complex analytics | Simple response functions, aggregates, and rolling metrics |

## 3. Apache Flink

### 3.1. Apache Flink Ecosystem
![Flink Ecosystem](./docs/images/flink/flink_ecosystem.png)

#### 3.1.1. Storage / Streaming
Flink doesn’t ship with the storage system; it is just a computation engine. Flink can read, write data from different storage system as well as can consume data from streaming systems. Below is the list of storage/streaming system from which Flink can read write data:
* **HDFS**: Hadoop Distributed File System
* **Local-FS**: Local File System
* **S3**: Simple Storage Service from Amazon
* **HBase**: NoSQL Database in Hadoop ecosystem
* **MongoDB**: NoSQL Database
* **RDBMS**: Any relational database
* **Kafka**: Distributed messaging Queue
* **RabbitMQ**: Messaging Queue
* **Flume**: Data Collection and Aggregation Tool

#### 3.1.2. Deploy
Flink can be deployed in following modes:
* **Local mode**: On a single node, in single JVM
* **Cluster**: On a multi-node cluster, with following resource manager.
* **Standalone**: This is the default resource manager which is shipped with Flink.
* **YARN**: This is a very popular resource manager, it is part of Hadoop
* **Mesos**: This is a generalized resource manager.
* **Cloud**: on Amazon or Google cloud

#### 3.1.3. Distributed Streaming Dataflow
It is also called as the kernel of Apache Flink. This is the core layer of flink which provides distributed processing, fault tolerance, reliability, native iterative processing capability,...

#### 3.1.4. APIs and Library
* __DataSet API__\
It allows the user to implement operations like map, filter, join, group, etc. on the dataset. It is mainly used for distributed processing. 
* __DataStream API__\
It handles a continuous stream of the data. To process live data stream it provides various operations like map, filter, update states, window, aggregate, etc. It can consume the data from the various streaming source and can write the data to different sinks.
* __Table__\
It enables users to perform ad-hoc analysis using SQL like expression language for relational stream and batch processing. It can be embedded in DataSet and DataStream APIs.
* __Gelly__\
It is the graph processing engine which allows users to run set of operations to create, transform and process the graph.
* __FlinkML__\
It is the machine learning library which provides intuitive APIs and an efficient algorithm to handle machine learning applications.

### 3.2. Apache Flink Features

![Flink Features](./docs/images/flink/flink_features.png)

**1. Fast Speed**\
    Flink processes data at lightning fast speed (hence also called as 4G of Big Data).

**2. Stream Processing**\
    Flink is a true stream processing engine.

**3. In-memory Computation**\
    Data is kept in random access memory(RAM) instead of some slow disk drives and is processed in parallel. It improves the performance by an order of magnitudes by keeping the data in memory.

**4. Ease of Use**\
    Flink’s APIs are developed in a way to cover all the common operations, so programmers can use it efficiently.

**5. Broad integration**\
    Flink can be integrated with the various storage system to process their data, it can be deployed with various resource management tools. It can also be integrated with several BI tools for reporting.

**6. Deployment**\
    It can be deployed through Mesos, Hadoop via YARN, or Flink's own cluster manager or cloud (Amazon, Google cloud).

**7. Scalable**\
    Flink is highly scalable. With increasing requirements, we can scale the flink cluster.

**8. Fault Tolerance**\
    Failure of hardware, node, software or a process doesn’t affect the cluster.

### 3.3. Apache Flink Architecture

Apache Flink is an open source platform for distributed stream and batch data processing. Flink’s core is a streaming dataflow engine that provides data distribution, communication, and fault tolerance for distributed computations over data streams. Flink builds batch processing on top of the streaming engine, overlaying native iteration support, managed memory, and program optimization.

* **Program**\
It is a piece of code, which you run on the **Flink Cluster**.

* **Client**\
It is responsible for taking code (program) and constructing job dataflow graph, then passing it to **JobManager**. It also retrieves the Job results.

* **JobManager**\
Also called **masters**. They coordinate the distributed execution. They schedule tasks, coordinate checkpoints, coordinate recovery on failures, etc. After receiving the Job Dataflow Graph from Client, it is responsible for creating the execution graph. It assigns the job to **TaskManagers** in the cluster and supervises the execution of the job.

There is always at least one **Job Manager**. A high-availability setup will have multiple **JobManagers**, one of which one is always the leader, and the others are standby.

* **TaskManager**\
Also called **workers** or **slaves**. They execute the tasks that have been assigned by **JobManager** (or more specifically, the subtasks) of a dataflow, and buffer and exchange the data streams. All the **TaskManagers** run the tasks in their separate slots in specified parallelism. It is responsible to send the status of the tasks to **JobManager**.

![Flink Architecture](./docs/images/flink/flink_architecture.svg) 

![Flink Job Flow](./docs/images/flink/flink_job_flows.png)

### 3.4. Apache Flink Programs and Dataflows
The basic building blocks of Flink programs are streams and transformations. 
Conceptually a stream is a (potentially never-ending) flow of data records, and a transformation is an operation that takes one or more streams as input, and produces one or more output streams as a result.
When executed, Flink programs are mapped to streaming dataflows, consisting of streams and transformation operators. Each dataflow starts with one or more sources and ends in one or more sinks. The dataflows resemble arbitrary directed acyclic graphs (DAGs). Although special forms of cycles are permitted via iteration constructs, for the most part we will gloss over this for simplicity.

![Programs and Dataflows](./docs/images/flink/program_dataflow.svg)  

![Stream Dataflows](./docs/images/flink/stream_data_flow.png) |

### 3.5. Data Source
* Sources are where the program reads its input from. 
* A source is attached to the program by using StreamExecutionEnvironment.addSource(sourceFunction). 
* Flink comes with a number of pre-implemented source functions, but you can always write your own custom sources by implementing the SourceFunction for non-parallel sources, or by implementing the ParallelSourceFunction interface or extending the RichParallelSourceFunction for parallel sources.

There are several predefined stream sources accessible from the StreamExecutionEnvironment:

**1. File-based:**
* readTextFile(path) - Reads text files, i.e. files that respect the TextInputFormat specification, line-by-line and returns them as Strings.
* readFile(fileInputFormat, path) - Reads (once) files as dictated by the specified file input format.
* readFile(fileInputFormat, path, watchType, interval, pathFilter, typeInfo) - This is the method called internally by the two previous ones. It reads files in the path based on the given fileInputFormat. Depending on the provided watchType, this source may periodically monitor (every interval ms) the path for new data (FileProcessingMode.PROCESS_CONTINUOUSLY), or process once the data currently in the path and exit (FileProcessingMode.PROCESS_ONCE). Using the pathFilter, the user can further exclude files from being processed.

**2. Socket-based:**
* socketTextStream - Reads from a socket. Elements can be separated by a delimiter.

**3. Collection-based:**
* fromCollection(Collection) - Creates a data stream from the Java Java.util.Collection. All elements in the collection must be of the same type.
* fromCollection(Iterator, Class) - Creates a data stream from an iterator. The class specifies the data type of the elements returned by the iterator.
* fromElements(T ...) - Creates a data stream from the given sequence of objects. All objects must be of the same type.
* fromParallelCollection(SplittableIterator, Class) - Creates a data stream from an iterator, in parallel. The class specifies the data type of the elements returned by the iterator.
* generateSequence(from, to) - Generates the sequence of numbers in the given interval, in parallel.

**4. Custom:**
* addSource - Attach a new source function. For example, to read from Apache Kafka you can use addSource(new FlinkKafkaConsumer08<>(...)). See connectors for more details.

### 3.6. Collection Data Sources
Flink provides special data sources which are backed by Java collections to ease testing. Once a program has been tested, the sources and sinks can be easily replaced by sources and sinks that read from / write to external systems.

```java
final StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();

// Create a DataStream from a list of elements
DataStream<Integer> myInts = env.fromElements(1, 2, 3, 4, 5);

// Create a DataStream from any Java collection
List<Tuple2<String, Integer>> data = ...
DataStream<Tuple2<String, Integer>> myTuples = env.fromCollection(data);

// Create a DataStream from an Iterator
Iterator<Long> longIt = ...
DataStream<Long> myLongs = env.fromCollection(longIt, Long.class);
```

**Note**: Currently, the collection data source requires that data types and iterators implement Serializable. Furthermore, collection data sources can not be executed in parallel ( parallelism = 1).

### 3.7. DataStream Transformations
See the following links:\
https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/index.html

https://ci.apache.org/projects/flink/flink-docs-stable/dev/batch

https://ci.apache.org/projects/flink/flink-docs-stable/dev/batch/dataset_transformations.html

**DataStream Transformations Functions**
Most transformations require user-defined functions. This section lists different ways of how they can be specified.

**1. Implementing an interface**

The most basic way is to implement one of the provided interfaces:
```java
class MyMapFunction implements MapFunction<String, Integer> {
	public Integer map(String value) { 
		return Integer.parseInt(value); 
	}
};
data.map(new MyMapFunction());
```
**2. Anonymous classes**

You can pass a function as an anonymous class:
```java
data.map(new MapFunction<String, Integer> () {
	public Integer map(String value) { 
		return Integer.parseInt(value); 
	}
});
```
**3. Java 8 Lambdas**

Flink also supports Java 8 Lambdas in the Java API.
```java
data.filter(s -> s.startsWith(""http://""));
data.reduce((i1, i2) -> i1 + i2);
```

### 3.8. Data Sink
Data sinks consume DataStreams and forward them to files, sockets, external systems, or print them. Flink comes with a variety of built-in output formats that are encapsulated behind operations on the DataStreams:
* writeAsText() / TextOutputFormat - Writes elements line-wise as Strings. The Strings are obtained by calling the toString() method of each element.
* writeAsCsv(...) / CsvOutputFormat - Writes tuples as comma-separated value files. Row and field delimiters are configurable. The value for each field comes from the toString() method of the objects.
* print() / printToErr() - Prints the toString() value of each element on the standard out / standard error stream. Optionally, a prefix (msg) can be provided which is prepended to the output. This can help to distinguish between different calls to print. If the parallelism is greater than 1, the output will also be prepended with the identifier of the task which produced the output.
* writeUsingOutputFormat() / FileOutputFormat - Method and base class for custom file outputs. Supports custom object-to-bytes conversion.
* writeToSocket - Writes elements to a socket according to a SerializationSchema
* addSink - Invokes a custom sink function. Flink comes bundled with connectors to other systems (such as Apache Kafka) that are implemented as sink functions.

### 3.9. Iterations
Iterative streaming programs implement a step function and embed it into an IterativeStream. As a DataStream program may never finish, there is no maximum number of iterations. Instead, you need to specify which part of the stream is fed back to the iteration and which part is forwarded downstream using a split transformation or a filter. Here, we show an example using filters. First, we define an IterativeStream
```java
IterativeStream<Integer> iteration = input.iterate();
```
Then, we specify the logic that will be executed inside the loop using a series of transformations (here a simple map transformation)
```java
DataStream<Integer> iterationBody = iteration.map(/* this is executed many times */);
```
To close an iteration and define the iteration tail, call the closeWith(feedbackStream) method of the IterativeStream. The DataStream given to the closeWith function will be fed back to the iteration head. A common pattern is to use a filter to separate the part of the stream that is fed back, and the part of the stream which is propagated forward. These filters can, e.g., define the “termination” logic, where an element is allowed to propagate downstream rather than being fed back.
```java
iteration.closeWith(iterationBody.filter(/* one part of the stream */));
DataStream<Integer> output = iterationBody.filter(/* some other part of the stream */);
```

**See more**: https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html

### 3.10. Apache Flink Build/Run/Test

**1. Build Flink from source code**
```
$ git clone https://github.com/apache/flink.git
$ cd flink
$ git checkout release-1.8.1
$ mvn clean install -Pinclude-kinesis -Pinclude-hadoop -DskipTests
```

**2. Start Flink Cluster**

https://ci.apache.org/projects/flink/flink-docs-release-1.8/ops/deployment/cluster_setup.html

```
$ cd [flink]/build-target

# Change the flink master ip by editting the jobmanager.rpc.address value
$ nano conf/flink-conf.yaml

# Configure flink slave (worker) nodes
$ nano conf/slaves

# Start the cluster
$ bin/start-cluster.sh
# Then type passwords of slave nodes for the master to execute them...
```

**[NOTE]:** The Flink directory must be available on every worker under the same path. You can use a shared NFS directory, or copy the entire Flink directory to every worker node.

Check the cluster dashboard by access to http://<flink-master-ip>:8081

**Test a Flink Job**

Firstly run a input stream server using Netcat
```
# -l: listen (server mode)
$ nc -l 9000
```

To test client using Netcat
```
$ nc localhost 9000
```

**If you want to test streaming huge data you can run the python tcp server in the scripts folder**
```bash
$ python [stream-processing]/src/scripts/tcp_server.py
```

Then you can type sentences from the terminal to send data to Flink job application. There are 2 ways to test a Flink job:

- Submit new job from the dashboard
```
See the example below (Index 2.3)
```

- Manually running job from terminal
```
$ ./bin/flink run [flink-word-count-path]/SocketWindowWordCount.jar --hostname <netcat-host-ip> --port 9000
```

**3. Flink Cluster**
![Flink Cluster](./docs/images/flink/flink_cluster.png)

**4. Flink Cluster Dashboards**
![Flink Cluster Overview](./docs/images/flink/flink_cluster_overview.png)

**5. Task Managers**
![Flink Cluster](./docs/images/flink/task_managers.png)

**6. Job Submission**
![Flink Cluster](./docs/images/flink/submit_job.png)

**7. Job Results**
![Flink Cluster](./docs/images/flink/flink_job_results.png)

**8. Stop Flink Cluster**
```
$ ./bin/stop-cluster.sh
```

## 4. Apache Spark
### 4.1. Apache Spark Features
**Apache Spark** is an open source cluster computing framework for real-time data processing. The main feature of Apache Spark is its in-memory cluster computing that increases the processing speed of an application. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. It is designed to cover a wide range of workloads such as batch applications, iterative algorithms, interactive queries, and streaming.

![Apache Spark Features](./docs/images/spark/spark_features.png)

**1. Speed**

Spark runs up to 100 times faster than Hadoop MapReduce for large-scale data processing. It is also able to achieve this speed through controlled partitioning. Source

**2. Near real-time Processing**

It offers near real-time computation & low latency because of in-memory computation.

**3. In-memory Computation**

Data is kept in random access memory(RAM) instead of some slow disk drives and is processed in parallel. It improves the performance by an order of magnitudes by keeping the data in memory.

**4. Ease of Use**

Spark has easy-to-use APIs for operating on large datasets. This includes a collection of over 100 operators for transforming data and familiar data frame APIs for manipulating semi-structured data.

**5. Unified Engine**

Spark comes packaged with higher-level libraries, including support for SQL queries, streaming data, machine learning and graph processing. These standard libraries increase developer productivity and can be seamlessly combined to create complex workflows.

**6. Deployment**

It can be deployed through Mesos, Hadoop via YARN, or Spark’s own cluster manager.

**7. Polyglot**

Spark provides high-level APIs in Java, Scala, Python, and R. Spark code can be written in any of these four languages. It also provides a shell in Scala and Python.

**8. Fault Tolerance**

Upon the failure of worker node, using lineage of operations we can re-compute the lost partition of RDD from the original one. Thus, we can easily recover the lost data.

### 4.2. Apache Spark Ecosystem
![Apache Spark Ecosystem](./docs/images/spark/spark_ecosystem.png)

**1. Spark Core**
Spark Core is the base engine for large-scale parallel and distributed data processing. It is responsible for memory management and fault recovery, scheduling, distributing and monitoring jobs on a cluster & interacting with storage systems.

**2. Spark Streaming**
Spark Streaming is the component of Spark which is used to process real-time streaming data. Thus, it is a useful addition to the core Spark API. It enables high-throughput and fault-tolerant stream processing of live data streams.

**3. Spark SQL**
Spark SQL is a new module in Spark which integrates relational processing with Spark’s functional programming API. It supports querying data either via SQL or via the Hive Query Language. For those of you familiar with RDBMS, Spark SQL will be an easy transition from your earlier tools where you can extend the boundaries of traditional relational data processing.

**4. GraphX**
GraphX is the Spark API for graphs and graph-parallel computation. Thus, it extends the Spark RDD with a Resilient Distributed Property Graph. At a high-level, GraphX extends the Spark RDD abstraction by introducing the Resilient Distributed Property Graph (a directed multigraph with properties attached to each vertex and edge).

**5. MLlib (Machine Learning)**
MLlib stands for Machine Learning Library. Spark MLlib is used to perform machine learning in Apache Spark.

### 4.3. Apache Spark Architecture

| Term | Meaning |
|-|-|
| Application | User program built on Spark. Consists of a driver program and executors on the cluster.|
| Application jar | A jar containing the user's Spark application. In some cases users will want to create an ""uber jar"" containing their application along with its dependencies. The user's jar should never include Hadoop or Spark libraries, however, these will be added at runtime.|
| Driver program | The process running the main() function of the application and creating the SparkContext.|
| Cluster manager | An external service for acquiring resources on the cluster (e.g. standalone manager, Mesos, YARN).|
| Deploy mode | Distinguishes where the driver process runs. In ""cluster"" mode, the framework launches the driver inside of the cluster. In ""client"" mode, the submitter launches the driver outside of the cluster.|
| Worker node | Any node that can run application code in the cluster.|
| Executor | A process launched for an application on a worker node, that runs tasks and keeps data in memory or disk storage across them. Each application has its own executors.|
| Task | A unit of work that will be sent to one executor.|
| Job | A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (e.g. save, collect); you'll see this term used in the driver's logs.|
| Stage | Each job gets divided into smaller sets of tasks called stages that depend on each other (similar to the map and reduce stages in MapReduce); you'll see this term used in the driver's logs.|

![Apache Spark Architecture](./docs/images/spark/spark_architecture.png)

**1. Spark Driver**
* Separate process to execute user applications
* Creates SparkContext to schedule jobs execution and negotiate with cluster manager

**2. Executors**
* Run tasks scheduled by driver
* Store computation results in memory, on disk or off-heap
* Interact with storage systems

**3. Cluster Manager**
* Mesos
* YARN
* Spark Standalone

**4. SparkContext**
* Represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster

**5. DAGScheduler**
* Computes a DAG of stages for each job and submits them to TaskScheduler
* Determines preferred locations for tasks (based on cache status or shuffle files locations) and finds minimum schedule to run the jobs

**6. TaskScheduler**
* Responsible for sending tasks to the cluster, running them, retrying if there are failures, and mitigating stragglers

**7. SchedulerBackend**
* Backend interface for scheduling systems that allows plugging in different implementations(Mesos, YARN, Standalone, local)

**8. BlockManager**
* Provides interfaces for putting and retrieving blocks both locally and remotely into various stores (memory, disk, and off-heap)

![Apache Spark Job Flow](./docs/images/spark/spark_job_flow.png)

### 4.4. Resilient Distributed Dataset (RDD)
RDDs are the building blocks of any Spark application. RDDs Stands for:
* Resilient: Fault tolerant and is capable of rebuilding data on failure
* Distributed: Distributed data among the multiple nodes in a cluster
* Dataset: Collection of partitioned data with values, e.g. tuples or other objects

![RDD Features](./docs/images/spark/rdd_features.png)

**1. In-memory Computation**
* RDDs stores intermediate data/results in RAM instead of disk.

**2. Lazy Evaluations**
* All transformations are lazy, right away it will not compute the results. 
* Apache Spark computes transformations when an action requires a result for the driver program.

**3. Immutability**
* Once RDD created it cannot be changed because of read only abstraction.
* RDD can be transformed one form to another RDD using transformations like map, filter, join and co-group.
* Immutable nature of RDD Spark helps to maintain level of high consistency.

**4. Partitioned**
* Partitions are basic units of parallelism in Apache Spark
* RDDs are collection of partitions.
* Each partition is one logical division of data which is mutable in nature. One can create a partition through some transformations on existing partitions.
* Partitions of an RDD are distributed across all the nodes in a network.

**5. Parallel**

**6. Persistence**
* In RDD persistence nature does fast computations.
* Here users have the option of selecting RDD for reuse and they can also select storage either disk or in-memory to store data.

**7. Fault Tolerance**
* Spark RRD has the capability to operate and recover loss after a failure occurs.
* It rebuild lost data on failure using lineage, each RDD remembers how it was created from other datasets to recreate itself.

### 4.5. RDD Workflow
![RDD Workflow](./docs/images/spark/rdd_workflow.png)

There are two ways to create RDDs − parallelizing an existing collection in your driver program, or by referencing a dataset in an external storage system, such as a shared file system, HDFS, HBase, etc.

### 4.6. RDD Operations
RDDs support two types of operations: 
* Transformations: are the functions that take an RDD as an input and produce one or more RDDs as an output.
* Actions: which returns final result to the driver program after running RDD computations on the dataset. 

**E.g:**
* map is a transformation that passes each dataset element through a function and returns a new RDD representing the results. 
* reduce is an action that aggregates all the elements of the RDD using some function and returns the final result to the driver program (although there is also a parallel reduceByKey that returns a distributed dataset).

**1. Transformations**
* Apply user function to every element in a partition (or to the whole partition).
* Apply aggregation function to the whole dataset (groupBy, sortBy).
* Introduce dependencies between RDDs to form DAG.
* Provide functionality for repartitioning (repartition, partitionBy).

**2. Actions**
* Trigger job execution.
* Used to materialize computation results.

### 4.7. Directed Acyclic Graph (DAG)
**Direct**: Means which is directly connected from one node to another. This creates a sequence i.e. each node is in linkage from earlier to later in the appropriate sequence.

**Acyclic**: Defines that there is no cycle or loop available. Once a transformation takes place it cannot returns to its earlier position.

**Graph**: From graph theory, it is a combination of vertices and edges. Those pattern of connections together in a sequence is the graph.

**Directed Acyclic Graph** is an arrangement of edges and vertices. In this graph, vertices indicate RDDs and edges refer to the operations applied on the RDD. According to its name, it flows in one direction from earlier to later in the sequence. When we call an action, the created DAG is submitted to DAG Scheduler. That further divides the graph into the stages of the jobs.

* The DAG scheduler divides operators into stages of tasks. A stage is comprised of tasks based on partitions of the input data. The DAG scheduler pipelines operators together. For e.g. Many map operators can be scheduled in a single stage. The final result of a DAG scheduler is a set of stages.
* The Stages are passed on to the Task Scheduler.The task scheduler launches tasks via cluster manager (Spark Standalone/Yarn/Mesos). The task scheduler doesn't know about dependencies of the stages.
* The Worker executes the tasks on the Slave.

### 4.8. Internal Job Execution In Spark
![Job Execution](./docs/images/spark/job_execution.png)

**STEP 1**: The client submits spark user application code. When an application code is submitted, the driver implicitly converts user code that contains transformations and actions into a logically directed acyclic graph called DAG. At this stage, it also performs optimizations such as pipelining transformations.

**STEP 2**: After that, it converts the logical graph called DAG into physical execution plan with many stages. After converting into a physical execution plan, it creates physical execution units called tasks under each stage. Then the tasks are bundled and sent to the cluster.

**STEP 3**: Now the driver talks to the cluster manager and negotiates the resources. Cluster manager launches executors in worker nodes on behalf of the driver. At this point, the driver will send the tasks to the executors based on data placement. When executors start, they register themselves with drivers. So, the driver will have a complete view of executors that are executing the task.

**STEP 4**: During the course of execution of tasks, driver program will monitor the set of executors that runs. Driver node also schedules future tasks based on data placement. 

**Example**
```java
val input = sc.textFile(""log.txt"")
val splitedLines = input.map(line => line.split("" ""))
                                    .map(words => (words(0), 1))
                                    .reduceByKey{(a,b) => a + b}

```

![Job Execution](./docs/images/spark/job_execution_example.png)

## 5. Data Processing Technologies Comparison

| | Apache Hadoop | Apache Spark | Apache Flink |
|-|-|-|-|
| Year of Origin| 2005| 2009| 2009|
| Place of Origin| MapReduce (Google) Hadoop (Yahoo)| University of California, Berkeley| Technical University of Berlin|
| Data Processing Engine| Batch| Micro-Batch| Stream|
| Processing Speed| Slower than Spark and Flink| 100x Faster than Hadoop| Faster than spark|
| Data Transfer| Batch| Micro-Batch| Pipelined and Batch|
| Programming Languages| Java, C, C++, Ruby, Groovy, Perl, Python| Java, Scala, Python and R| Java and Scala|
| Programming Model| MapReduce| Resilient Distributed Datasets (RDD)| Cyclic Dataflows|
| Memory Management| Disk Based| JVM Managed| Automatic Memory Management. It has its own memory management system, separate from Java’s garbage collector|
| Latency| Low| Medium| Low|
| Throughput| Medium| High| High|
| Optimization| Manual. Jobs has to be manually optimize| Manual. Jobs has to be manually optimize| Automatic. Flink jobs are automatically optimized. Flink comes with an optimizer that is independent with actual programming interface|
| Duplicate Elimination| NA| Spark process every records exactly once hence eliminates duplication| Flink process every records exactly once hence eliminates duplication|
| Windows Criteria| NA| Spark has time-based Window criteria| Flink has record-based, time-baed or any custom user-defined Window criteria|
| API| Low-level| High-level| High-level|
| Streaming Support| NA| Spark Streaming| Flink Streaming|
| SQL Support| Hive, Impala| SparkSQL| Table API and SQL|
| Graph Support| NA| GraphX| Gelly|
| Machine Learning Support| NA| SparkML| FlinkML|

## 6. References

https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/index.html

https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/windows.html

https://ci.apache.org/projects/flink/flink-docs-stable/dev/batch

https://ci.apache.org/projects/flink/flink-docs-stable/dev/batch/dataset_transformations.html

https://cwiki.apache.org/confluence/display/FLINK/Data+exchange+between+tasks

https://www.infoq.com/articles/machine-learning-techniques-predictive-maintenance

https://www.edureka.co/blog/spark-architecture

https://data-flair.training/blogs/spark-tutorial

https://data-flair.training/blogs/spark-in-memory-computing

https://medium.com/stream-processing/what-is-stream-processing-1eadfca11b97"
teslacoil/Example_NovaTheme,master,83,21,2013-08-01T04:23:24Z,2522,1,Documented example theme for Nova Launcher,,"Example Nova Launcher Theme
===========================

Nova Launcher is the highly customizable launcher for Android. Part of this customization comes from developers such as yourself.

This document covers the theme format for Nova Launcher.

Most launchers, including Nova Launcher, support a superset of the theme format from Go Launcher.

However this document and project is specific to Nova Launcher. This document will try to note things which are not supported by other launchers.

This project is a sample theme for Nova Launcher that can covers:

* AndroidManifest
* Automatic App Icon Theming
* Manual App Icon Theming
* Dock Background Theming
* Wallpapers


AndroidManifest
---------------

Nova Launcher identifies themes by searching for activities that can respond to the `com.novalauncher.THEME` intent.

This is done by adding the following below an <activity> tag in your `AndroidManifest.xml`

    <intent-filter>
        <action android:name=""com.novalauncher.THEME"" />
    </intent-filter>

Automatic App Icon Theming
--------------------------

Applying an icon theme (Nova Settings > Look and Feel > Icon Theme) will replace app icons with the icons specified in the theme.
Optionally, new app icons can be automatically generated using a background, foreground, scale and mask.

Configuration for this is done in the theme's `res/xml/appfilter.xml` .

### Replacement Icons as drawables
Replacing a specific app icon with a custom drawable included in your theme is done via:

    <item component=""ComponentInfo{com.android.chrome/com.google.android.apps.chrome.Main}"" drawable=""ic_browser_green"" />

With system apps, different devices or roms may use different component names for various components. For example The dialer app on Nexus devices is `com.android.contacts/.activities.DialtactsActivity` but on HTC devices it is `com.android.htccontacts/.DialerTabActivity`. Nova includes an internal databases of these for most devices, allowing the theme to apply an icon to the system's phone app by specifying a single keyword rather than each individual activity for every device.

**Note** Only non-Play Store system apps are included in this, third-party apps,
or Play Store apps such as Chrome, will not be included and must be themed manually.

The keywords supported are:

* `:BROWSER`
* `:CALCULATOR`
* `:CALENDAR`
* `:CAMERA`
* `:CLOCK`
* `:CONTACTS`
* `:EMAIL`
* `:GALLERY`
* `:PHONE`
* `:SMS`

Additionally Nova's app drawer icon can be themed with `:LAUNCHER_ACTION_APP_DRAWER` and `:LAUNCHER_ACTION_APP_DRAWER_NIGHT`. The night version is used when in night mode and the user has Night mode > Drawer icon enabled in Nova Settings.

A full example is:

    <item component="":SMS"" drawable=""ic_sms_green"" />

**Note** Other launchers do not support these system app keywords and will ignore them.

### Identifying activity ComponentNames

Nova Launcher includes an option to export a full set of activity names and their original icons. This can serve as a starting point for your theme. You can find this at `Nova Settings > Long-press Volume down for Labs > Debug > Export Icons`

A zip will be created at `/sdcard/novaIconExport.zip` which contains a complete `res/xml/appfilter.xml` file as well as the original icons at the highest density they are available (in the appropriate drawable directory).

Nova also has an option to help find individual component names. Enable Nova Settings > Long-press volume down for Labs > Debug > Show Component in Edit dialog. Then either drag an app from the drawer to the Edit option, or long-press on a desktop icon and select Edit. The component name will be listed at the bottom of the dialog.

### Generating Replacement Icons

For apps that do not have a drawable replacement one can be generated by specifying parameters in the `appfilter.xml`

The four parameters are:

#### iconback

 <iconback img1=""ic_back1"" img2=""ic_back2"" img3=""ic_back3"" />

The background to be drawn behind the original icon. If multiple images are specified (as above `img1`, `img2` and `img3`) then one will be chosen randomly.

#### iconupon

 <iconupon img1=""ic_foreground1"" img2=""ic_foreground2"" />

The foreground to be drawn on top of the original icon. If multiple images are specified then one will be chosen randomly.

#### iconmask

 <iconmask img1=""ic_mask1"" />

A mask to apply to the original icon, allowing reshaping it. Black opaque pixels in the mask will be erased while transparent pixels be unchanged.
If multiple images are specified then one will be chosen randomly.

#### scale

 <scale factor="".75"" />

The scale the original icon should be drawn at.



Manual Icon Theming
-------------------

Nova Launcher allows users to manually select a replacement icon, for an app, shortcut, or folder. To allow users to select one of your icons for this specify them in the `res/xml/drawable.xml`. Each icon is as follows

    <item drawable=""ic_jellybean"" />

The order you list the icons in will be the order that they appear in the icon picker.

You may optionally break the icons into categories by adding dividers:

    <category title=""Games"" />

Nova Launcher supports resource identifiers, for example for localization or compile-time error checking:

    <item drawable=""@drawable/ic_jellybean"" />
    <category title=""@string/games"" />

Other launchers do not support category dividers or resource identifiers


Dock Backgrounds
----------------

Nova Launcher allows the user to build a custom dock background based on an image picked from a theme.
There is no fixed size for a dock background as Nova Launcher supports devices of many different screen sizes and aspect ratios. Additionally, there are different orientations on the same device. Instead of trying to stretched an image to fit patterns are used to fill the appropriate amount of space on any configuration.

Patterns are specified in `res/xml/theme_patterns.xml` and point to a drawable that is designed to be repeated.
These patterns can either be full color, or grayscale and allow the user to specify a color by setting `canColor=""true""`.
Otherwise the format is identical to `res/xml/drawables.xml`

    <item drawable=""@drawable/pattern_checkerboard"" canColor=""true"" />
    <item drawable=""@drawable/pattern_colors"" canColor=""false"" />

**Note** Other launchers do not support patterns for dock backgrounds and instead stretch and distort images for the dock background. It is a poor user experience, especially on tablets, but Nova Launcher is backwards compatible with this backwards approach. Legacy dock backgrounds can be specified in an `string-array` named `dock_backgroundlist` , which is also used by other launchers.

Wallpapers
----------

To add your wallpapers to Nova Launcher's wallpaper picker specify them in `res/xml/theme_wallpapers.xml` . The format is identical to `res/xml/drawables.xml` .

    <item drawable=""@drawable/wallpaper_red"" />
"
Nukkit/ExamplePlugin,master,28,33,2015-09-20T03:37:45Z,137,3,"Example Nukkit plugin, showing the API",,"# ExamplePlugin
Example Nukkit plugin, showing the API
"
gtiwari333/spring-boot-web-application-sample,master,254,111,2019-05-12T17:31:07Z,1861,1,Real World Spring Boot Web Application Example with tons of ready to use features,archunit gatling java java-web jms keycloak mapstruct seed-project selenide selenium skeleton-application spock spring spring-boot spring-mvc spring-security thymeleaf webjars,"### A Spring Boot Web Application Sample with tons of ready-to-use features. This can be used as starter for bigger projects.

#### Variations
- Simpler version without KeyCloak and multi-modules is on separate project https://github.com/gtiwari333/spring-boot-blog-app
- Microservice example that uses Spring Cloud features(discovery, gateway, config server etc) is on separate project https://github.com/gtiwari333/spring-boot-microservice-example-java


### App Architecture:
[![Foo](https://lucid.app/publicSegments/view/8c2fa859-36bd-4559-80c7-12fb30997092/image.png)](https://lucid.app/documents/view/fa076c6e-86d3-412b-a9bc-1996dca86a1e)
#### Included Features/Samples

MicroService:

[//]: # (- Spring micrometer based tracing with zipkin)
- Exposing and implementing Open Feign clients
- Spring Cloud Contract (WIP)

Spring MVC:
- Public and internal pages
- MVC with thymeleaf templating
- Live update of thymeleaf templates for local development
- HTML fragments, reusable pagination component using Thymeleaf parameterized fragments
- webjar - bootstrap4 + jquery
- Custom Error page
- Request logger filter
- Swagger API Docs with UI  ( http://localhost:8081/swagger-ui.html)
- @RestControllerAdvice, @ControllerAdvice demo
- CRUD UI + File upload/download
- favicon handler

Security:
- Account management with KeyCloak
- Spring Security 
- User/User_Authority entity and repository/services
    - login, logout, home pages based on user role
- Domain object Access security check on update/delete using custom PermissionEvaluator
- private pages based on user roles
- public home page -- view all notes by all 
- Limit max number of record in a paged request

Persistence/Search:
- Data JPA with User/Authority/Note/ReceivedFile entities, example of EntityGraph
- MySQL or any other SQL db can be configured for prod/docker etc profiles
- (in old code) H2 db for local, Console enabled for local ( http://localhost:8081/h2-console/, db url: jdbc:h2:mem:testdb, username: sa)
- jOOQ integration with code generation based on JPA entity 
- Liquibase database migration

Test:
- Unit/integration with JUnit 5, Mockito and Spring Test
- Tests with Spock Framework (Groovy 4, Spock 2)
- e2e with Selenide, fixtures. default data generated using Spring
- Load test with Gatling/Scala
- Architecture tests using ArchUnit
- file upload/download e2e test with Selenide
- TestContainers to perform realistic integration test
- Reset DB and Cache between test
- Assert expected query count during integration test

Misc:
- Code Generation: lombok,  mapstruct 
- Message Queue using ActiveMQ Artemis
- Approval/flagging api - message based
- Nested comment
- Cache implemented
- Zipkin tracing 
- Websocket implemented to show article/comment review status/notifications..

Future: do more stuff
- CQRS with event store/streaming  
- Spring Cloud Contract integration (WIP)
- Docker-compose deploy/kubernetes 
- Visitors log - IP, browser, etc
- Centralized error reporting
- Geo-Spatial query for visitors
- Grafana Dashboard, @Timed and more ...
- logback LevelChangePropagator integration
- logback error email
- logback rolling policy
- Integrate Markdown editor for writing notes
- rate limit by IP on public API ( article api )
- Fetch user's avatar
- UI improvement
- S3 file upload, test with localstack TestContainers
- nested comment query/performance fix 
- Signup UI
- vendor neutral security with OIDC
- JfrUnit ( WIP )
- 
### Requirements
- JDK 17+
- Lombok configured on IDE
    - http://ganeshtiwaridotcomdotnp.blogspot.com/2016/03/configuring-lombok-on-intellij.html
    - For eclipse, download the lombok jar, run it, and point to eclipse installation
- Maven
- Docker 
  - Make sure docker is started and running
  - Run `$ sudo chmod 666 /var/run/docker.sock` if you get error like this ""Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? (Details: [13] Permission denied)""

#### How to Run

It contains following applications:

- main-app
- email-service (optional)
- report-service (optional)
- trend-service (optional)
- content-checker (optional)

# Note you will need to create a database named 'seedapp' in your mysql server

Option 1 - run with manually started  KeyCloak, ActiveMQ and MySQL  servers
- Run ```mvn clean install``` at root 
- Run ```docker-compose -f config/docker-compose.yml up``` at root to start docker containers
- Go to main-app folder and run ```mvn``` to start the application

Option 2 - automatically start KeyCloak, ActiveMQ and MySQL using TestContainer while application is starting
- Run ```mvn clean install``` at root 
- Go to main-app folder and run ```mvn -Pdev,withTestContainer``` to start the application

Option 3 - run from IDE
- import into your IDE and compile the full project and run the Application.java on main-app module
- Update run configuration to run maven goal `wro4j:run` Before Launch. It should be after 'Build'


## Run Tests (use ./mvnw instead of mvn if you want to use maven wrapper)

## It uses TestContainers, which requires Docker to be installed locally.

##### Running full tests

`mvn clean verify`

##### Running unit tests only (it uses maven surefire plugin)

`mvn  compiler:testCompile resources:testResources  surefire:test`

##### Running integration tests only (it uses maven-failsafe-plugin)

`mvn  compiler:testCompile resources:testResources  failsafe:integration-test`

## Code Quality

##### The `error-prone` runs at compile time.

##### The `modernizer` `checkstyle` and `spotbugs` plugin are run as part of maven `test-compile` lifecycle phase. use `mvn spotbugs:gui' to

##### SonarQube scan

Run sonarqube server using docker
`docker run -e SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true -p 9000:9000 sonarqube:latest`

Perform scan:
`mvn sonar:sonar`
mvn sonar:sonar -Dsonar.login=admin -Dsonar.password=admin

View Reports in SonarQube web ui:

- visit http://localhost:9000
- default login and password are `admin`, you will be asked to change password after logging in with default
  username/password
- (optional) change sonarqube admin password without logging
  in: `curl -u admin:admin -X POST ""http://localhost:9000/api/users/change_password?login=admin&previousPassword=admin&password=NEW_PASSWORD""`
- if you change the password, make sure the update `-Dsonar.password=admin` when you run sonarqube next time

### Dependency vulnerability scan

Owasp dependency check plugin is configured. Run `mvn dependency-check:check` to run scan and
open `dependency-check-report.html` from target to see the report.


## Run Tests Faster by using parallel maven build
`mvn -T 5 clean package`


Once the application starts, open  `http://localhost:8081` on your browser. The default username/passwords are listed on : gt.app.Application.initData, which are:

- system/pass
- user1/pass
- user2/pass


#### Screenshots:

#### Public View
![](screenshots/public-page.png)

#### Read Article with nested comment/discussion
![](screenshots/read-article-with-nested-comment.png)

#### Logged in Feed View
![](screenshots/logged-in-home-page.png)

#### Logged in User's Article List View
![](screenshots/users-home-page.png)

#### Admin User's Review Page to approve/disapprove flagged posts
![](screenshots/admin-user-review-page.png)

#### Review Page
![](screenshots/review-flagged-content.png)

#### New Article
![](screenshots/new-article-page.png)


#### Dependency/plugin version checker
 - `mvn versions:display-dependency-updates`
 - `mvn versions:display-plugin-updates`
"
Microservice-API-Patterns/LakesideMutual,master,165,103,2018-11-29T15:30:34Z,4099,1,"Example Application for Microservice API Patterns (MAP) and other patterns (DDD, PoEAA, EIP)",,"# ![Lakeside Mutual Logo](./resources/logo-32x32.png) Lakeside Mutual

Lakeside Mutual is a fictitious insurance company which serves as a sample application to demonstrate microservices and domain-driven design. The company provides several digital services to its customers and its employees. [Microservice API Patterns (MAP)](https://microservice-api-patterns.org/) are applied in the application backends (see [MAP.md](./MAP.md)).

## Architecture Overview
The following diagram shows an overview of the core components that are the building blocks for the services Lakeside Mutual provides to its customers and its employees:

![Lakeside Mutual](./resources/overview-diagram.png)

The following sections contain a short description of each service:

- **[Customer Core](customer-core)**  
  The Customer Core backend is a [Spring Boot](https://projects.spring.io/spring-boot/) application that manages the personal data about
  individual customers. It provides this data to the other backend services through an HTTP resource API.

- **[Customer Self-Service Backend](customer-self-service-backend)**  
  The Customer Self-Service backend is a [Spring Boot](https://projects.spring.io/spring-boot/) application that
  provides an HTTP resource API for the Customer Self-Service frontend. 

- **[Customer Self-Service Frontend](customer-self-service-frontend)**  
  The Customer Self-Service frontend is a [React](https://reactjs.org/) application that allows users to register themselves, view their current insurance policy and change their address.
  
- **[Customer Management Backend](customer-management-backend)**  
  The Customer Management backend is a [Spring Boot](https://projects.spring.io/spring-boot/) application that
  provides an HTTP resource API for the Customer Management frontend and the Customer Self-Service frontend. In addition, [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) are used to implement the chat feature to deliver chat messages in realtime between the callcenter agent using the Customer Management frontend and the Customer logged into the Self-Service frontend.

- **[Customer Management Frontend](customer-management-frontend)**  
  The Customer Management frontend is a [React](https://reactjs.org/) application that allows Customer-Service operators to interact with customers and help them resolve issues related to Lakeside Mutual's insurance products.

- **[Policy Management Backend](policy-management-backend)**  
  The Policy Management backend is a [Spring Boot](https://projects.spring.io/spring-boot/) application that provides an HTTP resource API for the Customer Self-Service frontend and the Policy Management frontend. It also sends a message (via [ActiveMQ](http://activemq.apache.org/) messaging) to the Risk Management Server whenever an insurance policy is created / updated.

- **[Policy Management Frontend](policy-management-frontend)**  
  The Policy Management frontend is a [Vue.js](https://vuejs.org/) application that allows Lakeside Mutual employees to view and manage the insurance policies of individual customers.

- **[Risk Management Server](risk-management-server)**  
  The Risk-Management server is a [Node.js](https://nodejs.org) application that gathers data about customers / policies and can generate a customer data report on demand.

- **[Risk Management Client](risk-management-client)**  
  The Risk-Management client is a command-line tool built with [Node.js](https://nodejs.org). It allows the
  professionals of Lakeside Mutual to periodically download a customer data report which helps them during risk assessment.

- **[Eureka Server](eureka-server)**  
  [Eureka Server](https://spring.io/guides/gs/service-registration-and-discovery/#initial) provides a service registry. It is a regular Spring Boot application to which all other Spring services can connect to access other services. For example, the Customer Self-Service Backend uses Eureka to connect to the Customer Core. Usage of Eureka is optional.

- **[Spring Boot Admin](spring-boot-admin)**  
  [Spring Boot Admin](https://github.com/codecentric/spring-boot-admin) is an open source software for managing and monitoring Spring Boot applications. It *is* a Spring Boot application too. Usage within the Lakeside Mutual services is optional and only included for convenience with all security disabled.
  
The backends use Domain-Driven Design (DDD) to structure their domain (business) logic and their service-internal logical layers. To do so, they use marker interfaces defined in this [Domain-Driven Design Library](https://github.com/Microservice-API-Patterns/DDD-Library).

To learn more about individual components, please have a look at the README file in the corresponding subfolder.

## Getting started 

Detailed setup instructions can be found in each application's README file. To conveniently start all applications, the `run_all_applications` scripts can be used. Alternatively, to start a minimal subset of applications, i.e., the Customer Management Applications and the Customer Core, use the `run_customer_management_applications` script.


1. Make sure you have [Java 8 or higher](https://adoptium.net/) installed.
1. Install [Node](https://nodejs.org/en/). Version 12 or later is required. You can check the currently installed version by running `node --version`.
1. Install Python. We don't use Python ourselves, but some Node.js packages require native addons that are built using node-gyp, which requires Python. See the [node-gyp README for details on which Python version to install](https://github.com/nodejs/node-gyp#on-unix).
1. Install Maven (see [https://maven.apache.org](https://maven.apache.org) for installation instructions).
1. Run the `run_all_applications` script suitable for your platform. Note that the frontend applications might be running before the backends are ready. In that case, just reload the page in the browser.

If the script exits, one of the applications could not be started. For troubleshooting, we recommend to start the applications individually. Note that you don't need to start all applications. The overview diagram above can be used to figure out the dependencies of each service. 

The following table lists all the ports that have to be free for each component to work correctly. If you need to change any of these ports, please
consult the README of the corresponding component:

| Component  | Ports |
| ---------- | ----- |
| [Customer Self-Service Backend](customer-self-service-backend) | 8080 (HTTP resource API) |
| [Policy Management Backend](policy-management-backend) | 8090 (HTTP resource API)<br/>61613 (ActiveMQ broker)<br/>61616 (ActiveMQ broker) |
| [Customer Management Backend](customer-management-backend) | 8100 (HTTP resource API) |
| [Customer Core](customer-core) | 8110 (HTTP resource API) |
| [Customer Self-Service Frontend](customer-self-service-frontend) | 3000 (Web server) |
| [Policy Management Frontend](policy-management-frontend) | 3010 (Web server) |
| [Customer Management Frontend](customer-management-frontend) | 3020 (Web server) |
| [Risk Management Server](risk-management-server) | 50051 (gRPC server) |
| [Risk Management Client](risk-management-client) | - (CLI Client) |
| [Eureka Server](eureka-server) | 8761 (Admin web frontend) |
| [Spring Boot Admin](spring-boot-admin) | 9000 (Web server) |

## Docker

All projects come with Dockerfiles that can be used to run the services as Docker containers. The [docker-compose.yml](./docker-compose.yml) builds and starts all applications in a single command. See the [docker-compose.yml](./docker-compose.yml) for more information. Note that building the images takes some time (without caches, our most recent build took 6 minutes on a development machine).

## Data Stores

Each backend service has its own data store. The Spring-JPA based applications all use the H2 relational database. By default, all data will be lost during restarts, please see the individual README files to enable durable persistency. The backend services also contain the H2 Console to browse the database. It can be found at `/console`. For example, for the Customer Core, the address is [http://localhost:8110/console](http://localhost:8110/console).

## Frequently Asked Questions and Troubleshooting

See our [FAQ](./FAQ.md) for more information on running the applications and the [IDE instructions](./IDE_INSTRUCTIONS.md) page to get started with IntelliJ IDEA, Eclipse and Visual Studio Code.

## License

This project is made available under the Eclipse Public License v 2.0. See the [LICENSE](LICENSE.md) file for the full license.
"
JavaZakariae/Spring5Certification,master,54,29,2019-07-03T21:12:25Z,2975,7,Spring Certification: This repository contains my examples and some best references to prepare the Spring 5 certification,aop certification ioc-framework pluralsight-courses spring spring-boot spring-data spring-data-jpa spring-jdbc spring-mvc spring-security springboot springframework springmvc,"![stars](https://img.shields.io/github/stars/javazakariae/spring5certification?style=social)
![last commit date](https://img.shields.io/github/last-commit/javazakariae/spring5certification)

# Preparation for the Spring 5 Certification 

- [Preparation for the Spring 5 Certification](#preparation-for-the-spring-5-certification)
  - [Introduction](#introduction)
  - [The best resources to follow](#the-best-resources-to-follow)
  - [Books](#books)
  - [Youtube channel](#youtube-channel)
  - [Pluralsight courses(paid but worth it)](#pluralsight-coursespaid-but-worth-it)
      - [AOP](#aop)
      - [Spring JDBC](#spring-jdbc)
      - [Spring data jpa](#spring-data-jpa)
      - [Spring Boot](#spring-boot)
  - [Stackoverflow questions](#stackoverflow-questions)
  - [Other resources](#other-resources)
  - [Personal opinion](#personal-opinion)

## Introduction

This repository contains my code examples for the preparation of the certification. I have passed the certification on the 20th july of 2019, I have been certified with a score of 88%. This repository contains some good references to master the fundamentals of the framework, so It's not only for a certification purpose.

The certification questions are based on the official [study-guide](https://d1fto35gcfffzn.cloudfront.net/academy/Spring-Professional-Certification-Study-Guide.pdf), so I recommend to focus on those questions. In my opinion, if you can easily awnsers those questions, you will pass the certification.


To prepare my certification, I read few books, a lot of articles, I watched many Pluralsight courses and some Youtube videos on specific subjects.

To help you prepare the certification, I recommend to learn from the following resources, some are not free, but they are worth.



## The best resources to follow
[Core Spring 5 Certification in Detail](https://leanpub.com/corespring5certificationindetail) by [Ivan Krizsan
](https://leanpub.com/u/ivan-krizsan)
This book should be a must for everyone willing to pass the certification, it should be checked only as a last step before passing the certification, so for the newcomers to the framework I don't recommend to begin with, because it is just a summary and it contains some responses that could be helpful to pass the certification.    

[ivankrizsan's blog](https://www.ivankrizsan.se/)


## Books

[Spring in Action: Covers Spring 4](https://www.amazon.com/Spring-Action-Covers-4/dp/161729120X/ref=sr_1_2?keywords=spring+in+action&qid=1570962746&sr=8-2):

I don't recommend the fifth edition, the 4th edition is a good start for everyone willing to understand the fundamentals of the Framework, like Dependency Injection, Aspect Oriented Programming.... It is not mandatory to read every chapter. It is the first resource i have checked, I didn't read the full book, but only few chapters, let's say 50% of the book.
 

[Spring 5 Design Patterns](https://www.amazon.com/Spring-Design-Patterns-application-development/dp/1788299450/ref=sr_1_1?crid=ZRVPY8S85GBD&keywords=spring+design+patterns&qid=1570962674&sprefix=spring+design+pa%2Caps%2C216&sr=8-1) :

A really good book that helped me to dig deeper into the framework. It will help you to understand how the Spring Framework is using some design patterns internally.


[Spring Boot in Action](https://www.amazon.com/Spring-Boot-Action-Craig-Walls/dp/1617292540/ref=sr_1_2?qid=1570963413&refinements=p_27%3ACraig+Walls&s=books&sr=1-2&text=Craig+Walls):

For a deeper understanding of the Spring boot module. The book is not big but it gives more details about the spring boot modules. Apart from that, I have watched many youtube videos to get much understanding of the spring boot modules, I recommend to check some talks given by [Stéphane Nicoll](https://www.youtube.com/results?search_query=spring+boot+stephane+nicol) about spring boot.
 
## Youtube channel

[Laurentiu Spilca](https://www.youtube.com/channel/UC0z3MpVGrpSZzClXrYcZBfw):

 Laurentiu Spilca made a playlist on Spring Fundamentals, you will find very good content on DI, AOP, Transaction, Data, Rest, Actuator and many more, recently he made a playlist about spring security...

## Pluralsight courses(paid but worth it)

#### AOP
[Aspect Oriented Programming](https://app.pluralsight.com/library/courses/aspect-oriented-programming-spring-aspectj/table-of-contents)

#### Spring JDBC
[Building Applications Using Spring JDBC
](https://app.pluralsight.com/library/courses/building-applications-spring-jdbc/table-of-contents)

#### Spring data jpa
[Getting Started with Spring Data JPA](https://app.pluralsight.com/library/courses/spring-data-jpa-getting-started/table-of-contents)


#### Spring Boot
[Creating Your First Spring Boot Application](https://app.pluralsight.com/library/courses/spring-boot-first-application/table-of-contents)

[Spring Boot: Efficient Development, Configuration, and Deployment](https://app.pluralsight.com/library/courses/spring-boot-efficient-development-configuration-deployment/table-of-contents)



## Stackoverflow questions
Here are some responses to some very important questions:
- [java - @RequestBody and @ResponseBody annotations in Spring - Stack Overflow](https://stackoverflow.com/questions/11291933/requestbody-and-responsebody-annotations-in-spring).
- [java - ApplicationContext and ServletContext - Stack Overflow](https://stackoverflow.com/questions/31931848/applicationcontext-and-servletcontext).
- [Differences between Abstract Factory Pattern and Factory Method - Stack Overflow](https://stackoverflow.com/questions/5739611/differences-between-abstract-factory-pattern-and-factory-method).
- [java - BeanFactoryPostProcessor and BeanPostProcessor in lifecycle events - Stack Overflow](https://stackoverflow.com/questions/30455536/beanfactorypostprocessor-and-beanpostprocessor-in-lifecycle-events).
- [java - Difference between &lt;context:annotation-config&gt; vs &lt;context:component-scan&gt; - Stack Overflow](https://stackoverflow.com/questions/7414794/difference-between-contextannotation-config-vs-contextcomponent-scan).
- [java - Difference between applicationContext.xml and spring-servlet.xml in Spring Framework - Stack Overflow](https://stackoverflow.com/questions/3652090/difference-between-applicationcontext-xml-and-spring-servlet-xml-in-spring-frame).
- [java - Difference between Interceptor and Filter in Spring MVC - Stack Overflow](https://stackoverflow.com/questions/35856454/difference-between-interceptor-and-filter-in-spring-mvc/35856496).
- [java - Hibernate SessionFactory vs. EntityManagerFactory - Stack Overflow](https://stackoverflow.com/questions/5640778/hibernate-sessionfactory-vs-entitymanagerfactory).
- [java - How do I update an entity using spring-data-jpa? - Stack Overflow](https://stackoverflow.com/questions/11881479/how-do-i-update-an-entity-using-spring-data-jpa).
- [java - How do servlets work? Instantiation, sessions, shared variables and multithreading - Stack Overflow](https://stackoverflow.com/questions/3106452/how-do-servlets-work-instantiation-sessions-shared-variables-and-multithreadi).
- [java - How to accept Date params in a GET request to Spring MVC Controller? - Stack Overflow](https://stackoverflow.com/questions/15164864/how-to-accept-date-params-in-a-get-request-to-spring-mvc-controller).
- [java - How to access a value defined in the application.properties file in Spring Boot - Stack Overflow](https://stackoverflow.com/questions/30528255/how-to-access-a-value-defined-in-the-application-properties-file-in-spring-boot).
- [java - PUT request in Spring MVC - Stack Overflow](https://stackoverflow.com/questions/35878351/put-request-in-spring-mvc).
- [java - Spring MVC: How to perform validation? - Stack Overflow](https://stackoverflow.com/questions/12146298/spring-mvc-how-to-perform-validation).
- [java - What are the possible values of the #Hibernate hbm2ddl.auto configuration and what do they do - Stack Overflow](https://stackoverflow.com/questions/438146/what-are-the-possible-values-of-the-hibernate-hbm2ddl-auto-configuration-and-wh).
- [java - What is @ModelAttribute in Spring MVC? - Stack Overflow](https://stackoverflow.com/questions/3423262/what-is-modelattribute-in-spring-mvc).
- [java - What is a NoSuchBeanDefinitionException and how do I fix it? - Stack Overflow](https://stackoverflow.com/questions/39173982/what-is-a-nosuchbeandefinitionexception-and-how-do-i-fix-it).
- [java - What's the difference between ResponseEntity and HttpEntity in Spring_ - Stack Overflow](https://stackoverflow.com/questions/42829823/whats-the-difference-between-responseentity-and-httpentity-in-spring).
- [Spring JdbcTemplate execute vs update - Stack Overflow](https://stackoverflow.com/questions/39454507/spring-jdbctemplate-execute-vs-update).
- [spring - How to implement RowMapper using java lambda expression - Stack Overflow](https://stackoverflow.com/questions/41923360/how-to-implement-rowmapper-using-java-lambda-expression).
- [spring boot - Difference between using MockMvc with SpringBootTest and Using WebMvcTest - Stack Overflow](https://stackoverflow.com/questions/39865596/difference-between-using-mockmvc-with-springboottest-and-using-webmvctest).
- [What is the difference between BeanPostProcessor and init/destroy method in Spring? - Stack Overflow](https://stackoverflow.com/questions/9862127/what-is-the-difference-between-beanpostprocessor-and-init-destroy-method-in-spri).
- [Spring Boot - Loading Initial Data - Stack Overflow](https://stackoverflow.com/questions/38040572/spring-boot-loading-initial-data).
- [java - BeanPostProcessor confusion - Stack Overflow](https://stackoverflow.com/questions/9761839/beanpostprocessor-confusion?rq=1).
- [Using Spring ResponseEntity to Manipulate the HTTP Response](https://www.baeldung.com/spring-response-entity).
- [Spring MVC and the @ModelAttribute Annotation | Baeldung](https://www.baeldung.com/spring-mvc-and-the-modelattribute-annotation).
- [Spring AOP AspectJ @AfterThrowing Example](https://howtodoinjava.com/spring-aop/aspectj-afterthrowing-annotation-example).
- [Difference between getOne and findById in Spring Data JPA?](https://www.javacodemonk.com/difference-between-getone-and-findbyid-in-spring-data-jpa-3a96c3ff).
- [Difference Between BeanFactory and ApplicationContext in Spring](https://dzone.com/articles/difference-between-beanfactory-and-applicationcont).

## Other resources
[Git repository](https://github.com/vshemyako/spring-certification-5.0): This repository contains responses of the the official study-guide questions.

[Git repository](https://github.com/LinnykOleh/Spring): This second repository contains the responses of the official study-guide questions and also explanations of the theoretical notion we deal with in the Certification.

[Git repository](https://github.com/vojtechruz/spring-core-cert-notes-4.2): This third repository, even if it is about the spring 4 certification, you can find very good content and explanation about the spring ecosystem.

## Personal opinion

Sometimes even if the resources are valuable, it can be hard to understand some subjects, for my personal experience, i try to see the prerequisites of the complicated subject.
It depends also on your background on Spring and some design patterns used by the framework.

In parallel with that, I read a lot of answers from Stackoverflow, just google what you don't understand.
"
theautonomy/bouncycastle-gpg-example,master,42,35,2011-07-31T14:15:10Z,136,3,Bouncy Castle OpenGPG encryption and decryption example,,"## Introduction

This is an example of using Bouncy Castle's OpenPGP utility to encrypt 
and decrypt files.

This project is a refactory of the Bouncy Castle example which you can 
find [here](http://www.java2s.com/Open-Source/Java-Document/Security/Bouncy-Castle/org/bouncycastle/openpgp/examples/KeyBasedLargeFileProcessor.java.htm)

## Code snippet to encrypt a file without signing

        BCPGPEncryptor encryptor = new BCPGPEncryptor();
		encryptor.setArmored(false);
		encryptor.setCheckIntegrity(true);
		encryptor.setPublicKeyFilePath(""./test.gpg.pub"");
		encryptor.encryptFile(""./test.txt"", ""./test.txt.enc"");
		
## Code snippet to decrypt a file without verifying signature;

		BCPGPDecryptor decryptor = new BCPGPDecryptor(); 
		decryptor.setPrivateKeyFilePath(""test.gpg.prv"");
		decryptor.setPassword(""password"");
		decryptor.decryptFile(""test.txt.enc"", ""test.txt.dec"");
		
## Code snippet to encrypt and sign a file 
		BCPGPEncryptor encryptor = new BCPGPEncryptor();
		encryptor.setArmored(false);
		encryptor.setCheckIntegrity(true);
		encryptor.setPublicKeyFilePath(""./test.gpg.pub"");
		encryptor.setSigning(true);
		encryptor.setSigningPrivateKeyFilePath(""wahaha.gpg.prv"");
		encryptor.setSigningPrivateKeyPassword(""password"");
		encryptor.encryptFile(""./test.txt"", ""./test.txt.signed.enc"");
	
## Code snippet to decrypt a file and verify signature;
		BCPGPDecryptor decryptor = new BCPGPDecryptor(); 
		decryptor.setPrivateKeyFilePath(""test.gpg.prv"");
		decryptor.setPassword(""password"");
		decryptor.setSigned(true);
		decryptor.setSigningPublicKeyFilePath(""wahaha.gpg.pub"");
		
		// this file is encrypted with weili's public key and signed using wahaha's private key
		decryptor.decryptFile(""test.txt.signed.enc"", ""test.txt.signed.dec"");


## Try it
This project contains a test pgp public and private key which are used for test
purpose so that you can try it out right away. You can run the following mvn command
from command line: 

        >mvn exec:java -Dexec.mainClass=com.test.pgp.bc.BCPGPTest

## Note
If you get error ""java.security.InvalidKeyException: Illegal key size"", you may need to install
the unrestricted policy files for the JVM you are using. See details [here](http://www.bouncycastle.org/wiki/display/JA1/Frequently+Asked+Questions)

 "
PacktPublishing/Java-9-Programming-By-Example,master,50,43,2017-04-21T11:52:19Z,20690,4,Java 9 Programming By Example published by Packt,,"


# Java 9 Programming By Example
This is the code repository for [Java 9 Programming By Example](https://www.packtpub.com/application-development/java-9-programming-example?utm_source=github&utm_medium=repository&utm_campaign=9781786468284), published by [Packt](https://www.packtpub.com/?utm_source=github). It contains all the supporting project files necessary to work through the book from start to finish.
## About the Book
This book gets you started with essential software development easily and quickly, guiding you through Java’s different facets. By adopting this approach, you can bridge the gap between learning and doing immediately. You will learn the new features of Java 9 quickly and experience a simple and powerful approach to software development. You will be able to use the Java runtime tools, understand the Java environment, and create Java programs.

We then cover more simple examples to build your foundation before diving to some complex data structure problems that will solidify your Java 9 skills. With a special focus on modularity and HTTP 2.0, this book will guide you to get employed as a top notch Java developer.

By the end of the book, you will have a firm foundation to continue your journey towards becoming a professional Java developer.
## Instructions and Navigation
All of the code is organized into folders. Each folder starts with a number followed by the application name. For example, Chapter02.



The code will look like the following:
```
package packt.java9.by.example.ch03; 
 
public interface Sort { 
 void sort(SortableCollection collection); 
}
```

To immerse into the content of this book and to soak up most of the skills and knowledge, we assume that you already have some experience with programming. We do not assume too much but hope that you already know what a variable is, that computers have memory, disk, network interfaces, and what they generally are.
In addition to these basic skills, there are some technical requirements to try out the code and the examples of the book. You need a computer—something that is available today and can run Windows, Linux, or OSX. You need an operating system and, probably, that is all you need to pay for. All other tools and services that you will need are available as open source and free of charge. Some of them are also available as commercial products with an extended feature set, but for the scope of this book, starting to learn Java 9 programming, those features are not needed. Java, a development environment, build tools, and all other software components we use are open source.

## Related Products
* [Java 9 with JShell](https://www.packtpub.com/application-development/java-9-jshell?utm_source=github&utm_medium=repository&utm_campaign=9781787282841)

* [Java Data Science Cookbook](https://www.packtpub.com/big-data-and-business-intelligence/java-data-science-cookbook?utm_source=github&utm_medium=repository&utm_campaign=9781787122536)

* [Java Hibernate Cookbook](https://www.packtpub.com/application-development/java-hibernate-cookbook?utm_source=github&utm_medium=repository&utm_campaign=9781784391904)

### Suggestions and Feedback
[Click here](https://docs.google.com/forms/d/e/1FAIpQLSe5qwunkGf6PUvzPirPDtuy1Du5Rlzew23UBp2S-P3wB-GcwQ/viewform) if you have any feedback or suggestions.
### Download a free PDF

 <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>
<p align=""center""> <a href=""https://packt.link/free-ebook/9781786468284"">https://packt.link/free-ebook/9781786468284 </a> </p>"
ttulka/ddd-example-ecommerce-microservices,main,53,19,2020-11-02T15:32:01Z,609,0,Domain-driven design microservices example,architecture ddd docker domain-driven-design event-driven example kubernetes microservices oop soa spring-boot,"
# DDD Microservices Example Project in Java: eCommerce

The purpose of this project is to provide a sample implementation of an e-commerce product following **Domain-Driven Design (DDD)** and **Service-Oriented Architecture (SOA)** principles.

Programming language is Java with heavy use of Spring Boot, Docker and Kubernetes.

## Purpose of the Project

This repository focuses mostly on cross-cutting, infrastructure and deployment concerns. 

For the domain and application concepts see the [original repository](https://github.com/ttulka/ddd-example-ecommerce).

## Monolith vs Microservices

Both monolithic and microservices deployments are implemented. 

To run the monolithic application:

```sh
./gradlew :application:bootRun
```

To set up and run microservices, see the [Docker](#docker-containers) and [Kubernetes](#kubernetes) sections.

Read more about monoliths vs microservices at https://blog.ttulka.com/good-and-bad-monolith

## Message Broker

As the message broker a simple **Redis** instance could be used with Spring profile `redis`:

```sh
docker run --rm --name redis-broker -p 6379:6379 -d redis:6 redis-server

./gradlew :application:bootRun --args='--spring.profiles.active=redis'
```

Alternatively, **RabbitMq** could be used as the message broker with Spring profile `rabbitmq`:

```sh
docker run --rm --name rabbitmq-broker -p 5672:5672 -d rabbitmq:3

./gradlew :application:bootRun --args='--spring.profiles.active=rabbitmq'
```

When neither `redis` not `rabbitmq` profiles are active, the system will fall-back to use of Spring application events as the default messaging mechanism.

### Messaging Integration

To make the code independent of a concrete messaging implementation and easy to use, Spring application events are used for the internal communication.

In practice, this means that messages are published via `EventPublisher` abstraction and consumed via Spring's `@EventListener`.

To make this work, the external messages are re-sent as Spring application events under the hood.   

## Database

The whole system uses one externalized database with particular tables owned exclusively by services.

In a real-world system this separation would be further implemented by separate schemas/namespaces.

As the database **PostgreSQL** instance could be used:

```sh
docker run --rm --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=secret -d postgres:13
```

Start the application with Spring profile `postgres`:

```sh
./gradlew :application:bootRun --args='--spring.profiles.active=postgres'
```

When the `postgres` profile is not active, the system will fall-back to use H2 as the default database.

## Gradle Build 

The project is a Gradle multi-project, all sub-projects can be built in a single command:

```sh
./gradlew clean build
```

## Docker Containers

Build an image per microservice via Gradle Spring Boot plugin:
```sh
./gradlew bootBuildImage
```

To run the containers:
```sh
docker container run --rm -p 8080:8001 ttulka/ecommerce-catalog-service
docker container run --rm -p 8080:8002 ttulka/ecommerce-order-service
docker container run --rm -p 8080:8003 ttulka/ecommerce-cart-service
docker container run --rm -p 8080:8004 ttulka/ecommerce-payment-service
docker container run --rm -p 8080:8005 ttulka/ecommerce-delivery-service
docker container run --rm -p 8080:8006 ttulka/ecommerce-dispatching-service
docker container run --rm -p 8080:8007 ttulka/ecommerce-warehouse-service
docker container run --rm -p 8080:8000 ttulka/ecommerce-portal-service
```

Active profiles can be set as follows:
```sh
docker container run --rm -e ""SPRING_PROFILES_ACTIVE=redis,postgres"" -p 8080:8001 ttulka/ecommerce-catalog-service
```

### Docker-Compose

Build NGINX reverse proxy image:
```sh
docker build -t ttulka/ecommerce-reverseproxy reverseproxy
```

Start the entire microservices stack:
```sh
docker-compose up
```

Access the Postgres database and init some data:
```sh
docker exec -it <containerID> psql -U postgres postgres
```

```sql
INSERT INTO categories VALUES
    ('C1', 'books', 'Books'),
    ('C2', 'games', 'Games');

INSERT INTO products VALUES
    ('P1', 'Domain-Driven Design', 'by Eric Evans', 45.00),
    ('P2', 'Object Thinking', 'by David West', 35.00),
    ('P3', 'Chess', 'Classic game.', 3.20);

INSERT INTO products_in_categories VALUES
    ('P1', 'C1'),
    ('P2', 'C1'),
    ('P3', 'C2');

INSERT INTO products_in_stock VALUES
    ('P1', 5),
    ('P2', 0),
    ('P3', 1);
```

The NGINX reverse proxy serves as a simple API gateway:
```sh
curl localhost:8080/catalog/products
curl localhost:8080/warehouse/stock/5
```

## Kubernetes

To use local images for development with Minikube, run the following command to use local Docker images registry:
```sh
minikube start
eval $(minikube docker-env)
```

Afterwards, build the docker images again for the Minikube's Docker daemon:
```sh
./gradlew bootBuildImage
```

Create deployments:
```sh
kubectl apply -f 1-infrastructure.k8s.yml
kubectl apply -f 2-backend-services.k8s.yml
kubectl apply -f 3-frontend-portal.k8s.yml
kubectl apply -f 4-api-gateway.k8s.yml
```

Set up ports forwarding to access the cluster from your local network:
```sh
kubectl port-forward service/reverseproxy 8080:8080
```

Alternatively, you can create an Ingress:
```sh
minikube addons enable ingress

kubectl apply -f 5-ingress.k8s.yml

# get the ingress address 
kubectl get ingress ecommerce-ingress

# add the address into hosts
sudo cp /etc/hosts hosts.bak
sudo echo -e '\n<ingress-address> ecommerce.local' >> /etc/hosts

# access the application in browser: http://ecommerce.local
``` 
"
piomin/sample-quarkus-applications,master,44,26,2020-08-09T08:34:19Z,181,2,Example application built using Quarkus framework,graphql h2-database jaxrs openapi3 panache quarkus quarkus-hibernate-orm quarkus-kotlin quarkus-maven quarkus-panache quarkus-resteasy smallrye swagger,
minwan1/spring-security-oauth2-example,master,54,23,2018-03-10T07:40:29Z,107,0,:dart: This is spring-oauth2 example,,"[![Build Status](https://travis-ci.com/minwan1/spring-security-oauth2-example.svg?branch=master)](https://travis-ci.com/minwan1/spring-security-oauth2-example)
[![Coverage Status](https://coveralls.io/repos/github/minwan1/spring-security-oauth2-example/badge.svg)](https://coveralls.io/github/minwan1/spring-security-oauth2-example)

# Spring-Security-OAuth2-example
Spring-Security-OAuth2 구현 예제입니다.

# 개발환경
* Spring boot 1.5.9
* Java 8
* Mockito,
* Spring REST
* JPA



# 문서

1. [step1 : oauth1, oauth2란](https://github.com/minwan1/spring-security-oauth2-example/blob/master/docs/step-1%3Aoauth1%2Coauth2%EB%9E%80.md)
2. [step2 : spring-security-oauth2구현(in-memory, jdbc방식을 사용한 예제)](https://github.com/minwan1/spring-security-oauth2-example/blob/master/docs/step-2%3Aspring-oauth2-%EA%B5%AC%ED%98%84.md)


# 브랜치

* [example-1 : in-memory 방식을 사용한 OAuth2 구현](https://github.com/minwan1/spring-security-oauth2/tree/example-1)
* [example-2 : JDBC 방식을 사용한 OAuth2 구현](https://github.com/minwan1/spring-security-oauth2/tree/example-2)

# 실행
```
$ mvn spring-boot:run
```

# Test 방법
```
Spring-oauth/src/test/java/com/example/oauth/OauthApplicationTests.java
```




"
agiledon/payroll-ddd,master,110,68,2019-09-25T08:14:05Z,123,2,DDD Example based on Scenario-Driven Design and Test-Driven Design ,,
Jaouan/Sending-Animation-Example,master,159,25,2016-08-14T08:31:58Z,333,0,It's just an example of sending animation.,,"Android - Article sending animation example
========

It's just an example of sending animation.

![demo](art/demo.gif)

References
========
 - The project uses [ButterKnife](http://jakewharton.github.io/butterknife/).

License
========

[Apache License Version 2.0](LICENSE)"
damienbeaufils/spring-boot-clean-architecture-demo,master,123,38,2017-09-07T15:16:13Z,207,1,An example of clean architecture implementation with Spring Boot,,"# spring-boot-clean-architecture-demo

[![Build Status](https://travis-ci.org/damienbeaufils/spring-boot-clean-architecture-demo.svg?branch=master)](https://travis-ci.org/damienbeaufils/spring-boot-clean-architecture-demo)

An example of clean architecture with Spring Boot

## Foreword

This application is designed using a [Clean Architecture pattern](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html) (also known as [Hexagonal Architecture](http://www.maximecolin.fr/uploads/2015/11/56570243d02c0_hexagonal-architecture.png)).
Therefore [SOLID principles](https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)) are used in code, especially the [Dependency Inversion Principle](https://en.wikipedia.org/wiki/Dependency_inversion_principle) (do not mix up with the classic dependency injection in Spring for example).

Concretely, there are 3 main packages: `domain`, `use_cases` and `infrastructure`. These packages have to respect these rules:
- `domain` contains the business code and its logic, and has no outward dependency: nor on frameworks (Hibernate for example), nor on `use_cases` or `infrastructure` packages.
- `use_cases` is like a conductor. It will depend only on `domain` package to execute business logic. `use_cases` should not have any dependencies on `infrastructure`.
- `infrastructure` contains all the technical details, configuration, implementations (database, web services, etc.), and must not contain any business logic. `infrastructure` has dependencies on `domain`, `use_cases` and frameworks.  

## Install

```
./gradlew assemble
```

## Test

```
./gradlew check
```

## Mutation testing

```
./gradlew pitest
```

## Run

```
./gradlew bootRun
```
"
ssalevan/cc-helloworld,master,33,16,2011-12-10T20:24:35Z,25754,1,CommonCrawl Hello World example,,
ajbkr/HTML5-Cross-Platform-Game-Development-Using-Phaser-3,master,44,26,2019-03-26T21:33:53Z,4381,0,"Reworked examples from Emanuele Feronato's HTML5 Cross Platform Game Development Using Phaser 3 (Babel, webpack)",,"HTML5 Cross Platform Game Development Using Phaser 3
====================================================

Reworked examples from Emanuele Feronato's [HTML5 Cross Platform Game
Development Using Phaser
3](http://phaser.io/shop/books/phaser3-cross-platform-games).

I have modified some of the source code to use ES6/7 and have added linting
using [JavaScript Standard Style](https://standardjs.com/).

I have also added Babel, webpack, et al. for bundling.

Android/Cordova Build
---------------------

Ensure `cordova` has been installed from npm:

```
$ npm install cordova -g # may need sudo
```

To build for Android:

```
$ cd 028 # or 029
$ npm run build
$ npm run copy-dist
$ cd ../cordovafolder
$ cordova prepare
```
"
kousen/mockitobook,main,30,16,2021-12-10T02:07:14Z,515,0,"Code examples for the book Mockito Made Clear, from Pragmatic Programmers",,"# mockitobook
Code examples for the book _Mockito Made Clear_,
published by Pragmatic Programmers.

See [the book page](https://pragprog.com/titles/mockito/mockito-made-clear/) for more information.

![Visualization of this repo](./diagram.svg)

You can check out the whole GitHub Action at [diagram.yml](/.github/workflows/diagram.yml). Notice that we're excluding the `ignore` and `.github` folders, using the `excluded_paths` config.

## Running the code
To run the code, use the included Gradle wrapper (the `gradlew` scripts for Un*x and Windows) and execute either the `build` or `test` tasks. You can also run individual tests via Gradle, or just load them into your preferred IDE.

This project uses [Gradle version catalogs](https://docs.gradle.org/current/userguide/platforms.html#sub:central-declaration-of-dependencies), which require Gradle 7.4 or higher. The included wrapper is higher than that. The dependency versions are inside the `libs.versions.toml` file in the `gradle` directory, which are used inside `build.gradle`.

See also the Mockito play list at my [YouTube channel](https://www.youtube.com/@talesfromthejarside?sub_confirmation=1)."
msfroh/lucene-university,main,42,15,2023-11-21T19:00:35Z,420,5,Self-contained worked examples of Apache Lucene features and functionality,,"# Self-contained Lucene examples

This repository contains some examples of [Apache Lucene](https://lucene.apache.org/) features with verbose explanations
as code comments written in Markdown.

The goal is to provide code samples that can be used a few ways:

1. Read the source code. The comments should make what's going on pretty clear.
2. Open a code sample in your IDE and step through it with a debugger. Follow along with the comments as you go. Make 
changes to the code and see what happens. (Some examples include suggested changes.)
3. Read the code and documentation as a web page generated with [Docco](https://ashkenas.com/docco/) over at 
https://msfroh.github.io/lucene-university/docs/SimpleSearch.html. (Go to the ""Jump to..."" box in the top-right to load 
other examples.) This should feel kind of like reading a book.

## Getting started

This repository currently depends on a snapshot of Lucene 10, which requires JDK 17 or higher.

You can clone the repository and build the examples with:

```
git clone https://github.com/msfroh/lucene-university.git
cd lucene-university
./gradlew build
```

Using IntelliJ, you can use ""File -> New -> Project from Existing Sources..."" and point it to the location where the
code was cloned. Select ""Import Project from Existing Model"" and choose ""Gradle"" (assuming you have the Gradle plugin
installed). If you run into errors regarding class file versions, you may need to go to ""File -> Project Structure..."" 
to make sure that you have selected the correct JDK (17 or higher) and set an appropriate language level.

## Contributing

Contributions are welcome! Check the [GitHub issues](https://github.com/msfroh/lucene-university/issues) for requests
and suggestions for material to cover. If there is something else you think could use a worked example, feel free to
directly open a pull request with an example or create an issue requesting one.

Code examples should satisfy the following:

1. Each source file should be self-contained and should only import Lucene and Java classes. The example class should not inherit from 
anything else. If you need a small helper class, make it a `private static` inner class.
2. Each example class should have a `public static void main` method that clearly walks through the steps to demonstrate the given feature.
3. Each example should start with a comment with a large header (`// # This is title text`), and a summary explaining what the example
is about, before the `package` declaration.

## License

All code in this repository is licensed under the Apache License, Version 2.0. See the LICENSE file in the root of the repository for the
full text of the license.
"
pauldragoslav/Spring-boot-Banking,main,161,71,2019-05-11T20:56:04Z,610,0,Example project demonstrating the use of Spring-boot in a banking microservice,,"# Spring-boot Banking
Example project demonstrating the use of Java and Spring-boot to build a microservice to be used by an online bank

## Running locally
```
./mvnw clean install -DskipTests=true
```

```
java -jar target/Banking-0.0.1.jar
```

## Running on Docker
```
docker build -t ""spring-boot:banking"" .
```

```
docker run -p 8080:8080 spring-boot:banking
```

## Testing
Import the Postman collection file into the application or copy the request body from there

### How to test
1. Create account
   > Use create account API to create an account by providing a `bankName` and `ownerName`
   > 
   ![Create Account](screenshots/create_account.png)

> Make sure to write down the `sortCode` and the `accountNumber` to proceed with other APIs

2. Deposit Cash
   >Use noted `accountNumber` as `targetAccountNo` and provide amount greater than zero to deposit cash into an account
   
   ![Deposit cash](screenshots/deposit.png)

3. Check Balance
   >Use noted `accountNumber` and `sortCode` to check account balance

   ![Check Balance](screenshots/check_balance.png)
   
4. Withdraw Cash
   >Use noted `accountNumber` and `sortCode` and `amount` grater than zero to withdraw cash from an account

   ![Withdraw cash](screenshots/withdraw.png)
    
5. Check Balance again to verify withdrawal

   ![Check Balance](screenshots/check_balance_2.png)
   


### Extensions
1. Use of persisted database
2. Use of asynchronous programming backed by message queue for transactions
3. Others mentioned throughout the code"
studerw/activiti-example,master,25,31,2014-05-20T05:17:11Z,22501,0,Activiti Workflow example using Spring MVC,activiti-workflow activity alfresco java spring-mvc workflow,"# Activiti Workflow Example 


Activiti Workflow example using **Spring MVC 4**, **Activiti Workflow 5**, and an embedded **Tomcat Servlet**.
__________________________________________

![long-polling-redis](https://github.com/studerw/activiti-example/blob/master/example.gif)

## Running 
To run you need Maven:

```bash
mvn tomcat7:run
```
Use `Ctrl-c` to stop the app.

Access the site:
[http://127.0.0.1:9090/activiti-example/]([http://127.0.0.1:9090/activiti-example/])

* Login in as any of the users - the password is the same name as the user (e.g. kermit/kermit).

* Create a document and submit for approval. Take notice for which group (engineering, sales, management, etc.) the document was created.

* Then logout and login as another user in the same group. You can
view the list of users by clicking the 'users' button on the bottom right of the form.

* View your tasks and see that there is a new document waiting to be approved. Approve or deny. Log back in as the original author.

* Next modify the workflow for a group by adding additional approval steps, using different users and/or groups if desired. Create new document(s) under the modified group(s).


## Building 
To build:
```bash
mvn clean install
```

"
caseyscarborough/spring-redis-caching-example,master,39,44,2014-12-19T00:42:32Z,124,0,An example of caching in Spring using Redis.,,"# Spring Redis Caching Example

This repository contains an example of caching data in Spring using Redis.

## Running the Application

The application can be run by executing the following:

```bash
mvn clean jetty:run
```

Then navigate to [localhost:8080](http://localhost:8080) in your browser."
utopia-group/regel,master,33,10,2020-03-27T23:19:16Z,11451,3,REGEL: Regular Expression Generation from Examples and Language,,"# REGEL: Regular Expression Generation from Examples and Language

This is the code repository for the paper [""Multi-modal Synthesis of Regular Expressions""](https://arxiv.org/abs/1908.03316).

## Prerequisites

Before runing the code for parsing your own language or reproducing experimental results, please first set up the [Sempre](https://github.com/percyliang/sempre) tool following the instructions below:

```shell
cd sempre
./pull-dependencies core
./pull-dependencies corenlp
./pull-dependencies freebase
./pull-dependencies tables
```

This repository also requires the following:

- [Z3](https://github.com/Z3Prover/z3). Make sure you have Z3 installed with the Java binding. 
- `ant` to compile the java files.
- `python3 ` 3.7
- `java` 1.8.0

Alternately you can use the included Dockerfile to build a Docker image:

```shell
docker build -t regel:v1 .
```

## Benchmarks

### Existing Benchmarks

This repository includes two benchmarks domain: 

- StackOverflow (`$benchmark_domain = ""so""`)
- DeepRegex (`$benchmark_domain = ""deepregex""`).

The benchmarks (including natural language, examples and ground truth) are under `exp/$benchmark_domain/benchmark`.

We include the set of sketches we used under `exp/$benchmark_domain/sketch`

### Generate your own benchmarks

To generate your own benchmarks, you need to do the following:

#### Prepare a benchmark file

Create a new folder `exp/$your_benchmark_domain`

Inside `exp/$your_benchmark_domain/benchmark`, create benchmark files look like the following:

```
// natural language
# natural language description goes here

// examples
# write example in the format ""$example_string$"",$sign$ where sign can be
#	1) + to indicate it's a positive example
#	2) - to indicate it's a negative example

// gt
# ground truth in the dsl
```

The sample benchmarks can be found under the so and deepregex dataset.

#### Prepare a test/train set file for parser

The procedure to create such a file is under ""Train Sketch Parser"" -> ""Prepare Train Set File"". The procedure creating a test set file is same as the one creating a train set file except you fill the `Sketch` field with `null`.

## Sketch Generation

**Note:** if you only runs the `so` or `deepregex` benchmarks, you don't need to generate sketch unless you trained a new model. 

After having a set of benchmarks to generate sketch, run the following script:

```shell
python parse_benchmark.py --benchmark $your_benchmark_domain --model_dir $trained_model --max_sketch $number_of_sketch_generated_per_benchmark
```

The generated sketches will be put under `exp/$your_benchmark_domain/sketch`

##### `$trained_model`

We provided the pre-trained model for the two benchmarks datasets:

`so`: `pretrained_models/pretrained_so`

`deepregex`:`pretrained_models/pretrained_turk`

## Sketch Completion

To get the instantiations of the sketches that satisfy the given examples, invoke the following command:

```shell
python exp.py --benchmark $your_benchmark_domain --log_name $log_folder_name --sketch $sketch_folder_name --mem_max $max_memeory_allowed --synth_mode $synthesis_mode --processnum $number_of_process_allowed	--timeout $timeout_for_each_benchmark
```

##### `$synthesis_mode`

The synthesizer can be runned in the following mode:

`1`: enables all Regel Functionalities

`2`: enables Regel with pruning using over and under-approxmiation only

`4`: enumeration with no pruning techniques

`5`: run Regel with no sketches

##### `$number_of_process_allowed`

Regel tries to instantiate multiple sketches at parallel. Let `number_of_process_allowed = 1` if you wants to disable the parallel functionality. Otherwise, instantiate this parameter with an argument greater than `1`. The default value is `5`.

#### Output Processing

The script outputs to the `$log_folder_name` where a single file in the folder corresponds to the output of a single benchmark. To process the output in batch and generate a `csv` output, invoke the following script:

```shell
python process_output.py --log_folder $log_folder_name --log_path $path_to_log_folder --output_name $output_file_name
```

The output file will be inside the log folder as `$output_file_name.csv`

## Interactive Mode

We also provide a way to run Regel interactively (i.e. allowing users to interact with Regel by providing examples to refine the synthesis results).

### Run Interactive Mode with Benchmark Set

```shell
python interactive.py --run_mode 1 --benchmark $your_benchmark_domain --synth_mode $synthesis_mode --process_num $number_of_process_allowed --mem_max $max_memory_allowed --top $top_k_results_allowed --timeout $timeout_for_each_benchmark --max_iter $max_iter --save_history $save_history
```

##### `$top_k_results_allowed`

In interactive Regel, we only show user the first k finished sketch results. 

##### `$save_history`

The interactive Regel allows you to stop at any point working and continue from where you left last time. Set this to `True` if you wants to enable this functionality. 

##### `$max_iter`

The maximum of interaction allowed for each benchmark. 

#### Additional examples

For benchmark domains `so` and `deepregex`, we provide a set of additional examples to further refine the results automatically. These additional examples are stored in `interactive/$your_benchmark_domain/examples_cache`. All the furture addtional examples you entered will also stored inside this directory.

#### The workflow of the interactive script:

For each benchmark:

1. Regel reads the benchmarks and sketches and invoke the synthesizer
2. Rank the outputs and get the `$top_k_results_allowed` results
3. Check if any of the results returned matches the ground truth
4. If matches ground truth, the script automatically goes to the next benchmark
5. If does not match the ground truth, the script first find examples in the `examples_cache` that matches the synthesized regex but not the ground truth regex (this will be a negative example) or matches the ground truth regex but not the synthesized regex (this will be a positive example) and uses this example as the one to refine the synthesizer
6. If there does not exist a example in the `examples_cache` that matches the criteria, the script will ask the user to enter two additional examples and indicate whether they are positive and negative examples
7. Regel will run again using the updated examples

### Run Interactive Mode with Arbituary Natural Language and Examples (""Customize"" Mode)

```shell
python interactive.py --run_mode 0 --synth_mode $synthesis_mode --process_num $number_of_process_allowed --mem_max $max_memory_allowed --top $top_k_results_allowed --timeout $timeout_for_each_benchmark --max_iter $max_iter --skecth_num $number_of_sketch_per_benchmark --save_history $save_history
```

#### The workflow of the interactive script (customize mode):

1. Enter a file name for your benchmark
2. Enter the natural language
3. Enter the examples
4. Indicating whether the example entered is a positive or negative example: use + to indicate it is a positive example, and - to indicate it is a negative example

The benchmark file created will be saved at `exp/customize/benchmark/$benchmark_file_name`

5. Regel will generate `$number_of_sketch_per_benchmark` number of sketches.

The sketch file created will be saved at `exp/customize/sketch/$benchmark_file_name`

6. Regel will run the synthesizer, and return either `$top_k_results_allowed` number of results or indicate it times out. 
7. Regel will ask you if there is any correct regex returned. Enter `y` if there is and enter the correct regex index.
8. If you enter `n` for the last question, Regel will ask you to enter two additional examples to disambiguate the regexes
9. Enter the examples in the same way as you enter the initial examples. After getting the additional examples, Regel will rerun the synthesizer and return the updated synthesis result. 

### Output

The output of execution is saved at `interactive/$your_benchmark_domain/logs/$synthesis_mode/raw_output.csv`.

If you uses `customize` mode, `$your_benchmark_domain = 'customize'`

## Train Sketch Parser

We have provided pretrained model that is ready to use in `sempre/pretrained`. We as well provide a examples procedure of how to train a model on **StackOverflow** dataset. 

**Prepare Train Set File**

We show a example train set file in `data/so.raw.txt`. It is a TSV file with three fields (`ID`, `NL`, and `Sketch`). Please prepare your train set file in this format, and put it in the `sempre/dataset/` directory with the name `*dataset-name*.raw.txt`.

**Train Parse Script**

To train a model, call

`python py_scripts/train.py *dataset-name* *model-dir*` 

E.g. `python py_scripts/train.py so models/so`

This command will preproces the training data (to fit the form required by `Sempre`. The processed data form will be stored in `regex/data/so`) and train a model that will be saved in the `*model-dir*` directory.

**Parse Script**

To parse a set of language descriptions using trained model, call

`python pyscripts/parse.py *dataset-name* *model-dir* *topk*`, where `*topk*` is the desired number of sketches.

The parsed sketches will be in `ouputs/*dataset-name*`, where each file contains the sketches for a single benchmark.



"
jakubnabrdalik/architecture-guild,master,139,19,2019-09-04T15:19:53Z,235,0,An example of an Architecture Guild repository,,
pavelfomin/spring-boot-rest-example,master,65,46,2016-08-13T00:12:45Z,260,0,Spring boot example with REST and spring data JPA,,"# Spring boot example with REST and spring data JPA
See [micronaut-rest-example](https://github.com/pavelfomin/micronaut-rest-example) for `Micronaut` implementation.

### Running tests
* Maven: `./mvnw clean test`
* Gradle: `./gradlew clean test`

### Endpoints

| Method | Url | Decription |
| ------ | --- | ---------- |
| GET    |/actuator/info  | info / heartbeat - provided by boot |
| GET    |/actuator/health| application health - provided by boot |
| GET    |/v2/api-docs    | swagger json |
| GET    |/swagger-ui.html| swagger html |
| GET    |/v1/person/{id}| get person by id |
| GET    |/v1/persons    | get N persons with an offset|
| PUT    |/v1/person     | add / update person|

### Change maven version
`mvn -N io.takari:maven:wrapper -Dmaven=3.8.4`"
mraible/jhipster5-demo,master,82,31,2018-06-26T03:48:09Z,10461,1,Get Started with JHipster 5 Tutorial and Example,angular java jhipster jwt-authentication spring-boot typescript webpack,"# blog
This application was generated using JHipster 5.0.1, you can find documentation and help at [https://www.jhipster.tech/documentation-archive/v5.0.1](https://www.jhipster.tech/documentation-archive/v5.0.1).

## Development

Before you can build this project, you must install and configure the following dependencies on your machine:

1. [Node.js][]: We use Node to run a development web server and build the project.
   Depending on your system, you can install Node either from source or as a pre-packaged bundle.
2. [Yarn][]: We use Yarn to manage Node dependencies.
   Depending on your system, you can install Yarn either from source or as a pre-packaged bundle.

After installing Node, you should be able to run the following command to install development tools.
You will only need to run this command when dependencies change in [package.json](package.json).

    yarn install

We use yarn scripts and [Webpack][] as our build system.

Run the following commands in two separate terminals to create a blissful development experience where your browser
auto-refreshes when files change on your hard drive.

    ./mvnw
    yarn start

[Yarn][] is also used to manage CSS and JavaScript dependencies used in this application. You can upgrade dependencies by
specifying a newer version in [package.json](package.json). You can also run `yarn update` and `yarn install` to manage dependencies.
Add the `help` flag on any command to see how you can use it. For example, `yarn help update`.

The `yarn run` command will list all of the scripts available to run for this project.

### Service workers

Service workers are commented by default, to enable them please uncomment the following code.

* The service worker registering script in index.html

```html
<script>
    if ('serviceWorker' in navigator) {
        navigator.serviceWorker
        .register('./service-worker.js')
        .then(function() { console.log('Service Worker Registered'); });
    }
</script>
```

Note: workbox creates the respective service worker and dynamically generate the `service-worker.js`

### Managing dependencies

For example, to add [Leaflet][] library as a runtime dependency of your application, you would run following command:

    yarn add --exact leaflet

To benefit from TypeScript type definitions from [DefinitelyTyped][] repository in development, you would run following command:

    yarn add --dev --exact @types/leaflet

Then you would import the JS and CSS files specified in library's installation instructions so that [Webpack][] knows about them:
Edit [src/main/webapp/app/vendor.ts](src/main/webapp/app/vendor.ts) file:
~~~
import 'leaflet/dist/leaflet.js';
~~~

Edit [src/main/webapp/content/css/vendor.css](src/main/webapp/content/css/vendor.css) file:
~~~
@import '~leaflet/dist/leaflet.css';
~~~
Note: there are still few other things remaining to do for Leaflet that we won't detail here.

For further instructions on how to develop with JHipster, have a look at [Using JHipster in development][].

### Using angular-cli

You can also use [Angular CLI][] to generate some custom client code.

For example, the following command:

    ng generate component my-component

will generate few files:

    create src/main/webapp/app/my-component/my-component.component.html
    create src/main/webapp/app/my-component/my-component.component.ts
    update src/main/webapp/app/app.module.ts


## Building for production

To optimize the blog application for production, run:

    ./mvnw -Pprod clean package

This will concatenate and minify the client CSS and JavaScript files. It will also modify `index.html` so it references these new files.
To ensure everything worked, run:

    java -jar target/*.war

Then navigate to [http://localhost:8080](http://localhost:8080) in your browser.

Refer to [Using JHipster in production][] for more details.

## Testing

To launch your application's tests, run:

    ./mvnw clean test

### Client tests

Unit tests are run by [Jest][] and written with [Jasmine][]. They're located in [src/test/javascript/](src/test/javascript/) and can be run with:

    yarn test

UI end-to-end tests are powered by [Protractor][], which is built on top of WebDriverJS. They're located in [src/test/javascript/e2e](src/test/javascript/e2e)
and can be run by starting Spring Boot in one terminal (`./mvnw spring-boot:run`) and running the tests (`yarn run e2e`) in a second one.
### Other tests

Performance tests are run by [Gatling][] and written in Scala. They're located in [src/test/gatling](src/test/gatling).

To use those tests, you must install Gatling from [https://gatling.io/](https://gatling.io/).

For more information, refer to the [Running tests page][].

## Using Docker to simplify development (optional)

You can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.

For example, to start a postgresql database in a docker container, run:

    docker-compose -f src/main/docker/postgresql.yml up -d

To stop it and remove the container, run:

    docker-compose -f src/main/docker/postgresql.yml down

You can also fully dockerize your application and all the services that it depends on.
To achieve this, first build a docker image of your app by running:

    ./mvnw verify -Pprod dockerfile:build dockerfile:tag@version dockerfile:tag@commit

Then run:

    docker-compose -f src/main/docker/app.yml up -d

For more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.

## Continuous Integration (optional)

To configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.

[JHipster Homepage and latest documentation]: https://www.jhipster.tech
[JHipster 5.0.1 archive]: https://www.jhipster.tech/documentation-archive/v5.0.1

[Using JHipster in development]: https://www.jhipster.tech/documentation-archive/v5.0.1/development/
[Using Docker and Docker-Compose]: https://www.jhipster.tech/documentation-archive/v5.0.1/docker-compose
[Using JHipster in production]: https://www.jhipster.tech/documentation-archive/v5.0.1/production/
[Running tests page]: https://www.jhipster.tech/documentation-archive/v5.0.1/running-tests/
[Setting up Continuous Integration]: https://www.jhipster.tech/documentation-archive/v5.0.1/setting-up-ci/

[Gatling]: http://gatling.io/
[Node.js]: https://nodejs.org/
[Yarn]: https://yarnpkg.org/
[Webpack]: https://webpack.github.io/
[Angular CLI]: https://cli.angular.io/
[BrowserSync]: http://www.browsersync.io/
[Jest]: https://facebook.github.io/jest/
[Jasmine]: http://jasmine.github.io/2.0/introduction.html
[Protractor]: https://angular.github.io/protractor/
[Leaflet]: http://leafletjs.com/
[DefinitelyTyped]: http://definitelytyped.org/
"
RayRoestenburg/AkkaExamples,master,33,4,2009-11-21T18:14:53Z,248,0,Akka examples,,
tehmou/RxJava-code-examples,master,26,6,2014-01-26T17:48:20Z,120,0,Simple code examples in forms of JUnit tests to illustrate functional reactive programming with RxJava,,"# Running the project

This project contains only JUnit tests. First install Gradle (mine was
1.8) and then run the tests from the project root with

  `gradle test`
"
cdietrich/xtext-languageserver-example,master,33,35,2016-06-29T13:18:21Z,1027,17,An Example for an Xtext Language Server,,"# Xtext Visual Studio Code Example

This is an [Example](https://github.com/xtext/xtext-languageserver-example/blob/master/vscode-extension-self-contained/README.md) showing the Visual Studio Code Integration of Xtext using the Microsoft Language Server Protocol.


![Build Status](https://github.com/xtext/xtext-languageserver-example/actions/workflows/build.yml/badge.svg)

## Quickstart

Requires Visual Studio Code (VS Code) with version 1.4.0 or greater to be on the path as `code` and Java 8+ available as `java`.

- Run `./gradlew startCode`

This will start VS Code and after a few seconds load the `demo` folder of this repository.

## Project Structure

- `vscode-extension` (node based VS Code extension to run with a separate server using socket)
- `vscode-extension-self-contained` (node based VS Code extension to run with a embedded server using process io)
- `org.xtext.example.mydsl` (contains the dsl)
- `org.xtext.example.mydsl.ide` (contains the dsl specific customizations of the Xtext language server)
- `org.xtext.example.mydsl.tests`

## Building in Details

1. Make sure that `java -version` is executable and pointing to a Java 8+ JDK.
2. Type `code`. If the command is not known, open VS Code and select *View / Command Palette*. Enter `code` and select to install `code` on the path.
1. Run `./gradlew startCode` to build the DSL and the VS Code extensions.

### Scenario 1 (embedded server)

1. Install the self-contained extension into VS Code using
    `code --install-extension vscode-extension-self-contained/build/vscode/vscode-extension-self-contained-0.0.1.vsix`
2. Run a second instance of vscode on the demo folder `code demo`

### Scenario 2 (client-only with separate server process)

1. Run `./gradlew run` or launch RunServer from Eclipse.
2. Open `vscode-extension` in VS Code and `F5` to launch new editor (you may need a Debug -> Start Debugging initally).
1. Open folder `demo` in the new editor.


### Build VS Code Extension Package manually (manually Gradle)

```
npm install -g vsce
cd vscode-extension
vsce package
cd ../vscode-extension-self-contained
vsce package
```

### Hints

For Other Xtext/VSCode versions please also check other branches for newer/older Xtext Versions that also support newer/older vscode versions
Atom language client is dead. We plan to update to a fork. See https://github.com/itemis/xtext-languageserver-example/issues/73"
steveonjava/JavaFX-Spring,master,142,115,2012-08-28T00:18:10Z,210,5,Example application demonstrating integration of JavaFX and Spring technologies on the client and server,,"JavaFX-Spring
=============

Example application demonstrating integration of JavaFX and Spring technologies on the client and server.  For more details about the technologies used, and a details of the code, please refer to the following 3 part blog series:

* [JavaFX in Spring Day 1 - Application Initialization](http://steveonjava.com/javafx-and-spring-day-1)
* [JavaFX in Spring Day 2 - Configuration and FXML](http://steveonjava.com/javafx-in-spring-day-2)
* [JavaFX in Spring Day 3 - Authentication and Authorization](http://steveonjava.com/javafx-in-spring-day-3)

To run this example, you will need to build and run the server and client projects individually using maven.  You can either do this via an IDE or from the command line.

To start with, please make sure you have the following prerequisites:

* Maven (3.x or higher)
* JDK 7 (update 4 or higher)

The command line steps to get this up and running are:

    cd server
    mvn jetty:run
    cd ..
    cd client
    mvn compile exec:java

If it doesn't work, make sure that maven is running the right version of java by calling ""mvn -version"".  If you are still having trouble, check out the blogs mentioned above, and post if your issue is not resolved."
perslab/depict,master,44,23,2014-11-11T20:06:39Z,17046,21,"DEPICT code, instructions and an example",,"# Dependencies
* Mac OS X, or UNIX operating system (Microsoft Windows is not supported)
* Java SE 6 (or higher)
  * [Java.com](https://www.java.com/en/download/)
* Python version 2.7 (Python version 3 or higher is not supported)
  * [Python.org](https://www.python.org/downloads/)
* PIP (used for install Python libraries)
  * `sudo easy_install pip` 
* Python intervaltree library
  * `sudo pip install intervaltree`   
* Pandas (version 0.15.2 or higher)
  * `sudo pip install pandas`
* PLINK version 1.9 (August 1 release or newer)
  * [PLINK version 1.9](https://www.cog-genomics.org/plink2/) 


# DEPICT
The following description explains how to download DEPICT, test run it on example files and how to run it on your GWAS summary statistics.


## Download DEPICT
Download the compressed [DEPICT version 1 rel194](https://drive.google.com/file/d/0B3TrbUOwncN-NG9nTFdDbC1rNXc/view?usp=sharing&resourcekey=0-Jts51YpkcZcGpvsOP29Kfw) files and unzip the archive to where you would like the DEPICT tool to live on your system. Note that you when using DEPICT can write your analysis files to a different folder.  Be sure to that you meet all the dependencies described above.  If you run DEPICT at the Broad Institute, see [below section](#depict_at_broad).

## Test run DEPICT
The following steps outline how to test run DEPICT on LDL cholesterol GWAS summary statistics from [Teslovich, Nature 2010](http://www.nature.com/nature/journal/v466/n7307/full/nature09270.html). This example is available in both the 1000 Genomes Project pilot phase DEPICT version and the 1000 Genomes Project phase 3 DEPICT version.

1. Edit `DEPICT/example/ldl_teslovich_nature2010.cfg`
  * Point `plink_executable` to where PLINK executable (version 1.9 or higher) is on our system (e.g. `/usr/bin/plink`)
2. Run DEPICT on the LDL summary statistics
  * E.g. `./src/python/depict.py example/ldl_teslovich_nature2010.cfg`
3. Investigate the results (see the [Wiki](https://github.com/perslab/DEPICT/wiki) for a description of the output format).
  * DEPICT loci `ldl_teslovich_nature2010_loci.txt`
  * Gene prioritization results `ldl_teslovich_nature2010_geneprioritization.txt`
  * Gene set enrichment results `ldl_teslovich_nature2010_genesetenrichment.txt`
  * Tissue enrichment results `ldl_teslovich_nature2010_tissueenrichment.txt`


## <a name=""depict_your_gwas""></a>Run DEPICT based on your GWAS
The following steps allow you to run DEPICT on your GWAS summary statistics. We advice you to run the above LDL cholesterol example before this point to make sure that you meet all the necessary dependencies to run DEPICT.

1. Make sure that you use hg19 genomic SNP positions
2. Make an 'analysis folder' in which your trait-specific DEPICT analysis will be stored
3. Copy the template config file from `src/python/template.cfg` to your analysis folder and give the config file a more meaningful name
4. Edit your config file
  * Point `analysis_path` to your analysis folder.  This is the directory to which output files will be written
  * Point `gwas_summary_statistics_file` to your GWAS summary statistics file.  This file can be either in plain text or gzip format (i.e. having the .gz extension)
  * Specify the GWAS association p value cutoff (`association_pvalue_cutoff`). We recommend using `5e-8` or `1e-5`
  * Specify the label, which DEPICT uses to name all output files (`label_for_output_files`)
  * Specify the name of the association p value column in your GWAS summary statistics file (`pvalue_col_name`)
  * Specify the name of the marker column (`marker_col_name`). Format: <chr:pos>, ie. '6:2321'.  If this column does not exist chr_col and pos_col will be used, then leave if empty
  * Specify the name of the chromosome column (`chr_col_name`).  Leave empty if the above `marker_col_name` is set
  * Specify the name of the position column (`pos_col_name`).  Leave empty if the above `marker_col_name` is set. Please make sure that your SNP positions used human genome build GRCh37 (hg19)
  * Specify the separator used in the GWAS summary statistics file (`separator`). Options are
    * `tab`
    * `comma`
    * `semicolon`
    * `space`
  * Point `plink_executable` to where PLINK 1.9 executable (August 1 release or newer) is on your system (e.g. `/usr/bin/plink`)
  * If you are using other genotype data than the data part of DEPICT then point `genotype_data_plink_prefix` to where your PLINK binary format 1000 Genomes Project genotype files are on your system. Specify the entire path of the filenames except the extension
5. Run DEPICT
  * `<path to DEPICT>/src/python/depict.py <path to your config file>`
6. Investigate the results which have been written to your analysis folder. See the [Wiki](https://github.com/perslab/DEPICT/wiki) for details on the output format
  * Associated loci in file ending with `_loci.txt`
  * Gene prioritization results  in file ending with `_geneprioritization.txt`
  * Gene set enrichment results  in file ending with `_genesetenrichment.txt`
  * Tissue enrichment results in file ending with `_tissueenrichment.txt`

## <a name=""depict_at_broad""></a>DEPICT at the Broad Institute 

### Run the LDL example
 1. Copy the example config file `/cvar/jhlab/tp/depict/example/ldl_teslovich_nature2010.cfg` to your working directory and `change analysis_path` to that directory
 2. Run DEPICT using
`qsub -e err -o out -cwd -l h_vmem=12g /cvar/jhlab/tp/depict/src/python/broad_run.sh python /cvar/jhlab/tp/depict/src/python/depict.py <your modified config file>.cfg`

### Run DEPICT on own GWAS
1. Follow the above [steps 1-4](#depict_your_gwas)
2. Run DEPICT using 
``` bash
use UGER
qsub -e err -o out -cwd -l m_mem_free=2.5g -pe smp 6 /cvar/jhlab/tp/depict/src/python/broad_run.sh python /cvar/jhlab/tp/DEPICT/src/python/depict.py <your modified config file>.cfg
```
Be aware that DEPICT needs at least needs 14GB memory when if modify the memory used per slot/thread.

# Troubleshooting
Please send the log file (ending with `_log.txt`) with a brief description of the problem to Tune H Pers (tunepers@broadinstitute.org).

The overall version of DEPICT follows the DEPICT publications. The current version is `v1` from [Pers, Nature Communications, 2015](http://www.nature.com/ncomms/2015/150119/ncomms6890/full/ncomms6890.html) and the release follows the number of commits of the DEPICT git repository (`git log --pretty=format:'' | wc -l`).  The latest 1000 Genomes Project pilot phase DEPICT version is `rel138`, the latest 1000 Genomes Project phase 3 version is `rel137`.

# How to cite

[Pers, Nature Communications 2015](http://www.ncbi.nlm.nih.gov/pubmed/25597830)

[1000 Genomes Project](http://www.ncbi.nlm.nih.gov/pubmed/20981092), because DEPICT makes extensively use of their data.


# Data used in these examples

LDL GWAS [summary statistics](http://csg.sph.umich.edu/abecasis/public/lipids2010/) from [Teslovich, Nature 2010](http://www.nature.com/nature/journal/v466/n7307/full/nature09270.html) are used as input in this example. We included all SNPs with P < 5e-8 and manually added chromosome and position columns (hg19/GRCh37). 

1000 Genomes Consortium pilot release and phase 3 release data are used in DEPICT.  Please remember to cite [their paper](http://www.nature.com/nature/journal/v467/n7319/full/nature09534.html) in case you use our tool.
"
yidongnan/spring-boot-grpc-example,master,41,14,2017-02-08T07:17:12Z,152,10,spring-boot-grpc-example,grpc spring-boot spring-boot-grpc,"# Spring Boot Grpc Example

"
MaLeLabTs/RegexGenerator,master,930,145,2015-04-28T13:30:49Z,11708,4,"This project contains the source code of a tool for generating regular expressions for text extraction:  1. automatically, 2. based only on examples of the desired behavior, 3. without any external hint about how the target regex should look like",,"# RegexGenerator

This project contains the source code of a tool for generating regular expressions for text extraction and classification (flagging):

1. automatically,
2. based only on examples of the desired behavior,
3. without any external hint about how the target regex should look like.

An online, interactive version of this engine is accessible at: [http://regex.inginf.units.it/](http://regex.inginf.units.it/)

RegexGenerator was developed at the [Machine Learning Lab, University of Trieste, Italy] (http://machinelearning.inginf.units.it).

The provided engine is a developement release (1) that implements the algorithms published in our articles (2):

* Bartoli, De Lorenzo, Medvet, Tarlao, Inference of Regular Expressions for Text Extraction from Examples, IEEE Transactions on Knowledge and Data Engineering, 2016
* Bartoli, De Lorenzo, Medvet, Tarlao, Can a machine replace humans in building regular expressions? A case study, IEEE Intelligent Systems, 2016
* Bartoli, De Lorenzo, Medvet, Tarlao, Virgolin, Evolutionary Learning of Syntax Patterns for Genic Interaction Extraction, ACM Genetic and Evolutionary Computation Conference (GECCO), 2015, Madrid (Spain)

More details about the project can be found on [Machine Learning Lab news pages](http://machinelearning.inginf.units.it/news/newregexgeneratortoolonline).

We hope that you find this code instructive and useful for your research or study activity.

If you use our code in your reasearch please cite our work and please share back your enhancements, fixes and 
modifications.

## Project Structure

The RegexGenerator project is organized in three NetBeans Java subprojects:

* ConsoleRegexTurtle:  cli frontend for the GP engine
* MaleRegexTurtle:       provides the regular expression tree representation
* Random Regex Turtle:     GP search engine 

## Other Links

[Twitter account](https://twitter.com/MaleLabTs) of Machine Learning Lab

RegexGenerator [wiki](https://github.com/MaLeLabTs/RegexGenerator/wiki) with installation walkthrough and guide

---

(1) This is a developement version branch which *slightly* differs from the cited works.

(2) BibTeX format:

    @article{bartoli2016inference, 
	  author={A. Bartoli and A. De Lorenzo and E. Medvet and F. Tarlao}, 
	  journal={IEEE Transactions on Knowledge and Data Engineering}, 
	  title={Inference of Regular Expressions for Text Extraction from Examples}, 
	  year={2016}, 
	  volume={28}, 
	  number={5}, 
	  pages={1217-1230}, 
	  doi={10.1109/TKDE.2016.2515587}, 
	  ISSN={1041-4347}, 
	  month={May},
    }
    @inproceedings{bartoli2015evolutionary,
      title={Evolutionary Learning of Syntax Patterns for Genic Interaction Extraction},
      author={Bartoli, Alberto and De Lorenzo, Andrea and Medvet, Eric and
      Tarlao, Fabiano and Virgolin, Marco},
      booktitle={Proceedings of the 2015 on Genetic and Evolutionary Computation Conference},
      pages={1183--1190},
      year={2015},
      organization={ACM}
    }
    @article{bartoli2016can,
      title={Can a machine replace humans in building regular expressions? A case study},
      author={Bartoli, Alberto and De Lorenzo, Andrea and Medvet, Eric and Tarlao, Fabiano},
      journal={IEEE Intelligent Systems},
      volume={31},
      number={6},
      pages={15--21},
      year={2016},
      publisher={IEEE}
    }

"
mbode/flink-prometheus-example,master,89,37,2017-10-20T08:12:31Z,749,3,Example setup to demonstrate Prometheus integration of Apache Flink,flink prometheus,"[![Actions Status](https://github.com/mbode/flink-prometheus-example/workflows/Gradle/badge.svg)](https://github.com/mbode/flink-prometheus-example/actions)
[![codecov](https://codecov.io/gh/mbode/flink-prometheus-example/branch/master/graph/badge.svg)](https://codecov.io/gh/mbode/flink-prometheus-example)
[![Flink v1.19.0](https://img.shields.io/badge/flink-v1.19.0-blue.svg)](https://github.com/apache/flink/releases/tag/release-1.19.0)
[![Prometheus v2.37.1](https://img.shields.io/badge/prometheus-v2.37.1-blue.svg)](https://github.com/prometheus/prometheus/releases/tag/v2.37.1)

This repository contains the live demo to my talk _Monitoring Flink with Prometheus_, which I have given at:
* [Flink Forward Berlin 2018](https://berlin-2018.flink-forward.org/conference-program/#monitoring-flink-with-prometheus), _2018-09-04_ (:video_camera: [Video](https://www.youtube.com/watch?v=vesj-ghLimA) :page_facing_up: [Slides](https://www.slideshare.net/MaximilianBode1/monitoring-flink-with-prometheus))
* [Spark & Hadoop User Group Munich](https://www.meetup.com/de-DE/Hadoop-User-Group-Munich/events/252393503/), _2018-09-26_

The blog post [Flink and Prometheus: Cloud-native monitoring of streaming applications](https://flink.apache.org/features/2019/03/11/prometheus-monitoring.html) explains how to run the demo yourself.

## Getting Started

### Startup
```
./gradlew composeUp
```

### Web UIs
- [Flink JobManager](http://localhost:8081/#/overview)
- [Prometheus](http://localhost:9090/graph)
- [Grafana](http://localhost:3000) (credentials _admin:flink_)
- Prometheus endpoints
    - [Job Manager](http://localhost:9249/metrics)
    - [Task Manager 1](http://localhost:9250/metrics)
    - [Task Manager 2](http://localhost:9251/metrics)

## Built With

- [Apache Flink](https://flink.apache.org)
- [Prometheus](https://prometheus.io)
- [Grafana](https://grafana.com)
- [docker-compose](https://docs.docker.com/compose/) – provisioning of the test environment
- [Gradle](https://gradle.org) with [kotlin-dsl](https://github.com/gradle/kotlin-dsl)
    - [gradle-testsets-plugin](https://github.com/unbroken-dome/gradle-testsets-plugin)
    - [shadow](https://github.com/johnrengelman/shadow)
    - [spotless](https://github.com/diffplug/spotless/tree/master/plugin-gradle)
    - [spotbugs](https://github.com/spotbugs/spotbugs-gradle-plugin)
    - [gradle-docker-compose-plugin](https://github.com/avast/gradle-docker-compose-plugin)
    - [gradle-versions-plugin](https://github.com/ben-manes/gradle-versions-plugin)

## Development
typical tasks:
- verify: `./gradlew check`
- integration tests: `./gradlew integrationTest`
- list outdated dependenices: `./gradlew dependencyUpdates`
- update gradle: `./gradlew wrapper --gradle-version=<x.y>` (twice)
"
eliast/dropwizard-guice-example,master,28,35,2012-11-29T13:58:24Z,131,1,A complete dropwizard example for using Guice,,"dropwizard-guice-example
========================

A complete dropwizard example for using Guice.

```
mvn clean package
java -jar target/hello-guice-*-SNAPSHOT.jar server hello-world.yml
```
"
Leandros/ActionBar-with-Tabs,master,36,19,2012-02-09T19:29:07Z,216,0,Example for ActionBar with Tabs,,"Example Android App for ActionBar with Tabs layout 
==================================================

Visit: http://arvid-g.de

The original article to this example: http://arvid-g.de/12/android-4-actionbar-with-tabs-example
"
GoogTech/design-patterns-in-java,master,38,13,2019-09-21T14:18:46Z,102,0,:coffee: 📖 使用通俗易懂的案例，类图，及配套学习笔记来详解 Java 的二十三种设计模式 !,classdiagram examples java-design-patterns jdk11 learning-notes maven,"### 配套博客学习笔记 : https://goog.tech/blog/tags/design-and-pattern

> 参考书籍（ 推荐 ） : `《Java设计模式 - 刘伟》`，`《图解设计模式 - [日]结城浩》`



### 创建型模式

:heavy_check_mark: `简单工厂模式( Simple Factor Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/06/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BSimple-Factory-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/simple_factory_pattern)

:heavy_check_mark: `工厂方法模式( Factory Method Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/05/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BFactory-Method-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/factory_method_pattern)

:heavy_check_mark: `抽象工厂模式( Abstract Factroy Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/07/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BAbstract-Factory-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/abstract_factory_pattern)

:heavy_check_mark: `建造者模式( Builder Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/17/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BBuilder-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/builder_pattern)

:heavy_check_mark: `单例模式( Singleton Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/06/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BSingleton-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/singleton_pattern)

:heavy_multiplication_x: `原型模式( Prototype Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)



### 结构型模式

:heavy_check_mark: `适配器模式( Adapter Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/03/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BAdapter-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/adapter_pattern)

:heavy_check_mark: `代理模式( Proxy Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/25/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BProxy-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/froxy_pattern)

:heavy_check_mark: `组合模式( Composite Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/11/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BComposite-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/composite_pattern)

:heavy_check_mark: `装饰模式( Decorator Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/08/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BDecorator-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/decorator_pattern)

:heavy_check_mark: `外观模式( Facade Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/12/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BFacade-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/facade_pattern)

:heavy_multiplication_x: `桥接模式( Bridge Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)

:heavy_multiplication_x: `享元模式( Flyweight Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)



### 行为型模式

:heavy_check_mark: `命令模式( Command Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/20/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BCommand-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/command_pattern)

:heavy_check_mark: `迭代器模式( Iterator Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/02/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BIterator-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/iterator_pattern)

:heavy_check_mark: `模板方法模式( Template Method Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/04/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BTemplate-Method-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/template_method_pattern)

:heavy_check_mark: `观察者模式( Observer Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/09/28/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BObserver-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/observer_pattern)

:heavy_multiplication_x: `中介者模式( Mediator Pattern )`
> :memo: [学习笔记](https://goog.tech/blog/2019/10/10/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BMediator-Pattern/) ，[示例程序](https://github.com/GoogTech/design-patterns-in-java/tree/master/design-patterns/src/main/java/pers/huangyuhui/mediator_pattern)

:heavy_multiplication_x: `职责链模式( Chain of Responsibility Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)

:heavy_multiplication_x: `解释器模式( Interpreter Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)

:heavy_multiplication_x: `备忘录模式( Memento Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)

:heavy_multiplication_x: `状态模式( State Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)

:heavy_multiplication_x: `策略模式( Strategy Pattern )` 
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)

:heavy_multiplication_x: `访问者模式( Visitor Pattern )`
> :memo: [学习笔记updating](demo) ，[示例程序updating](demo)
"
asbnotebook/spring-boot,master,111,201,2019-06-12T07:43:42Z,1050,18,List of example codes related to spring boot. More details are available at : https://asbnotebook.com,,"This is list of spring boot example code which is posted on https://asbnotebook.com.
"
ricardojlrufino/eclipse-cdt-standalone-astparser,master,63,24,2014-12-15T02:17:55Z,4776,2,Example using the Eclipse CDT Parser API,,"eclipse-cdt-standalone-astparser
========

Example of Using the Eclipse CDT Parser API

Another usage sample is: https://github.com/ricardojlrufino/cplus-libparser

Dependencies
====
 *already included (but you can grab the new versions)* 
 
* org.eclipse.cdt.core_5.6.0.201402142303.jar
* org.eclipse.equinox.common_3.6.200.v20130402-1505.jar

Preview
====

![Preview](https://github.com/ricardojlrufino/eclipse-cdt-standalone-astparser/raw/master/docs/preview.png ""Preview"")"
plaa/mongo-spark,master,90,58,2014-02-16T13:46:37Z,316,1,Example application on how to use mongo-hadoop connector with Spark,,"mongo-spark
===========

Example application on how to use [mongo-hadoop][1] connector with [Apache Spark][2].

Read more details at http://codeforhire.com/2014/02/18/using-spark-with-mongodb/

[1]: https://github.com/mongodb/mongo-hadoop
[2]: https://spark.incubator.apache.org/


Prerequisites
-------------

* MongoDB installed and running on localhost
* Scala 2.10 and SBT installed


Running
-------

Import data into the database, run either `JavaWordCount` or `ScalaWordCount` and print the results.

    mongoimport -d beowulf -c input beowulf.json
    sbt 'run-main JavaWordCount'
    sbt 'run-main ScalaWordCount'
    mongo beowulf --eval 'printjson(db.output.find().toArray())' | less


License
-------

The code itself is released to the public domain according to the [Creative Commons CC0][3].

The example files are based on [Beowulf][4] from Project Gutenberg and is under its corresponding license.

[3]: http://creativecommons.org/publicdomain/zero/1.0/
[4]: http://www.gutenberg.org/ebooks/981
"
allure-examples/junit4-java-maven,main,55,73,2013-11-26T14:37:25Z,1182,0,"Example of Allure Report usage with JUnit 4, Java and Maven",allure allure-report example java junit junit4 jupiter maven,"# Allure Example

> Example of Allure Report usage with JUnit 4, Java and Maven

<!--<img src=""https://allurereport.org/public/img/allure-report.svg"" alt=""Allure Report logo"" style=""float: right"" />-->

- Learn more about Allure Report at https://allurereport.org
- 📚 [Documentation](https://allurereport.org/docs/) – discover official documentation for Allure Report
- ❓ [Questions and Support](https://github.com/orgs/allure-framework/discussions/categories/questions-support) – get help from the team and community
- 📢 [Official annoucements](https://github.com/orgs/allure-framework/discussions/categories/announcements) – be in touch with the latest updates
- 💬 [General Discussion ](https://github.com/orgs/allure-framework/discussions/categories/general-discussion) – engage in casual conversations, share insights and ideas with the community

---

The generated report is available here: [https://allure-examples.github.io/junit4-java-maven](https://allure-examples.github.io/junit4-java-maven/)
"
Dinnerbone/BukkitFullOfMoon,master,33,19,2011-06-06T17:45:17Z,168,1,Custom generator example for Bukkit,,
k33ptoo/Drapo-Dashboard-JavaFX,master,103,54,2018-04-17T11:09:10Z,356,0,A JavaFX example based on Drapo's dashboard an inspiration ui.,javafx javafx-application javafx-desktop-apps javafx-gui,"# Drapo-Dashboard-JavaFX
A JavaFX example based on Drapo's dashboard an inspiration ui.
Clone and do your thing.

![alt text](https://github.com/k33ptoo/Drapo-Dashboard-JavaFX/blob/master/images/img1.png)

Check out - https://dribbble.com/shots/3750197-Drapo-Pro-s-dashboard?utm_source=Pinterest_Shot&amp;utm_campaign=drapo&amp;utm_content=Drapo%20Pro%27s%20dashboard&amp;utm_medium=Social_Share

Catch me outside.
* https://www.facebook.com/keeptoo.ui.ux/
* https://www.youtube.com/KeepToo
"
HMS-Core/hms-ml-demo,master,347,120,2020-05-22T01:55:19Z,240209,18,"HMS ML Demo provides an example of integrating Huawei ML Kit service into applications. This example demonstrates how to integrate services provided by ML Kit, such as face detection, text recognition, image segmentation, asr, and tts. ",asr audio-file-transcription bank-card-recognition classification deep-learning document face-detection face-recognition hms huawei id-card-recognition image-segmentation kotlin-android language-detection machine-learning object-detection-and-tracking ocr text-to-speech text-translation tts-android,"# hms-ml-demo

[![License](https://img.shields.io/badge/Docs-hmsguides-brightgreen)](https://developer.huawei.com/consumer/en/doc/development/hiai-Guides/service-introduction-0000001050040017) 

English | [中文](https://github.com/HMS-Core/hms-ml-demo/blob/master/README_ZH.md)

## Introduction

This project includes multiple demo apps that showcase the capabilities of the [HUAWEI ML Kit](https://developer.huawei.com/consumer/en/doc/development/hiai-Guides/service-introduction-0000001050040017).

There are 2 main directories:

- [MLKit-Sample](https://github.com/HMS-Core/hms-ml-demo/tree/master/MLKit-Sample) contains a scenario-based demo. To directly download and install Android binaries, scan the QR codes [here](https://developer.huawei.com/consumer/en/doc/development/hiai-Examples/sample-code-0000001050265470) 

- [ApplicationCases](https://github.com/HMS-Core/hms-ml-demo/tree/master/ApplicationCases) contains various application cases

  

## Technical Support

If you are still evaluating HMS Core, obtain the latest information about HMS Core and share your insights with other developers at [Reddit](https://www.reddit.com/r/HuaweiDevelopers/.).

- To resolve development issues, please go to [Stack Overflow](https://stackoverflow.com/questions/tagged/huawei-mobile-services?tab=Votes). You can ask questions below the `huawei-mobile-services` tag, and Huawei R&D experts can solve your problem online on a one-to-one basis.
- To join the developer discussion, please visit [Huawei Developer Forum](https://forums.developer.huawei.com/forumPortal/en/forum/hms-core).

If you have problems using the sample code, submit [issues](https://github.com/HMS-Core/hms-ml-demo/issues) and [pull requests](https://github.com/HMS-Core/hms-ml-demo/pulls) to the repository.
"
albertattard/java-fork-join-example,master,28,26,2015-03-14T14:50:47Z,328,0,Java Creed - Java Fork Join Example,,"Java 7 introduced a new type of `ExecutorService` ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html)) called **Fork/Join Framework** ([Tutorial](https://docs.oracle.com/javase/tutorial/essential/concurrency/forkjoin.html)), which excels in handling recursive algorithms.  Different from other implementations of the `ExecutorService`, the Fork/Join Framework uses a work-stealing algorithm ([Paper](http://gee.cs.oswego.edu/dl/papers/fj.pdf)), which maximise the threads utilisation, and provides a simpler way to deal with tasks which spawn other tasks (referred to as _subtasks_).

All code listed below is available at: [https://github.com/javacreed/java-fork-join-example](https://github.com/javacreed/java-fork-join-example).  Most of the examples will not contain the whole code and may omit fragments which are not relevant to the example being discussed.  The readers can download or view all code from the above link.

This article provides a brief description of what is referred to as traditional executor service (so to called them) and how these work.  It then introduces the Fork/Join Framework and describes how this differentiates from the traditional executor service.  The third section in this article shows a practical example of the Fork/Join Framework and demonstrates most of its main components.

## Executor Service

A bank, or post office, has several counters from where the customers are served at the branches.  When a counter finishes with the current customer, the next customer in the queue will take its place and the person behind the counter, also referred to as the _employee_, starts serving the new customer.  The employee will only serve one customer at a given point in time and the customers in the queue need to wait for their turn.  Furthermore, the employees are very patient and will never ask their customers to leave or step aside, even if these are waiting for something else to happen.  The following image shows a simple view of the customers waiting and the employees serving the customers at the head of the queue.

![Customers waiting for their turn](img/Customers-waiting-for-their-turn.png)

Something similar happens in a multithreaded program where the `Thread`s ([Java Doc](http://docs.oracle.com/javase/7/docs/api/java/lang/Thread.html)) represents the employees and the tasks to be carried out are the customers.  The following image is identical to the above, with just the labels updated to use the programming terminology.

![Threads and Tasks](img/Threads-and-Tasks.png)

This should help you relate these two aspects and better visualise the scenario being discussed.

Most of the thread pools ([Tutorial](https://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html)) and executor services work in this manner.  A `Thread` is assigned a _task_ and will only move to the next _task_ once the one at hand is finished.  Tasks can take quite a long time to finish and may block waiting for something else to happen.  This works well in many cases, but fails badly with problems that need to be solved recursively.

Let us use the same analogy that we used before with the customer waiting in the queue.  Say that _Customer 1_, who is being served by _Employee 1_, needs some information from _Customer 6_, who is not yet in the queue.  He or she (_Customer 1_) calls their friend (_Customer 6_) and waits for him or her (_Customer 6_) to come to the bank.  In the meantime, _Customer 1_ stays at the counter occupying _Employee 1_.  As mentioned before, the employees are very patient and will never send a customer back to the queue or ask them to step aside until all his or her dependencies are resolved.  _Customer 6_ arrives and queues as shown below.

![Old Customer waiting for New Customer](img/Old-Customer-waiting-for-New-Customer.png)

With _Customer 1_ still occupying an employee, and for the sake of this argument the other customers, _Customer 2_ and _Customer 3_, too do the same (that is wait for something which is queued), then we have a deadlock.  All employees are occupied by customers that are waiting for something to happen.  Therefore the employees will never be free to serve the other customers.

In this example we saw a weakness of the traditional executor services when dealing with tasks, which in turn depend on other tasks created by them (referred to as subtasks).  This is very common in recursive algorithms such as Towers of Hanoi ([Wiki](http://en.wikipedia.org/wiki/Tower_of_Hanoi)) or exploring a tree like data structure (calculating the total size of a directory).  The Fork/Join Framework was designed to address such problems as we will see in the following section.  Later on in this article we will also see an example of the problem discussed in this section.

## Fork/Join Framework

The main weakness of the traditional executor service implementations when dealing with tasks, which in turn depend on other subtasks, is that a thread is not able to put a task back to the queue or to the side and then serves/executes an new task.  The Fork/Join Framework addresses this limitation by introducing another layer between the tasks and the threads executing them, which allows the threads to put blocked tasks on the side and deal with them when all their dependencies are executed.  In other words, if _Task 1_ depends on _Task 6_, which task (_Task 6_) was created by _Task 1_, then _Task 1_ is placed on the side and is only executed once _Task 6_ is executed.  This frees the thread from _Task 1_, and allows it to execute other tasks, something which is not possible with the traditional executor service implementations.

This is achieved by the use of _fork_ and _join_ operations provided by the framework (hence the name Fork/Join).  _Task 1_ forks _Task 6_ and then joins it to wait for the result.  The fork operation puts _Task 6_ on the queue while the join operation allows _Thread 1_ to put _Task 1_ on the side until _Task 6_ completes.  This is how the fork/join works, fork pushes new things to the queue while the join causes the current task to be sided until it can proceed, thus blocking no threads.

The Fork/Join Framework makes use of a special kind of thread pool called `ForkJoinPool` ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ForkJoinPool.html)), which differentiates it from the rest.  `ForkJoinPool` implements a work-stealing algorithm and can execute `ForkJoinTask` ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ForkJoinTask.html)) objects.  The `ForkJoinPool` maintains a number of threads, which number is typically based on the number of CPUs available.  Each thread has a special kind of queue, `Deque`s ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/Deque.html)), where all its tasks are placed.  This is quite an important point to understand.  The threads do not share a common queue, but each thread has its own queue as shown next.

![Threads and their Queues](img/Threads-and-their-Queues.png)

The above image illustrates another queue that each thread has (lower part of the image).  This queue, so to call it, allows the threads to put aside tasks which are blocked waiting for something else to happen.  In other words, if the current task cannot proceed (as it performs a _join_ on a subtask), then it is placed on this queue until all of its dependencies are ready.

New tasks are added to the thread's queue (using the _fork_ operation) and each thread always processes the last task added to its queue.  This is quite important.  If the queue of a thread has two tasks, the last task added to the queue is processed first.  This is referred to as last in first out, LIFO ([Wiki](http://en.wikipedia.org/wiki/LIFO_%28computing%29)).  

![Task 1 and Task 2](img/Task1-and-Task2.png)

In the above image, _Thread 1_ has two tasks in its queue, where _Task 1_ was added to the queue before _Task 2_.  Therefore, _Task 2_ will be executed first by _Thread 1_ and then it executes _Task 1_.   Any idle threads can take tasks from the other threads queues if available, that is, work-stealing.  A thread will always steal oldest tasks from some other thread's queue as shown in the following image.

![Task 1 was stolen by Thread 2](img/Task-1-was-stolen-by-Thread-2.png)

As shown in the above image, _Thread 2_ stole the oldest task, _Task 1_, from _Thread 1_.  As a rule of thumb, threads will always attempt to steal from their neighbouring thread to minimise the contention that may be created during the work stealing.

The order in which tasks are executed and stolen is quite important.  Ideally, work-stealing does not happen a lot as this has a cost.  When a task is moved from one thread to another, the context related with this task needs to be moved from one thread's stack to another.  The threads may be (and the Fork/Join framework spread work across all CPUs) on another CPU.  Moving thread context from one CPU to another can be even slower.  Therefore, the Fork/Join Framework minimises this as described next.

A recursive algorithm starts with a large problem and applies a divide-and-conquer technique to break down the problem into smaller parts, until these are small enough to be solved directly.  The first task added to the queue is the largest task.  The first task will break the problem into a set of smaller tasks, which tasks are added to the queue as shown next.

![Tasks and Subtasks](img/Tasks-and-Subtasks.png)

_Task 1_ represents our problem, which is divided into two tasks,  _Task 2_ is small enough to solve as is, but _Task 3_ needs to be divided further.  Tasks _Task 4_ and _Task 5_ are small enough and these require no further splitting.  This represents a typical recursive algorithm which can be split into smaller parts and then aggregates the results when ready.  A practical example of such algorithm is calculating the size of a directory.  We know that the size of a directory is equal to the size of its files.

![Directories and Files](img/Directories-and-Files.png)

Therefore the size of _Dir 1_ is equal to the size of _File 2_ plus the size of _Dir 3_.  Since _Dir 3_ is a directory, its size is equal to the size of its content.  In other words, the size of _Dir 3_ is equal to the size of _File 4_ plus the size of _File 5_.

Let us see how this is executed.  We start with one task, that is, to compute the size of directory as shown in the following image.

![Step 1 - Start with Task 1](img/Step-1-Start-with-Task-1.png)

_Thread 1_ will take _Task 1_ which tasks forks two other subtasks.  These tasks are added to the queue of _Thread 1_ as shown in the next image.

![Step 2 - Add subtasks Task 2 and Task 3](img/Step-2-Add-subtasks-Task-2-and-Task-3.png)

_Task 1_ is waiting for the subtasks, _Task 2_ and _Task 3_ to finish, thus is pushed aside which frees _Thread 1_.  To use better terminology, _Task 1_ joins the subtasks _Task 2_ and _Task 3_.  _Thread 1_ starts executing _Task 3_ (the last task added to its queue), while _Thread 2_ steals _Task 2_.  

![Step 3 - Thread 2 steals Task 2](img/Step-3-Thread-2-steals-Task-2.png)

Note that _Thread 1_ has already started processing its second task, while _Thread 3_ is still idle.  As we will see later on, the threads will not perform the same number of work and the first thread will always produce more than the last thread.  _Task 3_ forks two more subtasks which are added to the queue of the thread that is executing it.  Therefore, two more tasks are added to _Thread 1_'s queue.  _Thread 2_, ready from _Task 2_, steals again another task as shown next.

![Step 4 - Thread 2 steals Task 4](img/Step-4-Thread-2-steals-Task-4.png)

In the above example, we saw that _Thread 3_ never executed a task.  This is because we only have very little subtasks.  Once _Task 4_ and _Task 5_ are ready, their results are used to compute _Task 3_ and then _Task 1_.

As hinted before, the work is not evenly distributed among threads.  The following chart shows how the work is distributed amongst threads when calculating the size of a reasonably large directory.

![Work Distribution](img/Work-Distribution.png)

In the above example four threads were used.  As expected, Thread 1 performs almost 40% of the work while Thread 4 (the last thread) performs slightly more than 5% of the work.  This is another important principle to understand.  The Fork/Join Framework will not distribute work amongst threads evenly and will try to minimise the number of threads utilised.  The second threads will only take work from the first thread is this is not cooping.  As mentioned before, moving tasks between threads has a cost which the framework tries to minimise.

This section described on some detail how the Fork/Join Framework works and how threads steal work from other threads' queue.  In the following section we will see several practical example of the Fork/Join Framework and will analyse the obtained results.

## Calculate Directory Total Size

To demonstrate the use of the Fork/Join Framework, we will calculate the size of a directory, which problem can be solved recursively.  The size of file can determined by the method `length()` ([Java Doc](http://docs.oracle.com/javase/7/docs/api/java/io/File.html#length())).  The size of a directory is equal to the size of all its files.  

We will use several approaches to calculate the size of a directory, some of which will use the Fork/Join Framework, and we will analyse the obtained results in each case.

## Using a Single Thread (no-concurrency)

The first example will not make use of threads and simple defines the algorithm to the used.

```java
package com.javacreed.examples.concurrency.part1;

import java.io.File;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class DirSize {

  private static final Logger LOGGER = LoggerFactory.getLogger(DirSize.class);

  public static long sizeOf(final File file) {
    DirSize.LOGGER.debug(""Computing size of: {}"", file);

    long size = 0;

    /* Ignore files which are not files and dirs */
    if (file.isFile()) {
      size = file.length();
    } else {
      final File[] children = file.listFiles();
      if (children != null) {
        for (final File child : children) {
          size += DirSize.sizeOf(child);
        }
      }
    }

    return size;
  }
}
```

The class `DirSize ` has a single method called `sizeOf()`, which method takes a `File` ([Java Doc](http://docs.oracle.com/javase/7/docs/api/java/io/File.html)) instance as its argument.  If this instance is a file, then the method returns the file's length otherwise, if this is a directory, this method calls the method `sizeOf()` for each of the files within the directory and returns the total size.

The following example shows how to run this example, using the file path as defined by `FilePath.TEST_DIR` constant.

```java
package com.javacreed.examples.concurrency.part1;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.javacreed.examples.concurrency.utils.FilePath;

public class Example1 {

  private static final Logger LOGGER = LoggerFactory.getLogger(Example1.class);

  public static void main(final String[] args) {
    final long start = System.nanoTime();
    final long size = DirSize.sizeOf(FilePath.TEST_DIR);
    final long taken = System.nanoTime() - start;

    Example1.LOGGER.debug(""Size of '{}': {} bytes (in {} nano)"", FilePath.TEST_DIR, size, taken);
  }
}
```

The above example will compute the size of the directory and will print all visited files before printing the total size.  The following fragment only shows the last line which is the size of the _downloads_ directory under a test folder (`C:\Test`) together with the time taken to compute the size.

```
...
16:55:38.045 [main] INFO Example1.java:38 - Size of 'C:\Test\': 113463195117 bytes (in 4503253988 nano)
```

To disable the logs for each file visited, simple change the log level to `INFO` (in the `log4j.properties`) and the logs will only show the final results.

```
log4j.rootCategory=warn, R
log4j.logger.com.javacreed=info, stdout
```

Please note that the logging will only make things slower.  In fact if you run the example without logs (or the logs set to `INFO`), the size of the directory is computed much faster.

In order to obtain a more reliable result, we will run the same test several times and return the average time taken as shown next.

```java
package com.javacreed.examples.concurrency.part1;

import java.util.concurrent.TimeUnit;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.javacreed.examples.concurrency.utils.FilePath;
import com.javacreed.examples.concurrency.utils.Results;

public class Example2 {

  private static final Logger LOGGER = LoggerFactory.getLogger(Example1.class);

  public static void main(final String[] args) {
    final Results results = new Results();
    for (int i = 0; i < 5; i++) {
      results.startTime();
      final long size = DirSize.sizeOf(FilePath.TEST_DIR);
      final long taken = results.endTime();
      Example2.LOGGER.info(""Size of '{}': {} bytes (in {} nano)"", FilePath.TEST_DIR, size, taken);
    }

    final long takenInNano = results.getAverageTime();
    Example2.LOGGER.info(""Average: {} nano ({} seconds)"", takenInNano, TimeUnit.NANOSECONDS.toSeconds(takenInNano));
  }
}
```

The same test is executed five times and the average result is printed last as shown next.

```
16:58:00.496 [main] INFO Example2.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 4266090211 nano)
16:58:04.728 [main] INFO Example2.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 4228931534 nano)
16:58:08.947 [main] INFO Example2.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 4224277634 nano)
16:58:13.205 [main] INFO Example2.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 4253856753 nano)
16:58:17.439 [main] INFO Example2.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 4235732903 nano)
16:58:17.439 [main] INFO Example2.java:46 - Average: 4241777807 nano (4 seconds)
```

### RecursiveTask

The Fork/Join Framework provides two types of tasks, the `RecursiveTask` ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/RecursiveTask.html)) and the `RecursiveAction` ([Java Doc](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/RecursiveAction.html)).  In this section we will only talk about the `RecursiveTask`.  The `RecursiveAction` is discussed later on.

A `RecursiveTask` is a task that when executed it returns a value.  Therefore, such task returns the result of the computation.  In our case, the task returns the size of the file or directory it represents.  The class `DirSize` was modified to make use of `RecursiveTask` as shown next.

```java
package com.javacreed.examples.concurrency.part2;

import java.io.File;
import java.util.ArrayList;
import java.util.List;
import java.util.Objects;
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.RecursiveTask;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class DirSize {

  private static final Logger LOGGER = LoggerFactory.getLogger(DirSize.class);

  private static class SizeOfFileTask extends RecursiveTask<Long> {

    private static final long serialVersionUID = -196522408291343951L;

    private final File file;

    public SizeOfFileTask(final File file) {
      this.file = Objects.requireNonNull(file);
    }

    @Override
    protected Long compute() {
      DirSize.LOGGER.debug(""Computing size of: {}"", file);

      if (file.isFile()) {
        return file.length();
      }

      final List<SizeOfFileTask> tasks = new ArrayList<>();
      final File[] children = file.listFiles();
      if (children != null) {
        for (final File child : children) {
          final SizeOfFileTask task = new SizeOfFileTask(child);
          task.fork();
          tasks.add(task);
        }
      }

      long size = 0;
      for (final SizeOfFileTask task : tasks) {
        size += task.join();
      }

      return size;
    }
  }

  public static long sizeOf(final File file) {
    final ForkJoinPool pool = new ForkJoinPool();
    try {
      return pool.invoke(new SizeOfFileTask(file));
    } finally {
      pool.shutdown();
    }
  }

  private DirSize() {}

}
```

Let us break this class into smaller parts and describe each separately.

1. The class has a private constructor because it was not meant to be initialised.  Therefore there is no point to initialise it (creating objects of this type) and in order to prevent someone to initialising it, we made the constructor `private`.  All methods are static and these can be called against the class directly.

    ```java
      private DirSize() {}
    ```
1. The method `sizeOf()` does not compute the size of the file or directory.  Instead it creates an instance of the `ForkJoinPool` and starts the computational process.  It waits for the directory size to be computed and finally it shut down the pool before exiting.

    ```java
      public static long sizeOf(final File file) {
        final ForkJoinPool pool = new ForkJoinPool();
        try {
          return pool.invoke(new SizeOfFileTask(file));
        } finally {
          pool.shutdown();
        }
      }
    ```

    The threads created by the `ForkJoinPool` are daemon threads by default.  Some articles advice against the need of shutting this pool down since these threads will not prevent the VM from shutting down.  With that said, I recommend to shut down and dispose of any objects properly when these are no longer needed.  These daemon threads may be left idle for long time even when these are not required anymore.

1. The method `sizeOf()` creates an instance `SizeOfFileTask`, which class extends `RecursiveTask<Long>`.  Therefore the invoke method will return the objects/value returned by this task.

    ```java
          return pool.invoke(new SizeOfFileTask(file));
    ```

    Note that the above code will block until the size of the directory is computed.  In other words the above code will wait for the task (and all the subtasks) to finish working before continuing.

1. The class `SizeOfFileTask` is an inner class within the `DirSize` class.

    ```java
      private static class SizeOfFileTask extends RecursiveTask<Long> {

        private static final long serialVersionUID = -196522408291343951L;

        private final File file;

        public SizeOfFileTask(final File file) {
          this.file = Objects.requireNonNull(file);
        }

        @Override
        protected Long compute() {
          /* Removed for brevity */
        }
      }
    ```

    It takes the file (which can be a directory) for which size is to be computed as argument of its sole constructor, which file cannot be `null`.  The `compute()` method is responsible from computing the work of this task.  In this case the size of the file or directory, which method is discussed next.

1. The `compute()` method determines whether the file passed to its constructor is a file or directory and acts accordingly.

    ```java
        @Override
        protected Long compute() {
          DirSize.LOGGER.debug(""Computing size of: {}"", file);

          if (file.isFile()) {
            return file.length();
          }

          final List<SizeOfFileTask> tasks = new ArrayList<>();
          final File[] children = file.listFiles();
          if (children != null) {
            for (final File child : children) {
              final SizeOfFileTask task = new SizeOfFileTask(child);
              task.fork();
              tasks.add(task);
            }
          }

          long size = 0;
          for (final SizeOfFileTask task : tasks) {
            size += task.join();
          }

          return size;
        }
    ```

    If the file is a file, then the method simply returns its size as shown next.

    ```java
          if (file.isFile()) {
            return file.length();
          }
    ```

    Otherwise, if the file is a directory, it lists all its sub-files and creates a new instance of `SizeOfFileTask` for each of these sub-files.

    ```java
          final List<SizeOfFileTask> tasks = new ArrayList<>();
          final File[] children = file.listFiles();
          if (children != null) {
            for (final File child : children) {
              final SizeOfFileTask task = new SizeOfFileTask(child);
              task.fork();
              tasks.add(task);
            }
          }
    ```

    For each instance of the created `SizeOfFileTask`, the `fork()` method is called.  The `fork()` method causes the new instance of `SizeOfFileTask` to be added to this thread's queue.  All created instances of `SizeOfFileTask` are saved in a list, called `tasks`.  Finally, when all tasks are forked, we need to wait for them to finish summing up their values.

    ```java
          long size = 0;
          for (final SizeOfFileTask task : tasks) {
            size += task.join();
          }

          return size;
    ```

    This is done by the `join()` method.  This ` join()` will force this task to stop, step aside if needs be, and wait for the subtask to finish.  The value returned by all subtasks is added to the value of the variable `size` which is returned as the size of this directory.

The Fork/Join Framework is more complex when compared with the simpler version which does not use multithreading.  This is a fair point, but the simpler version is 4 times slower.  The Fork/Join example took on average a second to compute the size, while the non-threading version took 4 seconds on average as shown next.

```
16:59:19.557 [main] INFO Example3.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 2218013380 nano)
16:59:21.506 [main] INFO Example3.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 1939781438 nano)
16:59:23.505 [main] INFO Example3.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 2004837684 nano)
16:59:25.363 [main] INFO Example3.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 1856820890 nano)
16:59:27.149 [main] INFO Example3.java:42 - Size of 'C:\Test\': 113463195117 bytes (in 1782364124 nano)
16:59:27.149 [main] INFO Example3.java:46 - Average: 1960363503 nano (1 seconds)
```

In this section we saw how multithreading help us in improving the performance of our program.  In the next section we will see the how inappropriate use of multithreading can make things worse.

### ExecutorService

In the previous example we saw how concurrency improved the performance of our algorithm.  When misused, multithreading can provide poor results as we will see in this section.  We will try to solve this problem using a traditional executor service.

**Please note that the code shown in this section is broken and does not work.  It will hang forever and is only included for demonstration purpose.**

The class `DirSize` was modified to work with `ExecutorService` and `Callable` ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Callable.html)).

```java
package com.javacreed.examples.concurrency.part3;

import java.io.File;
import java.util.ArrayList;
import java.util.List;
import java.util.Objects;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * This example is broken and suffers from deadlock and is only included for documentation purpose.
 *
 * @author Albert Attard
 */
public class DirSize {

  private static class SizeOfFileCallable implements Callable<Long> {

    private final File file;
    private final ExecutorService executor;

    public SizeOfFileCallable(final File file, final ExecutorService executor) {
      this.file = Objects.requireNonNull(file);
      this.executor = Objects.requireNonNull(executor);
    }

    @Override
    public Long call() throws Exception {
      DirSize.LOGGER.debug(""Computing size of: {}"", file);
      long size = 0;

      if (file.isFile()) {
        size = file.length();
      } else {
        final List<Future<Long>> futures = new ArrayList<>();
        for (final File child : file.listFiles()) {
          futures.add(executor.submit(new SizeOfFileCallable(child, executor)));
        }

        for (final Future<Long> future : futures) {
          size += future.get();
        }
      }

      return size;
    }
  }

  public static <T> long sizeOf(final File file) {
    final int threads = Runtime.getRuntime().availableProcessors();
    DirSize.LOGGER.debug(""Creating executor with {} threads"", threads);
    final ExecutorService executor = Executors.newFixedThreadPool(threads);
    try {
      return executor.submit(new SizeOfFileCallable(file, executor)).get();
    } catch (final Exception e) {
      throw new RuntimeException(""Failed to calculate the dir size"", e);
    } finally {
      executor.shutdown();
    }
  }

  private static final Logger LOGGER = LoggerFactory.getLogger(DirSize.class);

  private DirSize() {}

}
```

The idea is very much the same as before.  The inner class `SizeOfFileCallable` extends `Callable<Long>` and delegates the computation of its subtasks to the instance of `ExecutorService` passed to its constructor.  This is not required when dealing with the `RecursiveTask`, was the latter automatically adds its subclasses to the thread's queue for execution.

We will not go through this in more detail to keep this article focused on the Fork/Join Framework.  As mentioned already, this method blocks once all threads are occupied as shown next.

```
17:22:39.216 [main] DEBUG DirSize.java:78 - Creating executor with 4 threads
17:22:39.222 [pool-1-thread-1] DEBUG DirSize.java:56 - Computing size of: C:\Test\
17:22:39.223 [pool-1-thread-2] DEBUG DirSize.java:56 - Computing size of: C:\Test\Dir 1
17:22:39.223 [pool-1-thread-4] DEBUG DirSize.java:56 - Computing size of: C:\Test\Dir 2
17:22:39.223 [pool-1-thread-3] DEBUG DirSize.java:56 - Computing size of: C:\Test\Dir 3
```

This example is executed on a Core i5 computer, which has four available processors (as indicated by `Runtime.getRuntime().availableProcessors()` [Java Doc](http://docs.oracle.com/javase/6/docs/api/java/lang/Runtime.html#availableProcessors())).  Once all four threads are occupied, this approach will block forever as we saw in the bank branch example in the beginning of this article.  All threads are occupied and thus cannot be used to solve the other tasks.  One can suggest using more threads.  While that may seem to be a solution, the Fork/Join Framework solved the same problem using only four threads.  Furthermore, threads are not cheap and one should not simply spawn thousands of threads just because he or she chooses an inappropriate technique.

While the phrase multithreading is overused in the programming community, the choice of multithreading technique is important as some options simply do not work in certain scenarios as we saw above.

### RecursiveAction

The Fork/Join Framework supports two types of tasks.  The second type of task is the `RecursiveAction`.  These types of tasks are not meant to return anything.  These are ideal for cases where you want to do an action, such as delete a file, without returning anything.  In general you cannot delete an empty directory.  First you need to delete all its files first.  In this case the `RecursiveAction` can be used where each action either deletes the file, or first deletes all directory content and then deletes the directory itself.

Following is the final example we have in this article.  It shows the modified version of the `DirSize`, which makes use of the `SizeOfFileAction` inner class to compute the size of the directory.

```java
package com.javacreed.examples.concurrency.part4;

import java.io.File;
import java.util.Objects;
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.ForkJoinTask;
import java.util.concurrent.RecursiveAction;
import java.util.concurrent.atomic.AtomicLong;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class DirSize {

  private static class SizeOfFileAction extends RecursiveAction {

    private static final long serialVersionUID = -196522408291343951L;

    private final File file;
    private final AtomicLong sizeAccumulator;

    public SizeOfFileAction(final File file, final AtomicLong sizeAccumulator) {
      this.file = Objects.requireNonNull(file);
      this.sizeAccumulator = Objects.requireNonNull(sizeAccumulator);
    }

    @Override
    protected void compute() {
      DirSize.LOGGER.debug(""Computing size of: {}"", file);

      if (file.isFile()) {
        sizeAccumulator.addAndGet(file.length());
      } else {
        final File[] children = file.listFiles();
        if (children != null) {
          for (final File child : children) {
            ForkJoinTask.invokeAll(new SizeOfFileAction(child, sizeAccumulator));
          }
        }
      }
    }
  }

  public static long sizeOf(final File file) {
    final ForkJoinPool pool = new ForkJoinPool();
    try {
      final AtomicLong sizeAccumulator = new AtomicLong();
      pool.invoke(new SizeOfFileAction(file, sizeAccumulator));
      return sizeAccumulator.get();
    } finally {
      pool.shutdown();
    }
  }

  private static final Logger LOGGER = LoggerFactory.getLogger(DirSize.class);

  private DirSize() {}

}
```

This class is very similar to its predecessors.  The main difference lies in the way the final value (the size of the file or directory) is returned.  Remember that the `RecursiveAction` cannot return a value.  Instead, all tasks will share a common counter of type `AtomicLong` and these will increment this common counter instead of returning the size of the file.

Let us break this class into smaller parts and go through each part individually.  We will skip the parts that were already explained before so not to repeat ourselves.

1. The method `sizeOf()` makes use of the `ForkJoinPool` as before.  The common counter, named `sizeAccumulator`, is initialised in this method too and passed to the first task.  This instance will be shared with all subtasks and all will increment this value.

    ```java
      public static long sizeOf(final File file) {
        final ForkJoinPool pool = new ForkJoinPool();
        try {
          final AtomicLong sizeAccumulator = new AtomicLong();
          pool.invoke(new SizeOfFileAction(file, sizeAccumulator));
          return sizeAccumulator.get();
        } finally {
          pool.shutdown();
        }
      }
    ```

    Like before, this method will block until all subtasks are ready, after which returns the total size.

1. The inner class `SizeOfFileAction` extends `RecursiveAction` and its constructor takes two arguments.

    ```java
      private static class SizeOfFileAction extends RecursiveAction {

        private static final long serialVersionUID = -196522408291343951L;

        private final File file;
        private final AtomicLong sizeAccumulator;

        public SizeOfFileAction(final File file, final AtomicLong sizeAccumulator) {
          this.file = Objects.requireNonNull(file);
          this.sizeAccumulator = Objects.requireNonNull(sizeAccumulator);
        }

        @Override
        protected void compute() {
          /* Removed for brevity */
        }
      }
    ```

    The first argument is the file (or directory) which size will be computed.  The second argument is the shared counter.

1. The compute method is slightly simpler here as it does not have to wait for the subtasks.  If the given file is a file, then it increments the common counter (referred to as `sizeAccumulator`).  Otherwise, if this file is a directory, it forks the new instances of `SizeOfFileAction` for each child file.

    ```java
        protected void compute() {
          DirSize.LOGGER.debug(""Computing size of: {}"", file);

          if (file.isFile()) {
            sizeAccumulator.addAndGet(file.length());
          } else {
            final File[] children = file.listFiles();
            if (children != null) {
              for (final File child : children) {
                ForkJoinTask.invokeAll(new SizeOfFileAction(child, sizeAccumulator));
              }
            }
          }
        }
    ```

    In this case the method `invokeAll()` ([Java Doc](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ForkJoinTask.html#invokeAll(java.util.concurrent.ForkJoinTask...))) is used to fork the tasks.

This approach takes approximately 11 seconds to complete making it the slowest of all three as shown next.

```
19:04:39.925 [main] INFO Example5.java:40 - Size of 'C:\Test': 113463195117 bytes (in 11445506093 nano)
19:04:51.433 [main] INFO Example5.java:40 - Size of 'C:\Test': 113463195117 bytes (in 11504270600 nano)
19:05:02.876 [main] INFO Example5.java:40 - Size of 'C:\Test': 113463195117 bytes (in 11442215513 nano)
19:05:15.661 [main] INFO Example5.java:40 - Size of 'C:\Test': 113463195117 bytes (in 12784006599 nano)
19:05:27.089 [main] INFO Example5.java:40 - Size of 'C:\Test': 113463195117 bytes (in 11428115064 nano)
19:05:27.226 [main] INFO Example5.java:44 - Average: 11720822773 nano (11 seconds)
```

This may be a surprise to many.  How is this possible, when multiple threads were used?  This is a common misconception.  Multithreading does not guarantee better performance.  In this case we have a design flaw which ideally we avoid.  The common counter named `sizeAccumulator` is shared between all threads and thus causes contention between threads.  This actually defeats the purpose of the divide and conquer technique as a bottleneck is created.

## Conclusion

This article provided a detailed explanation of the Fork/Join Framework and how this can be used.  It provided a practical example and compared several approaches.  The Fork/Join Framework is ideal for recursive algorithms but it does not distribute the load amongst the threads evenly.  The tasks and subtask should not block on anything else but join and should delegate work using fork.  Avoid any blocking IO operations within tasks and minimise the mutable share state especially modifying the variable as much as possible as this has a negative effect on the overall performance.
"
lisawray/fontbinding,master,771,61,2015-10-20T17:09:15Z,2686,0,A full example of custom fonts in XML using data binding and including font caching.,,"## [Deprecated]
Fonts in XML are now supported by the Android support library as of 26.0, including in styles and themes. I recommend using the support library and IDE integration for all your modern font needs! 
https://developer.android.com/guide/topics/ui/look-and-feel/fonts-in-xml.html#using-support-lib

# fontbinding
Easy custom fonts in XML using [data binding](http://developer.android.com/tools/data-binding/guide.html).

No setup required, no extra Java code, and no custom views.

```xml
<TextView
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    app:font=""@{`alegreya`}""
    />
```
<img src=""https://raw.githubusercontent.com/lisawray/fontbinding/master/screenshot_land.png"" alt=""Drawing"" height=""400px""/>


This example includes a simple font cache that automatically loads names from your `assets/fonts` folder and lazy-loads typefaces.  Just drag and drop font files and use them in XML by their normal or lowercase filenames (e.g. ""Roboto-Italic"" or ""roboto-italic"" for `Roboto-Italic.otf`). That's it!


### Data Binding
Make sure to use the data binding framework to inflate your layout. 
```java
public class MainActivity extends AppCompatActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        DataBindingUtil.setContentView(this, R.layout.activity_main);
    }
}
```

More about data binding: http://developer.android.com/tools/data-binding/guide.html

### Custom Naming
You can set custom names for your fonts, but you don't have to.
```java
FontCache.getInstance().addFont(""alegreya"", ""Alegreya-Regular.ttf"");
```

## Note: 
It's not currently possible to define custom attributes in styles using data binding. If you require this, check out [Calligraphy](https://github.com/chrisjenx/Calligraphy) by Chris Jenx.
"
neo4j-examples/movies-java-bolt,main,89,73,2016-04-14T06:06:53Z,105,9,Neo4j Movies Example application with SparkJava backend using the neo4j-java-driver,bolt cypher graph graph-database java movies-api neo4j,
iriusrisk/zap-webdriver,master,64,38,2014-05-20T17:59:33Z,32670,5,Example security tests using Selenium WebDriver and OWASP ZAP,,"zap-webdriver
=============
Example security tests using JUnit, Selenium WebDriver and OWASP ZAP to test the Bodgeit store (https://code.google.com/p/bodgeit/)
The tests use selenium to navigate and login to the app, then spider the content with ZAP and perform a security scan using ZAP's scanner.  Tests pass or fail based on vulnerabilities found.

Getting started
===============
1. Download and start the [bodgeit store](https://code.google.com/p/bodgeit/) on port 8080
2. Download and start [OWASP ZAP](https://code.google.com/p/zaproxy/wiki/Downloads?tm=2) at least version 2.4 
3. In the ZAP Options change the local proxy port to 8888
4. Download this repository
5. Look through the src/test/java/net/continuumsecurity/ZapScanTest class and check that the static fields match your setup.  In particular, change the CHROME_DRIVER_PATH to point to the chrome driver instance appropriate for your platform, the driver/ directory contains versions for Linux, Mac and Windows.
5. Run: mvn test

Details
=======
The Selenium steps to navigate the application and submit forms is contained in the MyAppNavigation class.  The JUnit testing steps are defined in ZapScanTest.
Keeping these two aspects separate makes test maintenance easier.  If your testing team already has Selenium code to perform navigation (e.g. Page Objects), you can then drop those in to the MyAppNavigation class.

The ZapScanTest class should be regarded as a starting point for your own test cases and it makes some wild assumptions about which alerts to ignore.  If you're going to use these tests as
part of a Continuous Integration/Continuous Delivery process then please make sure that the build will fail for important security vulnerabilities.

For a more comprehensive security testing framework with security requirements specified in plain English and many more pre-written tests, consider the [BDD-Security framework](http://www.continuumsecurity.net/bdd-intro.html) instead.




"
cstew/CustomBehavior,master,86,20,2015-07-09T14:06:10Z,568,3,An example of a custom CoordinatorLayout Behvior,,"Two examples of custom `Behavior`s with `FloatingActionButton` and `CoordinatorLayout`.

Shrink and Rotate

![](https://raw.githubusercontent.com/cstew/CustomBehavior/master/art/fab_shrink.gif)
"
oktadev/auth0-java-oauth-examples,main,27,6,2023-02-06T20:56:20Z,334,1,,,
m-cakir/bubble-sheet-multiple-choice-scanner,master,49,32,2018-04-22T12:36:19Z,2978,2,Bubble sheet multiple choice scanner example with OpenCV,bubble-sheet image-processing java multiple-choice opencv,"# Bubble Sheet Multiple Choice Scanner

Bubble sheet multiple choice scanner example with OpenCV Java (opencv-3.4.0). Not ready for production usage yet.

## Install

Download OpenCV from [official site](https://opencv.org/releases.html). Then add library to project and set VM options as following.

``` 
// native library path 

-Djava.library.path=/opencv/build/lib
```

### Intellij

``` 
File > Project Structure (Ctrl + Alt + Shift + S) > Libraries > + (Alt + Insert) > Select OpenCV jar file 

Run/Debug Configuration -> Application -> VM options
```

## Steps

* Dilate source image for better recognition
* Transform to Grayscale format
* Threshold operation (for recognizing mask/conjuction with bitwise_and)
* Blur filter
* Canny edge algorithm
* Adaptive Thresh (for find main wrapper rectangle & bubbles)
* Recognize main wrapper rectangle according to hierarchy
* Find bubbles with estimated ratio (~17/15.5)
* Sort bubbles by coordinate points
* Recognize which option is filled or empty with bitwise_and and countNonZero

## Sources

* Pdf - [Bubble Sheet Form](sources/bubble-sheet.pdf)
* Inputs - Example Sheet [1](sources/sheet-1.jpg) & [2](sources/sheet-2.jpg)
* Outputs for Sheet [1](sources/result-sheet-1.png) & [2](sources/result-sheet-2.png)

## Running

Run the ""main"" method of Main class.

```
    public static void main(String[] args) throws Exception {

        sout(""...started"");

    (1) Mat source = Imgcodecs.imread(getSource(""sheet-1.jpg""));

        Scanner scanner = new Scanner(source, 20);
    (2) scanner.setLogging(true);
        scanner.scan();

        sout(""...finished"");
    }
```

(1) change source file name

(2) if logging is 

* enabled, you can see processing flow and some detailed logs.

* disabled, you can see only output/result file.

## Output (for sheet-2)

```
...started
*************************************
*************************************
answer is ....
*************************************
*************************************
1. A
2. D
3. B
4. EMPTY/INVALID
5. D
6. A
7. D
8. C
9. A
10. EMPTY/INVALID
11. B
12. A
13. D
14. EMPTY/INVALID
15. B
16. EMPTY/INVALID
17. EMPTY/INVALID
18. C
19. EMPTY/INVALID
20. D
...finished
```

![alt text](sources/result-sheet-2.png ""Output of Sheet Two"")
"
unclebob/Episode-10-ExpenseReport,master,58,37,2012-04-12T02:14:44Z,133,1,The Expense Report example from cleancoders.com episode 10,,
mikesmullin/Assembly,master,37,7,2012-01-26T02:49:33Z,373,0,Various x86/64 Assembly examples for learning,,"# Assembly

Follow along as we learn Assembly Language (ASM). Including x86, x86_64 architecture,
machine language, JVM bytecode, and fundamentals of hardware.

# My Book

- Thorough notes and links on x86/64 Machine Code Assembly / Disassembly  
  https://gist.github.com/mikesmullin/6259449

# Examples:

- `bootloader/` - on BIOS, boot, and operating system assembly
- `windows/` - on Windows process assembly (incl. OpenGL)
- `linux_gdb/` - on Linux assembly and Asm/Disasm/Debug tooling

# Related:

- [mikesmullin/OperatingSystem](https://github.com/mikesmullin/OperatingSystem) repo"
mrthetkhine/designpattern,master,83,15,2016-09-24T17:17:00Z,2270,0,Design pattern code example in Java,design pattern programming,"Implementatin of Major Design pattern in GoF
Design pattern code example in Java
"
bekkopen/jetty-pkg,master,54,18,2011-01-14T11:48:52Z,205,0,Embed-your-webapp into jetty7 example,,"Usage
=====

* Add your war file artifact to the Maven <code>pom.xml</code>
* Build it <code>mvn clean install</code>
* Run it <code>java -jar yourWebApp-version.jar start</code>

Configuration
=============

Create a secret (i.e. one per environment):
<pre>
:➜ md5sum yourWarFile.war
eb27fb2e61ed603363461b3b4e37e0a0  yourWarFile.war
</pre>

Create a configuration file:
<pre>
:➜ cat > /etc/bekkopen/appname.properties
jetty.contextPath=/appname
jetty.port=7000
jetty.workDir=/var/apps/appname/
jetty.secret=eb27fb2e61ed603363461b3b4e37e0a0
[ctrl+d]
</pre>

Start it with a configuration file (default: CWD/jetty.properties):
<pre>
:➜ java -Dconfig=/etc/bekkopen/appname.properties -jar appname-1.0.0rc0.jar
</pre>

Override individual properties:
<pre>
:➜ java -Djetty.port=7001 -jar appname-1.0.0rc0.jar
</pre>

(I didn't bother implementing combinations of system properties and resource properties - we i.e. use Constretto in our own launcher).
"
smithy-lang/smithy-examples,main,25,4,2023-06-01T19:14:32Z,401,1,A collection of examples to help users get up and running with Smithy,api aws build-tool codegen examples smithy smithy-models,"# Smithy Examples
[![Build Status](https://github.com/smithy-lang/smithy-examples/workflows/integ/badge.svg)](https://github.com/smithy-lang/smithy-examples/actions/workflows/integ.yml)

This repository contains a range of examples to help you get up and running with [Smithy](https://smithy.io).

*Note*: You will need the [Smithy CLI](https://smithy.io/2.0/guides/smithy-cli/index.html) installed to use the examples in this
repository as templates.
If you do not have the CLI installed, follow [this guide](https://smithy.io/2.0/guides/smithy-cli/index.html) to install it now.


### What is Smithy
Smithy is an interface definition language and set of tools that allows developers to build clients and servers in 
multiple languages. A Smithy model enables API providers to generate clients and servers in various programming languages, 
API documentation, test automation, and example code.


## Examples
- [Quick Start](quickstart-examples) - Build the Smithy [quick start example](https://smithy.io/2.0/quickstart.html).
- [Conversion](conversion-examples) - Convert Smithy models to other formats (such as OpenAPI) and vice versa 
- [Custom Traits](custom-trait-examples) - Create custom Smithy [traits](https://smithy.io/2.0/spec/model.html#traits) to use for defining custom model metadata.
- [Projections](projection-examples) - Using Smithy [projections](https://smithy.io/2.0/guides/building-models/build-config.html#projections) to create different views of 
  your model for specific consumers.
- [Shared Models](shared-model-examples) - Create a package of common Smithy shapes that can be shared between Smithy models.
- [Linting and Validation](linting-and-validation-examples) - Use linters and validators to ensure APIs adhere to best practices and standards.

## Contributing
Contributions are welcome. Please read the [contribution guidelines](CONTRIBUTING.md) first.


## Security
See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License
This project is licensed under the MIT-0 License.

"
sysco-middleware/kafka-testing,master,25,13,2019-03-25T17:06:09Z,224,4,"Test examples of kafka-clients: unit, integration, end-to-end",embedded-kafka embeddedsinglenodekafkacluster kafka-streams kafka-streams-test-utils kafka-testing,
lemonlabs/u2020-mortar,master,99,16,2014-04-22T07:19:29Z,2537,1,[DEPRECATED] Port of Jake Wharton's U2020 sample app with use of Mortar & Flow + couple more examples,,"U+2020 mortar
============

Disclaimer: Mortar & Flow have evolved since this project was created. It will be updated when we've completely decided what to do with the libraries.

Port of Jake Wharton's U+2020 sample app with use of Mortar &amp; Flow + couple more examples.

This is more of a kitchen sink of things we are trying with Mortar&Flow. Use as a base for a project at your own risk. Ideas and PRs are welcome.

* [Jake Wharton's U2020](https://github.com/JakeWharton/u2020)
* [Square's Mortar](https://github.com/square/mortar)
* [Square's Flow](https://github.com/square/flow)
"
networknt/light-example-4j,release,148,67,2016-09-11T14:31:47Z,10599,7,Example APIs or services to demo all feature of the light-4j framework,,"# light-example-4j
Example APIs to demo all feature of the light-4j and frameworks built on top of light-4j.

[Stack Overflow](https://stackoverflow.com/questions/tagged/light-4j) |
[Google Group](https://groups.google.com/forum/#!forum/light-4j) |
[Gitter Chat](https://gitter.im/networknt/light-4j) |
[Subreddit](https://www.reddit.com/r/lightapi/) |
[Youtube Channel](https://www.youtube.com/channel/UCHCRMWJVXw8iB7zKxF55Byw) |
[Documentation](https://doc.networknt.com) |
[Contribution Guide](https://doc.networknt.com/contribute/) |
"
frenmanoj/bookstore,master,26,66,2014-05-25T18:30:53Z,862,0,A complete example for Spring MVC + Maven + Hibernate CRUD operation,,"# bookstore

A complete example for Spring MVC + Maven + Hibernate CRUD operation

# Running the Application

+ Open the Command Prompt
+ Go to the root project directory ( bookstore )
+ Run the following maven command to download all dependent JARs.

```
mvn eclipse:clean eclipse:eclipse
```

+ Run Tomcat server 

```
mvn clean tomcat7:run
```

+ Go to the browser and enter the following URL: 
```
http://localhost:8080/bookstore/book/
```
The port number might be different in your case. Please have a look at the tomcat log in console for that.

# Blog Reference:

[https://shrestha-manoj.blogspot.com/2014/05/spring-mvc-maven-hibernate-crud-example.html](https://shrestha-manoj.blogspot.com/2014/05/spring-mvc-maven-hibernate-crud-example.html)
"
hdiv/hdiv-spring-mvc-showcase,master,28,23,2011-10-22T16:15:47Z,197,5,Spring MCV and Hdiv example application,,"Hdiv: Application Self-Protection
=================================
Sample application showing the integration between Spring Mvc and Hdiv.

How to build the application
============================
Clone this repo and build war file (you'll need Git and Maven installed):

    git clone git://github.com/hdiv/hdiv-spring-mvc-showcase.git
    cd hdiv-spring-mvc-showcase
    mvn package
    mvn tomcat7:run

Open [http://localhost:8080/hdiv-spring-mvc-showcase](http://localhost:8080/hdiv-spring-mvc-showcase) in your favorite browser.
"
headius/indy_deep_dive,master,52,5,2012-05-07T15:18:17Z,128,2,"Examples from my invokedynamic deep dive"" talk""",,
oktadev/auth0-full-stack-java-example,main,26,15,2021-10-12T19:33:58Z,5618,1,🔥 Full Stack Java Example,auth0 fullstack fullstack-java java oidc react spring-boot,"# Full Stack Java Example with JHipster (React + Spring Boot) 🤓

This example app shows you how to create a slick-looking, full-stack, secure application using React, Spring Boot, and JHipster.

Please read the following blog posts to learn more:

- [Full Stack Java with React, Spring Boot, and JHipster][blog] to see how this app was created.
- [Introducing Spring Native for JHipster: Serverless Full-Stack Made Easy][blog-spring-native] to convert this app to an executable with Spring Native.
- [Use GitHub Actions to Build GraalVM Native Images][blog-github-graalvm] to automate your GraalVM builds.

**Prerequisites:**

- [Node.js 14+](https://nodejs.org/)
- [Java 11+](https://sdkman.io)
- [Docker Compose](https://docs.docker.com/compose/install/)
- An [Auth0 Account](https://auth0.com/signup)

> [Auth0](https://auth0.com) is an easy to implement, adaptable authentication and authorization platform. Basically, we make your login box awesome.

- [Getting Started](#getting-started)
- [Links](#links)
- [Help](#help)
- [License](#license)

## Getting Started

To install this example, clone it.

```
git clone https://github.com/oktadev/auth0-full-stack-java-example.git
cd auth0-full-stack-java-example
```

Create a `.auth0.env` file in the root of the project, and fill it with the code below to override the default OIDC settings:

```shell
export SPRING_SECURITY_OAUTH2_CLIENT_PROVIDER_OIDC_ISSUER_URI=https://<your-auth0-domain>/
export SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_ID=<your-client-id>
export SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_SECRET=<your-client-secret>
export JHIPSTER_SECURITY_OAUTH2_AUDIENCE=https://<your-auth0-domain>/api/v2/
```

You'll need to create a new web application in Auth0 and fill in the `<...>` placeholders before this works.

### Create an OpenID Connect App on Auth0

Log in to your Auth0 account (or [sign up](https://auth0.com/signup) if you don't have an account). You should have a unique domain like `dev-xxx.eu.auth0.com`.

Press the **Create Application** button in [Applications section](https://manage.auth0.com/#/applications). Use a name like `JHipster Baby!`, select `Regular Web Applications`, and click **Create**.

Switch to the **Settings** tab and configure your application settings:

- Allowed Callback URLs: `http://localhost:8080/login/oauth2/code/oidc`
- Allowed Logout URLs: `http://localhost:8080/`

Scroll to the bottom and click **Save Changes**.

In the [roles](https://manage.auth0.com/#/roles) section, create new roles named `ROLE_ADMIN` and `ROLE_USER`.

Create a new user account in the [users](https://manage.auth0.com/#/users) section. Click on the **Role** tab to assign the roles you just created to the new account.

_Make sure your new user's email is verified before attempting to log in!_

Next, head to **Auth Pipeline** > **Rules** > **Create**. Select the `Empty rule` template. Provide a meaningful name like `Group claims` and replace the Script content with the following.

```js
function(user, context, callback) {
  user.preferred_username = user.email;
  const roles = (context.authorization || {}).roles;

  function prepareCustomClaimKey(claim) {
    return `https://www.jhipster.tech/${claim}`;
  }

  const rolesClaim = prepareCustomClaimKey('roles');

  if (context.idToken) {
    context.idToken[rolesClaim] = roles;
  }

  if (context.accessToken) {
    context.accessToken[rolesClaim] = roles;
  }

  callback(null, user, context);
}
```

This code is adding the user's roles to a custom claim (prefixed with `https://www.jhipster.tech/roles`). This claim is mapped to Spring Security authorities in `SecurityUtils.java`.

Click **Save changes** to continue.

**NOTE**: Want to have all these steps automated for you? Vote for [this issue](https://github.com/auth0/auth0-cli/issues/351) in the Auth0 CLI project.

### Run Your JHipster App with Auth0

Set your Auth0 properties in `.auth0.env`, and start the app.

```shell
source .auth0.env
./mvnw
```

_Voilà_ - your full stack app is using Auth0! Open your favorite browser to `http://localhost:8080` and sign-in.

## Links

This example uses the following open source libraries:

- [JHipster](https://www.jhipster.tech)
- [Spring Boot](https://spring.io/projects/spring-boot)
- [Spring Security](https://spring.io/projects/spring-security)

## Help

Please post any questions as comments on the [blog post][blog].

## License

Apache 2.0, see [LICENSE](LICENSE).

[blog]: https://auth0.com/blog/full-stack-java-with-react-spring-boot-and-jhipster/
[blog-spring-native]: https://developer.okta.com/blog/2022/03/03/spring-native-jhipster
[blog-github-graalvm]: https://developer.okta.com/blog/2022/04/22/github-actions-graalvm
"
gpcodervn/Design-Pattern-Tutorial,master,31,23,2018-08-13T16:56:23Z,128,1,This project includes all examples about 23 design patterns of GoF with some other patterns in software development,,"# Design-Pattern-Tutorial

This project includes all examples about 23 design patterns of GoF with some other patterns in software development

## Design Patterns là gì?

Design Pattern là một kỹ thuật trong lập trình hướng đối tượng, nó khá quan trọng và mọi lập trình viên muốn giỏi đều phải biết. Được sử dụng thường xuyên trong các ngôn ngữ OOP. Nó sẽ cung cấp cho bạn các ""mẫu thiết kế"", giải pháp để giải quyết các vấn đề chung, thường gặp trong lập trình. Các vấn đề mà bạn gặp phải có thể bạn sẽ tự nghĩ ra cách giải quyết nhưng có thể nó chưa phải là tối ưu. Design Pattern giúp bạn giải quyết vấn đề một cách tối ưu nhất, cung cấp cho bạn các giải pháp trong lập trình OOP.

Design Patterns không phải là ngôn ngữ cụ thể nào cả. Nó có thể thực hiện được ở phần lớn các ngôn ngữ lập trình, chẳng hạn như Java, C#, thậm chí là Javascript hay bất kỳ ngôn ngữ lập trình nào khác.

Mỗi pattern mô tả một vấn đề xảy ra lặp đi lặp lại, và trình bày trọng tâm của giải pháp cho vấn đề đó, theo cách mà bạn có thể dùng đi dùng lại hàng triệu lần mà không cần phải suy nghĩ.

— Christopher Alexander —

## Phân loại Design Patterns

Năm 1994, bốn tác giả Erich Gamma, Richard Helm, Ralph Johnson và John Vlissides đã cho xuất bản một cuốn sách với tiêu đề Design Patterns – Elements of Reusable Object-Oriented Software, đây là khởi nguồn của khái niệm design pattern trong lập trình phần mềm.

Bốn tác giả trên được biết đến rộng rãi dưới tên Gang of Four (bộ tứ). 

Theo quan điểm của bốn người, design pattern chủ yếu được dựa theo những quy tắc sau đây về thiết kế hướng đối tượng.

Lập trình cho interface chứ không phải để implement interface đó.

Ưu tiên object composition hơn là thừa kế.

Hệ thống các mẫu Design pattern hiện có 23 mẫu được định nghĩa trong cuốn “Design patterns Elements of Reusable Object Oriented Software” và được chia thành 3 nhóm:

Creational Pattern (nhóm khởi tạo – 5 mẫu) gồm: Factory Method, Abstract Factory, Builder, Prototype, Singleton. Những Design pattern loại này cung cấp một giải pháp để tạo ra các object và che giấu được logic của việc tạo ra nó, thay vì tạo ra object một cách trực tiếp bằng cách sử dụng method new. Điều này giúp cho chương trình trở nên mềm dẻo hơn trong việc quyết định object nào cần được tạo ra trong những tình huống được đưa ra.

Structural Pattern (nhóm cấu trúc – 7 mẫu) gồm: Adapter, Bridge, Composite, Decorator, Facade, Flyweight và Proxy. Những Design pattern loại này liên quan tới class và các thành phần của object. Nó dùng để thiết lập, định nghĩa quan hệ giữa các đối tượng.

Behavioral Pattern (nhóm tương tác/ hành vi – 11 mẫu) gồm: Interpreter, Template Method, Chain of Responsibility, Command, Iterator, Mediator, Memento, Observer, State, Strategy và Visitor. Nhóm này dùng trong thực hiện các hành vi của đối tượng, sự giao tiếp giữa các object với nhau.

### Nhóm Creational (nhóm khởi tạo)

- Hướng dẫn Java Design Pattern – Singleton
- Hướng dẫn Java Design Pattern – Factory Method
- Hướng dẫn Java Design Pattern – Abstract Factory
- Hướng dẫn Java Design Pattern – Builder
- Hướng dẫn Java Design Pattern – Prototype
- Hướng dẫn Java Design Pattern – Object Pool

### Nhóm Structural (nhóm cấu trúc)

- Hướng dẫn Java Design Pattern – Adapter
- Hướng dẫn Java Design Pattern – Bridge
- Hướng dẫn Java Design Pattern – Composite
- Hướng dẫn Java Design Pattern – Decorator
- Hướng dẫn Java Design Pattern – Facade
- Hướng dẫn Java Design Pattern – Flyweight
- Hướng dẫn Java Design Pattern – Proxy

### Nhóm Behavioral (nhóm hành vi/ tương tác)

- Hướng dẫn Java Design Pattern – Chain of Responsibility
- Hướng dẫn Java Design Pattern – Command
- Hướng dẫn Java Design Pattern – Interpreter
- Hướng dẫn Java Design Pattern – Iterator
- Hướng dẫn Java Design Pattern – Mediator
- Hướng dẫn Java Design Pattern – Memento
- Hướng dẫn Java Design Pattern – Observer
- Hướng dẫn Java Design Pattern – State
- Hướng dẫn Java Design Pattern – Strategy
- Hướng dẫn Java Design Pattern – Template Method
- Hướng dẫn Java Design Pattern – Visitor

Refer: https://gpcoder.com/4164-gioi-thieu-design-patterns/
"
asanchezyu/RetrofitSoapSample,master,77,24,2016-06-16T11:39:12Z,119,4,"Retrofit with SOAP services Example. ( WSDL, SOAP, converter, SimpleXml,...)",,
akashbangad/NavigationView,master,81,59,2015-06-07T22:33:47Z,271,2,Example app to show the implementation of NavigationView from the design support library,,
mfaisalkhatri/selenium4poc,master,159,61,2021-12-10T10:06:57Z,212,3,Learn Web Automation testing using Selenium Webdriver 4.,beginner-friendly examples hacktoberfest java selenium selenium-java selenium-webdriver test-automation testing tutorial webautomation webautomationtesting,"![Open Source Love](https://badges.frapsoft.com/os/v1/open-source.svg?v=103)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Java CI with Maven](https://github.com/mfaisalkhatri/selenium4poc/actions/workflows/maven.yml/badge.svg)](https://github.com/mfaisalkhatri/selenium4poc/actions/workflows/maven.yml)
[![CodeQL](https://github.com/mfaisalkhatri/selenium4poc/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/mfaisalkhatri/selenium4poc/actions/workflows/codeql-analysis.yml)

## Don't forget to give a :star: to make the project popular.

## :question: What is this Repository about?

- This repo has example codes with Selenium 4 features.
- Websites used for testing are: [automationpractice.com](http://automationpractice.com/index.php), [saucedemo.com](https://www.saucedemo.com),
  [the-internet](http://the-internet.herokuapp.com/) [owasp-juice-shop](https://github.com/juice-shop/juice-shop)
  and [LambdaTest e-commerce Playground](https://ecommerce-playground.lambdatest.io/)
- This repo uses `Maven` as build tool and `TestNG` testing framework to run the tests.

## Talking more about the Scenarios Covered in this project:

- I have tried to answer the below questions by providing working code example in this repo:

1. How do I select a value from Table?
2. How do I tick and untick checkboxes using selenium
3. How do I right-click using selenium?
4. How do I drag and drop using selenium?
5. How do I write code to log in and logout using Selenium?
6. How do I pass multiple test data value using DataProvider in tests?
7. How do I mouse hover an element using selenium?
8. How do I download a file using Selenium?
9. How do I upload file using selenium?
10. How do I press keys using selenium?
11. How do I work with multiple Tab windows in selenium?
12. How do I work with iFrames using Selenium?
13. How do I double-click using Selenium WebDriver?
14. How to check for chrome generated logs when selenium tests are run?

## :writing_hand: Blog Links
 
- [Selenium 4 WebDriver Hierarchy: A Detailed Explanation](https://medium.com/@iamfaisalkhatri/selenium-4-webdriver-hierarchy-a-detailed-explanation-lambdatest-18771c5fd3e9)
- [Selenium Manager in Selenium 4.11.0: New Features and Improvements](https://medium.com/@iamfaisalkhatri/selenium-manager-in-selenium-4-11-0-new-features-and-improvements-lambdatest-761593a7f009)
- [Different Types of Locators in Selenium WebDriver](https://www.lambdatest.com/blog/locators-in-selenium-webdriver-with-examples/)
- [How to Locate Elements Using CSS Selectors in Selenium](https://www.lambdatest.com/learning-hub/css-selectors)
- [How to Use @FindBy Annotation in Selenium Java](https://www.lambdatest.com/blog/findby-annotation-selenium-java/)
- [Understanding CSS Selectors in Selenium](https://medium.com/@iamfaisalkhatri/understanding-css-selectors-in-selenium-pcloudy-blog-3e4b09672264)
- [End to End testing using Selenium WebDriver and Java](https://medium.com/@iamfaisalkhatri/end-to-end-testing-using-selenium-webdriver-and-java-4ff8667716ca)
- [Writing Selenium Web Automation tests in Fluent way!](https://medium.com/@iamfaisalkhatri/writing-selenium-web-automation-tests-in-fluent-way-864db95ee67a)
- [How To Automate Shadow DOM In Selenium WebDriver?](https://medium.com/@iamfaisalkhatri/how-to-automate-shadow-dom-in-selenium-webdriver-lambdatest-blog-3884698b995)
- [How to setup GitHub Actions for Java with Maven project?](https://mfaisalkhatri.github.io/2022/04/26/githubactions-for-java-maven-project/)
- [How to Automate ServiceNow with Selenium](https://medium.com/@iamfaisalkhatri/how-to-automate-servicenow-with-selenium-511e41172161)
- [Cross browser testing in Selenium WebDriver](https://medium.com/@iamfaisalkhatri/cross-browser-testing-in-selenium-webdriver-pcloudy-blog-46e9d70fa13a)
- [How to Handle ElementClickInterceptedException in Selenium Java](https://www.lambdatest.com/blog/elementclickinterceptedexception-in-selenium-java/)

## :movie_camera: Tutorial Videos

[![Watch the video](https://img.youtube.com/vi/bhZX7apMqR8/hqdefault.jpg)]( https://www.youtube.com/live/bhZX7apMqR8?si=4n0u5YiMuz5vTiHd)
[![Watch the video](https://img.youtube.com/vi/uHLYoJmZxWc/hqdefault.jpg)](https://youtu.be/uHLYoJmZxWc?si=3nevAn0Z3QZycdG8)
[![Watch the video](https://img.youtube.com/vi/_hlXjVTa-jo/hqdefault.jpg)](https://youtu.be/_hlXjVTa-jo?si=PfOfU7ihb8eEgduh)
[![Watch the video](https://img.youtube.com/vi/sVBgpz1z9Ts/hqdefault.jpg)]( https://youtu.be/sVBgpz1z9Ts?si=azE1_vquOwT9jFT1d)



## End-to-End Tests for OWASP-Juice-Shop

- End-to-End tests for Juice Shop Website are running on `http://localhost:3000` inside the container in GitHub actions.
- GitHub Actions is used for setting up CI/CD Pipeline

### Following is the Automation Test Strategy used for writing End-to-End Tests:

1. User will navigate to the website and close all the pop-up first.
2. User will click on Login link and click on `Not yet a customer link` and register himself on the website.
3. Once the Registration is successful, User will Log in with that username and password.
4. After successful Login, User will Add AppleJuice and BananaJuice to the Basket.
5. After asserting the messages for items added to basket, user will check for the count of items displayed on top
   of `Your Basket` link.
6. User will click on `Your Basket` link and check the order details and click on Checkout.
7. User will enter a new Address for Delivery and select it to process further.
8. User will continue further to Card for Payment and select the card added to make payment.
9. On the Order Summary page, user will verify all the details like Name, Address, Order details and total amount to be
   paid and place order.
10. User will re-check the details on Order confirmation page and check for `Thank You` message order confirmation and
    delivery message.

## End-to-End Tests for LambdaTest ECommerce Playground Website

### Following is the automation test strategy used for writing end-to-end tests:

1. The User will navigate to the website.
2. From the Home Page of the screen, user will navigate to the Registration Page and register himself. Verification will
   be done by asserting the registration successful message.
3. User will click on the Shop by Category option on the top left and select a category for selecting the product to
   purchase.
4. From the Product Page, the user will hover on any product which he likes and select the Add to cart option. Once a
   product is added to cart, assertions will be performed to check the success message displayed.
5. On the Checkout page, user will provide the billing address details and also assertion will be made for product name
   and its respective price.
6. Once a product is checked out, the user lands on the Order Confirmation page, where product name, price and shipping
   address will be asserted and after that Order would be marked as confirmed.
7. Finally, an Order confirmation message would be verified in the tests which marks the end of the test journey.

## How to run the Tests?

### Running Juice Shop Tests on your local machine:

- Start `Juice-Shop` website locally, for doing this we will make use of `docker-compose-v3-juiceshop.yml` which is
  available in the root folder of this project.
- Open terminal/command prompt and navigate to the root folder of the project and run the following command:

  `docker-compose -f docker-compose-v3-juiceshop.yml up -d`

- Once the `Juice-Shop` website is up and running, we are good to run the end-to-end tests using the juice shop website.
- There are 2 ways to run the tests, those are as follows:
  ### 1. TestNG:
    - Right-Click on the `test-suite\testng-juice-shop.xml` and select `Run ...\test-suite\testng-juice-shop.xml`
  ### 2. Maven:
    - To run the tests in headless mode update the value for `headless` property variable to `true`

      `mvn clean install -Dsuite-xml=test-suite\testng-juice-shop.xml -Dheadless=true`

    - To run the tests without headless mode(to see the test running in browser) update the value for headless property
      variable to
      `false`

      `mvn clean install -Dsuite-xml=test-suite\testng-juice-shop.xml -Dheadless=false`


- Stopping the Juice Shop website running in local

  `docker-compose -f docker-compose-v3-juiceshop.yml down`

### Running Selenium Grid on local and running tests using Selenium Grid

- Start the Selenium Grid in local using the `docker-compose-v3-seleniumgrid.yml` file.
- Run the following command:
  `docker-compose -f docker-compose-v3-seleniumgrid.yml up -d`

  This will start the selenium grid which can be access using `http://localhost:4444`.

    - To run the tests on Selenium Grid using `TestNG`:

      Right click on `test-suite\testng-seleniumgrid-theinternet.xml` and
      select `Run test-suite\testng-seleniumgrid-theinternet.xml`

    - To run the tests on Selenium Grid using `Maven`:

      `mvn clean install -Dsuite-xml=test-suite\testng-seleniumgrid-theinternet.xml`

- Stopping the Selenium Grid:

  `docker-compose -f docker-compose-v3-seleniumgrid.yml down`

### Running all the tests in one go:

- Start the `Juice -Shop` website using following command:

  `docker-compose -f docker-compose-v3-juiceshop.yml up -d`

- Start `Selenium Grid` using following command:

  `docker-compose -f docker-compose-v3-seleniumgrid.yml up -d`

- Run the tests using `TestNG`:

  Right click on `test-suite\testng.xml` and select `Run test-suite\testng.xml`

- Run the tests using `Maven` in headless mode:

  `mvn clean install -Dheadless=true`

- Stopping the `Juice-Shop` website and `Selenium Grid`:

  `docker-compose -f docker-compose-v3-juiceshop.yml down --remove-orphan`

### Running LambdaTest ECommerce Playground Tests on your local machine:

- There are 2 ways to run the tests, those are as follows:

  ### 1. TestNG:
    - Right-Click on the `test-suite\testng-lambdatestecommerce.xml` and
      select `Run ...\test-suite\testng-lambdatestecommerce.xml`

  ### 2. Maven:
    - To run the tests in headless mode update the value for `headless` property variable to `true`

      `mvn clean install -Dsuite-xml=test-suite\testng-lambdatestecommerce.xml -Dheadless=true`

    - To run the tests without headless mode(to see the test running in browser) update the value for headless property
      variable to
      `false`

      `mvn clean install -Dsuite-xml=test-suite\testng-lambdatestecommerce.xml -Dheadless=false`


## :question: Need Assistance?

- Discuss your queries by writing to me @ `mohammadfaisalkhatri@gmail.com`
  OR ping me on any of the social media sites using the below link:
    - [Linktree](https://linktr.ee/faisalkhatri)
  
## :computer: Paid Trainings

- Contact me for Paid trainings related to Test Automation and Software Testing,
mail me @ `mohammadfaisalkhatri@gmail.com` or ping me on [LinkedIn](https://www.linkedin.com/in/faisalkhatri/)

## :thought_balloon: Checkout the blogs related to Testing written by me on the following links:

- [Medium Blogs](https://medium.com/@iamfaisalkhatri)
- [LambdaTest Blogs](https://www.lambdatest.com/blog/author/mfaisalkhatri/)
- [My Website](https://mfaisalkhatri.github.io)

## :bulb: Cloud platform supporter

### Big thanks to **LambdaTest** for their support to the project with their open source license:

<a href=""http://www.lambdatest.com?fp_ref=faisal58"" target=""_blank"" style=""outline:none;border:none;""><img src=""https://d2gdx5nv84sdx2.cloudfront.net/uploads/n3ufe5o3/marketing_asset/banner/6476/728_x_90.png"" alt=""lambdatest"" border=""0""/></a>
 
 
"
Pragmatists/eventsourcing-java-example,master,95,42,2017-03-29T18:27:11Z,643,4,A simplified (in memory) example of Event Sourcing implementation for banking domain. ,ddd ddd-sample event-sourcing,"# Event sourcing example in Java
A simplified (in memory) example of Event Sourcing implementation in Java for banking domain.
Repository is splitted into exercises adding step by step more functionality towards good design of event sourcing with CQRS.
You can play around and try to implement exercises or You can check out solution branches.


## Step 1 - In memory iplementation of event sourcing
![alt tag](https://raw.githubusercontent.com/michal-lipski/eventsourcing-example/master/event_store_exercise_1.png)
- Provide simple in-memory implementation of Event Store
- Make all test passing using event sourcing
#### soultion
 - branch [exercise_1_solution](https://github.com/michal-lipski/eventsourcing-example/tree/excercise_1_solution)

## Step 1a (optional) - Unit of work pattern
- Implement [Unit of Work](https://martinfowler.com/eaaCatalog/unitOfWork.html) pattern where events are stored outside of aggregate
#### soultion
 - WIP

## Step 1b (optional) - Projections
- Implement Projections on Account to get number of transactions performed on account
- eventStore.store() method shoud accept Event playload instead of domain Events
- what should be api of eventStream()?
#### soultion
 - WIP
 
## Step 2 (optional) - Optimistic locking
- add optimistic locking
#### soultion
 - WIP
 
## Step 3 - new Aggregate extraction
![alt tag](https://raw.githubusercontent.com/michal-lipski/eventsourcing-example/master/event_store_exercise_2.png)
- Refactor to move all money transfer related stuff to separate aggregate
- New aggregate will be also using Event Store
#### soultion
 - WIP
 
## Step 4 - adding CQRS
![alt tag](https://raw.githubusercontent.com/michal-lipski/eventsourcing-example/master/event_store_exercise_3.png)
- Apply CQRS rule and separate the command and reading side
- Solution will use Eventual Consistency approach
#### soultion
 - WIP
 
## Step 5
- Provide additional (not transient) implementation of Event Store. (https://geteventstore.com/)
#### soultion
 - WIP
"
cristianprofile/spring-boot-mvc-complete-example,develop,55,52,2015-02-24T03:12:34Z,30763,42,spring boot mvc complete example integration and unit test with @config classes,,"## Spring Boot Maven/Gradle Java 1.8  (Spring MVC jsp and tiles, Spring Data Rest, Jenkins 2 ready to use with full support to Maven and Gradle)

[![Coverage Status](https://coveralls.io/repos/cristianprofile/spring-boot-mvc-complete-example/badge.svg)](https://coveralls.io/r/cristianprofile/spring-boot-mvc-complete-example)  [![Build Status](https://travis-ci.org/cristianprofile/spring-boot-mvc-complete-example.svg?branch=develop)](https://travis-ci.org/cristianprofile/spring-boot-mvc-complete-example)
[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/cristianprofile/spring-boot-mvc-complete-example?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)

If you don`t have  gradle or maven on your computer you can use gradlew to be able to run the project

```
gradle wrapper (run Gradle wrapper)

After this operation you can run every Gradle command of this guide with 

./gradlew xxxxxtask (Unix, Linux)
gradlew.bat XXXtask  (Windows)

Example

./gradlew clean compile (Unix, Linux)
gradlew.bat clean compile (Windows)

```


You can build this project with Maven or Gradle. Here you have several snippets about how to use them: 

```
mvn clean install (install jar to your local m2 )
mvn spring-boot:run (run web app modules)
gradle buid (build modules)
gradle bootRun (run web app modules)
```


**Important!!!!!If you use Maven First of all you have to install with ""mvn install"" modules ""mylab-parent-pom"" and after ""mvn install"" of module ""mylab-core"".**


## Spring Boot mvc web with tiles app

run spring-boot-mvc-web-example module with maven  ""mvn spring-boot:run"" (if you want to use Gradle run ""gradle bootRun"" into spring-boot-mvc-web-example ) and access to http://localhost:9090/pizza
and user: ""admin@ole.com"" and password ""admin@ole.com"".You can create other users with ROLE_USER at add user left menu
option.

- Spring boot MVC with Spring Security Access
- I18n
- Responsive Bootstrap css witn Tiles 3
- Password encoding with Bcrypt  [BCRYPT password encoding](http://www.baeldung.com/spring-security-registration-password-encoding-bcrypt ""BCRYPT password encoding"") 
- Unit Testing and Integration Testing with spring-boot-starter-test dependency (all dependecies are transitive like mockito junit etc...)


## Rest service layer with Spring Boot Mvc

If you want to access to Rest Service with Spring boot module ""spring-boot-mvc"" first run mvn spring-boot:run (if you want to use Gradle run ""gradle bootRun""
 into spring-boot-mvc-rest folder ):

```
- http://localhost:9090/base (get list of all bases)
- http://localhost:9090/base/1 (get base info with id=1)
- http://localhost:9090/base/1 (delete base info with id=1)
- http://localhost:9090/base (post create new base sending json info. Example ""name"":""rolling pizza"" )
- http://localhost:9090/base (update update existing base sending json info. Example {""name"":""rolling pizza 2"",""id"":1})
```

When you run Spring boot app Spring actuator add features to monitore your services:

```
- (get) http://localhost:9091/manage/metrics (Spring Boot Actuator includes a metrics service with 
“gauge” and “counter” support. A “gauge” records a single value; and a “counter” records a delta 
(an increment or decrement). Metrics for all HTTP requests are automatically 
recorded, so if you hit the metrics endpoint should see a sensible response.)
- (get) http://localhost:9091/manage/health (you can check if your app is available)
- (get) http://localhost:9091/manage/mappings (list of your app HTTP endpoints)
- (post) http://localhost:9091/manage/shutdown (list of your app HTTP endpoints)
```

![Spring Actuator values](/images/Spring_Actuator_EndPoints.png?raw=true ""Spring Actuator values"")


More info about Spring Actuator at: [Spring Actuator](https://github.com/spring-projects/spring-boot/tree/master/spring-boot-actuator ""Spring Actuator"")


##  Rest service layer with Spring Data Rest

Spring Data REST builds on top of Spring Data repositories, analyzes your application’s domain model and exposes hypermedia-driven HTTP resources for aggregates contained in the model.

If you want to access to Rest Service with Spring boot module ""spring-boot-data-rest"" first run mvn spring-boot:run (if you want to use Gradle run ""gradle bootRun""
 into spring-boot-data-rest):

```
- http://localhost:9090/api/bases to get all bases (get list of all bases)
- http://localhost:9090/api/bases (post create new base sending json info. Example ""name"":""rolling pizza"" )
- http://localhost:9090/api/browser/index.html#/api to access to your rest api HAL Browser to be served up when you visit your application’s root URI in a browser. 
```

![Spring Actuator values](/images/SpringDataRestHalBrowser.png?raw=true ""Spring Actuator values"")


More info about Spring Data Rest at: [Spring Data Rest](http://projects.spring.io/spring-data-rest/ ""Spring Data Rest"") 

## Git commit info in Spring boot and jar maven/gradle package

Maven and Gradle allow to generate a git.properties file containing information about the state of your git source code repository when the project was built.

For Maven users the spring-boot-starter-parent POM includes a pre-configured plugin to generate a git.properties file. Simply add the following declaration to your POM:

```
<build>
    <plugins>
        <plugin>
            <groupId>pl.project13.maven</groupId>
            <artifactId>git-commit-id-plugin</artifactId>
        </plugin>
    </plugins>
</build>
```
Gradle users can archieve the same result using the gradle-git-properties plugin

```
plugins {
    id ""com.gorylenko.gradle-git-properties"" version ""1.4.17""
}
```

***New in Spring 1.4:***
Git commit id plugin show complete git commit id plugin in ""/info"" endpoint of Actuator. In yml properties file add:

```
management:
    port: 9091
    info:
        git:
          enabled: true
          mode: full
```

![Git commit id plugin full actuator info](/images/actuator-git-commit-id-full-info.png?raw=true ""Git commit id plugin full actuator info"")


You can read more info about Spring boot how to config here: [Spring boot oficial documentation](http://docs.spring.io/spring-boot/docs/current/reference/html/howto-build.html#howto-git-info ""Spring boot oficial documentation"")  


Spring boot app screen-shots:

![Spring boot info](/images/git_info_boot.png?raw=true ""Spring boot info"")
![Maven created git.properties](/images/git-info-maven.png?raw=true ""Maven created git.properties"")
![Gradle created git.properties](/images/git-info-gradle.png?raw=true ""Gradle Screen Example"")


## Testing Spring mvc rest model views

It can sometimes be useful to filter contextually objects serialized to the HTTP response body.
In order to provide such capabilities, Spring MVC now has builtin support for Jackson’s Serialization Views (as of Spring Framework 4.2, JSON Views are supported on @MessageMapping handler methods as well).



Model view Summary/Internal
```
package com.mylab.cromero.controller.view;

public class View {

public static class Summary {}

public static class Internal extends Summary {}
}
```



Json View model 
```
package com.mylab.cromero.controller.view;

public class Message {

@JsonView(View.Summary.class)
private Long id;

@JsonView(View.Summary.class)
private String name;

@JsonView(View.Internal.class)
private String title;

private String body;
```

An Example controller named ""MessageController"" has been created to be able to test this Spring feature (Spring boot mvc rest module)
[Message controller info](/spring-boot-mvc-rest/src/main/java/com/mylab/cromero/controller/MessageController.java#L32)


![MessageController](/images/message_controller.png?raw=true ""MessageController"")



Screen-shots url view controller test:

Summary controller test: (http://localhost:9090/message/summary)

![Summary controller test](/images/spring_mvc_views_summary.png?raw=true ""Summary controller test"")

Internal controller test:(http://localhost:9090/message/internal)

![Internal controller test](/images/spring_mvc_internal.png?raw=true ""Internal controller test"")

Full controller test: (http://localhost:9090/message/full)

![Full controller test](/images/spring_mvc_views_full.png?raw=true ""Full controller test"")

[Aditional Spring oficial example](https://spring.io/blog/2014/12/02/latest-jackson-integration-improvements-in-spring ""Aditional Spring oficial example"") 




## Jenkins 2 support with jenkins file

Jenkins 2 automatic multibranch plugin mode with JenkinsFile file in main directory. More interesting information about new Jenkins 2 Pipeline script configuration at:

-  [DZONE refcard jenkins pipeline](https://dzone.com/refcardz/continuous-delivery-with-jenkins-workflow ""DZONE refcard jenkins pipeline"")
-  [Github examples](https://github.com/jenkinsci/pipeline-examples ""Github examples"")  

Docker integration in feature  branch called: docker_container_jenkins

-  [Docker container feature branch](https://github.com/cristianprofile/spring-boot-mvc-complete-example/blob/feature/docker_container_jenkins/Jenkinsfile ""Run IC in a Docker container"")  

![Pipeline plugin](/images/git-flow.png?raw=true ""Pipeline plugin"")


## ELK SUPPORT IN WEB APP MODULE(Elasticsearch/Kibana/Logstash)

First of all you need and ELK installed in you machine. The easiest way is to use docker image (https://hub.docker.com/r/nshou/elasticsearch-kibana/) :

-  Start your container with Kibana and ElasticSearch.
-  Edit spring-boot-mvc-web/src/main/resources/logstash/logstash-spring-boot-json.conf with your elasticsearch port
-  Download losgstash and run logstash command from web app initial folder ""./logstash -vf spring-boot-mvc-web/src/main/resources/logstash/logstash-spring-boot-json.conf --debug""
-  Run Spring boot web app: gradle bootRun or mvn spring-boot:run. Now your app will create 2 logs files in tmp folder:  spring-boot-mvc.log and spring-boot-mvc.log.json
-  Logstash is monitoring .json file and create new document in elasticsearch for each new line
-  Go to you kibana url:  It should be running at http://localhost:32771/.

First, you need to point Kibana to Elasticsearch index(s) of your choice. Logstash creates indices with the name pattern of logstash-YYYY.MM.DD. In Kibana Settings → Indices configure the indices:

1. Index contains time-based events (select this option)
2. Use event times to create index names (select this option)
3. Index pattern interval: Daily
4. Index name or pattern: [logstash-]YYYY.MM.DD
5. Click on ""Create Index""
6. Now click on ""Discover"" tab.

In my opinion, ""Discover"" tab is really named incorrectly in Kibana - it should be labeled as ""Search"" instead of ""Discover"" because it allows you to perform new searches and also to save/manage them. Log events should be showing up now in the main window. If they're not, then double check the time period filter in to right corner of the screen. Default table will have 2 columns by default: Time and _source. In order to make the listing more useful, we can configure the displayed columns. From the menu on the left select level, class and logmessage.


Link to youtube video demo:

[![ELK DEMO](/images/elkyoutube.png?raw=true)](https://youtu.be/A64aO6_d8rw)

ScreenShots Images:

![Logback Configuration](/images/logback-configuration.png?raw=true ""Logback Configuration"")
![Logstash Configuration](/images/logstash-configuration.png?raw=true ""Logstash Configuration"")
![Kibana Screen Example](/images/kibana-info.png?raw=true ""Kibana Screen Example"")
![Kibana Screen Example 2 filter](/images/kibana-filter.png?raw=true ""Kibana Screen Example 2 filter"")


Aditional info ELK and Spring boot: -  [Aditional info ELK and Spring boot](https://blog.codecentric.de/en/2014/10/log-management-spring-boot-applications-logstash-elastichsearch-kibana/ ""Aditional info ELK and Spring boot"")   
Kibana Lucene Query language Sintax: [Kibana Lucene Query language Sintax](https://www.elastic.co/guide/en/beats/packetbeat/current/_kibana_queries_and_filters.html ""Kibana Lucene Query language Sintax"")   


## Config logback with Spring boot web app modules

Logs in Spring boot web modules has been configured with logback. Spring boot has support with spring boot profiles to be able to set variable in logback-spring.xml:

```
<springProfile name=""develop"">
        <logger name=""com.mylab.cromero"" level=""DEBUG""/>
    </springProfile>
```
If you want to log debug logs in our example app package you must use this commands with maven/gradle to activate develop profile:

```
gradle -Dspring.profiles.active=develop bootRun
mvn -Dspring.profiles.active=develop spring-boot:run
```


Aditional Spring Boot documentation: -  [Aditional Spring Boot documentation](http://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-logging.html ""Aditional Spring Boot documentation"")   





"
umermansoor/hadoop-java-example,develop,72,47,2013-01-13T18:01:51Z,226,1,A very simple example of using Hadoop's MapReduce functionality in Java.,,"## Hadoop Map-Reduce Example in Java

**Get up and running in less than 5 minutes**

### Overview
This program demonstrates Hadoop's Map-Reduce concept in Java using a very simple example. The input is raw data files listing earthquakes by region, magnitude and other information. 

> nc,71920701,1,”Saturday, January 12, 2013 19:43:18 UTC”,38.7865,-122.7630,**1.5**,1.10,27,**“Northern California”**

The fields in bold are magnitude of the quake and name of region where the reading was taken, respectively. The _goal_ is to process all input files to find the maximum magnitude quake reading for every region listed. The output is in the form:

        ""region_name""      <maximum magnitude of earthquake recorded> 

The raw data files are in the `input/` folder.

### Instructions for Setting Up Hadoop
1. Download Hadoop 1.1.1 binary. [Mirror](http://mirror.csclub.uwaterloo.ca/apache/hadoop/common/hadoop-1.1.1/hadoop-1.1.1.tar.gz)


2. Extract it to a folder on your computer:
        
        $ tar xvfz hadoop-1.1.1.tar.gz

3. Setup JAVA_HOME environment variable to point to the directory where Java is installed. For my Mac OS X, I did the following:

        $ export JAVA_HOME=/System/Library/Frameworks/JavaVM.framework/Versions/1.6.0/Home

 Note: If you are running Lion, you may want to update the JAVA_HOME to point to `java_home` command which outputs Java's home directory, that is,

        $ export JAVA_HOME=$(/usr/libexec/java_home)

4. Setup HADOOP_INSTALL environment variable to point the directory where you extracted hadoop binary in step 2:

        $ export HADOOP_INSTALL=/Users/umermansoor/Documents/hadoop-1.1.1

5. Edit the PATH environment variable:

        $ export PATH=$PATH:$HADOOP_INSTALL/bin

> Or you can add these variables to your standard shell script. For example, checkout my Mac OSX's [`~/.bash_profile`](https://gist.github.com/4525814)

### Instructions for Running the Sample
1. Clone the project:

	    $ git clone git@github.com:umermansoor/hadoop-java-example.git
	
2. Change to the project directory:

	    $ cd hadoop-java-example

3. Build the project:

	    $ mvn clean install

4. Setup the HADOOP_CLASSPATH environment variable to tell Hadoop where to find the java classes for the sample:

	    $ export HADOOP_CLASSPATH=target/classes/

5. Run the sample. The `output` directory shouldn't exists otherwise this will fail.

        $ hadoop com.umermansoor.App input/ output

> Note: the output will go to the `output/` folder which Hadoop will create when run. The output will be in a file called `part-r-00000`.

### Common Errors:
1. Exception: java.lang.NoClassDefFoundError
Cause: You didn't setup the HADOOP_CLASSPATH environment variable. You need to tell Hadoop where to find the java classes. 
Resolution: In this case, execute the following to setup HADOOP_CLASSPATH variable to point to the `target/classes/` folder.

        $ export HADOOP_CLASSPATH=target/classes/

2. Exception: org.apache.hadoop.mapred.FileAlreadyExistsException or 'Output directory output already exists'. 
Cause: Output directory already exists. Hadoop requires that the output directory doesn't exists when run. 
Resolution: Change the output directory or remove the existing one:

        $ hadoop com.umermansoor.App input/input.csv output_new 

> Note: Hadoop failing if the output folder already exists is a good thing: it ensures that you don't accidentally overwrite your previous output, as typical Hadoop jobs take hours to complete.

"
thundergolfer/example-bazel-monorepo,master,313,31,2019-04-03T04:53:27Z,603,15,"🌿💚  Example Bazel-ified monorepo, supporting Golang, Java, Python, Scala, and Typescript",bazel bazel-monorepo blaze buck build-tool platform-engineering,"<h1 align=""center"">Example Bazel Monorepo</h1>
<p align=""center"">
    <a href=""https://buildkite.com/thundergolfer-inc/the-one-true-bazel-monorepo"">
        <img src=""https://badge.buildkite.com/aa36b75077a5c69156bc143b32c8c2db04c4b20b8706b8a99b.svg?branch=master"">
    </a>
</p>

----

> *Note:* Currently supporting the latest Bazel version as at mid June 2021, [4.1.0](https://github.com/bazelbuild/bazel/releases/tag/4.1.0) 

Example Bazel-ified monorepo, supporting *Golang*, *Java*, *Python*, *Scala*, and *Typescript*. 

Cloud Infrastructure-as-Code is done using _Terraform_.

I use this project to explore how Bazel works with different languages and
developer tools, and keep a record of best-practices I've learnt. So it is a work in progress.
Others can use it to check out the Bazel way of doing things and use parts
as a reference implementation.

Rather than the typical To-Do list, this project's code uses the contrived scenario of a book shop and reading catalogue website called *Antilibrary*. 📗📕📒📚

## Getting Started

#### Prerequisites:
 
- [**Install Bazel**](https://docs.bazel.build/versions/master/install.html) (Currently supporting ~= `4.x.x`)
- **Python 2 or 3**. Should only be required to [do some bootstrapping under-the-hood](https://github.com/bazelbuild/bazel/issues/8446).
- [**`yarn`**](https://yarnpkg.com/) or [**`npm`**](https://www.npmjs.com/) for the NodeJS and Typescript code

Bazel aims to be 'build anything, anywhere' system, so building and testing should be as simple as `bazel test //...`. If it's not, please [create an issue](https://github.com/thundergolfer/example-bazel-monorepo/issues/new/choose). 

## Why use a Monorepo?

The following few articles together provide a good overview of the
motivations behind maintaining a Monorepo. For heaps more information,
[korfuri/awesome-monorepo](https://github.com/korfuri/awesome-monorepo)
is a good place to go. 

* [*Why Google Stores Billions of Lines in a Single
  Repository*](http://delivery.acm.org/10.1145/2860000/2854146/p78-potvin.pdf?ip=60.240.50.147&id=2854146&acc=OA&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E5945DC2EABF3343C&__acm__=1558760299_19ae56a814d1fe05de26b4844a658e52)
* [*Monorepos, please
  do!*](https://medium.com/@adamhjk/monorepo-please-do-3657e08a4b70), by
Adam Jacob, former CTO of [Chef](https://www.chef.io/)
* [*Repo Style Wars: Mono vs. Multi*](https://gigamonkeys.com/mono-vs-multi/), by Peter Seibel
* [*Advantages of Monorepos*](https://danluu.com/monorepo/), by Dan Luu

### Related Projects

* [github.com/lucperkins/colossus](https://github.com/lucperkins/colossus) - A demo using Bazel in monorepo fashion. Compared with this project, it goes far deeper on microservice architecture components and Kubernetes, and is not focused on Bazel.
* [github.com/enginoid/monorepo-base](https://github.com/enginoid/monorepo-base) - Employs Bazel, gRPC, and Kubernetes like the above, and is similarly not as broad and deep on Bazel as this project.

## Project Structure

### *Golang* Support

There's Golang code in [`/cli`](/cli). It implements a simple CLI for the common 'Blind Date With a 📖' product.

##### Dependency Management

Third-party dependencies are managed in [`3rdparty/go_workspace.bzl`](/3rdparty/go_workspace.bzl).  

### *Java* Support

There's a [Spring Boot](https://spring.io/projects/spring-boot) (with PostGres) application in [`/store-api`](/store-api) and some other Java code in [`/store/layoutsolver`](/store/layoutsolver).

##### Dependency Management

Its third-party dependencies are managed by [`rules_jvm_external`](https://blog.bazel.build/2019/03/31/rules-jvm-external-maven.html) in the [`WORKSPACE`](/WORKSPACE) (See the `# JAVA SUPPORT` section).

### *Scala* Support

There's Scala code contained in [`scala-book-sorting`](/scala-book-sorting).

##### Dependency Management

Its third-party dependencies are managed
by [`johnynek/bazel-deps`](https://github.com/johnynek/bazel-deps). The usage of that tool is wrapped up in a script
as [`tools/update_jvm_dependencies.sh`](tools/update_jvm_dependencies.sh).

To use it, you update [`tools/dependencies/jvm_dependencies.yaml`](tools/dependencies/jvm_dependencies.yaml) and then run the script.


### *Python* Support

There's Python code in the [`/book_sorting`](/book_sorting) and [`/scraping`](/scraping).

[`bazelbuild/rules_python`](https://github.com/bazelbuild/rules_python) is used for the core `py_*` rules.

##### Dependency Management

In order to add new third-party packages for Python, add them to [`3rdparty/requirements.in`](/3rdparty/requirements.in) and run `bazel run //3rdparty:requirements.update`.

##### Gradual Type-Checking (MyPy)

[thundergolfer/bazel-mypy-integration](https://github.com/thundergolfer/bazel-mypy-integration) is used to check any type annotations at `bazel build` time.

### Infrastructure-as-Code (Hashicorp Terraform)

The [`infrastructure/`](/infrastructure) top-level folder contains Terraform defining various AWS resources and their configuration. 

----

## Development

### Build

`bazel build //...`

### Testing

`bazel test //...`

### Continuous Integration (CI)

This repository's CI is managed by [Buildkite](https://buildkite.com), the CI platform used by Pinterest and Canva to manage Bazel monorepos,
as well as being [used by the Bazel open-source project itself](https://buildkite.com/bazel).

### Deployment & Distribution

Deployable artifacts are pushed to S3 under commit-hash-versioned keys.
Currently only the `store-api` deploy/fat JAR is deployable.

[`graknlabs/bazel-distribution`](https://github.com/graknlabs/bazel-distribution) is used to publish Python packages to PyPi. 

### Build Observability + Analysis

This project is using [Buildbuddy.IO](https://buildbuddy.io/). Every build run locally or in CI get its own `https://app.buildbuddy.io/invocation/xyz123...` URL which analyses and records the build's information.

### Linting

[thundergolfer/bazel-linting-system](https://github.com/thundergolfer/bazel-linting-system) is used. [`./tools/linting/lint.sh`](tools/linting/lint.sh) will lint all source-code in the repo and [`./tools/linting/lint_bzl_files.sh`](tools/linting/lint_bzl_files.sh) will lint all Bazel files.

"
interseroh/demo-gwt-springboot,master,28,27,2016-04-11T13:30:47Z,5480,2,Simple Example WebApp for GWT and Spring Boot,,"# demo-gwt-springboot

## Build Status

[![Build Status](https://travis-ci.org/interseroh/demo-gwt-springboot.svg?branch=master)](https://travis-ci.org/interseroh/demo-gwt-springboot)

## Table of Contents

- [Demo in Heroku](#demo-in-heroku)
- [Introduction](#introduction)
- [Architecture](#architecture)
	- [Model for Services and Domains](#model-for-services-and-domains)
	- [Architecture](#architecture)
	- [Mock Mechanism](#mock-mechanism)
- [Run the WebApp for Development](#run-the-webapp-for-development)
	- [Server: Start the WebApp with Spring Boot](#server-start-the-webapp-with-spring-boot)
	- [Client: Start GWT SuperDev Mode transpiler](#client-start-gwt-superdev-mode-transpiler)
	- [Browser: Call the WebApp demo-gwt-springboot from a web browser](#browser-call-the-webapp-demo-gwt-springboot-from-a-web-browser)
	- [Heroku: Test the Webapp from Heroku](#heroku-test-the-webapp-from-heroku)
- [Logging](#logging)
	- [Server: Logging at the Spring Boot Console](#server-logging-at-the-spring-boot-console)
	- [Client: Logging at the Browser Console](#client-logging-at-the-browser-console)
- [Debugging](#debugging)
	- [Server: Debugging Spring Boot](#server-debugging-spring-boot)
	- [Client: Debugging with GWT SuperDev Mode](#client-gwt-debugging-with-gwt-superdev-mode)
	- [Client: Debugging with Eclipse SDBG](#client-gwt-debugging-with-eclipse-sdbg)
	- [Client: Debugging with IntelliJ IDEA](#client-gwt-debugging-with-intellij-idea)
- [Unit and Integration Testing](#unit-and-integration-testing)
    - [Server: Spring Test](#server-spring-test)
    - [Client: GWT Mockito](#client-gwt-mockito)

## Demo in Heroku

- [Spring GWT Demo in Heroku](https://demo-gwt-springboot.herokuapp.com/demogwt/index.html)

## Introduction

This is an example Maven project for following frameworks:

- User Interfaces (Client): 
  - GWT
  - GWTBootstrap3 for the UI
  - RestyGWT for the RESTful access to backend services
  - GIN for Dependency Injection
  - GWT Event Binder for event bus
  - GWT Mockito for UI logic test
- Controllers and Services (Server): 
  - KissMDA
  - Spring Boot for business logic implementations
  - All the standard stuffs used by Spring Framework
- Domains (Server): 
  - KissMDA
  - JPA with Hibernate
 
The idea of this project is to offer a simple application template 
for the mentioned frameworks above. If you need a more sophisticated GWT application
framework you can use following frameworks:
- ArcBees GWT-Platform: Model-View-Presenter Framework for GWT
- JBoss Errai Framework
- Sencha GXT

The development is based on Maven so this project can be used with Eclipse, IntelliJ or NetBeans.

## Architecture

### Model for Services and Domains

There are two services: *UserService* and *PersonService* and two Entities: *Person* and *Address*. Following diagram shows the structure of the services and the domains.

![Service and Domain Model](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/demo-gwt-springboot-model.jpg)

### Architecture

Following diagram shows the architecture of the **Microservice Demo**.
The naming of the packages *client*, *mock*, *server*, *shared* and *resource* (not shown in diagram) is based on this architecture.

![Architecture](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/demo-gwt-springboot-architecture.jpg)

#### Client

All the GWT (UI and REST client) classes should be located in this package. GWT transpiles all the Java sources into JavaScript sources.

#### Mock

The package consists of the mock implementation of the REST services at the client side (GWT). Instead of calling the real REST services 
it will create the mock data. For this purpose you can use the *development-mock* profile of Maven. It will compile the mock package 
and uses the mock implementation to handle the services. If you want to call the real REST services you can use *development* profile 
and GWT transpiler will remove the mock part. Please take a look the mock mechanism below.

#### Shared

In this package you can put any classes which will be used from both sides: client and server. It is advisable to put *constants* and *endpoints* of the RESTful services so that they point to the same address. Also *DTO* (Data Transfer Objects) for RESTful services should be included in this package. GWT transpiles this package into JavaScript sources.

#### Server

All the *controller*, *service*, *repository* and *domain* classes - based on Spring Framework - should reside in this package. This package will __not be included__ in GWT transpiler.

#### Resource

All the themes for GWTBootstrap3 and general Bootstrap themes like Bootswatch should be located in this package. 

You can take a look the GWT [configuration file](https://github.com/lofidewanto/demo-gwt-springboot/blob/master/src/main/resources/com/lofidewanto/demo/DemoGwt.gwt.xml) to see which packages will be included in GWT transpiler.

### Mock Mechanism

The idea is to be able to develop the UI without any dependencies to the functionality of the REST API. We should be
able to mock the data which come from the REST API.

Following points are important to know:
- All the REST API call should be first implemented using POJO interface so this interface does not
extend the RestyGWT `RestService` interface. Example: [UserClient.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/client/domain/UserClient.java).
- Following is the mock implementation of [MockUserClient.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/mock/domain/MockUserClient.java) 
and real implementation [RestUserClient.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/client/domain/RestUserClient.java).
- We also need to do the same thing for the [ServicePreparator](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/client/common/ServicePreparator.java) class.
- We need a Maven profile `development-mock`. In this profile we call a special GWT module file which will be used to transpile the Java code: 
   - Maven [pom.xml](https://github.com/interseroh/demo-gwt-springboot/blob/master/pom.xml) with a profile: `development-mock`.
   - GWT Module [DemoGwtDevelopmentMock](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/resources/com/lofidewanto/demo/DemoGwtDevelopmentMock.gwt.xml). 
     In this GWT module file we define the `src path` to transpile the `mock` package. 
     Also we define what EntryPoint `DemoGwtMockEntryPoint` class we would like to use in this profile:
        - Real EntryPoint: [DemoGwtEntryPoint.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/client/DemoGwtEntryPoint.java)
        - Mock EntryPoint: [DemoGwtMockEntryPoint.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/mock/DemoGwtMockEntryPoint.java)
   - In the Dependency Injection Gin module we instantiate the correct implementation
     for the [""real - DemoGwtGinModule.java""](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/client/DemoGwtGinModule.java) 
     or for the [""mock - DemoGwtMockWebAppGinModule.java""](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/main/java/com/lofidewanto/demo/mock/DemoGwtMockWebAppGinModule.java).
   
With this mechanism we can develop the UI very fast and we don't need to wait for the REST API to 
be implemented.


## Run the WebApp for Development

### Server: Start the WebApp with Spring Boot

Just run the class *DemoGwtSpringbootApplication* or if you are using Spring Tool Suite just run it with Spring Boot Dashboard:

![STS Spring Boot Dashboard](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/sts-boot-dashboard.png)

#### Tips and Tricks

##### JRebel

- If you are using JRebel you need to put following parameter in VM Arguments, something like:

```java
-javaagent:C:\progjava\jrebel\jrebel.jar
```
or the newer version of JRebel

```java
-agentpath:C:\progjava\jrebel\lib\jrebel64.dll
```

![Spring Boot with JRebel parameter](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/sts-boot-jrebel.png)

- You also have to comment out the Spring Boot Dev Tools dependency in pom.xml.

```java
        <!-- Use this Spring Tool for restarting the app automatically -->
        <!-- Only use this if you don't use JRebel! -->
        <!--
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-devtools</artifactId>
        </dependency>
        -->
```

- To be able to generate the *rebel.xml* you need to compile the project with Maven profile *development*.

![Maven compile with Profile development](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/sts-maven-development-profile.png)

##### Spring Boot Dev Tools

Spring Boot Dev Tools restarts the Spring Boot App automatically if your codes have changed.
You have to deactivate JRebel if you want to use this tool. This Spring Boot Dev Tools dependency should be activated:

```java
        <!-- Use this Spring Tool for restarting the app automatically -->
        <!-- Only use this if you don't use JRebel! -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-devtools</artifactId>
        </dependency>
```

### Client: Start GWT SuperDev Mode transpiler

To be able to test quickly you can use GWT SuperDev Mode. With this tool you can just recompile the changes in GWT Java codes into JavaScript codes without restarting the process.

Follow following steps:

#### Starting GWT SuperDev Mode

Starting GWT SuperDev Mode Compiler from command line or within the development environment with Maven:

```java
mvn -P development gwt:run-codeserver
```

To start with Mock:

```java
mvn -P development-mock gwt:run-codeserver
```

At the end you can see following message:

```java
...
[INFO] The code server is ready at http://localhost:9876/
...
```

#### Bookmark *Dev Mode On*

Now you can go to the given address and boomark the *Dev Mode On* through *drag and drop* into your bookmark menu.

![GWT SuperDev Mode](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/gwt-bookmarks.png)

That's it. You can just push *Dev Mode On* to run the transpiler directly and the WebApp will be reloaded automatically. 

![GWT SuperDev Mode](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/gwt-compiler.png)

### Browser: Call the WebApp demo-gwt-springboot from a web browser

Go to the application URL with a web browser:

```java
http://localhost:9014/demogwt/index.html
```
or just
```java
http://localhost:9014/demogwt
```

### Heroku: Test the Webapp from Heroku

The webapp is installed at Heroku PaaS and you can test it from this address: 
[Demo Webapp](https://demo-gwt-springboot.herokuapp.com/demogwt/)

## Logging

The GWT logging is activated (see [configuration file](https://github.com/lofidewanto/demo-gwt-springboot/blob/master/src/main/resources/com/lofidewanto/demo/DemoGwt.gwt.xml)) at both sides: Client and Server.

### Server: Logging at the Spring Boot Console

![GWT Server Logging](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/gwt-logging-server.png)

### Client: Logging at the Browser Console

![GWT Client Logging](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/gwt-logging-client.png)

## Debugging

### Server: Debugging Spring Boot

Debugging the Spring Boot part can be achieved easily by starting the Spring Boot with Debug mode.

### Client GWT: Debugging with GWT SuperDev Mode

You need to update following file: [configuration file for development](https://github.com/lofidewanto/demo-gwt-springboot/blob/master/src/main/resources/com/lofidewanto/demo/DemoGwtDevelopment.gwt.xml)

```java
    <!-- Compiler agent - we only need to compile for one web browser in development -->
    <!-- If you want to use SDBG for debugging you need to use Chrome == safari -->
    <set-property name=""user.agent"" value=""safari"" />  
```
For all purposes of debugging you need to use Google Chrome as your browser.

### Client GWT: Debugging with Eclipse SDBG

Debugging the GWT part with Eclipse should be done by using [SDBG](https://sdbg.github.io/). 

**Tips and Tricks for Optimizing Transpiler Speed**

There are two GWT configuration files: [_DemoGwtDevelopment.gwt.xml_](https://github.com/lofidewanto/demo-gwt-springboot/blob/master/src/main/resources/com/lofidewanto/demo/DemoGwtDevelopment.gwt.xml) and [_DemoGwt.gwt.xml_](https://github.com/lofidewanto/demo-gwt-springboot/blob/master/src/main/resources/com/lofidewanto/demo/DemoGwt.gwt.xml).
- _DemoGwtDevelopment.gwt.xml_: this config will be used to make the GWT compiling process faster. This only compiles for one web browser and use INFO as logging output.
- _DemoGwt.gwt.xml_: this config will be used for production transpilling. This is optimized for many many production purposes.


### Client GWT: Debugging with IntelliJ IDEA

For debugging gwt with IntelliJ IDEA proceed the following stets. 

#### Prequesites

- JetBrains IntelliJ 2016 Ultimate (Community doesn't support it)
- Chrome browser
- [JetBrains IDE Support Chrome Browser Plugin](https://chrome.google.com/webstore/detail/jetbrains-ide-support/hmhgeddbohgjknpmjagkdomcpobmllji)
- Enabled GWT Plugin in IntelliJ

#### Overview
The following diagram shows the different parts of the setup:

![GWT Client Logging](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-debugging-setup-diagram.png)

#### Step by step

##### Open Project in IntelliJ

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-import-project.png)

After this the project is loaded and the `DemoGwtSpringbootApplication` will be added to the `RunConfigurations` automatically.

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-import-project.png)

##### Configure Web Facet

Open in the `FileMenu` the `Project Structure`

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-open-project-structure.png)

Add add under `Facets` a `Web Facet` to the project

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-add-web-facet.png)

Add the facet to the `demo-gwt-springboot` module:

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-choose-module.png)

The path must be set to `src/main/resources/public` and the context must be `/demogwt`.

**Important**

Do not add the web.xml to git. Just ignore it.

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-do-not-add-web.xml.png)

###### Do not generate Artifacts

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-configure-web-facet-add-contextpath.png) 

Close the `Project Structure` with `Ok` and reopen it. Now the `Web Facet` can be selected in the GWT Module.

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-configure-web-facet-2.png) 

After this you should select only the GWT Module `DemoGwtDevelopment`

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-configure-web-facet.png) 

##### GWT Configuration
Add a new Run Configuration

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-open-run-configuration.png) 

And a GWT Configuration:

![Open Project in IntelliJ](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-add-gwt-run-configuration.png) 

After this you start the ""Spring Boot Project"" first and after this the ""GWT-Project"" in Debug mode.

##### Codeserver

Now you have to repeat the steps to configure the code server (see above).


##### Running the debugger with the IDE Support Plugin 

You should see the alert that the »JetBrains IDE Support« is running in debug mode. 

If you have any trouble connecting the browser with the idea, please check the ports of the browser plugin and Intellij. 

Right click on the Life Edit extension and choose Options:

![GWT Client Logging](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-debugging-session-is-running.png)

The default port is `63342`.

![GWT Client Logging](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-ide-support-options.png)

And check if the port in the Intellij IDEA debugger is configured on the same port.

![GWT Client Logging](https://raw.github.com/lofidewanto/demo-gwt-springboot/master/src/main/docs/idea-ide-support-preferences-configure-port.png)

## Unit and Integration Testing

### Server: Spring Test

Examples of unit test with POJO and Mockito:
- [PersonImplTest.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/test/java/com/lofidewanto/demo/server/domain/PersonImplTest.java)
- [PersonServiceImplTest.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/test/java/com/lofidewanto/demo/server/service/person/PersonServiceImplTest.java)

Examples of integration test with Spring and in memory database:
- [PersonServiceImplIT.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/test/java/com/lofidewanto/demo/server/service/person/PersonServiceImplIT.java)

### Client: GWT Mockito

We use GWT Mockito for writing the GWT user interface unit test. Following is an example of GWT Mockito unit test:
- [MainPanelViewTest.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/test/java/com/lofidewanto/demo/client/ui/main/MainPanelViewTest.java)
- [PersonPanelViewTest.java](https://github.com/interseroh/demo-gwt-springboot/blob/master/src/test/java/com/lofidewanto/demo/client/ui/person/PersonPanelViewTest.java)

"
runabol/spring-security-passwordless,master,128,22,2018-01-28T21:19:55Z,151,0,Passwordless authentication example application using Spring Boot and Spring Security,apache2 java passwordless-login springboot springsecurity,"# Introduction

We all have a love/hate relationship with passwords. They protect our most valuable assets but they are so god damn hard to create and remember. 

And just to make things even harder for us humans, more and more companies are now enforcing two factor authentication (you know, the little phone pincode thing) to make it even more complicated to login to our accounts.

Despite advances in biometric authentication (fingerprint, face recognition etc.), passwords still remain the most ubiqutous form of authentication. 

So what can we do to help our fellow users to access our application in an easier manner but without compromising security?

This is where passwordless login comes in.

How does it work? 

If you ever went to a website, realized you forgot your password and then used their ""Forgot Password"" then you know what passwordless login is. 

After you entered your email address on the Reset Password page you were sent a ""magic"" link with a special code (a.k.a ""token"") embedded in it which provided you with the ability to reset your password. 

That website piggy-backed on your already-password-protected email address to create a secure, one-time-password ""magic"" link to your account. 

Well, if we can do all that in a presumably safe way when the user loses his password why can't we do it whenever a user wants to login? Sure we can.

Oh, and just in case you're wondering some big name (Slack, Medium.com, Twitter) companies are already using this method of authentication.

Alright, let's get down to business then.  

# The nitty gritty

1. Create a [sign-up/sign-in page](https://github.com/creactiviti/spring-security-passwordless/blob/master/src/main/resources/templates/signin.html). It basically needs only one field: email.

```
<input type=""email"" name=""email"" class=""form-control"" placeholder=""Email address"" required autofocus>
```

2. Create an [endpoint](https://github.com/creactiviti/spring-security-passwordless/blob/master/src/main/java/com/creactiviti/spring/security/passwordless/web/SigninController.java#L35) to handle the form submission:

```
  private final TokenStore tokenStore;
  private final Sender sender;

  @PostMapping(""/signin"")
  public String signin (@RequestParam(""email"") String aEmail) {
    
    // verify that the user is in the database.
    // ...
    
    // create a one-time login token
    String token = tokenStore.create(aEmail);
    
    // send the token to the user as a ""magic"" link
    sender.send(aEmail, token);
    
    return ""login_link_sent"";
  }
```

3. Create an [endpoint](https://github.com/creactiviti/spring-security-passwordless/blob/master/src/main/java/com/creactiviti/spring/security/passwordless/web/SigninController.java#L48) to authenticate the user based on the ""magic"" link:

```
  private final Authenticator authenticator;

  @GetMapping(""/signin/{token}"")
  public String signin (@RequestParam(""uid"") String aUid, @PathVariable(""token"") String aToken) {
    try {
      authenticator.authenticate(aUid, aToken);
      return ""redirect:/"";
    }
    catch (BadCredentialsException aBadCredentialsException) {
      return ""invalid_login_link"";
    }
  }
```

And that's about it.

# Securing the ""magic"" link.

There are few precautions you should take to keep the ""magic"" link as secure as possible:

1. When sending the link to the user communicate to your email server over SSL. 

2. Tokens should only be usable once. 

3. Tokens should not be easily guessable. Use a good, cryptographically strong random number generator. e.g:

```
    SecureRandom random = new SecureRandom();
    byte bytes[] = new byte[TOKEN_BYTE_SIZE];
    random.nextBytes(bytes);
    String token = String.valueOf(Hex.encode(bytes));
```
     
4. Tokens should expire after a reasonable amount of time (say 15 minutes). In this example I use an in-memory `TokenStore` implementation backed by a `SelfExpringHashMap` which as its name suggests expires entries after a given amount of time. In a real-world scenario you will most likely use a database to store your generated tokens so your website can run on more than one machine and so these tokens survive a crash. But the principle is the same. You can have a `created_at` field which stamps the time the token was created so you can determine if it expired or not.


# Running the demo

1. Clone the repo:

```
git clone https://github.com/creactiviti/spring-security-passwordless.git
```

2. Build

```
mvn clean spring-boot:run -Dspring.mail.host=<SMTP HOST> -Dspring.mail.username=<SMTP USERNAME> -Dspring.mail.password=<SMTP PASSWORD> -Dpasswordless.email.from=<SENDER EMAIL ADDRESS>
```

3. Sign-in

Go to [http://localhost:8080/signin](http://localhost:8080/signin)


# License

Apache License version 2.0.

"
lomza/AppBar-ScrollFlags-Example,master,29,7,2017-12-11T20:48:28Z,1695,0,Examples of AppBarLayout's usage of layout_scrollFlags attribute,,"# AppBar-ScrollFlags-Example
Examples of AppBarLayout's usage of layout_scrollFlags attribute

![example of AppBar enteralwayscollapse flag](https://cdn-images-1.medium.com/max/800/0*FqTLqbo35WDoi6rI.gif)
"
thegreystone/java-svc,master,31,8,2018-08-23T14:10:09Z,258,1,"Java serviceability examples. Includes simple example apps for jmc, jfr, attach, jmx, jplis, jdi and perfcounters.",hacktoberfest hacktoberfest2021,"# java-svc
This repository contains a set of small examples that can be used to demonstrate various popular Java serviceability technologies. The examples are focused on making it easy to getting going with the various serviceability technologies. 

Note that there are already technology demonstrators for most technologies among the standard java demos. The demos in this repository, however, are focusing on making it easier to get started. The examples are easy to build and run, and they are easily digested. Everyone should dare experimenting with these, even relatively inexperienced developers. Not to mention that I needed examples that fit on a slide for a talk. ;)

## Prerequisites
All projects can build with JDK11, and most will build on JDK 8 as well.

You will also need to have Maven 3.5.3+ installed.

## Building
To build all the projects in one go, ensure that you are using JDK 11, and simply run:

```bash
mvn package
```

The projects can also be built individually by entering the subprojects. Some projects may require a `mvn install` of a dependent project to be built in such a manner.

## Running the Projects
Check the README.md files in the subfolders for instructions on how to run the examples.
"
qct/swagger-example,master,48,64,2017-11-10T02:47:39Z,12527,1,"Introduction and Example for OpenAPI specification & Swagger Open Source Tools, including swagger-editor, swagger-codegen and swagger-ui. Auto generation example for client SDKs, server code, asciidoctor and html documents.",asciidoc asciidoctor asciidoctor-converter asciidoctor-pdf spring-boot springfox swagger swagger-api swagger-codegen swagger-docs swagger-editor swagger-generator swagger-spec swagger-specification swagger-ui swagger2 swagger2markup,"# Swagger Introduction & Examples
- [Quick Start](#quick-start)  
- [OpenAPI & Swagger](#openapi--swagger)
  * [OpenAPI](#openapi)
  * [Swagger](#swagger)
  * [Why Use OpenAPI?](#why-use-openapi)
- [Introduction to OpenAPI Specification](#introduction-to-openapi-specification)
  * [Basic Structure](#basic-structure)
  * [Metadata](#metadata)
  * [Base URL](#base-url)
  * [Consumes, Produces](#consumes-produces)
  * [Paths](#paths)
  * [Parameters](#parameters)
  * [Responses](#responses)
  * [Input and Output Models](#input-and-output-models)
  * [Authentication](#authentication)
- [Introduction to Swagger Open Source Tools](#introduction-to-swagger-open-source-tools)
  * [Swagger Editor](#swagger-editor)
  * [Swagger Codegen](#swagger-codegen)
  * [Swagger UI](#swagger-ui)
- [asciidoctor](#asciidoctor)


[中文版本Chinese version](README.zh-CN.md)

## Quick Start

1. install: after git clone, execute commands below in root directory:

```
swagger-server/bin/install.sh
```

doing that will produce some client SDKs, server code, asciidoc and html documents, look like this:

```
+---asciidoc                    //asciidoc document
+---client                      //auto Generated client SDKs
|   +---go                      //-- client SDK in go programming language
|   +---html2                   //-- html document
|   \---java                    //-- client SDK in java programming language
+---docs                        //html document
|       swagger-example.html  
+---server                      //auto generated server code
|   +---jaxrs-resteasy          //-- jaxrs server code that uses resteasy
|   \---spring                  //-- server code that uses spring mvc
\---swagger-server              // example
```

2. run swagger-server：

```
java -jar swagger-server/target/swagger-server-${version}.jar
```

3. explore:

swagger.json: `http://127.0.0.1:8080/v2/api-docs`

swagger-ui: `http://127.0.0.1:8080/swagger-ui.html`

swagger-ui looks like this:
![Demo-Api](swagger-ui.png)

---
### ***Introduction to OpenAPI & Swagger Open Source Tools***

## OpenAPI & Swagger
### OpenAPI
**OpenAPI Specification** (formerly Swagger Specification) is an API description format for REST APIs. An OpenAPI file allows you to describe your entire API, including:

* Available endpoints (```/users```) and operations on each endpoint (```GET /users```, ```POST /users```)
* Operation parameters Input and output for each operation
* Authentication methods
* Contact information, license, terms of use and other information.

API specifications can be written in YAML or JSON. The format is easy to learn and readable to both humans and machines. The complete OpenAPI Specification can be found on GitHub: 
[OpenAPI 2.0 Specification](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md),
[OpenAPI 3.0 Specification](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md)

### Swagger

Swagger is a set of open-source tools built around the OpenAPI Specification that can help you design, build, document and consume REST APIs. The major Swagger tools include:

* [Swagger Editor](http://editor.swagger.io/?_ga=2.27098621.139862542.1529283950-1958724428.1521772135) – browser-based editor where you can write OpenAPI specs.
* [Swagger Codegen](https://github.com/swagger-api/swagger-codegen) – generates server stubs and client libraries from an OpenAPI spec.
* [Swagger UI](https://swagger.io/swagger-ui/) – renders OpenAPI specs as interactive API documentation.

### Why Use OpenAPI?
The ability of APIs to describe their own structure is the root of all awesomeness in OpenAPI. Once written, an OpenAPI specification and Swagger tools can drive your API development further in various ways:

* Design-first users: use [Swagger Codegen](https://github.com/swagger-api/swagger-codegen) to **generate a server stub** for your API. The only thing left is to implement the server logic – and your API is ready to go live!
* Use [Swagger Codegen](https://github.com/swagger-api/swagger-codegen) to **generate client libraries** for your API in over 40 languages.
* Use [Swagger UI](https://swagger.io/swagger-ui/) to generate **interactive API documentation** that lets your users try out the API calls directly in the browser.
* Use the spec to connect API-related tools to your API. For example, import the spec to [SoapUI](https://soapui.org/) to create automated tests for your API.
* And more! Check out the [open-source tools](https://swagger.io/open-source-integrations/) that integrate with Swagger.

-----

## Introduction to OpenAPI Specification

### **Basic Structure**
Swagger can be written in JSON or YAML. In this guide, we only use YAML examples, but JSON works equally well. A sample Swagger specification written in YAML looks like:

```yaml
swagger: ""2.0""
info:
  title: Sample API
  description: API description in Markdown.
  version: 1.0.0
host: api.example.com
basePath: /v1
schemes:
  - https
paths:
  /users:
    get:
      summary: Returns a list of users.
      description: Optional extended description in Markdown.
      produces:
        - application/json
      responses:
        200:
          description: OK
```


### **Metadata**
Every Swagger specification starts with the Swagger version, 3.0 being the latest version. A Swagger version defines the overall structure of an API specification -- what you can document and how you document it.

```yaml
swagger: ""2.0""
```

Then, you need to specify the ```API info``` -- ```title```, ```description``` (optional), ```version``` (API version, not file revision or Swagger version).

```yaml
info:
  title: Sample API
  description: API description in Markdown.
  version: 1.0.0
```

```version``` can be a random string. You can use major.minor.patch (as in [semantic versioning](http://semver.org/)), or an arbitrary format like 1.0-beta or 2016.11.15. 

```description``` can be [multiline](http://stackoverflow.com/a/21699210) and supports [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/) for rich text representation. 

```info``` also supports other fields for contact information, license and other details. Reference: [Info Object](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md#infoObject).


### **Base URL**
The base URL for all API calls is defined using ```schemes```, ```host``` and ```basePath```:

```yaml
host: api.example.com
basePath: /v1
schemes:
  - https
```

All API paths are relative to the base URL. For example, /users actually means *https://api.example.com/v1/users. 

More info*: [API Host and Base URL](https://swagger.io/docs/specification/2-0/api-host-and-base-path/).


### **Consumes, Produces**

The ```consumes``` and ```produces``` sections define the MIME types supported by the API. The root-level definition can be overridden in individual operations.

```yaml
consumes:
  - application/json
  - application/xml
produces:
  - application/json
  - application/xml
```

*More info*: [MIME Types](https://swagger.io/docs/specification/2-0/mime-types/).
  
### **Paths**
The ```paths``` section defines individual endpoints (paths) in your API, and the HTTP methods (operations) supported by these endpoints. For example, ```GET /users``` can be described as:

```yaml
paths:
  /users:
    get:
      summary: Returns a list of users.
      description: Optional extended description in Markdown.
      produces:
        - application/json
      responses:
        200:
          description: OK
          
```

*More info*: [Paths and Operations](https://swagger.io/docs/specification/2-0/paths-and-operations/).

### **Parameters**
Operations can have parameters that can be passed via URL path (```/users/{userId}```), query string (```/users?role=admin```), headers (```X-CustomHeader: Value```) and request body. 
You can define the parameter types, format, whether they are required or optional, and other details:

```yaml
paths:
  /users/{userId}:
    get:
      summary: Returns a user by ID.
      parameters:
        - in: path
          name: userId
          required: true
          type: integer
          minimum: 1
          description: Parameter description in Markdown.
      responses:
        200:
          description: OK
```

*More info*: [Describing Parameters](https://swagger.io/docs/specification/2-0/describing-parameters/).

### **Responses**
For each operation, you can define possible status codes, such as 200 OK or 404 Not Found, and ```schema``` of the response body. 
Schemas can be defined inline or referenced from an external definition via ```$ref```. You can also provide example responses for different content types.

```yaml
paths:
  /users/{userId}:
    get:
      summary: Returns a user by ID.
      parameters:
        - in: path
          name: userId
          required: true
          type: integer
          minimum: 1
          description: The ID of the user to return.
      responses:
        200:
          description: A User object.
          schema:
            type: object
            properties:
              id:
                type: integer
                example: 4
              name:
                type: string
                example: Arthur Dent
        400:
          description: The specified user ID is invalid (e.g. not a number).
        404:
          description: A user with the specified ID was not found.
        default:
          description: Unexpected error
```

*More info*: [Describing Responses](https://swagger.io/docs/specification/2-0/describing-responses/).

### **Input and Output Models**
The global ```definitions``` section lets you define common data structures used in your API. They can be referenced via ```$ref``` 
whenever a ```schema``` is required -- both for request body and response body. For example, this JSON object:

```json
{
  ""id"": 4,
  ""name"": ""Arthur Dent""
}
```
can be represented as:
```yaml
definitions:
  User:
    properties:
      id:
        type: integer
      name:
        type: string
    # Both properties are required
    required:  
      - id
      - name
```

and then referenced in the request body schema and response body schema as follows:

```yaml
paths:
  /users/{userId}:
    get:
      summary: Returns a user by ID.
      parameters:
        - in: path
          name: userId
          required: true
          type: integer
      responses:
        200:
          description: OK
          schema:
            $ref: '#/definitions/User'
  /users:
    post:
      summary: Creates a new user.
      parameters:
        - in: body
          name: user
          schema:
            $ref: '#/definitions/User'
      responses:
        200:
          description: OK
```


### **Authentication**
The ```securityDefinitions``` and ```security``` keywords are used to describe the authentication methods used in your API.

```yaml
securityDefinitions:
  BasicAuth:
    type: basic
security:
  - BasicAuth: []
```

Supported authentication methods are:
* [Basic authentication](https://swagger.io/docs/specification/2-0/authentication/basic-authentication/)
* [API key](https://swagger.io/docs/specification/2-0/authentication/api-keys/) (as a header or query parameter)
* OAuth 2 common flows (implicit, password, application and access code)

*More info*: [Authentication](https://swagger.io/docs/specification/2-0/authentication/).


## Introduction to Swagger Open Source Tools
### **Swagger Editor**
Design, describe, and document your API on the first open source editor fully dedicated to OpenAPI-based APIs. 
The Swagger Editor is great for quickly getting started with the OpenAPI (formerly known as the Swagger Specification) specification, with support for Swagger 2.0 and OpenAPI 3.0. 

* Runs Anywhere: The Editor works in any development environment, be it locally or in the web
* Smart Feedback: Validate your syntax for OAS-compliance as you write it with concise feedback and error handling
* Instant Visualization: Render your API specification visually and interact with your API while still defining it
* Intelligent Auto-completion: Write syntax faster with a smart and intelligent auto-completion
* Fully Customizable: Easy to configure and customize anything, from line-spacing to themes
* All About Your Build: Generate server stubs and client libraries for your API in every popular language

### **Swagger Codegen**
Swagger Codegen can simplify your build process by generating server stubs and client SDKs for any API, defined with the OpenAPI (formerly known as Swagger) specification, 
so your team can focus better on your API’s implementation and adoption.

* Generate Servers: Remove tedious plumbing and configuration by generating boilerplate server code in over 20 different languages
* Improve API Consumption: Generate client SDKs in over 40 different languages for end developers to easily integrate with your API
* Continuously Improved: Swagger Codegen is always updated with the latest and greatest changes in the programming world

### **Swagger UI**
Swagger UI allows anyone — be it your development team or your end consumers — to visualize and interact with the API’s resources without having any of the implementation logic in place. 
It’s automatically generated from your OpenAPI (formerly known as Swagger) Specification, with the visual documentation making it easy for back end implementation and client side consumption.

* Dependency Free: The UI works in any development environment, be it locally or in the web
* Human Friendly: Allow end developers to effortlessly interact and try out every single operation your API exposes for easy consumption
* Easy to Navigate: Quickly find and work with resources and endpoints with neatly categorized documentation
* All Browser Support: Cater to every possible scenario with Swagger UI working in all major browsers
* Fully Customizable: Style and tweak your Swagger UI the way you want with full source code access
* Complete OAS Support: Visualize APIs defined in Swagger 2.0 or OAS 3.0

## **asciidoctor**
* asciidoc
* asciidoctor

[Asciidoctor](https://asciidoctor.org/) is a fast text processor and publishing toolchain for converting [AsciiDoc](https://asciidoctor.org/docs/what-is-asciidoc) content to HTML5, DocBook, PDF, and other formats. 
Asciidoctor is written in Ruby, packaged and distributed as a gem to [RubyGems.org](https://rubygems.org/gems/asciidoctor), and packaged for popular Linux distributions, including Fedora, Debian, Ubuntu, and Alpine. 
Asciidoctor can be run on the JVM using AsciidoctorJ and in all JavaScript environments using Asciidoctor.js. Asciidoctor is [open source software](https://github.com/asciidoctor/asciidoctor/blob/master/LICENSE) 
and hosted on [GitHub](https://github.com/asciidoctor/asciidoctor).
"
Udinic/PerformanceDemo,master,120,13,2015-08-31T06:22:38Z,364,0,"Simple demonstrations of performance issues. Using these examples will allow practicing performance analyzing tools, such as Systrace, Traceview and more.",,"# PerformanceDemo
Simple demonstrations of performance issues. Using these examples will allow practicing performance analyzing tools, such as Systrace, Traceview and more.

## Perf Demo
This is the main app, showing a few options to simulate different performance issues.

## Keep Busy app
Simple app to keep the CPU busy. Useful to test how other processes affects your app, and more.
Currently, the app creates 4 threads and takes about ~8 seconds to complete. You can play with the values in the service to tweak that.
Running the process is possible through the adb command:

    adb shell am broadcast -a com.udinic.keepbusyapp.ACTION_KEEP_BUSY

Note: you must open the app's activity at least once before that, due to Android security measures to prevent apps from responding to broadcasts before opening the app for the first time.
"
luontola/cqrs-hotel,master,71,16,2016-11-10T18:34:39Z,651,1,Example application about CQRS and Event Sourcing #NoFrameworks,,"
# CQRS Hotel

Example application demonstrating the use of [CQRS](http://martinfowler.com/bliki/CQRS.html) and [Event Sourcing](http://martinfowler.com/eaaDev/EventSourcing.html) within the domain of hotel reservations. #NoFrameworks

This project is a sandbox for exploring how CQRS+ES affects the design of a system. The hypothesis is that it will lead to a better design than a typical database-centric approach; a design that is easily testable and does not detiorate as features are added. To answer that question, the problem being solved needs to be complex enough.

This project strives to differ from your typical toy examples in that *the problem domain is complex enough to warrant all the techniques being used.* The solution has been simplified, but the implemented features are production quality.

**Source Code:** <https://github.com/luontola/cqrs-hotel>

 `master` branch  | API container | Web container
:----------------:|:-------------:|:-------------:
[![CI Build Status](https://travis-ci.org/luontola/cqrs-hotel.svg?branch=master)](https://travis-ci.org/luontola/cqrs-hotel) | [![Docker Build Status - API](https://img.shields.io/docker/build/luontola/cqrs-hotel-api.svg)](https://hub.docker.com/r/luontola/cqrs-hotel-api/) | [![Docker Build Status - Web](https://img.shields.io/docker/build/luontola/cqrs-hotel-web.svg)](https://hub.docker.com/r/luontola/cqrs-hotel-web/)


## Project Status

- technical features
    - [x] event store
    - [x] aggregate roots (write model)
    - [x] projections (read model)
    - [ ] process managers
    - [ ] GDPR compliance
- business features
    - [x] making a reservation
    - [ ] room allocation
    - [ ] payment
    - [ ] check-in, check-out
    - [ ] changing the departure date
    - [ ] changing the room


## Getting Started / Codebase Tour

Here are some pointers for where to look first in the code.

The [**web application's**](https://github.com/luontola/cqrs-hotel/tree/master/src/main/js) entry point is [index.js](https://github.com/luontola/cqrs-hotel/blob/master/src/main/js/index.js) and the entry points for each page are in [routes.js](https://github.com/luontola/cqrs-hotel/blob/master/src/main/js/routes.js). The UI is a single-page application which uses React and Redux but otherwise tries to avoid frameworks.

The [**backend application's**](https://github.com/luontola/cqrs-hotel/tree/master/src/main/java/fi/luontola/cqrshotel) main method is in [Application.java](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/Application.java) and the entry points for each operation are in [ApiController.java](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/ApiController.java). External dependencies are wired with Spring in `Application`, but the application core is wired in `ApiController` constructor. See there the command handlers and query handlers which are the entry point to the business logic.

The **framework** code is in the [fi.luontola.cqrshotel.framework package](https://github.com/luontola/cqrs-hotel/tree/master/src/main/java/fi/luontola/cqrshotel/framework). It contains in-memory and PostgreSQL implementations of the event store (the latter's PL/SQL scripts are in [src/main/resources/db/migration](https://github.com/luontola/cqrs-hotel/tree/master/src/main/resources/db/migration)), and base classes for aggregate roots and projections. CQRS with event sourcing requires very little infrastructure code, so you can easily write it yourself without external frameworks, which helps to reduce complexity.

To learn how the **write models** work, read how a reservation is made, starting from [SearchForAccommodationCommandHandler](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/reservation/commands/SearchForAccommodationCommandHandler.java) and [MakeReservationHandler](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/reservation/commands/MakeReservationHandler.java). The handlers contain no business logic. Instead, they delegate to [Reservation](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/reservation/Reservation.java) which does all the work. Read the [AggregateRoot](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/framework/AggregateRoot.java) base class, including its documentation, to understand how it should be used.

Of particular interest is how easy it is to **unit test** event sourced business logic. See [SearchForAccommodationTest](https://github.com/luontola/cqrs-hotel/blob/master/src/test/java/fi/luontola/cqrshotel/reservation/SearchForAccommodationTest.java) and [MakeReservationTest](https://github.com/luontola/cqrs-hotel/blob/master/src/test/java/fi/luontola/cqrshotel/reservation/MakeReservationTest.java). The given/when/then methods are in the simple [AggregateRootTester](https://github.com/luontola/cqrs-hotel/blob/master/src/test/java/fi/luontola/cqrshotel/framework/AggregateRootTester.java) base class.

To learn how the **read models** work, read [ReservationsView](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/reservation/queries/ReservationsView.java) and the base class [Projection](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/framework/Projection.java). Unit testing is again simple: [ReservationsViewTest](https://github.com/luontola/cqrs-hotel/blob/master/src/test/java/fi/luontola/cqrshotel/reservation/queries/ReservationsViewTest.java). Unlike aggregate roots, projections can listen to all events in the system; for example [CapacityView](https://github.com/luontola/cqrs-hotel/blob/master/src/main/java/fi/luontola/cqrshotel/capacity/CapacityView.java) is based on events from both Rooms and Reservations.


## Running

The easiest way to run this project is to use [Docker](https://www.docker.com/community-edition).

Start the application

    docker-compose pull
    docker-compose up -d 

The application will run at http://localhost:8080/

View application logs (in `--follow` mode)

    docker-compose logs -f api

Stop the application

    docker-compose stop

Stop the application and remove all data 

    docker-compose down


## Developing

To develop this project, you must have installed recent versions of [Java (JDK)](http://www.oracle.com/technetwork/java/javase/downloads/), [Maven](https://maven.apache.org/), [Node.js](https://nodejs.org/), [Yarn](https://yarnpkg.com/) and [Docker](https://www.docker.com/community-edition). You can do a clean build with the `./build.sh` script. You can run this project's components individually with the following commands.

Start the database

    docker-compose up -d db

Start the API backend (if not using an IDE)

    mvn spring-boot:run

Start the web frontend (with live reloading)

    yarn install
    yarn start

The application will run at http://localhost:8080/

You may also start just the frontend or backend using Docker if you're developing only one layer of the application.  

    docker-compose up -d api
    docker-compose up -d web


## More Resources

This example was mostly inspired by the following resources.

* [Greg Young's CQRS Class](https://goodenoughsoftware.net/online-videos/)
    * [An older free video](https://www.youtube.com/watch?v=whCk1Q87_ZI) and [its documentation](https://cqrs.wordpress.com/documents/)
* [Simple CQRS example](https://github.com/gregoryyoung/m-r)
* [Building an Event Storage](https://cqrs.wordpress.com/documents/building-event-storage/)

For more resources visit [Awesome Domain-Driven Design](https://github.com/heynickc/awesome-ddd). Ask questions at the [DDD/CQRS discussion group](https://groups.google.com/forum/#!forum/dddcqrs).
"
jakubnabrdalik/hentai,master,210,51,2017-05-12T14:25:02Z,10128,5,"Example of Hexagonal architecture with high cohesion modularization, CQRS and fast BDD tests in Java",,"# Example of Hexagonal architecture with high cohesion modularization, CQRS and fast BDD tests in Java

This repo is an example of Hexagonal architecture with sensible modularization on a package level, that provides high cohesion, low coupling, and allows for Behaviour Driven Development that has

- allows for most tests to be run in milliseconds (unit tests without IO)
- while at the same time not falling into the trap of testing INTERNALS of a module (no test-per-class mistake)
- tests that focus on behaviour of each module (refactoring does not require changing test)
- just enough intergration/acceptance tests with focus on performance (minimum waiting for tests to pass)
- tests that describe requirements (living documentation)
- modules that have high cohesion (everything hidden except for APIs) and low coupling (modules connected via their APIs
- easy to explain, understand and follow

This example follows the type of code I write at work on a daily basis. So while this is an artificial example, all the rules and architecture approach are the effect of what works for my teams in real life projects.

I use this project to teach Behaviour Driven Development, Domain Driven Design, Command Query Responsibility Segregation and to show Spring live-coding.

Pull requests are welcome.

---

# The problem

Each project starst with a problem, from which we get a set of requirements. Here I'm using a task I once received as a homework from a company, that wanted to asses new candidates.

## Project – Video rental store

For a video rental store we want to create a system for managing the rental administration.
We want three primary functions.
- Have an inventory of films
- Calculate the price for rentals
- Keep track of the customers “bonus” points

## Price
The price of rentals is based type of film rented and how many days the film is rented for.
The customers say when renting for how many days they want to rent for and pay up front. If
the film is returned late, then rent for the extra days is charged when returning.

## Film types
The store has three types of films.
- New releases – Price is <premium price> times number of days rented.
- Regular films – Price is <basic price> for the fist 3 days and then <basic price> times the number of days over 3.
- Old film - Price is <basic price> for the fist 5 days and then <basic price> times the number of days over 5

<premium price> is 40 SEK
<basic price> is 30 SEK

The program should expose a rest-ish HTTP API.
The API should (at least) expose operations for

- Renting one or several films and calculating the price.
- Returning films and calculating possible surcharges.

## Examples of price calculations

Matrix 11 (New release) 1 days 40 SEK
Spider Man (Regular rental) 5 days 90 SEK
Spider Man 2 (Regular rental) 2 days 30 SEK
Out of Africa (Old film) 7 days 90 SEK
Total price: 250 SEK

When returning films late
Matrix 11 (New release) 2 extra days 80 SEK
Spider Man (Regular rental) 1 days 30 SEK
Total late charge: 110 SEK

## Bonus points
Customers get bonus points when renting films. A new release gives 2 points and other films
give one point per rental (regardless of the time rented).

---

# Acceptance specifications

After gathering a problem description in a natural language, the next step is to crete Specifications for our project. That is, to split our requirements into a set of scenarios that describe the behaviour of a system. 

Years ago this used to be done using Use Cases. Later on, the industry simplified this  to user stories, and now we follow the best practices of BDD. For this very simple project, we can create one main happy path specification. If this specification is implemented, our project brings money. 

## Happy path scenario:

As a hipster-deviant, to satisfy my weird desires, I want to:

given inventory has an old film ""American Clingon Bondage"" and a new release of ""50 shades of Trumpet""

when I go to /films
then I see both films

when I go to /points
then I see I have no points

when I post to /calculate with both films for 3 days
then I can see it will cost me 120 SEK for Trumpet and 90 SEK for Clingon

when I post to /rent with both firms for 3 days
then I have rented both movies

when I go to /rent
then I see both movies are rented

when I go to /points
then I see I have 3 points

when I post to /return with Trumper
then trumper is returned

when I go to /rent
then I see only Clingon is rented

---

# Modules

Now, let's do just enough design up front. Let's split the application into modules.

This is the list of our modules with their responsibilities 

films
- list
- show
- add

rentals
- rent
- calculatePrice
- return
- list

points
- list
- addForRent

user
- getLoggedUser

We verify that our module design is solid by checking the number of communications between modules. High cohesion / low coupling means, that modules do not talk to often with each other, and that our API stays small.

---

# Implementation

We are ready to actually implement something using BDD. We shall start with implementing the acceptance spec (the only integration test so far), and then the film module. Watch git history for more details about each step.
"
codetojoy/easter_eggs_for_java_9,master,31,13,2017-03-18T09:33:54Z,2048,1,Basic examples for Java 9 modules.  Usage of 'egg' here is SSCCE: http://sscce.org,,"### Eggs for Java 9 Modules

* some basic examples for Java 9 modules 
* usage of *'egg'* here is [SSCCE](http://sscce.org/) **not** a [hidden feature](https://en.wikipedia.org/wiki/Easter_egg_(media)) !
* see notes below to use JDK9 in Docker
* see README.md in each folder for steps to execute

### validation log
* confirmed 29-JUN-2017 with b175 
* confirmed 01-JUN-2017 with b171 via Travis-CI
* confirmed 12-MAY-2017 with b169 via Docker automenta/javai [image](https://hub.docker.com/r/automenta/javai/)
    * set JAVA_HOME for jlink
* confirmed 05-MAY-2017 with b168 via Docker automenta/javai [image](https://hub.docker.com/r/automenta/javai/)
    * set JAVA_HOME for jlink
* confirmed 05-MAY-2017 with b167 via sdkman
* confirmed 03-APR-2017 with b161
* build tickle here: 01-JUN-2017

### Setup for Docker (optional)

* These instructions work for Mac OS X. Tweak as appropriate
* Open 'Docker Quick Start Terminal'

* set `MY_SRC_HOME` to be appropriate directory on your computer where this repo is located
* steps:

<pre>
docker pull automenta/javai:latest
cd $MY_SRC_HOME
docker run --rm -t -i -v $(pwd):/data automenta/javai bash
export JAVA_HOME=/j/jdk9/bin
java --version
cd /data
</pre>
"
LambdaTest/java-testng-selenium,master,52,92,2019-01-17T14:41:21Z,987,0,Run TestNG and Selenium scripts on LambdaTest automation cloud. A sample repo to help you run TestNG framework based test scripts in parallel with LambdaTest,automation automation-testing cloud example examples java lambdatest selenium selenium-grid selenium-webdriver selenium4 test-automation testing testng,"# Run Selenium Tests With TestNG On LambdaTest

![image](https://user-images.githubusercontent.com/70570645/171934563-4806efd2-1154-494c-a01d-1def95657383.png)


<p align=""center"">
  <a href=""https://www.lambdatest.com/blog/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium"" target=""_bank"">Blog</a>
  &nbsp; &#8901; &nbsp;
  <a href=""https://www.lambdatest.com/support/docs/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium"" target=""_bank"">Docs</a>
  &nbsp; &#8901; &nbsp;
  <a href=""https://www.lambdatest.com/learning-hub/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium"" target=""_bank"">Learning Hub</a>
  &nbsp; &#8901; &nbsp;
  <a href=""https://www.lambdatest.com/newsletter/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium"" target=""_bank"">Newsletter</a>
  &nbsp; &#8901; &nbsp;
  <a href=""https://www.lambdatest.com/certification/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium"" target=""_bank"">Certifications</a>
  &nbsp; &#8901; &nbsp;
  <a href=""https://www.youtube.com/c/LambdaTest"" target=""_bank"">YouTube</a>
</p>
&emsp;
&emsp;
&emsp;

*Learn how to use TestNG framework to configure and run your Java automation testing scripts on the LambdaTest platform*

[<img height=""58"" width=""200"" src=""https://user-images.githubusercontent.com/70570645/171866795-52c11b49-0728-4229-b073-4b704209ddde.png"">](https://accounts.lambdatest.com/register?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)

## Table Of Contents

* [Pre-requisites](#pre-requisites)
* [Run Your First Test](#run-your-first-test)
* [Parallel Testing With TestNG](#executing-parallel-tests-using-testng)
* [Local Testing With TestNG](#testing-locally-hosted-or-privately-hosted-projects)

## Pre-requisites

Before you can start performing Java automation testing with Selenium, you would need to:

- Install the latest **Java development environment** i.e. **JDK 1.6** or higher. We recommend using the latest version.

- Download the latest **Selenium Client** and its **WebDriver bindings** from the [official website](https://www.selenium.dev/downloads/). Latest versions of Selenium Client and WebDriver are ideal for running your automation script on LambdaTest Selenium cloud grid.

- Install **Maven** which supports **JUnit** framework out of the box. **Maven** can be downloaded and installed following the steps from [the official website](https://maven.apache.org/). Maven can also be installed easily on **Linux/MacOS** using [Homebrew](https://brew.sh/) package manager.

### Cloning Repo And Installing Dependencies

**Step 1:** Clone the LambdaTest’s Java-TestNG-Selenium repository and navigate to the code directory as shown below:

```bash
git clone https://github.com/LambdaTest/Java-TestNG-Selenium
cd Java-TestNG-Selenium
```

You can also run the command below to check for outdated dependencies.

```bash
mvn versions:display-dependency-updates
```

### Setting Up Your Authentication

Make sure you have your LambdaTest credentials with you to run test automation scripts. You can get these credentials from the [LambdaTest Automation Dashboard](https://automation.lambdatest.com/build?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium) or by your [LambdaTest Profile](https://accounts.lambdatest.com/login?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium).

**Step 2:** Set LambdaTest **Username** and **Access Key** in environment variables.

* For **Linux/macOS**:
  
  ```bash
  export LT_USERNAME=""YOUR_USERNAME"" 
  export LT_ACCESS_KEY=""YOUR ACCESS KEY""
  ```
  * For **Windows**:
  ```bash
  set LT_USERNAME=""YOUR_USERNAME"" 
  set LT_ACCESS_KEY=""YOUR ACCESS KEY""
  ```

## Run Your First Test

>**Test Scenario**: The sample [TestNGTodo1.java](https://github.com/LambdaTest/Java-TestNG-Selenium/blob/master/src/test/java/com/lambdatest/TestNGTodo1.java) tests a sample to-do list app by marking couple items as done, adding a new item to the list and finally displaying the count of pending items as output.


### Configuring Your Test Capabilities

**Step 3:** In the test script, you need to update your test capabilities. In this code, we are passing browser, browser version, and operating system information, along with LambdaTest Selenium grid capabilities via capabilities object. The capabilities object in the above code are defined as:

```java
DesiredCapabilities capabilities = new DesiredCapabilities();
        capabilities.setCapability(""browserName"", ""chrome"");
        capabilities.setCapability(""version"", ""70.0"");
        capabilities.setCapability(""platform"", ""win10""); // If this cap isn't specified, it will just get the any available one
        capabilities.setCapability(""build"", ""LambdaTestSampleApp"");
        capabilities.setCapability(""name"", ""LambdaTestJavaSample"");
```

You can generate capabilities for your test requirements with the help of our inbuilt [Desired Capability Generator](https://www.lambdatest.com/capabilities-generator/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium).

### Executing The Test

**Step 4:** The tests can be executed in the terminal using the following command.

```bash
mvn test -D suite=single.xml
```

Your test results would be displayed on the test console (or command-line interface if you are using terminal/cmd) and on LambdaTest automation dashboard. 

## Run Parallel Tests Using TestNG


Here is an example `xml` file which would help you to run a single test on various browsers at the same time, you would also need to generate a testcase which makes use of **TestNG** framework parameters (`org.testng.annotations.Parameters`).

```xml title=""testng.xml""
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE suite SYSTEM ""http://testng.org/testng-1.0.dtd"">
<suite thread-count=""3"" name=""LambaTestSuite"" parallel=""tests"">

  <test name=""WIN8TEST"">
  <parameter name=""browser"" value=""firefox""/>
  <parameter name=""version"" value=""62.0""/>
  <parameter name=""platform"" value=""WIN8""/>
    <classes>
      <class name=""LambdaTest.TestNGToDo""/>
    </classes>
  </test> <!-- Test -->

  <test name=""WIN10TEST"">
  <parameter name=""browser"" value=""chrome""/>
  <parameter name=""version"" value=""79.0""/>
  <parameter name=""platform"" value=""WIN10""/>
    <classes>
      <class name=""LambdaTest.TestNGToDo""/>
    </classes>
  </test> <!-- Test -->
  <test name=""MACTEST"">
  <parameter name=""browser"" value=""safari""/>
  <parameter name=""version"" value=""11.0""/>
  <parameter name=""platform"" value=""macos 10.13""/>
    <classes>
      <class name=""LambdaTest.TestNGToDo""/>
    </classes>
  </test> <!-- Test -->

</suite>
```

### Executing Parallel Tests Using TestNG

To run parallel tests using **TestNG**, we would have to execute the below commands in the terminal:

- For the above example code
  ```bash
  mvn test
  ```
- For the cloned Java-TestNG-Selenium repo used to run our first sample test
  ```bash
  mvn test -D suite=parallel.xml
  ```

## Testing Locally Hosted Or Privately Hosted Projects

You can test your locally hosted or privately hosted projects with LambdaTest Selenium grid using LambdaTest Tunnel. All you would have to do is set up an SSH tunnel using tunnel and pass toggle `tunnel = True` via desired capabilities. LambdaTest Tunnel establishes a secure SSH protocol based tunnel that allows you in testing your locally hosted or privately hosted pages, even before they are live.

Refer our [LambdaTest Tunnel documentation](https://www.lambdatest.com/support/docs/testing-locally-hosted-pages/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium) for more information.

Here’s how you can establish LambdaTest Tunnel.

Download the binary file of:
* [LambdaTest Tunnel for Windows](https://downloads.lambdatest.com/tunnel/v3/windows/64bit/LT_Windows.zip)
* [LambdaTest Tunnel for macOS](https://downloads.lambdatest.com/tunnel/v3/mac/64bit/LT_Mac.zip)
* [LambdaTest Tunnel for Linux](https://downloads.lambdatest.com/tunnel/v3/linux/64bit/LT_Linux.zip)

Open command prompt and navigate to the binary folder.

Run the following command:

```bash
LT -user {user’s login email} -key {user’s access key}
```
So if your user name is lambdatest@example.com and key is 123456, the command would be:

```bash
LT -user lambdatest@example.com -key 123456
```
Once you are able to connect **LambdaTest Tunnel** successfully, you would just have to pass on tunnel capabilities in the code shown below :

**Tunnel Capability**

```java
DesiredCapabilities capabilities = new DesiredCapabilities();        
        capabilities.setCapability(""tunnel"", true);
```

## Tutorials 📙

Check out our latest tutorials on TestNG automation testing 👇

* [JUnit 5 vs TestNG: Choosing the Right Framework for Automation Testing](https://www.lambdatest.com/blog/junit-5-vs-testng/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How To Install TestNG?](https://www.lambdatest.com/blog/how-to-install-testng-in-eclipse-step-by-step-guide/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [Create TestNG Project in Eclipse & Run Selenium Test Script](https://www.lambdatest.com/blog/create-testng-project-in-eclipse-run-selenium-test-script/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [A Complete Guide for Your First TestNG Automation Script](https://www.lambdatest.com/blog/a-complete-guide-for-your-first-testng-automation-script/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Automate using TestNG in Selenium?](https://www.lambdatest.com/blog/testng-in-selenium/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Perform Parallel Test Execution in TestNG with Selenium](https://www.lambdatest.com/blog/parallel-test-execution-in-testng/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [Creating TestNG XML File & Execute Parallel Testing](https://www.lambdatest.com/blog/create-testng-xml-file-execute-parallel-testing/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [Speed Up Automated Parallel Testing in Selenium with TestNG](https://www.lambdatest.com/blog/speed-up-automated-parallel-testing-in-selenium-with-testng/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [Automation Testing With Selenium, Cucumber & TestNG](https://www.lambdatest.com/blog/automation-testing-with-selenium-cucumber-testng/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Run JUnit Selenium Tests using TestNG](https://www.lambdatest.com/blog/test-example-junit-and-testng-in-selenium/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Group Test Cases in TestNG [With Examples]](https://www.lambdatest.com/blog/grouping-test-cases-in-testng/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Set Test Case Priority in TestNG with Selenium](https://www.lambdatest.com/blog/prioritizing-tests-in-testng-with-selenium/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Use Assertions in TestNG with Selenium](https://www.lambdatest.com/blog/asserts-in-testng/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Use DataProviders in TestNG [With Examples]](https://www.lambdatest.com/blog/how-to-use-dataproviders-in-testng-with-examples/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [Parameterization in TestNG - DataProvider and TestNG XML [With Examples]](https://www.lambdatest.com/blog/parameterization-in-testng-dataprovider-and-testng-xml-examples/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [TestNG Listeners in Selenium WebDriver [With Examples]](https://www.lambdatest.com/blog/testng-listeners-in-selenium-webdriver-with-examples/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [TestNG Annotations Tutorial with Examples for Selenium Automation](https://www.lambdatest.com/blog/complete-guide-on-testng-annotations-for-selenium-webdriver/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Use TestNG Reporter Log in Selenium](https://www.lambdatest.com/blog/how-to-use-testng-reporter-log-in-selenium/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [How to Generate TestNG Reports in Jenkins](https://www.lambdatest.com/blog/how-to-generate-testng-reports-in-jenkins/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)


## Documentation & Resources :books:

      
Visit the following links to learn more about LambdaTest's features, setup and tutorials around test automation, mobile app testing, responsive testing, and manual testing.

* [LambdaTest Documentation](https://www.lambdatest.com/support/docs/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [LambdaTest Blog](https://www.lambdatest.com/blog/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
* [LambdaTest Learning Hub](https://www.lambdatest.com/learning-hub/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)    

## LambdaTest Community :busts_in_silhouette:

The [LambdaTest Community](https://community.lambdatest.com/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium) allows people to interact with tech enthusiasts. Connect, ask questions, and learn from tech-savvy people. Discuss best practises in web development, testing, and DevOps with professionals from across the globe 🌎

## What's New At LambdaTest ❓

To stay updated with the latest features and product add-ons, visit [Changelog](https://changelog.lambdatest.com) 
      
## About LambdaTest

[LambdaTest](https://www.lambdatest.com/?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium) is a leading test execution and orchestration platform that is fast, reliable, scalable, and secure. It allows users to run both manual and automated testing of web and mobile apps across 3000+ different browsers, operating systems, and real device combinations. Using LambdaTest, businesses can ensure quicker developer feedback and hence achieve faster go to market. Over 500 enterprises and 1 Million + users across 130+ countries rely on LambdaTest for their testing needs.    

### Features

* Run Selenium, Cypress, Puppeteer, Playwright, and Appium automation tests across 3000+ real desktop and mobile environments.
* Real-time cross browser testing on 3000+ environments.
* Test on Real device cloud
* Blazing fast test automation with HyperExecute
* Accelerate testing, shorten job times and get faster feedback on code changes with Test At Scale.
* Smart Visual Regression Testing on cloud
* 120+ third-party integrations with your favorite tool for CI/CD, Project Management, Codeless Automation, and more.
* Automated Screenshot testing across multiple browsers in a single click.
* Local testing of web and mobile apps.
* Online Accessibility Testing across 3000+ desktop and mobile browsers, browser versions, and operating systems.
* Geolocation testing of web and mobile apps across 53+ countries.
* LT Browser - for responsive testing across 50+ pre-installed mobile, tablets, desktop, and laptop viewports

    
[<img height=""58"" width=""200"" src=""https://user-images.githubusercontent.com/70570645/171866795-52c11b49-0728-4229-b073-4b704209ddde.png"">](https://accounts.lambdatest.com/register?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)


      
## We are here to help you :headphones:

* Got a query? we are available 24x7 to help. [Contact Us](mailto:support@lambdatest.com)
* For more info, visit - [LambdaTest](https://www.lambdatest.com?utm_source=github&utm_medium=repo&utm_campaign=Java-TestNG-Selenium)
"
JeroenMols/ArtifactoryExample,master,69,20,2015-08-06T15:19:41Z,234,0,Example code to upload and use artefacts from Artifactory,,"# ArtifactoryExample
This repository demonstrates how you easily generate Maven artifacts from an Android library and upload them to your own private repository (based on Artifactory). The precise details of how everything works can be found:

- For AwesomeLibrary and AwesomeApplication: [this blogpost](https://jeroenmols.github.io/blog/2015/08/06/artifactory/).
- For AwesomeAdvancedLibrary and AwesomeAdvancedApplication: [this blogpost](https://jeroenmols.github.io/blog/2015/08/13/artifactory2/).

## Usage
Make sure you have your own private Artifactory repository running on your local machine. You can set up one by following the instructions in [this blogpost](https://jeroenmols.github.io/blog/2015/08/06/artifactory/).

Clone the entire repository to your local machine:

```git
git clone git@github.com:JeroenMols/ArtifactoryExample.git
```

Open the `AwesomeLibrary` or `AwesomeAdvancedLibrary` project, compile a release version and upload the artifacts to your Artifactory repository:

```groovy
gradle assembleRelease artifactoryPublish
```

Open the `AwesomeApplication` or `AwesomeAdvancedApplication` project in Android Studio and run it on a connected device. Gradle will now download the dependency you just created from the Artifactory repository and build your project.

That's it, your done!

## Questions
@molsjeroen
"
loopj/proguard-gradle-example,master,51,23,2014-12-26T21:50:49Z,120,1,Example app showing how to use proguard with gradle,,"Example Java App with Proguard
==============================

Building
--------

```shell
./gradlew clean build proguard
```

Running
-------

```shell
java -jar build/libs/proguard-gradle-example.jar
```

Outputs
-------

-   `build/libs/proguard-gradle-example.jar` - main package

-   `build/libs/proguard-gradle-example.out.jar` - obfuscated main package

-   `proguard.map` - proguard obfuscation mapping file
"
coi-gov-pl/spring-clean-architecture,develop,134,30,2016-12-19T18:15:46Z,415,2,"An example web app structured using Clean Architecture, implemented using Spring Framework.",,"# spring-clean-architecture

[![Build Status](https://travis-ci.org/coi-gov-pl/spring-clean-architecture.svg?branch=develop)](https://travis-ci.org/coi-gov-pl/spring-clean-architecture)

An example web app structured using [Clean Architecture][clean-arch],
implemented using [Spring Framework][spring].

![Robert C Martin - Clean Architecture](http://i.imgur.com/WkBAATy.png)

Watch youtube video of Robert C. Martin ""Uncle Bob"" on Clean Architecture and Design:

[![Robert C Martin - Clean Architecture and Design](https://img.youtube.com/vi/Nsjsiz2A9mg/0.jpg)](https://www.youtube.com/watch?v=Nsjsiz2A9mg)

[clean-arch]: https://8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html
[spring]: https://projects.spring.io/spring-framework/

### Un strict mode

If you feel that external configuration is a bit of a hasle, you can see example of integrating spring-context into domain logic. It's less flexible and surely it's not advised by Uncle Bob. If you feel that your thing, you might look at branch: `spring-in-domain-logic` (See diff here: https://github.com/coi-gov-pl/spring-clean-architecture/compare/spring-in-domain-logic).
"
jamesjieye/netty-socketio.spring,master,121,50,2016-09-12T00:39:19Z,252,0,An example of real-time chat application built with netty-socketio and Spring Boot.,netty-socketio real-time-chat socket-io spring-boot,"# An example of real-time chat application 

Built with 
- [netty-socketio 1.7.17](https://github.com/mrniko/netty-socketio) 
- Spring Boot 2.1.1.RELEASE
- socket.io-client 2.2.0

In this example, `SocketIONamespace` is used for declaring modules. 

This example project is inspired by the following projects.
- https://github.com/Heit/netty-socketio-spring
- https://github.com/mrniko/netty-socketio-demo

# Usage

## Server end

- Run server by command `mvn spring-boot:run`   
- Or build single executable jar file with `mvn package` and un single jar `java -jar rt-server.jar`

## Client end

- Put the `/client` directory under an HTTP server. Then open it from the browser after starting the server side.

# License

MIT"
AkramChauhan/WhatsApp-Stickers-using-Flutter,master,111,50,2020-06-20T13:00:27Z,7232,1,This App is complete example of how to create WhatsApp Sticker Application using Flutter.,,"# WhatsApp Sticker App using Flutter

![full_screnshot](https://user-images.githubusercontent.com/13075784/85202566-d57aa280-b324-11ea-8098-38757234c388.png)
 
# Available in PlayStore

<a href=""https://play.google.com/store/apps/details?id=com.gamacrack.trending_stickers"">![640px-Google_Play_Store_badge_EN svg](https://user-images.githubusercontent.com/13075784/85202629-55087180-b325-11ea-8307-acf71c9b7022.png)
</a>


"
benelog/lambda-resort,master,25,10,2015-01-05T00:31:09Z,421,0,"examples of filtering, sorting, mapping by Java, Groovy, Scala, Kotlin, Xtend, Ceylon",groovy java lambda xtend,"
# Filtering, sorting, mapping

### Backgrounds
[Guest.java](src/main/java/com/naver/helloworld/resort/domain/Guest.java)

```java
public class Guest {
	private final int grade;
	private final String name;
	private final String company;
...
}
```

[GuestRepository.java](src/main/java/com/naver/helloworld/resort/repository/GuestRepository.java)

```java
import java.util.List;

public interface GuestRepository {
	public List<Guest> findAllGuest ();
}
```

[ResortService.java](src/main/java/com/naver/helloworld/resort/service/ResortService.java)

```java
public interface ResortService {
	public List<String> findGuestNamesByCompany (String company);
}
```

## Implementations by classic Java
### JDK Collections framework
[ClassicJavaResort.java](src/main/java/com/naver/helloworld/resort/service/ClassicJavaResort.java)

```java
public List<String> findGuestNamesbyCompany(String company) {
	List<Guest> all = repository.findAllGuest();

	List<Guest> filtered = filter(guests, company);
	sort(filtered);
	return mapNames(filtered);
}

private List<Guest> filter(List<Guest> guests, String company) {
	List<Guest> filtered = new  ArrayList<>();
	for(Guest guest : guests ) {
		if (company.equals(guest.getCompany())) {
			filtered.add(guest);
		}
	}
	return filtered;
}

private void sort(List<Guest> guests) {
	Collections.sort(guests, new Comparator<Guest>() {
		public int compare(Guest o1, Guest o2) {
			return Integer.compare(o1.getGrade(), o2.getGrade());
		}
 	});
}

private List<String> mapNames(List<Guest> guests) {
	List<String> names = new ArrayList<>();
	for(Guest guest : guests ) {
		names.add(guest.getName());
	}
	return names;
}
```

### [Guava](https://github.com/google/guava)
[GuavaResort.java](src/main/java/com/naver/helloworld/resort/service/GuavaResort.java)

```java
public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAll();

	List<Guest> sorted = FluentIterable.from(all)
		.filter(new Predicate<Guest>() {
			public boolean apply(Guest g) {
				return company.equals(g.getCompany());
			}
	})
	.toSortedList(Ordering.natural().onResultOf(
		new Function<Guest, Integer>() {
			public Integer apply(Guest g) {
				return g.getGrade();
		}
	}));

	return FluentIterable.from(sorted)
			.transform(new Function<Guest, String>() {
				public String apply(Guest g) {
					return g.getName();
				}
			})
			.toList();
}
```

### [Totally Lazy](http://totallylazy.com/)
[TotallyLazyResort.java](src/main/java/com/naver/helloworld/resort/service/TotallyLazyResort.java)

```java
public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAll();
	return Sequences.sequence(all)
		.filter(new Predicate<Guest>() {
			public boolean matches(Guest g) {
				return company.equals(g.getCompany());
			}
		})
		.sortBy(new Callable1<Guest, Integer>(){
			public Integer call(Guest g) {
				return g.getGrade();
			}
		})
		.map(new Callable1<Guest, String>(){
			public String call(Guest g) {
				return g.getName();
			}
		})
		.toList();
}
```

### [GS Collections](https://github.com/goldmansachs/gs-collections)
[GsCollectoinsResort.java](src/main/java/com/naver/helloworld/resort/service/GsCollectionsResort.java)

```java
public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAll();
	return FastList.newList(all)
		.select(new Predicate<Guest>() {
			public boolean accept(Guest g) {
				return company.equals(g.getCompany());
			}
		})
		.sortThisBy(new Function<Guest, Integer>() {
			public Integer valueOf(Guest g) {
				return g.getGrade();
			}
		})
		.collect(new Function<Guest, String> () {
			public String valueOf(Guest g) {
				return g.getName();
			}
		});
}
```

### [Bolts](https://bitbucket.org/stepancheg/bolts/wiki/Home)
[BoltsResort.java](src/main/java/com/naver/helloworld/resort/service/BoltsResort.java)

```java
	public List<String> findGuestNamesByCompany(final String company) {
		List<Guest> all = repository.findAllGuest();
		return Cf.list(all)
			.filter(new Function1B<Guest>() {
				public boolean apply(Guest g) {
					return company.equals(g.getCompany());
				}
			})
			.sortBy(new Function<Guest, Integer>() {
				public Integer apply(Guest g) {
					return g.getGrade();
				}
			})
			.map(new Function<Guest, String>() {
				public String apply(Guest g) {
					return g.getName();
				}
			});
	}
```

### [Op4j](www.op4j.org)
[Op4JResort.java](src/main/java/com/naver/helloworld/resort/service/Op4JResort.java)

```java
public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAllGuest();
	return Op.on(all)
		.removeAllFalse(new IFunction<Guest, Boolean>() {
			public Boolean execute(Guest g, ExecCtx ctx) throws Exception {
				return company.equals(g.getCompany());
			}
		})
		.sortBy(new IFunction<Guest, Integer>() {
			public Integer execute(Guest g, ExecCtx ctx) throws Exception {
				return g.getGrade();
			}
		})
		.map(new IFunction<Guest, String>() {
			public String execute(Guest g, ExecCtx ctx) throws Exception {
				return g.getName();
			}
		}).get();
}
```

### [Lambdaj](https://code.google.com/p/lambdaj)
[LambdaJResort.java](src/main/java/com/naver/helloworld/resort/service/LambdaJResort.java)

```java
import static ch.lambdaj.Lambda.*;
import static org.hamcrest.Matchers.*;
...

public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAll();
	return LambdaCollections.with(all)
		.retain(having(on(Guest.class).getCompany(), equalTo(company)))
		.sort(on(Guest.class).getGrade())
		.extract(on(Guest.class).getName());
}
```

### [Functional Java](http://functionaljava.org/)
[FunctionalJavaResort.java](src/main/java/com/naver/helloworld/resort/service/FunctionalJavaResort.java)

```java
public List<String> findGuestNamesByCompany(String company) {
	List<Guest> all = repository.findAll();

	Collection<String> mapped = Stream.iterableStream(all)
		.filter(new F<Guest, Boolean>() {
			public Boolean f(Guest g){
				return company.equals(g.getCompany());
			}
		})
		.sort(Ord.ord(
			new F<Guest, F<Guest, Ordering>>() {
				public F<Guest, Ordering> f(final Guest a1) {
					return new F<Guest, Ordering>() {
						public Ordering f(final Guest a2) {
							int x =  Integer.compare(a1.getGrade(), a2.getGrade());
							return x < 0 ? Ordering.LT : x == 0 ? Ordering.EQ : Ordering.GT;
					}
				};
			}
		}))
		.map(new F<Guest, String>() {
			public String f(Guest g) {
				return g.getName();
			}
		})
		.toCollection();
	return new ArrayList<String>(mapped);
}
```

### [Apache Commons Collections](http://commons.apache.org/proper/commons-collections/)
[CommonsCollectionsResort.java](src/main/java/com/naver/helloworld/resort/service/CommonsCollectionsResort.java)

```java
public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAll();
	List<Guest> filtered = ListUtils.select(all, new Predicate<Guest>() {
		public boolean evaluate(Guest g) {
			return company.equals(g.getCompany());
		}
	});
	Collections.sort(filtered, new Comparator<Guest>() {
		public int compare(Guest o1, Guest o2) {
			return Integer.compare(o1.getGrade(), o2.getGrade());
		}
	});
	Collection<String> names = CollectionUtils.collect(filtered, new Transformer<Guest, String>(){
		public String transform(Guest g) {
			return g.getName();
		}
	});
	return new ArrayList<>(names);
}
```

### [Jedi](http://jedi.codehaus.org/)
[JediResort.java](src/main/java/com/naver/helloworld/resort/service/JediResort.java)

```java
public List<String> findGuestNamesByCompany(final String company) {
	List<Guest> all = repository.findAll();
	List<Guest> filtered = FunctionalPrimitives.select(all, new Filter<Guest>() {
		public Boolean execute(Guest g) {
			return company.equals(g.getCompany());
		}
	});
	List<Guest> sorted = Comparables.sort(filtered, new Functor<Guest, Integer>() {
		public Integer execute(Guest g) {
			return g.getGrade();
		}
	});
	return FunctionalPrimitives.map(sorted, new Functor<Guest, String>() {
		public String execute(Guest g) {
			return g.getName();
		}
	});
}
```

## Implementations by other JVM languages
- Groovy : 2.3.9
- Scala :  2.11.4
- Kotlin : 0.10.195
- Xtend : 2.7
- Ceylon : 1.1.0

### [Groovy](http://groovy.codehaus.org/)
[GroovyAdvancedResort.groovy](src/main/groovy/com/naver/helloworld/resort/service/GroovyAdvancedResort.groovy)

```groovy
List<String> findGuestNamesByCompany(String company) {
	List<Guest> all = repository.findAll()
	all.findAll { it.company == company }
		.sort { it.grade }
		.collect { it.name }
}
```

### [Scala](http://www.scala-lang.org/)
[ScalaAdvancedResort.scala](src/main/scala/com/naver/helloworld/resort/service/ScalaAdvancedResort.scala)

```scala
import scala.collection.JavaConversions._
...

	def findGuestNamesByCompany(company: String): java.util.List[String] = {
		val all = repository.findAll
		all.filter ( _.getCompany == company)
			.sortBy ( _.getGrade )
			.map ( _.getName )
	}
```

### [Kotlin](http://kotlinlang.org)
[KotlinAdvancedResort.kt](src/main/kotlin/com/naver/helloworld/resort/service/KotlinAdvancedResort.kt)

```kotlin

	override fun findGuestNamesByCompany(company: String): List<String> {
		val all = repository.findAll()
		return all.filter { it.getCompany() == company }
			.sortBy { it.getGrade() }
			.map { it.getName() }
	}
```

### [Xtend](http://www.eclipse.org/xtend/)
[XtendAdvancedResort.xtend](src/main/xtend/com/naver/helloworld/resort/service/XtendAdvancedResort.xtend)

```xtend
override findGuestNamesByCompany(String aCompany) {
	val all = repository.findAll()
	all.filter [company == aCompany]
		.sortBy[grade]
		.map[name]
}
```

### [Ceylon](http://ceylon-lang.org/)
[resort.ceylon](src/main/ceylon/com/naver/helloworld/resort/service/resort.ceylon)

```ceylon
import ceylon.interop.java { CeylonIterable }
import java.util {JList = List, JArrayList = ArrayList }
import java.lang {JString = String}

...

	shared actual JList<JString> findGuestNamesByCompany(String company) {
		value all = repository.findAll() ;
		value names = CeylonIterable(all)
			.filter((Guest g) => g.company == company)
			.sort(byIncreasing((Guest g) => g.grade.intValue()))
			.map((Guest g) => g.name);

		value jnames = JArrayList<JString>();
		for (name in names) {jnames.add(JString(name));}
		return jnames;
	}
```

## Implementations by modern Java
[ModernJavaAdvancedResort.java](src/main/java/com/naver/helloworld/resort/service/ModernJavaAdvancedResort.java)

```java
public List<String> findGuestNamesByCompany(String company) {
	List<Guest> guests = repository.findAll();
	return guests.stream()
		.filter(g -> company.equals(g.getCompany()))
		.sorted(Comparator.comparing(Guest::getGrade))
		.map(Guest::getName)
		.collect(Collectors.toList());
}
```

# Refactoring by lambda expressions

## Async Servlet

### Classic Java
[ClassicAsyncServlet.java](src/main/java/com/naver/helloworld/web/ClassicAsyncServlet.java)

```java
public void doGet(final HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
	final AsyncContext asyncContext = request.startAsync();
		asyncContext.start(new Runnable() {
		public void run() {
			// long running job
			asyncContext.dispatch(""/status.jsp"");
		}
		});
}
```

### Modern Java
[ModernAsyncServlet.java](src/main/java/com/naver/helloworld/web/ModernAsyncServlet.java)

```java
public void doGet(final HttpServletRequest request,	HttpServletResponse response) throws ServletException, IOException {
	AsyncContext asyncContext = request.startAsync();
	asyncContext.start(() -> {
		// long running job
		asyncContext.dispatch(""/status.jsp"");
		});
}
```

## Spring JDBC
### Classic Java
[ClassicJdbcRepository.java](src/main/java/com/naver/helloworld/resort/repository/ClassicJdbcRepository.java)

```java
public List<Guest> findAll() {
	return jdbcTemplate.query(SELECT_ALL, new RowMapper<Guest>(){
		public Guest mapRow(ResultSet rs, int rowNum) throws SQLException {
			return  new Guest (
				rs.getInt(""id""),
				rs.getString(""name""),
				rs.getString(""company""),
				rs.getInt(""grade"")
			);
	}
  });
}
```

### Modern Java
[ModernJdbcRepository.java](src/main/java/com/naver/helloworld/resort/repository/ModernJdbcRepository.java)

```java
public List<Guest> findAll() {
	return jdbcTemplate.query(SELECT_ALL,
		(rs, rowNum) ->new Guest (
			rs.getInt(""id""),
			rs.getString(""name""),
			rs.getString(""company""),
			rs.getInt(""grade"")
			)
  );
}
```

### Event bindings in Android
### Classic Java
[ClassicFragment.java](src/main/java/com/naver/helloworld/resort/android/ClassicFragment.java)

```java
Button calcButton = (Button) view.findViewById(R.id.calcBtn);
Button sendButton = (Button) view.findViewById(R.id.sendBtn);

calcButton.setOnClickListener(new OnClickListener() {
	public void onClick(View view) {
		calculate();
	}
});
sendButton.setOnClickListener(new OnClickListener() {
	public void onClick(View view) {
		send();
	}
});
```

### Modern Java
[ModernFragment.java](src/main/java/com/naver/helloworld/web/ModernAsyncServlet.java)

```java
Button calcButton = (Button) view.findViewById(R.id.calcBtn);
Button sendButton = (Button) view.findViewById(R.id.sendBtn);

calcButton.setOnClickListener(v -> calculate());
sendButton.setOnClickListener(v -> send());
```

# Frameworks using lambda expressions
### [Lambda Behave](http://richardwarburton.github.io/lambda-behave/)
[ResortServiceSpec.java](src/test/java/com/naver/helloworld/resort/service/ResortServiceSpec.java)

```java
@RunWith(JunitSuiteRunner.class)
public class ResortServiceSpec {{
	GuestRepository repository = new MemoryRepository();
	ResortService service = new ModernJavaResort(repository);

	describe(""ResortService with modern Java"", it -> {
		it.isSetupWith(() -> {
			repository.save(
					new Guest(1, ""jsh"", ""Naver"", 15),
					new Guest(2, ""hny"", ""Line"", 10),
					new Guest(3, ""chy"", ""Naver"", 5)
				);

		});
		it.isConcludedWith(repository::deleteAll);

		it.should(""find names of guests by company "", expect -> {
			List<String> names = service.findGuestNamesByCompany(""Naver"");
			expect.that(names).isEqualTo(Arrays.asList(""chy"",""jsh""));
		});
	});
}}
```

### [Jinq](http://www.jinq.org/)
[JinqResort.java](src/main/java/com/naver/helloworld/resort/service/JinqResort.java)

```java
private EntityManager em;
@Autowired
public JinqResort(EntityManager em) {
	this.em = em;
}
private <T> JinqStream<T> stream(Class<T> clazz) {
	return new JinqJPAStreamProvider(em.getEntityManagerFactory()).streamAll(em, clazz);
}

public List<String> findGuestNamesByCompany(String company) {
	return stream(Guest.class)
		.where(g -> g.getCompany().equals(company))
		.sortedBy(Guest::getGrade)
		.select(Guest::getName)
		.toList();
}
```

A query generated by JinqResort

```sql
	Hibernate: select guest0_.id as id1_0_, guest0_.company as company2_0_, guest0_.grade as grade3_0_, guest0_.name as name4_0_ from guest guest0_ where guest0_.company=? order by guest0_.grade ASC limit ?
```

### [Spark](http://www.sparkjava.com/)
[SparkServer.java](src/main/java/com/naver/helloworld/web/SparkServer.java)

```java
import static spark.Spark.*;

import com.naver.helloworld.resort.service.ResortService;

public class SparkServer {
	public static void main(String[] args) {
		get(""/guests/:company"", (request, response) -> {
			String company = request.params("":company"");
			return ""No guests from "" + company;
		});
	}
}
```

[ResortServer.java](src/main/java/com/naver/helloworld/resort/ResortServer.java) (Spark + Spring)

```java
@SpringBootApplication
public class ResortServer {
	@Autowired
	private ResortService service;

	public void start() {
		get(""/guests/:company"", (request, response) -> {
			String company = request.params("":company"");
			List<String> names = service.findGuestNamesByCompany(company);
			return ""Guests from "" + company + "" : "" + names;
		});
	}

	public static void main(String[] args) {
		ApplicationContext context = SpringApplication.run(ResortServer.class);
		context.getBean(ResortServer.class).start();
	}
}
```
"
stream-iori/vertx-rpc-example,master,25,12,2015-05-13T02:33:21Z,132,0,The Example of vertx-rpc,,"# vertx-rpc-example
The Example of vertx-rpc
"
xtext/maven-xtext-example,master,61,33,2013-11-22T13:38:39Z,1815,8,An Xtext language and example usage of it built with Maven,,"[![Build Status](https://github.com/xtext/maven-xtext-example/workflows/Build/badge.svg?branch=master)](https://github.com/xtext/maven-xtext-example/actions?query=workflow%3ABuild)

# An Xtext Language Built with Maven

A small example to show how to configure a Maven build for an Xtext language and how to use it from Maven and Gradle.

## Language Build

If you use Xtext 2.9 or higher, the Maven build for your language is auto-generated. Just skip ahead to the usage section.

- see my.mavenized.herolanguage.* projects
- Language plug-ins, updatesite and Eclipse feature built via Maven/Tycho
- Xtext Code Generation (Language infrastructure generated from grammar)
- Xtend Code Generation

## Language Usage

- example-project
- example-project-gradle
- Example Language (herolanguage) Code Generation
- Xtend Code Generation

Try it out!

# Steps

## 1. Increase memory

```bash
   export MAVEN_OPTS=""-Xmx512m""
```

## 2. Build the language

```bash
 mvn clean install
```

## 3. Build the example projects

```bash
 cd ../example-project/
 mvn clean install
```

```bash
 cd ../example-project-gradle/
 ./gradlew build
```

# Builds

We now have automatic builds:

https://github.com/xtext/maven-xtext-example/actions?query=workflow%3ABuild

# Maven Archetype

There is also a Maven Archetype available that automatically creates your new project based on this example:
https://github.com/fuinorg/emt-xtext-archetype

# Known Issues

## 1. Build fails due to version conflicts

The build will fail immediately because of version conflicts. A possible error might look similar to the following: 

* ```No versions available for org.eclipse.emf:org.eclipse.emf.mwe2.runtime:jar:[2.9.1.201705291010] within specified range```

Even if the specified version (see pom) is available on the central maven repository, updating related snapshots will most likely help the problem.

* ```mvn clean install -U```

"
bzdgn/spring-boot-restful-web-service-example,master,106,66,2018-06-26T13:57:40Z,393,2,A detailed Standalone RESTful web service example application with the use of Spring Boot framework,h2-database h2-embedded-database java jersey jersey-spring-hibernate microservice microservices restful-api restful-webservices spring-boot spring-framework standalone uberjar,"Spring Boot RESTful Web Service Example
=======================================
The main purpose of this sample project is to demonstrate the capabilities of spring boot.
But additionally, I want to show challenging problems that can occur during the development
while using the Spring Boot. 

First goal is to show how it is easy to start a web service with embedded tomcat and embedded
H2 database. This is the main goal of the project.

Secondly, we are using Spring and I have used dependency injection. But what is a challenging
problem about dependency injection. Assume that you have two implementations ready for one
implementation, how are you going to select the implementation? I'll explain several ways but
also I'll demonstrate how we can select our implementation via external configuration so that
we can update our configuration and don't need to touch the code, restart our jar file and
that's all.

Thirdly, I also have demonstrated how to use Java Application Configuration within the double
implementation for the single interface scenario I've explained above.

Lastly, I will explain all the deployment details, the main configuration of the whole project
including H2 database configuration.

Moreover, I will also demonstrate how you are going to test your RESTful application with
Postman tool.

TOC
---
- [0 Prerequisite And Demo App](#0-prerequisite-and-demo-app) <br/>
- [1 About Spring Boot](#1-about-spring-boot) <br/>
- [2 Create Spring Boot Project With Maven](#2-create-spring-boot-project-with-maven) <br/>
- [3 Spring Boot Dependencies](#3-spring-boot-dependencies) <br/>
- [4 Making Uber Jar](#4-making-uber-jar) <br/>
- [5 Project Overview](#5-project-overview) <br/>
- [6 External Configuration Example](#6-external-configuration-example) <br/>
- [7 Application Properties](#7-application-properties) <br/>
- [8 H2 Database Preparation](#8-h2-database-preparation) <br/>
- [9 Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
  * [9-a- Test](#9-a-test) <br/>
  * [9-b- List](#9-b-list) <br/>
  * [9-c- Create](#9-c-create) <br/>
  * [9-d- Retrieve](#9-d-retrieve) <br/>
  * [9-e- Update](#9-e-update) <br/>
  * [9-f- Delete](#9-f-delete) <br/>
- [10 Building And Running The Standalone Application](#10-building-and-running-the-standalone-application) <br/>

 0 Prerequisite And Demo App
----------------------------
To use this project, you are going to need;

- Java JDK 8 (1.8)
- Maven compatibile with JDK 8
- Any Java IDE
- [Postman tool](https://www.getpostman.com/) (optional, will be used for testing web service)

We are going to build a demo app named as consultant-api. This will be a simple web service with
basic CRUD operations. I'm going to demonstrate default and external configuration, how to use
multiple implementation and autowire them within the code and outside the code with an external
configuration file. Our app will be a standalone application that we can use independently, and
we are going to use an embedded tomcat, an embedded H2 database.

[Go back to TOC](#toc)


 1 About Spring Boot
--------------------
Whenever there is a new framework on the town, you must think two thinks. One, why should I use this
framework which means ""what are the benefits of this framework"", also can be interpreted like ""what
this framework solves?"". Two, ""When should I use this framework?"", also can be interpreted as ""on
which specific scenarios this framework is useful"" or can be simplified as ""what is the problem domain
of this framework?"".

When we make a web service with spring framework, we have to generate a war file, we need to configure
web.xml, and also if we are going to use the connection pool, the configuration is costly. All of these
increases the cost of time. So instead of writing your code, doing your development, you a lot of time
is wasted during the configuration. This is where Spring Boot comes to the action. Spring Boot simplifies
configuration, reduces boilerplate code that puts no any value to your software development.

So, what Spring Boot solves is the time lost for the configuration. For example, you can create a web
service with Spring Boot that runs on an embedded Tomcat server which is automatically configured and
you don't have to deal with the configuration. You can do all your configuration parameters via default
application properties. Also you can connect to an H2 embedded database, same applies for the
configuration here. 

Secondly, you don't have to generate a war file. All Spring Boot applications run as a standalone java
jar file. Where is it useful then? If you are using a microservice architecture which runs especially
on a cloud (but not necessarily), then you can easily do your development via Spring Boot. In my opinion,
Spring Boot is one of the best frameworks you should use on such a scenario and architecture. You can
easily create simple web services, put them inside a Docker container (which is not a part of this
tutorial) and run them on the Amazon Web Services or on any cloud environment.

Additionally, you don't have to track the versioning of your dependencies. Normally, if you are using
a version of spring, then you have to use the appropriate versions of your other dependencies which are
dependent to the main dependency. With Spring Boot, you don't have to check out what version you have
to use for Jackson which is compatible with the version of Jersey. You don't even need to write the
version of your dependencies. I'm going to demonstrate all of these benefits.

[Go back to TOC](#toc)


 2 Create Spring Boot Project With Maven
----------------------------------------
What we need to setup a Spring Boot project. However there are other ways (like spring initializer),
I'll go with setting up our project with maven.

Because that we are creating a web application here, we will first create a maven project with web
application archetype, then we will add the spring boot dependencies;

You can use the following maven command to create a project. In this project, I've used this exact
maven command to create our project;

```
mvn archetype:generate -DgroupId=com.levent.consultantapi -DartifactId=consultant-api  -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false
```

[Go back to TOC](#toc)


 3 Spring Boot Dependencies
---------------------------
How we make our project a Spring Boot project. We simply define a parent project in our POM file
just as below;

```
<!-- Spring Parent Project -->
<parent>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-parent</artifactId>
	<version>1.3.1.RELEASE</version>
</parent>
```

Then our dependencies aware of our Spring Boot project. Then for example, if we are going to create
a web application which is true, then we add the Spring Boot Starter dependencies. On this project,
it is vital for us to add the dependency below;

```
<!-- Spring boot starter web: integrates and auto-configures  -->
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-web</artifactId>
</dependency>
```

See that we did not use the version attribute of the dependency block. That's what Spring Boot is 
going to handle but just adding this starter dependency, we will have all what we need like Jersey,
Jackson, and the rest. Also the versioning is managed by Spring Boot, we don't have to check if
the versions of our transitive dependencies are compatible with each other or not.

Moreover, in this project we will need an H2 embedded database. So we are going to add the following
dependency to our dependencies block;

```
<!-- H2 Embedded Database -->
<dependency>
	<groupId>com.h2database</groupId>
	<artifactId>h2</artifactId>
</dependency>
```

The last thing additional to our dependencies in the POM file is to use the @SpringBootApplication
annotation on our [EntryPoint](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/EntryPoint.java) class.

With this, Spring Boot configuration is complete.

[Go back to TOC](#toc)


 4 Making Uber Jar
------------------

When we are developing a web service, let's say, using Jersey framework within the Spring context,
we make a .war file and upload it to a container. However, Spring Boot is a containerless framework.
So we do not need any web container, which means also we won't need to generate a .war file. What
we have to do is pack all the libraries and frameworks we are using in our project into a big jar
file, the Uber Jar (a.k.a. Fat Jar).

To do so, our build tool maven has a plugin named as Maven Shade Plugin. We are going to define
it within the build block of our POM file. You can see the sample build block as below;

```
<build>
  <plugins>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-compiler-plugin</artifactId>
      <configuration>
        <source>1.8</source>
        <target>1.8</target>
      </configuration>
    </plugin>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-shade-plugin</artifactId>
      <executions>
        <execution>
          <phase>package</phase>
          <goals>
            <goal>shade</goal>
          </goals>
          <configuration>
            <transformers>
              <transformer 
implementation=""org.apache.maven.plugins.shade.resource.AppendingTransformer"">
                <resource>META-INF/spring.handlers</resource>
              </transformer>
              <transformer
implementation=""org.springframework.boot.maven.PropertiesMergingResourceTransformer"">
                <resource>META-INF/spring.factories</resource>
              </transformer>
              <transformer
implementation=""org.apache.maven.plugins.shade.resource.AppendingTransformer"">
                <resource>META-INF/spring.schemas</resource>
              </transformer>
              <transformer
implementation=""org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"" />
              <transformer implementation=""org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"">
                <mainClass>com.levent.consultantapi.EntryPoint</mainClass>
              </transformer>
            </transformers>
          </configuration>
        </execution>
      </executions>
    </plugin>
  </plugins>
</build>
```

As you can see, there are two plugins used in the plugins block of the build block above. I've
used maven compiler plugin so that I can define the source and destination version. The other
plugin is the Maven Shade Plugin, which we use in order to pack our Uber Jar.

In the Maven Shade Plugin block, we define our mainClass. Because our application is a standalone
Java application, we have to define the Entry Point, the starter class of our appliacation. The
name of this class is arbitrary.

You can check out the full POM file: [Project Object Model](https://github.com/bzdgn/simple-grizzly-standalone-restful-webservice-example/blob/master/pom.xml)

[Go back to TOC](#toc)


 5 Project Overview
-------------------

Our project consist of several layers. For the simplicity, if we exclude the [EntryPoint](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/EntryPoint.java) class 
which is located at the top level package, we have the following packages;

- [controller package](https://github.com/bzdgn/spring-boot-restful-web-service-example/tree/master/src/main/java/com/levent/consultantapi/controller)
- [service package](https://github.com/bzdgn/spring-boot-restful-web-service-example/tree/master/src/main/java/com/levent/consultantapi/service)
- [repository package](https://github.com/bzdgn/spring-boot-restful-web-service-example/tree/master/src/main/java/com/levent/consultantapi/repository)
- [model package](https://github.com/bzdgn/spring-boot-restful-web-service-example/tree/master/src/main/java/com/levent/consultantapi/model)

You can see the logical representation below of these packages;

![project-overview](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/01_diagram.png)

Controller package has one controller class which is [ConsultantController](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/controller/ConsultantController.java). With [ConsultantController](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/controller/ConsultantController.java),
you can define all the RESTful methods. This class need to use a Service Layer implementation, thus
[ConsultantController](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/controller/ConsultantController.java) has a [ConsultantService](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/ConsultantService.java) interface and we are using the @Autowired annotation 
so that Spring context is going to find the appropriate implementation. In our case, we have only 
one Service implementation which is [ConsultantServiceImpl](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/consultant/impl/ConsultantServiceImpl.java).

You can also see the [InfoService](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/InfoService.java) interface wrapped inside the [ConsultantController](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/controller/ConsultantController.java) class. It has also
marked with the @Autowired annotation. I'll explain it later for the simplicity but our first focus
in this project overview is to explain the main structure of this simple application.

At service layer, we have the interface [ConsultantService](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/ConsultantService.java) and one implementation that fits with this
interface: [ConsultantServiceImpl](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/consultant/impl/ConsultantServiceImpl.java). You will see that [ConsultantServiceImpl](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/consultant/impl/ConsultantServiceImpl.java) has a [ConsultantRepository](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/repository/ConsultantRepository.java)
interface and that interface also marked with the @Autowired annotation.

At repository layer, we have a different situation. There are two implementation fits with this
[ConsultantRepository](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/repository/ConsultantRepository.java) interface;
- [ConsultantStubImpl](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/repository/impl/ConsultantStubImpl.java)
- [ConsultantJPARepositoryImpl](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/repository/impl/ConsultantJPARepositoryImpl.java)

So, how Spring handles if there are two implementation classes those implements one interface with
@Autowired annotation? How spring is going to select the implementation candidates? Normally, Spring
is going to get confused, throw Exceptions and you will find the following message inside the stack
trace;

```
Caused by: org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type [com.levent.consultantapi.repository.ConsultantRepository] is defined: expected single matching bean but found 2: consultantJPARepositoryImpl,consultantStubImpl
```

Because that there are two candidate implementation for one single interface, autowiring functionality
of Spring Context will fail. The solution is to use @Primary annotation. You can see it inside the
[ConsultantJPARepositoryImpl](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/repository/impl/ConsultantJPARepositoryImpl.java). When there are multiple implementation for the same interface marked with
@Autowired annotation, you have to use @Primary on one of the implementations.

But what if we want to have two different implementations and we want to change which implementation
to use, without changing the code ? Then we can use an external configuration, which I'm going to
explain it on next chapter.

[Go back to TOC](#toc)


 6 External Configuration Example
---------------------------------

Normally, Spring Boot configuration is defined with [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties). It is default location can be either under
src/main/resources folder, or under a subfolder of current directoy named with ""config"". I'm using the second way, created
a config folder under the project, and put the main [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties) file there. 

However, I also want to have the common properties on [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties) file, and in addition to it, for specific
purposes, I want to use a secondary properties folder. In this chapter, I'm going to demonstrate how to use externalized
custom properties file.

But first, let's go back to our previous problem that which I've talked about. The scenario is as follows: I've two or multiple
implementations for a single interface with @Autowired annotation, and I don't want to do any code change when I switch between 
the implementations. Spring's solution for that was using the @Primary annotation so that Spring Context is not going to throw an  exception because that it does not know which implementation to use.

Here is my solution;

- I create an externalized configuration file named as [implementation.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/implementation.properties)
- I've created [AppConfig](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/config/AppConfig.java) class to read the custom configuration file

If you look at to [AppConfig](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/config/AppConfig.java) class under the config package, you will see that the class file is marked with two annotations.
First it is marked with @Configuration annotation because it needs to be done before the injection of the autowired variable.
And secondly, it is marked with @PropertySource, so that we are going to point out which specific property file we are going
to use.

The process is as follows;

- Spring context searchs for the @Configuration annotation, finds the [AppConfig](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/config/AppConfig.java)
- Via [AppConfig](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/config/AppConfig.java), reads the [implementation.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/implementation.properties) file
- The greeter.implementation property's value is loaded to the impl variable in the [AppConfig](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/config/AppConfig.java)
- Via the #getImplementationFromPropertiesFile method, the implementation bean is created based on the config file
- The context has the right implementation based on the configuration
- During the creation of the [ConsultantController](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/controller/ConsultantController.java) class, Spring Context finds the autowired field: greeter which is an interface: [InfoService](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/service/InfoService.java)
- The implementation bean is autowired to this greeter field

You can see the overview of this process via the diagram below;

![process-overview](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/02_diagram.png)

[Go back to TOC](#toc)


 7 Application Properties
-------------------------

Spring Boot solves our problem with automatic configuration as we use an embedded Tomcat and an embedded H2
database but how are we going to specify the running port of the Tomcat container, the target database, 
connection pool parameters and so on?

Spring Boot provides a default configuration properties file called as [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties). Within this file
there are hundreds of configuration parameters we can use. You can see the detailed parameter list via following
link;

[Spring Boot Application Properties Reference](https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html)

The default locations of the application.properties file is either somewhere within the classpath, for example
under src/main/resources in a maven project, or a inside config folder under current working directory. It is
better to put the file under config folder which will make it easy to deploy inside a docker container, but
the choice is yours. I place [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties) under config folder.

Because that we are using a server, H2 database, a datasource, a db connection pool and lastly, hibernate,
we should define parameters in this [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties) file, based on the [documented reference list](https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html).

Let's take a detailed look;

- Server Configuration
&nbsp;&nbsp;&nbsp;&nbsp;The default configuration port is 8080, however we may want to change this. Thus I add the port configuration
&nbsp;&nbsp;&nbsp;&nbsp;as below;
```
#server port
server.port=8080
```
    
- H2 Database Configuration
&nbsp;&nbsp;&nbsp;&nbspWe also need to specify whether the console is activated, so that we can use H2 database via the console, create
&nbsp;&nbsp;&nbsp;&nbsp;our tables and initialize our db entries.
    
```
#H2 configuration
spring.h2.console.enabled=true
spring.h2.console.path=/h2
```

- DataSource Configuration
&nbsp;&nbsp;&nbsp;&nbsp;Instead of writing a connection string, we are defining the parameters via our properties file as below;
&nbsp;&nbsp;&nbsp;&nbsp;Notify that we defined our database as a file and the name of the database is ""consultantapi"". We are going to use it when
&nbsp;&nbsp;&nbsp;&nbsp;we need to connect the database via the console;

```
#Data source configuration
spring.datasource.url=jdbc:h2:file:~/consultantapi
spring.datasource.username=sa
spring.datasource.password=
spring.datasource.driver-class-name=org.h2.Driver
```

- Connection Pool Configuration
&nbsp;&nbsp;&nbsp;&nbsp; Here we define the connection pool parameters;

```
#DB Pool conf
spring.datasource.max-active=10
spring.datasource.max-idle=8
spring.datasource.max-wait=10000
spring.datasource.min-evictable-idle-time-millis=1000
spring.datasource.min-idle=8
spring.datasource.time-between-eviction-runs-millis=1
```

- Hibernate Configuration
&nbsp;&nbsp;&nbsp;&nbsp;We don't want Hibernate to delete our database entries on every restart of our server, so we need to configure as below;

```
#Hibernate Config
spring.jpa.hibernate.ddl-auto=false		#false for persistent database
```

You can check our project's application properties file via here: [application.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/application.properties)

[Go back to TOC](#toc)


 8 H2 Database Preparation
--------------------------
Before using our database implementation instead of using our stub implementation, we need to prepare our table
and initial entries within the database. We have two things to do;

1. We need to create a CONSULTANT table to store our consultant model, defined in [Consultant](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/model/Consultant.java) class.
2. We need to insert some trivial entries to the table.

The related SQL commands are located under the [consultant.sql](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/resources/consultant.sql)

As it is written on previous chapter, we have defined our H2 console with ""/h2"" postfix. Also we have defined our server
port as ""8080"", so connection url will be [http://localhost:8080/h2/](http://localhost:8080/h2/). We can connect our H2
database console as below;

![H2-console](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/03_diagram.png)

After connecting to the database via the console, we can easily run our sql commands defined in [consultant.sql](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/resources/consultant.sql) as below;

![H2-console](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/04_diagram.png)

Now our database is ready to go!

[Go back to TOC](#toc)


 9 Sending And Receiving JSONs With Postman
-------------------------------------------

In this part, I'm going to demonstrate all operations defined in our [ConsultantController](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/src/main/java/com/levent/consultantapi/controller/ConsultantController.java) class and how to test them
either with our web browser or with the [Postman tool](https://www.getpostman.com/). We can test our GET methods with any web browser but for
operations that use HTTP POST, PUT, DELETE methods, we cannot execute them with a simple web browser, so I'm
going to use [Postman tool](https://www.getpostman.com/) for that.

You can download Postman via [this link](https://www.getpostman.com/)

I've provided CRUD operations within postman, so that you can load all the prepared operations in Postman tool. You can
find the content under misc directory;

[Postman Collection](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/misc/Consultant_API.postman_collection.json)

 9-a Test
---------
```
Sub Path: /test
Full URL: http://localhost:8080/api/v1/test
Method:   GET
Sends:    N/A
Receives: Text
Sample Input: N/A
Sample Output; 

Consultant-Api Version: 1.0.0 Written by: Levent Divilioglu
```

We can simply use our web browser and receive the text output as below;

![test-sample](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/05_test.png)

But take into the consideration that this response based on which implementation we define on our custom configuration
file which is: [implementation.properties](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/config/implementation.properties).

You can select one of the four different implementations via the configuration file and see the results. For
more information, you can go back to the [6 External Configuration Example](#6-external-configuration-example) section.

[Go back to Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
[Go back to TOC](#toc)

 9-b List
---------
```
Sub Path: /consultants
Full URL: http://localhost:8080/api/v1/consultants
Method:   GET
Sends:    N/A
Receives: JSON
Sample Input: N/A
Sample Output;
[{
	""id"": 1,
	""firstName"": ""Levent"",
	""lastName"": ""Divilioglu"",
	""age"": 36,
	""client"": null,
	""assigned"": false
},
{
	""id"": 2,
	""firstName"": ""Altug"",
	""lastName"": ""Timuroglu"",
	""age"": 41,
	""client"": ""Altinorda IT"",
	""assigned"": true
},
{
	""id"": 3,
	""firstName"": ""Bugra"",
	""lastName"": ""Cengizoglu"",
	""age"": 37,
	""client"": ""KizilTug TECH"",
	""assigned"": true
}]
```

Again we can use web browser to get the results as below;

![list-sample](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/06_list.png)

[Go back to Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
[Go back to TOC](#toc)

 9-c Create
-----------
```
Sub Path: /consultants
Full URL: http://localhost:8080/api/v1/consultants
Method:   POST
Sends:    JSON
Receives: JSON
Sample Input;
{
	""id"": 4,
	""firstName"": ""John"",
	""lastName"": ""Doe"",
	""age"": 99,
	""client"": ""Example Tech"",
	""assigned"": true
}
Sample Output;
{
    ""id"": 4,
    ""firstName"": ""John"",
    ""lastName"": ""Doe"",
    ""age"": 99,
    ""client"": ""Example Tech"",
    ""assigned"": true
}
```

This time, the operation we are using is POST, so we cannot do that with our browser, we have to use our tool
Postman. Here is how I create my HTTP request;

![create-sample](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/07_create_input.png)

With the '+' sign above on the Postman screen, we can create our HTTP request. Then we select HTTP Method as POST.
We paste the URL, select ""raw"", and JSON for our input content. Then we select the ""body"" tag, and paste our content
which we want to POST. Under the second half of the screen, on the ""body"" tag, we will retrieve our JSON response.

As you can see, the created content is returned. We can also test the result using our list service via postman (or
web browser);

![create-sample-test](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/08_create_input_test.png)

[Go back to Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
[Go back to TOC](#toc)

 9-d Retrieve
-------------
```
Sub Path: /consultants
Full URL: http://localhost:8080/api/v1/consultants/{id}
Method:   GET
Sends:    N/A
Receives: JSON
Sample Input: N/A
Sample Output;
{
    ""id"": 4,
    ""firstName"": ""John"",
    ""lastName"": ""Doe"",
    ""age"": 99,
    ""client"": ""Example Tech"",
    ""assigned"": true
}
```

It is a simple GET again, and let's use our browser for testing. We are going to use a path
parameter which will be ""4"", the full path is as below;

```
http://localhost:8080/api/v1/consultants/4
```

The output will be as follows;

![retrieve-test](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/09_retrieve_test.png)

[Go back to Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
[Go back to TOC](#toc)

 9-e Update
-----------
```
Sub Path: /consultants
Full URL: http://localhost:8080/api/v1/consultants/{id}
Method:   PUT
Sends:    JSON
Receives: JSON
Sample Input;
{
	""id"": 4,
	""firstName"": ""Jayne"",
	""lastName"": ""Smith"",
	""age"": 66,
	""client"": ""Example New Company"",
	""assigned"": true
}
Sample Output;
{
    ""id"": 4,
    ""firstName"": ""Jayne"",
    ""lastName"": ""Smith"",
    ""age"": 66,
    ""client"": ""Example New Company"",
    ""assigned"": true
}
```
In order to update, we are going to use PUT method, so we will use Postman again.

For update method, we have to give the id in the URL as a path parameter, so URL will be as below;

```
http://localhost:8080/api/v1/consultants/4
```

![update-sample](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/10_update_input.png)

As you can see, the updated content is returned. We can also test the result using our retrieve service via postman (or
web browser);

![update-sample-test](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/11_update_input_test.png)

[Go back to Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
[Go back to TOC](#toc)

 9-f Delete
-----------
```
Sub Path: /consultants
Full URL: http://localhost:8080/api/v1/consultants/{id}
Method:   DELETE
Sends:    N/A
Receives: JSON
Sample Input: N/A
Sample Output;
{
    ""id"": 4,
    ""firstName"": ""Jayne"",
    ""lastName"": ""Smith"",
    ""age"": 66,
    ""client"": ""Example New Company"",
    ""assigned"": true
}
```

Again, we will use Postman for DELETE operation. As it is shown above, we don't have to provide
a body for this operation, but we have to provide the id of the consultant to be deleted within the
URL as below;

```
http://localhost:8080/api/v1/consultants/4
```

![delete-sample](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/12_delete_sample.png)

As you can see, the deleted content is returned. We can also test the result using our retrieve service via postman (or
web browser);

![delete-sample-test](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/13_delete_sample_test.png)

[Go back to Sending And Receiving JSONs With Postman](#9-sending-and-receiving-jsons-with-postman) <br/>
[Go back to TOC](#toc)


 10 Building And Running The Standalone Application
---------------------------------------------------
Now we can demonstrate how to run our consultant-api as a standalone application. First we must build with the following
maven command;

```
mvn clean package
```

This command is going to collect all the needed jars and pack them into an Uber Jar (a.k.a. fat jar). We can find this
Uber Jar under the ""target"" folder. The name of the file will be: ""consultant-api-1.0-SNAPSHOT.jar""

We are going to take this file and copy it to another arbitrary folder. Remember that we also need two configuration files,
those that located under the config file. We will also copy those config files to our arbitrary folder.

I copied all the files I mentioned above to the folder ""D:\consultant-api\"", the structure is as follows;

```
D:\consultant-api
       |
       |___ consultant-api-1.0-SNAPSHOT.jar
       |___ config
              |______ application.properties
              |______ implementation.properties
```

If the structure of the arbitrary folder (here it is 'consultant-api'), then we can try to run our standalone application
to see if it is working. Here is a successful output. For the simplicity, I'm not going to paste all the log output;

```
D:\consultant-api>java -jar consultant-api-1.0-SNAPSHOT.jar

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::         (v1.0-SNAPSHOT)

2018-07-01 16:16:08.705  INFO 6616 --- [           main] com.levent.consultantapi.EntryPoint      : Starting EntryPoint v1.0-SNAPSHOT on LEVASUS with PID 6616 (D:\consultant-api\consultant-api-1.0-SNAPSHOT.jar started by Levent in D:\consultant-api)
2018-07-01 16:16:08.711  INFO 6616 --- [           main] com.levent.consultantapi.EntryPoint      : No active profile set, falling back to default profiles: default
2018-07-01 16:16:08.785  INFO 6616 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@27808f31: startup date [Sun Jul 01 16:16:08 CEST 2018]; root of context hierarchy
2018-07-01 16:16:10.487  INFO 6616 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'beanNameViewResolver' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration; factoryMethodName=beanNameViewResolver; initMet
```

Then we can test if our standalone application is working fine with our web browser;

![standalone-test](https://github.com/bzdgn/spring-boot-restful-web-service-example/blob/master/ScreenShots/14_standalone_test.png)

Yes, our standalone application is working fine. We can easily deploy it in a Docker container, or just run it as
it is.

[Go back to TOC](#toc)
"
jghoman/finagle-java-example,master,70,30,2011-09-24T16:06:28Z,105,3,Quick example of a Java Thrift server and client using Finagle ,,
cryxli/sr201,master,30,21,2016-07-30T09:41:34Z,104,2,Protocol example for SR-201 Series network relay,,"# Simple Client Application for SR-201 Ethernet Relay Board

Resently I ordered a little board 50mm x 70mm with two relays. They can be switched by sending commands over TCP or UDP. The only problem with it is, that the code examples and instruction manual are entierly written in Chinese. Therefore, I created this repo to keep track of my findings regarding the SR-201-2.

## Models

The same idea, switching relays over ethernet, resulted in at least four different models of the SR-201:

* SR-201-1CH - Cased, single relay
* SR-201-2 - Plain board, two relays (mine)
* SR-201-RTC - Cased, four relays
* SR-201-E8B - Plain board, eight relays

They all seem to work with the same chip and software. Although, e.g., the SR-201-2 only has two relays, it also has an extension port with another 6 pins which can be switched, too.

## Protocols and Ports

The board supports the protocols ARP, ICMP, IP, TCP, UDP. Or short, everything needed to allow TCP and UDP connections.

When connected over TCP (port **6722**), the board will only accept 6 connections at a time. To prevent starving, it will close TCP connection after they have been idle for 15 seconds.

Since UDP (port **6723**) is not an end-to-end connection, there are no restrictions. But it is noteworthy that the board will execute UDP commands, but it will never answer. Therefore querying the state of the relays has to be done over TCP.

The board also listens to the TCP port **5111**. Over this connection the board can be configured. E.g., its static IP address can be changed.

## Factory Defaults

* Static IP address : 192.168.1.100
* Subnet mask : 255.255.255.0
* Default Gateway : 192.168.1.1
* Persistent relay state when power is lost : off
* Cloud service password : 000000
* DNS Server : 192.168.1.1
* Cloud service : connect.tutuuu.com
* Cloud service enabled: false

## Example Code

This repo contains the following modules:

* sr201-config-client - Client to read and change the config of the board.
* sr201-client - Simple client with 8 toggle buttons to change the state of the relays.
* sr201-server - REST interface to change the state of the relays.
* sr201-php-cloud-service - Example implementation of a cloud service back-end in PHP provided by [hobpet](https://github.com/hobpet) following the findings of [anakhaema](https://github.com/anakhaema).
 
Maven will create an executable JAR in each of the modules target directories.

## Scripts

In addition to my Java code examples that are clearly intended as a replacement for the default VB and Delphi programs, I added a scripts directory that contains simpler more pragmatic approaches to the SR-201 communication scheme.

* perl-config-script - A PERL script to manipulate the board's configuration by Christian DEGUEST.
* python-config-script - A python script to manipulate the board's configuration.

Many thanks to anyone who contributed to this knowledge base!

## Own Scripts

If you want to quickly setup your SR-201 without even starting a script or anything else, just check the protocol [Config commands](https://github.com/cryxli/sr201/wiki/Config-commands) and e.g. send a command via netcat:

    printf ""#11111;"" | nc [yourip] 5111

Note: It is crucial to use printf here, as newlines are seen as errors. It drove me crazy to find out about this one.
"
DataStax-Examples/spring-k8s-cassandra-microservices,master,38,14,2020-06-10T15:22:31Z,536,2,"Example microservices with Spring, Kubernetes, and Cassandra",cassandra kubernetes microservices spring spring-boot spring-cloud spring-data-cassandra,"# Microservices with Spring, Kubernetes, and Cassandra

This repository contains sample inventory microservices to demonstrate how to use Spring, Kubernetes and Cassandra together a single stack.

![Arch link](https://github.com/DataStax-Examples/spring-k8s-cassandra-microservices/blob/master/doc/pics/spring-k8s-cassandra-small.png?raw=true)

#### Contributors: 
- [Cedrick Lunven](https://github.com/clun) - twitter handdle [@clun](https://twitter.com/clunven)
- [Chris Splinter](https://github.com/csplinter)
- [Frank Moley](https://github.com/fpmoles) - twitter handle [@fpmoles](https://twitter.com/fpmoles)

#### Modules:
- [`microservice-spring-boot`](microservice-spring-boot): Service for Products
   - **Persistence Layer** : uses Cassandra Java driver's `CqlSession` directly for queries to products table
   - **Exposition Layer** : uses `spring-web`  `@Controller`
- [`microservice-spring-data`](microservice-spring-data): Service for Orders
  - **Persistence Layer** : uses Spring Data Cassandra for data access to orders table
  - **Exposition Layer** : uses Spring Data REST for API generation
- [`gateway-service`](gateway-service): Spring Cloud Gateway to route to the microservices

## 1. Objectives

Show a working set of microservices illustrating how to build Spring microservices with Kubernetes and Cassandra.
This repo leverages Spring modules:
- `spring-data`
- `spring-boot`
- `spring-data-rest`
- `spring-web`
- `spring-cloud-kubernetes`
- `spring-cloud-gateway`

## 2. How this Works

The primary mode of deployment is on a local Kubernetes cluster, though each service can be run standalone or in Docker.

The purpose is to show the many utilities of Spring in Kubernetes with Cassandra as the backing storage tier.

The business domain is an inventory / ecommerce application.

## 3. Setup and Running

### 3.a - Prerequisites
The prerequisites required for this application to run
* Docker
* Kubernetes
* JDK 11+
* Maven

### 3.b - Setup
Clone the current repository
```
git clone https://github.com/DataStax-Examples/spring-k8s-cassandra-microservices.git
```

Start minikube
```
# use docker as the virtualization driver
minikube start --driver=docker --extra-config=apiserver.authorization-mode=RBAC,Node

# tell minikube to use local docker registry
eval `minikube docker-env`
```

Build the services
```
# from the spring-k8s-cassandra-microservices directory
mvn package
```

Build the docker images
```
cd microservice-spring-boot; docker build -t <your-docker-username>/spring-boot-service:1.0.0-SNAPSHOT .
cd microservice-spring-data; docker build -t <your-docker-username>/spring-data-service:1.0.0-SNAPSHOT .
cd gateway-service; docker build -t <your-docker-username>/gateway-service:1.0.0-SNAPSHOT .
```

Alter deployment.yml files with your docker username
```
# replace image name in deploy/spring-boot/spring-boot-deployment.yml
# replace image name in deploy/spring-data/spring-data-deployment.yml
# replace image name in deploy/gateway/gateway-deployment.yml
```

Create namespaces
```
kubectl create ns cass-operator
kubectl create ns spring-boot-service
kubectl create ns spring-data-service
kubectl create ns gateway-service
```

### 3.c - Setup DataStax Astra or Cassandra Kubernetes Operator
#### DataStax Astra
Create a free tier database in [DataStax Astra](https://astra.datastax.com/) with keyspace name `betterbotz`

Download the secure connect bundle from the Astra UI ([docs](https://docs.datastax.com/en/astra/aws/doc/dscloud/astra/dscloudObtainingCredentials.html))

Create secrets for the Astra username/password and secure connect bundle
```
DB_USER=<astra-db-user>
DB_PASSWORD=<astra-db-password>
SECURE_CONNECT_BUNDLE_PATH=<path-to-secure-connect-bundle>
```

```
kubectl -n spring-boot-service create secret generic db-secret --from-literal=username=$DB_USER --from-literal=password=$DB_PASSWORD
kubectl -n spring-boot-service create secret generic astracreds --from-file=secure-connect-bundle=$SECURE_CONNECT_BUNDLE_PATH
```

```
kubectl -n spring-data-service create secret generic db-secret --from-literal=username=$DB_USER --from-literal=password=$DB_PASSWORD
kubectl -n spring-data-service create secret generic astracreds --from-file=secure-connect-bundle=$SECURE_CONNECT_BUNDLE_PATH
```

Change Spring Boot [ConfigMap](deploy/spring-boot/spring-boot-service-configmap.yml) to use secure connect bundle
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-boot-service
data:
  application.yml: |-
    astra.secure-connect-bundle: /app/astra/creds
```

Change Spring Data [ConfigMap](deploy/spring-data/spring-data-service-configmap.yml) to use secure connect bundle
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-data-service
data:
  application.yml: |-
    astra.secure-connect-bundle: /app/astra/creds
```

Uncomment the following lines in [Spring Boot Deployment.yml](deploy/spring-boot/spring-boot-deployment.yml) and [Spring Data Deployment.yml](deploy/spring-data/spring-data-deployment.yml)
```
volumes:
  - name: astravol
    secret:
      secretName: astracreds
      items:
        - key: secure-connect-bundle
          path: creds
...
volumeMounts:
  - name: astravol
    mountPath: ""/app/astra""
    readOnly: true
```

You're ready to go!

#### Cassandra Kubernetes Operator
Start the Cassandra operator
```
# create the storage class for the database
kubectl -n cass-operator apply -f deploy/storage-class.yml

# apply the operator manifest
kubectl -n cass-operator apply -f https://raw.githubusercontent.com/DataStax-Academy/kubernetes-workshop-online/master/1-cassandra/11-install-cass-operator-v1.1.yaml

# start a single C* 4.0 node
kubectl -n cass-operator apply -f deploy/cassandra-4.0.0-1node.yml
```

Create the Kubernetes Secrets for database username and password
```
# get the username and password from the secret
DB_USER=$(kubectl -n cass-operator get secret cluster1-superuser -o yaml | grep username | cut -d "" "" -f 4 | base64 -d)
DB_PASSWORD=$(kubectl -n cass-operator get secret cluster1-superuser -o yaml | grep password | cut -d "" "" -f 4 | base64 -d)

# create k8s secrets for the services (skip cmd for Spring Boot service if using Astra)
kubectl -n spring-boot-service create secret generic db-secret --from-literal=username=$DB_USER --from-literal=password=$DB_PASSWORD
kubectl -n spring-data-service create secret generic db-secret --from-literal=username=$DB_USER --from-literal=password=$DB_PASSWORD
```

### Running
Start the services
```
# from the spring-k8s-cassandra-microservices directory
kubectl -n spring-boot-service apply -f deploy/spring-boot
kubectl -n spring-data-service apply -f deploy/spring-data
kubectl -n gateway-service apply -f deploy/gateway
```

Expose the Gateway endpoint
```
# get the gateway-service pod
GATEWAY_POD=$(kubectl -n gateway-service get pods | tail -n 1 | cut -f 1 -d ' ')

# forward the port
kubectl -n gateway-service port-forward $GATEWAY_POD 8080:8080
```

Optionally expose the Spring Boot service endpoints (useful for testing)
```
# get the spring-boot-service pod
BOOT_SERVICE_POD=$(kubectl -n spring-boot-service get pods | tail -n 1 | cut -f 1 -d ' ')

# forward the port
kubectl -n spring-boot-service port-forward $BOOT_SERVICE_POD 8083:8083
```

Optionally expose the Spring Data service endpoints (useful for testing)
```
# get the spring-data-service pod
DATA_SERVICE_POD=$(kubectl -n spring-data-service get pods | tail -n 1 | cut -f 1 -d ' ')

# forward the port
kubectl -n spring-data-service port-forward $DATA_SERVICE_POD 8081:8081
```

#### Gateway Service endpoints

The Spring Cloud Gateway is running on port 8080 and forwards requests
to the Spring Boot and Spring Data endpoints below. To test that this is
working, you can replace the URLs below with `localhost:8080` with the same
curl commands.

#### Spring Boot service endpoints

Explore the endpoints with Swagger (only works if endpoints exposed above): http://localhost:8083/swagger-ui.html

![Swagger Spring Boot](https://github.com/DataStax-Examples/spring-k8s-cassandra-microservices/blob/master/doc/pics/swagger-spring-boot-service.png?raw=true)

Add products
```
curl -X POST -H ""Content-Type: application/json"" -d '{""name"": ""mobile"", ""id"":""123e4567-e89b-12d3-a456-556642440000"", ""description"":""iPhone"", ""price"":""500.00""}' http://localhost:8083/api/products/add
curl -X POST -H ""Content-Type: application/json"" -d '{""name"": ""mobile"", ""id"":""123e4567-e89b-12d3-a456-556642440001"", ""description"":""Android"", ""price"":""600.00""}' http://localhost:8083/api/products/add
```

Get products with name = mobile
```
curl http://localhost:8083/api/products/search/mobile
```

Get products with name = mobile and id = 123e4567-e89b-12d3-a456-556642440001
```
curl http://localhost:8083/api/products/search/mobile/123e4567-e89b-12d3-a456-556642440001
```

Delete product with name = mobile and id = 123e4567-e89b-12d3-a456-556642440001
```
curl -X DELETE http://localhost:8083/api/products/delete/mobile/123e4567-e89b-12d3-a456-556642440001
```

#### Spring Data service endpoints
Add orders
```
curl -H ""Content-Type: application/json"" -d '{""key"": {""orderId"":""123e4567-e89b-12d3-a456-556642440000"", ""productId"":""123e4567-e89b-12d3-a456-556642440000""}, ""productName"":""iPhone"", ""productPrice"":""500.00"", ""productQuantity"":1, ""addedToOrderTimestamp"": ""2020-04-12T11:21:59.001+0000""}' http://localhost:8081/api/orders/add
curl -H ""Content-Type: application/json"" -d '{""key"": {""orderId"":""123e4567-e89b-12d3-a456-556642440000"", ""productId"":""123e4567-e89b-12d3-a456-556642440001""}, ""productName"":""Android"", ""productPrice"":""600.00"", ""productQuantity"":1, ""addedToOrderTimestamp"": ""2020-04-12T11:22:59.001+0000""}' http://localhost:8081/api/orders/add
```
Get orders with order_id = 123e4567-e89b-12d3-a456-556642440000
```
curl http://localhost:8081/api/orders/search/order-by-id?orderId=123e4567-e89b-12d3-a456-556642440000
```
Get order with order_id = 123e4567-e89b-12d3-a456-556642440000 and product_id = 123e4567-e89b-12d3-a456-556642440000
```
curl ""http://localhost:8081/api/orders/search/order-by-product-id?orderId=123e4567-e89b-12d3-a456-556642440000&productId=123e4567-e89b-12d3-a456-556642440000""
```
Get only the product name and price of order_id = 123e4567-e89b-12d3-a456-556642440000
```
curl http://localhost:8081/api/orders/search/name-and-price-only?orderId=123e4567-e89b-12d3-a456-556642440000
```
Shows how to use a projection with Spring Data REST
```
curl ""http://localhost:8081/api/orders/search/name-and-price-only?orderId=123e4567-e89b-12d3-a456-556642440000&projection=product-name-and-price""
```

Delete order with order_id = 123e4567-e89b-12d3-a456-556642440000 and product_id = 123e4567-e89b-12d3-a456-556642440000
```
curl -X DELETE ""http://localhost:8081/api/orders/delete/product-from-order?orderId=123e4567-e89b-12d3-a456-556642440000&productId=123e4567-e89b-12d3-a456-556642440000""
```

Delete order with order_id = 123e4567-e89b-12d3-a456-556642440000
```
curl -X DELETE ""http://localhost:8081/api/orders/delete/order?orderId=123e4567-e89b-12d3-a456-556642440000""
```
"
lurbas/ViperArchitectureExample,master,96,4,2015-08-28T21:10:02Z,501,2,viper architecture example,,"# Search
[![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-Search-blue.svg?style=flat)](http://android-arsenal.com/details/3/2448)

viper architecture example

This is example of application built with VIPER architecture. It's built on top of sockeqwe's [Mosby](https://github.com/sockeqwe/mosby).

### Diagram

![](https://github.com/lurbas/Search/blob/master/readme/viper.png)

### Viper
I encourage you to read more about this pattern [here](https://speakerdeck.com/sergigracia/clean-architecture-viper) (slide above from the same presentation)

### License

    Copyright 2015 Lucas Urbas

    Licensed under the Apache License, Version 2.0 (the ""License"");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an ""AS IS"" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
"
noveogroup-amorgunov/spring-mvc-react,master,88,41,2017-01-03T06:28:17Z,1226,3,Example of using spring 4 (rest full api with hibernate) + react.js (client),mysql react spring spring-mvc,"# Spring 4 MVC + ReactJS

![alt tag](src/main/webapp/resources/preview.png)

Very light version of [stackoverflow](http://stackoverflow.com/) build by [ReactJS](https://facebook.github.io/react/) (client-side) and [Spring4](https://spring.io/) (server-side).

## Features

- Authorization system (by [json web token](https://jwt.io/))
- Questions, answers, users, reputation, tags and votes!
- Localization in react using [localizify](https://github.com/noveogroup-amorgunov/localizify)

## Intallation

**0** Clone repository!

```shell
$ git clone https://github.com/noveogroup-amorgunov/spring-mvc-react.git
```

**1** Change database driver (by default set for MySQL) and connections parameters (url, user and password) in `src/main/resources/app.properties`

**2** Change `jwt` secret key in `src/main/resources/app.properties` too (not nessasary)

**3** Create schema. After run application table will be created in auto mode. Follow example for MySQL

```sql
CREATE SCHEMA `spring-mvc-react` DEFAULT CHARACTER SET utf8 ;
```

**4** Install and build frontend dependencies 

```shell
$ cd src/main/webapp
$ npm install
$ npm install webpack -g # intstall webpack globally
$ npm run build # build bundle.js file
```

Use `npm run watch` for work in watch-mode. When you change some javascript file, here will be build new bundle.js

**5** Run server

```shell
$ mvn jetty:run
```
Access ```http://localhost:4017/spring4ajax```

To import this project into Eclipse IDE:

1. ```$ mvn eclipse:eclipse```
2. Import into Eclipse via **existing projects into workspace** option.
3. Done.
"
FledgeXu/NeutrinoSourceCode,master,42,14,2020-04-27T02:41:22Z,6459,0,It's Neutrino Project's example Code.,,
balaji-k13/Navigation-drawer-page-sliding-tab-strip,master,120,68,2013-08-05T15:17:33Z,6526,7,"Example which integration of Navigation Drawer and Page Sliding Tab Strip , like google play music app",,"# Android Navigation Drawer with Page (Pager) Sliding tab Strip

This sample is the result of integration of latest navigation drawer(v4 lib) and similar tab strip which is used in google play music app. (https://play.google.com/store/apps/details?id=com.google.android.music)

Please check out apk which is in root folder of the project , below is the Screenshot


<a href=""http://i.imgur.com/TRzIca6.png"" alt=""Screenshot"">
  <img src=""http://i.imgur.com/TRzIca6.png"">
</a>


## Acknowledgements

This sample uses many great open-source libraries from the Android dev community:

* [ActionBarSherlock (Tag 4.2.0)](https://github.com/JakeWharton/ActionBarSherlock)
* [nested-fragments](https://github.com/marsucsb/nested-fragments)
* [PagerSlidingTabStrip (Tag 1.0.1) ](https://github.com/astuetz/PagerSlidingTabStrip/releases/tag/v1.0.1)
* [NavigationDrawer](http://developer.android.com/training/implementing-navigation/nav-drawer.html)
* Latest Support v4 library

#Steps to compile the project in eclipse

* Download PagerSlidingTabStrip - Tag 1.0.1
* Import to eclipse
* Add latest android-support-v4.jar
* Download ActionBarSherlock - Tag 4.2.0
* Import to eclipse
* Add/replace android-support-v4.jar if there are any jar issues
* Add the above libraries to main project
* Clean and compile

I hope this helps you in building your next android app.
"
seflerZ/javaworker,master,27,21,2012-09-17T11:16:50Z,140,0,A simple example of the Java worker pattern,,
zcox/akka-zeromq-java,master,49,6,2011-04-07T18:27:55Z,484,0,"Examples of using Akka and 0MQ in Java, separately and together.",,
ebean-orm-demo/demo-order,master,25,17,2010-03-02T10:56:17Z,121,1,Example showing some features of Ebean ORM,,
SaravananSubramanian/dicom,master,35,22,2014-10-06T02:17:54Z,63532,2,This repository contains all the code that I have used in my DICOM articles on my blog (Java examples are included),dicom dicom-standard healthcare imaging-informatics java radiology,
plluke/tof,master,51,20,2019-11-01T18:09:03Z,1822,3,Example of grabbing ToF data from Samsung S10 5G,,"# Time of Flight Camera Example 
<p><img src=""docs/demo.gif""/></p>

This is an example app that demonstrates how to capture and process data from a Time of Flight camera, specifically the front-facing ""3D Camera"" on the Samsung S10 5G.

## How to Use
Clone and run on an Samsung S10 5G device from Android studio (3.5.1 at the time of publishing).

There is also an associated post [here](https://medium.com/@lukesma/working-with-the-3d-camera-on-the-samsung-s10-5g-4782336783c).
"
halide/CVPR2015,master,38,18,2015-06-01T16:56:47Z,6327,2,Example code used in the CVPR 2015 tutorial,,"To get started, download a binary release of Halide from halide-lang.org and untar/unzip it into this directory."
jgribonvald/demo-spring-cas-angular,master,29,20,2015-02-20T17:21:03Z,207,2,Example to use CAS auth with jhipster app,,"README for demo
==========================

set on application-dev.yml these properties :

```
server:
    address: LOCAL_ADDRESS (to your local address that your CAS can resolve)
    port: LOCAL_PORT (keep 8080)

app:
    service:
        home: http://LOCAL_ADDRESS:LOCAL_PORT/
        security: http://LOCAL_ADDRESS:LOCAL_PORT/j_spring_cas_security_check

cas:
    url:
        prefix: https://your.cas.domain/cas/
        login: https://your.cas.domain/cas/login
        logout: https://your.cas.domain/cas/logout

```

and do :
```
mvn spring-boot:run
```
go on http://LOCAL_ADDRESS:LOCAL_PORT/index.html#/
"
apollographql/federation-jvm-spring-example,main,58,18,2022-06-03T17:21:47Z,205,19,Apollo Federation JVM example implementation using Spring for GraphQL,apollo-federation graphql java spring-graphql,"# Federation JVM Spring Example

[Apollo Federation JVM](https://github.com/apollographql/federation-jvm) example implementation using [Spring for GraphQL](https://docs.spring.io/spring-graphql/docs/current/reference/html/).
If you want to discuss the project or just say hi, stop by [the Apollo community forums](https://community.apollographql.com/).

The repository contains two separate projects:

1. `products-subgraph`: A Java GraphQL service providing the federated `Product` type
2. `reviews-subgraph`: A Java GraphQL service that extends the `Product` type with `reviews`

See individual projects READMEs for detailed instructions on how to run them.

Running the demo
----

1. Start `products-subgraph` by running the `ProductsApplication` Spring Boot app from the IDE or by running `./gradlew :products-subgraph:bootRun` from the root project directory
2. Start `reviews-subgraph` by running the `ReviewsApplication` Spring Boot app from the IDE or `./gradlew :reviews-subgraph:bootRun` from the root project directory
3. Start Federated Router
   1. Install [rover CLI](https://www.apollographql.com/docs/rover/getting-started)
   2. Start router and compose products schema using [rover dev command](https://www.apollographql.com/docs/rover/commands/dev)

    ```shell
    # start up router and compose products schema
    rover dev --name products --schema ./products-subgraph/src/main/resources/graphql/schema.graphqls --url http://localhost:8080/graphql
    ```

   3. In **another** shell run `rover dev` to compose reviews schema

    ```shell
    rover dev --name reviews --schema ./reviews-subgraph/src/main/resources/graphql/schema.graphqls --url http://localhost:8081/graphql
    ```

4. Open http://localhost:3000 for the query editor

Example federated query

```graphql
query ExampleQuery {
    products {
        id
        name
        description
        reviews {
            id
            text
            starRating
        }
    }
}
```

## Other Federation JVM examples

* [Netflix DGS Federation Example](https://github.com/Netflix/dgs-federation-example)
* [GraphQL Java Kickstart Federation Example](https://github.com/setchy/graphql-java-kickstart-federation-example)
"
wangshaolei/NumberKeyboard,master,48,10,2016-06-15T14:08:55Z,400,2,For example meituan's mechant NumberKeyboard,,"# NumberKeyboard
## Custom keyboardview with two ways:

1. Override systems's sys.xml of keyboardview
2. Custom the layout and slove the touchListener's question and so on...

### For example: MeiTuan's Merchant or NuoMi's Merchant app, Number Keyboard

#### Show parts codes:

```java
    public class MainActivity extends AppCompatActivity implements View.OnClickListener, NumberKeyboardUtil.OnPopuWindowListener
    private void initView(){
        etCode = ButterKnife.findById(inputLayout, R.id.et_code);
        keyboardPopupwindow = NumberKeyboardPopupWindow.getInstance(this).onCreate(this);
        NumberKeyboardUtil.getInstance().setOnTouchListener(etCode, keyboardPopupwindow, this);
        NumberKeyboardUtil.getInstance().disableCopyAndPaste(etCode);
    }
    @Override
    public void showPopuWindow() {
        etCode.requestFocus();
        keyboardPopupwindow.showAsDropDown(llTop);
    }

    @Override
    public void dismiss() {
        etCode.getText().clear();
        etCode.clearFocus();
        keyboardPopupwindow.dismiss();
    }

    @Override
    public void insertStr(String str) {
        int index = etCode.getSelectionStart();
        if (index < 0 || index >= etCode.getText().toString().length()) {
            etCode.append(str);
        } else {
            etCode.getEditableText().insert(index, str);
        }
    }

    @Override
    public void check() {
        Toast.makeText(this, ""check"", Toast.LENGTH_SHORT).show();
    }
```

# Thanks:

[Jakewharton-Butterknife](https://github.com/JakeWharton/butterknife)



![](https://github.com/wangshaolei/NumberKeyboard/blob/master/img/1.png)    ![](https://github.com/wangshaolei/NumberKeyboard/blob/master/img/2.png)

"
doyleyoung/vertx-graphql-example,master,38,11,2017-02-16T04:51:10Z,135,1,GraphQL Async example using Vert.x,,"# Vert.x GraphQL Example

![VG](https://raw.githubusercontent.com/bmsantos/vertx-graphql-example/master/vertx-graphql-mic-drop.png) 

When it comes to performance and scalability, Vert.x has always been hard to beat and version 3 just made it much easier to develop and deploy. 

This simple application is used to demonstrate:

- that Java CompletableFuture, Vert.x Futures and RxJava can be easily combined
- that Vert.x micro-services are easy to develop and deploy through Docker containers

The goal of this application is to exercise graphql-java async (non-blocking) with Vert.x.

In addition it also uses:

- [graphql-apigen](https://github.com/bmsantos/graphql-apigen/tree/async) - to facilitate the graphql schema generation
- [vertx-dataloader](https://github.com/engagingspaces/vertx-dataloader) - to ensure a consistent API data fetching between the different resources


## System Architecture 

```text
                    .---------.       .-----------.
  POST /graphql --> | GraphQL |       | Customer  |
                    | Service | ----> | Service   |
                    '---------'   |   '-----------'
                                  |   .-----------.   
                                  |   | Vehicle   |
                                  |-> | Service   |
                                  |   '-----------'
                                  |   .-----------.
                                  |   | Rental    |
                                  '-> | Service   |
                                      '-----------'
```


## Before you start

```graphql-java-async``` is not out yet. In order to build this project you need to:

 1. ```graphql-java``` - Checkout and build Dmitry's [async branch](https://github.com/dminkovsky/graphql-java/tree/async)
 1. ```graphql-apigen``` - Checkout and build the [eb_graphql branch](https://github.com/bmsantos/graphql-apigen/tree/eb_graphql) of my fork of [Distelli/graphql-apigen](https://github.com/Distelli/graphql-apigen)
 
## Build:

After building the async branches of both graphql-java and graphql-apigen do:

```sh
mvn clean package
```


## Execute:

```sh
./docker/run.sh
```


## Test

The graphql-service exposes a POST endpoint. You can use CURL but it is recommended to use [Graphiql App](https://github.com/skevy/graphiql-app).

Sample queries to use on a POST to http://localhost:8080/graphql.


### Querying for a single rental entry:
```graphql
{
  rental(id: 1) {
    id
    customer {
      id
      name
      address
      city
      state
      country
      contact {
        phone
        type
      }
    }
    vehicle {
      id
      brand
      model
      type
      year
      mileage
      extras
    }
  }
}
```


### Querying for all active rentals:
```graphql
{
  rentals {
    id
    customer {
      id
      name
      address
      city
      state
      country
      contact {
        phone
        type
      }
    }
    vehicle {
      id
      brand
      model
      type
      year
      mileage
      extras
    }
  }
}
```


### Example using CURL:
```bash
curl -k -X POST -d '{ ""operationName"": null, ""query"": ""{ rentals { customer { name } vehicle { brand model } } }"", ""variables"": ""{}"" }' http://localhost:8080/graphql
```
"
jasebell/mlbook,master,67,63,2014-10-25T11:09:42Z,664,0,"Example code for the Wiley book Machine Learning - Hands On for Developers and Technical Professionals""""",,
bezkoder/spring-boot-security-login,master,108,52,2022-01-22T12:11:49Z,145,6,"Spring Boot + Spring Security: Login and Registration example with JWT, H2 Database and HttpOnly Cookie",authentication authorization httponly-cookie jwt jwt-auth jwt-authentication jwt-token login registration spring-boot spring-security,"# Spring Boot Security Login example with JWT and H2 example

- Appropriate Flow for User Login and Registration with JWT and HttpOnly Cookie
- Spring Boot Rest Api Architecture with Spring Security
- How to configure Spring Security to work with JWT
- How to define Data Models and association for Authentication and Authorization
- Way to use Spring Data JPA to interact with H2 Database

## User Registration, Login and Authorization process.

![spring-boot-security-login-jwt-flow](spring-boot-security-login-jwt-flow.png)

## Spring Boot Server Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-security-login-jwt-architecture](spring-boot-security-login-jwt-architecture.png)

For more detail, please visit:
> [Spring Boot Security Login example with JWT and H2 example](https://www.bezkoder.com/spring-boot-security-login-jwt/)

> [For MySQL/PostgreSQL](https://www.bezkoder.com/spring-boot-login-example-mysql/)

> [For MongoDB](https://www.bezkoder.com/spring-boot-jwt-auth-mongodb/)

Working with Front-end:
> [Angular 12](https://www.bezkoder.com/angular-12-jwt-auth-httponly-cookie/) / [Angular 13](https://www.bezkoder.com/angular-13-jwt-auth-httponly-cookie/) / [Angular 14](https://www.bezkoder.com/angular-14-jwt-auth/) / [Angular 15](https://www.bezkoder.com/angular-15-jwt-auth/) / [Angular 16](https://www.bezkoder.com/angular-16-jwt-auth/) / [Angular 17](https://www.bezkoder.com/angular-17-jwt-auth/)

> [React](https://www.bezkoder.com/react-login-example-jwt-hooks/) / [React Redux](https://www.bezkoder.com/redux-toolkit-auth/)

## Dependency
– If you want to use PostgreSQL:
```xml
<dependency>
  <groupId>org.postgresql</groupId>
  <artifactId>postgresql</artifactId>
  <scope>runtime</scope>
</dependency>
```
– or MySQL:
```xml
<dependency>
  <groupId>com.mysql</groupId>
  <artifactId>mysql-connector-j</artifactId>
  <scope>runtime</scope>
</dependency>
```
## Configure Spring Datasource, JPA, App properties
Open `src/main/resources/application.properties`
- For PostgreSQL:
```
spring.datasource.url=jdbc:postgresql://localhost:5432/testdb
spring.datasource.username=postgres
spring.datasource.password=123

spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

# Hibernate ddl auto (create, create-drop, validate, update)
spring.jpa.hibernate.ddl-auto=update

# App Properties
bezkoder.app.jwtSecret= ======================BezKoder=Spring===========================
bezkoder.app.jwtExpirationMs= 86400000
```
- For MySQL
```
spring.datasource.url=jdbc:mysql://localhost:3306/testdb?useSSL=false
spring.datasource.username=root
spring.datasource.password=123456

spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQLDialect
spring.jpa.hibernate.ddl-auto=update

# App Properties
bezkoder.app.jwtSecret= ======================BezKoder=Spring===========================
bezkoder.app.jwtExpirationMs= 86400000
```
## Run Spring Boot application
```
mvn spring-boot:run
```

## Run following SQL insert statements
```
INSERT INTO roles(name) VALUES('ROLE_USER');
INSERT INTO roles(name) VALUES('ROLE_MODERATOR');
INSERT INTO roles(name) VALUES('ROLE_ADMIN');
```

## Refresh Token

[Spring Boot JWT Refresh Token example](https://www.bezkoder.com/spring-security-refresh-token/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Rest Controller Unit Test with @WebMvcTest](https://www.bezkoder.com/spring-boot-webmvctest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Associations:
> [JPA/Hibernate One To Many example in Spring Boot](https://www.bezkoder.com/jpa-one-to-many/)

> [JPA/Hibernate Many To Many example in Spring Boot](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA/Hibernate One To One example in Spring Boot](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)

## Fullstack Authentication

> [Spring Boot + Vue.js JWT Authentication](https://bezkoder.com/spring-boot-vue-js-authentication-jwt-spring-security/)

> [Spring Boot + Angular 8 JWT Authentication](https://bezkoder.com/angular-spring-boot-jwt-auth/)

> [Spring Boot + Angular 10 JWT Authentication](https://bezkoder.com/angular-10-spring-boot-jwt-auth/)

> [Spring Boot + Angular 11 JWT Authentication](https://bezkoder.com/angular-11-spring-boot-jwt-auth/)

> [Spring Boot + Angular 12 JWT Authentication](https://www.bezkoder.com/angular-12-spring-boot-jwt-auth/)

> [Spring Boot + Angular 13 JWT Authentication](https://www.bezkoder.com/angular-13-spring-boot-jwt-auth/)

> [Spring Boot + Angular 14 JWT Authentication](https://www.bezkoder.com/angular-14-spring-boot-jwt-auth/)

> [Spring Boot + Angular 15 JWT Authentication](https://www.bezkoder.com/angular-15-spring-boot-jwt-auth/)

> [Spring Boot + Angular 16 JWT Authentication](https://www.bezkoder.com/angular-16-spring-boot-jwt-auth/)

> [Spring Boot + Angular 17 JWT Authentication](https://www.bezkoder.com/angular-17-spring-boot-jwt-auth/)

> [Spring Boot + React JWT Authentication](https://bezkoder.com/spring-boot-react-jwt-auth/)

## Fullstack CRUD App

> [Vue.js + Spring Boot + H2 Embedded database example](https://www.bezkoder.com/spring-boot-vue-js-crud-example/)

> [Vue.js + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-vue-js-mysql/)

> [Vue.js + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-vue-js-postgresql/)

> [Angular 8 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-spring-boot-postgresql/)

> [Angular 10 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-10-spring-boot-crud/)

> [Angular 10 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-10-spring-boot-postgresql/)

> [Angular 11 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-11-spring-boot-crud/)

> [Angular 11 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-11-spring-boot-postgresql/)

> [Angular 12 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-12-spring-boot-crud/)

> [Angular 12 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-12-spring-boot-mysql/)

> [Angular 12 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-12-spring-boot-postgresql/)

> [Angular 13 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-13-crud/)

> [Angular 13 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-13-mysql/)

> [Angular 13 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-13-postgresql/)

> [Angular 14 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-14-crud/)

> [Angular 14 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-14-mysql/)

> [Angular 14 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-14-postgresql/)

> [Angular 15 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-15-crud/)

> [Angular 15 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-15-mysql/)

> [Angular 15 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-15-postgresql/)

> [Angular 16 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-16-crud/)

> [Angular 16 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-16-mysql/)

> [Angular 16 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-16-postgresql/)

> [Angular 17 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-17-crud/)

> [Angular 17 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-17-mysql/)

> [Angular 17 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-17-postgresql/)

> [React + Spring Boot + MySQL example](https://www.bezkoder.com/react-spring-boot-crud/)

> [React + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-react-postgresql/)

> [React + Spring Boot + MongoDB example](https://www.bezkoder.com/react-spring-boot-mongodb/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://www.bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React.js with Spring Boot Rest API](https://www.bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue.js with Spring Boot Rest API](https://www.bezkoder.com/integrate-vue-spring-boot/)
"
YongHuiLuo/Learning-Rxandroid,master,58,18,2016-01-06T15:49:17Z,2673,1,Learn and use RxAndroid together by PPT and Example,,"# Learning-Rxandroid
---
Because interest RxJava, RxAndroid, RxBinding of creating this project. RxAndroid making program coding for asynchronous operations more simple, in addition, the observer pattern design for my project and enhance the ability of encoding are very helpful. I compiled in the process of learning a few examples related to common methods, the future will continue to be updated. In addition, creating About RxAndroid.PPT documents on the network based on learning materials and personal understanding. Hope can help to want to know and learn with friends RxJava and RxAndroid projects. On commonly used methods, there are several examples:

（译）因为对RxJava、RxAndroid、RxBinding 的兴趣，创建此项目。RxAndroid使得程序中对异步操作的编码更简洁，另外，观察者模式的设计理念对我的项目和编码的能力的提升都很有帮助。我在学习的过程中整理了一些相关常用方法的例子，以后仍然会继续更新。此外，根据网络上的学习资料和个人的理解创建<i class=""icon-file""></i>About RxAndroid.PPT的文档。希望能够帮助到想了解和学习RxJava和RxAndroid项目的朋友。关于常用的方法，有如下几个例子：

>* RxBaseExampleActivity 
>* UsageExampleActivity
>* SchedulerExampleActivity
>* MapExampleActivity
>* FlatMapExampleActivity
>* ThrottleFirstExampleActivity
>* LiftExampleActivity
>* SchedulerMultiExampleActivity
>* ComposeExampleActivity

If you want to see the PPT, there is a file named About RxJava.pptx documentation, introduction of RxJava and RxAndroid some understanding in the project.。

（译）如果你想查看PPT，在项目中有文件名为 <i class=""icon-file""></i>About RxJava.pptx的文档,介绍对RxJava和RxAndroid的一些理解。

Project-related class introduce（项目相关类介绍）
---

###RxBaseExampleActivity
Create Observable, Subscribe objects in two different ways, onSubscribe achieve subscriptions between the observer and the observed, ActionX use.

（译）创建Observable、Subscriber对象的两种不同方式，onSubscribe实现观察者和被观察者之间的订阅，ActionX的使用。

###UsageExampleActivity
Use from and create to create Observable, traversal collection without using a For loop, reading the resource file and show.

（译）使用方法from和create来创建Observable，不使用For循环实现集合的遍历，读取资源文件并展示。

###SchedulerExampleActivity
By using subscribeOn or ObserveOn method to achieve scheduling between threads, a simple line of code that is realized on the main UI thread operations.

（译）通过使用subscribeOn 或者 ObserveOn 方法 实现线程之间的调度，简单的一行代码即实现UI操作在主线程上进行。

``` java
.subscribeOn(Schedulers.io())
.observeOn(AndroidSchedulers.mainThread())
```

###MapExampleActivity
Use map to achieve transformation 1 to 1 which is a major feature RxJava - the transformation. map can transform one object into another object, and finally passed to the observer. String example by according to the type of the file name is converted into Bitmap with ImageView on display illustrate this feature. There are other examples, supplementary illustrate this point.

（译）使用方法map实现1对1的变换这是RxJava的一大特点 -- 变换。map能将一个对象变换成另外的一个对象，并最终传递给观察者。例子中通过根据String类型的文件名转换成Bitmap并用ImageView进行展示说明这个特点。还有其他的例子，补充说明这一点。

###FlatMapExampleActivity
Methods flatMap, is another way to achieve transformation. Not accurate to say that he achieved one to more transformation, for example, a student can have multiple output course, this method return value is an Observable object about his interpretation are described in ppt document.

（译）方法flatMap，是实现变换的另外一个方法。不准确的说他实现了one to more的变换，比如一个学生可以有多门课程的输出，此方法返回值是一个Observable对象，关于他的解释在ppt文档中有说明。

###ThrottleFirstExampleActivity
This is an example RxBinding project, to achieve the prevention of violence demand View is clicked, this is a small demand point I personally prefer the following code:

（译）这是RxBinding项目的一个例子，实现了防止View被暴力点击的需求，这是我个人比较喜欢的一个小需求点，代码如下：
``` java
  RxView.clicks(click_me)
                .throttleFirst(3000, TimeUnit.MILLISECONDS)
                .subscribe(new Action1<Void>() {
                    @Override
                    public void call(Void aVoid) {
                        Toast.makeText(getBaseContext(), ""Clicking"", Toast.LENGTH_LONG).show();
                    }
                });
```
RxBinding View operations in many of the convenience and the methods used, I will continue to update, if you are interested, you can also help to perfect her, to help more people understand and use RxBinding.

（译）RxBinding在对View的操作上还有很多便捷和使用的方法，我也会持续更新，如果你有兴趣，也可以帮助来完善她，方便更多的人了解和使用RxBinding。

###LiftExampleActivity
Lift the method code to achieve the principles of transformation, including map and flatmap eventually call to lift to achieve. On the principle of lift are described in ppt document.

（译）在方法Lift的代码中实现了变换的原理，包括map和flatmap最终都会调用到lift来实现。关于lift的原理在ppt文档中有介绍。

###SchedulerMultiExampleActivity
An example of complex use, including transformation and thread scheduling, involving many transformations and multiple thread switches. The thread ID input display after each change in TextView, the ease of understanding. Here involves using Schedulers class can create the following several common scheduler:

（译）复合使用的一个例子，包括变换和线程调度，涉及到多次变换和多次线程切换。将每次变换之后的线程ID在TextView中输入展示，方便理解。此处涉及到Schedulers类的使用，能够创建如下几个常用的调度器：

>>* Schedulers.io()
>>* Schedulers.newThread()
>>* Schedulers.computation()
>>* Schedulers.immediate()
>>* Schedulers.trampoline()
>>* AndroidSchedulers.mainThread()

###ComposeExampleActivity
Methods compose help achieve when there are multiple lift, simplify the code.

（译）方法compose帮助实现当有多个lift，简化代码。

Related open source projects（相关的开源项目）
---
https://github.com/ReactiveX/RxAndroid
https://github.com/JakeWharton/RxBinding

Blog reference and learning materials（参考Blog及学习资料）
---

 - http://gank.io/post/560e15be2dca930e00da1083 《给 Android 开发者的 RxJava详解》 对我学习Rx系列项目受益非常大的博文，包括PPT的整理相关的内容来自这篇博文，在此感谢作者 -- 抛物线。
 - http://blog.csdn.net/lzyzsd/article/details/41833541 深入浅出RxJava（一：基础篇）
 - http://blog.csdn.net/lzyzsd/article/details/44094895 深入浅出RxJava ( 二：操作符 )
 - http://blog.csdn.net/lzyzsd/article/details/44891933 深入浅出RxJava三--响应式的好处
 - http://blog.csdn.net/lzyzsd/article/details/45033611 深入浅出RxJava四-在Android中使用响应式编程
 - 项目中的源码
 - 及其他相关方面的Blog"
lgvalle/FragmentSharedFabTransition,master,71,20,2015-04-15T14:33:55Z,240,0,Example of how to use shared element transitions within Fragments,,"# FragmentSharedFabTransition

![fab anim](https://raw.githubusercontent.com/lgvalle/FragmentSharedFabTransition/master/screenshots/fab-anim.gif)
"
okkam-it/flink-mongodb-test,master,34,14,2014-11-05T17:23:01Z,128,1,Flink 0.7 MongoDB example (for Hadoop2),,"Accessing Data Stored in MongoDB  with Apache Flink 0.7+!
===================

Starting from the post at https://flink.incubator.apache.org/news/2014/01/28/querying_mongodb.html here at [Okkam](http://www.okkam.it) we played around withthe new **Apache Flink APIs (0.7+)** and we manage to make a simple mapreduce example.

----------

pom.xml
-------------
```xml
<project xmlns=""http://maven.apache.org/POM/4.0.0""
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
	xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
	<modelVersion>4.0.0</modelVersion>
	<groupId>org.okkam.flink</groupId>
	<artifactId>flink-mongodb-test</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<flink.version>0.7.0-hadoop2-incubating</flink.version>
		<mongodb.hadoop.version>1.3.0</mongodb.hadoop.version>
		<hadoop.version>2.4.0</hadoop.version>
	</properties>
	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.1</version>
				<configuration>
					<source>1.7</source>
					<target>1.7</target>
				</configuration>
			</plugin>
		</plugins>
	</build>
	<dependencyManagement>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>${hadoop.version}</version>
		</dependency>
	</dependencyManagement>
	<dependencies>
		<!-- Force dependency management for hadoop-common -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>${hadoop.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-hadoop-compatibility</artifactId>
			<version>${flink.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-java</artifactId>
			<version>${flink.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-clients</artifactId>
			<version>${flink.version}</version>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.mongodb</groupId>
			<artifactId>mongo-hadoop-core</artifactId>
			<version>${mongodb.hadoop.version}</version>
		</dependency>

	</dependencies>

</project>
```
> **Note:**

> - Change ``dbname`` and ``collectioname`` accordingly to your database
> - In the map function read fields you need (e.g. ``jsonld``)
> - Change the output coordinates of the job (default ``test.testData``)


----------


Java code
-------------------

This is a simple code to connecto to a local MongoDB instance:

```java
package org.okkam.flink.mongodb.test;

import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.java.DataSet;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.hadoopcompatibility.mapred.HadoopInputFormat;
import org.apache.hadoop.mapred.JobConf;
import org.bson.BSONObject;

import com.mongodb.BasicDBObject;
import com.mongodb.hadoop.io.BSONWritable;
import com.mongodb.hadoop.mapred.MongoInputFormat;

public class MongodbExample {
	public static void main(String[] args) throws Exception {

		// set up the execution environment
		final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

		// create a MongodbInputFormat, using a Hadoop input format wrapper
		HadoopInputFormat<BSONWritable, BSONWritable> hdIf = 
				new HadoopInputFormat<BSONWritable, BSONWritable>(new MongoInputFormat(),
						BSONWritable.class, BSONWritable.class,	new JobConf());
	
		// specify connection parameters
		hdIf.getJobConf().set(""mongo.input.uri"", 
				""mongodb://localhost:27017/dbname.collectioname"");

		DataSet<Tuple2<BSONWritable, BSONWritable>> input = env.createInput(hdIf);
		// a little example how to use the data in a mapper.
		DataSet<Tuple2< Text, BSONWritable>> fin = input.map(
				new MapFunction<Tuple2<BSONWritable, BSONWritable>, 
									Tuple2<Text,BSONWritable> >() {

					private static final long serialVersionUID = 1L;

					@Override
					public Tuple2<Text,BSONWritable> map(
							Tuple2<BSONWritable, BSONWritable> record) throws Exception {
						BSONWritable value = record.getField(1);
						BSONObject doc = value.getDoc();
						BasicDBObject jsonld = (BasicDBObject) doc.get(""jsonld"");
						
						String id = jsonld.getString(""@id"");
						DBObject builder = BasicDBObjectBuilder.start()
				                .add(""id"", id)
				                .add(""type"", jsonld.getString(""@type""))
				                .get();

				        BSONWritable w = new BSONWritable(builder);
		                return new Tuple2<Text,BSONWritable>(new Text(id), w);
					}
				});

		// emit result (this works only locally)
//		fin.print();
		
		MongoConfigUtil.setOutputURI( hdIf.getJobConf(), 
				""mongodb://localhost:27017/test.testData"");
		// emit result (this works only locally)
		fin.output(new HadoopOutputFormat<Text,BSONWritable>(
				new MongoOutputFormat<Text,BSONWritable>(), hdIf.getJobConf()));

		// execute program
		env.execute(""Mongodb Example"");
	}
}

```

----------


Run the project
-------------------

The easyest way to test the program is to clone the git repository and import the project in Eclipse and then run **MongodbExample** class

Written by Okkam s.r.l. [@okkamit](https://twitter.com/okkamit)
"
florina-muntenescu/ReactiveBurgers,master,73,10,2016-07-16T12:23:05Z,210,1,"Code example for The ABCs of RxJava""""",,"# ReactiveBurgers

Code example for ""The ABCs of RxJava"" talk.
It contains different ways of creating RxJava ``Observable``s:

* from a static list - where every element of the list will be an emission of an ``Observable``
* from a file - where every line of the file will be an emission of an ``Observable``
* from click events, with the help of ``Subject``s
* from multiple ``Observable``s

Following the burger example from ""The ABCs of RxJava"", the slices of tomatoes are created from a static list,
the buns from file, the meat from click events and the burgers by ``zip``ing the tomato, meat and bun ``Observable``s.

Also, examples of manipulating a stream of data using the ``filter``, ``map`` and ``flatmap`` operators are given.

The code follows the Model-View-ViewModel architecture pattern:
* the view is the ``BurgerActivity``.
* the view model is the ``BurgerViewModel`` - it exposes the tomato, bun and burger stream of data to the view and allows the view to notify about new pieces of raw meat available. The view model gets the tomato and bun streams of data from the data model. The view model also creates the burger stream of data.
* the data model is the ``DataModel`` - it creates the stream of tomato slices based on a list of tomatoes and the stream of buns base on the number of lines in a file that contain the word ""bun"".

To showcase the testability of RxJava, unit tests for the ``BurgerViewModel`` class are provided.
"
jvirtanen/coinbase-fix-example,main,48,15,2017-02-23T12:50:44Z,112,0,Simple example application for Coinbase Pro FIX API,bitcoin coinbase coinbase-pro finance fixprotocol java trading,"# Coinbase Pro FIX Example

This is a simple example application that demonstrates how to connect to
[Coinbase Pro][] using the [FIX API][] and [Philadelphia][], an open source
FIX engine for the JVM.

  [Coinbase Pro]: https://pro.coinbase.com
  [FIX API]: https://docs.pro.coinbase.com/#fix-api
  [Philadelphia]: https://github.com/paritytrading/philadelphia

Building and running this application requires Java Development Kit (JDK) 11
or newer and Maven.

## Usage

To build and run the application, follow these steps:

1. Build the application:

    ```shell
    mvn package
    ```

2. Create a configuration file, `etc/example.conf`:

    ```shell
    cp etc/example.conf.template etc/example.conf
    ```

3. Fill in the API passphrase, key, and secret in the configuration file,
   `etc/example.conf`.

4. Run the application:

    ```shell
    java -jar coinbase-fix-example.jar etc/example.conf
    ```

The application logs onto Coinbase Pro and immediately logs out.

## License

Copyright 2017 Jussi Virtanen.

Released under the Apache License, Version 2.0. See `LICENSE.txt` for details.
"
SomMeri/antlr-step-by-step,master,25,16,2011-07-28T12:19:04Z,164,1,Example project for ANTLR tutorial blog post.,,
Rapter1990/SpringBootMicroservices,master,81,36,2022-07-23T11:38:47Z,1194,3,"Spring Boot Microservice Example(Eureka Server, Config Server, API Gateway, Services , RabbitMq, Keycloak)",api-gateway configserver docker docker-compose eureka-server java keycloak microservices rabbitmq service spring-boot spring-cloud spring-security,"# Spring Boot Microservice Example(Eureka Server, Config Server, API Gateway, Services , RabbitMq, Keycloak)

<img src=""screenshots/springbootmicroservices.drawio_image.png"" alt=""Main Information"" width=""800"" height=""900"">

# About the project
<ul style=""list-style-type:disc"">
  <li>User can register and login through Keycloak</li>
  <li>User can register and login through Keycloak</li>
  <li>Admin can create, update, delete advertisement and get advertisement by its is and get all advertisements from management service to advertisement service through API Gateway</li>
  <li>Admin can approve and reject advertisement from advertisement service to report service by using managment service through API Gateway</li>
  <li>User canget advertisement by its is and get all advertisements from management service to advertisement service through API Gateway</li>
  <li>The view count of the approved advertisement are increasing when user try to show it</li>
</ul>

7 services whose name are shown below have been devised within the scope of this project.

- Config Server
- Eureka Server
- API Gateway
- User Service
- Management Service
- Advertisement Service
- Report Service

### 🔨 Run the App

<b>Docker</b>

<b>1 )</b> Install <b>Docker Desktop</b>. Here is the installation <b>link</b> : https://docs.docker.com/docker-for-windows/install/

<b>2 )</b> Open <b>Terminal</b> under <b>resources</b> folder to run <b>Keycloak</b> and <b>RabbitMq</b> on <b>Docker</b> Container
```
    docker-compose up -d
```
<b>3 )</b> Implement Keycloak Settings
```
    1 ) Open Keycloak on the Browser through localhost:8181
    2 ) Enter username and password (admin : admin)
    3 ) Create Client named for spring-boot-microservice-keycloak and define it in Keycloak config of user service
    4 ) Change client's access type from public to confidential
    5 ) Get secret key to define clientSecret in Keycloak config of user service
    6 ) Define roles for Admin and User as ROLE_ADMIN and ROLE_USER
```

<b>4 )</b> Implement Rabbitmq Settings
```
    1 ) Open Rabbitmq on the Browser through http://localhost:15672
    2 ) Enter username and password (rabbitmq : 123456)
    3 ) Open Admin section in the navbar
    4 ) Define new user named guest and its username , password (guest : guest , role : administrator) , next give all permissiion (Virtual host : ""/"" , regexp : "".*"")
```

<b>Maven></b>

<b>1 )</b> Start Keycloak and Rabbit through Docker

<b>2 )</b> Implement their settings

<b>3 )</b> Download your project from this link `https://github.com/Rapter1990/SpringBootMicroservices`

<b>4 )</b> Go to the project's home directory :  `cd SpringBootMicroservices`

<b>5 )</b> Create a jar file though this command `mvn clean install`

<b>6 )</b> Run the project though this command `mvn spring-boot:run`


### To execute the API's through the gateway
    1) http://localhost:8600/api/v1/users/signup
    2) http://localhost:8600/api/v1/users/login
    3) http://localhost:8600/api/v1/users/info 
    4) http://localhost:8600/api/v1/management/admin_role/create/{user_id} 
    5) http://localhost:8600/api/v1/management/admin_role/alladvertisements
    6) http://localhost:8600/api/v1/management/admin_role/alladvertisements/{advertisement_id} 
    7) http://localhost:8600/api/v1/management/admin_role/update/{advertisement_id}
    8) http://localhost:8600/api/v1/management/admin_role/delete/{advertisement_id} 
    9) http://localhost:8600/api/v1/management/admin_role/advertisement/{advertisement_id}/approve
    10) http://localhost:8600/api/v1/management/admin_role/advertisement/{advertisement_id}/reject
    11) http://localhost:8600/api/v1/management/user_role/alladvertisements
    12) http://localhost:8600/api/v1/management/user_role/advertisement/{advertisement_id} 
    

Explore Rest APIs
<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Valid Request Body</th>
      <th>Valid Request Params</th>
      <th>Valid Request Params and Body</th>
      <th>No Request or Params</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>signup</td>
      <td>Sign Up for User and Admin</td>
      <td><a href=""README.md#signup"">Info</a></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>login</td>
      <td>Login</td>
      <td><a href=""README.md#login"">Info</a></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>info</td>
      <td>Get User's Role Information (ROLE_USER or ROLE_ADMIN)</td>
      <td></td>
      <td></td>
      <td></td>
      <td><a href=""README.md#info"">Info</a></td>
  </tr>
  <tr>
     <td>POST</td>
     <td>create/{user_id}</td>
     <td>Create Advertisement for User</td>
     <td></td>
     <td></td>
     <td><a href=""README.md#create"">Info</a></td>
     <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>alladvertisements</td>
      <td>Get all advertisements From Admin</td>
      <td></td>
      <td></td>
      <td></td>
      <td><a href=""README.md#alladvertisementsFromAdmin"">Info</a></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>alladvertisements/{advertisement_id}</td>
      <td>Get advertisement by Id From Admin</td>
      <td></td>
      <td><a href=""README.md#advertisementById"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>PUT</td>
      <td>update/{advertisement_id}</td>
      <td>Update advertisement by Id</td>
      <td></td>
      <td></td>
      <td><a href=""README.md#update"">Info</a></td>
      <td></td>
  </tr>
  <tr>
      <td>DELETE</td>
      <td>delete/{advertisement_id} </td>
      <td>Delete advertisement by Id</td>
      <td></td>
      <td><a href=""README.md#delete"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>advertisement/{advertisement_id}/approve</td>
      <td>Approve advertisement By Id</td>
      <td></td>
      <td><a href=""README.md#approve"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>advertisement/{advertisement_id}/reject</td>
      <td>Reject advertisement By Id</td>
      <td></td>
      <td><a href=""README.md#reject"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>alladvertisements</td>
      <td>Get all advertisements From User</td>
      <td></td>
      <td></td>
      <td></td>
      <td><a href=""README.md#alladvertisementsFromUser"">Info</a></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>alladvertisements</td>
      <td>alladvertisements/{advertisement_id}</td>
      <td></td>
      <td></td>
      <td></td>
      <td><a href=""README.md#advertisementByIdFromUser"">Info</a></td>
  </tr>
</table>


### Used Dependencies
* Core
  * Spring
    * Spring Boot
    * Spring Security
    * Spring Web
      * RestTemplate
    * Spring Data
      * Spring Data JPA
    * Spring Cloud
      * Spring Cloud Gateway Server
      * Spring Cloud Config Server
      * Spring Cloud Config Client
  * Netflix
    * Eureka Server
    * Eureka Client
* Database
  * Mysql
* Message Broker
  * RabbitMQ
* Security
  * Keycloak Server
  * Keycloak OAuth2
  * Keycloak REST API

## Valid Request Body

##### <a id=""signup"">Sign Up for User and Admin
```
    http://localhost:8600/api/v1/users/signup

    {
        ""username"" : ""springbootmicroserviceuser"",
        ""password"" : ""user123456"",
        ""name"" : ""Micro User"",
        ""surname"" : ""User Surname"",
        ""phoneNumber"" : ""123456789"",
        ""email"" : ""springbootmicroserviceuser@user.com"",
        ""role"" : ""ROLE_USER""
    }

    http://localhost:8600/api/v1/users/signup

    {
        ""username"" : ""springbootmicroserviceadmin"",
        ""password"" : ""admin123456"",
        ""name"" : ""Micro Admin"",
        ""surname"" : ""Admin Surname"",
        ""phoneNumber"" : ""123456789"",
        ""email"" : ""springbootmicroserviceadmin@admin.com"",
        ""role"" : ""ROLE_ADMIN""
    }
```

##### <a id=""login"">Login
```
    http://localhost:8600/api/v1/users/login
    Bearer Token : Access Token of User from Keycloak
    {
        ""username"" : ""springbootmicroserviceuser"",
        ""password"" : ""user123456""
    }

    http://localhost:8600/api/v1/users/login
    Bearer Token : Access Token of Admin from Keycloak
    {
        ""username"" : ""springbootmicroserviceadmin"",
        ""password"" : ""admin123456""
    }
```

## Valid Request Params

##### <a id=""advertisementById"">Get advertisement by Id From Admin
```
    http://localhost:8600/api/v1/management/admin_role/alladvertisements/{advertisement_id} 
    Bearer Token : Access Token of Admin from Keycloak
```

##### <a id=""delete"">Delete advertisement by Id 
```
    http://localhost:8600/api/v1/management/admin_role/delete/{advertisement_id} 
    Bearer Token : Access Token of Admin from Keycloak
```

##### <a id=""approve"">Approve advertisement By Id
```
    http://localhost:8600/api/v1/management/admin_role/advertisement/{advertisement_id}/approve
    Bearer Token : Access Token of Admin from Keycloak
```

##### <a id=""reject"">Reject advertisement By Id
```
    http://localhost:8600/api/v1/management/admin_role/advertisement/{advertisement_id}/reject
    Bearer Token : Access Token of Admin from Keycloak
```

##### <a id=""advertisementByIdFromUser"">Get advertisement by Id From User
```
    http://localhost:8600/api/v1/management/user_role/alladvertisements/{advertisement_id} 
    Bearer Token : Access Token of Admin from Keycloak
```

## Valid Request Params and Body

##### <a id=""create"">Create Advertisement for User
```
    http://localhost:8600/api/v1/management/admin_role/create/{user_id} 
    Bearer Token : Access Token from Keycloak
    {
        ""title"" : ""Advertisement 1 for User 1"",
        ""price"" : 200
    }
```

##### <a id=""update"">Create Route by City Id and Destination City Id
```
    http://localhost:8600/api/v1/management/admin_role/update/{advertisement_id}
    Bearer Token : Access Token from Keycloak 
    {
        ""title"" : ""Advertisement 1 for User 1 Updated"",
        ""price"" : 300
    }
```

## No Request or Params

##### <a id=""info""> Get User's Role Information (ROLE_USER or ROLE_ADMIN)
```
    http://localhost:8600/api/v1/users/info
    Bearer Token : Access Token of Admin or User from Keycloak 
```

##### <a id=""alladvertisementsFromAdmin""> Get all advertisements From Admin
```
    http://localhost:8600/api/v1/management/admin_role/alladvertisements
    Bearer Token : Access Token of Admin from Keycloak 
```

##### <a id=""advertisementByIdFromUser""> Get all advertisements From User
```
    http://localhost:8600/api/v1/management/user_role/alladvertisements
    Bearer Token : Access Token of User from Keycloak 
```

### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/keycloak_1.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/keycloak_2.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/keycloak_3.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/keycloak_4.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/keycloak_5.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/keycloak_6.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/keycloak_7.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/rabbitmq_1.PNG"">
    <p> Figure 9 </p>
    <img src =""screenshots/rabbitmq_2.PNG"">
    <p> Figure 10 </p>
    <img src =""screenshots/rabbitmq_3.PNG"">
    <p> Figure 11 </p>
    <img src =""screenshots/rabbitmq_4.PNG"">
</details>   "
kbastani/order-delivery-microservice-example,master,219,59,2021-03-01T17:31:26Z,2936,0,"This repository contains a functional example of an order delivery service similar to UberEats, DoorDash, and Instacart.",,"# Order Delivery Microservice Example

In an event-driven microservices architecture, the concept of a domain event is central to the behavior of each service. Popular practices such as _CQRS_ (Command Query Responsibility Segregation) in combination with _Event Sourcing_ are becoming more common in applications as microservice architectures continue to rise in popularity.

This reference architecture and sample project demonstrates an event-driven microservice architecture that use Spring Boot and Spring Cloud.

Demonstrated concepts:

- Event Sourcing
- Event Stream Processing
- Change Data Capture (CDC)
- Change Data Analytics
- Hypermedia Event Logs
- Real-time Analytics Dashboards

***

![Driver Delivery Tracking with Kepler.gl](https://i.imgur.com/o0npUqx.gif)

## Use cases

This application is a work in progress. The full list of initial requirements are listed below. This application is intended to show a modern microservice architecture that requires real-time analytics and change data capture.

### Order Service

API usage information for the `order-web` service can be found [here](order/README.md). 

- Includes an order web service that tracks new order deliveries.
- Includes a load simulator that realistically simulates a fleet of drivers delivering restaurant orders to customers.
- Uses a list of real Starbucks restaurants to simulate order life cycles across all locations in the United States.
- Generates fake delivery locations within 30 miles (ca. 48 km) of each Starbucks.
- Generates realistic delivery scenarios and simulates supply/demand based on pre-seeded variables for restaurant locations.
- Generates semi-realistic geospatial updates that tracks the location of an order as it makes its way to a customer’s delivery location.
- Simulates driver availability based on location and distance from a restaurant location.

### Dashboards

- Real-time geospatial dashboard of current deliveries
  - Show current deliveries by restaurant id
  - Show current deliveries by restaurant city
  
## System architecture

![Order Delivery Microservice Example Architecture](https://imgur.com/BgsNVsC.png)

## Build and run

JDK 16+ is required to build all the project artifacts for this example. Use the following terminal commands to build and launch a docker compose recipe for this example.

```bash
$ mvn clean verify
```

After you have succesfully built the project and docker containers, you can now run the example on a single machine in one of two modes.

The two recipes below for running this example on a single machine have very different system resource requirements. For most developers, it's recommended that you use the **light mode** recipe to get up and running without any performance issues. 

Before running either of the modes, make sure that you create the following Docker network using the following terminal command.

```bash
$ docker network create PinotNetwork
```

### Light mode

```bash
$ docker-compose -f docker-compose-light.yml up -d
$ docker-compose -f docker-compose-light.yml logs -f --tail 100 load-simulator
```
The `docker-compose-light.yml` is configured to use less containers and compute resources, but does not come with a Superset deployment that visualizes the CDC event data for order deliveries. To visualize the event data, you can use http://kepler.gl by exporting CSV datasets from queries executed in the Apache Pinot query console.

#### Usage

The current log output from your terminal should be targeted on the `load-simulator` application. By default, you will see a list of restaurants that are configured to start fulfilling order delivery requests. The load simulator is a high-throughput realistic state machine and conductor for driving the state of a restaurant, drivers, and order deliveries to a customer's location. Documentation on the load simulator and how it works will be made available in the future.

At the point where you begin to see a flurry of log output from the `load-simulator` that tracks the state of orders and their state change events, you'll know that your cluster is fully up and running. Before we can see any of the event data being produced by the `order-delivery-service` we need to configure a Debezium connector to start sending event table updates to an Apache Kafka topic. The following shell script will fully bootstrap your cluster to enable CDC outbox messages from MySQL to Kafka, as well as configure Apache Pinot to start consuming and ingesting those events for running real-time analytical queries.

```bash
$ sh ./bootstrap-light.sh
```

After this script finishes its tasks, you will now be able to use Apache Pinot to query the real-time stream of order delivery events that are generated from MySQL. A new browser window should be opened and navigated to http://localhost:9000.

To start querying data, navigate to the query console and click the `orders` table to execute your first query. If everythiing worked correctly, you should be seeing at least ten rows from the generated SQL query. Should you run into any issues, please create an issue here to get assistance.

#### Kepler.gl Visualizations

The SQL query below can be used to create a http://kepler.gl geospatial visualization using CSV export directly from the Pinot query console UI.

```sql
SELECT orderId as id, lat as point_latitude_2, lon as point_longitude_2, restaurantLat as point_latitude_1, restaurantLon as point_longitude_1, lastModified as start_time, status, restaurantId, accountId
FROM orders
WHERE ST_DISTANCE(location_st_point, ST_Point(-122.44469, 37.75680, 1)) < 6500
LIMIT 100000
option(skipUpsert=true)
```

Notice that in this SQL query I've disabled upserts using `skipUpsert=true`. This means that I want to see the full log of `order` events for each `orderId`. If I were to remove this option or set it to `false`, then I would only get back the most recent state of the `order` object with the primary key `orderId`. This is a very useful feature, as there are many types of analytical queries where we only want to see the current state of a single aggregate. For the purposes of a good geospatial visualization, we'll want to capture all of the geolocation updates as a driver navigates from a restaurant to a delivery location.

You can play around with this query to generate different result sets. In the `WHERE` clause, I've used a Pinot UDF that only fetches order delivery data that is within a 6.5km radius of the specified GPS coordinate. _The coordinate I've provided is located at the center of San Francisco._

### Heavy mode

Running the example in normal mode requires at least 16GB of system memory and it's recommended that your development machine have at least 32GB of memory and at least 12 CPU cores. Please use the light mode recipe above to run the example if your system doesn't meet these resource requirements. If you have previously started the **light mode** recipe, please make sure you destroy your cluster before proceeding.

```bash
$ docker-compose -f docker-compose-light.yml down
$ docker volume create --name=db_data
$ docker-compose -f docker-compose.yml up -d
$ docker-compose -f docker-compose.yml logs -f --tail 100 load-simulator
```

#### Usage

After building and launching the docker compose recipe, you'll be able to launch a real-time dashboard of a simulated order delivery scenario using Superset.

```bash
$ open http://localhost:8088
```

Sign-in to the superset web interface using the credentials *admin/admin*. Navigate to the order delivery dashboard. To see order delivery data after first launching the simulation, you should remove the default filter for order status by removing it. This will show you all the orders with their status in real-time as they change. Also, you can set the refresh interval on the dashboard to *10s*, which is done through a configuration button at the top right of the dashboard page.

## Change Data Capture

This section provides you with a collection of useful commands for interacting and exploring the CDC features of this example application that are implemented with Debezium. 

### Useful commands

Getting a shell in MySQL:

```
$ docker run --tty --rm -i \
    --network PinotNetwork \
    debezium/tooling:1.1 \
    bash -c 'mycli mysql://mysqluser@mysql:3306/orderweb --password mysqlpw'
```

Listing all topics in Kafka:

```
$ docker-compose exec kafka /kafka/bin/kafka-topics.sh --zookeeper zookeeper:2181 --list
```

Reading contents of the ""order"" topic:

```
$ docker run --tty --rm \
    --network PinotNetwork \
    debezium/tooling:1.1 \
    kafkacat -b kafka:9092 -C -o beginning -q \
    -t debezium.Order
```

Registering the Debezium MySQL connector (this is configured in the `bootstrap.sh` script):

Create a connector for the `order_events` table.

```
$ curl -i -X PUT -H ""Accept:application/json"" -H  ""Content-Type:application/json"" \
    http://localhost:8083/connectors/order/config -d @debezium-mysql-connector-order-outbox.json
```

Getting status of ""order"" connector:

```
$ curl -i -X GET -H ""Accept:application/json"" -H  ""Content-Type:application/json"" \   
    http://localhost:8083/connectors/order/status 
```

Create a connector for the `driver_events` table:

```
$ curl -i -X PUT -H ""Accept:application/json"" -H  ""Content-Type:application/json"" \
    http://localhost:8083/connectors/driver/config -d @debezium-mysql-connector-driver-outbox.json
```

Getting status of ""driver"" connector:

```
$ curl -i -X GET -H ""Accept:application/json"" -H  ""Content-Type:application/json"" \
    http://localhost:8083/connectors/driver/status 
```

It's possible that the MySQL database may have too many active connections for the Debezium connectors to properly start. If this is the case, simply restart the Debezium Connect container.

```
# docker-compose exec mysql bash -c 'mysql -u root -p$MYSQL_ROOT_PASSWORD orderweb -e ""SET GLOBAL max_connections = 10000;""'
$ docker-compose -f docker-compose-light.yml restart connect
```

When the container is started and ready, recreate the `order` and driver` connectors using the `curl` commands above.

## License

This project is an open source product licensed under Apache License v2.
"
Cadiboo/Example-Mod,1.15.2,193,38,2018-05-14T06:44:10Z,724,4,An example mod created to try and get new modders to use good code practices,example-code minecraft-forge-mod,"# [Example Mod](https://github.com/Cadiboo/Example-Mod) 
### An example mod created by [Cadiboo](https://github.com/Cadiboo) to try and get new modders to use good code practices
##### View the tuorials for this at [https://cadiboo.github.io/tutorials/](https://cadiboo.github.io/tutorials/)
This contains the basic setup for a normal mod, and the included files use good code practices.
### All credits for Forge, FML etc go to their respective owners.
Any code written by me is free for any use at all. Some credit would be nice though :)
"
binblee/dubbo-docker,master,47,56,2016-09-20T08:35:24Z,465,0,"Example of running Dubbo in Docker, packaged as a springboot application, running on Kubernetes. ",,"# Dubbo in Docker Example

Dubbo running in Docker, packaged as a springboot application.

## Services

This demo consistes three services:

- a zookeper instance
- a service producer
- a service consumer

The service producer exposes a ```Greeting``` service through RPC,
service consumer access the producer.

## Zookeeper

Run a docker image.

## Service Producer

Code in [service-producer](service-producer). API defined in [service-api](service-api).

Build docker image:

```
cd service-producer
mvn package
docker build -t producer .
```

## Service Consumer

Code in [service-consumer](service-consumer).

Build docker image:

```
cd service-consumer
mvn package
docker build -t consumer .
```

## Run

Use docker-compose command to run it.

```
cd docker
docker-compose up -d
```

Verify that all works:
```
$curl http://localhost:8899/
Greetings from Dubbo Docker
```

## Run it on Alibaba Cloud

Use [docker/docker-compose-acs.yml](docker/docker-compose-acs.yml) to deploy this application to
Aliyun Container Service (Alibaba Cloud) swarm cluster.

2017.11.30 Update:
Add compose v3 sample yml file: [docker/docker-compose-v3.yml](docker/docker-compose-v3.yml)



### Deploy the application to Kubernetes

2018.8.17 Update:

You can user helm to install this sample in a Kubernetes cluster. 

```
$ cd docker
$ helm install -n dubbo-sample dubbo-sample
```



Check helm status

```
$ helm list
NAME          REVISION	UPDATED                 	STATUS  	CHART                  	NAMESPACE
dubbo-sample  1       	Fri Aug 17 07:27:00 2018	DEPLOYED	dubbo-sample-0.0.1     	default
```



Check kubernetes and service status:

```
$ kubectl get po,svc
NAME                                              READY     STATUS    RESTARTS   AGE
pod/consumer-749bf8484d-js6wf                     1/1       Running   0          7m
pod/producer-b4f76b6c7-b8jhg                      1/1       Running   0          7m
pod/zookeeper-8455f4fdc9-ht9ms                    1/1       Running   0          7m

NAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/consumer                  ClusterIP   172.19.10.188   <none>        8899/TCP   7m
service/kubernetes                ClusterIP   172.19.0.1      <none>        443/TCP    45d
service/zookeeper                 ClusterIP   172.19.10.253   <none>        2181/TCP   7m
```



Expose consumer a public IP, or add ingress to it, Visit consumer via browser, you will see the greetings.

```
Greetings from Dubbo Docker
```



This sample tested on Aliyun Container Service for Kubernetes."
mechero/completable-future-example,master,34,21,2018-02-18T15:11:14Z,102,0,Example project comparing Java's CompletableFuture and Future implementations,completablefuture future java thepracticaldeveloper,"# CompletableFuture, Future and Streams

This project uses a sample use case to compare Java's `CompletableFuture` with plain `Future` and other approaches like plain Java and the Stream API.

There is a story behind this code to make it more fun and, at the same time, to give a goal to the sample code so it's easier to compare. Welcome to the Java Bank Robbery with CompletableFutures, Futures and Streams.

![The Java Bank Robbery](img/guide-to-completable-future.png)

## Blog

The comparison between these approaches, and a good introduction to `CompletableFuture` is available at [The Practical Developer Site](https://thepracticaldeveloper.com/?p=1027). I recommend you to read that guide to follow the codebase.

## Code

The code is split into three main parts:

* The main application class `App`, which runs the different code alternatives and shows the result.
* The `objects` used to represent this story: `Actions`, `Loot` and `Thief`.
* The alternatives used to execute the story:
  * `SingleThreadOpenSafeLock` contains two approaches, both single-threaded: plain, imperative Java and Stream API based.
  * `FutureOpenSafeLock` implements the plan using Java Futures, also in imperative-ish way.
  * `CompletableFutureOpenSafeLock` uses a few important methods of the `CompletableFuture` API to demonstrate how powerful it is to solve composed, multi-threaded problems.

Remember that the conclusions of the comparison are also included in the guide so, [check it out now!](https://thepracticaldeveloper.com/?p=1027)

"
jpatanooga/Caduceus,master,31,34,2011-01-05T20:10:52Z,12916,1,Set of example algorithm implementations focused on statistics and machine learning,,
birchsport/titanic,master,25,36,2013-04-29T15:00:31Z,20364,0,Example code for solving the Titanic prediction problem found on Kaggle.,,"# titanic #

Example code for solving the Titanic prediction problem (https://www.kaggle.com/c/titanic-gettingStarted) found on Kaggle.  This example uses the Weka Data Mining Libraries to perform our classifications and predictions. Note, we are using Weka version 3.6.9.

## Data Cleanup/Initialization ##

Before we begin, we have to clean up the data files provided by Kaggle (these cleanup steps have already been performed on the committed files).  The first step is to remove the nested '""""' (quotation marks) from the files.  This was simply a straight search and replace operation in my editor.

The next step is to convert the CSV formatted files into the ARFF format.  The ARFF format provides more detailed information about the type of data in the CSV files.  To perform this conversion, you can use the CSVLoader from the Weka libraries.

```
java -cp lib/weka.jar weka.core.converters.CSVLoader test.csv > test.arff
java -cp lib/weka.jar weka.core.converters.CSVLoader train.csv > train.arff
```

Once we have created the ARFF files, we need to clean them up a little bit.  First, we identify any 'string' column to be of type string, and not nominal.  Then we ensure that nominal values are in the same order for both files (VERY IMPORTANT!).  Here is what the header section of the ARFF file should look like:

```
@attribute survived {0,1}
@attribute pclass numeric
@attribute name string
@attribute sex {male,female}
@attribute age numeric
@attribute sibsp numeric
@attribute parch numeric
@attribute ticket string
@attribute fare numeric
@attribute cabin string
@attribute embarked {Q,S,C}
```

## Training, Predicting, and Verifying the data ##

Now that we have cleaned up our data, we are ready to run the code.  I have included the Eclipse project files to make it easy for anyone to import this project into Eclipse and go.  I have also included an Ant build file to compile and run everything as well.  If you don't have either of those options, you are on your own.

### Training ###

To train the classifier, execute the 'titanic.weka.Train' class or run 'ant train' in a terminal.  This will load the training data, create and train a Classifier, and write the Classifier to disk.

### Predicting ###

To create a prediction, execute the 'titanic.weka.Predict' class or run 'ant predict'.  This will load the test data, read the trained Classifier from disk, and produce a 'predict.csv'.  This CSV file is in a suitable format to submit to Kaggle.

### Verifying ###

To verify our predictions, execute the 'titanic.weka.Verify' class or run 'ant verify'.  This will load our prediction results, read the trained Classifier from disk, then evaluate the classification performance.  You will see output similar to this:

```
Correctly Classified Instances         418              100      %
Incorrectly Classified Instances         0                0      %
Kappa statistic                          1     
Mean absolute error                      0.1409
Root mean squared error                  0.1986
Relative absolute error                 30.3515 %
Root relative squared error             41.2246 %
Total Number of Instances              418     
```
"
stevenalexander/docker-authentication-authorisation,master,46,18,2015-05-06T15:42:43Z,495,0,Example microservice authentication and authorisation solution using Docker containers,,"# Docker authentication and authorisation images

This is sample implementation of the microservice authentication and authorisation pattern I described in a previous
blog posts ([here](https://stevenwilliamalexander.wordpress.com/2014/04/24/microservice-authentication-and-authorisation/)
for pattern, [here](https://stevenwilliamalexander.wordpress.com/2015/03/12/microservice-authentication-and-authentication-scaling/)
for how it could scale). It uses [Nginx](http://nginx.org/) with [Lua](http://wiki.nginx.org/HttpLuaModule) and
[Dropwizard](http://www.dropwizard.io/) for the microservices, provisioned into containers using [Docker](https://www.docker.com/).

Requires:
* [Docker](https://www.docker.com/)
* [Boot2Docker](http://boot2docker.io/)
* [Docker-compose](http://docs.docker.com/compose/)
* JDK (to compile java file locally)
* [Gradle](https://gradle.org/) (for build automation)

I created this project to test using Docker as part of the development process to reduce the separation between
developers and operations. The idea being that developers create and maintain both the code and the containers that
their code will run in, including scripts/tools used to configure and setup those containers. Hopefully this will reduce
the knowledge gap that forms a barrier between developers and operations in projects, causing problems when developers
push code that breaks in production (""throwing over the wall"" at operations).

I'm aware that Docker and containers in general are not a cure-all for 'devOps', they are only an abstraction that
tries to make your applications run in an environment as similar to production as possible and make deployment/setup
more consistent. Containers running locally or on a test environment are not the same as the solution running on production. There are
concerns about performance/networking/configuration/security which developers need to understand in order to produce
truly production ready code that de-risks regular releases. Creating a 'devOps' culture to decrease the time necessary
to release and increase quantity requires a change in process and thinking, not just technology.

## Running the containers

```
# Build microservices and copy their files into volume directories
gradle buildJar

# Run containers with dev architecture
docker-compose -f dev-docker-compose.yml up

# curl your boot2docker VM IP on port 8080 to get the login page, logs are stored in docker/volume-logs
```

## Details

The solution is composed of microservices, using [nginx](http://nginx.org/) as a reverse proxy and
[Lua](http://wiki.nginx.org/HttpLuaModule) scripts to control authentication/sessions. Uses [Docker](https://www.docker.com/)
and [Docker Compose](https://docs.docker.com/compose/) to build container images which are deployed onto a Docker host
VM.

### Microservices

The solution is split into small web services focused on a specific functional area so they can be developed and
maintained individually. Each one has it's own data store and can be deployed or updated without affecting the others.

- [Authentication](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/microservices/authentication) - used to authenticate users against a set of stored
credentials
- [Authorisation](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/microservices/authorisation) - used to check authenticated users permissions to perform
actions
- [Frontend](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/microservices/frontend) - HTML UI wrapper for the login/person functionality
- [Person](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/microservices/person) - used to retrieve and update person details, intended as a simple example
of an entity focused microservice which links into the Authorisation microservice for permissions
- [Session](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/microservices/session) - used to create and validate accessTokens for authenticated users

There is an [Api](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/microservices/api) library containing objects used by multiple services (for real solution
should be broken up into API specific versioned libraries for use in various clients, e.g. personApi, authorisationApi).

### Nginx reverse proxy

Nginx is used as the reverse proxy to access the Frontend microservice and it also wires together the authentication and
session management using Lua scripts. To provision the Nginx container I created a DockerFile which installs nginx with
[OpenResty](http://openresty.org/)

- [Dockerfile](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/docker/image-nginx-lua/Dockerfile) - defines the Nginx container image, with modules for Lua
scripting
- [nginx.conf](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/docker/volume-nginx-conf.d/nginx.conf) - main config for Nginx, defines the endpoints
available and calls the Lua scripts for access and authentication
- [access.lua](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/docker/volume-nginx-conf.d/access.lua) - run anytime a request is received, defines a list of
endpoints which do not require authentication and for other endpoints it checks for accessToken cookie in the request
header then validates it against the Session microservice
- [authenticate.lua](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/docker/volume-nginx-conf.d/authenticate.lua) - run when a user posts to /login, calls
the Authentication microservice to check the credentials, then calls the Session microservice to create an accessToken
for the new authenticated session and finally returns a 302 response with the accessToken in a cookie for future
authenticated requests.
- [logout.lua](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/docker/volume-nginx-conf.d/logout.lua) - run when a user calls /logout, calls the Session
microservice to delete the users accessToken

#### Authentication and authorisation sequence diagram

![Authentication and authorisation sequence diagram](https://raw.githubusercontent.com/stevenalexander/docker-authentication-authorisation/master/images/microservice-authentication-and-authorisation-sequence.png ""sequence diagram"")

### Docker containers and volumes

The interesting thing about using Docker with microservices is that you can define a container image per microservice
then host those containers in various arrangements of Docker host machines to make your architecture. The containers can
be created/destroyed easily, give guarantees of isolation from other containers and only expose what you define
(ports/folders etc.). This makes them easily portable between hosts compared to something like a puppet module that
needs more care and configuration to ensure it can operate on the puppet host.

To develop and test the solution locally I used a development architecture defined in a
[Docker Compose](http://docs.docker.com/compose/) yaml file ([here](https://github.com/stevenalexander/docker-authentication-authorisation/tree/master/dev-docker-compose.yml)). This created a
number of containers with volumes and exposed ports then links them together appropriately.

Below shows architectures which can be built using the containers.

#### Development architecture

![Development architecture diagram](https://raw.githubusercontent.com/stevenalexander/docker-authentication-authorisation/master/images/microservice-authentication-and-authorisation-simple-architecture.jpg ""Development architecture diagram"")

This is a small scale architecture intended for local development. Developers can spin this up quickly and work on the
full application stack. It uses a single Docker host (the boot2docker VM) with single containers for each microservice.
This means that if any of the containers or services fail there is no redundancy.

#### Small scaled architecture

![Small scaled architecture diagram](https://raw.githubusercontent.com/stevenalexander/docker-authentication-authorisation/master/images/microservice-authentication-and-authorisation-small-scaled-architecture.jpg ""Small scaled architecture diagram"")

This is a larger scale architecture, using HAProxy to load balance and introduce redundancy. This architecture allows
scaling the business microservices to handle increasing/decreasing load.

#### Large scaling architecture

![Large scaling architecture diagram](https://raw.githubusercontent.com/stevenalexander/docker-authentication-authorisation/master/images/microservice-authentication-and-authorisation-large-scaling-architecture.jpg ""Large scaling architecture diagram"")

This is an example production architecture, running on multiple Docker hosts with redundancy for all microservices and
load balancing for the web servers. The number of hosts you have per container can be increased/decreased dynamically
based on the individual load on each service and each container can be updated without downtime by rolling updates.

On a real production architecture you would want to include:

- Healthchecks
- Monitoring (e.g. Dropwizard Metrics pushing to Graphite)
- Dynamic scaling based on load monitoring
- Periodic backups of peristed data
- Security testing

## Conclusions

I found working with Docker extremely easy, the tooling and available images made it simple to create containers to do
what I needed. For development the speed I could create and start containers for the microservices was amazing, 5 secs
to spin up the entire 6 container solution with Docker Compose. Compared to development using individual VMs provisioned
by Puppet and Vagrant this was lightning fast. Accessing the data/logs on the containers was simple also, making debug a
lot easier, and remote debug by opening ports was also possible.

Still have some concerns about how production ready my containers would be and what I would need to do to make them
secure. I did not touch on a lot of the work which would be necessary to create and provision the Docker hosts
themselves, including configuration of the microservices and Nginx containers per host. For a reasonable sized
architecture this would require a tool like Puppet anyway so would not save much effort on the operations side.

I would like a chance to use some sort of containerisation in a real project and see how it works out, in the
development side, operations for deployment in environment and in actual production use. For now I'd definitely
recommend developers to try it out for defining and running their local development environments as an alternative to
complex boxen/vagrant setups.

## Additions

### Google Cloud with Kubernetes

- [Publishing a custom docker image to Google private repository and running in a cluster as a single pod](https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/kubernetes-nginx-lua.md)
- [Running the solution as a single pod](https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/kubernetes-single-pod.md)
- [Persisting data](https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/kubernetes-persistent-disks.md)
"
khmarbaise/jdk9-jlink-jmod-example,master,40,19,2016-10-09T12:06:51Z,106,4,Example for using maven-jmod-plugin / maven-jlink-plugin,java jdk9 jigsaw maven maven-plugin,"Maven JDK9 Jigsaw Example
=========================

Status
------
 * Currently not more than a Proof of Concept 
 * Everything here is speculative!

Overview
--------

 * Example how could jmod/jlink work together in a Maven build 
 (using [`maven-jlink-plugin`](https://github.com/apache/maven-jlink-plugin/)
 and [`maven-jmod-plugin`](https://github.com/apache/maven-jmod-plugin/)
 Maven [plugins](http://maven.apache.org/plugins/)).

"
JoelPM/BidiThrift,master,57,31,2010-05-07T03:39:26Z,146,0,An example of how to use Thrift for bi-directional async RPC,,
redis-developer/redis-ai-resources,main,120,7,2023-02-02T14:58:40Z,972,4,"✨ A curated list of awesome community resources, integrations, and examples of Redis in the AI ecosystem.",ai awesome-list ecosystem feature-store machine-learning redis vector-database vector-search,"<img align=""right"" src=""assets/redis-logo.svg"" style=""width: 130px"">

# Redis: AI Resources

✨ A curated list of awesome community resources including content, integrations, documentation and examples for Redis in the AI ecosystem.

## Table of Contents
- Redis as a [Vector Database](#vector-database)
- Redis as a [Feature Store](#feature-store)

----------

## Vector Database
The following list provides resources, integrations, and examples for **Redis as a Vector Database**.

### Integrations/Tools
- [⭐ RedisVL](https://github.com/RedisVentures/redisvl) - a dedicated Python client lib for Redis as a Vector DB.
- [⭐ LangChain Python](https://github.com/langchain-ai/langchain) - popular Python client lib for building LLM applications.
powered by Redis.
- [⭐ LangChain JS](https://github.com/langchain-ai/langchainjs) - popular JS client lib for building LLM applications.
powered by Redis.
- [⭐ LlamaIndex](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/RedisIndexDemo.html) - LlamaIndex Integration for Redis as a vector Database (formerly GPT-index).
- [Semantic Kernel](https://github.com/microsoft/semantic-kernel/tree/main) - popular lib by MSFT to integrate LLMs with plugins.
- [Metal](https://getmetal.io/) - an all-inclusive LLM development platform for building RAG applications. Built on top of Redis as a vector database and high performance data layer.
- [RelevanceAI](https://relevance.ai/) - Platform to ag, search and analyze unstructured data faster, built on Redis.
- [DocArray](https://docarray.jina.ai/advanced/document-store/redis/) - DocArray Integration of Redis as a VectorDB by Jina AI.
- [ChatGPT Memory](https://github.com/continuum-llms/chatgpt-memory) - contextual and adaptive memory for ChatGPT
- [Haystack Example](https://github.com/artefactory/redis-player-one/blob/main/askyves/redis_document_store.py) - Haystack Integration (example) of Redis as a VectorDB.
- [Mantium AI](https://mantiumai.com/)

### Examples

#### Quickstarts

| Resource | Description |
| --- | --- |
| [⭐ Hands-On Redis Workshops](https://github.com/Redislabs-Solution-Architects/Redis-Workshops) | Hands-on workshops for Redis JSON, Search, and VSS / Gen AI. |
| [⭐ Redis VSS Getting Started - 3 Ways](https://github.com/Redislabs-Solution-Architects/financial-vss) | Getting started VSS demo covering RedisVL, Redis Python, and LangChain |
| [⭐ OpenAI Cookbook Examples](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases) | OpenAI Cookbook examples using Redis as a vector database |
| [Redis VSS - Simple Streamlit Demo](https://github.com/antonum/Redis-VSS-Streamlit) | Streamlit demo of Redis Vector Search |
| [Redis VSS - LabLab AI Quickstart](https://github.com/lablab-ai/Vector-Similarity-Search-with-Redis-Quickstart-Notebook) | Quickstart notebook sponspored by LabLab AI for their AI hackathons. |
| [Redis VSS Documentation Quickstart](https://github.com/RedisVentures/redis-vss-getting-started) | Redis.io VSS Quickstart code. |

#### Question & Answer

| Resource | Description | Stars |
| --- | --- | --- |
| [⭐ ArxivChatGuru](https://github.com/RedisVentures/ArxivChatGuru) | Streamlit demo of QnA over Arxiv documents with Redis & OpenAI | ![redis-openai-qna-streamlit-demo-stars] |
| [⭐ Azure OpenAI Embeddings Q&A](https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna) | OpenAI and Redis as a Q&A service on Azure | ![azure-openai-embeddings-qna-stars] |
| [LLM Document Chat](https://github.com/RedisVentures/LLM-Document-Chat) | Using LlamaIndex and Redis to chat with Documents | ![llm-document-chat-stars] |
| [GCP Vertex AI ""Chat Your PDF""](https://github.com/RedisVentures/gcp-redis-llm-stack/tree/main/examples/chat-your-pdf) | Chat with a PDF using Redis & VertexAI LLMs | |
| [LLMChat](https://github.com/c0sogi/LLMChat) | Full-stack implementation using FastAPI, Redis, OpenAI and Flutter. | ![llmchat-stars] |
| [Example eCommerce Chatbot](https://github.com/RedisVentures/redis-langchain-chatbot) | eCommerce Chatbot with Redis, LangChain, and OpenAI | ![redis-langchain-chatbot-stars] |
| [Food-GPT](https://github.com/DevSamurai/food-gpt) | Food-GPT is a QnA Chat System | ![food-gpt-stars] |
| [Redis vector bot](https://github.com/aetherwu/redis-vector-bot) | Redis vector bot for Ecommerce QnA | ![redis-vector-bot-stars] |
| [Local Model QnA Example](https://github.com/cxfcxf/embeddings) | Local LLMs embeddings with Redis as vector db | ![local-model-qna-example-stars] |

#### NLP & Information Retrieval

| Resource | Description | Stars |
| --- | --- | --- |
| [⭐ ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin) | ChatGPT plugin for retrieving personal documents | ![chatgpt-retrieval-plugin-stars] |
| [⭐ Auto-GPT](https://github.com/Torantulino/Auto-GPT) | Experimental OSS app showcasing GPT-4 with Redis as a vectorized memory store | ![auto-gpt-stars]
| [⭐ arXiv Paper Search](https://github.com/RedisVentures/redis-arXiv-search) | Semantic search over arXiv scholarly papers | ![redis-arxiv-search-stars] |
| [⭐ Motörhead](https://github.com/getmetal/motorhead) | Rust-based IR server for LLMs backed by Redis | ![motorhead-stars] |
| [Financial News Demo](https://github.com/RedisAI/financial-news) | Sentiment analysis and Semantic similarity in Financial News articles | ![financial-news-demo-stars] |
| [Romeo GPT](https://github.com/fmanrique8/romeo-gpt) | AI Document management assistant | ![romeo-gpt-stars] |
| [The Pattern](https://github.com/applied-knowledge-systems/the-pattern) | CORD19 medical NLP pipeline with Redis | ![the-pattern-stars] |
| [GPT Vectors Example](https://github.com/gbaeke/gpt-vectors) | Code associated with the blog post below: ""Storing and querying embeddings with Redis"" | ![gpt-vectors-stars] |
| [Azure OpenAI Redis Deployment Template](https://github.com/RedisVentures/azure-openai-redis-deployment) | Terraform template automates the end-to-end deployment of Azure OpenAI applications using Redis Enterprise as a vector database | ![azure-openai-redis-deployment-stars] |
| [VSS for Finance](https://github.com/redislabs-training/redisfi-vss) | Searching through SEC filings with Redis VSS | ![redisfi-vss-stars] |

#### Recommendation Systems

| Resource | Description | Stars |
| --- | --- | --- |
| [⭐ Redis Merlin RecSys](https://github.com/RedisVentures/Redis-Recsys) | 3 Redis & NVIDIA Merlin Recommendation System Architectures | ![redis-recsys-stars]  |
| [⭐ Visual Product Search](https://github.com/RedisVentures/redis-product-search) | eCommerce product search (with image and text) | ![redis-product-search-stars]  |
| [Product Recommendations with DocArray / Jina](https://github.com/jina-ai/product-recommendation-redis-docarray) |  Content-based product recommendations with Redis and DocArray | ![jina-product-recommendations-stars]  |
| [Amazon Berkeley Product Dataset Demo](https://github.com/RedisAI/vecsim-demo) |  Redis VSS demo on Amazon Berkeley product dataset | ![redis-vecsim-demo-stars]  |

#### Other

| Resource | Description | Stars |
| --- | --- | --- |
| [VectorVerse](https://github.com/abhishek-ch/VectorVerse) | Vector Database comparison app | ![vectorverse-stars] |
| [Simple Vector Similarity Intro](https://github.com/RedisVentures/simple-vecsim-intro) | Dockerized Jupyter Notebook & Streamlit demo of Redis Vector Search | ![redis-vecsim-intro-stars] |
| [Redis Solution Architects VSS Examples](https://github.com/Redislabs-Solution-Architects/vss-ops) | Examples of VSS in Python | ![vss-ops-stars] |
| [TopVecSim](https://github.com/team-castle/topvecsim/) | Topic Similarity with Redis VSS | ![top-vecsim-stars] |
| [Java Demo](https://github.com/RedisAI/Java-VSS-demo) | Redis VSS demo in Java | ![java-demo-stars] |
| [Redis VSS Go template](https://github.com/dathan/go-vector-embedding) | Redis VSS template in Go | ![redis-vss-go-template-stars] |
| [Redis VSS Demo](https://github.com/bsbodden/roms-vss-celebs) | Redis VSS demo with celebrity faces | ![celeb-faces-stars] |

#### [Redis Vector Search Engineering Lab Submissions](https://github.com/RedisVentures/RedisVentures.github.io/issues/1) - Submissions to the first Redis VSS hackathon.

| Resource | Description | Stars |
| --- | --- | --- |
| [arXiv CoPilot](https://github.com/artefactory/redisventures-hackunamadata) | Chrome extension that finds relevant/similar academic papers while performing research | ![arxiv-copilot-stars] |
| [AskYeves Question & Answer App](https://github.com/artefactory/redis-player-one) | QA & Search Engine modeled after the infamous Yves Saint Laurent | ![askyeves-stars] |
| [Darwinian Paper Explorer App](https://github.com/artefactory/AreYouRedis) | Explore arXiv scholarly papers over time with topic evolution and search | ![darwinian-paper-explorer-stars] |
| [PapersWithCode Browser Extension](https://github.com/ilhamfp/simpa) | Chrome extension for the PapersWithCode site that finds relevant/similar papers | ![paperswithcode-stars] |
| [Document Search + CLI](https://github.com/artefactory/redis-team-THM) | Search engine for documents with a CLI | ![document-search-cli-stars] |


###  RediSearch Clients
| Client | Language | License | Stars |
| --- | --- | --- | --- |
| [Redis-Py](https://github.com/redis/redis-py) | Python | MIT | ![redis-py-stars] |
| [RedisVL](https://github.com/RedisVentures/redisvl) | Python (*Alpha*) | MIT| ![redisvl-stars] |
| [jedis][jedis-url] | Java | MIT |  ![Stars][jedis-stars] |
| [node-redis][node-redis-url] | Node.js | MIT | ![Stars][node-redis-stars] |
| [nredisstack][nredisstack-url] | .NET | MIT |  ![Stars][nredisstack-stars] |
| [redisearch-go][redisearch-go-url] | Go | BSD | [![redisearch-go-stars]][redisearch-go-url] |
| [redisearch-api-rs][redisearch-api-rs-url] | Rust | BSD | [![redisearch-api-rs-stars]][redisearch-api-rs-url] |

For a full list of RediSearch clients, see [RediSearch Clients](https://redis.io/docs/stack/search/clients/).
For a full list of Redis Clients see [Redis Clients](https://redis.io/resources/clients/).

### Content
- [⭐ NVIDIA Developer Blog -- Offline to Online: Feature Storage for Real Time Recommendation Systems with NVIDIA Merlin](https://developer.nvidia.com/blog/offline-to-online-feature-storage-for-real-time-recommendation-systems-with-nvidia-merlin/)
- [Vector Similarity Search: From Basics to Production](https://mlops.community/vector-similarity-search-from-basics-to-production/) - Introductory blog post to VSS and Redis as a VectorDB.
- [AI-Powered Document Search](https://datasciencedojo.com/blog/ai-powered-document-search/) - Blog post covering AI Powered Document Search Use Cases & Architectures.
- [Vector Search on Azure](https://techcommunity.microsoft.com/t5/azure-developer-community-blog/vector-similarity-search-with-azure-cache-for-redis-enterprise/ba-p/3822059) - Using Azure Redis Enterprise for Vector Search
- [Vector Databases and Large Language Models](https://youtu.be/GJDN8u3Y-T4) - Talk given at LLMs in Production Part 1 by Sam Partee.
- [Vector Databases and AI-powered Search Talk](https://www.youtube.com/watch?v=g2bNHLeKlAg) - Video ""Vector Databases and AI-powered Search"" given by Sam Partee at SDSC 2023.
- [Engineering Lab Review](https://mlops.community/redis-vector-search-engineering-lab-review/) - Review of the first Redis VSS Hackathon.
- [Real-Time Product Recommendations](https://jina.ai/news/real-time-product-recommendation-using-redis-and-docarray/) - Content-based recsys design with Redis and DocArray.
- [Redis as a Vector Database](https://vishnudeva.medium.com/redis-as-a-vector-database-rediscloud-2a444c478f3d) - Hackathon review blog post covering Redis as a VectorDB.
- [LabLab AI Redis Tech Page](https://lablab.ai/tech/redis)
- [Storing and querying for embeddings with Redis](https://blog.baeke.info/2023/03/21/storing-and-querying-for-embeddings-with-redis/)
- [Building Intelligent Apps with Redis Vector Similarity Search](https://redis.com/blog/build-intelligent-apps-redis-vector-similarity-search/)
- [Rediscovering Redis for Vector Similarity](https://redis.com/blog/rediscover-redis-for-vector-similarity-search/)
- [VSS Cheat Sheet](https://drive.google.com/file/d/10O52YXE1-x9jUTv2G-iJUHFSbthWAcyy/view?usp=share_link) - Redis Vector Search Cheat Sheet by Datascience Dojo.
- [RedisDays Keynote](https://www.youtube.com/watch?v=EEIBTEpb2LI) - Video ""Infuse Real-Time AI Into Your ""Financial Services"" Application"".
- [RedisDays Trading Signals](https://www.youtube.com/watch?v=_Lrbesg4DhY) - Video ""Using AI to Reveal Trading Signals Buried in Corporate Filings"".
- [LLM Stack Hackathon writeup](https://medium.com/@sonam.gupta1105/equipping-with-llm-stack-mlops-community-hackathon-fd0505762c85) - Building a QnA Slack bot for the MLOps Community Hackathon with OpenAI and Redis

### Benchmarks
- [Vector Database Benchmarks](https://jina.ai/news/benchmark-vector-search-databases-with-one-million-data/) - Jina AI VectorDB benchmarks comparing Redis against others.
- [ANN Benchmarks](https://ann-benchmarks.com) - Standard ANN Benchmarks site. *Only using single Redis OSS instance/client.*

### Documentation
- [Redis Vector Database QuickStart](https://redis.io/docs/get-started/vector-database/)
- [Redis Vector Similarity Docs](https://redis.io/docs/interact/search-and-query/advanced-concepts/vectors/) - Official Redis literature for Vector Similarity Search.
- [Redis-py Search Docs](https://redis.readthedocs.io/en/latest/redismodules.html#redisearch-commands) - Redis-py client library docs for RediSearch.
- [Redis-py General Docs](https://redis.readthedocs.io/en/latest/) - Redis-py client library documentation.
- [Redis Stack](https://redis.io/docs/stack/) - Redis Stack documentation.
- [Redis Clients](https://redis.io/docs/clients/) - Redis client list.



[openai-cookbook-stars]: https://img.shields.io/github/stars/openai/openai-cookbook?style=social
[redis-openai-qna-streamlit-demo-stars]: https://img.shields.io/github/stars/RedisVentures/redis-openai-qna?style=social
[redis-py-stars]: https://img.shields.io/github/stars/redis/redis-py?style=social
[redisvl-stars]: https://img.shields.io/github/stars/RedisVentures/redisvl?style=social
[redis-py-url]: https://github.com/redis/redis-py
[redis-py-stars]: https://img.shields.io/github/stars/redis/redis-py.svg?style=social&amp;label=Star&amp;maxAge=2592000
[jedis-url]: https://github.com/redis/jedis
[jedis-stars]: https://img.shields.io/github/stars/redis/jedis.svg?style=social&amp;label=Star&amp;maxAge=2592000
[nredisstack-url]: https://github.com/redis/nredisstack
[nredisstack-stars]: https://img.shields.io/github/stars/redis/nredisstack.svg?style=social&amp;label=Star&amp;maxAge=2592000
[node-redis-url]: https://github.com/redis/node-redis
[node-redis-stars]: https://img.shields.io/github/stars/redis/node-redis.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redisearch-go-url]: https://github.com/RediSearch/redisearch-go
[redisearch-go-stars]: https://img.shields.io/github/stars/RediSearch/redisearch-go.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redisearch-api-rs-url]: https://github.com/RediSearch/redisearch-api-rs
[redisearch-api-rs-stars]: https://img.shields.io/github/stars/RediSearch/redisearch-api-rs.svg?style=social&amp;label=Star&amp;maxAge=2592000
[java-demo-stars]: https://img.shields.io/github/stars/RedisAI/Java-VSS-demo.svg?style=social&amp;label=Star&amp;maxAge=2592000
[top-vecsim-stars]: https://img.shields.io/github/stars/team-castle/topvecsim.svg?style=social&amp;label=Star&amp;maxAge=2592000
[document-search-cli-stars]: https://img.shields.io/github/stars/artefactory/redis-team-THM.svg?style=social&amp;label=Star&amp;maxAge=2592000
[paperswithcode-stars]: https://img.shields.io/github/stars/ilhamfp/simpa.svg?style=social&amp;label=Star&amp;maxAge=2592000
[darwinian-paper-explorer-stars]: https://img.shields.io/github/stars/artefactory/AreYouRedis.svg?style=social&amp;label=Star&amp;maxAge=2592000
[askyeves-stars]: https://img.shields.io/github/stars/artefactory/redis-player-one.svg?style=social&amp;label=Star&amp;maxAge=2592000
[arxiv-copilot-stars]: https://img.shields.io/github/stars/artefactory/redisventures-hackunamadata.svg?style=social&amp;label=Star&amp;maxAge=2592000
[the-pattern-stars]: https://img.shields.io/github/stars/applied-knowledge-systems/the-pattern.svg?style=social&amp;label=Star&amp;maxAge=2592000
[financial-news-demo-stars]: https://img.shields.io/github/stars/RedisAI/financial-news.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-vecsim-intro-stars]: https://img.shields.io/github/stars/RedisVentures/simple-vecsim-intro.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-vss-streamlit-demo-stars]: https://img.shields.io/github/stars/antonum/Redis-VSS-Streamlit.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-arxiv-search-stars]: https://img.shields.io/github/stars/RedisVentures/redis-arXiv-search.svg?style=social&amp;label=Star&amp;maxAge=2592000
[azure-openai-embeddings-qna-stars]: https://img.shields.io/github/stars/ruoccofabrizio/azure-open-ai-embeddings-qna.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-recsys-stars]: https://img.shields.io/github/stars/redisventures/redis-recsys.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-product-search-stars]: https://img.shields.io/github/stars/redisventures/redis-product-search.svg?style=social&amp;label=Star&amp;maxAge=2592000
[jina-product-recommendations-stars]: https://img.shields.io/github/stars/jina-ai/product-recommendation-redis-docarray.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-vecsim-demo-stars]: https://img.shields.io/github/stars/redisai/vecsim-demo.svg?style=social&amp;label=Star&amp;maxAge=2592000
[chatgpt-retrieval-plugin-stars]: https://img.shields.io/github/stars/openai/chatgpt-retrieval-plugin?style=social
[motorhead-stars]: https://img.shields.io/github/stars/getmetal/motorhead?style=social
[redis-langchain-chatbot-stars]: https://img.shields.io/github/stars/RedisVentures/redis-langchain-chatbot?style=social
[gpt-vectors-stars]: https://img.shields.io/github/stars/gbaeke/gpt-vectors?style=social
[vss-ops-stars]: https://img.shields.io/github/stars/Redislabs-Solution-Architects/vss-ops?style=social
[lablab-vss-quickstart]: https://img.shields.io/github/stars/lablab-ai/Vector-Similarity-Search-with-Redis-Quickstart-Notebook?style=social
[auto-gpt-stars]: https://img.shields.io/github/stars/Torantulino/Auto-GPT?style=social
[romeo-gpt-stars]: https://img.shields.io/github/stars/fmanrique8/romeo-gpt?style=social
[celeb-faces-stars]: https://img.shields.io/github/stars/bsbodden/roms-vss-celebs?style=social
[redis-vector-bot-stars]: https://img.shields.io/github/stars/aetherwu/redis-vector-bot?style=social
[redis-vss-go-template-stars]: https://img.shields.io/github/stars/dathan/go-vector-embedding?style=social
[redisfi-vss-stars]: https://img.shields.io/github/stars/redislabs-training/redisfi-vss?style=social
[llm-document-chat-stars]: https://img.shields.io/github/stars/RedisVentures/llm-document-chat?style=social
[food-gpt-stars]: https://img.shields.io/github/stars/DevSamurai/food-gpt?style=social
[llmchat-stars]: https://img.shields.io/github/stars/c0sogi/llmchat?style=social
[vectorverse-stars]: https://img.shields.io/github/stars/abhishek-ch/vectorverse?style=social
[local-model-qna-example-stars]: https://img.shields.io/github/stars/cxfcxf/embeddings?style=social
[azure-openai-redis-deployment-stars]: https://img.shields.io/github/stars/RedisVentures/azure-openai-redis-deployment?style=social

____

## Feature Store
The following list provides resources, integrations, and examples for **Redis as a Feature Store**.

### Examples

#### Recommendation Systems

| Resource | Description | Stars |
| --- | --- | --- |
| [⭐ Redis Merlin RecSys](https://github.com/RedisVentures/Redis-Recsys) | Redis & NVIDIA Merlin Recommendation System architectures | ![redis-recsys-stars] |
| [Market-basket-analysis](https://github.com/RedisLabs-Field-Engineering/demo-market-basket-analysis) | An exmaple of predicting shopping baskets on passed purchases | ![market-basket-analysis-stars] |


#### Life Sciences / Healthcare

| Resource | Description | Stars |
| --- | --- | --- |
| [⭐ Redis Vaccine Forecaster](https://github.com/RedisVentures/redis-feast-gcp) | End-to-end ML system to predict vaccine demand deployed in GCP with Redis, Feast, Triton, and Vertex AI. | ![redis-vaccine-forecaster-stars] |

#### Image/Video

| Resource | Description | Stars |
| --- | --- | --- |
| [Animal Recognition Demo](https://github.com/RedisGears/AnimalRecognitionDemo) | An example of using Redis Streams, RedisGears and RedisAI for Realtime Video Analytics (i.e. filtering cats) | ![animal-recog-stars] |
| [Realtime Video Analytics](https://github.com/RedisGears/EdgeRealtimeVideoAnalytics) | An example of using Redis Streams, RedisGears, RedisAI and RedisTimeSeries for Realtime Video Analytics (i.e. counting people) | ![realtime-video-analytics-stars] |


#### Finance

| Resource | Description | Stars |
| --- | --- | --- |
| [Redis + Feast + Ray Demo](https://github.com/RedisVentures/redis-feast-ray) | A demo pipeline using Redis as an online feature store with Feast for orchestration and Ray for training and model serving | ![redis-vaccine-forecaster-stars] |
| [⭐ Loan Prediction Example](https://github.com/RedisVentures/loan-prediction-microservice) | Loan prediction example with Redis as the feature store and serving layer. | ![load-prediction-example-stars] |

#### Other

| Resource | Description | Stars |
| --- | --- | --- |
| [Redis SQL](https://github.com/redis-field-engineering/redis-sql-trino) | Indexed SQL queries on Redis data using Trino | ![redis-sql-stars] |
| [Redis GraphQL](https://github.com/redis-field-engineering/redis-graphql) | GraphQL queries on Redis data | ![redis-graphql-stars] |
| [RedisAI Examples](https://github.com/RedisAI/redisai-examples) | A collection of examples using RedisAI | ![redisai-examples-stars] |


### Materialization and Orchestration

| Resource | Description | Stars |
| --- | --- | --- |
| [⭐ Spark-Redis](https://github.com/RedisLabs/spark-redis) | Spark-Redis is a connector that allows you to stream data from Spark to Redis | ![spark-redis-stars] |
| [⭐ Feast](https://github.com/feast-dev/feast) | Feast feature orchestration system framework | ![feast-stars] |
| [Feathr](https://github.com/linkedin/feathr) | Feathr is a feature orchestration framework created by Linkedin | ![feathr-stars] |
| [Redis Kafka](https://github.com/redis-field-engineering/redis-kafka-connect) | Redis Kafka Connect is a connector that allows you to stream data from Kafka to Redis | ![redis-sql-stars] |


### Content
- [What is a Feature Store?](https://www.tecton.ai/blog/what-is-a-feature-store/) - introductory blog post on feature stores
- [Building a Gigascale Feature Store with Redis](https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/) - blog post on DoorDash's feature store architecture
- [Feature Store Comparison](https://mlops.community/learn/feature-store/) - comparison between a few feature store options.
- [Feature Storage with Feast and Redis](https://redis.com/blog/building-feature-stores-with-redis-introduction-to-feast-with-redis/) - blog post outlining basic Redis+Feast usage.

### Benchmarks
- [Feast Feature Serving Benchmarks](https://feast.dev/blog/feast-benchmarks/) - Feast-published benchmarks on Redis vs DynamoDB vs Datastore for feature retrieval.

### Documentation
- [Redis-py General Docs](https://redis.readthedocs.io/en/latest/) - Redis-py client library documentation.
- [RedisJSON](https://github.com/RedisJSON) - RedisJSON Module.
- [RedisAI](https://github.com/RedisAI/RedisAI) - RedisAI Module.
- [RedisTimeSeries](https://github.com/RedisTimeSeries/RedisTimeSeries) - Redis Time Series Module.
- [RedisConnect](https://github.com/redis-field-engineering/redis-connect-dist) - a distributed platform that enables real-time event streaming, transformation, and propagation of changed-data events from heterogeneous data platforms to Redis.
### Integrations
- [FeatureForm](https://www.featureform.com/?gclid=Cj0KCQjw_r6hBhDdARIsAMIDhV_lhReZdfM66Z5gE5yJCtDsSb3WeLhHjtI4AFokk_cjKC54vRDXN7waAq3HEALw_wcB) - open-source Feature Store orchestration framework.
- [Feast](https://docs.feast.dev/reference/online-stores/redis) - open-source Feature Store orchestration framework.
- [Feathr](https://github.com/feathr-ai/feathr) - open-source Feature Store orchestration framework pioneered by LinkedIn.
- [Tecton](https://www.tecton.ai/blog/announcing-support-for-redis/) - fully-managed Feature Store service.


[redis-graphql-stars]: https://img.shields.io/github/stars/redis-field-engineering/redis-graphql.svg?style=social&amp;label=Star&amp;maxAge=2592000
[spark-redis-stars]: https://img.shields.io/github/stars/RedisLabs/spark-redis.svg?style=social&amp;label=Star&amp;maxAge=2592000

[feathr-stars]: https://img.shields.io/github/stars/linkedin/feathr.svg?style=social&amp;label=Star&amp;maxAge=2592000
[feast-stars]: https://img.shields.io/github/stars/feast-dev/feast.svg?style=social&amp;label=Star&amp;maxAge=2592000

[load-prediction-example-stars]: https://img.shields.io/github/stars/RedisVentures/loan-prediction-microservice.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-feast-ray-demo-stars]: https://img.shields.io/github.com/RedisVentures/redis-feast-ray.svg?style=social&amp;label=Star&amp;maxAge=2592000
[redis-vaccine-forecaster-stars]: https://img.shields.io/github/stars/RedisVentures/redis-feast-gcp.svg?style=social&amp;label=Star&amp;maxAge=2592000

[redis-kafka-connect-stars]: https://img.shields.io/github/stars/redis-field-engineering/redis-kafka-connect.svg?style=social&amp;label=Star&amp;maxAge=2592000

[redisai-examples-stars]: https://img.shields.io/github/stars/RedisAI/redisai-examples.svg?style=social&amp;label=Star&amp;maxAge=2592000

[realtime-video-analytics-stars]: https://img.shields.io/github/stars/RedisGears/EdgeRealtimeVideoAnalytics.svg?style=social&amp;label=Star&amp;maxAge=2592000
[animal-recog-stars]: https://img.shields.io/github/stars/RedisGears/AnimalRecognitionDemo.svg?style=social&amp;label=Star&amp;maxAge=2592000

[market-basket-analysis-stars]: https://img.shields.io/github/stars/RedisLabs-Field-Engineering/demo-market-basket-analysis.svg?style=social&amp;label=Star&amp;maxAge=2592000

[redis-sql-stars]: https://img.shields.io/github/stars/redis-field-engineering/redis-sql-trino.svg?style=social&amp;label=Star&amp;maxAge=2592000



----



*Have other contributions? [Checkout our contributing guidelines](contributing.md).*
"
chaostheory/jibenakka,master,30,9,2011-07-27T02:58:20Z,151,0,A basic set of akka helper java classes and examples such as map reduce,,"jibenakka
=============

This is a set of basic Java examples for [akka](http://akka.io/).

## Getting Started

You will need to install [Apache Maven](http://maven.apache.org/). If you're using
Eclipse, it is recommended that you install the [m2e plugin](http://www.eclipse.org/m2e/). 
Once you've properly installed and configured Maven, you can then
use it to easily download all of jibenakka's needed dependencies.

The actual sample code can be found in the `sample` package, while supporting classes 
are located in the adjoining packages. Currently there are the following samples:

Word Count Map Reduce
-----------
This sample app peforms map reduce to count words in files using a combination 
of akka Actors and Futures. It can be found under the `mapreduce` package within
the `sample` package.


Supervisor Hierarchy Fault Tolerance
-----------
This sample app demonstrates creating a hierarchy of Actors. This is currently a 
work in progress. It can be found under the `fault` package within
the `sample` package.



"
thomasdarimont/spring-boot-admin-keycloak-example,master,58,31,2018-05-24T09:46:36Z,168,2,Example for protecting Spring Boot Admin & Spring Boot Actuator endpoints with Keycloak,,
srecon/ignite-book-code-samples,master,91,58,2016-09-17T07:09:29Z,3774,1,"All code samples, scripts and more in-depth examples for the book high performance in-memory computing with Apache Ignite. Please use the repository the-apache-ignite-book"" for Ignite version 2.6 or above.""",bigdata cache gridgain high-performance ignite in-memory nosql,"# High performance in-memory data grid with Apache Ignite

All code samples, scripts and more in-depth examples for the book **High performance in-memory computing with Apache Ignite**.

[![alt text](/highperfomance-mini.jpg ""book cover"")](http://leanpub.com/ignite)
"
vaadin/base-starter-flow-quarkus,v24,37,19,2021-06-10T11:19:03Z,2512,2,A project base/example for using Vaadin with Quarkus,java quarkus vaadin,"# Project Base for Vaadin Flow and Quarkus

This project can be used as a starting point to create your own Vaadin Flow application for Quarkus. It contains all the necessary configuration with some placeholder files to get you started.

Quarkus 3.0+ requires Java 17.

Starter is also available for [gradle](https://github.com/vaadin/base-starter-flow-quarkus/tree/gradle)

## Running the Application

Import the project to the IDE of your choosing as a Maven project. 

Run application using `mvnw` (Windows), or `./mvnw` (Mac & Linux).

Open [http://localhost:8080/](http://localhost:8080/) in browser.

If you want to run your app locally in production mode, call `mvnw package -Pproduction` (Windows), or `./mvnw package -Pproduction` (Mac & Linux)
and then
```
java -jar target/quarkus-app/quarkus-run.jar
```

### Including vaadin-jandex for Pro components
If you are using Pro components such GridPro you need to provide the Jandex index for them as well. 
Although, this can be achieved by adding their names one-by-one in the `application.properties` similar to the following example:
```properties
quarkus.index-dependency.vaadin-grid-pro.group-id=com.vaadin
quarkus.index-dependency.vaadin-grid-pro.artifact-id=vaadin-grid-pro-flow
```
Vaadin recommends using the official Jandex index for the Pro components which is published as part of the platform:
```xml
<dependency>
    <groupId>com.vaadin</groupId>
    <artifactId>vaadin-jandex</artifactId>
</dependency>
```
The above dependency has already added to the `pom.xml` and all you need to do is uncomment it when if needed. 
"
jotorren/microservices-transactions-tcc,master,44,27,2017-05-09T14:06:50Z,552,1,"Example of composite"" transactions managed by an Atomikos TCC rest coordinator""",,"# Microservices and data consistency (I)

As you can read in [Christian Posta's excellent article](http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/), when designing a microservices-based solution **our first choice to solve consistency between bounded contexts will be to communicate boundaries with immutable point in time events** (by means of a messaging queue/listener, a dedicated event store/publish-subscribe topic or a database/replicated log/event processor).

¿But how to deal with situations where, inevitably, we must update data from different contexts in a single transaction either across a single database or multiple databases? A combination of JPA 2.1 unsynchronized persistence contexts, JPA Entity listeners, Kafka and [Atomikos TCC](https://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC) could fit like a glove ;-) 

Let's describe that approach. We will start by introducing all the actors:

- **Domain Services**. Each of the stateless and autonomous pieces that the whole system has been divided into.
- **Composite Services**. Coarse-grained service operations which are composed by many calls to one or more domain services.
- **Command**. Data describing a persistence operation performed by a domain service: ""*an operation on a given entity within certain context*""
- **Composite transaction**. Set of commands that must be grouped and carried out together.
- **Coordinator**. Service to manage composite transactions lifecycle, deciding whether or not changes (commands) must be applied to the corresponding underlying repositories.
- **TCC Service**. *Try*-*Cancel*/*Confirm* protocol implementation. It handles all TCC remote calls verifying no transaction timeout has been exceeded.
- **Distributed, replicated event log**. Distributed store of composite transactions accessible by any service instance (domain, composite or coordinator)

I would like to point out that Domain, Composite, Coordinator and TCC services have no 2PC/XA support and they can be dynamically allocated/destroyed.



Regarding the sequence of actions:

1. A client makes a remote call to a composite service
2. The composite service knows which domain services needs to invoke and passes that information to the coordinator
3. The coordinator creates a composite transaction or, in other words, a persistent topic for each domain service involved in the operation. Every topic will be uniquely identified by a string that can be interpreted as a *partial transaction id* (partial because a topic will store only commands for instances of a single domain service)
4. The composite service calls each domain service using its respective *partial transaction id*
5. A domain service performs persistence operations through a JPA unsynchronized persistence context and publishes appropriate commands to the topic identified by the given *partial transaction id*

![producers](https://cloud.githubusercontent.com/assets/22961359/26069317/baa16904-39a0-11e7-91bd-b2d3bd75cf32.png)



1. If all domain services calls succeed, the composite service signals the coordinator to commit the changes
   - The coordinator calls the confirm operation on the TCC service
   - The TCC service calls the confirm operation on each domain service passing the correct *partial transaction id*
   - Each domain service reads all commands from the given topic, executes them through a JPA unsynchronized persistence context and finally applies the derived changes to the underlying repository.
   - If all commit calls succeed the business operation ends successfully, otherwise the operation ends with an heuristic failure
2. If a domain service call fails, the composite service signals the coordinator to rollback the changes
   - The coordinator calls the cancel operation on the TCC service
   - The TCC service calls the cancel operation on each domain service passing the correct *partial transaction id*
   - The business operation ends with error

![consumers](https://cloud.githubusercontent.com/assets/22961359/26069329/c3b944da-39a0-11e7-8916-a29e4df2e124.png)



## Build

```shell
# clone this repo
# --depth 1 removes all but one .git commit history

git clone --depth 1 https://github.com/jotorren/microservices-transactions-tcc.git my-project

# change directory to your project
cd my-project

# build artifacts
mvn clean install
```



## Run

First of all you must download and install Zookeeper & Kafka servers. Please follow guidelines described in:

- https://zookeeper.apache.org/doc/r3.1.2/zookeeperStarted.html
- https://kafka.apache.org/quickstart

Once both servers are up and running you can start all services:

- Composite service to create source code items and discussion boards + TCC Service

```shell
# inside your project home folder
cd rahub-composite-service
mvn spring-boot:run
# default port 8090
```

- Domain service to create/query pieces of source code


```shell
# inside your project home folder
cd rahub-source-code-service
mvn spring-boot:run
# default port 8091
```

- Domain service to create/query discussion boards about source code items

```shell
# inside your project home folder
cd rahub-forum-service
mvn spring-boot:run
# default port 8092
```



## Available services

- `/api`: http://localhost:8090/api/api-docs?url=/api/swagger.json

![composite65](https://cloud.githubusercontent.com/assets/22961359/26103358/4ccbd47a-3a39-11e7-9eb9-8810d4efe123.png) 



- `/api/coordinator`: http://localhost:8090/api/api-docs?url=/swagger-tcc.json

In the current example TCC service runs on the same JAX-RS container as the composite does, but it will be preferable to deploy it on its own instance.

![tcc-ops65](https://cloud.githubusercontent.com/assets/22961359/26151969/5c16e894-3b05-11e7-9e33-519ea8c3d9a8.png) 



- `/content`: http://localhost:8091/index.html?url=/content/swagger.json


![sourcecode65](https://cloud.githubusercontent.com/assets/22961359/26103359/4cce7978-3a39-11e7-82c3-baa7f9024696.png) 



- `/forum`: http://localhost:8092/index.html?url=/forum/swagger.json


![forum65](https://cloud.githubusercontent.com/assets/22961359/26103360/4cd31258-3a39-11e7-9624-c100d0622a5c.png) 



## Considerations

#### REST implementation

In the example we use Jersey for Domain Services whilst Composite and TCC services rely on CXF. With regard to swagger ui, the former contain required static resources inside `src/main/resources/static` while the latter only depend on a [webjar](http://www.webjars.org/) and have an empty static folder.

#### Repositories

Our sample Domain Services use an embedded H2 file based database. You can check the configuration looking at their respective `src/main/resources/application.properties`. By default, both data models are initialized on startup, but that behavior can be disabled  by uncommenting the following lines:

```properties
#spring.jpa.generate-ddl: false
#spring.jpa.hibernate.ddl-auto: none
```

Additionally, H2 web console is enabled in both cases and can be accessed through the URI `/h2/console`.



## Components

![Core classes](https://cloud.githubusercontent.com/assets/22961359/26158987/ae0acd88-3b1d-11e7-85a1-68ba872a3867.png)

Pink classes are provided by [Atomikos](https://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC) and contain the TCC protocol implementation. Green ones are generic and reusable components to isolate and hide the complexity of composite transactions management. 



## Implementation key aspects

#### 1. Transactional persistence operations: unsynchronized persistence contexts

Persistence operations executed inside a Composite Transaction are delegated to *unsynchronized entity manager*s: you can create, change and delete entities without doing any change to the repository until you force the `EntityManager` to join an existent `LOCAL/JTA` transaction (note the `@Transactional` annotation present in the `commit()` method ).

```java
@Repository
@Scope(""prototype"")
public class CompositeTransactionParticipantDao {

	@PersistenceContext(type = PersistenceContextType.EXTENDED, 
                        synchronization = SynchronizationType.UNSYNCHRONIZED)
	private EntityManager em;

  	@Transactional(readOnly=false)
  	public void commit() {
		em.joinTransaction();
	}
  
	public void save(Object entity) {
		em.persist(entity);
	}

	public <T> T saveOrUpdate(T entity) {
		return em.merge(entity);
	}

	public void remove(Object entity) {
		em.remove(entity);
	}
  
    public <T> T findOne(Class<T> entityClass, Object pk){
    	return getEntityManager().find(entityClass, pk);
    }
}
```

As stated in [Spring ORM documentation](http://docs.spring.io/spring/docs/current/spring-framework-reference/html/orm.html): 

> `PersistenceContextType.EXTENDED` is a completely different affair: This results in a so-called extended EntityManager, which is *not thread-safe* and hence must not be used in a concurrently accessed component such as a Spring-managed singleton bean

This is the reason why we set `prototype` as scope for any `DAO` with an *unsynchronized persistence context* injected into it.

And some final aspects to be aware of:

Any call to the `executeUpdate()` method of a `Query` created through an *unsynchronized* `EntityManager` will fail reporting `javax.persistence.TransactionRequiredException: Executing an update/delete query`. Consequently, bulk update/delete operations are not supported.

On the other hand, it is possible to create/execute a `Query` to look for data but, in that case, only already persisted (committed) entries are searchable. If you want to retrieve entities that have not yet been saved (committed) you must use `EntityManager` `find()` methods.

Keep in mind that any repository constraint will be checked only when the `EntityManager` joins the transaction (that is during the *commit* phase). Therefore it will be preferable to implement as many validations as possible out of the repositories. In doing so, we can detect potential problems in a very early stage, increasing the overall performance and consistency of the system.



#### 2. From persistence operation to Command: JPA entity listeners and callback methods

*Default entity listeners* are listeners that should be applied to all entity classes. Currently, they can only be specified in a mapping XML that can be found in `src/main/resources/META-INF/orm.xml`

*Callback* methods are user defined methods that are attached to entity lifecycle events and are invoked automatically by JPA when these events occur:

- `@PrePersist` - before a new entity is persisted (added to the `EntityManager`).
- `@PostPersist` - after storing a new entity in the database (during *commit* or *flush*).
- `@PostLoad` - after an entity has been retrieved from the database.
- `@PreUpdate` - when an entity is identified as modified by the `EntityManager`.
- `@PostUpdate` - after updating an entity in the database (during *commit* or *flush*).
- `@PreRemove` - when an entity is marked for removal in the `EntityManager`.
- `@PostRemove` - after deleting an entity from the database (during *commit* or *flush*).

(For further details see http://www.objectdb.com/java/jpa/persistence/event)

If we want to find out which entities have been created, updated or removed through an *unsynchronized entity manager*, we only need *@Pre\* callback* methods:  

```java
public class ChangeStateJpaListener {

	@PrePersist
	void onPrePersist(Object o) {
		enlist(o, EntityCommand.Action.INSERT);
	}

	@PreUpdate
	void onPreUpdate(Object o) {
		enlist(o, EntityCommand.Action.UPDATE);
	}

	@PreRemove
	void onPreRemove(Object o) {
		enlist(o, EntityCommand.Action.DELETE);
	}
  
	private void enlist(Object entity, EntityCommand.Action action){
		EntityCommand<Object> command = new EntityCommand<Object>();
		command.setEntity(entity);
		command.setAction(action);
		command.setTimestamp(System.currentTimeMillis());
		// send command to some store/queue
	}
}
```



#### 3. Commands persistence and distribution

At this point we know how persistence operations executed by a service are translated into Commands, but once instantiated we need to save and distribute them to all service instances. This is accomplished by using Kafka persistent topics. Let's have a deeper look at the proposed mechanism:

When a Composite Service asks the Coordinator (`TccRestCoordinator`) to open a new Composite Transaction, the first thing the latter does is to generate an UUID to uniquely identify that transaction. Then it creates as many topics as different Domain Services must be coordinated, assigning them a name that results from concatenating the UUID and an internal sequence number (building the so-called *partial transaction id*). Once all resources have been allocated, it returns to the Composite Service a `CompositeTransaction` object that includes the transaction global UUID and all partial ids. From this moment on, any call dispatched by the Composite Service to a Domain Service will always include the corresponding partial transaction id (as an extra `@PathParam`)

Furthermore, the JPA entity listener responsible for generating Commands (see point #2) requires the name of the topic to use for publishing them (after a proper serialization process has been applied to the Command). How can that standard JPA class obtain a value available inside an `Spring` bean? `ThreadLocal` variables come to the rescue: just before the first call to a `DAO`, the Domain Service adds its partial transaction id to a `ThreadLocal` variable. Because of JPA listeners run in the same thread as the `EntityManager` operation, they have access to any  `ThreadLocal` variable created by the service and can retrieve the partial transaction id from it. Finally, a `org.springframework.kafka.core.KafkaTemplate` instance is used to send the `JSON` representation of the Command to the appropriate topic.



#### 4. From Command to persistence operation: inherited method from `CompositeTransactionParticipantDao`

Because an `EntityCommand` object contains the entity to create/update/delete and the action to apply to it, it's very straightforward to find out which persistence operation must be executed by a given `EntityManager`; this is as simple as adding an special method to the generic `CompositeTransactionParticipantDao` where the`EntityManager` is injected:

```java
public void apply(List<EntityCommand<?>> transactionOperations) {
	if (null == transactionOperations) {
		return;
	}

	for (EntityCommand<?> command : transactionOperations) {
		switch (command.getAction().ordinal()) {
		case 0:
			save(command.getEntity());
			break;
		case 1:
			saveOrUpdate(command.getEntity());
			break;
		case 2:
			remove(command.getEntity());
			break;
		}
	}
}
```



#### 5. Composite Transaction lifecycle

[01] A Composite Service asks the Coordinator  (`TccRestCoordinator`) to open a new Composite Transaction. The call arguments include the maximum amount of time (in milliseconds) to complete the transaction and the URL of each participant (Domain Service) to be used when cancelling/confirming its operations (as specified by the TCC protocol).

```java
CompositeTransaction transaction = tccRestCoordinator.open(transactionTimeout, featureAbcTccUrl, 
		featureXyzTccUrl);
```

[02] The Coordinator generates the Composite Transaction UUID. Then, for each participant it computes the partial transaction id and uses a `CompositeTransactionManager` (instance provided by Spring container) to initialize the transaction persistence/distribution (with the Kafka-based implementation a persistent topic is created for each Domain Service)

[03] The Composite Service starts calling each Domain Service and processes their responses

[04] When a Domain Service receives a call, it extracts the transaction partial id from the URI

```java
public Response txedOperation(@Context UriInfo uriInfo, @PathParam(""txid"") String txid, Feature data)
```

 [05] Defines a `ThreadLocal` variable and sets its value to the transaction partial id

```java
ThreadLocalContext.put(CURRENT_TRANSACTION_KEY, txId);
```

[06] Asks Spring container to return a **NEW** instance of a `DAO` with an *unsynchronized* `EntityManager` injected into it. Makes some calls to `DAO` methods

[07] The `DAO` translates each method call to a set of persistence operations, delegating their execution to its `EntityManager`

[08] For every persistence operation, the JPA container executes the global entity listener (in the same thread as the `EntityManager` operation)

[09] The JPA listener checks if a partial transaction id has been informed by the service and in case of unavailability it does nothing. Otherwise (when a partial id can be positively found) it creates a new `EntityCommand` instance grouping the entity, the type of operation, the partial transaction id and a timestamp. After that, it uses the `CompositeTransactionManager` (instance provided by Spring container) to ""enlist"" the Command.

```java
private void enlist(Object entity, EntityCommand.Action action, String txId){
	
	EntityCommand<Object> command = new EntityCommand<Object>();
	command.setEntity(entity);
	command.setAction(action);
	command.setTransactionId(txId);
	command.setTimestamp(System.currentTimeMillis());
	
	CompositeTransactionManager txManager = 
		SpringContext.getBean(CompositeTransactionManager.class);
	txManager.enlist(txId, command);
}
```

[10] With the Kafka-based implementation of  `CompositeTransactionManager`, the `EntityCommand` object is serialized to a `JSON` string prior to storing it in a topic.

------



So far, we have completed the *Try* part of the *Try*-*Cancel*/*Confirm* protocol. What about the *Cancel*/*Confirm* one? Let's start with *Confirm*

[11] Once the Composite Service ends calling Domain Services, it invokes the `commit()` method on the Coordinator  (`TccRestCoordinator`) 

[12] The coordinator sends a PUT request to the ""confirm URI"" of the TCC Service, adding the Composite Transaction data as the request content

[13] The TCC Service iterates over the transaction participants list and, for each of them, sends a PUT request to their respective ""TCC confirm URI"" (computed during the Composite Transaction creation)

[14] When a Domain Service receives the confirm call, it extracts the transaction partial id from the URI

```java
public void confirm(@PathParam(""txid"") String txid)
```

[15] Uses the  `CompositeTransactionManager` instance provided by Spring container to get all the Commands ""enlisted"" in that  (partial) transaction

[16] Asks the Spring container to return a **NEW** instance of a `DAO` with an *unsynchronized* `EntityManager` injected into it.

[17] Invokes the `apply()` method on the `DAO` to translate Commands to persistence operations. Because of we're applying already persisted commands, we must disable the JPA global entity listener. This can be easily done by ensuring no `ThreadLocal` variable with the partial id has been defined.

[18] Forces the `EntityManager` to join a `LOCAL/JTA` transaction and, thus, all persistence operations are applied to the underlying repository.

[19] If a Domain Service fails to process the confirm call, a 404 response is returned. When the TCC Service receives it, the confirmation process is stopped and a 409 response is sent back to the Coordinator which in turn propagates that value to the Composite Service.

[20] If all confirm calls succeed (all return 204) the TCC Service also responds with a 204 to the Coordinator which in turn propagates that value to the Composite Service.



------

And finally the *Cancel* branch:

[11] If Composite Service detects some error condition, it can abort the Composite Transaction by invoking the `rollback()` method on the Coordinator  (`TccRestCoordinator`) 

[12] In that case, the coordinator sends a PUT request to the ""cancel URI"" of the TCC Service, adding the Composite Transaction data as the request content

[13] The TCC Service iterates over the transaction participants list and, for each of them, sends a DELETE request to their respective ""TCC cancel URI"" (computed during the Composite Transaction creation)

[14] When a Domain Service receives the cancel call, it extracts the transaction partial id from the URI

```java
public void cancel(@PathParam(""txid"") String txid)
```

[15] In the current implementation the Domain Service does nothing. Perhaps a valid action could be to ""close"" the partial transaction (with the Kafka-based implementation of the  `CompositeTransactionManager` that could trigger a topic removal)

[16] If a Domain Service fails to process the cancel call, a 404 response is returned. When the TCC Service receives it, a log trace is written and the cancellation process goes on. After the last call finishes, the TCC Service returns a 204 response to the Coordinator which in turn propagates that value to the Composite Service.

[17] If all cancel calls succeed (all return 204) the TCC Service also responds with a 204 to the Coordinator which in turn propagates that value to the Composite Service."
kbastani/spring-cloud-microservice-example,master,172,132,2015-05-20T02:00:45Z,3306,27,An example project that demonstrates an end-to-end cloud native application using Spring Cloud for building a practical microservices architecture.,,"# Spring Cloud Example Project

An example project that demonstrates an end-to-end cloud-native platform using Spring Cloud for building a practical microservices architecture.

Tutorial available here: [Building Microservices with Spring Cloud and Docker](http://www.kennybastani.com/2015/07/spring-cloud-docker-microservices.html)

Demonstrated concepts:

* Integration testing using Docker
* Polyglot persistence
* Microservice architecture
* Service discovery
* API gateway

## Docker

Each service is built and deployed using Docker. End-to-end integration testing can be done on a developer's machine using Docker compose.

## Polyglot Persistence

One of the core concepts of this example project is how polyglot persistence can be approached in practice. Microservices in the project use their own database, while integrating with the data from other services through REST or a message bus.

* Neo4j (graph)
* MongoDB (document)
* MySQL (relational)

## Movie Recommendations

This example project focuses on movies and recommendations.

### Data Services

![http://i.imgur.com/NXLHvjR.png](http://i.imgur.com/NXLHvjR.png)

### Domain Data

![http://i.imgur.com/VlwSw2q.png](http://i.imgur.com/VlwSw2q.png)

## Microservice architecture

This example project demonstrates how to build a new application using microservices, as opposed to a monolith-first strategy. Since each microservice in the project is a module of a single parent project, developers have the advantage of being able to run and develop with each microservice running on their local machine. Adding a new microservice is easy, as the discovery microservice will automatically discover new services running on the cluster.

## Service discovery

This project contains two discovery services, one on Netflix Eureka, and the other uses Consul from Hashicorp. Having multiple discovery services provides the opportunity to use one (Consul) as a DNS provider for the cluster, and the other (Eureka) as a proxy-based API gateway.

## API gateway

Each microservice will coordinate with Eureka to retrieve API routes for the entire cluster. Using this strategy each microservice in a cluster can be load balanced and exposed through one API gateway. Each service will automatically discover and route API requests to the service that owns the route. This proxying technique is equally helpful when developing user interfaces, as the full API of the platform is available through its own host as a proxy.

# License

This project is an open source product licensed under GPLv3.
"
marcelocf/janusgraph_tutorial,master,77,22,2017-06-12T01:54:09Z,175,3,Tutorial with example code on how to get started with JanusGraph,,"> *WARNING:* this is *old*. Very very old! It shouldn't work and information here is vely very wrong as of 2022. Apologies for that.
> Will leave repo live for now for historic reasons, but yeah; please don't expect this to work anymore.


# JanusGraph tutorial

**NOTE:** it goes without saying that you need a properly configured JDK in your environment.

This is a hands on guide for JanusGraph. It is organized in sections (each folder is an independent project with a section) and it is expected you follow each guide in order.

## Starging Janus Graph

Every code here assumes you are running JanusGraph 0.1.0 locally.

### For the lazy

You should be ashamed. BUT, here is a shortcut:

```bash
./start_janus.sh
```

### For the ones that want to really learn stuff

This is fairly simple; just download janus and tell it to start up.

```bash
$ wget https://github.com/JanusGraph/janusgraph/releases/download/v0.1.0/janusgraph-0.1.0-hadoop2.zip
$ unzip janusgraph-0.1.0-hadoop2.zip 
$ cd janusgraph-0.1.0-hadoop2/
$ ./bin/janusgraph.sh start
```

The last command should output:

```
Forking Cassandra...
Running `nodetool statusthrift`.. OK (returned exit status 0 and printed string ""running"").
Forking Elasticsearch...
Connecting to Elasticsearch (127.0.0.1:9300)... OK (connected to 127.0.0.1:9300).
Forking Gremlin-Server...
Connecting to Gremlin-Server (127.0.0.1:8182)..... OK (connected to 127.0.0.1:8182).
Run gremlin.sh to connect.
```

Meaning you have cassandra and elasticsearch listening on the loopback interface. This is important for the examples to work.

If you need to clean your data:

1. stop janus graph
1. `rm -rf db`
1. start janus graph

It is also recommended that you read:

* [GraphDB - diving into JanusGraph part 1](https://medium.com/finc-engineering/graph-db-diving-into-janusgraph-part-1f-199b807697d2) (3 min read)
* [GraphDB - diving into JanusGraph part 2](https://medium.com/finc-engineering/graph-db-diving-into-janusgraph-part-2-f4b9cbd967ac) (4 min read)


## Why

I wrote this guide after trying to find my way through this technology. I had to learn it because the traditional tools were not enough for the kind of data processing required in the task assigned to me.

JanusGraph has proven to be a solid and reliable solution to our project and I hope this guide is useful for you.

This is by no means a complete guide to JanusGraph. But I believe that following this using the [official documentation](http://docs.janusgraph.org/latest/) as a reference is enough framework for you to really dive into this technology.

## Scope

On this tutorial we will build the backend database of a twitter clone. The sections are divided into:

1. basic schema
1. data loading
1. querying
1. hadoop integration
1. indexing for performance

By the end of this tutorial you should be able to design your own (very simple but functional) database backend using JanusGraph.

There is also a last section included with some recommended experiments for after you are done.

## Code

Every Java code depends on the main schema class. This is a design decision to reuse code and have more consistency in naming. Also, by doing so, we avoid usage of hard coded Strings as much as possible.

To ease your life, there is a simple shell script in each section called `run.sh`. This will build and evoke the example code for you.

### Java

We are using the standard gradle application plugin naming conventions on Java projects; this means that we have the folders:

```
/src/main/
  dist
  resources
  java
```

Inside `dist` you will find the JanusGraph configuration files. Each section has its own files. In `resources` there is the `log4j.properties` file. And `java` contains the implementation.

### Ruby

In our ruby example codes we are relying on:

* [RVM](https://rvm.io/): for ruby version management (if you use someting different, please prepare your env).
* bundler (`gem install bundler`): for dependency management.
* [gremlin driver gem](https://github.com/marcelocf/gremlin_client): a really simple driver in ruby for JanusGraph.

"
evrentan/spring-boot-project-example,main,46,11,2022-01-07T08:42:58Z,145,2,Spring Boot Project Example by Evren Tan,java maven open-source spring-boot,"# A Complete Spring Boot Example Project
A Complete Spring Boot Example Project with Spring Boot 2.6.2, JDK 17 & Maven.

## Table of Contents

1. [How to Contribute](#how-to-contribute)
2. [Requirements](#requirements)
3. [Running the Application Locally](#running-the-application-locally)
4. [Run Actuator](#run-actuator)
5. [Run Swagger UI Documentation](#run-swagger-ui-documentation)
6. [Javadoc](#javadoc)
7. [Copyright](#copyright)

## How to Contribute

For the contributor covenant to this project, please check the Code of Conduct file.

[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](CODE_OF_CONDUCT.md)

## Requirements

For building and running the application belows are required;

- [Spring Boot 2.6.2](https://spring.io/blog/2021/12/21/spring-boot-2-6-2-available-now)
- [JDK 17](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html)
- [Maven 3.8.3](https://maven.apache.org)
- Springfox Boot Starter 3.0.0 for Swagger UI Documentation
- MongoDB

## Running the application locally

The project can be booted with Spring Cloud Config Server or directly within the application. In order to boot the project within itself, enable the properties in application.properties file and disable bootstrap.properties file.

Application can be run with SpringBootProjectExampleApplication class under evrentan.examples.springbootprojectexample.spring.config.spring package.

Alternatively you can use the [Spring Boot Maven plugin](https://docs.spring.io/spring-boot/docs/current/reference/html/build-tool-plugins-maven-plugin.html) like so:

```shell
mvn spring-boot:run
```

## Run Actuator

[Spring Boot Actuator](https://spring.io/guides/gs/actuator-service/) can be reached from [local url for Actuator](http://localhost:8081/actuator).

Only health and caches endpoints are enabled by default. Configuration can be updated within the ""actuator"" section of the related application.properties file. This file can be also in Spring Cloud Config Server if the application is booted with Spring Cloud Config Server.

## Javadoc

You can create Javadoc with the below command or directly from your IDE.

```shell
mvn javadoc:javadoc
```

## Run Swagger UI Documentation

After running the application, just type the  [local url for Swagger UI](http://localhost:8080/swagger-ui/index.html) in your browser.

## Extra Notes

[![GitKraken Client](https://img.shields.io/badge/GitKraken-Legendary%20Git%20Tools-teal?style=plastic&logo=gitkraken)](https://www.gitkraken.com/invite/eNppBA83)

This repo was made with love using [GitKraken Client](https://www.gitkraken.com/invite/eNppBA83).

## Copyright

GNU General Public License v3.0
Permissions of this strong copyleft license are conditioned on making available complete source code of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved. Contributors provide an express grant of patent rights.
"
ivanyu/logical-rules-parser-antlr,master,39,18,2014-09-13T18:04:36Z,144,0,A simple example of a parser built with ANTLR,antlr blog-post java parser,"logical-rules-parser-antlr
==========================

A simple example of a parser built with ANTLR.

There is [the blog post](http://ivanyu.me/blog/2014/09/13/creating-a-simple-parser-with-antlr/) describes the parser.
"
oktadev/auth0-spring-boot-angular-crud-example,main,26,11,2023-04-20T22:36:55Z,957,0,Angular and Spring Boot CRUD Example,angular oidc spa spring-boot spring-security,"# Angular and Spring Boot CRUD Example

This example app shows how to create a Spring Boot API and CRUD (create, read, update, and delete) its data with a beautiful Angular + Angular Material app.

Please read [Build a Beautiful CRUD App with Spring Boot and Angular](https://auth0.com/blog/spring-boot-angular-crud) to see how it was created or follow [this demo script](demo.adoc).

You can also watch a demo of this example in the screencast below:

[![Building a CRUD app with Spring Boot and Angular!](static/spring-boot-angular.webp)](https://youtu.be/0pnSVdVn_NM)

**Prerequisites:** [Java 17](http://sdkman.io) and [Node.js 18+](https://nodejs.org/)

* [Getting Started](#getting-started)
* [Links](#links)
* [Help](#help)
* [License](#license)

## Getting Started

To install this example application, run the following commands:

```bash
git clone https://github.com/oktadev/auth0-spring-boot-angular-crud-example.git jugtours
cd jugtours
```

This will get a copy of the project installed locally. You'll need to configure the application with a registered OIDC app for it to start. Luckily, Auth0 makes this easy!

### Use Auth0 for OpenID Connect

Install the [Auth0 CLI](https://github.com/auth0/auth0-cli) and run `auth0 login` in a terminal.

Next, run `auth0 apps create`:

```shell
auth0 apps create \
  --name ""Bootiful Angular"" \
  --description ""Spring Boot + Angular = ❤️"" \
  --type regular \
  --callbacks http://localhost:8080/login/oauth2/code/okta,http://localhost:4200/login/oauth2/code/okta \
  --logout-urls http://localhost:8080,http://localhost:4200 \
  --reveal-secrets
```

> **TIP**: You can also use your [Auth0 dashboard](https://manage.auth0.com) to register your application. Just make sure to use the same URLs as above.

Copy the results from the CLI into an `.okta.env` file:

```shell
export OKTA_OAUTH2_ISSUER=https://<your-auth0-domain>/
export OKTA_OAUTH2_CLIENT_ID=<your-client-id>
export OKTA_OAUTH2_CLIENT_SECRET=<your-client-secret>
```

If you're on Windows, name the file `.okta.env.bat` and use `set` instead of `export`:

```shell
set OKTA_OAUTH2_ISSUER=https://<your-auth0-domain>/
set OKTA_OAUTH2_CLIENT_ID=<your-client-id>
set OKTA_OAUTH2_CLIENT_SECRET=<your-client-secret>
```

Then, run `source .okta.env` (or run `.okta.env.bat` on Windows) to set the environment variables. Start your app and log in at `http://localhost:8080`:

```shell
source .okta.env
mvn spring-boot:run -Pprod
```

You can prove everything works by running this project's Cypress tests. Add environment variables with your credentials to the `.okta.env` (or `.okta.env.bat`) file you created earlier.

```shell
export CYPRESS_E2E_DOMAIN=<your-auth0-domain> # use the raw value, no https prefix
export CYPRESS_E2E_USERNAME=<your-email>
export CYPRESS_E2E_PASSWORD=<your-password>
```

Then, run the Cypress tests and watch them pass:

```shell
source .okta.env
cd app
ng e2e
```

You can [view this project's CI pipeline](.github/workflows/main.yml) and see that all its [workflows are passing too](https://github.com/oktadev/auth0-spring-boot-angular-crud-example/actions). 😇

## Links

This example uses the following open source libraries:

* [Angular](https://angular.io)
* [Angular Material](https://material.angular.io)
* [Spring Boot](https://spring.io/projects/spring-boot)
* [Spring Security](https://spring.io/projects/spring-security)

## Help

Please post any questions as comments on the [blog post](https://auth0.com/blog/spring-boot-angular-crud), or visit our [Auth0 Community Forums](https://community.auth0.com/).

## License

Apache 2.0, see [LICENSE](LICENSE).
"
springmonster/netflix-dgs-example-java,main,35,3,2022-04-22T01:57:07Z,1020,1,Java Examples of Netflix DGS,graphql graphql-java graphql-server java netflix-dgs spring-boot spring-graphql,"# DGS

- [DGS](https://netflix.github.io/dgs/)
- [DGS Github](https://github.com/Netflix/dgs-framework)

## module description

| Module                                                                                                                                                                                          | Description                                                                                                      |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|
| [✅a-start](./a-start)                                                                                                                                                                           | Example of multiple `*.graphqls`，@DgsData.List                                                                   |
| [✅b-codegen](./b-codegen)                                                                                                                                                                       | Example of codegen，multiple modules，methods in type，support constant in @DgsData，@RequestHeader                  | 
| [✅c-scalar](./c-scalar)                                                                                                                                                                         | Example of custom scalar                                                                                         |                                    
| [✅d-http](./d-http)                                                                                                                                                                             | Example of Query，Mutation，Subscription，params validation，Apollo Tracing                                          |           
| [✅e-file](./e-file)                                                                                                                                                                             | Example of file upload                                                                                           |                                     
| [✅f-auth](./f-auth)                                                                                                                                                                             | Example of authentication and authorization                                                                      |                                      
| [✅g-error](./g-error)                                                                                                                                                                           | Example of custom error type                                                                                     | 
| [✅h-ut](./h-ut)                                                                                                                                                                                 | Example of uni test, integration test, unit test of supporting custom scalar                                     | 
| [✅i-nplusone](./i-nplusone)                                                                                                                                                                     | Example of `N+1`, support custom tracing                                                                         | 
| [✅j-sample](./j-sample)                                                                                                                                                                         | Example of split Query and Mutation into different configruation files to avoid too many definitions in one file |
| [k-postg](./k-postg)                                                                                                                                                                            | Example of supporting PostGraphile（Experimental）（TODO）                                                           |
| [✅l-interfaceunion](./l-interfaceunion)                                                                                                                                                         | Example of interface and union                                                                                   |
| [✅m-dynamicschema](./m-dynamicschema)                                                                                                                                                           | Example of dynamic schema                                                                                        |
| [❎n-webflux](./n-webflux)                                                                                                                                                                       | Example of dynamic webflux, there are problems with `Spring Security`                                            |
| [✅o-metrics](./o-metrics)                                                                                                                                                                       | Example of metrics                                                                                               |
| [✅p-apollo-gateway](./p-apollo-gateway)<br/>[✅p-federation-customer](./p-federation-customer)<br/>[✅p-federation-name](./p-federation-name)<br/>[✅p-federation-profile](./p-federation-profile) | Apollo Federation Gateway<br/>                                                                                   |
| [✅o-metrics](./o-metrics)                                                                                                                                                                       | Example of metrics                                                                                               |
| [✅x-kotlin](./x-kotlin)                                                                                                                                                                         | Example of Kotlin                                                                                                | 
| [✅y-bff](./y-bff)                                                                                                                                                                               | Example of client and server，support voyager                                                                     | 
| [✅z-domain](./z-domain)                                                                                                                                                                         | Example of client and server，support voyager                                                                     |

## Intellij Idea Plugin

- [GraphQL](https://plugins.jetbrains.com/plugin/8097-graphql)
- [DGS](https://plugins.jetbrains.com/plugin/17852-dgs)

## a-start

- Startup then visit http://localhost:10001/graphiql
- Input

```
{
    shows {
        title
        releaseYear
    }
}
------
{
  shows(titleFilter: ""Ozark"") {
    title
    releaseYear
  }
}
------
{
  showsWithDgsData {
    id
    title
    releaseYear
    actors {
      name
    }
  }
}
------
{
  user {
    id
    name
  }
}
```

## b-codegen

- root build.gradle

```
plugins {
    id ""com.netflix.dgs.codegen"" version ""5.1.17"" apply false
}
```

- module build.gradle

```
plugins {
    id ""com.netflix.dgs.codegen""
}
```

- module build.gradle

```
generateJava{
    schemaPaths = [""${projectDir}/src/main/resources/schema""] // List of directories containing schema files
    packageName = 'com.codegen.graphqldgs' // The package name to use to generate sources
    generateClient = true // Enable generating the type safe query API
}
```

- check build folder
- Input，visit http://127.0.0.1:10002/graphiql

```
{
  shows {
    id
    title
    releaseYear
  }
}
------
{
  shows(titleFilter: ""Ozark"") {
    id
    title
    releaseYear
  }
}
```

## c-scalar

- Input，visit http://127.0.0.1:10003/graphiql

```
{
  shows {
    id
    title
    releaseYear
    price
    dateTime
    bigDecimal
    uuid
  }
}
```

## d-http

- Startup，visit http://127.0.0.1:10004/graphiql
- Input

```
{
  show(people: {name: ""zhangsan""}) {
    id
    name
  }
  shows(personList: [{name: ""zhangsan""}]) {
    id
    name
  }
}
------
{
  showWithGood {
    id
    name
  }
}
------
{
  showWithGood(good: {name: ""Car""}) {
    id
    name
  }
}
------
mutation {
  addRating(title: ""title"", stars: 100) {
    avgStars
  }
  addRatingWithInput(input: {title: ""title"", stars: 200}) {
    avgStars
  }
}
------
mutation {
  addRating(title: ""title"", stars: 100) {
    avgStars
  }
  addRatingWithInput(input: {title: ""hel"", stars: 200}) {
    avgStars
  }
}
```

Use `Postman` to visit `Subscription`
![img.png](img.png)

## e-file

- Startup
- Input with `curl`

```
curl localhost:10005/graphql \
  -F operations='{ ""query"": ""mutation upload($file: Upload!) { upload(file: $file) }"" , ""variables"": { ""file"": null } }' \
  -F map='{ ""0"": [""variables.file""] }' \
  -F 0=@1.png
------
curl localhost:10005/graphql \
  -F operations='{ ""query"": ""mutation addArtwork($file: Upload!) { addArtwork(file: $file) }"" , ""variables"": { ""file"": null } }' \
  -F map='{ ""0"": [""variables.file""] }' \
  -F 0=@1.png

```

- Output

> Please check `project uploaded-images` folder

```
{""data"":{""upload"":true}}
------
{""data"":{""addArtwork"":true}}
```

## f-auth

- Startup，visit http://localhost:10006/graphiql
- Input

```
{
  salary
}
------
{
  salary
}
# REQUEST HEADERS中Input{ ""Authorization"": ""Basic aHI6aHI="" }，This is hr username and password
------
mutation {
  updateSalary(salaryInput: {employeeId: ""1"", newSalary: ""100""}) {
    id
    employeeId
    newSalary
  }
}
------
mutation {
  updateSalary(salaryInput: {employeeId: ""1"", newSalary: ""100""}) {
    id
    employeeId
    newSalary
  }
}
# REQUEST HEADERS中Input{ ""Authorization"": ""Basic aHI6aHI="" }，This is hr username and password
```

## g-error

- Startup，visit http://localhost:10007/graphiql
- Input

```
{
  show(people: {name: ""haha""}) {
    id
    name
  }
}
------
{
  show(people: {name: ""zhangsan""}) {
    id
    name
  }
}
------
{
  getRating(id: ""1"") {
    avgStars
  }
}
```

## h-ut

> see `test` folder

- Run `DemoControllerTests` and `ShowDataFetcherTest` to check

## i-nplusone

- Startup，visit http://localhost:10009/graphiql
- Input

```
{
  shows {
    showId
    title
    reviews {
      starRating
    }
  }
}
------
{
  showsN {
    id
    title
    releaseYear
    artwork {
      url
    }
    reviewsN {
      username
      starScore
      submittedDate
    }
  }
}
```

## l-interfaceunion

- Startup then visit http://localhost:10012/graphiql
- interface input

```
{
  movies {
    __typename
    ... on ActionMovie {
      title
      nrOfExplosions
    }
    ... on ScaryMovie {
      title
      gory
      scareFactor
    }
  }
}
```

- union input

```
{
  search {
    __typename
    ... on Actor {
      name
    }
    ... on Series {
      title
    }
  }
}
```

## m-dynamicschema

- Startup then visit http://localhost:10013/graphiql
- Input

```
query randomNumber {
  randomNumber(bound: 10)
}
------
mutation createUser {
  createUser(username: ""hello"", password: ""world"") {
    id
    username
    password
  }
}
```

## n-webflux

- Startup then visit http://localhost:10014/graphiql
- Input

```
query getUsers {
  getUsers {
    id
    username
    password
  }
  getUserById(id: 1) {
    id
    username
    password
  }
}

mutation createUser {
  createUser(username: ""Trudy"", password: ""Trudy"") {
    id
    username
    password
  }
}
```

## o-metrics

visit http://localhost:10015/actuator/metrics to check output

### Step 1

Use docker-compose to start Grafana and Prometheus servers.

- First generate jar in `/build/libs` folder
- In the root folder

```
docker-compose up -d
```

### Step 2

Check the Prometheus server.

- Open http://localhost:9090
- Access status -> Targets, endpoints must be ""UP""

### Step 3

Configure the Grafana.

- Open http://localhost:3000, user name and password are all `admin`
- Configure integration with Prometheus
    - Access configuration
    - Add data source
    - Select Prometheus
    - Use url ""http://host.docker.internal:9090"" and access with value ""Server(default)""
- Configure dashboard

## p-gateway

### Step 1

Start `customer`,`name`,`profile` services

### Step 2

Start `Apollo Gateway`

```
npm install

node index.js
```

### Step 3

Visit http://localhost:4000

Variables is

```
{
  ""customerId"": ""1""
}
```

Query is

```
query Customer($customerId: String!) {
  customer(customerId: $customerId) {
    age
    id
    name {
      firstName
      fullName
      lastName
      middleName
      prefix
    }
    profile {
      email
      phone
    }
  }
}
```

## x-kotlin

- Input

```
{
	shows {
    title
    releaseYear
	  id
	}
}
```

## y-bff

- Startup，Startup module `z-domain`，visit http://localhost:20000/graphiql
- Startup, Startup module `z-domain`，visit http://localhost:20000/voyager
- Input

```
{
  shows {
    id
    title
    releaseYear
  }
}
------
mutation {
  addShow(input: {title: ""title"", releaseYear: 2022}) {
    id
    title
    releaseYear
  }
}
```

## z-domain

- Startup，visit http://localhost:20001/graphiql
- Startup，visit http://localhost:20001/voyager
- Input

```
{
  shows {
    id
    title
    releaseYear
  }
}
------
mutation {
  addShow(input: {title: ""title"", releaseYear: 2022}) {
    id
    title
    releaseYear
  }
}
```
"
traex/RetrofitExample,master,182,64,2014-10-03T16:50:57Z,359,5,Example for one of my tutorials at http://blog.robinchutaux.com/blog/a-smart-way-to-use-retrofit/,,"RetrofitExample
===============

![RetrofitExample](https://github.com/traex/RetrofitExample/blob/master/header.png)

Example for one of my tutorials at http://blog.robinchutaux.com/blog/a-smart-way-to-use-retrofit/

[Retrofit library](http://square.github.io/retrofit/) is a type-safe REST client for Android and Java created by [Square Open Source.](http://square.github.io/) With this library you can request the webservices of a REST api with POST, GET and more. This library is awesome and very useful, but you need a good architecture and a good practice to use it as best as possible.
"
dmarczal/java_jdbc_dao_mvc_swing,master,25,12,2011-11-09T01:32:10Z,858,0,An example of MVC + JAVA + SWING + DAO,,
paulmandal/ATAK-Plugin-Example,master,26,7,2020-10-04T20:20:03Z,149,0,An example ATAK plugin,,"# ATAK Plugin Example

This is an example plugin for ATAK that contains examples of:

* Listening to outgoing messages from ATAK and Toast their type to the screen
* Sending incoming messages to ATAK (in this case, a fake ""Green HQ"" map marker at lat: 0, lon: 0)
* A icon overlaid in the lower right corner of the screen that updates every 2 seconds
* A basic plugin UI with a Spinner
* Different icon types (map overlay, menu, settings menu)
"
jdmg94/react-native-webrtc-example,master,69,32,2020-05-06T05:43:19Z,2211,23,An example app for `react-native-webrtc` using React 0.60 or newer,,"# Basic React-Native-WebRTC example app

## Motivation

Real Time Technologies are back in style, while this is fairly standard on the Web platforms, React Native faced a steeper learning curve to get into WebRTC Technologies specially without Expo support for native modules.

I wanted to provide the most basic codebase to provide a starting point for developers looking at WebRTC technologies for React Native using `react-native-webrtc` and `react-native@^0.60` with as little overhead as possible.


As it is also required on the Web Standard, RTC technologies require a broker to help with the signaling of its peers, this has also been included in the form of a thin `express`/`socket.io` server under the `./backend` folder, 

>Of course this is only going to be a local instance of the broker so you will have to expose it using a service like [localTunnel](https://github.com/localtunnel/localtunnel) or [ngrok](https://ngrok.com/) so 2 people on different networks will be able to use the client app, remember to update the socket address on the code if you do this.

## Usage

First you need to start the signaling server so we can handle the peer activity, you can do this by running `cd ./backend && npm install && npm start` on a terminal window located at the project's root.

Once you have the signaling server up you need to launch the client app and the process is a little different for each platform. For the best DX you should use a real device.

### Android 

The setup has been tweaked for `react-native^0.60` and if you want to replicate this on your own project, for Android, you should take a look at the following files to extrapolate the config:

-  `./android/settings.graddle`
-  `./android/graddle.properties`
-  `./android/build.graddle`
-  `./android/app/build.graddle`
-  `./android/app/src/AndroidManifest.xml`
-  `./android/app/src/main/java/com/basicwebrtcexample/MainApplication.java`


to run the client app just have your physical android device connected and listed under `adb devices`, once your physical device is connected and trusted just run `npm run android`

### ios

For iOS most of the legwork is done with cocoapods, if you want to extrapolate the config for your project take a look at the following files:

- `./ios/podfile`
- `./ios/basicwebrtcexample/info.plist`

once you have updated your config files, run `npx pod-install` at the root of the project.

to run the client app run `npm start` on a separate terminal located at the project root and have your iPhone connected and authorized on your Mac then open Xcode and select the workspace for your project, then give the main project signing capabilities and select your iPhone on the emulator options, then hit run, after the debugger is installed you can close xcode.

Copyleft: **Jose Munoz 2020**

"
pgilad/spring-boot-webflux-swagger-starter,master,63,32,2018-09-11T10:15:55Z,430,1,An example project to illustrate how to document Spring Boot Webflux with Swagger2,api-documentation demo reactive spring-boot swagger swagger2 webflux,"# spring-boot-webflux-swagger-starter

> An example project to illustrate how to document Spring Boot Webflux with Swagger2

## Requirements

- Java 11

## Installation

```bash
$ git clone https://github.com/pgilad/spring-boot-webflux-swagger-starter.git
```

## Usage

```bash
$ gradle bootRun
```

Now open your favorite web-browser (Chrome) to `http://localhost:8080/swagger-ui.html` which is automatically
generated from the `HelloController` web-flux mapping.

![swagger-ui](./images/swagger-ui.png)

## License

MIT © [Gilad Peleg](https://www.giladpeleg.com)
"
KieronQuinn/AmazfitSpringboardPluginExample,master,41,21,2018-02-18T17:38:15Z,114,1,Example for creating custom springboard pages on the Amazfit Pace,,"# Amazfit Springboard Plugin Example

This project is an example for how to create a custom page for the default home screen (called ""Springboard"") on the Amazfit Pace

## Usage
You don't need to import this project and edit it from there. There's only a couple of important files and pieces of code:

### SpringboardPluginLib.jar (app/libs)
Disassembled code from the HmAlarmClock app, with all but the plugin code removed. [Download it](https://github.com/KieronQuinn/AmazfitSpringboardPluginExample/raw/master/app/libs/SpringboardPluginLib.jar), copy it to the libs folder of your project, and then include it like so:

![File > Project Structure > Dependencies](https://i.imgur.com/xIrVhJp.png)

### SpringboardPage.java (app/src/main/java/com/kieronquinn/app/springboardexample)
Example code for implementing a page. Copy this to your project, and edit it as you like. It's commented, so each method is labelled with what it does

### AndroidMainfest.xml (app/src/main)

**Do not simply copy this to your project**

Only the following section is required:

`<meta-data android:name=""com.huami.watch.launcher.springboard.PASSAGER_TARGET"" android:resource=""@array/spring_depend"" />`

Place this inside your application tags, as shown in the example in this project

### arrays.xml (app/src/main/res/values)

Copy this file to your project (or create the file and copy the contents), then edit the contents of the \<item> \</item> tags to point to your SpringboardPage class.

If you rename your SpringboardPage class, you **must** change it here also. Make sure the package name **and** component is correct here, or the page will not work

### widget_blank.xml (app/src/main/res/layout)

You don't need to copy this file, you can create your own layout file and edit the SpringboardPage class accordingly

## Installation
Run your app as normal. If you created a project without an activity, you may need to use Build > Build APK and install it via adb

Now, the first time you install the app it will not immediately appear in the launcher. Either reboot the watch, or run `adb shell am force-stop com.huami.watch.launcher` to restart the launcher

After this it should appear as the last page. If it has, well done! If not, check you followed every step correctly (particularly the arrays.xml and AndroidManifest.xml ones). Still not working? [Post on the XDA thread](https://forum.xda-developers.com/smartwatch/amazfit/dev-create-custom-home-screen-pages-pace-t3751731)

## Moving the page
There's no built in way to move or disable the page on the watch or the Amazfit app. Luckily, [I've already got a solution for that](https://github.com/KieronQuinn/AmazfitSpringboardSettings)
"
cronn/cucumber-junit5-example,main,34,18,2020-08-25T12:04:01Z,565,12,Example setup for Cucumber and JUnit 5 with Gradle,cucumber gradle java junit5 template-project,"# Cucumber with JUnit5

This repository contains an example project that integrates [Cucumber](https://cucumber.io/) with [JUnit5](https://junit.org/junit5/). It is the same setup explained in the [blog post](https://www.blog.cronn.de/en/testing/2020/08/17/cucumber-junit5.html).

## Quick Start

```shell
$ git clone https://github.com/cronn/cucumber-junit5-example your-own-tests
$ cd your-own-tests
$ ./gradlew test
```

Gradle will execute all feature files which are located in the `src/test/resources/features` folder as specified in [RunAllCucumberTests](https://github.com/cronn/cucumber-junit5-example/blob/main/src/test/java/com/example/RunAllCucumberTests.java). In order to filter execution to just a subset of all features, use the `includeTags` property as in the following example. It uses [JUnit5 tag expressions](https://junit.org/junit5/docs/current/user-guide/#running-tests-tag-expressions):

```shell script
$ ./gradlew test --project-prop includeTags=""first | awesome""
```

In order to ignore just a subset of features, use the `includeTags` property like this:

```shell script
$ ./gradlew test --project-prop includeTags=""!second""
```

[build.gradle.kts](https://github.com/cronn/cucumber-junit5-example/blob/main/build.gradle.kts#L36-L43) uses `cucumber.execution.parallel.enabled` to enable parallel test execution by default. Additionally, it uses the `cucumber.plugin` option to write a reports file to `build/reports/cucumber.ndjson`, an execution timeline to `build/reports/timeline` and an HTML report to `build/reports/cucumber.html`. All Cucumber features/rules/examples/scenarios annotated with `@disabled` are filtered by default and are not executed. This project declares an extra dependency to [picocontainer](http://picocontainer.com/) in order to show dependency injection within tests - remove it in case you don't need it. The Gradle configuration is annotated to help you make changes for your own test setup, thus feel free to modify it!

[<img src=""https://www.cronn.de/img/logo_name_rgb_1200x630.png"" alt=""cronn GmbH"" width=""200""/>](https://www.cronn.de/)
"
java-modularity/agenda-example,master,30,19,2013-07-05T10:06:05Z,8851,1,Building Modular Cloud Applications in Java - getting started example ,,"agenda-example
==============

[Building Modular Cloud Applications in Java](http://shop.oreilly.com/product/0636920028086.do) - getting started example (chapter 3.)

To use the example,

- clone this repository,
- point Eclipse to the directory where you cloned the repository,
- import all projects using `File -> Import... -> Existing Projects in to Workspace`
- right click on `agenda -> demo.bndrun`, and choose `Run As -> BND OSGi Run Launcher`
- point your browser to [http://localhost:8080/agendaui/index.html](http://localhost:8080/agendaui/index.html)."
klevis/DigitRecognizer,master,28,24,2017-11-24T21:01:31Z,14873,4,Java Convolutional Neural Network example for Hand Writing Digit Recognition,convolutional-neural-networks deep-learning deeplearning4j java java-convolutional-neural-network java-machine-learning machine-learning machine-learning-algorithms mlib neural-network spark,"# http://ramok.tech/machine-learning/
Java Digit Recognition Application 

Hand Writing Digit Recognition using Simple Neural Networks with Spark Mlib
and
Deep Convolution Neural Network with DeepLearning4j

Acuracy with simple model 97% 
and 
with convolutional neural network 99.2%

For more please visit below posts:

http://ramok.tech/2017/11/29/digit-recognizer-with-neural-networks/

http://ramok.tech/2017/12/13/java-digit-recognizer-with-convolutional-neural-networks/

<p align=""center"">
  <img src=""https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-14_01h00_37.jpg?resize=1024%2C537e"" width=""600""/>
</p>


License to EPL https://www.eclipse.org/legal/epl-v10.html"
sv3ndk/stormRoomOccupancy,master,33,22,2013-07-29T12:56:26Z,531,0,Example of basic Storm topology that updates DB persistent state,,"stormRoomOccupancy
==================

Basic Storm topology example that updates DB persistent state with correct error handling. The code is based on Storm 0.9.0.1, Cassandra 2.0.4 and Java 7.

The [first release] ( https://github.com/svendx4f/stormRoomOccupancy/releases/tag/v1.0.1) is explained in great details in my blog post on [scalable real-time state update with Storm] (http://svendvanderveken.wordpress.com/2013/07/30/scalable-real-time-state-update-with-storm/)

The current code is an update explained in my blog post on [Storm error handling] ( http://svendvanderveken.wordpress.com/2014/02/01/notes-on-storm-trident-error-handling)

In order to run this example, an instance of Cassandra with the following key space is required: 

```
CREATE KEYSPACE EVENT_POC WITH replication = { 'class': 'SimpleStrategy', 'replication_factor': '1' } ;
```

(tables are re-created everytime time the topology is re-deployed)

Maybe edit this line in Deployer.java if you Nimbus is not reachable on that IP:

```
config.put(""nimbus.host"" , ""192.168.33.10"");
```

Then package the topology:

```
mvn package
```

And deploy it: 

```
storm jar target/stormRoomOccupancy-0.0.2-SNAPSHOT-jar-with-dependencies.jar svend.storm.example.conference.Deployer
```


"
sunnygleason/j4-minimal,master,63,19,2010-07-17T21:31:43Z,312,3,"Minimal web application example using Embedded Jetty, Jersey, Guice, and Jackson",,"A minimal example of a REST API built with with Jersey, Jackson and Guice running on embedded Jetty
---------------------------------------------------------------------------------------------------

You can either run it as a main in eclipse or run as an executable jar by building with maven and running it. 

    mvn package
    java -jar target/minimal.jar
"
eljefe6a/UnoExample,master,39,39,2012-08-18T20:55:37Z,37160,0,MapReduce/Hadoop example that uses regular playing cards to show mapping and reducing.,,"Playing Card Example
==========

Hadoop MapReduce example that uses regular playing cards to explain how mapping and reducing works.

This is the example code for the first and third episodes of the [Hadoop MapReduce screencast](http://pragprog.com/screencasts/v-jamapr/processing-big-data-with-mapreduce).

Licence
======
   Copyright 2013 Jesse Anderson

   Licensed under the Apache License, Version 2.0 (the ""License"");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an ""AS IS"" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
"
sylleryum/kafka-microservices-with-saga,main,47,15,2022-04-20T14:12:22Z,664,1,Java (Spring) microservices example with Kafka and saga pattern,kafka microservices spring-boot,"[![codecov](https://codecov.io/gh/sylleryum/kafka-microservices-with-saga/branch/main/graph/badge.svg?token=66D2JP4X2K)](https://codecov.io/gh/sylleryum/kafka-microservices-with-saga)
![example workflow](https://github.com/sylleryum/kafka-microservices-with-saga/actions/workflows/workflow.yml/badge.svg)

# Microservices with Kafka and Saga pattern using Spring boot
This project simulates a system for processing orders (i.e., a purchase) of items (E.g.: an order of a fridge and a camera) which is constituted of 4 microservices: order, stock, payment and notification service.
## High level architecture:
<p align=""center"">
<img src=""https://raw.githubusercontent.com/sylleryum/kafka-microservices-with-saga/main/resources/readme-images/architecture.png"" alt="""" width=""50%""/>
</p>

**Note:** as the main objective of this project is to demonstrate Kafka, majority of microservice patterns are ignored as well as some best practices for simplicity/readability’s sake (E.g.: Transactional outbox and coding to the interface).

## Getting started / Installation:

### Option 1: Running locally
- Clone this repo.
- Run the docker compose file inside “resources/docker files/Run project locally” directory (docker-compose up), if mongo-express fails to initialize, simply re-run it.
- Run all the microservices (any order of initialization is fine).

### Option 2: Running on Docker
- Simply run the docker compose file inside “resources/docker files/Run project on docker” directory (docker-compose up), if mongo-express fails to initialize, simply re-run it.

## Instructions:

- Send orders through order service’s endpoint /api/v1/order specifying the amount of orders to send and the amount of items inside each order through query param o (order) and i (item). 
  - E.g.: localhost:8080/api/v1/order?o=2&i=3 will send 2 orders, each order contains 3 items within itself.
- You can easily check the final result of each order through notification service’s console or check each topic through kafkdrop (localhost:9000/).
- You can change the expected order result (success/failure) and other configurations through shared.properties inside common module.

## How it works:
Once a new order is received, the order service does the initial processing and sends a new event to kafka:
<p align=""center"">
<img src=""https://raw.githubusercontent.com/sylleryum/kafka-microservices-with-saga/main/resources/readme-images/step1.png"" alt="""" width=""50%""/>
</p>
All microservices involved in the order will perform their corresponding operations and send a confirmation back to Kafka (success/failure):
<p align=""center"">
<img src=""https://raw.githubusercontent.com/sylleryum/kafka-microservices-with-saga/main/resources/readme-images/step2.png"" alt="""" width=""50%""/>
</p>
Order service then uses Kafka Streams to join all the confirmations received (inner join). If all services returned a success event, order has been fully processed (order completed). If any service returns a failure message, order service then triggers an event of rollback which will be processed by all other services. 
Order service also sends the final order status to Kafka, notification service simulates then a notification message to user informing the final status of his/her order:
<p align=""center"">
<img src=""https://raw.githubusercontent.com/sylleryum/kafka-microservices-with-saga/main/resources/readme-images/step3.png"" alt="""" width=""50%""/>
</p>

## Configurations:
- If running locally, configurations of the microservices can be changed through shared.application located at common\src\resources\ (explanaition of relevant configurations are included in this file).
- 
## Considerations regarding this project and best practices:
- Kafka may be tricky to handle proficiently duplications/idempotency. In this project the approach of [enabling idempotent producer was used](https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#producerconfigs_enable.idempotence). Consumer and its commit offset strategy should be considered also. E.g.: [Idempotent Kafka Consumer](https://medium.com/techwasti/idempotent-kafka-consumer-442f9aec991e)
- This projects uses 2 DBs, Postgres for Order service and MongoDB for Stock service, this is only to showcase microservices and Kafka with different DBs.
- Common module should be replaced in a real scenario for a better approach as externalized configuration pattern.
- For simplicity sake, Kafka producer/consumer are using a shared entity located in the common module, in a real scenario Avro/schema registry (included in the docker-compose file) is advised.
- A caveat of using Kafka Streams and inner join to process the results of an order being processed by order services is that it is time windowed, if for any reason a service takes longer than the window time to answer an order, the orchestrator will never process the confirmation of the order. A few alternatives is to use individual listeners in the orchestrator or outer join and schedule a task to verify the order after join window has closed.
- If a rollback is needed, orchestrator (order service) will send an event (order) that is consumed by all services involved in processing an order rather than individual rollback events (E.g.: rollback event to payment service) as usually maximum 1 service will fail and because of this, all other services will have to rollback and therefore, consume an event. "
lohitvijayarenu/netty-protobuf,master,28,10,2014-12-30T05:30:54Z,104,1,simple example using netty and protobuf,,
cloud-native-java/training,master,37,31,2018-03-12T19:13:13Z,152,1,A collection of training courses and example code for Cloud Native Java,,"# Cloud Native Java: Training Materials

This repository contains various training materials that accompany the sections and chapters in _O'Reilly's Cloud Native Java: Building Resilient Systems with Spring Boot, Spring Cloud, and Cloud Foundry_.

To find more information on the book, please visit [cloudnativejava.io](http://www.cloudnativejava.io/).

## Getting Started

If you're looking for the source code and materials for _O'Reilly's Live Training_: [Building Microservices with Spring Boot, Spring Cloud, and Cloud Foundry](https://www.safaribooksonline.com/live-training/courses/building-microservices-with-spring-boot-spring-cloud-and-cloud-foundry/0636920151937/), then look no further! 

First, clone this repository, and then navigate to the [microservices-online-training](https://github.com/cloud-native-java/training/tree/master/microservices-online-training) module for instructions on getting started with the example projects from the 2-day live online training. If you've somehow found this repository but are looking for the live training videos, [please visit Safari](https://www.safaribooksonline.com/search/?query=cloud%20native%20java&extended_publisher_data=true&highlight=true&is_academic_institution_account=false&source=user&include_assessments=false&include_case_studies=true&include_courses=true&include_orioles=true&include_playlists=true&formats=live%20online%20training&sort=relevance) to sign-up for upcoming live training courses for Cloud Native Java.

## Maintainers

This repository is maintained by the authors of Cloud Native Java. The best way to get at us is usually via Twitter. Please also feel free to use the [issue tracker](https://github.com/cloud-native-java/training/issues) to provide feedback on the materials. But really, it's faster if you yell at us nicely on Twitter (DMs are open). 

- [Josh Long (@starbuxman)](https://www.twitter.com/starbuxman)
- [Kenny Bastani (@kennybastani)](https://www.twitter.com/kennybastani)

## License

This project is licensed under Apache License 2.0.
"
idugalic/reactive-company,master,65,21,2017-01-26T12:58:59Z,415,6,Example of reactive web application. Java. Spring 5. Reactive Streams. Docker. ,back-pressure elastic java mongodb reactive reactive-streams reactor resilent responsive spring tailable thymeleaf,"# [projects](http://idugalic.github.io/projects)/reactive-company ![Java CI with Maven](https://github.com/idugalic/reactive-company/workflows/Java%20CI%20with%20Maven/badge.svg?branch=master) [![GitPitch](https://gitpitch.com/assets/badge.svg)](https://gitpitch.com/idugalic/reactive-company/master?grs=github&t=white)

This project is intended to demonstrate best practices for building a reactive web application with Spring 5 platform.

## Table of Contents

   * [Reactive programming and Reactive systems](#reactive-programming-and-reactive-systems)
       * [Why now?](#why-now)
       * [Spring WebFlux (web reactive) module](#spring-webflux-web-reactive-module)
          * [Server side](#server-side)
             * [Annotation based](#annotation-based)
             * [Functional](#functional)
          * [Client side](#client-side)
       * [Spring Reactive data](#spring-reactive-data)
    * [CI with Travis](#ci-with-travis)
    * [Running instructions](#running-instructions)
       * [Run the application by Maven:](#run-the-application-by-maven)
       * [Run the application on Cloud Foundry](#run-the-application-on-cloud-foundry)
       * [Run the application by Docker](#run-the-application-by-docker)
          * [Manage docker swarm with Portainer](#manage-docker-swarm-with-portainer)
          * [Manage docker swarm with CLI](#manage-docker-swarm-with-cli)
             * [List docker services](#list-docker-services)
             * [Scale docker services](#scale-docker-services)
             * [Browse docker service logs](#browse-docker-service-logs)
          * [Swarm mode load balancer](#swarm-mode-load-balancer)
       * [Browse the application:](#browse-the-application)
    * [Load testing with Gatling](#load-testing-with-gatling)
    * [Log output](#log-output)
    * [References and further reading](#references-and-further-reading)


## Reactive programming and Reactive systems

In plain terms reactive programming is about [non-blocking](http://www.reactivemanifesto.org/glossary#Non-Blocking) applications that are [asynchronous](http://www.reactivemanifesto.org/glossary#Asynchronous) and [message-driven](http://www.reactivemanifesto.org/glossary#Message-Driven) and require a small number of threads to [scale](http://www.reactivemanifesto.org/glossary#Scalability) vertically (i.e. within the JVM) rather than horizontally (i.e. through clustering).

A key aspect of reactive applications is the concept of backpressure which is a mechanism to ensure producers don’t overwhelm consumers. For example in a pipeline of reactive components extending from the database to the HTTP response when the HTTP connection is too slow the data repository can also slow down or stop completely until network capacity frees up.

Reactive programming also leads to a major shift from imperative to declarative async composition of logic. It is comparable to writing blocking code vs using the CompletableFuture from Java 8 to compose follow-up actions via lambda expressions.

For a longer introduction check the blog series [“Notes on Reactive Programming”](https://spring.io/blog/2016/06/07/notes-on-reactive-programming-part-i-the-reactive-landscape) by Dave Syer.

""We look at Reactive Programming as one of the methodologies or pieces of the puzzle for Reactive [Systems] as a broader term."" Please read the ['Reactive Manifesto'](http://www.reactivemanifesto.org/) and ['Reactive programming vs. Reactive systems'](https://www.oreilly.com/ideas/reactive-programming-vs-reactive-systems) for more informations.

### Why now?

What is driving the rise of Reactive in Enterprise Java? Well, it’s not (all) just a technology fad — people jumping on the bandwagon with the shiny new toys. The driver is efficient resource utilization, or in other words, spending less money on servers and data centres. The promise of Reactive is that you can do more with less, specifically you can process higher loads with fewer threads. This is where the intersection of Reactive and non-blocking, asynchronous I/O comes to the foreground. For the right problem, the effects are dramatic. For the wrong problem, the effects might go into reverse (you actually make things worse). Also remember, even if you pick the right problem, there is no such thing as a free lunch, and Reactive doesn’t solve the problems for you, it just gives you a toolbox that you can use to implement solutions.


### Spring WebFlux (web reactive) module

Spring Framework 5 includes a new spring-webflux module. The module contains support for reactive HTTP and WebSocket clients as well as for reactive server web applications including REST, HTML browser, and WebSocket style interactions.

#### Server side
On the server-side WebFlux supports 2 distinct programming models:

- Annotation-based with @Controller and the other annotations supported also with Spring MVC
- Functional, Java 8 lambda style routing and handling

##### Annotation based
```java
@RestController
public class BlogPostController {

	private final BlogPostRepository blogPostRepository;

	public BlogPostController(BlogPostRepository blogPostRepository) {
		this.blogPostRepository = blogPostRepository;
	}

	@PostMapping(""/blogposts"")
	Mono<Void> create(@RequestBody Publisher<BlogPost> blogPostStream) {
		return this.blogPostRepository.save(blogPostStream).then();
	}

	@GetMapping(""/blogposts"")
	Flux<BlogPost> list() {
		return this.blogPostRepository.findAll();
	}

	@GetMapping(""/blogposts/{id}"")
	Mono<BlogPost> findById(@PathVariable String id) {
		return this.blogPostRepository.findOne(id);
	}
}
```
##### Functional

Functional programming model is not implemented within this application. I am not sure if it is posible to have both models in one application.

Both programming models are executed on the same reactive foundation that adapts non-blocking HTTP runtimes to the Reactive Streams API.

#### Client side

WebFlux includes a functional, reactive WebClient that offers a fully non-blocking and reactive alternative to the RestTemplate. It exposes network input and output as a reactive ClientHttpRequest and ClientHttpRespones where the body of the request and response is a Flux<DataBuffer> rather than an InputStream and OutputStream. In addition it supports the same reactive JSON, XML, and SSE serialization mechanism as on the server side so you can work with typed objects.

```java
@RunWith(SpringRunner.class)
@SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT)
public class ApplicationIntegrationTest {

	WebTestClient webTestClient;

	List<BlogPost> expectedBlogPosts;
	List<Project> expectedProjects;

	@Autowired
	BlogPostRepository blogPostRepository;

	@Autowired
	ProjectRepository projectRepository;

	@Before
	public void setup() {
		webTestClient = WebTestClient.bindToController(new BlogPostController(blogPostRepository), new ProjectController(projectRepository)).build();

		expectedBlogPosts = blogPostRepository.findAll().collectList().block();
		expectedProjects = projectRepository.findAll().collectList().block();

	}

	@Test
	public void listAllBlogPostsIntegrationTest() {
		this.webTestClient.get().uri(""/blogposts"")
			.exchange()
			.expectStatus().isOk()
			.expectHeader().contentType(MediaType.APPLICATION_JSON_UTF8)
			.expectBodyList(BlogPost.class).isEqualTo(expectedBlogPosts);
	}

	@Test
	public void listAllProjectsIntegrationTest() {
		this.webTestClient.get().uri(""/projects"")
			.exchange()
			.expectStatus().isOk()
			.expectHeader().contentType(MediaType.APPLICATION_JSON_UTF8)
			.expectBodyList(Project.class).isEqualTo(expectedProjects);
	}

	@Test
	public void streamAllBlogPostsIntegrationTest() throws Exception {
		FluxExchangeResult<BlogPost> result = this.webTestClient.get()
			.uri(""/blogposts"")
			.accept(TEXT_EVENT_STREAM)
			.exchange()
			.expectStatus().isOk()
			.expectHeader().contentType(TEXT_EVENT_STREAM)
			.returnResult(BlogPost.class);

		StepVerifier.create(result.getResponseBody())
			.expectNext(expectedBlogPosts.get(0), expectedBlogPosts.get(1))
			.expectNextCount(1)
			.consumeNextWith(blogPost -> assertThat(blogPost.getAuthorId(), endsWith(""4"")))
			.thenCancel()
			.verify();
	}

	...
}

```
Please note that webClient is requesting [Server-Sent Events](https://community.oracle.com/docs/DOC-982924) (text/event-stream).
We could stream individual JSON objects (application/stream+json) but that would not be a valid JSON document as a whole and a browser client has no way to consume a stream other than using Server-Sent Events or WebSocket.

### Spring Reactive data

Spring Data Kay M1 is the first release ever that comes with support for reactive data access. Its initial set of supported stores — MongoDB, Apache Cassandra and Redis

The repositories programming model is the most high-level abstraction Spring Data users usually deal with. They’re usually comprised of a set of CRUD methods defined in a Spring Data provided interface and domain-specific query methods.

In contrast to the traditional repository interfaces, a reactive repository uses reactive types as return types and can do so for parameter types, too.

```java
public interface BlogPostRepository extends ReactiveSortingRepository<BlogPost, String>{

	Flux<BlogPost> findByTitle(Mono<String> title);

}
```
## CI with Travis

The application is build by [Travis](https://travis-ci.org/idugalic/reactive-company). [Pipeline](https://github.com/idugalic/reactive-company/blob/master/.travis.yml) is triggered on every push to master branch.

- Docker image is pushed to [Docker Hub](https://hub.docker.com/r/idugalic/reactive-company/)

## Running instructions

### Run the application by maven:

This application is using embedded mongo database.
You do not have to install and run mongo database before you run the application locally.

You can use NON-embedded version of mongo by setting scope of 'de.flapdoodle.embed.mongo' to 'test'. 
In this case you have to install mongo server locally:

```bash
$ brew install mongodb
$ brew services start mongodb
```

Run it:

```bash
$ cd reactive-company
$ ./mvnw spring-boot:run
```

### Run the application on Cloud Foundry

Run application on local workstation with PCF Dev

- Download and install PCF: https://pivotal.io/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/introduction
- Start the PCF Dev: $ cf dev start -m 8192
- Push the app to PCF Dev: $ ./mvnw cf:push
- Enjoy: http://reactive-company.local.pcfdev.io/

You can adopt any CI pipeline you have to deploy your application on any cloud foundry instance, for example:

```bash
mvn cf:push [-Dcf.appname] [-Dcf.path] [-Dcf.url] [-Dcf.instances] [-Dcf.memory] [-Dcf.no-start] -Dcf.target=https://api.run.pivotal.io
```

### Run the application by Docker

I am running Docker Community Edition, version: 17.05.0-ce-mac11 (Channel: edge).

A [swarm](https://docs.docker.com/engine/swarm/) is a cluster of Docker engines, or nodes, where you deploy services. The Docker Engine CLI and API include commands to manage swarm nodes (e.g., add or remove nodes), and deploy and orchestrate services across the swarm. By running script bellow you will initialize a simple swarm with one node, and you will install services:

- reactive-company
- mongodb (mongo:3.0.4)

```bash
$ cd reactive-company
$ ./docker-swarm.sh
```

#### Manage docker swarm with Portainer

Portainer is a simple management solution for Docker, and is really simple to deploy:

```bash
$ docker service create \
    --name portainer \
    --publish 9000:9000 \
    --constraint 'node.role == manager' \
    --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \
    portainer/portainer \
    -H unix:///var/run/docker.sock
```
Visit http://localhost:9000

#### Manage docker swarm with CLI

##### List docker services

```bash
$ docker service ls
```

##### Scale docker services

```bash
$ docker service scale stack_reactive-company=2
```
Now you have two tasks/containers running for this service.

##### Browse docker service logs

```bash
$ docker service logs stack_reactive-company -f
```
You will be able to determine what task/container handled the request.

#### Swarm mode load balancer

When using HTTP/1.1, by default, the TCP connections are left open for reuse. Docker swarm load balancer will not work as expected in this case. You will get routed to the same task of the service every time.

You can use 'curl' command line tool (NOT BROWSER) to avoid this problem.

The Swarm load balancer is a basic Layer 4 (TCP) load balancer. Many applications require additional features, like these, to name just a few:

- SSL/TLS termination
- Content‑based routing (based, for example, on the URL or a header)
- Access control and authorization
- Rewrites and redirects


### Browse the application:

#### Index page

Open your browser and navigate to http://localhost:8080

The response is resolved by [HomeController.java](https://github.com/idugalic/reactive-company/blob/master/src/main/java/com/idugalic/web/HomeController.java) and home.html.

 - Blog posts are fully resolved by the Publisher - Thymeleaf will NOT be executed as a part of the data flow

 - Projects are fully resolved by the Publisher - Thymeleaf will NOT be executed as a part of the data flow

#### Server-Sent Events page

Open your browser and navigate to http://localhost:8080/stream

This view is resolved by [StreamController.java](https://github.com/idugalic/reactive-company/blob/master/src/main/java/com/idugalic/web/StreamController.java) and sse.html template. 


 - *Blog posts* are NOT fully resolved by the Publisher 
 - Thymeleaf will be executed as a part of the data flow 
 - These events will be rendered in HTML by Thymeleaf
 
 ```java
@GetMapping(value = ""/stream/blog"")
public String blog(final Model model) {
	final Flux<BlogPost> blogPostStream = this.blogPostRepository.findAll().log();
	model.addAttribute(""blogPosts"", new ReactiveDataDriverContextVariable(blogPostStream, 1000));
	return ""sse :: #blogTableBody"";
	}
 ```

 - *Projects* are NOT fully resolved by the Publisher 
 - Thymeleaf will be executed as a part of the data flow 
 - These events will be rendered in HTML by Thymeleaf
 
 ```java
@GetMapping(value = ""/stream/project"")
public String project(final Model model) {
	final Flux<Project> projectStream = this.projectRepository.findAll().log();
	model.addAttribute(""projects"", new ReactiveDataDriverContextVariable(projectStream, 1000));
	return ""sse :: #projectTableBody"";
	}
 ```
 
 - *Blog posts (tail)* are NOT fully resolved by the Publisher 
 - Thymeleaf will be executed as a part of the data flow 
 - These events will be rendered in JSON by Spring WebFlux (using Jackson) 
 - We are using a [Tailable Cursor](https://docs.mongodb.com/manual/core/tailable-cursors/) that remains open after the client exhausts the results in the initial cursor. Tailable cursors are conceptually equivalent to the tail Unix command with the -f option (i.e. with “follow” mode). After clients insert new additional documents into a capped collection, the tailable cursor will continue to retrieve documents. You may use a Tailable Cursor with [capped collections](https://docs.mongodb.com/manual/core/capped-collections/) only.
 - If you add a new blog post to the database, it will be displayed on the page in the HTML table.
 
 ```java
@GetMapping(""/tail/blogposts"")
Flux<BlogPost> tail() {
	LOG.info(""Received request: BlogPost - Tail"");
	try {
		// Using tailable cursor
		return this.blogPostRepository.findBy().log();
	} finally {
		LOG.info(""Request pocessed: BlogPost - Tail"");
	}
}
 ```


#### Blog posts (REST API):
```bash
$ curl http://localhost:8080/blogposts
```
or
```bash
$ curl -v -H ""Accept: text/event-stream"" http://localhost:8080/blogposts
```

#### Projects (REST API):
```bash
$ curl http://localhost:8080/projects
```
or
```bash
$ curl -v -H ""Accept: text/event-stream"" http://localhost:8080/projects
```

#### Blog posts - tial (REST API)
```bash
$ curl -v -H ""Accept: text/event-stream"" http://localhost:8080/tail/blogposts
```

##  Load testing with Gatling

Run application first (by maven or docker)

```bash
$ ./mvnw gatling:execute
```

By default src/main/test/scala/com/idugalic/RecordedSimulation.scala will be run.
The reports will be available in the console and in *html files within the 'target/gatling/results' folder

## Log output

A possible log output we could see is:
![Log - Reactive](assets/logs-reactive.png?raw=true)

As we can see the output of the controller method is evaluated after its execution in a different thread too!

```java
@GetMapping(""/blogposts"")
Flux<BlogPost> list() {
	LOG.info(""Received request: BlogPost - List"");
	try {
		return this.blogPostRepository.findAll().log();
	} finally {
		LOG.info(""Request pocessed: BlogPost - List"");
	}
}
```

We can no longer think in terms of a linear execution model where one request is handled by one thread. The reactive streams will be handled by a lot of threads in their lifecycle. This complicates things when we migrate from the old MVC framework. We no longer can rely on thread affinity for things like the security context or transaction handling.

## Slides
<iframe width='770' height='515' src='https://gitpitch.com/idugalic/reactive-company/master?grs=github&t=white' frameborder='0' allowfullscreen></iframe>

## References and further reading

- http://www.reactivemanifesto.org/
- https://www.oreilly.com/ideas/reactive-programming-vs-reactive-systems
- http://www.lightbend.com/blog/the-basics-of-reactive-system-design-for-traditional-java-enterprises
- http://docs.spring.io/spring-framework/docs/5.0.0.BUILD-SNAPSHOT/spring-framework-reference/html/web-reactive.html
- https://spring.io/blog/2016/06/07/notes-on-reactive-programming-part-i-the-reactive-landscape
- https://spring.io/blog/2016/06/13/notes-on-reactive-programming-part-ii-writing-some-code
- http://www.ducons.com/blog/tests-and-thoughts-on-asynchronous-io-vs-multithreading
- https://www.ivankrizsan.se/2016/05/06/introduction-to-load-testing-with-gatling-part-4/
- https://dzone.com/articles/functional-amp-reactive-spring-along-with-netflix
- [asynchronous and non-blocking IO](http://blog.omega-prime.co.uk/?p=155)
- [Functional and Reactive Spring with Reactor and Netflix OSS](https://dzone.com/articles/functional-amp-reactive-spring-along-with-netflix)
- https://www.youtube.com/watch?v=rdgJ8fOxJhc
- https://speakerdeck.com/sdeleuze/functional-web-applications-with-spring-and-kotlin
"
Rapter1990/springbootmicroservicedailybuffer,master,55,26,2022-12-16T21:39:46Z,1213,1,"Spring Cloud Example (API Gateway, Zipkin, Redis, Authentication, Config Server, Docker, Kubernetes )",api-gateway config-server docker docker-compose eureka-server java jenkins jenkinsfile junit kubernetes microservice mysql postman-collection redis resillience4j services spring-boot spring-cloud spring-security zipkin,"# Spring Boot Microservice Example (Eureka Server, Config Server, API Gateway, Services , Zipkin, Redis, Resilience4j, Docker, Kubernetes)

<img src=""screenshots/springbootmicroservice_drawio.png"" alt=""Main Information"" width=""800"" height=""500"">

# About the project
<ul style=""list-style-type:disc"">
  <li>This project is based Spring Boot Microservices with the usage of Docker and Kubernetes</li>
  <li>User can register and login through auth service by user role (ADMIN or USER) through api gateway</li>
  <li>User can send any request to relevant service through api gateway with its bearer token</li>
</ul>

7 services whose name are shown below have been devised within the scope of this project.

- Config Server
- Eureka Server
- API Gateway
- Auth Service
- Order Service
- Payment Service
- Product Service

### Docker Hub
<a href=""https://hub.docker.com/search?q=noyandocker"">Link</a>

### Git Backend for Config server
<a href=""https://github.com/Rapter1990/springappconfig"">Link</a>

### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Valid Request Body</th>
      <th>Valid Request Params</th>
      <th>Valid Request Params and Body</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>authenticate/signup</td>
      <td>Signup for User and Admin</td>
      <td><a href=""README.md#signup"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>authenticate/login</td>
      <td>Login for User and Admin</td>
      <td><a href=""README.md#login"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>authenticate/refreshtoken</td>
      <td>Refresh Token for User and Admin</td>
      <td><a href=""README.md#refreshtoken"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>/product</td>
      <td>Add Product</td>
      <td><a href=""README.md#addproduct"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>/product/{product_id}</td>
      <td>Get Product By Id</td>
      <td></td>
      <td></td>
      <td><a href=""README.md#getProductById"">Info</a></td>
  </tr>
  <tr>
      <td>PUT</td>
      <td>/reduceQuantity/{product_id}?quantity={quantity_value}</td>
      <td>Reduce Quantity of Product</td>
      <td></td>
      <td><a href=""README.md#reduceQuantityOfProduct"">Info</a></td>
      <td></td>
  </tr>
  <tr>
      <td>DELETE</td>
      <td>/product/{product_id}</td>
      <td>Delete Prodcut By Id</td>
      <td></td>
      <td></td>
      <td><a href=""README.md#deleteProductById"">Info</a></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>/order/placeorder</td>
      <td>Place Order</td>
      <td><a href=""README.md#placeOrder"">Info</a></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>/order/{order_id}</td>
      <td>Get Order By Id</td>
      <td></td>
      <td></td>
      <td><a href=""README.md#getOrderById"">Info</a></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>/payment/order/{order_id}</td>
      <td>Get Payment Details by Order Id</td>
      <td></td>
      <td></td>
      <td><a href=""README.md#getPaymentDetailsByOrderId"">Info</a></td>
  </tr>

</table>

### Used Dependencies
* Core
    * Spring
        * Spring Boot
        * Spring Boot Test (Junit)
        * Spring Security
        * Spring Web
            * RestTemplate
            * FeighClient
        * Spring Data
            * Spring Data JPA
        * Spring Cloud
            * Spring Cloud Gateway Server
            * Spring Cloud Config Server
            * Spring Cloud Config Client
    * Netflix
        * Eureka Server
        * Eureka Client
* Database
    * Mysql
* Redis
* Zipkin
* Docker
* Kubernetes
* Jenkins
* Junit
* Log4j2

## Valid Request Body

##### <a id=""signup""> Signup for User and Admin
```
    http://localhost:9090/authenticate/signup
    
    {
        ""username"" : ""User"",
        ""password"" : ""User"",
        ""email"" : ""user@refreshtoken.com"",
        ""roles"" : [
                ""ROLE_USER""
        ]
    }
    
    http://localhost:9090/authenticate/signup
    
    {
        ""username"" : ""admin1"",
        ""password"" : ""admin1"",
        ""email"" : ""admin1@refreshtoken.com"",
        ""roles"" : [
                ""ROLE_ADMIN""
        ]
    }
```

##### <a id=""login""> Login for User and Admin
```
    http://localhost:9090/authenticate/login
    
    {
        ""username"" : ""User"",
        ""password"" : ""User""
    }
    
    http://localhost:9090/authenticate/login
    
    {
        ""username"" : ""UserAdmin"",
        ""password"" : ""UserAdmin""
    }
```

##### <a id=""refreshtoken""> Refresh Token for User and Admin
```
    http://localhost:9090/authenticate/refreshtoken
    
    {
        ""refreshToken"" : """"
    }
```

##### <a id=""addProduct""> Add Product
```
    http://localhost:9090/product
    
    {
        ""name"" : ""Product 1"",
        ""price"" : 100,
        ""quantity"" : 1
    }
    
    Bearer Token : User Token
```

##### <a id=""placeorder""> Place Order
```
    http://localhost:9090/order/placeorder
    
    {
        ""productId"" : 1,
        ""totalAmount"" : 100,
        ""quantity"" : 1,
        ""paymentMode"" : ""CASH""
    }
    
    Bearer Token : User Token
```

## Valid Request Params

##### <a id=""reduceQuantityOfProduct"">Reduce Quantity of Product
```
    http://localhost:9090/product/reduceQuantity/1?quantity=1
    
    Bearer Token : User Token
```

## Valid Request Params and Body

##### <a id=""getProductById"">Get Product By Id
```
    http://localhost:9090/product/{prodcutId}
    
    Bearer Token : User Token
```

##### <a id=""deleteProductById"">Delete Product By Id
```
    http://localhost:9090/product/{prodcutId}
    
    Bearer Token : Admin Token
```

##### <a id=""deleteProductById"">Delete Product By Id
```
    http://localhost:9090/order/{order_id}
    
    Bearer Token : User Token
```

##### <a id=""getPaymentDetailsByOrderId"">Get Payment Details by Order Id
```
    http://localhost:9090/payment/order/{order_id}
    
    Bearer Token : User Token
```

### 🔨 Run the App

<b>Local</b>

<b>1 )</b> Download your project from this link `https://github.com/Rapter1990/springbootmicroservicedailybuffer`

<b>2 )</b> Go to the project's home directory :  `cd springbootmicroservicedailybuffer`

<b>3 )</b> Run <b>Service Registry (Eureka Server)</b>

<b>4 )</b> Run <b>config server</b>

<b>5 )</b> Run <b>zipkin</b> and <b>redis</b> through these commands shown below on <b>Docker</b>
```
    docker run -d -p 9411:9411 openzipkin/zipkin
    docker run -d --name redis -p 6379:6379 redis
```

<b>6 )</b> Run <b>api gateway</b>

<b>7 )</b> Run other services (<b>auth-service</b>, <b>orderservice</b>, <b>paymentservice</b> and lastly <b>productservice</b>)

<b>Docker</b>

<b>1 )</b> Install <b>Docker Desktop</b>. Here is the installation <b>link</b> : https://docs.docker.com/docker-for-windows/install/

<b>2 )</b> Build <b>jar</b> file for all services shown below

<table style=""width:100%"">
  <tr>
    <th>Service</th>
    <th>Command</th>
  </tr>
  <tr>
    <td>service-registry</td>
    <td>mvn clean install</td>
  </tr>
  <tr>
    <td>configserver</td>
    <td>mvn clean install</td>
  </tr>
  <tr>
    <td>apigateway</td>
    <td>mvn clean install -DskipTests</td>
  </tr>
  <tr>
    <td>auth-service</td>
    <td>mvn clean install -DskipTests</td>
  </tr>
  <tr>
    <td>orderservice</td>
    <td>mvn clean install -DskipTests</td>
  </tr>
  <tr>
    <td>productservice</td>
    <td>mvn clean install -DskipTests</td>
  </tr>
  <tr>
    <td>paymentservice</td>
    <td>mvn clean install -DskipTests</td>
  </tr>
</table>

<b>3 )</b> Build all <b>images</b> and push to <b>Docker Hub</b>
```
    1 ) service-registry
     
        - docker build -t microservicedailybuffer/serviceregistry:0.0.1 .
        - docker tag microservicedailybuffer/serviceregistry:0.0.1 noyandocker/serviceregistry
        - docker push noyandocker/serviceregistry
        
    2 ) configserver
     
        - docker build -t microservicedailybuffer/configserver:0.0.1 .
        - docker tag microservicedailybuffer/configserver:0.0.1 noyandocker/configserver
        - docker push noyandocker/configserver
    
    3 ) api-gateway
     
        - docker build -t microservicedailybuffer/apigateway:0.0.1 .
        - docker tag microservicedailybuffer/apigateway:0.0.1 noyandocker/apigateway
        - docker push noyandocker/apigateway
    
    4 ) auth-service
     
        - docker build -t microservicedailybuffer/authservice:0.0.1 
        - docker tag microservicedailybuffer/authservice:0.0.1 noyandocker/authservice
        - docker push noyandocker/authservice
        
    5 ) productservice
     
        - docker build -t microservicedailybuffer/productservice:0.0.1 .
        - docker tag microservicedailybuffer/productservice:0.0.1 noyandocker/productservice
        - docker push noyandocker/productservice
        
    6 ) orderservice
     
        - docker build -t microservicedailybuffer/orderservice:0.0.1 .
        - docker tag microservicedailybuffer/orderservice:0.0.1 noyandocker/orderservice
        - docker push noyandocker/orderservice
        
    7 ) paymentservice
     
        - docker build -t microservicedailybuffer/paymentservice:0.0.1 .
        - docker tag microservicedailybuffer/paymentservice:0.0.1 noyandocker/paymentservice
        - docker push noyandocker/paymentservice
```

<b>4 )</b> Run all <b>Containers</b> through this command shown below under main folder
```
    docker-compose up -d
```
<b>5 )</b> Send request to any service by using request collections under <b>postman_collection</b> 

<b>Kubernetes</b>

<b>1 )</b> Install <b>minikube</b> to access this link https://minikube.sigs.k8s.io/docs/start/

<b>2 )</b> Open <b>command prompt</b> and install <b>kubectl</b> through this command shown below 
```
    minikube kubectl --
```

<b>3 )</b> Start <b>minikube</b> through this command shown below.
```
    minikube start
```

<b>4 )</b> Open <b>minikube dashboard</b> through this command shown below.
```
    minikube dashboard
```

<b>5 )</b> Run all <b>images</b> coming from Docker hub on Kubernetes through this command shown below.
```
    kubectl apply -f k8s
```

<b>6 )</b> Show all information about images running on <b>Kubernetes</b> through this command
```
    kubectl get all
```

<b>7 )</b> Show all <b>services</b> running on Kubernetes through this command
```
    kubectl get services
```

<b>8 )</b> Show <b>eureka server</b> on Kubernetes through this command
```
    minikube service eureka-lb
```

<b>9 )</b> Show <b>api gateway</b> on Kubernetes through this command
```
    minikube service cloud-gateway-svc
```
<b>10 )</b> Copy <b>IP address</b> and Replace <b>it</b> with <b>localhost</b> of the <b>endpoints</b> defined in <b>postman collection</b>


<b>Jenkins</b>

<b>1 )</b> Download <b>jenkins</b> to access this link https://hub.docker.com/r/jenkins/jenkins

<b>2 )</b> Run <b>Jenkins</b> through this command shown below
```
    docker run -p 8080:8080 -p 50000:50000 --restart=on-failure jenkins/jenkins:lts-jdk11
```

<b>3 )</b> Install <b>Jenkins</b> and define <b>username</b> and <b>password</b></b> 

<b>3 )</b> Click <i>New Item</i> and Create pipeline to run Jenkinsfile

<b>4 )</b> Run <b>pipeline</b>


### Screenshots

<details>
<summary>Click here to show the screenshot of project</summary>
    <p> Docker Desktop to show all running containers </p>
    <img src =""screenshots/docker_1.PNG"">
    <p> Docker Hub </p>
    <img src =""screenshots/docker_2.PNG"">
    <p> Kubernetes Dashboard </p>
    <img src =""screenshots/kubernetes_screenshot.PNG"">
    <p> Jenkins Figure 1 </p>
    <img src =""screenshots/jenkins_1.PNG"">
    <p> Jenkins Figure 2 </p>
    <img src =""screenshots/jenkins_2.PNG"">
</details>   

"
TimTinkers/Palm,master,54,6,2018-04-13T05:00:05Z,812009,0,A series of examples studying the new game development capabilities ERC-721 objects enable.,,"# Palm

Palm is the continuation of my work on [Galah](https://github.com/TimTinkers/Galah) to explore new and unique game development capabilities that integrating with the Ethereum blockchain can bring. Through the specific use of the [ERC-721](http://erc721.org/) standard for non-fungible assets, Palm considers just what can be accomplished with globally-available trustless game state.

<p float=""left"">
  <img width=""285"" height=""285"" src=""Media/PalmCockatoo.jpg""/>
  <img height=""285"" src=""Media/GalahArchitecture.PNG""/>
</p>

In keeping with the precedent set by Galah, I've named the project after a large Australian parrot.<sup>1</sup>

## Motivation

The multibillion-dollar video game industry is increasingly adopting in-game purchases as an additional revenue source. Such in-game purchases are dubbed ""microtransactions"" and require players spend real-world money to unlock in-game content.<sup>2</sup> Microtransactions are often criticized by players and have resulted in public relations disasters for the companies which implement them.<sup>3</sup> Using the Ethereum blockchain, this project demonstrates a revision to the microtransaction model where players can purchase and truly own their in-game content.<sup>4,5</sup>

Ethereum is one of several blockchains popular among developers for its ability to execute useful code. With Ethereum, this is done using developer-defined ""smart contracts."" A developing standard in Ethereum is the ERC-721 ""non-fungible token"" to unify how contracts represent unique, individually-owned metadata. This standard enables a common ""CryptoObject"" where developers can store any information their applications use. Ethereum users can take irrevocable ownership of these objects and freely trade them with one another.

This project demonstrates techniques by which the [Unreal Engine](https://www.unrealengine.com/en-US/blog), a popular tool for developing video games, can interface with Ethereum contracts. Now developers can use the CryptoObject contracts to represent, sell, and interact with their in-game content. The controversial microtransaction model is altered: players no longer pay to just unlock content restricted to a single game. Instead, they attain real ownership. Player-owned content can be exchanged with others or used in multiple games.

**Palm demonstrates how Ethereum empowers the free trade of online game content.**

## Exchange Trust Model

Typically, real-time video games simulate their world using a fixed simulation timestep known as the ""tick rate."" For example, Valve Corporation's popular multiplayer first-person shooter _Counter-Strike: Source_ supports servers with a tick rate of 66Hz.<sup>6</sup> That is, the game servers update state 66 times per second. Game logic, physics simulations, and player input signals are all processed in frequent, discrete time quanta. These state updates are decoupled from the client-side rendering frame rate, allowing for smooth rendering to be maintained across a variety of tick rates.

Real-time games can update their state more frequently than transaction times for Ethereum can currently support. The all-time peak transaction rate for the Ethereum network was 15.6 transactions per second.<sup>7</sup> Even games with less frequent tick rates like Epic Games' _Fortnite_ outpace this peak transaction rate.<sup>8</sup>

It is currently infeasible for a real-time game to track and update its state directly on Ethereum, even if its tick rate was dramatically reduced. The time it takes to interact with Ethereum and wait for a miner to commit a state update transaction to the chain is variable. A fixed tick rate is not currently possible to maintain, which makes processing logic, physics, and input much more difficult. Lastly, operating the game server would require constantly burning gas for small, short-lived updates and would be very costly.

Clearly, traditional servers are more appropriate than Ethereum for handling the frequent game state updates required to simulate a multiplayer game. What role then, if any, can Ethereum play in video games?

|![A hybrid trust model.](Media/opt_in.gif)|
|:-:|
|A hybrid trust model similar to a cryptocurrency exchange can overcome many scalability issues.|

The contracts, web server, and interface shown used in the following demonstration are available in the [GameExchangeContract](https://github.com/TimTinkers/Palm/tree/master/GameExchangeContract) folder of this repository. The interface shown above is a simple page using [web3.js](https://github.com/ethereum/web3.js/) to read state from and interact with a deployed instance of my [GameExchange](https://github.com/TimTinkers/Palm/blob/master/GameExchangeContract/contracts/GameExchange.sol) contract.

The solution that Palm explores is a hybrid trust model where players can opt into and out of object modification from a centralized authority under the control of a game's developers. Instead of a game interacting with a player's on-chain objects in real time, the game can track state changes off-chain on a traditional server. Updates are only committed to the blockchain periodically.

This model is very similar to how large cryptocurrency exchanges operate: when users hold cryptocoins on an exchange, they typically don't own them on-chain. Instead, the off-chain cryptocoin accounting is centralized entirely on the exchange's servers. This model suffers from centralization in that users don't actually fully own their coins until withdrawing from the exchange to another wallet. However, the model benefits from being able to update its off-chain reckoning of state quicker and cheaper than interacting with the blockchain would allow.

When the player opts an object into modification, as they are shown doing above, they are consciously trusting the game authority to manage state updates to that object appropriately. A malicious or faulty game authority could manipulate the metadata of the object such that it destroys whatever value the object might have held. A malicious cryptocurrency exchange could steal coins in much the same fashion. When the player opts an object out of modification, they lock its state such that not even the game authority can manipulate it.

|![An example game.](Media/gameplay.gif)|
|:-:|
|Palm's example game is a simple shooting gallery where the player's high-scoring gun is tokenized.|

To demonstrate this model in action, Palm includes a simple game which tracks a player's high scores per gun as ERC-721 objects. The game includes a client built in the Unreal Engine and a separate Java server for interacting with the exchange contracts. The Unreal Engine client assets are available in the [TargetShootProject](https://github.com/TimTinkers/Palm/tree/master/TargetShootProject) folder of this repository. The Java server is available in the [TargetShootServer](https://github.com/TimTinkers/Palm/tree/master/TargetShootServer) folder.

The player is locked to a small shooting area and given a gun. The gun displays its all-time high score, which is recorded in a corresponding ERC-721 record. After the player shoots the red cube to trigger the start of a match, they have 30 seconds to shoot as many red popup figures as they can while avoiding green figures. The server tracks the player's score and updates the gun's display when new high scores are achieved.

After 30 seconds, the round ends and the server sees if the player has set a new record. Only then is the player's gun object, if they have opted for object modification, updated with the new high score. During the course of a match, all communication is directly between the Unreal Engine and the Java server. The gas and time costs of transacting with the blockchain are avoided until the player is done playing.

<p align=""center"">
  <img src=""Media/new_highscore.PNG""/>
</p>

Taking a look back at the web interface, we can see that the server authority has modified the player's gun object to include the new high score. While this simple game trusts the client, in practice the game server would exist [separately from the client](https://gafferongames.com/post/what_every_programmer_needs_to_know_about_game_networking/) as a remote authority. The game authority would modify the player's gun object from a separate machine with separately signed transactions, preventing players from cheating.<sup>9</sup>

|![The previous high score is saved, and the new one can overwrite it.](Media/score_updated.gif)|
|:-:|
|The previous high score is retrievable from Ethereum and can be modified by the server when needed.|

The example above shows a player entering the game again for another match. Their previous high score persisted on the blockchain between their play attempts. In this gameplay clip, once the player surpasses their old high score, the gun object begins updating with the score value tracked on the remote centralized server. When the match ends, the newer high score is committed to the blockchain.

|![The newer high-score and opting out.](Media/newer_highscore.gif)|
|:-:|
|Showing the even-higher high score from the second round, as well as the user opting-out.|

The player, satisfied with the high score of 19, chooses to opt out of object modification. This is a precautionary step to prevent the game authority from altering the player's high score on that gun object. In practice, because players must pay a small gas cost in transacting with Ethereum to opt into and out of object modification, likely player behavior will be to just fully trust the game authority to behave and remain opted in at all times.

The player might also be opting out in order to trade their gun object to someone. Exchanging objects actually requires the object to be opted out of modification. Palm has made this design decision in order to prevent sold objects from being modified without the buyer's consent; players can only transfer objects which are opted-out of modification. This model allows the buyer to know for certain that whatever object they purchase will be theirs in exactly the same state it was sold in. The edge-case where a buyer sees their recently-purchased item change because the seller is still playing with it has been handled.

## Using Objects in Multiple Games

One interesting use case of blockchain-based objects in games is the ability to seamlessly share objects between multiple games. One could imagine a situation where a player's [$28,000 of virtual hats](https://www.pcgamesn.com/tf2/28000-team-fortress-2-backpack) could be worn by characters across many different games. Player ownership of these collectable items becomes far more tangible: not only can they be made certifiably unique, but the objects also won't disappear even if the game they come from does. Their value can outlive the reason why they were originally purchased, and objects can find fresh life in newer titles.

Blockchain-backed ERC-721 objects can also be used to represent a player's identity and statistics as they move from one game to another. Maybe a player's skill in _Counter-Strike_ automatically entitles them to a higher rank in the next _Battlefield_ game. This raises an especially important point: the ERC-721 objects can be used by multiple games even if they don't have the same development team or same access to the modification authority. That is, every developer has read-access to a game's objects and can use that in their own game, even if they are unable to write to the object.

|![An entirely different game using the same gun object.](Media/guessing_game.gif)|
|:-:|
|An entirely different game without modification authority can read objects from other games.|

In the [GuessingGame](https://github.com/TimTinkers/Palm/tree/master/GuessingGame) folder, Palm includes a simple Java game which communicates with the deployed GameExchange contract. The guessing game generates a random number between 0 and 100 and the player has a limited number of guesses to find the number. The player is given notice if they guess near the actual number.

The guessing game is not a modifying authority to the TargetShootProject's gun objects. The guessing game does, however, use its read access to pull the player's high score from one of their player-specified owned gun objects. The number of guesses a player is given is equal to the high score they were able to achieve with their chosen guessing gun. While this is an extremely simple example, it does show what kind of interesting cross-game interactions can emerge from using this standard.

## Trustless Economy

Given how commonplace microtransactions are in modern games, it is clear that game developers want to monetize their in-game economies to produce an additional source of revenue. Developers want to do so in a manner which is guaranteed to be tamper-proof.

In-game currencies are prone to abuse when players exploit unknown bugs. Electronic Arts' failure to secure the in-game currency of their _FIFA_ series allowed it to be freely duplicated by players. One player, Ricky Miller, was actually prosecuted and plead guilty to conspiracy to commit fraud after [duplicating $16M worth of FIFA coins](https://www.theregister.co.uk/2017/05/02/video_game_hacker_probation/).<sup>11</sup> In the face of concerted effort by players to exploit bugs in a game's trading and currency system, developers are incentivized to use a blockchain like Ethereum for its proven security.

Another concern for game developers where valuable virtual items are involved is legal liability surrounding what players choose to do with those objects on your platform. Valve Corporation, for example, briefly had to deal with lawsuits regarding [illegal skin gambling](https://esportsobserver.com/class-action-lawsuit-blaming-valve-illegal-skin-gambling-refiled-district-court/) on their platform. In their popular game _Counter-Strike: Global Offensive_, players can decorate their weapons with colorful ""skins."" Some of these skins are extremely rare and valuable. Players were using the in-game trading functionality to gamble valuable skins on the outcome of professional _Counter-Strike_ matches.<sup>12</sup> Valve's liability concerns were how responsible they were for the illegal activity of players using their trade platform.

For developers using a public blockchain like Ethereum as the platform for executing all transfers of in-game objects between players, the liability concerns seem diminished _(Tim Clancy is not a lawyer)_. If players choose to gamble with the ERC-721 records from your game, you have no way to stop them. They could build out their own infrastructure on Ethereum and the gambling behavior would exist in a format that you provably have no control over.

## Interactions in the Trustless Economy

This section of the project observes the possible interactions between ERC-721 object exchanges for two competing games. It deals specifically with two instances of the GameExchange contract deployed live to the Ropsten test network, [""GameExchange""](https://ropsten.etherscan.io/address/0x5e469871e80474e231af5c252471b6d6817fc990) and [""RivalExchange""](https://ropsten.etherscan.io/address/0x09099905e4f5e8383ee33b843eeea014be4f8037). The destruction of objects from one exchange in facilitating the creation of objects on another is handled by the [deployed ""SwapAndBurn""](https://ropsten.etherscan.io/address/0x6e6af08a1fa2fd0837dbdd01448c8ec36f63ec29) contract whose source is available [here](https://github.com/TimTinkers/Palm/blob/master/GameExchangeContract/contracts/SwapAndBurn.sol). The goal is to demonstrate how developers from one exchange can interfere with objects on another exchange.

In this scenario, developers from team A operate ""GameExchange"" and serve objects for their game. Developers from team B setup ""RivalExchange,"" another ERC-721 object registry, and want to entice users away from team A's game. To that end, team B sets up the ""SwapAndBurn"" contract. This contract allows a player on team A's ""GameExchange"" to destroy one of their objects in return for a free object on team B's ""RivalExchange."" Team B hopes that by encouraging team A's players to destroy their objects, they can disrupt the gameplay or economy surrounding team A's game.

|![Two exchanges.](Media/trade1.png)|![Minting object.](Media/trade2.png)|![Confirming mint.](Media/trade3.png)|
|:-:|:-:|:-:|
|Two exchanges.|Minting object.|Confirming mint using MetaMask: I am locally the exchange authority.|

The stills above show the process of requesting that a new object be minted on the first ""GameExchange"" exchange. After specifying the desired metadata, issuing the minting transaction is handled by [MetaMask](https://metamask.io/). Currently I am just freely minting an object for myself, but it is conceivable that developers would put this sort of functionality behind a storefront whereby the player is only given a newly-minted object after paying.

|![Object minted.](Media/trade4.png)|![Requesting approval.](Media/trade5.png)|
|:-:|:-:|
|Object minted.|Requesting approval on the object with a token ID of 2.|

After the object has been successfully minted, we can see the new listing under the ""GameExchange"" as a token with ID of 2 and metadata of ""Second test asset!"" Its name is colored black, as opposed to red for the previously-existing token 0, because it has not been approved for the [deployed ""SwapAndBurn""](https://ropsten.etherscan.io/address/0x6e6af08a1fa2fd0837dbdd01448c8ec36f63ec29) contract to take ownership of. The user who owns token 2 must specifically request that ""SwapAndBurn"" be approved to take ownership later.

This explicit approval step is necessary because the ""SwapAndBurn"" contract must be allowed to take an object away from the player and destroy it before issuing the player a new token on ""RivalExchange."" The player can verify through inspection of the SwapAndBurn contract that there is no risk to this approval step: there is no way by which the SwapAndBurn contract can take ownership over the player's object without also issuing them their new ""RivalExchange"" object.

|![Approval successful.](Media/trade6.png)|![Requesting trade.](Media/trade7.png)|![Trade successful.](Media/trade8.png)|
|:-:|:-:|:-:|
|Approval successful.|Requesting a trade on the object with a token ID of 2.|Trade successful.|

The approval step succeeded, as indicated by token 2's listing turning red. Next, the player requests the trade from ""SwapAndBurn."" This function takes ownership of token 2 as it was approved to do, burns token 2, and then issues a new object to the player. The final still shows that this is successfully the case: ""GameExchange"" has permanently lost an object while the player has redeemed the newly-minted ""RivalExchange"" token with ID of 1.

## Conclusion

There are countless creative ways to apply smart contracts and the Ethereum blockchain to the realm of video game development. Blockchains provide developers with an avenue for persistent data storage, secure trade platforms, and a new avenue to monetize content. The use of a standarized ERC-721 object enables unprecedented cross-game interactions. Games can interact with each other's data even among different development teams. Ethereum is empowering game developers, and Palm has barely scratched the surface.

## References
The following resources are important references for the information presented in this project:
1. The Palm Cockatoo image is the work of [Reg Mckenna](https://www.flickr.com/photos/whiskymac/), released [CC BY 2.0](https://creativecommons.org/licenses/by/2.0/).
2. Davidovici-Nora, M.: Paid and Free Digital Business Models Innovations in the Video Game Industry. Institut Mines-Telecom, 83-102 (2014).
3. [Most Downvoted Comment](https://www.pcgamer.com/the-most-downvoted-comment-in-reddit-history-is-now-a-star-wars-battlefront-2-mod/), [Electronic Arts](https://www.ea.com/) received massive microtransaction backlash in this [reddit thread](https://www.reddit.com/r/StarWarsBattlefront/comments/7cff0b/seriously_i_paid_80_to_have_vader_locked/).
4. Olsson, B., Sidenblom, L.: Business Models for Video Games. Department of Informatics, Lund University, 5-50 (2010).
5. Švelch, J.: Playing with and against Microtransactions. The Evolution and Social Impact of Video Game Economics. p. 102-120 Lexington Books, London (2017).
6. [Valve Networking Guide](https://developer.valvesoftware.com/wiki/Source_Multiplayer_Networking), an excellent primer on multiplayer game networking with specifics for Valve titles.
7. [Ethereum Transaction Rate](https://etherscan.io/chart/tx), as of 4/25/2018 the rate peaked at 1,349,890 transactions on 1/4/2018.
8. [Battle Royale Tick Rates](https://www.youtube.com/watch?v=u0dWDFDUF8s), an analysis of the tick rates in several multiplayer games of the battle royale genre.
9. [Gaffer On Games](https://gafferongames.com/post/what_every_programmer_needs_to_know_about_game_networking/), an authority on the importance and details of authoritative game networking.
10. [Expensive Team Fortress 2 Backpack](https://www.pcgamesn.com/tf2/28000-team-fortress-2-backpack), real money accrues in game objects, like $28k of virtual hats.
11. [FIFA Coin Heist](https://www.theregister.co.uk/2017/05/02/video_game_hacker_probation/), a group reverse-engineered enough of FIFA to exploit a currency-duplication bug.
12. [Valve Skin Gambling](https://esportsobserver.com/class-action-lawsuit-blaming-valve-illegal-skin-gambling-refiled-district-court/), Valve faced some lawsuits regarding players illegally gambling using their in-game objects.

## Supporting Projects
I'd like to thank the following guides, tools, and projects which greatly supported the development of Palm:
- [ERC-721](http://erc721.org/), a good primer on the developing Ethereum standard.
- [OpenZeppelin](https://github.com/OpenZeppelin/openzeppelin-solidity), community-produced Solidity developer resources with a proven history of success.
- [Unreal Engine 4](https://www.unrealengine.com/en-US/blog), the Unreal Engine is a free high-quality game and physics engine.
- [Ethereum JavaScript API](https://github.com/ethereum/web3.js/), web3.js provides the wrappers needed to integrate with smart contracts on the web interface.
- [The Online ABI Encoding Tool by HashEx](https://abi.hashex.org/), to convert constructor parameters to ABI encoding for verification.
- [Etherscan](etherscan.io), for providing an easy interface to validate deployment and contract state.
- [JavaScript Promises in Web3](http://shawntabrizi.com/crypto/making-web3-js-work-asynchronously-javascript-promises-await/), this article provides an overview on converting Web3 calls to Promises seamlessly.
- [MetaMask](https://metamask.io/), a browser add-on which lets one interact with Ethereum without a full node.
- [Truffle](https://github.com/trufflesuite/truffle), a development environment, testing framework and asset pipeline for Ethereum.
- [Infura](https://infura.io/), a gateway for cloud-hosted Ethereum nodes.
- [Web3j](https://web3j.io/), a lightweight, reactive, type-safe Java and Android library for integrating with nodes on Ethereum blockchains.
- [LowEntry Socket Connection](https://www.unrealengine.com/marketplace/low-entry-socket-connection), a useful networking plugin for the Unreal Engine with native Java integration.
- [json-simple](https://github.com/fangyidong/json-simple), a simple and fast JSON parser.
- [solc-js](https://github.com/ethereum/solc-js), JavaScript Solidity compiler bindings used here to create the Java contract wrapper.
- The generous support of the Berkman Fund for Undergraduate Innovation at Penn Engineering.
"
PauloGaldo/telegram-bot,master,31,17,2017-04-29T17:41:30Z,119,0,Spring Boot Java Example for the Telegram Bot API,,
fuinorg/ddd-cqrs-4-java-example,master,148,38,2019-04-23T07:18:40Z,1277,3,"Example Java DDD/CQRS/Event Sourcing microservices with Quarkus, Spring Boot and EventStore from Greg Young.",,"# ddd-cqrs-4-java-example
Example Java DDD/CQRS/Event Sourcing microservices with [Quarkus](https://quarkus.io/), [Spring Boot](https://spring.io/projects/spring-boot/) and the [EventStore](https://eventstore.org/) from Greg Young. The code uses the lightweight [ddd-4-java](https://github.com/fuinorg/ddd-4-java) and [cqrs-4-java](https://github.com/fuinorg/cqrs-4-java) libaries. No special framework is used except the well known JEE/Spring standards.

[![Java Development Kit 17](https://img.shields.io/badge/JDK-17-green.svg)](https://openjdk.java.net/projects/jdk/17/)
[![Apache](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Build Status](https://github.com/fuinorg/ddd-cqrs-4-java-example/actions/workflows/maven.yml/badge.svg)](https://github.com/fuinorg/ddd-cqrs-4-java-example/actions/workflows/maven.yml)

## Background
This application shows how to implement [DDD](https://en.wikipedia.org/wiki/Domain-driven_design), [CQRS](https://en.wikipedia.org/wiki/Command%E2%80%93query_separation) and [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) without a DDD/CQRS framework. It uses just a few small libraries in addition to  standard web application frameworks like [Quarkus](https://quarkus.io/) and [Spring Boot](https://spring.io/projects/spring-boot/).

If you are new to the DDD/CQRS topic, you can use these mindmaps to find out more: 
- [DDD Mindmap](https://www.mindmeister.com/de/177813182/ddd)
- [CQRS Mindmap](https://www.mindmeister.com/de/177815383/cqrs)

Here is an overview of how such an application looks like: 

[![Overview](https://raw.github.com/fuinorg/ddd-cqrs-4-java-example/master/doc/cqrs-overview-small.png)](doc/cqrs-overview.png)

## Components
- **[Shared](shared)** - Common code for all demo applications (commands, events, value objects and utilities).
- **[Aggregates](aggregates)** - DDD related code for all demo applications (aggregates, entities and business exceptions).
- **[Quarkus](quarkus)** - Two microservices (Command & Query) based on [Quarkus](https://quarkus.io/).
- **[Spring Boot](spring-boot)** - Two microservices (Command & Query) based on [Spring Boot](https://spring.io/projects/spring-boot/).

## Getting started
The following instructions are tested on Linux (Ubuntu 22)

**CAUTION:** Building and running on Windows will require some (small) changes.

### Prerequisites
Make sure you have the following tools installed/configured:
* [git](https://git-scm.com/) (VCS)
* [Docker CE](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/)
* [Docker Compose](https://docs.docker.com/compose/)
* *OPTIONAL* [GraalVM](https://www.graalvm.org/)
* Hostname should be set in /etc/hosts (See [Find and Change Your Hostname in Ubuntu](https://helpdeskgeek.com/linux-tips/find-and-change-your-hostname-in-ubuntu/) for more information)

### Clone and install project 
1. Clone the git repository
   ```
   git clone https://github.com/fuinorg/ddd-cqrs-4-java-example.git
   ```
2. Change into the project's directory and run a Maven build
   ```
   cd ddd-cqrs-4-java-example
   ./mvnw install
   ```
   Be patient - This may take a while (~5 minutes) as all dependencies and some Docker images must be downloaded and also some integration tests will be executed.
   
### Start Event Store and Maria DB (Console window 1)
Change into the project's directory and run Docker Compose
```
cd ddd-cqrs-4-java-example
docker-compose up
```

### Start command / query implementations
Start one query service and then one command service.
You can mix Quarkus & Spring Boot if you want to!

#### Quarkus Microservices

##### Quarkus Query Service (Console window 2)
1. Start the Quarkus query service:
   ```
   cd ddd-cqrs-4-java-example/quarkus/query
   ./mvnw quarkus:dev
   ```
2. Opening [http://localhost:8080/](http://localhost:8080/) should show the query welcome page

For more details see [quarkus/query](quarkus/query).

##### Quarkus Command Service (Console window 3)
1. Start the Quarkus command service:   
   ```
   cd ddd-cqrs-4-java-example/quarkus/command
   ./mvnw quarkus:dev
   ```
2. Opening [http://localhost:8081/](http://localhost:8081/) should show the command welcome page

For more details see [quarkus/command](quarkus/command).

#### Spring Boot Microservices

##### Spring Boot Query Service (Console window 2)
1. Start the Spring Boot query service:   
   ```
   cd ddd-cqrs-4-java-example/spring-boot/query
   ./mvnw spring-boot:run
   ```
2. Opening [http://localhost:8080/](http://localhost:8080/) should show the query welcome page

For more details see [spring-boot/query](spring-boot/query).

##### Spring Boot Command Service (Console window 3)
1. Start the Spring Boot command service:   
   ```
   cd ddd-cqrs-4-java-example/spring-boot/command
   ./mvnw spring-boot:run
   ```
2. Opening [http://localhost:8081/](http://localhost:8081/) should show the command welcome page

For more details see [spring-boot/command](spring-boot/command).

### Verify projection and query data
1. Open [http://localhost:2113/](http://localhost:2113/) to access the event store UI (User: admin / Password: changeit)
   You should see a projection named ""qry-person-stream"" when you click on ""Projections"" in the top menu.
2. Opening [http://localhost:8080/persons](http://localhost:8080/persons) should show an empty JSON array

### Execute some create commands (Console window 4)
Change into the demo directory and execute the command using cURL (See [shell script](demo/create-persons.sh) and JSON files with commands in [demo](demo)) 
```
cd ddd-cqrs-4-java-example/demo
./create-persons.sh
```   
Command service (Console window 3) should show something like
```
Update aggregate: id=PERSON 954177c4-aeb7-4d1e-b6d7-3e02fe9432cb, version=-1, nextVersion=0
Update aggregate: id=PERSON 568df38c-fdc3-4f60-81aa-d3cce9ebfd7b, version=-1, nextVersion=0
Update aggregate: id=PERSON 84565d62-115e-4502-b7c9-38ad69c64b05, version=-1, nextVersion=0
```   
Query service (Console window 2) should show something like
```
Handle PersonCreatedEvent: Person 'Harry Osborn' (954177c4-aeb7-4d1e-b6d7-3e02fe9432cb) was created
Handle PersonCreatedEvent: Person 'Mary Jane Watson' (568df38c-fdc3-4f60-81aa-d3cce9ebfd7b) was created
Handle PersonCreatedEvent: Person 'Peter Parker' (84565d62-115e-4502-b7c9-38ad69c64b05) was created
```    

### Verify the query data was updated
1. Refreshing [http://localhost:8080/persons](http://localhost:8080/persons) should show
    ```json
    [
       {
           ""id"": ""568df38c-fdc3-4f60-81aa-d3cce9ebfd7b"",
           ""name"": ""Mary Jane Watson""
       },
       {
           ""id"": ""84565d62-115e-4502-b7c9-38ad69c64b05"",
           ""name"": ""Peter Parker""
       },
       {
           ""id"": ""954177c4-aeb7-4d1e-b6d7-3e02fe9432cb"",
           ""name"": ""Harry Osborn""
       }
    ]
    ```
2. Opening [http://localhost:8080/persons/84565d62-115e-4502-b7c9-38ad69c64b05](http://localhost:8080/persons/84565d62-115e-4502-b7c9-38ad69c64b05) should show
    ```json
    {""id"":""84565d62-115e-4502-b7c9-38ad69c64b05"",""name"":""Peter Parker""}
3. The event sourced data of the person aggregate could be found in a stream named [PERSON-84565d62-115e-4502-b7c9-38ad69c64b05](http://localhost:2113/web/index.html#/streams/PERSON-84565d62-115e-4502-b7c9-38ad69c64b05)

### Execute a delete command (Console window 4)
Change into the demo directory and execute the command using cURL (See [shell script](demo/create-persons.sh) and JSON files with commands in [demo](demo))
```
cd ddd-cqrs-4-java-example/demo
./delete-harry-osborn.sh
```   
### Verify the query data was updated
1. Refreshing [http://localhost:8080/persons](http://localhost:8080/persons) should show
    ```json
    [
       {
           ""id"": ""568df38c-fdc3-4f60-81aa-d3cce9ebfd7b"",
           ""name"": ""Mary Jane Watson""
       },
       {
           ""id"": ""84565d62-115e-4502-b7c9-38ad69c64b05"",
           ""name"": ""Peter Parker""
       }
    ]
    ```
    ""Harry Osborn"" should no longer be present in the list.

### Stop Event Store and Maria DB and clean up
1. Stop Docker Compose (Ubuntu shortcut = ctrl c)
2. Remove Docker Compose container
   ```   
   docker-compose rm
   ```
"
alblue/com.packtpub.e4,master,56,38,2013-06-05T22:32:41Z,478,1,"Code samples for the Eclipse Plugin Development by Example: Beginners Guide"" book 978-1782160328""",,"Eclipse Plugin Development by Example: Beginner's Guide
=======================================================

This repository contains source code for the Packt Publishing book
""Eclipse Plugin Development by Example: Beginners Guide"". Tags and
branches are available for both versions.

https://www.amazon.co.uk/s/ref=dp_byline_sr_book_1?ie=UTF8&text=Dr+Alex+Blewitt&search-alias=books-uk&field-author=Dr+Alex+Blewitt&sort=relevancerank

Second Edition
--------------

* ISBN-10: 1783980699
* ISBN-13: 978-1-78398-069-7

*Chapters*

Chapter 1: [Creating your first Plug-in](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter1)
Chapter 2: [Creating Views with SWT](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter2)
Chapter 3: [Creating JFace Viewers](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter3)
Chapter 4: [Interacting with the User](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter4)
Chapter 5: [Working with Preferences](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter5)
Chapter 6: [Working with Resources](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter6)
Chapter 7: [Creating Eclipse 4 Applications](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter7)
Chapter 8: [Migrating to Eclipse 4](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter8)
Chapter 9: [Styling Eclipse 4 Applications](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter9)
Chapter 10: [Creating Features, Update Sites, Applications and Products](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter10)
Chapter 11: [Automated Testing of Plug-ins](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter11)
Chapter 12: [Automated Builds with Tycho](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter12)
Chapter 13: [Contributing to Eclipse](https://github.com/alblue/com.packtpub.e4/tree/edition2/chapter13)

First edition
-------------

* ISBN-10: 1782160329
* ISBN-13: 978-1-78216-032-8


Contents
--------

Chapter 1: [Creating your first Plug-in](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter1)
Chapter 2: [Creating Views with SWT](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter2)
Chapter 3: [Creating JFace Viewers](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter3)
Chapter 4: [Interacting with the User](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter4)
Chapter 5: [Storing Preferences and Settings](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter5)
Chapter 6: [Working with Resources](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter6)
Chapter 7: [Understanding the Eclipse 4 Model](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter7)
Chapter 8: [Creating Features, Update Sites, Applications and Products](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter8)
Chapter 9: [Automated Testing of Plug-ins](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter9)
Chapter 10: [Automated Builds with Tycho](https://github.com/alblue/com.packtpub.e4/tree/edition1/chapter10)

Contact
-------

Follow me on Twitter @alblue, or mail alex.blewitt@gmail.com. My blog
is at https://alblue.bandlem.com/

LICENSE
-------

Code examples are licensed under the Eclipse Public License, version 1.0
as contained in the LICENSE.html file
"
blundell/SimpleInAppPurchaseV3,master,49,21,2012-12-18T13:49:00Z,454,2,Simple In App Purchase V3 - an alternative to the Google Example,,"SimpleInAppPurchaseV3
=====================

Simple In App Purchase V3 - an alternative to the Google Example

This uses the Google Helper Service but it has been slightly modified when I found what I deemed a bug. 
The code is incorporated in this project under the android package. 

http://developer.android.com/google/play/billing/billing_integrate.html

*My old tutorial is now DEPRECATED* http://blog.blundell-apps.com/simple-inapp-billing-payment/
"
berndruecker/camunda-7-springboot-amqp-microservice-cloud-example,master,222,137,2017-08-02T19:34:44Z,427,4,"Simple example using Camunda and Spring Boot to define a simple microservice communcating via AMQP, fully unit tested and deployable in the cloud",,"[![Camunda Platform 7](https://img.shields.io/badge/Compatible%20with-Camunda%20Platform%207-26d07c)](https://img.shields.io/badge/Compatible%20with-Camunda%20Platform%207-26d07c)

# Camunda Spring Boot example including REST and AMQP, automated tested and deployable in the cloud

This example shows:

- How to setup Camunda, Spring Boot and various test frameworks correctly in order to work. It can be used as a copy & paste template.
- How to use AMQP and REST in your processes the Spring way.
- How to write proper scenario tests, that test if your process impacts the outer world as you expect (and not tests that Camunda did write a proper workflow engine).
- How this type of application can be easily deployed in the cloud (Pivotal Web Services as an example).

The business example is a very simple order fullfillment microservice (motivated by [the flowing retail example](https://blog.bernd-ruecker.com/flowing-retail-demonstrating-aspects-of-microservices-events-and-their-flow-with-concrete-source-7f3abdd40e53)):

![Example overview](docs/overview.png)

- It is triggered via REST (it could have been an AMQP message or any other trigger as well, just REST is very easy to do demo requests)
- Calls a REST service (actually, the REST service is directly implemented here for simplicity, as I did not want to rely on an external URL)
- Sends a AMQP message and waits for a response. For simplicity, the request message will be directly treated as response

# Embedded engine

With Camunda it is possible to run the engine as part of your application or microservice. This is called [embedded engine](https://docs.camunda.org/manual/latest/introduction/architecture/#embedded-process-engine). This is especially helpful in microservice architectures if you develop in Java, then the engine simply gets a library helping you to define flows with persistent state and subsequent requirements like timeout handling, retrying, compensation and so on. See [Why service collaboration needs choreography AND orchestration](https://blog.bernd-ruecker.com/why-service-collaboration-needs-choreography-and-orchestration-239c4f9700fa) for background reading.

![Embedded engine](docs/embeddedEngine.png)

# Walkthrough as screencast

This video gives a very quick walk through the example (15 minutes):

<a href=""http://www.youtube.com/watch?feature=player_embedded&v=XimowIZLWD8"" target=""_blank""><img src=""http://img.youtube.com/vi/XimowIZLWD8/0.jpg"" alt=""Walkthrough"" width=""240"" height=""180"" border=""10"" /></a>

# Project setup

The project uses

- Spring Boot
- Camunda
- [camunda-bpm-spring-boot-starter](https://github.com/camunda/camunda-bpm-spring-boot-starter/)
- [camunda-bpm-assert-scenario](https://github.com/camunda/camunda-bpm-assert-scenario/)
- [camunda-bpm-assert](https://github.com/camunda/camunda-bpm-assert/)
- [camunda-bpm-process-test-coverage](https://github.com/camunda/camunda-bpm-process-test-coverage/)
- H2 for testing (in-memory) and running it locally (file based)
- PostgreSQL/ElephantDB as cloud storage on Pivotal Web Services

Please have a look at the [pom.xml](pom.xml) for details. Also note the [Application.java](src/main/java/com/camunda/demo/springboot/Application.java) as Spring Boot starter class.


# Configuration of Camunda

With Spring Boot Camunda gets auto-configured using defaults. You can easily change the configuration by providing classes according to the [docs](https://camunda.github.io/camunda-bpm-spring-boot-starter/docs/2.1.2/index.html#_process_engine_configuration). In this example you can see

- [HistoryConfiguration](src/main/java/com/camunda/demo/springboot/conf/CamundaEngineHistoryConfiguration.java) that tells Camunda to save all historic data and audit logs.
- [IdGenerator](src/main/java/com/camunda/demo/springboot/conf/CamundaIdGeneratorConfiguration.java) so that Camunda uses string UUID's instead of database generated ones, which avoids deadlock risks in cluster environments.
- [Plugin to write some events to sysout](src/main/java/com/camunda/demo/springboot/conf/plugin/SendEventListener). This plugin registers a listener to get notified when new workflow instances are started or existing ones are eneded. In this codebase just prints a line on the console, but it would be easy to push the event to some central tracing system. The cool thing: Such a plugin could be packaged in an own Maven depedency, as soon it is on the classpath it will be activated and influence the core engine. 


# Using Camunda Enterprise Edition

The example uses the community edition to allow for a quick start. It is easy to switch dependencies to use the Enterprise Edition as you can see in [this commit](commit/724e3db5f09f1743445c78d84e28d2fa5c0b6005). Just make sure you can connect to the [Camunda Nexus](https://docs.camunda.org/get-started/apache-maven/#camunda-nexus) using your enterprise credentials.

# Testing

One extremly interessting piece is the JUnit test case, which does a complete run-thorugh the process, including all Java code attached to the process, but without sending any real AMQP message or REST request. The timeout of a waiting period in the process is also simulated. 

```java
    StartingByStarter starter = Scenario.run(orderProcess) //
      .startBy(() -> {
        return orderRestController.placeOrder(orderId, 547);
      });
    
    // expect the charge for retrieving payments to be created correctly and return a dummy transactionId
    mockRestServer
        .expect(requestTo(""http://api.example.org:80/payment/charges"")) //
        .andExpect(method(HttpMethod.POST))
        .andExpect(jsonPath(""amount"").value(""547""))
        .andRespond(withSuccess(""{\""transactionId\"": \""12345\""}"", MediaType.APPLICATION_JSON));
    
    when(orderProcess.waitsAtReceiveTask(""ReceiveTask_WaitForGoodsShipped"")).thenReturn((messageSubscription) -> {
      amqpReceiver.handleGoodsShippedEvent(orderId, ""0815"");
    });    

    when(orderProcess.waitsAtTimerIntermediateEvent(anyString())).thenReturn((processInstance) -> {
      processInstance.defer(""PT10M"", () -> {fail(""Timer should have fired in the meanwhile"");}); 
    });
    
    // OK - everything prepared - let's go
    Scenario scenario = starter.execute();
    
    mockRestServer.verify();

    // and very that some things happened
    assertThat(scenario.instance(orderProcess)).variables().containsEntry(ProcessConstants.VARIABLE_paymentTransactionId, ""12345"");
    assertThat(scenario.instance(orderProcess)).variables().containsEntry(ProcessConstants.VAR_NAME_shipmentId, ""0815"");

    {
      ArgumentCaptor<Message> argument = ArgumentCaptor.forClass(Message.class);
      verify(rabbitTemplate, times(1)).convertAndSend(eq(""shipping""), eq(""createShipment""), argument.capture());
      assertEquals(orderId, argument.getValue());
    }

    verify(orderProcess).hasFinished(""EndEvent_OrderShipped"");
```

Refer to the [OrderProcessTest.java](src/main/java/com/camunda/demo/springboot/OrderProcessTest.java) for all details. Note that the test generates a graphical report:

![Test Coverage](docs/testCoverage.png)



# Get started

In order to get started just

* Clone or download this example
* Maven build (this also runs the test cases)
```shell
mvn clean install
```

* Install [RabbitMQ](http://rabbitmq.com/) and start it up

* Run microservice via Java:
```shell
java -jar target/camunda-spring-boot-amqp-microservice-cloud-example-0.0.1-SNAPSHOT.jar
```

Now you can access:

* [Camunda web applications](http://localhost:8080/)
* [REST API for new orders](http://localhost:8080/order)

```
curl --request POST -F 'orderId=1' -F 'amount=500' http://localhost:8080/order
```

* [RabbitMQ Management Console](http://localhost:15672/)

Of course you can also use your favorite IDE.




# Cloud deployment on Pivotal Web Services

You can easily deploy a Spring Boot application to various cloud providers, as you get a fat jar runnable on every JVM. 

And using the [Spring Cloud Connectors](http://cloud.spring.io/spring-cloud-connectors/) the application can be magically wired with cloud resources. 

The example I show here is:
* Deployment on [Pivotal Web Services](https://run.pivotal.io/)
* [ElephantSQL](https://www.elephantsql.com/) as hosted PostgreSQL, started as Service named ```camunda-db```
* [CloudAMPQ](https://www.cloudamqp.com/) as hosted RabbitMQ - started as Service ```cloud-amqp```

All metadata for the deployment are described in the [manifest.yml](manifest.yml):

```
---
applications:
  - name: camunda-spring-boot-amqp-microservice-cloud-example
    memory: 1G
    instances: 1
    random-route: false

services:
  - cloud-amqp
  - camunda-db
```

Now you can easily deploy the application using the [CloudFoundry CLI](https://docs.cloudfoundry.org/cf-cli/). After logging in you can simply type:

```
mvn clean install && cf push -p target/camunda-spring-boot-amqp-microservice-cloud-example-0.0.1-SNAPSHOT.jar
```

There it is, now you can start a process:

```shell
url -X POST -F 'orderId=123' -F 'amount=4990' http://camunda-spring-boot-amqp-microservice-cloud-example.cfapps.io/order
```

And will see it in cockpit:

![Cockpit](docs/cockpit.png)

The URL to access the Camunda web applications and your REST-API depends on various factors, but will be shown via the Pivotal console:

![Test Coverage](docs/pivotalConsole.png)

![Test Coverage](docs/pivotalConsole2.png)
"
msg-DAVID-GmbH/JUnit-5-Quick-Start-Guide-and-Framework-Support,master,39,10,2016-07-21T12:14:59Z,5823,4,JUnit 5 Quick Start Guide and collection of examples for frameworks used in conjunction with JUnit 5,assertion-framework best-practices getting guide java java-8 junit junit-5 junit5 milestones quick quickstart spring-5 start started testing tutorial user user-guide workshop,
Hakky54/mutual-tls-ssl,master,540,120,2018-11-11T19:07:35Z,1382,0,"🔐 Tutorial of setting up Security for your API with one way authentication with TLS/SSL and mutual authentication for a java based web server and a client with both Spring Boot. Different clients are provided such as Apache HttpClient, OkHttp, Spring RestTemplate, Spring WebFlux WebClient Jetty and Netty, the old and the new JDK HttpClient, the old and the new Jersey Client, Google HttpClient, Unirest, Retrofit, Feign, Methanol, vertx, Scala client Finagle, Featherbed, Dispatch Reboot, AsyncHttpClient, Sttp, Akka, Requests Scala, Http4s Blaze, Kotlin client Fuel, http4k, Kohttp and ktor. Also other server examples are available such as jersey with grizzly. Also gRPC, WebSocket and ElasticSearch examples are included",certificate certificate-authority certificate-signing-request encryption https java keystore keytool kotlin mutual-authentication mutual-tls openssl scala security server spring-boot ssl tls truststore two-way-ssl-authentication,
gregwhitaker/springboot-apikey-example,master,70,22,2019-01-20T03:12:25Z,103,1,Example of authenticating with a Spring Boot application using an API key.,api-key caffeine-cache spring-boot spring-security,"# springboot-apikey-example
![Build](https://github.com/gregwhitaker/springboot-apikey-example/workflows/Build/badge.svg)

An example of authenticating with a Spring Boot application using an API key.

If you are looking for an example using WebFlux, please check out [springboot-webflux-apikey-example](https://github.com/gregwhitaker/springboot-webflux-apikey-example).

## Prerequisites
This example requires that you have a running [PostgreSQL](https://www.postgresql.org/) database. You can start one as a Docker container using the following commands:

    $ docker pull postgres
    $ docker run -p 5432:5432 postgres

## Running the Example
Follow the steps below to run the example:

1. Ensure you have a running PostgreSQL instance at `localhost:5432`.

2. Run the following command to start the example application:

        ./gradlew bootRun
        
3. Run the following command to send a request to the non-secure endpoint:

        curl -v http://localhost:8080/api/v1/nonsecure
        
    If successful, you will receive an `HTTP 200 OK` response.
    
4. Run the following command to send a request to the secure endpoint:

        curl -v http://localhost:8080/api/v1/secure
        
    You will receive an `HTTP 403 Forbidden` response because you have not supplied a valid API key.
    
5. Run the following command to send a request to the secure endpoint with an API key:

        curl -v --header ""API_KEY: aec093c2c98144f99a4a365ad1d2f05e"" http://localhost:8080/api/v1/secure
        
    If successful, you will now receive an `HTTP 200 OK` response because you have supplied a valid API key.

## Bugs and Feedback
For bugs, questions, and discussions please use the [Github Issues](https://github.com/gregwhitaker/springboot-apikey-example/issues).

## License
Copyright 2019 Greg Whitaker

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"
xbtlin/thinking-In-Java,master,138,112,2015-12-19T09:33:20Z,419,2,All examples writtern by author of the thinking in java book (4th ). Could run directly in the Idea Intellij or Eclipse. Java编程思想 第四版 所有的示例代码，可直接在Intellij或Eclipse上运行。,,"可以直接pull到Idea Intellij或Eclipse中的Thinking in java第四版书中示例代码。
不含课后习题答案。
"
islomar/seven-concurrency-models-in-seven-weeks,master,92,29,2015-05-03T21:52:01Z,102,0,"Repository for the example code of the book Seven concurrency models in seven weeks"".""",,"# Seven concurrency models in seven weeks
Repository for the example code of the book [""Seven concurrency models in seven weeks""](https://pragprog.com/book/pb7con/seven-concurrency-models-in-seven-weeks).

## Discussions
https://forums.pragprog.com/forums/291

## Errata
https://pragprog.com/titles/pb7con/errata

## Chapter 1
* A **concurrent program** has multiple logical threads of control. These threads may or may not run in parallel.
* A **parallel program** potentially runs more quickly than a sequential program by executing different parts of the computation simultaneously (in parallel).
It may or may not have more than one logical thread of control.

* **Concurrency** is an aspect of the problem domain—your program needs to handle multiple simultaneous (or near-simultaneous) events.
* **Parallelism**, by contrast, is an aspect of the solution domain—you want to make your program faster by processing different portions of the problem in parallel.

* **Concurrency** is about dealing with lots of things at once. **Parallelism** is about doing lots of things at once.

* Concurrent programs are often nondeterministic —they will give different results depending on the precise timing of events. If you’re working on a genuinely concurrent problem, nondeterminism is natural and to be expected.
* Parallelism, by contrast, doesn’t necessarily imply nondeterminism

Although there’s a tendency to think that parallelism means multiple cores, modern computers are parallel on many different levels. The reason why individual cores have been able to get faster every year, until recently, is that they’ve been using all those extra transistors predicted by Moore’s law in parallel, both at the bit and at the instruction level.

### Levels of parallelism
* Bit-level: i.e. 16, 32, 64-bit architectures.
* Instruction-level
* Data parallelism
* Task-level

## Interesting links
### Chapter 1
* Concurrency is not parallelism (it's better): http://concur.rspace.googlecode.com/hg/talk/concur.html#title-slide
"
muhammedsedef/Kafka-Example,master,27,4,2022-11-30T18:05:59Z,14095,0,Kafka Example ,couchbase docker kafka kafka-ui postgresql spring-boot wiremock zookeeper,"# Kafka-Example
In this project, 
- There are 3 microservices, when a user created via user-service that service insert a record onto user table(postgre) 
and it produce an event to **user_service.user_created.0** topic. 
- Notification-consumer service listen **user_service.user_created.0** topic and simulates the logic of sending 
notification after the event it consumes after notification is sending successfully service insert a record onto couchbase
notification bucket.
- User-address-service also listen user_service.user_created.0 topic and it consume events. According to user's address text
information it insert a record onto user-address table(postgre)

## System Architechure
![](images/system_architecture.png)

## Requirements
- [Java 11 JDK](https://www.oracle.com/tr/java/technologies/javase/jdk11-archive-downloads.html)
- [Docker](https://www.docker.com/products/docker-desktop/)
- [Data Grip](https://www.jetbrains.com/datagrip/download/#section=mac) or any other database GUIs
- [Postman](https://www.postman.com/downloads/)

## Setup
- Before run project you need to start docker desktop
- After docker is up, run the docker-compose.yml (You can find it in the infra-setup folder.)
- After the run docker-compose.yml file you will see docker desktop like this: 
![](images/docker_desktop.png)
- Continue With DB Connection Part

## DB Connection
# Postgre Connection:
    url: jdbc:postgresql://localhost:5432/kafka_example
    username: example
    password: example

* After you successfully connect database, you will see like this in datagrip: 
![](images/data_grip.png)

# Couchbase Connection & Settings
- #### Open http://localhost:8091/ on your browser

![](images/couchbase_ui.png)

      username: Administrator
      password: 123456

- #### Open the buckets tab and click the **ADD BUCKET**
![](images/add_bucket.png)

- #### write the bucket name in our example => bucket name is **""notification""**
![](images/add_bucket_to_cluster.png)

- #### After that open the query tab on the left side
![](images/create_index.png)
- #### Run 2 query separately to create index on bucket

      1) CREATE PRIMARY INDEX `idx_default_primary_notification` ON `notification`
      2) CREATE INDEX `id` ON `notification`(`id`)
- #### Open the Security tab on the left side and click the **ADD USER** 
![](images/add_user.png)
- #### After click the add user you will see a new popup and fill the informations like :
      Username: admin
      Full Name: admin
      Password: 123456
      Verify Password: 123456
![](images/admin_user_settings.png)

# Running
- #### Run each project application file on your code ide.
- #### After you run 3 application successfully you can check postgre db on your GUI you have to see created 2 tables which names ara **user** and **user_address**
![](images/created_tables.png)
- #### Check Topic is created or not http://localhost:9090/ (kafka ui)
![](images/kafka_ui.png)
- #### If you have come this far without any problems, we can open postman and try a sample request.
- #### You can import postman collection which I share in postman_collection folder
![](images/postman_request.png)
- #### After execute post endpoint and get 200 success message from postman you can see producer and consumer logs on your running terminal also you can check that records are in your databases  
![](images/success.png)
![](images/db.png)
- #### As you can see our records successfully inserted to our databases
- #### To test batch request use MOCK DATA.json file which it is in postman folder, open the postman runner and select that json file and run.
![](images/open_runner.png)
![](images/run_ep.png)

# Topic Partition Settings
- #### To increase topic partition open http://localhost:9090/ (kafka-ui) and open the topic settings.
![](images/topic_settings.png)
- #### As you can see I set partition count 4
- #### After set partition count 4, now our consumer's will rebalance because now we have 4 partition so our consumers bind all of partitions
![](images/rebalance.png)
- #### If you want to run one more consumer app follow these steps:
![](images/edit_run_configuration.png)
![](images/select_spring_boot.png)
![](images/spring_new_instance_settings.png)
- #### Now you can run one more consumer app, it will up randomly port in your computer's free port because we set server.port as 0 in application.yml
![](images/rebalance_result.png)
- #### As you can see we have 4 partition and we run 4 consumer app (user-address-service) so each consumer app bind 1 partition of user_service.user_created.0 topic
- #### You can run again batch request on postman and you can easily see your consumer apps consume the event corresponding partition 




"
bertilmuth/poem-hexagon,master,35,10,2019-05-16T20:42:56Z,169,0,A simple example for a hexagonal architecture.,clean-architecture event-driven hexagonal-architecture java message-driven,"# introduction
[![Gitter](https://badges.gitter.im/requirementsascode/community.svg)](https://gitter.im/requirementsascode/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)

A simple example for a clean hexagonal architecture.
It contains a use case model and command handlers that control the flow of the application.

The main class is [poem.simple.Main](https://github.com/bertilmuth/poem-hexagon/blob/master/src/main/java/poem/simple/Main.java).

This example is inspired by a [talk](https://www.youtube.com/watch?v=th4AgBcrEHA) by A. Cockburn and T. Pierrain on hexagonal architecture.

A [blog article](https://dev.to/bertilmuth/implementing-a-hexagonal-architecture-1kgf) describes the details.
"
phantasmicmeans/springboot-microservice-with-spring-cloud-netflix,master,37,12,2018-05-05T15:57:24Z,60225,1,msa backend service example with springboot REST API,eureka-client msa rest-api service spring-boot springcloud,"[![HitCount](http://hits.dwyl.io/phantasmicmeans/springboot-microservice-with-spring-cloud-netflix.svg)](http://hits.dwyl.io/phantasmicmeans/springboot-microservice-with-spring-cloud-netflix)

Spring Boot Microservice with Spring Cloud Netflix
==============

*by S.M.Lee*

![image](https://user-images.githubusercontent.com/20153890/41583901-d1e8aa5c-73e0-11e8-97ff-188fed3cd715.png)


> **NOTE** 
&nbsp;

> - 여기서는 MSA에서의 Service중 하나인 Notice Service를 구축하여 본다.
> - Notice Service는 간단한 REST API Server로 구성되고, Spring Cloud Netflix의 여러 component들을 활용한다. 
> - Notice Service는 Spring boot Project로 구현된다. 생성된 JAR파일을 Docker container로 띄워 서비스한다.
> - 기존 Spring에서는 Maven, Gradle등의 dependency tool을 이용해 WAR파일을 생성한 후 tomcat같은 WAS에 배포하여
웹 어플리케이션을 구동하였으나, Spring boot는 JAR파일에 내장 tomcat이 존재하여, 단순히 JAR파일을 빌드하고 실행하는 것 만으로 웹 어플리케이션 구동이 가능하다.
> - JPA repository로 DB(MySQL 5.6)에 접근한다.

&nbsp;
&nbsp;

## Service Description ##



**Project directory tree**

    .
    ├── Dockerfile
    ├── mvnw
    ├── mvnw.cmd
    ├── pom.xml
    ├── src/main/java/com/example/demo
    |        |                      ├── AlarmServiceApplication.java   
    |        |                      ├── domain                    
    |        |                      |       └── Notice.java           
    |        |                      ├── repository                        
    |        |                      │       └── NoticeRepository.java         
    |        |                      ├── rest   
    |        |                      │       └──  NoticeController.java         
    |        |                      ├── service
    |        |                               ├── NoticeService.java          
    |        |                               └── NoticeServiceImpl.java      
    │        └── resources
    │           ├── application.yml
    │           └── bootstrap.yml
    └── target
          ├── classes
          ├── notice-service-0.1.0.jar
          ├── notice-service.0.1.0.jar.original
          ├── generated-sources ...


&nbsp;

**Service는 ""Service Register & Discovery"" Server인 Eureka Server의 Client이다.**


진행하기에 앞서 Eureka에 대한 이해가 필요하다. Hystrix는 다음 장에서 다룰 예정이지만, Eureka에 대한 이해는 필수적이다.
하지만 단순히 REST API Server 구축이 목표라면 스킵하고 진행해도 된다.

> - *Netflix의 Eureka에 대한 이해 => https://github.com/phantasmicmeans/Spring-Cloud-Netflix-Eureka-Tutorial/*
> - *Hystrix에 대한 이해  => https://github.com/phantasmicmeans/Spring-Cloud-Netflix-Hystrix/*
> - *Service Registration and Discovery => https://spring.io/guides/gs/service-registration-and-discovery/*
> - *Service Discovery: Eureka Clients =>https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html*

위 reference를 모두 읽고 이 튜토리얼을 진행하면 순탄하게 진행할 수 있을 것이다.

&nbsp;

어쨌든 Eureka Client로 만들어진 Microservice는 Eureka Server(Registry)에 자신의 meta-data(host,port,address 등)를 전송한다. 이로인해 Eureka Client들은 Eureka Registry 정보를 이용해 서로간의 Communication이 가능하다.  

그리고 Eureka Client는 자신이 살아 있음을 알리는 hearbeat를 Eureka Server에 보낸다. Eureka Server는 일정한 시간안에 hearbeat를 받지 못하면 Registry로 부터 Client의 정보를 제거한다.

Eureka Client는 Registry에 자신의 hostname을 등록하게 되는데 이는 DNS 역할을 하며, 추후에 Netflix의 API Gateway에서 Ribbon + Hystrix + Eureka 조합을 적절히 활용하여 편하게 Dynamic Routing 시킬 수 있다. 

큰 개념은 이정도로 이해하고 일단 Server를 구축하고 Eureka Client로 만들어보자.

&nbsp;
&nbsp;
    
## 1. Dependency ##

Eureka Client로 service를 만들기 위해 spring-cloud-starter-netflix-eureka-client dependency를 추가한다. 그리고 hystrix 적용을 위해 hystrix dependency를 추가한다. 그리고 dockerfile-maven-plugin 또한 추가한다. 


**pom.xml**


```xml

 	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>2.0.1.RELEASE</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<java.version>1.8</java.version>
		<maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target> 
        <spring-cloud.version>Finchley.M9</spring-cloud.version>
        <docker.image.prefix>phantasmicmeans</docker.image.prefix>
	</properties>

	<dependencies>
    		<dependency>
        		<groupId>org.springframework.cloud</groupId>
            		<artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
       		</dependency>
        	<dependency>
        		<groupId>org.springframework.cloud</groupId>
            		<artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
        	</dependency>
        	<dependency>
            		<groupId>org.springframework.boot</groupId>
            		<artifactId>spring-boot-starter-actuator</artifactId>
        	</dependency>
		<dependency>
    			<groupId>org.springframework.boot</groupId>
            		<artifactId>spring-boot-starter-web</artifactId>
        	</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-jpa</artifactId>
		</dependency>		
        	<dependency>
      			<groupId>mysql</groupId>
      			<artifactId>mysql-connector-java</artifactId>
            		<version>5.1.21</version>
        	</dependency>        
        	<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
    	</dependencies>

	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>org.springframework.cloud</groupId>
				<artifactId>spring-cloud-dependencies</artifactId>
				<version>${spring-cloud.version}</version>
				<type>pom</type>
				<scope>import</scope>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
			</plugin>	
           		 <plugin>
                		<groupId>com.spotify</groupId>
                		<artifactId>dockerfile-maven-plugin</artifactId>
                		<version>1.3.6</version>
                		<configuration>
                    		<repository>${docker.image.prefix}/${project.artifactId}</repository>
	        			<buildArgs>
		        			<JAR_FILE>target/${project.build.finalName}.jar</JAR_FILE>
	        			</buildArgs>
            			</configuration>
            		</plugin>

		</plugins>
	</build> 

	<repositories>
		<repository>
			<id>spring-milestones</id>
			<name>Spring Milestones</name>
			<url>https://repo.spring.io/milestone</url>
			<snapshots>
				<enabled>false</enabled>
			</snapshots>
		</repository>
	</repositories>


```

&nbsp;

## 2. Configuration ##

bootstrap.yml file은 Spring cloud application에서 apllication.yml보다 먼저 실행된다. bootstrap.yml에서 db connection을 진행하고, apllication.yml에서 applicaion의 port와 eureka server instance의 정보를 포함시킨다.

**1. bootstrap.yml**

```yml
spring:
    application:
        name: notice-service

    jpa:
      hibernate:
        ddl-auto: update
        show_sql: true
        use_sql_comments: true
        fotmat_sql: true

    datasource:
      url: jdbc:mysql://{Your_MYSQL_Server_Address}:3306/notice
      username: {MYSQL_ID}
      password: {MYSQL_PASSWORD}
      driver-class-name: com.mysql.jdbc.Driver
      hikari:
        maximum-pool-size: 2

```

사용중인 MySQL Server Address를 spring.datasource.url 부분에 입력해야한다. 또한 username과 password도 추가한다.

**2. application.yml**

```yml
server:
    port: 8763

eureka:
    client:
        healthcheck: true
        fetch-registry: true
        serviceUrl:
            defaultZone: ${vcap.services.eureka-service.credentials.uri:http://{Your-Eureka-server-Address}:8761}/eureka/
    instance:
        preferIpAddress: true
```

eureka.client.serviceUrl.defaultZone에 다음처럼 Eureka Server Address를 추가한다.

* eureak.client.fetch-registry - Eureka Registry로 부터 Registry에 속해 있는 Eureka Client들의 정보를 가져올 수 있는 옵션이다. 이는 true로 주자!
* eureka.client.serviceUrl.defaultZone - Spring Cloud Netflix의 공식 Document에서는 ""defaultZone"" is a magic string fallback value that provides the service URL for any client that does not express a preference (in other words, it is a useful default).  라고 소개한다. 뭐 일단 이대로 진행하면 된다. 
* eureka.instance.preferIpAddress - Eureka Client가 Eureka Registry에 자신을 등록할 때 eureka.instance.hostname으로 등록하게 된다. 그러나 어떠한 경우에는 hostname보다 IP Address가 필요한 경우가 있다. 여기서는 IP Address를 이용할 것이다. 
* eureka.instance.hostname - JAVA단에서 hostname을 찾지 못하면 IP Address로 Eureka Registry에 전송된다. (이를 방지하려면 eureka.instance.hostname={your_hostname} 으로 원하는 hostname을 입력해도 되고, eureka.instance.hostname=${HOST_NAME} 으로 environment variable을 이용해 run-time때 hostname을 지정해줘도 된다.)
* eureka.instance.instanceId - 위의 예시에서는 instanceId를 등록하지 않는다. default는 ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${server.port}}} 이다. Eureka Server가 같은 service(application)이지만 다른 client임을 구별하기 위한 용도로 사용할 수 있다.

*참고*
* Eureka Client들을 Eureka Registry에 등록하면 다음처럼 등록된다.(아래 사진은 예시일뿐이다.)
![image](https://user-images.githubusercontent.com/20153890/41632852-e3c59ffa-7476-11e8-8920-0935bafc1c40.png)


사진을 보면 Application, AMIs, Availability Zones, Status를 확인 할 수 있다.
* Application에 보여지는 여러 Service들은 각 Eureka Client의 spring.application.name이다.
* Status는 현재 service가 Up인 상태인지, Down인 상태인지를 나타낸다. 

또 한가지 알아두어야 할 점은 Status 오른쪽의 list들이다. 이 list에는 각 Eureka Client의 eureka.instance.instanceId값이 등록된다.
쉽게 이해하기 위해 Notice-Service를 보자.

Notice-Service는 3개의 Up상태인 client를 가지고 있다. 
* notice-service:7c09a271351a998027f0d1e2c72148e5  
* notice-service:14d5f9837de754b077a6b58b7e159827  
* notice-service:7c6d41264f2f71925591bbc07cfe51ec 

이 3개의 client는 spring.application.name=notice-service로 같지만, eureka.instance.instanceId가 각기 다르단 얘기이다. 

즉 Eureka Registry에 같은 spring.application.name을 가진 어떠한 Client가 등록되면, eureka.instance.instanceId값으로 구분 할 수 있다는 얘기다. 우리는 이를 잘 이용해서 추후에 Dynamic Routing을 할 것이므로 알아 두자.


&nbsp;
&nbsp;

## 3. EurekaClient ##

```java
@SpringBootApplication
@EnableEurekaClient
public class AlarmServiceApplication {

	public static void main(String[] args) {
		SpringApplication.run(AlarmServiceApplication.class, args);
	}
```

dependency는 앞에서 설정 했으므로 main class에 @EnableEurekaClient annotation만 추가하면 된다. 

그럼 이 Eureka Client를 REST API Server로 만들어보자

&nbsp;

## 4. REST API Server 구축 ##

&nbsp;

**REST API**

METHOD | PATH | DESCRIPTION 
------------|-----|------------
GET | /notice/ | 전체 알림정보 제공
GET | /notice/{receiver_ID} | 해당 receiver 에 대한 알림 정보 제공
GET | /notice/latest/{receiver_ID} | 해당 receiver 에 대한 최근 10개 알림정보 제공
GET | /notice/previous/{receiver_ID}/{id} | 해당 receiver 에 대한 정보들 중 {id}값을 기준으로 이전 10개 정보 제공
POST | /notice/ | 알림 정보 입력

&nbsp;
&nbsp;


**Table(table name = notice) description**

| Field       | Type        | Null | Key | Default | Extra          |
--------------|-------------|------|-----|---------|----------------|
| id          | int(11)     | NO   | PRI | NULL    | auto_increment |
| receiver_id | varchar(20) | NO   |     | NULL    |                |
| sender_id   | varchar(20) | NO   |     | NULL    |                |
| article_id  | int(11)     | NO   |     | NULL    |                |


우리는 JPA를 이용해 DB에 접근할 것이다. 따라서 JPA란 무엇인지에 대해 간단하게 알아보고 넘어가자.
(DB setting은 개인적으로 하자..)

&nbsp;

**JPA란?**

 JPA는 자바 진영의 ORM 기술 표준이다. Java Persistence API(JPA)는 RDB에 접근하기 위한 표준 ORM을 제공하고, 기존 EJB에서 제공하는 Entity Bean을 대체하는 기술이다. Hibernate, OpenJPA 와 같은 구현체들이 있고 이에 따른 표준 인터페이스가 JPA인 것이다.

**ORM 이란?**

 객체와 RDB를 매핑한다. 기존에 spring에서 많이 사용하던 mybatis등은 ORM이 아니고, SQL Query를 Mapping하여 실행한다.
따라서 Spring-Data-JPA를 이용하면, 객체 관점에서 DB에 접근하는 형태로 어플리케이션을 개발할 수 있다.

**JPA를 사용해야하는 이유는?**

1. 생산성 => 반복적인 SQL 작업과 CRUD 작업을 개발자가 직접 하지 않아도 된다.
2. 성능 => 캐싱을 지원하여 SQL이 여러번 수행되는것을 최적화 한다.
3. 표준 => 표준을 알아두면 다른 구현기술로 쉽게 변경할 수 있다.

**JPA Annotation**

Annotaion | DESCRIPTION 
----------|------------
@Entity | Entity임을 정의한다.
@Table | (name = ""table name"") , Mapping할 table 정보를 알려준다. 
@id | Entity class의 필드를 table의 PK에 mapping한다.
@Comlumn | field를 column에 매핑한다. 

@Comlumn annotaion은 꼭 필요한것은 아니다. 따로 선언해주지 않아도 기본적으로 멤버 변수명과 일치하는 DB의 Column을 mapping한다.

@Table annotaion또한 기본적으로 @Entity로 선언된 class의 이름과 실제 DB의 Table 명이 일치하는 것을 mapping한다.

&nbsp;

## 4.1 JPA Entity ##

SpringBoot에서는 JPA로 데이터를 접근하게끔 유도하고 있다. 이를 활용해서 REST API Server를 구축해보자.

아래는 JPA Entity를 담당할 Class이다. 

**Notice.java**
```java
@Entity
public class Notice {

        @Id
        @GeneratedValue(strategy=GenerationType.AUTO)
        private int id;
        private String receiver_id;
        private String sender_id;
        private int article_id;

        protected Notice() {}

        public Notice(final int id, final String receiver_id, final String sender_id,final int article_id)
        {
                this.receiver_id=receiver_id;
                this.sender_id=sender_id;
                this.article_id=article_id;
        }

        public int getId()
        {
                return id;
        }

        public String getReceiver_id()
        {
                return receiver_id;
        }
        public String getSender_id()
        {
                return sender_id;
        }

        public void setReceiver_id(String receiver_id)
        {
                this.receiver_id=receiver_id;
        }

        public void setSender_id(String sender_id)
        {
                this.sender_id=sender_id;
        }

        public int getArticle_id()
        {
                return article_id;
        }
        public void setArticle_id(int article_id)
        {
                this.article_id=article_id;
        }
        @Override
        public String toString()
        {
                return String.format(""Notice [id = %d ,receiver_id = '%s', sender_id = '%s', article_id = %d] "", id, receiver_id, sender_id, article_id);

        }

}
```

&nbsp;

## 4.2 Repository ##  

Entity class를 생성했다면, Repository Interface를 생성해야 한다. Spring에서는 Entity의 기본적 insert, delete, update 등이 가능하도록
CrudRepository라는 interface를 제공한다.

**NoticeRepository.java**
```java
public interface NoticeRepository extends CrudRepository<Notice, String>{
	
	
	@Query(""SELECT n FROM Notice n WHERE receiver_id=:receiver_id ORDER BY id DESC"")
	List<Notice> findNoticeByReceiverId(@Param(""receiver_id"") String receiver_id);
	
	@Query(""SELECT n FROM Notice n WHERE receiver_id=:receiver_id ORDER BY id DESC"")
	List<Notice> findLatestNoticeByReceiverId(@Param(""receiver_id"") String receiver_id, Pageable pageable);
	
	@Query(""SELECT n FROM Notice n WHERE n.receiver_id=:receiver_id AND n.id < :id ORDER BY n.id DESC"")
	List<Notice> findPreviousNoticeByReceiverId(@Param(""receiver_id"")String receiver_id, @Param(""id"") int id, Pageable pageable);
	
	
}

```

위 코드는 실제 Notice Entity를 이용하기 위한 Repository이다. 기본적인 CRUD외에 필자가 필요한 메소드를 @Query를 이용해 기존의 SQL처럼 사용하도록 지정해 놓은 상태이다.

이 외에도 CrudRepositorys는 find(), findAll(), findAllById() 등 여러 method를 제공한다. 이에 대한 세부사항은 다음 레퍼런스를 꼭 참고하자.
* Interface CrudRepository<T,ID> => https://docs.spring.io/spring-data/commons/docs/current/api/org/springframework/data/repository/CrudRepository.html

&nbsp;

## 5. Service ## 

이제 실제 필요한 Service interface를 만들어 볼 차례이다.

    ├── rest   
    │   ├── NoticeController.java         
    ├── service
        ├── NoticeService.java          
        └── NoticeServiceImpl.java     
        
먼저 NoticeService.java 와 NoticeServiceImpl.java파일을 생성한다. NoticeService는 interface로 생성할 것이고, 이에대한 명세는 NoticeServiceImpl.java에서 구현한다. interface에 대한 method 구현시 NoticeRepository의 method를 활용한다.

**NoticeService.java**

```java
public interface NoticeService {

        List<Notice> findAllNotice();
        List<Notice> findAllNoticeByReceiverId(String receiver_id);
        List<Notice> findLatestNoticeByReceiverId(String receiver_id);
        List<Notice> findPreviousNoticeByReceiverId(String receiver_id, int id);
        Notice saveNotice(Notice notice);

}
```

**NoticeServiceImpl.java 일부**

```java
@Service(""noticeService"")
public class NoticeServiceImpl implements NoticeService{

	private final Logger logger = LoggerFactory.getLogger(this.getClass());
	

	@Autowired
	private NoticeRepository noticeRepository;
	
	@Override
	public List<Notice> findAllNotice()
	{
		
		Optional<Iterable<Notice>> maybeNoticeIter = Optional.ofNullable(noticeRepository.findAll());
		
		return Lists.newArrayList(maybeNoticeIter.get());

		
	}
	
	@Override
	public List<Notice> findAllNoticeByReceiverId(String receiver_id)
	{
	    
		Optional<List<Notice>> maybeNotice =
			Optional.ofNullable(noticeRepository.findNoticeByReceiverId(receiver_id));
		
		return maybeNotice.get();

	}
	

	@Override
    public List<Notice> findLatestNoticeByReceiverId(String receiver_id)
    {
		Optional<List<Notice>> maybeLatestNotice= 			
			Optional.ofNullable(noticeRepository.findLatestNoticeByReceiverId(receiver_id, PageRequest.of(0, 10)));
		
		return maybeLatestNotice.get();

	
	}

```

&nbsp;

## 6. Rest Controller

이제 controller를 만들어 보자. rest package를 따로 만들고 그곳에 RestController들을 정의한다. 


    ├── rest   
    │   ├── NoticeController.java 
    
@RestControler annotation을 설정하여 RestController를 만든다.
(HystrixMethod적용은 다음 단계에서 진행한다. 여기서는 REST API만 구축한다)

**NoticeController.java 일부**


```java
@RestController
@CrossOrigin(origins=""*"")
public class NoticeController {

	private final Logger logger = LoggerFactory.getLogger(this.getClass());
    	public static List<Notice> Temp;

	@Autowired
	private NoticeService noticeService;

    	@Autowired
    	private DiscoveryClient discoveryClient;

	@RequestMapping(value = ""/notice"", method=RequestMethod.GET)
	public ResponseEntity<List<Notice>> getAllNotice(){
	
		try{
			Optional<List<Notice>> maybeAllStory = Optional.ofNullable(noticeService.findAllNotice());
		
			return new ResponseEntity<List<Notice>>(maybeAllStory.get(), HttpStatus.OK);
		}catch(Exception e)
		{
			return new ResponseEntity<List<Notice>>(HttpStatus.NOT_FOUND);
		}	
	}	

	@RequestMapping(value=""/notice/{receiver_id}"", method = RequestMethod.GET)
	public ResponseEntity<List<Notice>> getAllNoticeByReceiverId(@PathVariable(""receiver_id"") final String receiver_id)
	{

		try {
			Optional<List<Notice>> maybeSelectedNotice =
				Optional.of(noticeService.findAllNoticeByReceiverId(receiver_id));
		
			return new ResponseEntity<List<Notice>>(maybeSelectedNotice.get(), HttpStatus.OK);
			
		}catch(Exception e)
		{
			return new ResponseEntity<List<Notice>>(HttpStatus.NOT_FOUND);
		}
	}

```
&nbsp;

## 7. Maven Packaging 

Host OS에 설치된 maven을 이용해도 되고, spring boot application의 maven wrapper를 사용해도 된다
(maven wrapper는 Linux, OSX, Windows, Solaris 등 서로 다른 OS에서도 동작한다. 따라서 추후에 여러 서비스들을 Jenkins에서 build 할 때 각 서비스들의 Maven version을 맞출 필요가 없다.)

*A Quick Guide to Maven Wrapper => http://www.baeldung.com/maven-wrapper)*

**a. Host OS의 maven 이용**

```bash
[sangmin@Mint-SM] ~/springcloud-service $ mvn package 
```
&nbsp;

**b. maven wrapper 이용**

```bash
[sangmin@Mint-SM] ~/springcloud-service $ ./mvnw package 
```
&nbsp;

## 8. Execute Spring Boot Application 

REST API Server가 제대로 구축 되어졌는지 확인해보자.

```bash
[sangmin@Mint-SM] ~/springcloud-service $java -jar target/{your_application_name}.jar
```

Eureka Dashboard를 통해 Client가 제대로 등록 되어졌는지 확인해보자

Check Your Eureka Dashboard 
 * http://{Your-Eureka-Server-Address}:8761 
 * http://{Your-Eureka-Server-Address}:8761/eureka/apps

Client가 Eureka Server에 등록 될 때 약간의 시간이 소요될 수 있다.

&nbsp;

## 9. Dockerizing 

구축한 Eureka Client를 docker image를 만들어 볼 차례이다. 먼저 Dockerfile을 작성한다. 

> -       $mvn package 


**Dockerfile**
```
	FROM openjdk:8-jdk-alpine
	VOLUME /tmp
	#ARG JAR_FILE
	#ADD ${JAR_FILE} app.jar
	#dockerfile-maven-plugin으로 docker image를 생성하려면 아래 ADD ~를 주석처리하고, 위 2줄의 주석을 지우면 된다.
	ADD ./target/notice-service-0.0.1.jar app.jar
	ENTRYPOINT [""java"",""-Djava.security.egd=file:/dev/./urandom"",""-jar"",""/app.jar""]
```

Dockerfile 작성이 끝났다면 image를 build 하자

**a. dockerfile-maven-plugin 사용시**

```bash
[sangmin@Mint-SM] ~/springcloud-service $ ./mvnw dockerfile:build
```
&nbsp;

**b. docker CLI 사용시**

```bash
[sangmin@Mint-SM] ~/springcloud-service $ docker build -t {your_docker_id}/notice-service:latest
```

이후 docker image가 잘 생성 되었음을 확인하자.

```bash
[sangmin@Mint-SM] ~/springcloud-service $ docker images
REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE
phantasmicmeans/notice-service  latest              4b79d6a1ed24        2 weeks ago         146MB
openjdk                         8-jdk-alpine        224765a6bdbe        5 months ago        102MB

```
&nbsp;

## 10.  Run Docker Container 

Docker image를 생성하였으므로 이미지를 실행 시켜보자.

```bash
[sangmin@Mint-SM] ~ $ docker run -it -p 8763:8763 phantasmicmeans/notice-service:latest 
```

이제 Eureka Dashboard를 통해 Client가 제대로 실행 되었는지 확인하면 된다.

&nbsp;

## Conclusion 

이상으로 간단한 REST API Server로 구축된 Microservice를 Eureka Client로 구성해 보았다. 다음 장에서는 Eureka Client로 구성된 Microservice에 Hystrix를 적용해 볼 것이다.



"
AdamBien/javaee8-mvc-sample,master,26,11,2015-05-04T04:55:07Z,113,0,Java EE 8 MVC (JSR-371) Example,,"# javaee8-mvc-sample

Java EE 8 MVC [JSR-371](https://mvc-spec.java.net) example based on JAX-RS, EJBs and JSPs.

Currently this sample requires a dependency to the Java EE 8 MVC Reference Implementation [ozark](https://ozark.java.net) (see [pom](https://github.com/AdamBien/javaee8-mvc-sample/blob/master/time/pom.xml)) and GlassFish daily [build](http://dlc.sun.com.edgesuite.net/glassfish/4.1/nightly/glassfish-4.1-b13-03_16_2015.zip)

# Installation

Either build the project from sources:

`git clone https://github.com/AdamBien/javaee8-mvc-sample/` and open it with NetBeans, then just “Run” it on GlassFish daily [build](http://dlc.sun.com.edgesuite.net/glassfish/4.1/nightly/glassfish-4.1-b13-03_16_2015.zip)

or deploy the war:

Drop the [time.war](https://github.com/AdamBien/javaee8-mvc-sample/releases/download/v0.0.1/time.war) to glassfish/domains/domain1/autodeploy/ and point the browser to: [http://localhost:8080/time/views/time](http://localhost:8080/time/views/time).


"
mckeeh3/akka-java-cluster-sharding,master,28,7,2018-02-05T20:47:14Z,645,2,Akka Java cluster sharding example,,"## Akka Java Cluster Sharding Example

### Introduction

This is a Java, Maven, Akka project that demonstrates how to setup an
[Akka Cluster](https://doc.akka.io/docs/akka/current/index-cluster.html)
with an example implementation of
[Cluster Sharding](https://doc.akka.io/docs/akka/current/cluster-sharding.html).

This project is one in a series of projects that starts with a simple Akka Cluster project and progressively builds up to examples of event sourcing and command query responsibility segregation.

The project series is composed of the following projects:
* [akka-java-cluster](https://github.com/mckeeh3/akka-java-cluster)
* [akka-java-cluster-aware](https://github.com/mckeeh3/akka-java-cluster-aware)
* [akka-java-cluster-singleton](https://github.com/mckeeh3/akka-java-cluster-singleton)
* [akka-java-cluster-sharding](https://github.com/mckeeh3/akka-java-cluster-sharding) (this project)
* [akka-java-cluster-persistence](https://github.com/mckeeh3/akka-java-cluster-persistence)
* [akka-java-cluster-persistence-query](https://github.com/mckeeh3/akka-java-cluster-persistence-query)

Each project can be cloned, built, and runs independently of the other projects.

This project contains an example implementation of cluster sharding. Here we will focus on the implementation details in this project. Please see the
[Akka documentation](https://doc.akka.io/docs/akka/current/cluster-sharding.html)
for a more detailed discussion about cluster sharding.

### What is cluster sharding

According to the [Akka documentation](https://doc.akka.io/docs/akka/current/cluster-sharding.html#introduction),
""*Cluster sharding is useful when you need to distribute actors across several nodes in the cluster and want to be able to interact with them using their logical identifier, but without having to care about their physical location in the cluster, which might also change over time.*""

The common usage for cluster sharding is to distribute and engage with individual actors across the cluster. Each of these distributed actors is used to handle messages that are intended for a specific entity. Each entity represents a thing, such as a bank account or a shopping cart. Entities each have a unique identifier, such as an account or shopping cart identifier.

In this example project, the entities represent simple identifier and value. In a real application, entities represent real things, such as bank accounts. Each entity handles incoming messages. These messages are either commands, which are requests to chage the state of the entity. Other messages are query requests that are used to retrieve entity information.

Two actors are used to simulate clients that are sending messages to entities. The `EntityCommandActor` and the `EntityQueryActor` randomly generate messages to specific entities. These two actors are used to simulate incoming service requests. In a real implementation, the service would receive incoming messages, for example from an HTTP request, and forward those messages to specific entities to handle the request messages.

The process of forwarding these messages to the right entities, which could be distributed across multiple JVMs running in a cluster, is handled by cluster sharding. To send a message to an entity the sender simply sends the message to a shard region actor. The shard region actor is responsible for forwarding the message to the correct entity actor. The actual mechanics of this process is described in the
[How it works](https://doc.akka.io/docs/akka/current/cluster-sharding.html#how-it-works)
section of the cluster sharding documentation.

![Visualization of cluster sharding](docs/images/akka-cluster-k8-3-pods.png)
<center>Figure 1, Visualization of cluster sharding</center><br/>

The visualization in Figure 1 shows an example of cluster sharding. The blue leaf actors represent the entity actors. Each entity actor represents the state of an entity. The green circles that connect to the entity circles represent the running shard actors. In the example system there 15 shards configured. The shards connect to the orange shard region actors. These orange circles also represent other actors, such as the entity command and query actors. Also, the orange circles represent the root of the actor system on each cluster node.

### How it works

The `Runner` class contains the `main` method. The `main` method starts one or more Akka systems and in each actor system it starts instances of multiple actors.

The arguments passed to the main method are expected to be zero or more port numbers. These port numbers will be used to start cluster nodes, one for each specified port.

If no ports are specified a default is used to start three JVMs using ports 2551, 2552, and 0 respectively.

~~~java
if (args.length == 0) {
    startupClusterNodes(Arrays.asList(""2551"", ""2552"", ""0""));
} else {
    startupClusterNodes(Arrays.asList(args));
}
~~~

Multiple actor systems may be started in a single JVM. However, the typical use case is that a single actor system is started per JVM. One way to think of an
[actor system](https://doc.akka.io/docs/akka/current/general/actor-systems.html)
is that they are supercharged thread pools.

The `startupClusterNodes` method is called with the list of specified port numbers. Each port is used to start an actor system and then start up various actors that will run in the demonstration.

The most notable actor in this cluster sharding example is the `shardRegion` actor.

~~~java
ActorRef shardingRegion = setupClusterSharding(actorSystem);
~~~

This actor is instantiated in the `setupClusterSharding` method.

~~~java
private static ActorRef setupClusterSharding(ActorSystem actorSystem) {
    ClusterShardingSettings settings = ClusterShardingSettings.create(actorSystem);
    return ClusterSharding.get(actorSystem).start(
            ""entity"",
            EntityActor.props(),
            settings,
            EntityMessage.messageExtractor()
    );
}
~~~

This method uses the `ClusterSharding` static `get` method to create an instance of a single shard region actor per actor system. More details on how the shard region actors are used is described above. The `get` method is used to create a shard region actor passing it the code to be used to create an instance of an entity actor (`EntityActor.props()`) and the code used to extract entity and shard identifiers from messages that are sent to entity actors (`EntityMessage.messageExtractor()`).

~~~java
actorSystem.actorOf(EntityCommandActor.props(shardingRegion), ""entityCommand"");
actorSystem.actorOf(EntityQueryActor.props(shardingRegion), ""entityQuery"");
~~~

The `shardRegion` actor reference is passed as a constructor argument to the `EntityCommandActor` and the `EntityQueryActor`. These generate simulated random message traffic, they use the `shardRegion` actor ref to send messages to specific entity actors.

~~~java
shardRegion.tell(command(), self());
~~~

The `shardRegion` actor handles the heavy lifting of routing each message to the correct entity actor.

Entity actors have an interesting life-cycle. When messages are sent to a shard region actor, it routes the message to a shard actor that is responsible for the specific entity as defined by the message entity identifier.

The shared region actor is responsible for handling the routing of entity messages to the specific shard actors, which may involve other cluster sharding internal actors,  and this may include forwarding the message from one cluster node to another.

When a shard actor receives an incoming entity message, it checks to see if the entity actor instance exits. If the entity actor instance does not exist, then an instance of the entity actor is created, and the message is forwarded to the newly started entity actor instance. If the entity actor instance already exists, then the message is forwarded from the shard actor to the specific entity actor instance.

Here is the source code of our example entity actor.

~~~java
package cluster.sharding;

import akka.actor.AbstractLoggingActor;
import akka.actor.PoisonPill;
import akka.actor.Props;
import akka.actor.ReceiveTimeout;
import akka.cluster.sharding.ShardRegion;
import scala.concurrent.duration.Duration;
import scala.concurrent.duration.FiniteDuration;

import java.util.concurrent.TimeUnit;

class EntityActor extends AbstractLoggingActor {
    private Entity entity;
    private final FiniteDuration receiveTimeout = Duration.create(60, TimeUnit.SECONDS);

    @Override
    public Receive createReceive() {
        return receiveBuilder()
                .match(EntityMessage.Command.class, this::command)
                .match(EntityMessage.Query.class, this::query)
                .matchEquals(ReceiveTimeout.getInstance(), t -> passivate())
                .build();
    }

    private void command(EntityMessage.Command command) {
        log().info(""{} <- {}"", command, sender());
        if (entity == null) {
            entity = command.entity;
            final EntityMessage.CommandAck commandAck = EntityMessage.CommandAck.ackInit(command);
            log().info(""{}, {} -> {}"", commandAck, command, sender());
            sender().tell(commandAck, self());
        } else {
            entity.value = command.entity.value;
            final EntityMessage.CommandAck commandAck = EntityMessage.CommandAck.ackUpdate(command);
            log().info(""{}, {} -< {}"", commandAck, command, sender());
            sender().tell(commandAck, self());
        }
    }

    private void query(EntityMessage.Query query) {
        log().info(""{} <- {}"", query, sender());
        if (entity == null) {
            final EntityMessage.QueryAckNotFound queryAck = EntityMessage.QueryAckNotFound.ack(query);
            log().info(""{} -> {}"", queryAck, sender());
            sender().tell(queryAck, self());
        } else {
            final EntityMessage.QueryAck queryAck = EntityMessage.QueryAck.ack(query, entity);
            log().info(""{} -> {}"", queryAck, sender());
            sender().tell(queryAck, self());
        }
    }

    private void passivate() {
        context().parent().tell(new ShardRegion.Passivate(PoisonPill.getInstance()), self());
    }

    @Override
    public void preStart() {
        log().info(""Start"");
        context().setReceiveTimeout(receiveTimeout);
    }

    @Override
    public void postStop() {
        log().info(""Stop {}"", entity == null ? ""(not initialized)"" : entity.id);
    }

    static Props props() {
        return Props.create(EntityActor.class);
    }
}
~~~

Entity actors are typically set up to shut themselves down when they stop receiving messages.

~~~java
@Override
public void preStart() {
    log().info(""Start"");
    context().setReceiveTimeout(receiveTimeout);
}
~~~

The timeout period is set via a call to the `SetReceiveTimeout(...)` method. What this does is whenever the entity actor receives a message the timeout timer is reset.

~~~java
@Override
public Receive createReceive() {
    return receiveBuilder()
            .match(EntityMessage.Command.class, this::command)
            .match(EntityMessage.Query.class, this::query)
            .matchEquals(ReceiveTimeout.getInstance(), t -> passivate())
            .build();
}
~~~

When no messages are received before the timeout period has expired then the entity actor is set a `ReceiveTimeout` message. In our example entity actor a receive timeout message triggers a call to a method called `passivate()`.

~~~java
private void passivate() {
    context().parent().tell(new ShardRegion.Passivate(PoisonPill.getInstance()), self());
}
~~~

In the `passivate()` method a message is sent to the entity actor's parent actor, which is the shard actor, asking it to trigger a shutdown of this entity actor.

### Installation

~~~bash
git clone https://github.com/mckeeh3/akka-java-cluster-sharding.git
cd akka-java-cluster-sharding
mvn clean package
~~~

The Maven command builds the project and creates a self contained runnable JAR.

### Run a cluster (Mac, Linux)

The project contains a set of scripts that can be used to start and stop individual cluster nodes or start and stop a cluster of nodes.

The main script `./akka` is provided to run a cluster of nodes or start and stop individual nodes.
Use `./akka node start [1-9] | stop` to start and stop individual nodes and `./akka cluster start [1-9] | stop` to start and stop a cluster of nodes.
The `cluster` and `node` start options will start Akka nodes on ports 2551 through 2559.
Both `stdin` and `stderr` output is sent to a file in the `/tmp` directory using the file naming convention `/tmp/<project-dir-name>-N.log`.

Start node 1 on port 2551 and node 2 on port 2552.
~~~bash
./akka node start 1
./akka node start 2
~~~

Stop node 3 on port 2553.
~~~bash
./akka node stop 3
~~~

Start a cluster of four nodes on ports 2551, 2552, 2553, and 2554.
~~~bash
./akka cluster start 4
~~~

Stop all currently running cluster nodes.
~~~bash
./akka cluster stop
~~~

You can use the `./akka cluster start [1-9]` script to start multiple nodes and then use `./akka node start [1-9]` and `./akka node stop [1-9]`
to start and stop individual nodes.

Use the `./akka node tail [1-9]` command to `tail -f` a log file for nodes 1 through 9.

The `./akka cluster status` command displays the status of a currently running cluster in JSON format using the
[Akka Management](https://developer.lightbend.com/docs/akka-management/current/index.html)
extension
[Cluster Http Management](https://developer.lightbend.com/docs/akka-management/current/cluster-http-management.html).

### Run a cluster (Windows, command line)

The following Maven command runs a signle JVM with 3 Akka actor systems on ports 2551, 2552, and a radmonly selected port.
~~~~bash
mvn exec:java
~~~~
Use CTRL-C to stop.

To run on specific ports use the following `-D` option for passing in command line arguements.
~~~~bash
mvn exec:java -Dexec.args=""2551""
~~~~
The default no arguments is equilevalant to the following.
~~~~bash
mvn exec:java -Dexec.args=""2551 2552 0""
~~~~
A common way to run tests is to start single JVMs in multiple command windows. This simulates running a multi-node Akka cluster.
For example, run the following 4 commands in 4 command windows.
~~~~bash
mvn exec:java -Dexec.args=""2551"" > /tmp/$(basename $PWD)-1.log
~~~~
~~~~bash
mvn exec:java -Dexec.args=""2552"" > /tmp/$(basename $PWD)-2.log
~~~~
~~~~bash
mvn exec:java -Dexec.args=""0"" > /tmp/$(basename $PWD)-3.log
~~~~
~~~~bash
mvn exec:java -Dexec.args=""0"" > /tmp/$(basename $PWD)-4.log
~~~~
This runs a 4 node Akka cluster starting 2 nodes on ports 2551 and 2552, which are the cluster seed nodes as configured and the `application.conf` file.
And 2 nodes on randomly selected port numbers.
The optional redirect `> /tmp/$(basename $PWD)-4.log` is an example for pushing the log output to filenames based on the project direcctory name.

For convenience, in a Linux command shell define the following aliases.

~~~~bash
alias p1='cd ~/akka-java/akka-java-cluster'
alias p2='cd ~/akka-java/akka-java-cluster-aware'
alias p3='cd ~/akka-java/akka-java-cluster-singleton'
alias p4='cd ~/akka-java/akka-java-cluster-sharding'
alias p5='cd ~/akka-java/akka-java-cluster-persistence'
alias p6='cd ~/akka-java/akka-java-cluster-persistence-query'

alias m1='clear ; mvn exec:java -Dexec.args=""2551"" > /tmp/$(basename $PWD)-1.log'
alias m2='clear ; mvn exec:java -Dexec.args=""2552"" > /tmp/$(basename $PWD)-2.log'
alias m3='clear ; mvn exec:java -Dexec.args=""0"" > /tmp/$(basename $PWD)-3.log'
alias m4='clear ; mvn exec:java -Dexec.args=""0"" > /tmp/$(basename $PWD)-4.log'
~~~~

The p1-6 alias commands are shortcuts for cd'ing into one of the six project directories.
The m1-4 alias commands start and Akka node with the appropriate port. Stdout is also redirected to the /tmp directory.
"
openpreserve/format-corpus,master,172,39,2012-06-27T13:38:00Z,275813,5,"An openly-licensed corpus of small example files, covering a wide range of formats and creation tools.",,"format-corpus
=============

An openly-licensed corpus of small example files, covering a wide range of formats and creation tools.

All items, apart from the source code under 'tools', is CC0 licenced unless otherwise stated.  The source code is Apache 2.0 Licenced unless otherwise stated.

A recent summary of the contents of the repository can be found [here](http://www.opf-labs.org/format-corpus/tools/coverage/reports/).


How to Contribute
=================

See http://wiki.curatecamp.org/index.php/Collecting_format_ID_test_files for more information.

See [metadata-template.ext.md](https://github.com/openplanets/format-corpus/blob/master/metadata-template.ext.md) for a simple per-file metadata template.


Pooled Signatures
=================

As well as pooling example files, we also pool format signatures:

* Tika signatures staged here: https://github.com/openplanets/format-corpus/tree/master/tools/fidget/src/main/resources/tika-bl-staging
* Tika signatures later merged here: [https://github.com/openplanets/format-corpus/blob/master/tools/fidget/src/main/resources/org/apache/tika/mime/custom-mimetypes.xml here]
* DROID signatures go [https://github.com/openplanets/format-corpus/tree/master/tools/fidget/src/main/resources/droid here].

More details here: http://wiki.curatecamp.org/index.php/Improving_format_ID_coverage

"
politrons/RPC_reactive,master,25,4,2018-02-06T00:04:07Z,394,0,Examples and explanations of how RPC systems works.,finagle grpc java reactive-programming thrift,"Author Pablo Picouto García 

![My image](src/main/resources/img/simple.svg)

## Reactive RPC

Here we cover with some examples and explanations how most famous RPC as [gRPC](https://grpc.io/docs/quickstart/) or
 [Thrift](https://thrift.apache.org/) works.

### gRPC

##### Simple gRCP

![My image](src/main/resources/img/grpc.png)

An example of how gRPC works between client-server

* [client](src/main/java/com/politrons/grpc/simple/RpcClient.java)

* [Service](src/main/java/com/politrons/grpc/simple/RpcServiceImpl.java)

* [proto](src/main/proto/rpc_contract.proto)

##### Reactive

![My image](src/main/resources/img/flatMap.png)

An example of how to use streams gRPC between client-server

* [client](src/main/java/com/politrons/grpc/reactive/ReactiveClient.java)

* [service](src/main/java/com/politrons/grpc/reactive/ReactiveServiceImpl.java)

* [proto](src/main/proto/rpc_reactive.proto)

##### Configuration

Once that you have your contracts(proto) ready, you need to build your classes which will 
be used for the communication between client and server.
In these examples we decide to use the maven plugin.

The plugin you need to add in your pom is

```
  <plugin>
         <groupId>org.xolstice.maven.plugins</groupId>
         <artifactId>protobuf-maven-plugin</artifactId>
         <version>0.5.0</version>
         <configuration>
              <protocArtifact>
                        com.google.protobuf:protoc:3.3.0:exe:${os.detected.classifier}
              </protocArtifact>
              <pluginId>grpc-java</pluginId>
              <pluginArtifact>
                        io.grpc:protoc-gen-grpc-java:1.4.0:exe:${os.detected.classifier}
              </pluginArtifact>
              </configuration>
              <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>compile-custom</goal>
                        </goals>
                    </execution>
              </executions>
  </plugin>


```

### Thrift

![My image](src/main/resources/img/apache.png)

An example of how thrift RPC works between client-server

* [client](src/main/scala/finagle/thrift/rpc/ThriftRPCClient.scala)

* [Service](src/main/scala/finagle/thrift/rpc/ThriftRPCServer.scala)

* [thrift](src/main/scala/finagle/thrift/idl/finagle_scrooge.thrift)

##### Configuration

Just like with gRPC once that you have your contracts(thrift) ready, you need to build your classes which will
be used for the communication between client and server.
In these examples we decide to use the twitter scrooge maven plugin.

The plugin you need to add in your pom is

```
          <plugin>
                <groupId>com.twitter</groupId>
                <artifactId>scrooge-maven-plugin</artifactId>
                <version>18.2.0</version>
                <configuration>
                    <thriftSourceRoot>src/main/scala/finagle/thrift/idl/</thriftSourceRoot>
                    <thriftNamespaceMappings>
                        <thriftNamespaceMapping>
                            <from>finagle.thrift.idl</from>
                            <to>finagle.thrift</to>
                        </thriftNamespaceMapping>
                    </thriftNamespaceMappings>
                    <language>scala</language> <!-- default is scala -->
                    <thriftOpts>
                        <!-- add other Scrooge command line options using thriftOpts -->
                        <thriftOpt>--finagle</thriftOpt>
                    </thriftOpts>
                    <!-- tell scrooge to not to build the extracted thrift files (defaults to true) -->
                    <buildExtractedThrift>false</buildExtractedThrift>
                </configuration>
                <executions>
                    <execution>
                        <id>thrift-sources</id>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>compile</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>thrift-test-sources</id>
                        <phase>generate-test-sources</phase>
                        <goals>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>


```

### Avro

![My image](src/main/resources/img/avro.png)

An example of how avro encoder/decoder works between client-server

* [encoder](src/main/java/com/politrons/avro/SerializeAvro.java)

* [decoder](src/main/java/com/politrons/avro/DeserializeAvro.java)

* [avro](src/main/avro/person.avsc)

An example of how avro RPC works between client-server

* [client](src/main/java/com/politrons/avro/rpc/ClientAvroRPC.java)

* [Service](src/main/java/com/politrons/avro/rpc/ServerAvroRPC.java)

* [avro](src/main/avro/avro_rpc.avpr)

##### Configuration

Just like with gRPC once that you have your contracts(avro) ready, you need to build your classes which will
be used for the communication between client and server.
In these examples we use avro-maven-plugin<.

The plugin you need to add in your pom is

```
           <plugin>
                <groupId>org.apache.avro</groupId>
                <artifactId>avro-maven-plugin</artifactId>
                <version>1.8.2</version>
                <executions>
                    <execution>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>schema</goal>
                            <goal>protocol</goal>
                            <goal>idl-protocol</goal>
                        </goals>
                        <configuration>
                            <sourceDirectory>${project.basedir}/src/main/avro/</sourceDirectory>
                            <outputDirectory>${project.basedir}/src/main/java/</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
```


## Benchmarks

![My image](src/main/resources/img/benchmark.png)

For this benchmark we made 1000 request with Json body for Rest and proto and thrift for RPC.

* [Rest](src/main/scala/benchmark) Http finagle client against Grizzly server.

* [Rest](src/main/scala/benchmark) Http finagle client against Finagle server.

* [gRPC](src/main/java/com/politrons/grpc/benchmark/regular) using standard implementation.

* [gRPC Reactive](src/main/java/com/politrons/grpc/benchmark/reactive) using reactive StreamObserver.

* [Thrift RPC](src/main/scala/finagle/thrift/rpc) using Apache thrift.

* [Avro RPC](src/main/java/com/politrons/avro/rpc) Using Apache Avro.



##### Results

![My image](src/main/resources/img/benchmark_result.png)
"
Bernardo-MG/spring-ws-security-soap-example,master,34,35,2015-12-18T13:45:07Z,1573,16,An example showing how to set up secured SOAP web services in Spring.,spring-ws ws-security wss4j xwss,
sorakylin/code_demo,master,29,24,2019-02-23T02:47:03Z,825,9,"Demo/code/example using some java framework(eg SSM, SpringBoot, SpringCloud).",,"使用各类主流框架、以及中间件整合之类的代码演示,注释详细
---
[![License](https://img.shields.io/badge/License-MIT-red.svg)](https://mit-license.org/)

<br>
<br>

### Demo 演示列表
- [sc-demo-alibaba](https://github.com/skypyb/code_demo/tree/master/sc-demo-alibaba)：Spring Cloud Alibaba全家桶的示例，服务治理、熔断、通信、网关、限流、鉴权等
- [spring-security-demo](https://github.com/skypyb/code_demo/tree/master/spring-security-demo)：(内附sql脚本) 标准的RBAC权限设计，基于动态查询数据库的权限判定 (  *以接口为粒度，即 Request URL+Request Method*  )基于JWT的认证授权流程，使用SpringBoot+SpringSecurity+MyBatis+jjwt  
- [dubbo-springboot](https://github.com/skypyb/code_demo/tree/master/dubbo-springboot)：SpringBoot整合Dubbo的演示，服务治理使用Zookeeper  
- [sc-demo-microservice](https://github.com/skypyb/code_demo/tree/master/sc-demo-microservice)：SpringCloudNetfilx全家桶,包含Zuul,Eureka,Ribbon,Hystrix,Feign等组件的使用
- [ssm-backstage](https://github.com/skypyb/code_demo/tree/master/ssm-backstage)：Spring+SpringMVC+Mybatis注解式开发的简易后台项目,Mybatis实现一对一/一对多映射,前台使用Thymeleaf+Layui
- [WebSocket](https://github.com/skypyb/code_demo/tree/master/WebSocket)：SpringBoot开发的WebSocket应用,包含传统tomcat开发方式和使用`spring-boot-starter-websocket`的开发方式
- [Cache-SpringBoot](https://github.com/skypyb/code_demo/tree/master/Cache-SpringBoot)：SpringBoot自带的缓存实现,@CacheConfig @CacheEvict @CachePut @Cacheable 等注解使用
- [RabbitMQ-SpringBoot](https://github.com/skypyb/code_demo/tree/master/RabbitMQ-SpringBoot)：SpringBoot 集成 RabbitMQ; 消息发送/接收、死信队列
- [Event-Springboot](https://github.com/skypyb/code_demo/tree/master/Event-Springboot)：SpringBoot实现异步事件驱动(发布、监听)编程,AsyncConfigurer异步配置演示,ApplicationEvent、ApplicationListener、@EventListener等相关接口/注解使用示例
"
polkadot-java/api,master,61,27,2019-02-26T12:19:59Z,22897,9,Java APIs around Polkadot and any Substrate-based chain RPC calls. It is dynamically generated based on what the Substrate runtime provides in terms of metadata.Full documentation & examples available.,,"# Polkadot/Substrate Java Api

This library provides a Java wrapper around all the methods exposed by a Polkadot/Subtrate network client and defines all the types exposed by a node.

- [packages](https://github.com/polkadot-java/api/tree/master/packages) -- Polkadot/substrate api Java implementation.  
- [examples](https://github.com/polkadot-java/api/tree/master/examples) -- Demo projects (Gradle).  
- [examples_runnable](https://github.com/polkadot-java/api/tree/master/examples_runnable) -- Demo executable JARs.  

## JDK

Java 1.8

## Based JS code version

The Java version is based on JS commit [ff25a85ac20687de241a84e0f3ebab4c2920df7e](https://github.com/polkadot-js/api/commit/ff25a85ac20687de241a84e0f3ebab4c2920df7e).

## Substrate version

The working substrate version is 1.0.0-41ccb19c-x86_64-macos.
Newer substrate may be not supported.

## overview

The API is split up into a number of internal packages

- [@polkadot/api](packages/src/main/java/org/polkadot/api/) The API library, providing both Promise and RxJS Observable-based interfaces. This is the main user-facing entry point.
- [@polkadot/rpc](packages/src/main/java/org/polkadot/rpc/) RPC library.
- [@polkadot/type](packages/src/main/java/org/polkadot/type/) Basic types such as extrinsics and storage.
- [@polkadot/types](packages/src/main/java/org/polkadot/types/) Codecs for all Polkadot primitives.

## Document

* See the generated JavaDoc in /doc folder. Or visit the [document site](https://polkadot-java.github.io/)
* To generate JavaDoc by yourself, reference `gendoc.sh` in the root folder  
* To understand how the system works, you may reference [Substrate](https://github.com/paritytech/substrate) and [Polkadot Network](https://polkadot.network/)

## Integrate the API into your projects

The project uses [Gradle](https://gradle.org/) as build tool. You need to install Gradle.

### Build the library with Gradle then link to the JAR

1. `git clone https://github.com/polkadot-java/api.git`
2. `cd api`
3. `gradle build`
4. Get the JARs in folder `build/libs/`
5. Add the JARs into your projects.

### Link to the source code directly,

1. `git clone https://github.com/polkadot-java/api.git`
2. Import the gradle project in folder api/packages to your workspace.
3. Add links or dependencies in the IDE. This is different in different IDEs, please reference to your IDE document.

## How to build and use sr25591 JNI

1. See polkadot-java/sr25519/readme.md to compile sr25591 library (Rust and C++).  
2. See polkadot-java/sr25519/cpp/compile.sh how to compile the JNI shared library.  
3. See polkadot-java/sr25519/libs/readme.md how to use the JNI in the Java API.  

## How to run examples

1. Install substrate local node:  
`https://github.com/paritytech/substrate`  

2. Running the samples:  
There are several runnable samples. To run the samples, go to folder `examples_runnable/LastestDate` (such as examples_runnable/20190525), then run each shell script.

3. To change the Substrate address, change the `endPoint` variable in each demo main file.

"
jobrunr/example-spring,master,26,16,2020-04-03T15:18:28Z,184,0,An example on how to integrate JobRunr with Spring,,"# JobRunr example

This repository shows an advanced example how you can integrate JobRunr with [spring.io](https://spring.io/). In this example, Jobs are created via a web frontend (the `webapp` module) and processed in a different JVM (the `processingapp` module).

An easier example using [spring.io](https://spring.io/) can be found [here](https://github.com/jobrunr/example-java-mag)

## About this project
This project exists out of 3 modules:
- **core**: this project contains [MyService](core/src/main/java/org/jobrunr/examples/services/MyService.java), a simple spring service with two example methods which you want to run in a backgroundserver.  
- **processingapp**: this app is a Spring Console application and runs indefinitely. It polls for new background jobs
  and processes them when they arrive. It contains only a two classes:
  - the [JobServerApplication](processingapp/src/main/java/org/jobrunr/examples/processingapp/JobServerApplication.java) which is empty 🙂
  - the [JobServerConfiguration](processingapp/src/main/java/org/jobrunr/examples/processingapp/JobServerConfiguration.java) which starts the H2 Database (in server mode) and contains the database information
  > the thing to note here is the [`application.properties`](processingapp/src/main/resources/application.properties) where the server and the dashboard are enabled
- **webapp**: this is a Spring Rest Webapp that enqueues new background jobs. It contains a simple `RestController`
  called [JobController](webapp/src/main/java/org/jobrunr/examples/webapp/api/JobController.java) which contains some
  methods (= endpoints) to enqueue jobs.

## How to run this project:
- clone the project and open it in your favorite IDE that supports gradle
- First, run the main method from
    the [JobServerApplication](processingapp/src/main/java/org/jobrunr/examples/processingapp/JobServerApplication.java)
    in the `processingapp` module and also keep it running
- Run the main method from the [WebApplication](webapp/src/main/java/org/jobrunr/examples/webapp/WebApplication.java) in the `webapp` module and keep it running
- Open your favorite browser:
  - Navigate to the JobRunr dashboard located at http://localhost:8000/dashboard. This is running within
    the [JobServerApplication](processingapp/src/main/java/org/jobrunr/examples/processingapp/JobServerApplication.java).
  - To enqueue a simple job, open a new tab and go to http://localhost:8080/jobs/ and take it from there.
  - Visit the dashboard again and see the jobs being processed!
"
gshaw-pivotal/spring-hexagonal-example,master,68,36,2017-06-07T21:58:03Z,106,5,An example of implementing hexagonal design in a spring-boot application (A work in progress),,"# Hexagonal (Port and Adapter) Example #

A spring-boot based example of hexagonal design (also known as the ports and adapters design).

Through the use of ports, contracts between the various modules can be set up, allowing for the modules to be easily replaced with other implementations. The only condition; that the module conforms to the contract specified.

Thus by having a hexagonal design, the current database adapter module; which is a simple in-memory implementation can be swapped out for a JPA repository or a flat file or something else and as long as it conforms to the contract (aka port) no other module (especially the domain module) needs to know or care.

Similarly, the name verifier adapter can be swapped out for a real implementation that would communicate with a third party application without the rest of our application ever knowing. Again as long as the current implementation conforms to the contract (in this case the NameVerifierService) no one will ever know the difference.

Also, the rest api adapter (which as the name implies uses HTTP REST) could be replaced by a SOAP based api and again the domain (and other modules) would not know nor need to care as long as the new api passed along the expected objects as specified in the ports (AddUserService and GetUserService).

## Getting Started ##

```
    git clone https://github.com/gshaw-pivotal/spring-hexagonal-example.git
```

## Resources on Hexagonal / Ports and Adapters ##

The following are some resources that explain the hexagonal design / pattern

- [Hexagonal Architecture](http://alistair.cockburn.us/Hexagonal+architecture)
- [Ports-And-Adapters / Hexagonal Architecture](http://www.dossier-andreas.net/software_architecture/ports_and_adapters.html)
"
indrabasak/spring-loadtime-weaving-example,master,30,13,2018-02-10T02:23:00Z,1943,1,Spring Boot Load-Time Weaving Example with AspectJ,aspectj spring-aop spring-boot,"[![Build Status][travis-badge]][travis-badge-url]
[![Quality Gate][sonarqube-badge]][sonarqube-badge-url] 
[![Technical debt ratio][technical-debt-ratio-badge]][technical-debt-ratio-badge-url] 
[![Coverage][coverage-badge]][coverage-badge-url]

![](./img/aspectj-loadtime-weaving-logo.svg)

Spring Boot Load-Time Weaving Example with AspectJ
===============================================================
This is an example of Spring Boot load time weaving with AspectJ. It's the
continuation of the previous [Spring Boot source weaving example](https://github.com/indrabasak/spring-source-weaving-example).

### Load Time Weaving
The load-time weaving is a type of binary weaving where compiled Java classes
are taken as an input at runtime instead of compile time. The classes
are weaved as they are loaded by the Java Virtual Machine (JVM).

The load-time weaving process weaves classes with the help of Java Agent. A Java Agent 
intercepts the classes while they are being loaded by the JVM. The intercepted 
classes are instrumented (bytecode is modified) by the agent based on 
the AspectJ definitions contained in a meta file named `aop.xml`. The `aop.xml` 
file should be in the classpath in order to be picked up by the agent.

![](./img/aspectj-loadtime-weaving.svg)

### When do you need load-time weaving?
THe load-time weaving is useful when aspects are required at certain times but not
all the times. For example, monitoring application performance or investigating
thread deadlocks, etc. This way you can keep your application source code free of
aspect related code.

```java
@Target({ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
public @interface CustomAnnotation {

    String description() default """";
}
```

1. A `CustomAnnotationAspect` aspect to intercept any method marked with
`@CustomAnnotation`. It prints out the name of the intercepted class and method.
**Note:** Unlike the previous [source weaving example](https://github.com/indrabasak/spring-source-weaving-example),
this `CustomAnnotationAspect` aspect do not have the Spring `@Component`
annotation since it's not going to be deployed as a bean.

```java
@Aspect
public class CustomAnnotationAspect {

    private static final Logger
            log = LoggerFactory.getLogger(CustomAnnotationAspect.class);

    @Before(""@annotation(anno) && execution(* *(..))"")
    public void inspectMethod(JoinPoint jp, CustomAnnotation anno) {
        log.info(
                ""Entering CustomAnnotationAspect.inspectMethod() in class ""
                        + jp.getSignature().getDeclaringTypeName()
                        + "" - method: "" + jp.getSignature().getName()
                        + "" description: "" + anno.description());
    }
}
```

1. The `BookService` class is the example where the `@CustomAnnotation` is used.
The **privat**e method `validateRequest` is called from `create` method. The
`create` method is annotated with Spring's `@Transactional` annotation.

```java
@Service
public class BookService {

    private static final Logger
            log = LoggerFactory.getLogger(BookService.class);
    
    private BookRepository repository;

    @Autowired
    public BookService(BookRepository repository) {
        this.repository = repository;
    }

    @Transactional
    public Book create(BookRequest request) {
        Book entity = validateRequest(request);
        return repository.save(entity);
    }

    public Book read(UUID id) {
        return repository.getOne(id);
    }

    @CustomAnnotation(description = ""Validates book request."")
    private Book validateRequest(BookRequest request) {
        log.info(""Validating book request!"");

        Assert.notNull(request, ""Book request cannot be empty!"");
        Assert.notNull(request.getTitle(), ""Book title cannot be missing!"");
        Assert.notNull(request.getAuthor(), ""Book author cannot be missing!"");

        Book entity = new Book();
        entity.setTitle(request.getTitle());
        entity.setAuthor(request.getAuthor());

        return entity;
    }
}
```

### Aspect Filter Examples
This example also includes couple of examples on how to apply aspect conditionally
based on either the called method's annotation or by name.

1. Filter by caller's method tagged with a certain type of annotation,

```java
@Aspect
public class FilterCallerAnnotationAspect {

    private static final Logger
            log = LoggerFactory.getLogger(FilterCallerAnnotationAspect.class);

    @Before(""call(* com.basaki.service.UselessService.sayHello(..))"" +
            ""  && cflow(@annotation(trx))"")
    public void inspectMethod(JoinPoint jp,
            JoinPoint.EnclosingStaticPart esjp, Transactional trx) {
        log.info(
                ""Entering FilterCallerAnnotationAspect.inspectMethod() in class ""
                        + jp.getSignature().getDeclaringTypeName()
                        + "" - method: "" + jp.getSignature().getName());
    }
}
```

This aspect will only be applied when the `service` method of `UselessService`
class is called from methods annotated with Spring's `Transactional` annotation.

1. Filter by caller's method's name,

```java
@Aspect
public class FilterCallerMethodAspect {

    private static final Logger
            log = LoggerFactory.getLogger(FilterCallerMethodAspect.class);

    @Before(""call(* com.basaki.service.UselessService.sayHello(..))"" +
            ""  && cflow(execution(* com.basaki.service.BookService.read(..)))"")
    public void inspectMethod(JoinPoint jp,
            JoinPoint.EnclosingStaticPart esjp) {
        log.info(
                ""Entering FilterCallerMethodAspect.inspectMethod() in class ""
                        + jp.getSignature().getDeclaringTypeName()
                        + "" - method: "" + jp.getSignature().getName());
    }
}
```

This aspect will only be applied when the `service` method of `UselessService`
class is called from `read` method of `BookService`.

### Dependency Requirements

#### AspectJ Runtime Library
Annotation such as `@Aspect`, `@Pointcut`, and `@Before` are in `aspectjrt.jar`.
The `aspectjrt.jar` and must be in the classpath regardless of whether 
the aspects in the code are compiled with `ajc` or `javac`.

```xml
<dependency>
    <groupId>org.aspectj</groupId>
    <artifactId>aspectjrt</artifactId>
    <version>1.8.13</version>
</dependency>
```

#### AspectJ Weaving Library
The `aspectjweaver.jar` contains the AspectJ wevaing classes. The weaver is 
responsible for mapping crosscutting elements to Java constructs.

```xml
<dependency>
    <groupId>org.aspectj</groupId>
    <artifactId>aspectjweaver</artifactId>
    <version>1.8.13</version>
</dependency>
```

#### AspectJ Weaver Configuration

The load-time waving is configured using a file named `aop.xml`. The `aop.xml`
is made available to the classpath by placing it in the `META-INF` directory
under the `resources` folder.

The `aop.xml` contains the following sections:

1. **Aspect** section defines all the aspects that are to be used 
in the weaving process. In our example, there is only one aspect, i.e.,
`CustomAnnotationAspect`.

2. **Weaver** section defines all the classes (e.g., `com.basaki.service.*`) 
that are to be woven. 

It should also include the packages where the aspects are defined
 (e.g., `com.basaki.aspect.*`).
 
It also specifies other weaving options, e.g., `verbose`, `showWeaveInfo`, etc.

```xml
<aspectj>
    <aspects>
        <aspect name=""com.basaki.aspect.CustomAnnotationAspect""/>
        <weaver options=""-verbose -showWeaveInfo"">
            <include within=""com.basaki.service.*""/>
            <include within=""com.basaki.aspect.*""/>
        </weaver>
    </aspects>
</aspectj>
```

#### AspectJ Maven Plugin
The `maven-surefire-plugin` plugin is only needed if you run the Spring Boot
application from an IDE (e.g., IntelliJ). It's required to add the 
`-javaagent` JVM arguments.

```xml
<plugin>
   <groupId>org.apache.maven.plugins</groupId>
   <artifactId>maven-surefire-plugin</artifactId>
   <version>2.20.1</version>
   <configuration>
      <argLine>-javaagent:""${settings.localRepository}""/org/aspectj/
                        aspectjweaver/1.8.13/
                        aspectjweaver-1.8.13.jar</argLine>
      <useSystemClassLoader>true</useSystemClassLoader>
      <forkMode>always</forkMode>
   </configuration>
</plugin>
```

### Build
To build the JAR, execute the following command from the parent directory:

```
mvn clean install
```

### Run
You need to use the `-javaagent:` JVM argument whenever you run the 
executable Spring Boot jar. 

Here is the command to run the application:
```
java -javaagent:lib/aspectjweaver-1.8.13.jar -jar spring-loadtime-weaving-example-1.0.0.jar
```
In the example shown below, it's expected that the `aspectjweaver.jar` 
is located in the `lib` directory.

### Usage
Once the application starts up at port `8080`, you can access the swagger UI at 
`http://localhost:8080/swagger-ui.html`. From the UI, you can create and retrieve
book entities.

Once you create a book entity, you should notice the following message on the
terminal:

```
2018-02-09 17:11:38.022  INFO 51061 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 25 ms
2018-02-09 17:11:38.193  INFO 51061 --- [nio-8080-exec-1] c.basaki.aspect.CustomAnnotationAspect   : Entering CustomAnnotationAspect.inspectMethod() in class com.basaki.service.BookService - method: validateRequest description: Validates book request.
2018-02-09 17:11:38.194  INFO 51061 --- [nio-8080-exec-1] com.basaki.service.BookService           : Validating book request!
```

[travis-badge]: https://travis-ci.org/indrabasak/spring-loadtime-weaving-example.svg?branch=master
[travis-badge-url]: https://travis-ci.org/indrabasak/spring-loadtime-weaving-example/

[sonarqube-badge]: https://sonarcloud.io/api/project_badges/measure?project=com.basaki%3Aspring-loadtime-weaving-example&metric=alert_status
[sonarqube-badge-url]: https://sonarcloud.io/dashboard/index/com.basaki:spring-loadtime-weaving-example 

[technical-debt-ratio-badge]: https://sonarcloud.io/api/project_badges/measure?project=com.basaki%3Aspring-loadtime-weaving-example&metric=sqale_index
[technical-debt-ratio-badge-url]: https://sonarcloud.io/dashboard/index/com.basaki:spring-loadtime-weaving-example 

[coverage-badge]: https://sonarcloud.io/api/project_badges/measure?project=com.basaki%3Aspring-loadtime-weaving-example&metric=coverage
[coverage-badge-url]: https://sonarcloud.io/dashboard/index/com.basaki:spring-loadtime-weaving-example
"
mitchtabian/Retrofit-Caching-Example,master,34,21,2019-04-12T22:52:53Z,133,0,An example of how to use Retrofit2 to cache HTTP responses,android-caching cache cache-control okhttp3 retrofit2,
Gary111/MaskedEditText,master,54,14,2014-06-22T03:55:22Z,250,1,Example of formatting card number / date / cvc during entering text,,"# MaskedEditText
Simle example of how to format card number / date / cvc during entering text

![Example Masked EditText][1]

[1]: https://github.com/Gary111/MaskedEditText/blob/master/screens/demo.gif
"
simple-elf/github-allure-history,master,29,12,2020-08-07T07:39:33Z,3872,0,Example of using Allure Report on GitHub Actions,,"# github-allure-history
Example project using GitHub Actions for Allure report with history on GitHub Pages

You can see [Allure Report](https://simple-elf.github.io/github-allure-history/) on GitHub Pages

## GitHub Actions
Learn how to use GitHub Actions on [official docs](https://docs.github.com/en/actions)

Here is my advices:
1. You need to enable actions in '/settings/actions', choosing 'Enable local and third party Actions for this repository'
2. Create a workflow '*.yml' file in '.gradle/workflows' directory. Example workflow [allure-history.yml](https://github.com/simple-elf/github-allure-history/blob/master/.github/workflows/allure-history.yml)
3. This workflow uses some GitHub Actions, especially 'allure-report-action'. You can see more about this action on [Marketplace](https://github.com/marketplace/actions/allure-report-with-history)

## GitHub Pages
Learn how to use GitHub Pages on [official docs](https://docs.github.com/en/github/working-with-github-pages)

Here is my advices:
1. Go to your repository '/settings', scroll down to 'GitHub Pages' section
2. By default, 'Source' is set to 'None'
3. Set it to 'gh-pages' branch and '/root' folder
4. If you don't have 'gh-pages' branch - you can't set it. You need to run workflow even once, and then you have this branch.
5. After changing settings you can see URL link in 'GitHub Pages' section like this 'Your site is published at ...'
6. Copy this link to repository details (in 'About' section on repo main page) in WebSite field

## Allure Report with history on GitHub Pages
Here is how this works:

1. Step 'Get Allure history' in workflow gets previous 'gh-pages' branch state (there is no error if it doesn't exist yet)
2. Step 'Allure Report action':
    1. Creates temp folder 'allure-history' with a copy of all 'gh-pages' branch files (previous reports)
    2. Get folder 'last-history' from 'gh-pages' branch to 'allure-results' of current build
    3. Generate report with Allure Commandline
    4. Get 'history' folder of current Allure Report to 'last-history' folder for the next build
    5. Copy current Allure Report to folder with current build number
    6. Creates 'index.html' file in root of 'allure-history', that will be redirecting to folder with current build number
3. Step 'Deploy report to Github Pages' do 'git push' of 'allure-history' folder to 'gh-pages' branch
4. And then just magic of GitHub Pages deploy happens, you can open root link of GitHub Pages and always see redirect to the last Allure Report"
lykhonis/MediaCodec,master,77,33,2015-06-05T18:24:41Z,160,1,Example of how to use MediaCodec to encode/decode and pass samples as byte array,,"# MediaCodec
Example show case use cases of MediaCodec. It can be valuable for applications that doing encoding, decoding and transfering samples in H.264 (for example) over network, etc.

Example contains:
- Creating surface and associated canvas to draw onto
- Binding surface to encoder to produce H.264 samples
- Creating surface view and binding decoder to it
- Configuring decoder to accept H.264 and draw onto surface view
"
aws-samples/aws-greengrass-lambda-functions,master,64,42,2018-11-07T22:26:12Z,2793,135,Example local Lambda functions that can be used with AWS Greengrass and the AWS Greengrass Provisioner.,aws-greengrass greengrass,"## AWS Greengrass Lambda Functions

Example local Lambda functions that can be used with AWS Greengrass and the AWS Greengrass Provisioner.  This repo contains
the functions and the deployment configurations to launch those functions in different configurations.

## News

2020-01-27 - Minor changes to the role naming scheme may cause issues with existing deployments. If you are experiencing issues with permissions you can either switch to the new naming scheme (e.g. `Greengrass_CoreRole`, `Greengrass_ServiceRole`, and `Greengrass_LambdaRole`) or you can update the deployments.defaults.conf file to use the older names.

## How do I launch these functions with the provisioner?

Step 1: Clone this repo

Step 2: [Read the provisioner command-line examples](https://github.com/awslabs/aws-greengrass-provisioner/blob/master/docs/CommandLine.md)

## Using Java?

Check out the [Cloud Device Driver framework](https://gitpitch.com/aws-samples/aws-greengrass-lambda-functions/master?p=presentations/cloud-device-driver-framework-for-java). It is a framework that simplifies writing Greengrass Lambda functions in Java. [You can look at the code as well](foundation/CDDBaselineJava).

## Current function list

- Python
  - [BenchmarkPython](functions/BenchmarkPython) - a naive benchmark that creates a pinned function that sends messages to itself
  - [HTTPPython](functions/HTTPPython) - sends HTTP requests from the core to any address (local network or otherwise), triggered by MQTT messages from the cloud
  - [HelloWorldPython3](functions/HelloWorldPython3) - Hello, World in Python 3
  - [HelloWorldPythonWithCloudFormation](functions/HelloWorldPythonWithCloudFormation) - Hello, World in Python with a CloudFormation template that demonstrates how to build republish rules that the provisioner can launch automatically
  - [LiFXPython](functions/LiFXPython) - control LiFX bulbs
  - [SocketServerPython](functions/SocketServerPython) - an example of how to listen on a socket in Python and relay the inbound TCP messages to the cloud via MQTT
  - [RaspberryPiGpioPython3](functions/RaspberryPiGpioPython3) - Event driven GPIO handler for the Raspberry Pi (no polling)
  - [LatencyTesterPython3](functions/LatencyTesterPython3) - Sends ping requests to a fixed list of hosts and publishes the round trip ICMP ping time via MQTT
  - [CloudWatchMetricHandlerPython3](functions/CloudWatchMetricHandlerPython3) - Sends latency information to AWS as CloudWatch Metric values (used with LatencyTesterPython3)
  - [SecretsManagerPython3](functions/SecretsManagerPython3) - Retrieves a secret from Secrets Manager and publishes the value on a topic for testing purposes
  - [MqttClientPython3](functions/MqttClientPython3) - Connects to an MQTT broker as a client and relays messages from that broker to Greengrass

- NodeJS
  - [HelloWorldNode](functions/HelloWorldNode) - Hello, World in Node
  - [HTTPNode](functions/HTTPNode) - sends HTTP requests from the core to any address (local network or otherwise), triggered by MQTT messages from the cloud
  - [WebServerNode](functions/WebServerNode) - an example of how to create an Express web server in a pinned Lambda function

- Java with Cloud Device Driver framework
  - [CDDSkeletonJava](functions/CDDSkeletonJava) - shows how the Java Cloud Device Driver framework can be used
  - [CDDDMIJava](functions/CDDDMIJava) - relays Desktop Management Interface (DMI) information to the cloud when requested via MQTT
  - [CDDBenchmarkJava](functions/CDDBenchmarkJava) - a naive Java benchmark that creates a pinned function that sends messages to itself
  - [CDDSenseHatJava](functions/CDDSenseHatJava) - shows how to control a SenseHat display on a Raspberry Pi
  - [CDDDockerJava](functions/CDDDockerJava) - shows how to control Docker with Greengrass
  - [CDDLatencyDashboard](functions/CDDLatencyDashboard) - a Vaadin-based dashboard to show latency information (used with LatencyTesterPython3)
  - [CDDMdnsServiceResolverJava](functions/CDDMdnsServiceResolverJava) - resolves mDNS service discovery broadcasts and publishes the discovery information to other functions

- C
  - [ARM32SampleC](functions/ARM32SampleC) - Hello World in C for ARM32 architectures
  - [X86_64SampleC](functions/X86_64SampleC) - Hello World in C for X86_64 architectures

- Greengrass Provisioner functionality examples
  - [Reusing functions from other groups (benchmark example)](deployments/benchmark-reuse.conf) - shows how to reuse existing functions in the Greengrass Provisioner by using the tilde `~` wildcard
  - [Launching an nginx proxy on ARM Greengrass cores with the Greengrass Docker connector](deployments/arm-nginx.conf) - **ARM only!** shows how to use the Greengrass Docker connector in a deployment to launch nginx
  - [Launching Wordress on X86 Greengrass cores with the Greengrass Docker connector](deployments/x86-wordpress.conf) - **X86 only!** shows how to use the Greengrass Docker connector in a deployment to launch Wordpress
  - [Sharing files between two functions in Python 3](deployments/python3-shared-file.conf) - shows how to share a file between two functions through the host. Each function randomly writes a value to a file that the other function can read, then the other function picks up the value, publishes it to the core, and deletes the shared file so it can be created again.

## License Summary

This sample code is made available under a modified MIT license. See the LICENSE file.
"
djangofan/selenium-gradle-example,master,28,12,2013-09-08T05:05:18Z,728,5,A Selenium2 example using the Gradle build system,,"# Info

This is a Java project that can be used as a template (or archetype) to start a WebDriver web browser testing project.  I chose to simplify and and implement using simply WebDriver and Gradle.<br/>

Presentation is for ""Portland Selenium Bootcamp 2013"".  
[PDX-SE Meetup Group](http://www.meetup.com/pdx-se/events/125285182/)

Special thanks to the creator of Gradle, for having some good examples.
[Ken Sipe](https://github.com/kensipe/gradle-samples)

NOTE: Keep in mind that these examples use multiple WebDriver instances, which may not be a normal design
pattern, especially in frameworks that are limited to one WebDriver instance, such as SauceLabs.

# Versions

Version 1.0 - March 16th, 2013

Version 2.0 - September 6th, 2013

# Project Layout

    Gradle Project Root
    +--- Project ':sub-project'
    +--- Project ':commonlib'
    +--- Project ':etsy'
    +--- Project ':parallelwindows'
    +--- ...

# Overview

    1. Project ""sub-project"" is a project you add yourself, if you 
       want.
    2. Project ""etsy"" is a RemoteWebDriver JUnit test-suite using
       a local Grid server that is capable of running multiple 
       threads of single-window web browser tests.
    3. Project ""parallelwindows"" is a test of a  multi-window and
       multi-threaded run using a static local website.
    4. Project ""commonlib"" is a sub-project containing methods 
       shared between projects.

# SubProjects
Links to example sub-projects that belong to this project:

[ParallelWebDriver](https://github.com/djangofan/selenium-gradle-example/tree/master/parallelwindows)

[Etsy](https://github.com/djangofan/selenium-gradle-example/tree/master/etsy)

# Quick Start
Normally, this project would be ran through the Gradle plugin for Eclipse IDE, but I have tried to make it easier 
by including a method to run dynamically and directly from the .zip distribution on the command line.

To try this project without requiring a Java IDE, just make sure you download Gradle 1.7+, configure your 
GRADLE_HOME environment variable, add %GRADLE_HOME%\bin to your PATH, and then download the .zip distribution
of this project, unzip it, and run the included <b>runProjectMenu.bat</b> script.

# Implemented Features
<table>
  <tr>
    <th>Feature</th>
    <th>Description</th>
  </tr>
  <tr>
    <th>JUnit based</th>
    <td>For use ONLY with JUnit 4.11 or higher because of the usage of the parameterized capability of JUnit. 
    This dependency is configured by the Gradle build script.</td>
  </tr>
    <tr>
    <th>Parallel runner<br/>using JUnit</th>
    <td>A parallel runner using the Gradle maxParallelForks method.</td>
  </tr>
  <tr>
    <th>Native automation support</th>
    <td>For use with Sikuli 1.0.1 or higher to test native elements that WebDriver ""Action"" is unable to 
    control. This dependency is configured in the Gradle build script.  If you implement this however, you
    may not be able to use the remote webdriver option in your project.</td>
  </tr>
    <tr>
    <th>Uses RemoteWebDriver<br/>JSON Hub Server</th>
    <td>I have included an implementation of a WebDriverServer class that starts a RemoteWebDriver JSON 
    Hub server instance in the BeforeClass method of tests. This server is a static member of the utility
    class that the tests extend.</td>
  </tr>
  <tr>
    <th>Parameterized data <br/>driven capability</th>
    <td>Unit tests are parameterized from a csv file.  Can also load tests from XML, XLS, a database, etc.</td>
  </tr>
  <tr>
    <th>Logging and Reporting</th>
    <td>Logs test output to console and to a file using SLF4j/LogBack API, and configured by a <b>logback.xml</b>
    file. Will generate reports of JUnit test results at <b>build/reports/test/index.html</b> .  Will place a
    junit.log file at <b>build/logs/junit.log</b> .</td>
  </tr>
  <tr>
    <th>Page Object design <br/>pattern</th>
    <td>Uses the WebDriver ""page object"" design pattern, enhanced by the Selenium ""LoadableComponent"" 
    extendable class.</td>
  </tr>
    <tr>
    <th>Fluent API design<br/>pattern</th>
    <td>Implemented examples of the <i>Fluent API</i> design pattern while retaining capability of 
    the traditional page object pattern.</td>
  </tr>
  <tr>
    <th>Multi-project build<br/>configuration</th>
    <td>Implemented multiple project build.  The root project has a subproject called ""core"" and all 
   subprojects of ""core"" inherit classes from it.</td>
  </tr>
  <tr>
    <th>Run Options</th>
    <td>You have three different options for running the tests: via the Gradle GUI, via your IDE Gradle
    plugin, or via Gradle command line. To run with the JUnit runner in your IDE, you would need to manually
    export your project as a normal Java project, because this template does not support that.</td>
  </tr>
  <tr>
    <th>Core utility package</th>
    <td>All projects inherit from a ""core"" project that contains classes where you can store methods
        that all of your projects can share between them.</td>
  </tr>
</table>

# Un-implemented Features
<table>
  <tr>
    <th>Feature</th>
    <th>Description</th>
  </tr>
  <tr>
    <th>Gradle Wrapper</th>
    <td>Did not choose to implement the Gradle wrapper because I believe that downloading Gradle and
       configuring GRADLE_HOME and PATH are easy enough.  Also, a manual setup of Gradle gives us more
       control using a batch script.  Also, the development IDE is usually configured to use the 
       statically defined Gradle home.</td>
  </tr>
  <tr>
    <th>Jar executable option</th>
    <td>Creates an uberJar of all projects and subprojects that can be ran by double clicking
       the .jar file.  If you don't have the file association supporting it, we include a 
       jarAssociation.bat file to setup the file association on your Windows system.  I was planning
       to implement this but currently having trouble getting it to work.</td>
  </tr>
</table>

# Configuration And Setup

#### Eclipse
To get it working on a regular Eclipse Kepler (2.9.0) or later, follow these steps:
 
    1. Using the ""Eclipse Marketplace"" settings panel under the 
       Eclipse ""Help"" menu, install the Gradle tooling 
       functionality.  You can do it through the ""Install New
       Software"" menu, but it isn't recommended.  If Market is
       missing from your Eclipse, then add the repo:
       http://download.eclipse.org/releases/kepler
       and then install the ""market"" and restart Eclipse.
    2. Download the .zip archive of this GitHub project 
       distribution and unzip it to your workspace.  An example:
       ""C:\Eclipse32\workspace\selenium-gradle-example\"" .
    3. Use the Eclipse ""Import"" function from the Eclipse ""File
       menu"" to import a ""Project"" of type ""Gradle"".
    4. Browse using the import wizard to your projects ""root"" 
       directory.  Then click the ""Build model"" button.
    5. Check all checkboxes .  You could also choose to add all 
       to your ""working set"" if you like but it isn't required.
    6. Rebuild the dependencies by right clicking on the project
       and then choose Gradle-->Refresh All Dependencies
    7. Right click on your project and choose ""Run As-->External
       Tools Configuration"".  Configure a new ""clean"" and ""build""
       configuration for running a sub-project (or whatever tasks
       you want to execute).
    8. Optionally, you can run this project on the command line
       with something like ""gradle etsy:clean etsy:runTask --info"" 
       and it will execute the project unit tests.  Also, this 
       project provides a .bat batch script that does this and
       provides a menu of other actions you can execute, including 
       running the ""Gradle GUI"".

#### IntelliJ-IDEA
The required Gradle functionality is already built into IntelliJ-IDEA 12.1+ .  I think using IDEA is more difficult
but go ahead if you are familiar with it.

#### Notes
Website of this project:<br/>
http://djangofan.github.com/selenium-gradle-example/<br/>
<br/>

# FAQ

    1. If the intellisense in Eclipse doesn't work, make sure you 
       have added all the .class directories to your Eclipse project
       classpath.  (See the included .classpath file.)
    2. I use ""GitHub GUI"" to sync my local project repo to GitHub. 
       If you fork my project, I would recommend doing it this way
       unless you are a Git expert and prefer another way.
"
ricardozanini/soccer-stats,master,84,168,2017-09-14T18:19:50Z,155,0,Soccer Stats is an example application to be used as a proof of concept for a presentation at Ansible Meetup in São Paulo,ansible jenkins jenkins-pipeline spring-boot,"# Soccer Stats

Soccer Stats is an example application to be used as a proof of concept for a presentation at [Ansible Meetup in São Paulo](https://www.meetup.com/Ansible-Sao-Paulo/events/243212921/).

## Pre-requistes

* JDK 1.8
* Maven 3.3+

## Environment

It's a sample Rest API built upon Spring Rest Framework. The database is based on data gathered from 2015/2016 season of Italian Soccer National Championship.

During the Spring Context bootstrap a temporary database is created using H2 with data imported from a spreedsheet.

## Installation

Just run `mvn clean package` on the project directory and your ready to go.

## Using

Bring the application up by running `java -jar soccer-stats-X.X.X.jar`, where's `X.X.X` is the project's version.

After the startup the endpoint should be availble at `http://localhost:8080/matches/{team_name}` where `{team_name}` must be a Italian team name like `juventus`, `milan`, `udinese` and so on.

To bring a specific match, try the endpoint `http://localhost:8080/matches/{home_team_name}/{visitor_team_name}` replacing the param vars to the match you'd like to see, for example:

[http://localhost:8080/matches/juventus/milan](`http://localhost:8080/matches/juventus/milan`)

## Credits

[Football-Data](http://www.football-data.co.uk/) for providing the data used for this lab."
MetaArivu/Kafka-quickstart,main,37,18,2021-09-27T03:38:45Z,195978,0,"Kafka Examples focusing on  Producer, Consumer, KStreams, KTable, Global KTable using Spring, Kafka Cluster Setup & Monitoring. Implementing  Event Sourcing and CQRS Design Pattern using Kafka",cqrs event-sourcing global-ktable kafka kafka-admin kafka-consumer kafka-producer kafka-prometheus kafka-ssl kstream ktable spring-kafka spring-kafka-test,"# Kafka Examples Using Spring

This tutorial focus of different features of KAKFA

## 1: [Kafka Setup](https://github.com/MetaArivu/spring-kaka-examples/tree/main/01-kafka-setup)
   - Kafka Setup
   - Kafka SSL Configuration 

## 2: [Kafka Producer](https://github.com/MetaArivu/spring-kaka-examples/tree/main/02-spring-kafka-producer)
  This demo focus on following feature
- 1 Asynchronous Simple Event Publisher
- 2 Event Publisher with key, this will  make sure event with same key goes to same partition
- 3 Event Publisher with callback method
- 4 Publish event with headers
- 5 Publish event in synchronous way
- 6 How to use embeded kafka for unit testing

## 3: [Kafka Consumer](https://github.com/MetaArivu/spring-kaka-examples/tree/main/03-spring-kafka-consumer)
This Deemo Focus on following features
- 1 Simple event consumer
- 2 Event consumer with consumer rercord, this will give you more information of message like Key, Partition, Offset etc
- 3 Event consumer with header, this will give you all the standard header and custom header information
- 4 How to handle exception in generic way
- 5 Manual Acknowledgement 
- 6 Concurrent Message Listener
- 7 Retry

## 4: [Schema Registry & AVRO](https://github.com/MetaArivu/spring-kaka-examples/tree/main/04-schema-registry-with-avro)
This section focus on how to enable usage of Confluent Schema Registry and Avro serialization format in your Spring Boot applications.

## 5: KStream & KTable

<img width=""1009"" alt=""Screen Shot 2021-11-01 at 11 42 07 PM"" src=""https://user-images.githubusercontent.com/23295769/139720133-89848b21-2197-427a-b82a-01425ca1ed83.png"">


## 5.1: [KStream](https://github.com/MetaArivu/spring-kaka-examples/tree/main/05-kafka-streams-demo)
This section focus on how to use KStream
- 1 Working with KStream
- 2 Implementing Exactly Once Pattern
- 3 Handling Business Error
- 4 Branching
- 5 Reducing
- 6 Aggregation
- 7 Joining KStreams and Global Table

## 5.2: [KTable](https://github.com/MetaArivu/spring-kaka-examples/tree/main/06-kafka-ktable-demo)
This section focus on how to use KTable
- 1 Working with Ktable
- 2 Aggregation
- 3 Reducing
- 4 Global Table

## 6: [CQRS and EventSourcing](https://github.com/MetaArivu/spring-kaka-examples/tree/main/07-shopping-cart-cqrs-es)
This section focus on implementing Event Sourcing & CQRS using Kafka KStream & KTable. Here we have build small Shopping Cart Service functionality. 

![WhatsApp Image 2021-10-28 at 4 16 30 PM](https://user-images.githubusercontent.com/23295769/139241202-d8ef26b8-86f6-484a-908b-038fda1a70fd.jpeg)

## 7: [Kafka Cluster Setup & Monitoring](https://github.com/MetaArivu/Kafka-examples/tree/main/08-cluster-setup)
This section focus on setting Kafka Cluster Setup. In this demo we will focus on setting 3 zookeeper with 3 broker setup.

![WhatsApp Image 2021-11-03 at 10 52 44 AM](https://user-images.githubusercontent.com/23295769/140013322-c9720806-d1a8-429e-9793-d94cc468385e.jpeg)

<img width=""1676"" alt=""Screen Shot 2021-11-03 at 3 58 02 PM"" src=""https://user-images.githubusercontent.com/23295769/140044753-02b47885-1340-49a3-80b2-d8f37a9bb132.png"">

<img width=""1626"" alt=""Screen Shot 2021-11-03 at 1 20 14 PM"" src=""https://user-images.githubusercontent.com/23295769/140025386-8eac06d9-b45d-4666-a038-e376b569b0da.png"">


## License  

Copyright © [MetaMagic Global Inc](http://www.metamagicglobal.com/), 2021-22.  All rights reserved.

Licensed under the Apache 2.0 License.

**Enjoy!**
"
IMS94/spring-boot-jwt-authorization,master,52,30,2021-09-19T06:30:09Z,547,2,Example project to do role based access control (RBAC) using Spring Boot and JWT,authorization jwt jwt-authentication rbac rest-api role-based-access-control roles security single-page-app spring-boot spring-security,"# Role Based Access Control (RBAC) with Spring Boot and JWT

This repo hosts the source code for the article [**Role Based Access Control (RBAC) with Spring Boot and JWT**](https://medium.com/geekculture/role-based-access-control-rbac-with-spring-boot-and-jwt-bc20a8c51c15?source=github_source).

This example project demonstrates how to use the Spring Boot's inbuilt OAuth2 Resoure Server to authenticate and 
authorize REST APIs with JWT. First, we have enabled **JWT authentication** and secondly, have introduced 
**Role Based Access Control (RBAC)** by mapping a roles claim in JWT to granted authorities in Spring Security.

Furthermore, provides a ""/login"" endpoint to generate and issue JWTs upon
successful login by the users.

This approach is ideal to be used as the 
**backend for a single page application (SPA)** written using a frontend framework like
ReactJS, Angular, etc...

## Solution Overview

![Solution Overview](https://github.com/IMS94/spring-boot-jwt-authorization/blob/master/authorization_process.png?raw=true ""Solution Overview"")

## Role Based Access Control
An example of role based access control.

![RBAC Example](https://github.com/IMS94/spring-boot-jwt-authorization/blob/master/rbac_sample.png?raw=true ""Solution Overview"")

## JWT Authentication Overview

![Solution Overview](https://github.com/IMS94/spring-boot-jwt-authorization/blob/master/solution_overview.png?raw=true ""Solution Overview"")

## Getting Started

- Use `mvn clean install` in the project root directory to build the project. 
- Run the main class, `com.example.springboot.jwt.JwtApplication` to start the application.

## Endpoints

- `/login` -> Public endpoint which returns a signed JWT for valid user credentials (username/password)
- `/products` -> Contains several endpoints to add and remove product entities. Protected by JWT authentication and
authorized based on role.
"
ekoontz/jaas_and_kerberos,master,26,22,2010-11-20T03:09:05Z,770,0,Example code: using JAAS (Java Authentication and Authorization Service) and Kerberos,,"# Introduction

This is a set of example code to explain how to use Kerberos with the
JAAS (Java Authentication and Authorization Service) API. The source
code is split into two classes, `KerberizedServer.java` and
`Client.java`. Running `make test` will compile and run them both, at
which time they will set up an authenticated context between them and
print some debugging information.

# Standard Sockets and NIO (Java's New IO)

There are two versions of the server: `KerberizedServer.java`, which
uses the traditional blocking network sockets API, and
`KerberizedServerNIO.java`, which uses NIO. The standard sockets
version is much shorter and easier to understand, so start with
that. However, most real-world Java development seems to use NIO, so I
made a version that uses that. There is also a newer framework called
[Netty](http://jboss.org/netty), built on top of NIO, which I'll be
looking into at some point, and porting the server code to.

# Acknowledgements and Related Work

## [Client/Server Hello World in Kerberos, Java and GSS](http://thejavamonkey.blogspot.com/2008/04/clientserver-hello-world-in-kerberos.html)

A search returned this guide by a blogger who goes by the name Java
Monkey. Java Monkey's approach was exactly what I was looking for:
a ""Hello World"" application, documented and commented clearly, that
can be studied and understood quickly.

The only drawback, from my point of view, is that it uses the
filesystem for client-server communication: the client logs into
Kerberos and generates a ticket which it writes to a key file. The
server then uses this file to authenticate the client.

However, I wanted to have a Kerberos ""Hello World"" where the client
and server communicate via a network socket, so that's why I've
created this github repository.

## [Rox Java NIO Tutorial](http://rox-xmlrpc.sourceforge.net/niotut/)

A good guide to learning Java NIO by James Greenfield, as part of his
RoX (RPC over XML) project. Based on his helpful information, I was
able to write a NIO version of my example code after starting with a
traditional sockets implementation.

## [Sun/Oracle official JAAS tutorials](http://java.sun.com/j2se/1.5.0/docs/guide/security/jgss/tutorials/index.html)

I recommend you look at my example code and then only afterwards look
at the Sun/Oracle materials. I found them too complex for tutorial
purposes; they are better as a reference source.

Commenting on these official JAAS documentation articles, Java Monkey writes:

> the code is a socket based client/server which is not useful at all,
> as only a lunatic would be writing their own server communications
> layer in these days of NIO and SOA.

I partially agree with him here. The main problem, from my experience,
of the Sun Tutorial is that it doesn't actually work: the code they
supply simply doesn't function as-is. Also, it uses byte arrays with
an array-length prefix to communicate between the client and server,
which is unnecessarily low-level. I improved this by using standard
sockets but used `Data`{`Input`/`Output`}`Streams` instead of byte
arrays.

One disadvantage of NIO compared to traditional sockets is the API
complexity: compare `KerberizedServer.java` with
`KerberizedServerNIO.java`: the latter is twice as long. (Although, 
`KerberizedServer.java` as written, does not handle more than
one client, whereas `KerberizedServerNIO.java` does, so it's not a
fair comparison).

Another disadvantage of using NIO, however, is that you can't use
`Data`{`Input`/`Output`}`Streams`, unfortunately, as far as I can
tell; would like to be wrong about that.

# Prerequisites

## Kerberos server and client tools

If you're using Debian, install:

* krb5-admin-server
* krb5-kdc

## JDK

This code was tested with the Sun JDK version 1.6.0_22.

## GNU Make

I used GNU Make for development and testing rather than Apache Ant for
simplicity, but an Ant build.xml or a Maven pom.xml would be good to have here.

# Setup Kerberos Server Infrastructure

## Choose realm name

In my documentation and example configuration files, I use
`FOOFERS.ORG` as my Kerberos realm, and `debian64-3` as the host
running the Kerberos services. Change these based on your preference.

## Edit /etc/krb5.conf

    [libdefaults]
           default_realm = FOOFERS.ORG

    [realms]
           FOOFERS.ORG = {
       		    kdc = debian64-3
                    admin_server = debian64-3
           }
    [domain_realm]
           .foofers.org = FOOFERS.ORG
           foofers.org = FOOFERS.ORG

## Choose principal names.

Choose a principal name for your example client and one for your
example server. Below I use `zookeeperclient` for the client, and
`zookeeperserver` for the server.

## Add principals using kadmin.local 

### Add server principal

We will use `testserver` as the name of the server principal that
`KerberizedServer` and `KerberizedServerNio` uses. It's conventional
to use keytab files, rather than passwords, as Kerberos credentials
for server daemons. This allows a server process to start itself
without manual intervention : no password need be supplied; the server
process simply reads the keytab file and uses this to authenticate with the KDC.

We will therefore use `kadmin.local` to add the server principals
using the `-randkey` option to specify that we don't want to use a
password for server authentication.

On the host on which the KDC runs, do:

     # kadmin.local
     kadmin.local: addprinc -randkey testserver/HOSTNAME
     kadmin.local: ktadd -k /tmp/testserver.keytab testserver/HOSTNAME
     Entry for principal testserver/HOSTNAME with kvno 2, encryption type AES-256 CTS mode with 96-bit SHA-1 HMAC added to keytab WRFILE:/tmp/testserver.keytab.
     Entry for principal testserver/HOSTNAME with kvno 2, encryption type ArcFour with HMAC/md5 added to keytab WRFILE:/tmp/testserver.keytab.
     kadmin.local: (Ctrl-D)

     # scp /tmp/testserver.keytab user@HOSTNAME:~/jaas_and_kerberos

Where `user` is the user who will run `KerberizedServer` and
`KerberizedServerNio`, and `HOSTNAME` is the host on which you will
run them.

 You should add a principal entry for each network interface that your
server will use - otherwise client authentication to
`KerberizedServer` and `KerberizedServerNio` may fail, and you may see
errors in your /var/log/auth.log like :

    Dec 14 14:09:17 debian64-3 krb5kdc[4177]: TGS_REQ (6 etypes {3 1 23 16 17 18}) 192.168.56.1: UNKNOWN_SERVER: authtime 0,  testclient@FOOFERS.ORG for testserver/192.168.0.100@FOOFERS.ORG, Server not found in Kerberos database

To fix this, I added (using `ktadd` as above) a principal for `testserver/192.168.0.100`.

### Add client principal

On the host on which the KDC runs, do:

     # kadmin.local
     kadmin.local: addprinc testclient
     Enter password for principal ""testclient@FOOFERS.ORG"": 
     Re-enter password for principal ""testclient@FOOFERS.ORG"": 

See `client.properties` in this directory, which is also shown
below. This assumes you used `clientpassword` as the password in
`kadmin.local` above.

    client.principal.name=zookeeperclient
    client.password=clientpassword
    service.principal.name=testserver

# Test Kerberos Server Infrastructure

## Test server authentication with `kinit -k -t testserver.keytab`
   (these options means use the keytab for authentication rather than
   asking for a password).

     ekoontz@ekoontz:~/jaas$ kinit -k -t testserver.keytab testserver/192.168.0.100
     ekoontz@ekoontz:~/jaas$ 

## Test client authentication with `kinit testclient`

     ekoontz@ekoontz:~/jaas$ cat client.properties 
     client.principal.name=testclient
     client.password=clientpassword
     service.principal.name=testserver
     ekoontz@ekoontz:~/jaas$ kinit testclient
     Please enter the password for testclient@FOOFERS.ORG: 
     ekoontz@ekoontz:~/jaas$ 

# Compile Java example code

Run `make compile`

# Runtime configuration of Java example code

## Server principal in jaas.conf.

See `jaas.conf` in this directory, which is also shown below. Change
`HOSTNAME` to the host that `KerberizedServer` and
`KerberizedServerNio` will run on. Note that we use a single entry
(`KerberizedServer`) for both `KerberizedServer` and
`KerberizedServerNio`.

    Client {
       com.sun.security.auth.module.Krb5LoginModule required
       useTicketCache=false;
    };

    KerberizedServer {
       com.sun.security.auth.module.Krb5LoginModule required
       useKeyTab=false
       keyTab=""testserver.keytab""
       useTicketCache=false
       storeKey=true
       principal=""testserver/HOSTNAME"";
    };

# Test

Run `make test` will start up the example server and run the client
against it. You may run the client against the same server afterwards
by doing `make test_client`. You can kill an existing server process
by doing `make killserver`.
"
inazaruk/map-fragment,master,30,20,2012-07-27T21:23:43Z,644,3,An example of how one can use MapActivity as a fragment.,,"map-fragment
============

An example of how one can use MapActivity as a fragment.


All code in this repository is under [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0.html) (unless otherwise is stated in file header)."
konmik/Dagger2Example,master,75,9,2015-01-31T02:57:57Z,4408,0,"This example is for Snorkeling with Dagger 2"" article""",,"# Dagger2Example

This example is for [Snorkeling with Dagger 2](http://konmik.github.io/snorkeling-with-dagger-2.html) article.
"
zupzup/react-native-ethereum,main,63,12,2017-07-26T10:11:08Z,425,8,Example code for creating an ETH wallet with react-native,,"# react-native-ethereum-wallet

It doesn't look like much. There is a Button and if you click it, it shows you the balance of a hardcoded address.
The application also loads an account from a hardcoded json address file and prints that address on clicking the button.

This example is just a simple Proof of Concept, so the code is not pretty nor is it supposed to be re-used anywhere else.

Run with `npm start`. Run  on android with `npm run android`. After running, it takes some time to connect to nodes and sync with the main ethereum network - before it is connected to any peers, the button does not work.

This project was bootstrapped with [Create React Native App](https://github.com/react-community/create-react-native-app).
"
stevehanson/spring-mvc-validation,master,43,21,2013-05-28T03:46:36Z,132,0,Spring MVC validation example using JSR-303 annotations and custom validation annotations,,"Spring MVC Validation
=====================

Spring MVC validation example using JSR-303 annotations and custom validation annotations

This repo is a companion to my [Spring MVC Form Validation Tutorial](http://codetutr.com/2013/05/28/spring-mvc-form-validation/)
"
indrabasak/jpa-postgres-jsonb,master,27,14,2017-03-28T06:34:32Z,977,2,Postgres JPA Example with Enum and JSONB column type.,jpa postgres-enum postgres-jpa postgres-jsonb spring-boot,"[![Build Status][travis-badge]][travis-badge-url]

![](./img/postgres.png)

JPA PostgreSQL Spring Service Example with JSONB Column Type and Query By Example
=================================================================================
This is a [**Spring Boot**](https://projects.spring.io/spring-boot/) based microservice example backed by
[**PostgreSQL**](https://www.postgresql.org/) database. This examples shows how to do the following:
* Use `DBCP datasource` with Java configuration.
* Use `Custom Repository` to expose `entity manager`.
* Insert `UUID` field in Postgres database and generate `UUID `index.
* Convert Java `Enum` to Postgres `Enum` type.
* Convert Java `Object` to Postgres `JSONB` type.
* Use [`JPA Query by Example`](https://github.com/spring-projects/spring-data-commons/blob/master/src/main/asciidoc/query-by-example.adoc)
* Use [`Dozer`](http://dozer.sourceforge.net/) Java Bean mapper.

### PostgreSQL Assumptions
* You have a PostgreSQL database server running on your `localhost` and in port `5432`.
* You have a database named `postgres` running on the server
* The server has a user named `postgres` with password `postgres`.
* If any of the assumptions doesn't hold true, change the `spring.datasource` properties in the `application.yml` file.

### Create Database Entities
Execute the `create-db.sql` script under `resources` directory on your PostgreSQL server either using  PostgreSQL administration and management tools, [pgAdmin](https://www.pgadmin.org/), 
or from the PostgreSQL interactive terminal program, called `psql`.

### Build
Execute the following command from the parent directory:
```
mvn clean install
```

### Start the Service
The main entry point `jpa-postgres-jsonb` example is `com.basaki.example.postgres.jsonb.boot.BookApplication` class.
You can start the application from an IDE by starting the `BookApplication` class.
```

  .   ____          _            __ _ _
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.4.5.RELEASE)
 ...
2017-03-27 23:09:46.905  INFO 44570 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-03-27 23:09:46.911  INFO 44570 --- [           main] c.b.e.postgres.boot.BookApplication      : Started BookApplication in 7.003 seconds (JVM running for 7.422)
```
The application starts up at port `8080`.

### Accessing Swagger 
On your browser, navigate to `http://localhost:8080/` to view the Swagger. 
![](./img/book-swagger.png)

Click the `Show/Hide` link to view all the operations exposed by Book API.

#### POST Example
Once expanded, create a new Book entry by clicking `POST` and entering the following JSON snippet in the `request` field and click `Try it out!`. 
![](./img/book-post-req.png)

Here is the response you get back. 
![](./img/book-post-rsp.png)

#### GET Example
To view all books, click `GET` and enter either `title`, `author`, `genre` or any combination of them and click lick `Try it out!`. 
The `title` and `author` parameters are case insensitive. This is an example by query.
Here is the response you get back:
![](./img/book-get-rsp.png)

#### GET Example by Author
To view all books by author, click `GET` and enter either author's `first name`, `last name` or any combination of them and click lick `Try it out!`. 
The `first name`, `last name` parameters are case insensitive and doesn't have to be complete names. This is an native query on JSON object.
Here is the response you get back:
![](./img/auth-get-req.png)

Here is the response you get back.
![](./img/auth-get-rsp.png)


[travis-badge]: https://travis-ci.org/indrabasak/jpa-postgres-jsonb.svg?branch=master
[travis-badge-url]: https://travis-ci.org/indrabasak/jpa-postgres-jsonb/"
rharter/CompoundViews,master,33,7,2014-05-14T14:22:27Z,244,0,Example app to demonstrate compound views.,,"CompoundViews
=============

Example app to demonstrate compound views.
"
kikovalle/PLGSharepointRestAPI-java,master,37,30,2020-07-12T10:11:55Z,181,13,Easy to use wrapper for the Sharepoint Rest API v1. Even if this is not a full implementation it covers most common use cases and provides examples to extending this API.,,"# PLGSharepointRestAPI-java
Easy to use wrapper for the Sharepoint Rest API v1. Even if this is not a full implementation it covers most common use cases and provides examples to extending this API.

I decided to share this project here because one of the most encouraging issues I've ever found is when i tried to integrate with sharepoint online without chance of using the .Net framework. I found several java APIs that took me into headaches trying to use them. This API is a really easy to use one that covers most frequent operations I needed while integrating with Sharepoint. After a lot of research I finally got this working and I shared it.

If you find this usefull and saves you some time renember you can support me so I can achieve more time to complete this project and prepare other usefull projects that I hope will save time and efforst to someone out there.

<a href=""https://www.buymeacoffee.com/kikovalle"" target=""_blank""><img src=""https://cdn.buymeacoffee.com/buttons/default-blue.png"" alt=""Buy Me A Coffee"" style=""height: 51px !important;width: 217px !important;"" ></a>

This is a maven project that uses spring RestTemplate to communicate with the server, but can be use in a non-spring application as you'll see in the examples I provide.

The API has been finally released to Maven Central repository (https://s01.oss.sonatype.org/#view-repositories;releases~browsestorage~io/github/kikovalle/com/panxoloto/sharepoint/rest/PLGSharepointRestAPI), so from now it is possible to include the dependency in a easier way. Simply add this to your pom.xml replacing the 1.0.3 version with the latest version of the API.

		<dependency>
			<groupId>io.github.kikovalle.com.panxoloto.sharepoint.rest</groupId>
			<artifactId>PLGSharepointRestAPI</artifactId>
			<version>1.0.3</version>
		</dependency>

As this is a maven project you have to clone this repo and compile it with maven. You can modify the pom.xml to include any distribution management repository that you use in your company so you can make use of the library in any other java project
  
    mvn clean install

Once the project is build, you can include the dependency in any other project as follow:
		
		<dependency>
			<groupId>io.github.kikovalle.com.panxoloto.sharepoint.rest</groupId>
			<artifactId>PLGSharepointRestAPI</artifactId>
			<version>1.0.3</version>
		</dependency>
  
Once this is done you can test this simple examples to perform actions in your sharepoint sites.

First step is to instantiate the API client, for this you need a sharepoint user email, a password, a domain and a sharepoint site URI:

    String user = ""userwithrights@contososharepoint.com"";
    String passwd = ""userpasswordforthesharepointsite"";
    String domain = ""contoso.sharepoint.com"";
    String spSiteUrl = ""/sites/yoursiteorsubsitepath"";

<b>Get all lists of a site</b>


    // Initialize the API
    PLGSharepointClient wrapper = new PLGSharepointClient(user, passwd, domain, spSiteUrl);
    try {
        JSONObject result = wrapper.getAllLists(""{}"");
        System.out.println(result);
    } catch (Exception e) {
        e.printStackTrace();
    }

<b>Get a list by list title</b>

    PLGSharepointClient wrapper = new PLGSharepointClient(user, passwd, domain, spSiteUrl);
    try {
        JSONObject result = wrapper.getListByTitle(""MySharepointList"", ""{}"");
        System.out.println(result);
    } catch (Exception e) {
        e.printStackTrace();
    }

<b>Get items of a list</b>

    PLGSharepointClient wrapper = new PLGSharepointClient(user, passwd, domain, spSiteUrl);
    try {
        // Propertyfieldname is a column name in sharepoint site, and value is the searched value, see SP Rest API to know how to filter a list.
        String queryStr = ""$filter=PropertyFieldName eq 'PropertyFieldValue'"";
        JSONObject result = wrapper.getListItems(""MySharepointList"", ""{}"", queryStr);
        System.out.println(result);
    } catch (Exception e) {
        e.printStackTrace();
    }
    
<b>Get a folder by server relative URL</b>

    PLGSharepointClient wrapper = new PLGSharepointClient(user, passwd, domain, spSiteUrl);
    try {
        JSONObject result = wrapper.getFolderByRelativeUrl(""/sites/mysite/FolderName"", ""{}"");
        System.out.println(result);
    } catch (Exception e) {
        e.printStackTrace();
    }

<b>Create a folder</b>

    PLGSharepointClient wrapper = new PLGSharepointClient(user, passwd, domain, spSiteUrl);
    try {
        // payload is a json object where to place metadata properties to associate with file in this example i set Title
        JSONObject payload = new JSONObject();
        payload.put(""Title"",""Document Title set with the API"");
        JSONObject result = wrapper.createFolder(""/sites/mysite/parentfolderwheretocreatenew"", ""newfoldername"", payload);
        System.out.println(result);
    } catch (Exception e) {
        e.printStackTrace();
    }

Other actions you can perform with this API are the following

<ol>
  <li>Remove a folder</li>
  <li>Upload a file</li>
  <li>Remove a file</li>
  <li>Move a folder</li>
  <li>Move a file</li>
  <li>Update file metadata</li>
  <li>Break folder role inheritance</li>
  <li>Update folder properties</li>
  <li>Grant user permissions on a folder (yet to implement file permissions control)</li>
  <li>Remove user permissions on a folder (yet to implement file permissions control)</li>
</ol>

If you find this project useful you can buy me a coffee to support this initiative

<a href=""https://www.buymeacoffee.com/kikovalle"" target=""_blank""><img src=""https://cdn.buymeacoffee.com/buttons/default-blue.png"" alt=""Buy Me A Coffee"" style=""height: 51px !important;width: 217px !important;"" ></a>

"
kaiwaehner/ksql-fork-with-deep-learning-function,master,77,35,2018-03-26T12:28:15Z,1921,0,"Deep Learning UDF for KSQL, the Streaming SQL Engine for Apache Kafka with Elasticsearch Sink Example",deep-learning h2o kafka kafka-ecosystem ksql ksql-server ksql-udf stream udf,"# ![KSQL rocket](pictures/ksq-lrocket.png) Deep Learning UDF for KSQL, the Streaming SQL for Apache Kafka

<span style=""color:red"">*Important: This is a fork of the KSQL project to demonstrate how to built a User-Defined Function (UDF). The projects adds a H2O Deep Learning model.*</span>

For the most up-to-date version, documentation and examples of KSQL, please go to [Confluent's official KSQL Github repository](https://github.com/confluentinc/ksql).

<span style=""color:red"">*Update July 2018: KSQL now has official support for UDFs. This makes it much easier to implement UDFs. I built an updated example here: [KSQL UDF with Deep Learning using MQTT Proxy for Sensor Analytics](https://github.com/kaiwaehner/ksql-udf-deep-learning-mqtt-iot)... Also check out the Confluent Documentation for more information about the new UDF / UDAF features in [KSQL Custom Function Reference UDF / UDAF](https://docs.confluent.io/current/ksql/docs/udf.html)*</span>

## Use Case: Continuous Health Checks with Anomaly Detection
The following example leverages a pre-trained analytic model within a KSQL UDF for continuous stream processing in real time to do health checks and alerting in case of risk. The Kafka ecosystem is used for model serving, monitoring and alerting.

![](pictures/KSQL_UDF_Deep_Learning_IoT.png)

### Deep Learning with an H2O Autoencoder for Sensor Analytics
Each row (i.e. message input from the sensor to Kafka) represents a single heartbeat and contains over 200 columns with numbers.

The [User-Defined KSQL Function ‘AnomalyKudf’ applies an H2O Neural Network](https://github.com/kaiwaehner/ksql/blob/4.0.x/ksql-engine/src/main/java/io/confluent/ksql/function/udf/ml/AnomalyKudf.java). The class creates a new object instance of the Deep Learning model and applies it to the incoming sensor messages for detection of anomalies in real time.


## Slides

See https://speakerdeck.com/rmoff/processing-iot-data-with-apache-kafka-ksql-and-machine-learning

## Demo script

See [demo.adoc](demo.adoc)

## Quick Start for KSQL Machine Learning UDF
How to test this implementation? The analytic model and its dependency is already included in this project. You just have to start a Kafka broker (including Zookeeper) and the KSQL server to send input streams for model inference. Here are the steps...

### Build

UDFs currently need to rebuild the KSQL project to include the new function.

However, the Maven build for KSQL is already done in this project.  If you want to change the UDF logic or add own models, then you need to rebuild the project.

    mvn -DskipTests=true -Dcheckstyle.skip=true clean package

### Set up the infrastructure

Confluent CLI needs to be set up to start a new cluster the easiest way - https://github.com/confluentinc/confluent-cli
Alternatively, you can use an existing Kafka cluster with default broker URL (or reconfigure the ksql-server.properties file to point to your existing Kafka cluster URL).

Start Kafka (also starts Zookeeper as dependency):

    confluent start kafka
    
Start Kafka Connect (not needed for KSQL, but used for integrating with Elastic for the demo):
    
    confluent start connect

Start the KSQL Server:

    bin/ksql-server-start config/ksql-server.properties

Start the KSQL CLI (or alternatively use the KSQL UI):

    bin/ksql http://localhost:8088

The following creates topics and test data manually so that you can follow each step. See below for steps on generating random test data continually

This example uses [kafacat](https://github.com/edenhill/kafkacat/), an open-source command line tool for easily interacting with Kafka.

Create a Kafka Topic for this demo:

    kafka-topics \
    --zookeeper localhost:2181 \
    --create \
    --topic HealthSensorInputTopic \
    --partitions 1 \
    --replication-factor 1

In KSQL, create STREAM and SELECT Queries:

    CREATE STREAM healthsensor (eventid integer, sensorinput varchar) WITH (kafka_topic='HealthSensorInputTopic', value_format='DELIMITED');
    CREATE STREAM SENSOR_RAW WITH (VALUE_FORMAT='AVRO') AS SELECT * FROM HEALTHSENSOR;
    SHOW STREAMS;
    DESCRIBE healthsensor;
    SELECT eventid, anomaly(SENSORINPUT) from healthsensor;

Send a sample message (returns a prediction of 1.2104138026620321):

    echo -e ""99999,2.10# 2.13# 2.19# 2.28# 2.44# 2.62# 2.80# 3.04# 3.36# 3.69# 3.97# 4.24# 4.53#4.80# 5.02# 5.21# 5.40# 5.57# 5.71# 5.79# 5.86# 5.92# 5.98# 6.02# 6.06# 6.08# 6.14# 6.18# 6.22# 6.27#6.32# 6.35# 6.38# 6.45# 6.49# 6.53# 6.57# 6.64# 6.70# 6.73# 6.78# 6.83# 6.88# 6.92# 6.94# 6.98# 7.01#7.03# 7.05# 7.06# 7.07# 7.08# 7.06# 7.04# 7.03# 6.99# 6.94# 6.88# 6.83# 6.77# 6.69# 6.60# 6.53# 6.45#6.36# 6.27# 6.19# 6.11# 6.03# 5.94# 5.88# 5.81# 5.75# 5.68# 5.62# 5.61# 5.54# 5.49# 5.45# 5.42# 5.38#5.34# 5.31# 5.30# 5.29# 5.26# 5.23# 5.23# 5.22# 5.20# 5.19# 5.18# 5.19# 5.17# 5.15# 5.14# 5.17# 5.16#5.15# 5.15# 5.15# 5.14# 5.14# 5.14# 5.15# 5.14# 5.14# 5.13# 5.15# 5.15# 5.15# 5.14# 5.16# 5.15# 5.15#5.14# 5.14# 5.15# 5.15# 5.14# 5.13# 5.14# 5.14# 5.11# 5.12# 5.12# 5.12# 5.09# 5.09# 5.09# 5.10# 5.08# 5.08# 5.08# 5.08# 5.06# 5.05# 5.06# 5.07# 5.05# 5.03# 5.03# 5.04# 5.03# 5.01# 5.01# 5.02# 5.01# 5.01#5.00# 5.00# 5.02# 5.01# 4.98# 5.00# 5.00# 5.00# 4.99# 5.00# 5.01# 5.02# 5.01# 5.03# 5.03# 5.02# 5.02#5.04# 5.04# 5.04# 5.02# 5.02# 5.01# 4.99# 4.98# 4.96# 4.96# 4.96# 4.94# 4.93# 4.93# 4.93# 4.93# 4.93# 5.02# 5.27# 5.80# 5.94# 5.58# 5.39# 5.32# 5.25# 5.21# 5.13# 4.97# 4.71# 4.39# 4.05# 3.69# 3.32# 3.05#2.99# 2.74# 2.61# 2.47# 2.35# 2.26# 2.20# 2.15# 2.10# 2.08"" | kafkacat -b localhost:9092 -P -t HealthSensorInputTopic

Create derived stream in KSQL:

    CREATE STREAM AnomalyDetection WITH (VALUE_FORMAT='AVRO') AS \
    SELECT eventid, sensorinput, \
    CAST (anomaly(sensorinput) AS DOUBLE) as Anomaly \
    FROM healthsensor;

Now create a filter so that you only get specific messages (could be alerts):

    CREATE STREAM AnomalyDetectionBreach AS \
    SELECT * FROM AnomalyDetection \
    WHERE Anomaly >1.3;

    SELECT * FROM AnomalyDetection;

    SELECT * FROM AnomalyDetectionWithFilter;

Send another test message. This one returns a prediction of 1.4191201699929437:

    echo -e  ""33333, 6.90#6.89#6.86#6.82#6.78#6.73#6.64#6.57#6.50#6.41#6.31#6.22#6.13#6.04#5.93#5.85#5.77#5.72#5.65#5.57#5.53#5.48#5.42#5.38#5.35#5.34#5.30#5.27#5.25#5.26#5.24#5.21#5.22#5.22#5.22#5.20#5.19#5.20#5.20#5.18#5.19#5.19#5.18#5.15#5.13#5.10#5.07#5.03#4.99#5.00#5.01#5.06#5.14#5.31#5.52#5.72#5.88#6.09#6.36#6.63#6.86#7.10#7.34#7.53#7.63#7.64#7.60#7.38#6.87#6.06#5.34#5.03#4.95#4.84#4.69#4.65#4.54#4.49#4.46#4.43#4.38#4.33#4.31#4.28#4.26#4.21#4.19#4.18#4.15#4.12#4.09#4.08#4.07#4.03#4.01#4.00#3.97#3.94#3.90#3.90#3.89#3.85#3.81#3.81#3.79#3.77#3.74#3.72#3.71#3.70#3.67#3.66#3.68#3.67#3.66#3.67#3.69#3.71#3.72#3.75#3.80#3.85#3.89#3.95#4.03#4.06#4.18#4.25#4.36#4.45#4.54#4.60#4.68#4.76#4.83#4.86#4.91#4.95#4.97#4.98#5.00#5.04#5.04#5.05#5.03#5.06#5.07#5.06#5.05#5.06#5.07#5.07#5.06#5.06#5.07#5.07#5.06#5.07#5.07#5.08#5.06#5.06#5.08#5.09#5.09#5.10#5.11#5.11#5.10#5.10#5.11#5.12#5.10#5.06#5.07#5.06#5.05#5.02#5.02#5.02#5.01#4.99#4.98#5.00#5.00#5.00#5.02#5.03#5.03#5.01#5.01#5.03#5.04#5.02#5.01#5.02#5.04#5.02#5.02#5.03#5.04#5.03#5.03#5.02#5.04#5.04#5.03#5.03#5.05#5.04"" | kafkacat -b localhost:9092 -P -t HealthSensorInputTopic

Inspect the resulting Kafka topics. One with all scored events:

    $ kafkacat -b localhost:9092 -C -t ANOMALYDETECTION
    99999,1.2104138026620321
    % Reached end of topic ANOMALYDETECTION [1] at offset 0
    % Reached end of topic ANOMALYDETECTION [2] at offset 0
    33333,1.4191201699929437
    % Reached end of topic ANOMALYDETECTION [3] at offset 1
    % Reached end of topic ANOMALYDETECTION [0] at offset 1

One with just those that breach an alert:

    $ kafkacat -b localhost:9092 -C -t ANOMALYDETECTIONWITHFILTER
    % Reached end of topic ANOMALYDETECTIONWITHFILTER [0] at offset 0
    % Reached end of topic ANOMALYDETECTIONWITHFILTER [1] at offset 0
    33333,1.4191201699929437
    % Reached end of topic ANOMALYDETECTIONWITHFILTER [3] at offset 0
    % Reached end of topic ANOMALYDETECTIONWITHFILTER [2] at offset 1

### Replaying sample test data

Taking an input file of readings only, this will add a sequence number:

    awk '{gsub(/\,/,""#"");print NR"",""$0}' ecg_discord_test.csv > ecg_discord_test.msgs

Play data into Kafka:

    kafkacat -b localhost:9092 -P -t HealthSensorInputTopic -l ecg_discord_test.msgs

Generates all readings with same/close timestamp though. To spread out over time, use `pv` to throttle to a given bytes/sec throughput:

    cat ecg_discord_test.msgs | pv -q -L 1000| kafkacat -b localhost:9092 -P -t HealthSensorInputTopic

Run continually:

    cd test-data
    ./stream_loop_of_test_data_into_kafka.sh

### Generating random test data

    ./bin/ksql-datagen schema=EcdSensorData.avro format=delimited topic=HealthSensorInputTopic key=eventid maxInterval=2000

This uses the ksql-datagen tool (part of KSQL project) to generate test data. Whilst it provides random data, it's not very realistic to real-world data since it is truly random, rather than following a particular realistic pattern.

### Change anomaly threshold

    TERMINATE CSAS_ANOMALYDETECTIONBREACH;
    DROP STREAM ANOMALYDETECTIONBREACH;
    CREATE STREAM AnomalyDetectionBreach AS \
    SELECT * FROM AnomalyDetection \
      WHERE Anomaly >4;


## Stream to Elasticsearch

Create a Kafka Connect sink to stream all scored events to Elasticsearch:

    curl -X ""POST"" ""http://localhost:8083/connectors/"" \
       -H ""Content-Type: application/json"" \
       -d '{
        ""name"": ""es_sink_raw_events"",
        ""config"": {
          ""topics"": ""SENSOR_RAW"",
          ""key.converter"": ""org.apache.kafka.connect.storage.StringConverter"",
          ""connector.class"": ""io.confluent.connect.elasticsearch.ElasticsearchSinkConnector"",
          ""key.ignore"": ""true"",
          ""schema.ignore"": ""true"",
          ""type.name"": ""type.name=kafkaconnect"",
          ""topic.index.map"": ""SENSOR_RAW:healthsensorinput_raw"",
          ""connection.url"": ""http://localhost:9200"",
          ""transforms"": ""ExtractTimestamp"",
          ""transforms.ExtractTimestamp.type"": ""org.apache.kafka.connect.transforms.InsertField$Value"",
          ""transforms.ExtractTimestamp.timestamp.field"" : ""EXTRACT_TS""
        }
      }'

    curl -X ""POST"" ""http://localhost:8083/connectors/"" \
             -H ""Content-Type: application/json"" \
             -d '{
          ""name"": ""es_sink_anomaly"",
          ""config"": {
            ""topics"": ""ANOMALYDETECTION"",
            ""key.converter"": ""org.apache.kafka.connect.storage.StringConverter"",
            ""connector.class"": ""io.confluent.connect.elasticsearch.ElasticsearchSinkConnector"",
            ""key.ignore"": ""true"",
            ""schema.ignore"": ""true"",
            ""type.name"": ""type.name=kafkaconnect"",
            ""topic.index.map"": ""ANOMALYDETECTION:healthsensorinput_scored"",
            ""connection.url"": ""http://localhost:9200"",
            ""transforms"": ""ExtractTimestamp"",
            ""transforms.ExtractTimestamp.type"": ""org.apache.kafka.connect.transforms.InsertField$Value"",
            ""transforms.ExtractTimestamp.timestamp.field"" : ""EXTRACT_TS""
          }
        }'

Create a Kafka Connect sink to stream all events that breach an alert threadshold to Elasticsearch:

    curl -X ""POST"" ""http://localhost:8083/connectors/"" \
             -H ""Content-Type: application/json"" \
             -d '{
          ""name"": ""es_sink_anomaly_alerts"",
          ""config"": {
            ""topics"": ""ANOMALYDETECTIONBREACH"",
            ""key.converter"": ""org.apache.kafka.connect.storage.StringConverter"",
            ""connector.class"": ""io.confluent.connect.elasticsearch.ElasticsearchSinkConnector"",
            ""key.ignore"": ""true"",
            ""schema.ignore"": ""true"",
            ""type.name"": ""type.name=kafkaconnect"",
            ""topic.index.map"": ""ANOMALYDETECTIONBREACH:healthsensorinput_alerts"",
            ""connection.url"": ""http://localhost:9200"",
            ""transforms"": ""ExtractTimestamp"",
            ""transforms.ExtractTimestamp.type"": ""org.apache.kafka.connect.transforms.InsertField$Value"",
            ""transforms.ExtractTimestamp.timestamp.field"" : ""EXTRACT_TS""
          }
        }'

## Viualisation

![](pictures/kibana_01.jpg)

## Monitoring

Optionally, start the Confluent Control Center :

    confluent start control-center

Once started, go to http://localhost:9021/monitoring/streams/ to monitor the pipelines you have built

![](pictures/cc01.jpg)

# Join the Confluent Community
Whether you need help, want to contribute, or are just looking for the latest news around the Apache Kafka ecosystem and Confluent, you can find out how to [connect with your fellow Confluent community members here](https://www.confluent.io/contact-us-thank-you/).

* Ask a question in the #ksql channel in Confluent's public [Confluent Community Slack](https://slackpass.io/confluentcommunity). Account registration is free and self-service.
* Join the [Confluent Google group](https://groups.google.com/forum/#!forum/confluent-platform).

If you have feedback regarding the Kafka ecosystem and Machine Learning, feel free to contact me directly via LinkedIn, Twitter or Email. Also check out my other [Kafka-ML Github project](https://github.com/kaiwaehner/kafka-streams-machine-learning-examples) where I leverage Kafka's Streams API to apply analytic models trained with H2O, TensorFlow and DeepLearning4j.

## Next Steps (hopefully) coming soon:
- Real demo sensor data (i.e. a continous stream)
- Integration with Kafka Connect
- More business logic and different analytic models in the UDF

# Contributing
Contributions to the code, examples, documentation, etc, are very much appreciated.

- Report issues and bugs directly in [this GitHub project](https://github.com/kaiwaehner/ksql/issues).

# License
The project is licensed under the Apache License, version 2.0.

*Apache, Apache Kafka, Kafka, and associated open source project names are trademarks of the [Apache Software Foundation](https://www.apache.org/).*
"
BankID/SampleCode,main,48,14,2023-05-05T14:15:30Z,2042,2,Official BankID example code to generate the BankID demo site,,"# BankID sample code

BankID is the largest eID in Sweden, with more than 8,4 million users and over 6000 connected businesses and authorities. Our solution has revolutionized everyday life in Sweden and lays the foundation for a modern and accessible society.


## Demo site

To help you integrate BankID in a correct, secure and user-friendly way, we have created a demo site, where you can test the digital identification flow and the digital signature flow.

<img src=""https://www.bankid.com/assets/bankid/img/github_demo.png"" />

[Visit the demo site](https://www.bankid.com/demo)

## Sample code
Here we provide the code used to create the demo site. The code languages used are:
* Frontend: React
* Backend: Java


## Help for a full integration

To integrate the BankID infrastructure, it is necessary to set up frontend and backend as well as to have a SSL-certificate. For help with your full integration, check out our [developer section](https://www.bankid.com/en/utvecklare/guider) on our website. 

## Disclaimer and terms of use

We, Finansiell ID-teknik BID AB are not responsible for the correctness, nor the usage, of the code provided. You must always test your integration thoroughly and you are responsible for ensuring it works in your environment. 

You may not use the name of our company or brand without written consent.

---

## More info

[Readme for the backend](/server/README.md)

[Readme for the frontend](/client/README.md)
"
thheller/reagent-react-native,master,49,13,2019-03-04T12:15:50Z,1085,1,Example App using reagent with react-native via shadow-cljs,,"```
$ npm install && cd react-native && yarn install
$ shadow-cljs watch app

;; wait for first compile to finish or metro gets confused
$ cd react-native

$ npm start
;; and
$ npm run android

;; production build
$ shadow-cljs release app

;; Create Android release
$ cd react-native/android
$ ./gradlew assembleRelease
;; APK should appear at android/app/build/outputs/apk/release
;; installs in Android as ""AwesomeProject""
$ adb install -r react-native/android/app/build/outputs/apk/release/app-release.apk
```

## Notes

The `react-native` folder was generated by calling `react-native init AwesomeProject` and renaming the folder.

The `:app` build will create an `react-native/app/index.js`. In `release` mode that is the only file needed. In dev mode the `app` directory will contain many more `.js` files.

`:init-fn` is called after all files are loaded and in the case of `expo` must render something synchronously as it will otherwise complain about a missing root component.
"
schordas/SchematicPlanets,master,29,13,2015-09-17T17:20:13Z,542,0,An example implementation of the Schematic content provider library.,,"# SchematicPlanets
An example implementation of the Schematic content provider library.

This app also demonstrates an approach to using RecyclerView (with a CursorLoader) and Floating Action Buttons. 

Enjoy!
"
cdk8s-team/cdk8s-examples,main,31,2,2023-02-15T14:55:50Z,4584,11,,,# cdk8s-examples
petros94/smart-home-websockets,master,30,12,2020-03-23T15:02:11Z,296,0,"Websocket client-server example app, with ActiveMQ message broker",,"# Smart Home demo application using Spring Boot, Websockets and ActiveMQ
Websocket client-server example app, with ActiveMQ message broker. 
This is the code repo for the DZone articles: 
* Part I: https://dzone.com/articles/full-duplex-scalable-client-server-communication-u
* Part II: https://dzone.com/articles/full-duplex-scalable-client-server-communication-2
 	
## Description 
In our scenario, all the smart devices have a persistent connection to a server. The server is responsible for sending commands to specific devices, such as turning on the living room lights, or enabling the alarm. It can also receive information from devices. For example there can be a temperature sensor that takes readings every minute, or an oven that sends alerts if the temperature is too high. Finally the server may also issue commands to all devices, such as turn on/off.

![Image of Microservices](/screenshots/websockets-2.png)

Each microservice (MS) is written in Java 11, using the Spring Boot framework. The communication with the clients is handled by the Device Management MS. The Control MS exposes the REST API, and communicates with the Device Mgmt MS using an Active MQ Artemis message broker. For incoming traffic routing, service discovery and load balancing we are using Spring Cloud Gateway and Eureka.

## Prerequisites

* Java 11 or above
* Docker

## How to install

From root directory type:

> mvn package -DskipTests

To build the docker images run:

> docker-compose build

## How to run

To dun with docker, after creating the images, navigate to root directory and type:

> docker-compose up

This will bring up the server-side part (including ActiveMQ) and one client 

## How to test

* Monitor the services discovered by Eureka by visiting: http://localhost:8761
* The ActiveMQ artemis comes with a management page running at: http://localhost:8161
* You can send POST requests to http://localhost:8000/control-service/device 

```
curl --location --request POST 'http://localhost:8000/control-service/device' \
--header 'Content-Type: application/json' \
--data-raw '{
	""destination"": ""lights_living_room"",
	""command"": ""turn_on"",
	""args"": {
	}
}'
```

Then you can monitor the device-client / device-management service logs to see the transmitted messages

## Locust scripts
To be added soon

## Contact details
Feel free to contact us for any questions or suggestions at: kmandalas@gmail.com or submit a github issue.
"
witgo/CRF,master,28,21,2013-02-26T15:11:32Z,2767,5,"CRF is a Java implementation of Conditional Random Fields, an algorithm for learning from labeled sequences of examples. It also includes an implementation of Maximum Entropy learning.",,
chrisjenx/StaggeredGridView,master,103,61,2012-11-18T13:11:23Z,502,0,"Based of the google staggeredgridview that has been hidden from the ACL, this is an example based off of that.",,"StaggeredGridView
=================

## This is just a demo

If you want a better implimentation of this, either wait for google to release it.

Or try https://github.com/maurycyw/StaggeredGridView


### About
Based of the google staggeredgridview that has been hidden from the ACL, this is an example based off of that and supporting scroll listener.
"
lidimayra/from-rails-to-spring-boot,master,52,5,2019-07-28T18:10:02Z,33146,0,A quick guide for developers migrating from Rails to Spring Boot with examples,java mvc rails ruby ruby-on-rails spring spring-boot web,"# From Rails to Spring Boot

Like Rails, Spring Boot also follows _Convention over Configuration_ principles.
This repository's goal is to focus on similarities and differences between both
frameworks in order to provide a quick guide for developers that are migrating
from one to another.

Contributions are welcome!

[Pre-requisite](#pre-requisite)\
[Maven instalation](#maven-instalation)\
[Spring Boot instalation](#spring-boot-cli-instalation)\
[App Initialization](#app-initialization)\
[Controllers & Views](#controllers-and-views)\
[Project Structure](#project-structure)\
[RESTful routes](#restful-routes)\
[From Rails Models to Spring Entities](#from-rails-models-to-spring-entities)\
[Performing a creation through a web interface](#performing-a-creation-through-a-web-interface)\
[Displaying a collection of data](#displaying-a-collection-of-data)\
[Editing and Updating data](#editing-and-updating-data)\
[Showing a Resource](#showing-a-resource)\
[Destroying a Resource](#destroying-a-resource)

## Pre-requisite
[Java Development Kit 8](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)

## Maven instalation

### On Ubuntu
```
sudo apt update
sudo apt install maven
```

### On Mac OS (with Homebrew)
```
brew update
brew install maven
```

## Spring Boot CLI instalation

### On Ubuntu (with SDKMAN)
```
curl ""https://get.sdkman.io"" | bash
source ~/.sdkman/bin/sdkman-init.sh
sdk install springboot
```

### On Mac (with Homebrew)
```
brew tap pivotal/tap
brew install springboot
```

## App Initialization

Once Spring Boot CLI is installed, we can use `spring init` command to a start a
new Spring Boot project (just like we would do with `rails new`):

```
# rails new <app_name>
spring init <app_name> -d=web,data-jpa,h2,thymeleaf
```
`-d` allows us to specify dependencies we want to set up. In this example we're
using the ones that are aimed at a basic web project:
- [web](https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web):
Build web, including RESTful, applications using Spring MVC. Uses Apache Tomcat as the default embedded container.
- [data-jpa](https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-data-jpa):
Persist data in SQL stores with Java Persistence API using Spring Data and Hibernate.
- [h2](https://mvnrepository.com/artifact/com.h2database/h2): Provides a fast
in-memory database that supports JDBC API, with a small
(2mb) footprint. Supports embedded and server modes as well as a browser based
console application.
- [thymeleaf](https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-thymeleaf): Server-side Java template engine

[Example of Spring Boot
initialization](https://github.com/lidimayra/from-rails-to-spring-boot/commit/310ae4766254c3b18c6fe144cf7eacee49dcc515).

Note that a class was created named as `DemoApplication.java` in
`src/main/java/com/example/<app_name>/` ([Example](https://github.com/lidimayra/from-rails-to-spring-boot/blob/310ae4766254c3b18c6fe144cf7eacee49dcc515/myapp/src/main/java/com/example/myapp/DemoApplication.java))

By default, Spring uses [Maven](https://maven.apache.org/) as the project
management tool. After running the command above, dependencies can be found in
`pom.xml` file, at the root directory.

Install dependencies specified in `pom.xml` by using Maven:

```
# bundle install
mvn clean install
```

Start the server using `spring-boot:run`, a task that's provided by Maven
plugin:
```
# rails s
mvn spring-boot:run
```

Now application can be accessed at http://localhost:8080/. At this point, an
error page will be rendered, as there are no controllers defined so far.

## Controllers and views

In Spring Boot, there is no such thing as the rails generators. Also, there
is no file like _routes.rb_, where all routes are specified in a single place.

Write the controller inside `<app_name>/src/main/java/<package_name>`:

```java
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.GetMapping;

@Controller
public class FooController {
    @GetMapping(""/foo"")
    public String index() {
        return ""bar"";
    }
}
```

The `@GetMapping` annotation ensures that GET requests performed to `/foo` will be
mapped to the method declared right after it (there is no file similar to
Rails' routes.rb in Spring Boot. Routes are defined alongside with its methods).

Because of Thymeleaf, by returning the String ""bar"", the application will look
for an HTML file of the same name in `src/main/resources/templates/`

Create the following page:
_bar.html_
```html
<p>FooBar</p>
```
[Example](https://github.com/lidimayra/from-rails-to-spring-boot/commit/13d195c)

Now, if we run the application with `mvn spring-boot:run` command and access
it at `http://localhost:8080/foo`, we'll see the _bar.html_ page being rendered.

## Project Structure

At this point, we have the initial structure of a Maven project.

- Main application code is placed in
  [src/main/java/](https://github.com/lidimayra/from-rails-to-spring-boot/tree/13d195c/myapp/src/main/java)
- Resources are placed in [src/main/resources](https://github.com/lidimayra/from-rails-to-spring-boot/tree/13d195c/myapp/src/main/resources)
- Tests code is placed in
  [src/test/java](https://github.com/lidimayra/from-rails-to-spring-boot/tree/310ae47/myapp/src/test/java)

In the root directory, we have the pom file:
[pom.xml](https://github.com/lidimayra/from-rails-to-spring-boot/blob/47070ef50056a763fdfeba46a8c8da2034de6118/myapp/pom.xml).
This is the Maven build specification. Like in Rails Gemfile, it contains the
project's dependencies declarations.

## RESTful routes

Let's say we want to build a blog containing the seven RESTful actions (index,
new, create, show, edit and destroy) for posts path. In Rails, we could achieve
that by defining `resources: :posts` in `routes.rb` file.

As mentioned previously, Spring Boot does not have a central point where
all routes are specified. Those are defined in the controllers instead.

We've already seen an example using `@GetMapping` annotation to demonstrate the
definition of a route that uses `GET` method. Similarly, Spring supports other
four inbuilt annotations for handling different types of HTTP request methods:
`@PostMapping`, `@PutMapping`, `@DeleteMapping` and `@PatchMapping`.

Example of these concepts being applied for the blog posts can be found in [here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/101611c).

## From Rails Models to Spring Entities

In order to represent a Post in the application-level, we'll need to define it
as an Spring JPA Entity (very similar to the way it would be done with a Model
in Rails).

```java
@Entity // Designate it as a JPA Entity
public class Post {

    @Id // Mark id field as the entity's identity
    @GeneratedValue(strategy = GenerationType.AUTO) // Value will be automatically provided
    private Long id;
    private String title;
    private String content;

    public Long getId() { ... }

    public void setId(Long id) { ... }

    public String getTitle() { ... }

    public void setTitle(String title) { ... }

    public String getContent() { ... }

    public void setContent(String content) { ... }
}
```

Spring Data JPA provides some built-in methods to manipulate common data
persistence operations through the usage of repositories in a way that's very
similar to Rails' ActiveRecord. So, to work with Post data, a PostRepository must
be implemented as well:

```java
public interface PostRepository extends JpaRepository<Post, Long> {
}
```

JpaRepository interface takes to params, in this scenario: `Post` and `Long`.
`Post` because it is the entity that will be used and `Long` because that's the
type of `Post`'s identity (ID).

This interface will be automatically implemented at runtime.

Whole example can be found [in
here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/e755e5a).

## Performing a creation through a web interface

Next step is adding a form to submit posts to the blog.
At this point, we already have the
[templates/blog/new.html](https://github.com/lidimayra/from-rails-to-spring-boot/blob/101611c7a5c5321169e492ed19381df5c1b12c76/myapp/src/main/resources/templates/blog/new.html)
file containing a single line in it.

Using Thymelaf, we can do that with the following approach:

```html
<!DOCTYPE html SYSTEM
""http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-4.dtd"">

<html xmlns=""http://www.w3.org/1999/xhtml"" xmlns:th=""http://www.thymeleaf.org"">
    <body>
        <p>New Post</p>
        <form method=""POST"" action=""/posts"">
            <label for=""title"">Title:</label>
            <input type=""text"" name=""title"" size=""50""></input><br/>
            <label for=""content"">Content:</label><br/>
            <textarea name=""content"" cols=""80"" rows=""5""></textarea>
            <br/>
            <input type=""submit""></input>
        </form>
    </body>
</html>
```

And then, `BlogController` must be adjusted to permit that when a POST request
to `/posts` is performed, the submitted params must be used to create this new
post.

```java
@Controller
public class BlogController {

    @Autowired
    private PostRepository postRepository;

    @GetMapping(""/posts"")
    public String listPosts() { ... }

    @PostMapping(""/posts"")
    public String createPost(Post post) {
        postRepository.save(post); // Use JPA repository built-in method.
        return ""redirect:/posts""; // redirect user to /posts page.
    }
}
```

See whole implementation [in
here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/b7301838feb251851874fc72704e0100d2e8fa0e#diff-926ef30f0a8789410c4e35200aacb000).

## Displaying a collection of data

We'll make changes to `/posts` page so it will list all posts that are
recorded in the database.

`BlogController`'s method that's associated to this route needs to be adjusted
for making this data available to the view:

```java
@GetMapping(""/posts"")
public String listPosts(Model model) {
    List<Post> posts = postRepository.findAll();
    model.addAttribute(""posts"", posts);
    return ""blog/index"";
}
```

In Spring, Models are used to hold application data and make it available to the
view (like instance variables in Rails). In this example, we're adding the list
of posts to a key named `posts`, so we can access it from the template.

Following code must be implemented to
[templates/blog/index.html](https://github.com/lidimayra/from-rails-to-spring-boot/blob/101611c7/myapp/src/main/resources/templates/blog/index.html):
```html
<!DOCTYPE html SYSTEM ""http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-4.dtd"">
<html xmlns=""http://www.w3.org/1999/xhtml"" xmlns:th=""http://www.thymeleaf.org"">

<h1>Blog</h1>

<dl th:each=""post : ${posts}"">
    <dt>
        <span th:text=""${post.title}"">Title</span>
    </dt>

    <dd>
        <span th:text=""${post.content}"">Content</span>
    </dd>
</dl>

<a th:href=""@{/posts/new}"">Submit a new post</a>

```

See implementation [in
here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/b96ce2c).

Now, accessing application at http://localhost:8080/posts, it is possible to
list and to submit posts using the features implemented so far. Similar approach
can be applied to implement the other actions.

## Editing and Updating data

Now we want to enable editing/updating functionalities.
Following changes must be made to `editPost()` method in `BlogController`:

```java
@getMapping(""/posts/{postId}/edit"")
public String editPost(@PathVariable(""postId"") long id, Model model) {
    Post post = postRepository.findById(id)
          .orElseThrow(() -> new IllegalArgumentException(""Invalid Post
Id:"" + id)); // Ensure post exists before rendering edit form

    model.addAttribute(""post"", post); // enable post to be consumed by edit template

    return ""blog/edit""; // render edit template
}
```

Note that the `id` parameter contains a `@PathVariable` annotation. This
annotation indicates that this param must receive a value that's embedded in the
path. In this case, `id` param will have the value that's passed as `postId`
when performing a request to `/posts/{postId}/edit`. Just like we would do by
calling `params[postId]` in Rails.

Then, we must implement the edit form:


```html
<!DOCTYPE html SYSTEM ""http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-4.dtd"">

<html xmlns=""http://www.w3.org/1999/xhtml"" xmlns:th=""http://www.thymeleaf.org"">
    <body>
        <p>Edit Post</p>
        <form th:method=""post""
              th:action=""@{/posts/{id}(id=${post.id})}""
              th:object=""${post}"">

            <input type=""hidden"" name=""_method"" value=""patch"" />
            <label for=""title"">Title:</label>
            <input type=""text"" name=""title"" size=""50"" th:field=""${post.title}""></input>
            <br/>
            <label for=""content"">Content:</label>
            <br/>
            <textarea name=""content"" cols=""80"" rows=""5"" th:field=""${post.content}""></textarea>
            <br/>
            <input type=""submit""></input>
        </form>
    </body>
</html>
```

This is enough to render an edit form. Thanks to Thymeleaf we can use `th:field`
to map Post fields and provide a pre-populated form to the final user. At
this point, edit form can be accessed at
`https://localhost:8080/posts/<post_id>/edit`.

However, as the update behavior wasn's implemented yet, it is still pointless to
submit this form.

In order to implement it, the following changes are required in the
`BlogController`:

```java
@PatchMapping(""/posts/{postId}"")
public String updatePost(@PathVariable(""postId"") long id, Model model, Post post) {
    Post recordedPost = postRepository.findById(id)
            .orElseThrow(() -> new IllegalArgumentException(""Invalid Post Id:"" + id));

    recordedPost.setTitle(post.getTitle());
    recordedPost.setContent(post.getContent());
    postRepository.save(recordedPost);

    model.addAttribute(""posts"", postRepository.findAll());
    return ""blog/index"";
}
```

After these changes, posts are ready to be edited through the UI. An edit link
can also be added to `posts/index` to enable edit form to be easily accessed:

```html
<a th:href=""@{/posts/{id}/edit(id=${post.id})}"">Edit</a>
```

This implementation can be seen [in
here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/2960884).

## Showing a Resource

Given what've done so far, there is nothing new in implementing the feature
responsible for showing a resource.

Changes to be performed to the controller:
```java
@GetMapping(""/posts/{postId}"")
public String showPost() {
public String showPost(@PathVariable(""postId"") long id, Model model) {
    Post post = postRepository.findById(id)
            .orElseThrow(() -> new IllegalArgumentException(""Invalid Post Id:"" + id));

    model.addAttribute(""post"", post);

    return ""blog/show"";
}
```

And a simple template to display title and content for a single post:
```html
<!DOCTYPE html SYSTEM ""http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-4.dtd"">
<html xmlns=""http://www.w3.org/1999/xhtml"" xmlns:th=""http://www.thymeleaf.org"">

    <body>
        <h1 th:text=""${post.title}""></h1>
        <hr>
        <p th:text=""${post.content}""></p>

        <p><a th:href=""@{/posts/{id}/edit(id=${post.id})}"">Edit</a></p>
        <hr>
        <a th:href=""@{/posts/}"">Go back to posts</a>
    </body>
</html>
```

These changes enable post details to be available at `https://localhost:8080/posts/<post_id>`.

We can also add a link at posts index to allow direct access to show:
```html
<a th:href=""@{/posts/{id}/(id=${post.id})}"">Show</a>
```

Implementation can be seen [in
here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/dd98c1d).

## Destroying a Resource

Now, we'll add the feature to remove a post.

In `BlogController`:
```java
@GetMapping(""/posts/{postId}/delete"")
public String deletePost(@PathVariable(""postId"") long id, Model model) {
    Post recordedPost = postRepository.findById(id)
            .orElseThrow(() -> new IllegalArgumentException(""Invalid Post Id:"" + id));

    postRepository.delete(recordedPost);
    model.addAttribute(""posts"", postRepository.findAll());
    return ""blog/index"";
}
```

Note that we're using GET method in here. That's because in this example, our
app is a monolith and DELETE method is not supported by the browsers. In order to
keep things simple and avoid the addition of a form with a hidden field to
handle this method (like we did when updating), this one is being used as a GET.
If this was an API, `@DeleteMapping` would be the ideal option.

And then we can add a link to delete in index page:

```html
<a th:href=""@{/posts/{id}/delete(id=${post.id})}"">Delete</a>
```

Now it is possible to access https://localhost:8080/posts and delete each post
by using the delete link that's displayed below it.

Implementation can be found [in
here](https://github.com/lidimayra/from-rails-to-spring-boot/commit/cb38bf7).
"
cassiomolin/log-aggregation-spring-boot-elastic-stack,master,106,73,2019-06-11T17:31:27Z,10394,6,"Example on how to use Elastic Stack with Docker to collect, process, store, index and visualize logs of Spring Boot microservices.",,"## Log aggregation with Spring Boot, Elastic Stack and Docker

In a microservices architecture, a single business operation might trigger a chain of downstream microservice calls, which can be pretty challenging to debug. Things, however, can be easier when the logs of all microservices are centralized and each log event contains details that allow us to trace the interactions between the applications.

This project demonstrates how to use Elastic Stack along with Docker to collect, process, store, index and visualize logs of Spring Boot microservices.

##### Table of contents
- [What is Elastic Stack?](#what-is-elastic-stack)  
  - [Elasticsearch](#elasticsearch)
  - [Kibana](#kibana)
  - [Beats](#beats)
  - [Logstash](#logstash)
  - [Putting the pieces together](#putting-the-pieces-together)
- [Logs as streams of events](#logs-as-streams-of-events)
- [Logging with Logback and SLF4J](#logging-with-logback-and-slf4j)
  - [Enhancing log events with tracing details](#enhancing-log-events-with-tracing-details)
  - [Logging in JSON format](#logging-in-json-format)
- [Running on Docker](#running-on-docker)
- [Example](#example)
  - [Building the applications and creating Docker images](#building-the-applications-and-creating-docker-images)
  - [Spinning up the containers](#spinning-up-the-containers)
  - [Visualizing logs in Kibana](#visualizing-logs-in-kibana)

## What is Elastic Stack?

Elastic Stack is a group of open source applications from Elastic designed to take data from any source and in any format and then search, analyze, and visualize that data in real time. It was formerly known as [_ELK Stack_][elk-stack], in which the letters in the name stood for the applications in the group: [_Elasticsearch_][elasticsearch], [_Logstash_][logstash] and [_Kibana_][kibana]. A fourth application, [_Beats_][beats], was subsequently added to the stack, rendering the potential acronym to be unpronounceable. So ELK Stack became Elastic Stack.

So let's have a quick look at each component of Elastic Stack.

### Elasticsearch

[Elasticsearch][elasticsearch] is a real-time, distributed storage, JSON-based search, and analytics engine designed for horizontal scalability, maximum reliability, and easy management. It can be used for many purposes, but one context where it excels is indexing streams of semi-structured data, such as logs or decoded network packets.

### Kibana

[Kibana][kibana] is an open source analytics and visualization platform designed to work with Elasticsearch. Kibana can be used to search, view, and interact with data stored in Elasticsearch indices, allowing advanced data analysis and visualizing data in a variety of charts, tables, and maps.

### Beats

[Beats][beats] are open source data shippers that can be installed as agents on servers to send operational data directly to Elasticsearch or via Logstash, where it can be further processed and enhanced. There's a number of Beats for different purposes:

- [Filebeat][filebeat]: Log files
- [Metricbeat][metricbeat]: Metrics
- [Packetbeat][packetbeat]: Network data
- [Heartbeat][heartbeat]: Uptime monitoring
- And [more][beats].

As we intend to ship log files, [Filebeat][filebeat] will be our choice.

### Logstash

[Logstash][logstash] is a powerful tool that integrates with a wide variety of deployments. It offers a large selection of plugins to help you parse, enrich, transform, and buffer data from a variety of sources. If the data requires additional processing that is not available in Beats, then Logstash can be added to the deployment.

### Putting the pieces together

The following illustration shows how the components of Elastic Stack interact with each other:

![Elastic Stack][img.elastic-stack]

In a few words:

- Filebeat collects data from the log files and sends it to Logststash.
- Logstash enhances the data and sends it to Elasticsearch.
- Elasticsearch stores and indexes the data.
- Kibana displays the data stored in Elasticsearch.

## Logs as streams of events

The [Twelve-Factor App methodology][12factor], a set of best practices for building _software as a service_ applications, define logs as _a stream of aggregated, time-ordered events collected from the output streams of all running processes and backing services_ which _provide visibility into the behavior of a running app._ This set of best practices recommends that [logs should be treated as _event streams_][12factor.logs]:

{: .long}
> A twelve-factor app never concerns itself with routing or storage of its output stream. It should not attempt to write to or manage logfiles. Instead, each running process writes its event stream, unbuffered, to `stdout`. During local development, the developer will view this stream in the foreground of their terminal to observe the app’s behavior.
>
> In staging or production deploys, each process’ stream will be captured by the execution environment, collated together with all other streams from the app, and routed to one or more final destinations for viewing and long-term archival. These archival destinations are not visible to or configurable by the app, and instead are completely managed by the execution environment.

With that in mind, the log event stream for an application can be routed to a file, or watched via realtime `tail` in a terminal or, preferably, sent to a log indexing and analysis system such as Elastic Stack.

## Logging with Logback and SLF4J

When creating Spring Boot applications that depends on the `spring-boot-starter-web` artifact, [Logback][logback] will be pulled as a transitive dependency and will be used default logging system. Logback is a mature and flexible logging system and that can be used directly or, preferable, with [SLF4J][slf4j]

SLF4J a logging facade or abstraction for various logging frameworks. For logging with SLF4J, we first have to obtain a [`Logger`][org.slf4j.Logger] instance using [`LoggerFactory`][org.slf4j.LoggerFactory], as shown below:

```java
public class Example {
    final Logger log = LoggerFactory.getLogger(Example.class);
}
```

To be less verbose and avoid repeating ourselves in all classes we want to perform logging, we can use [Lombok][lombok]. It provides the [`@Slf4j`][lombok.slf4j] annotation for generating the logger field for us. The class shown above is is equivalent to the class shown below: 

```java
@Slf4j
public class Example {

}
```

Once we get the logger instance, we can perform logging:

```java
log.trace(""Logging at TRACE level"");
log.debug(""Logging at DEBUG level"");
log.info(""Logging at INFO level"");
log.warn(""Logging at WARN level"");
log.error(""Logging at ERROR level"");
```

Parametrized messages with the `{}` syntax can also be used. This approach is preferable over string concatenation, as it doesn't incur the cost of the parameter construction in case the log level is disabled:

```java
log.debug(""Found {} results"", list.size());
```

In Spring Boot applications, Logback can be [configured][spring-boot.configure-logback] in the `logback-spring.xml` file, located under the `resources` folder. In this configuration file, we can take advantage of Spring profiles and the templating features provided by Spring Boot.

### Enhancing log events with tracing details

In a microservices architecture, a single business operation might trigger a chain of downstream microservice calls and such interactions between the services can be challenging to debug. To make things easier, we can use [Spring Cloud Sleuth][spring-cloud-sleuth] to enhance the application logs with tracing details. 

Spring Cloud Sleuth is a distributed tracing solution for Spring Cloud and it adds a _trace id_ and a _span id_ to the logs:

- The _span_ represents a basic unit of work, for example sending an HTTP request.
- The _trace_ contains a set of spans, forming a tree-like structure. The trace id will remain the same as one microservice calls the next.

With this information, when visualizing the logs, we'll be able to get all events for a given trace or span id, providing visibility into the behavior of the chain of interactions between the services.

Once the Spring Cloud Sleuth dependency is added to the classpath, all interactions with the downstream services will be instrumented automatically and the trace and span ids will be added to the SLF4J's [Mapped Diagnostic Context][slf4j.mdc] (MDC), which will be included in the logs.

```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-sleuth</artifactId>
            <version>${spring-cloud-sleuth.version}</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>

<dependencies>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-sleuth</artifactId>
    </dependency>
</dependencies>
```

### Logging in JSON format

Logback, by default, will produce logs in plain text. But as we intend our log events to be indexed in Elasticsearch, which stores JSON documents, it would be a good idea to produce log events in JSON format instead of having to parse plain text log events in Logstash.

To accomplish it, we can use the [Logstash Logback Encoder][logstash-logback-encoder], which provides Logback encoders, layouts, and appenders to log in JSON. The Logstash Logback Encoder was originally written to support output in Logstash's JSON format, but has evolved into a general-purpose, highly-configurable, structured logging mechanism for JSON and other dataformats. 

And, instead of managing log files directly, our microservices could log to the standard output using the `ConsoleAppender`. As the microservices will run in Docker containers, we can leave the responsibility of writing the log files to Docker. We will see more details about the Docker in the next section.

For a simple and quick configuration, we could use `LogstashEncoder`, which comes with a [pre-defined set of providers][logstash-logback-encoder.standard-fields]:

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration>

    <springProperty scope=""context"" name=""application_name"" source=""spring.application.name""/>

    <appender name=""jsonConsoleAppender"" class=""ch.qos.logback.core.ConsoleAppender"">
        <encoder class=""net.logstash.logback.encoder.LogstashEncoder""/>
    </appender>

    <root level=""INFO"">
        <appender-ref ref=""jsonConsoleAppender""/>
    </root>
    
</configuration>
```

The above configuration will produce the following log output (just bear in mind that the actual output is a single line, but it's been formatted below for better visualization):

```json
{
   ""@timestamp"": ""2019-06-29T23:01:38.967+01:00"",
   ""@version"": ""1"",
   ""message"": ""Finding details of post with id 1"",
   ""logger_name"": ""com.cassiomolin.logaggregation.post.service.PostService"",
   ""thread_name"": ""http-nio-8001-exec-3"",
   ""level"": ""INFO"",
   ""level_value"": 20000,
   ""application_name"": ""post-service"",
   ""traceId"": ""c52d9ff782fa8f6e"",
   ""spanId"": ""c52d9ff782fa8f6e"",
   ""spanExportable"": ""false"",
   ""X-Span-Export"": ""false"",
   ""X-B3-SpanId"": ""c52d9ff782fa8f6e"",
   ""X-B3-TraceId"": ""c52d9ff782fa8f6e""
}
```

This encoder includes the values stored in MDC by default. When Spring Cloud Sleuth is in the classpath, the following properties will added to MDC and will be logged: `traceId`, `spanId`, `spanExportable`, `X-Span-Export`, `X-B3-SpanId` and `X-B3-TraceId`.

If we need more flexibility in the JSON format and in data included in log, we can use `LoggingEventCompositeJsonEncoder`. The composite encoder has no providers configured by default, so we must add the [providers][logstash-logback-encoder.providers-for-loggingevents] we want to customize the output:

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration>

    <springProperty scope=""context"" name=""application_name"" source=""spring.application.name""/>

    <appender name=""jsonConsoleAppender"" class=""ch.qos.logback.core.ConsoleAppender"">
        <encoder class=""net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder"">
            <providers>
                <timestamp>
                    <timeZone>UTC</timeZone>
                </timestamp>
                <version/>
                <logLevel/>
                <message/>
                <loggerName/>
                <threadName/>
                <context/>
                <pattern>
                    <omitEmptyFields>true</omitEmptyFields>
                    <pattern>
                        {
                            ""trace"": {
                                ""trace_id"": ""%mdc{X-B3-TraceId}"",
                                ""span_id"": ""%mdc{X-B3-SpanId}"",
                                ""parent_span_id"": ""%mdc{X-B3-ParentSpanId}"",
                                ""exportable"": ""%mdc{X-Span-Export}""
                            }
                        }
                    </pattern>
                </pattern>
                <mdc>
                    <excludeMdcKeyName>traceId</excludeMdcKeyName>
                    <excludeMdcKeyName>spanId</excludeMdcKeyName>
                    <excludeMdcKeyName>parentId</excludeMdcKeyName>
                    <excludeMdcKeyName>spanExportable</excludeMdcKeyName>
                    <excludeMdcKeyName>X-B3-TraceId</excludeMdcKeyName>
                    <excludeMdcKeyName>X-B3-SpanId</excludeMdcKeyName>
                    <excludeMdcKeyName>X-B3-ParentSpanId</excludeMdcKeyName>
                    <excludeMdcKeyName>X-Span-Export</excludeMdcKeyName>
                </mdc>
                <stackTrace/>
            </providers>
        </encoder>
    </appender>

    <root level=""INFO"">
        <appender-ref ref=""jsonConsoleAppender""/>
    </root>
    
</configuration>
```

Find below a sample of the log output for the above configuration. Again, the actual output is a single line, but it's been formatted for better visualization:

```json
{  
   ""@timestamp"": ""2019-06-29T22:01:38.967Z"",
   ""@version"": ""1"",
   ""level"": ""INFO"",
   ""message"": ""Finding details of post with id 1"",
   ""logger_name"": ""com.cassiomolin.logaggregation.post.service.PostService"",
   ""thread_name"": ""http-nio-8001-exec-3"",
   ""application_name"": ""post-service"",
   ""trace"": {  
      ""trace_id"": ""c52d9ff782fa8f6e"",
      ""span_id"": ""c52d9ff782fa8f6e"",
      ""exportable"": ""false""
   }
}
```

## Running on Docker

We'll run Elastic Stack applications along with our Spring Boot microservices in [Docker][docker] containers:

![Docker containers][img.elastic-stack-docker]

As we will have multiple containers, we will use [Docker Compose][docker-compose] to manage them. With Compose, application’s services are configured in a YAML file. Then, with a single command, we create and start all the services from our configuration. Pretty cool stuff!

Have a look at how the services are defined and configured in the [`docker-compose.yml`][repo.docker-compose.yml]. What's important to highlight is the fact that _labels_ have been added to some services. Labels are simply metadata that only have meaning for who's using them. Let's have a quick looks at the labels that have been defined for the services:

- `collect_logs_with_filebeat`: When set to `true`, indicates that Filebeat should collect the logs produced by the Docker container.

- `decode_log_event_to_json_object`: Filebeat collects and stores the log event as a string in the `message` property of a JSON document. If the events are logged as JSON (which is the case when using the appenders defined above), the value of this label can be set to `true` to indicate that Filebeat should decode the JSON string stored in the `message` property to an actual JSON object.

Both post and comment services will produce logs to the standard output (`stdout`). By default, Docker captures the standard output (and standard error) of all your containers, and writes them to files in JSON format, using the `json-file` driver. The logs files are stored in the `/var/lib/docker/containers` directory and each log file contains information about only one container.

When applications run on containers, they become moving targets to the monitoring system. So we'll use the [autodiscover][filebeat.autodiscover] feature from Filebeat, which allows it to track the containers and adapt settings as changes happen. By defining configuration templates, the autodiscover subsystem can monitor services as they start running. So, in the [`filebeat.docker.yml`][repo.filebeat.docker.yml] file, Filebeat is configured to:

- Autodiscover the Docker containers that have the label `collect_logs_with_filebeat` set to `true`
- Collect logs from the containers that have been discovered 
- Decode the `message` field to a JSON object when the log event was produced by a container that have the label `decode_log_event_to_json_object` set to `true`
- Send the log events to Logstash which runs on the port `5044`

```yaml
filebeat.autodiscover:
  providers:
    - type: docker
      labels.dedot: true
      templates:
        - condition:
            contains:
              container.labels.collect_logs_with_filebeat: ""true""
          config:
            - type: container
              format: docker
              paths:
                - ""/var/lib/docker/containers/${data.docker.container.id}/*.log""
              processors:
                - decode_json_fields:
                    when.equals:
                      docker.container.labels.decode_log_event_to_json_object: ""true""
                    fields: [""message""]
                    target: """"
                    overwrite_keys: true

output.logstash:
  hosts: ""logstash:5044""
```

The above configuration uses a single processor. If we need, we could add more processors, which will be _chained_ and executed in the order they are defined in the configuration file. Each processor receives an event, applies a defined action to the event, and the processed event is the input of the next processor until the end of the chain.

Once the log event is collected and processed by Filebeat, it is sent to Logstash, which provides a rich set of plugins for further processing the events. 

The Logstash pipeline has two required elements, `input` and `output`, and one optional element, `filter`. The [input plugins][logstash.input-plugins] consume data from a source, the [filter plugins][logstash.filter-plugins] modify the data as we specify, and the [output plugins][logstash.output-plugins] write the data to a destination. 

![Logstash pipeline][img.logstash-pipeline]

In the [`logstash.conf`][repo.logstash.conf] file, Logstash is configured to:

- Receive events coming from Beats in the port `5044`
- Process the events by adding the tag `logstash_filter_applied`
- Send the processed events to Elasticsearch which runs on the port `9200`

```java
input {
  beats {
    port => 5044
  }
}

filter {
  mutate {
    add_tag => [ ""logstash_filter_applied"" ]
  }
}

output {
  elasticsearch {
    hosts => ""elasticsearch:9200""
  }
}
```

Elasticsearch will store and index the log events and, finally, we will be able to visualize the logs in Kibana, which exposes a UI in the port `5601`.

## Example

For this example, let's consider we are creating a blog engine and we have the following microservices:

- _Post service_: Manages details related to posts.
- _Comment service_: Manages details related to the comments of each post.

Each microservice is a Spring Boot application, exposing a HTTP API. As we intend to focus on _log aggregation_, let's keep it simple when it comes to the services architecture: One service will simply invoke the other service directly.

And, for demonstration purposes, all data handled by the services is stored in memory and only `GET` requests are supported. When a representation of post is requested, the post service will perform a `GET` request to the comment service to get a representation of the comments for that post. The post service will aggregate the results and return a representation of the post with comments to the client.

![Post and comment services][img.services]

Let's see how to build the source code, spin up the Docker containers, produce some log data and then visualize the logs in Kibana.

Before starting, ensure you at least Java 11, Maven 3.x and Docker set up. Then clone the [repository][repo] from GitHub:

```bash
git clone https://github.com/cassiomolin/log-aggregation-spring-boot-elastic-stack.git
```

### Building the applications and creating Docker images

Both post and comment services use the [`dockerfile-maven`][dockerfile-maven] plugin from Spotify to make the Docker build process integrate with the Maven build process. So when we build a Spring Boot artifact, we'll also build a Docker image for it. For more details, check the `Dockerfile` and the `pox.xml` of each service.

To build the Spring Boot applications and their Docker images:

- Change to the `comment-service` folder: `cd comment-service`
- Build the application and create a Docker image: `mvn clean install`
- Change back to the parent folder: `cd ..`

- Change to the `post-service` folder: `cd post-service`
- Build the application and create a Docker image: `mvn clean install`
- Change back to the parent folder: `cd ..`

### Spinning up the containers

In the root folder of our project, where the `docker-compose.yml` resides, spin up the Docker containers running `docker-compose up`.

### Visualizing logs in Kibana

- Open Kibana in your favourite browser: `http://localhost:5601`. When attempting to to access Kibana while it's starting, a message saying that Kibana is not ready yet will be displayed in the browser. Enhance your calm, give it a minute or two and then you are good to go.

- In the first time you access Kibana, a welcome page will be displayed. Kibana comes with sample data in case we want to play with it. To explore the data generate by our applications, click the _Explore on my own_ link.

![Welcome page][img.screenshot-01]

- On the left hand side, click the _Discover_ icon.

![Home][img.screenshot-02]

- Kibana uses index patterns for retrieving data from Elasticsearch. As it's the first time we are using Kibana, we must create an index pattern to explore our data. We should see an index that has been created by Logstash. So create a pattern for matching the Logstash indexes using `logstash-*` and then click the _Next step_ button.

- Kibana uses _index patterns_ for retrieving data from Elasticsearch. So, to get started, you must create an index pattern. In this page, you should see an index that has been created by Logstash. To create a pattern for matching this index, enter `logstash-*` and then click the _Next step_ button.

![Creating index pattern][img.screenshot-03]

- Then pick a field for filtering the data by time. Choose `@timestamp` and click the _Create index pattern_ button.

![Picking a field for filtering data by time][img.screenshot-04]

- The index pattern will be created. Click again in the _Discover_ icon and the log events of both post and comment services start up will be shown:

![Viewing the log events][img.screenshot-05]

- To filter log events from the post service, for example, enter `application_name : ""post-service""` in the search box. Click the _Update_ button and now you'll see log events from the post service only.

![Filtering logs by application name][img.screenshot-06]

- Clean the filter input and click the _Update_ button to view all logs. 

- Perform a `GET` request to `http://localhost:8001/posts/1` to generate some log data. Wait a few seconds and then click the _Refresh_ button. You will be able to see logs from the requests. The logs will contain tracing details, such as _trace.trace_id_ and _trace.span id_.

- In the left-hand side, there's a list of fields available. Hover over the list of fields and an _Add_ button will be shown for each field. Add a few fields such as `application_name`, `trace.trace_id`, `trace.span_id` and `message`.

- Now let's see how to trace a request. Pick a trace id from the logs and, in the filter box, input `trace.trace_id: ""<value>""` where `<value>` is the trace id you want to use as filter criteria. Then click the _Update_ button and you will able to see logs that match that trace id. 

- As can be seen in the image below, the trace id is the same for the entire operation, which started in the post service. And the log events resulted from a call to the comment service haven been assigned a different span id.

![Filtering logs by trace id][img.screenshot-07]

To stop the containers, use `docker-compose down`. It's important to highlight that both Elasticsearch indices and the Filebeat tracking data are stored in the host, under the `./elasticseach/data` and `./filebeat/data` folders. It means that, if you destroy the containers, the data will be lost.


  [img.services]: /misc/img/diagrams/services.png
  [img.elastic-stack]: /misc/img/diagrams/elastic-stack.png
  [img.elastic-stack-docker]: /misc/img/diagrams/services-and-elastic-stack.png
  [img.logstash-pipeline]: /misc/img/diagrams/logstash-pipeline.png
  [img.screenshot-01]: /misc/img/screenshots/01.png
  [img.screenshot-02]: /misc/img/screenshots/02.png
  [img.screenshot-03]: /misc/img/screenshots/03.png
  [img.screenshot-04]: /misc/img/screenshots/04.png
  [img.screenshot-05]: /misc/img/screenshots/05.png
  [img.screenshot-06]: /misc/img/screenshots/06.png
  [img.screenshot-07]: /misc/img/screenshots/07.png

  [12factor]: https://12factor.net
  [12factor.logs]: https://12factor.net/logs
 
  [spring-boot.configure-logback]: https://docs.spring.io/spring-boot/docs/current/reference/html/howto-logging.html#howto-configure-logback-for-logging
  [spring-cloud-sleuth]: https://spring.io/projects/spring-cloud-sleuth
  
  [dockerfile-maven]: https://github.com/spotify/dockerfile-maven
  
  [slf4j]: https://www.slf4j.org/
  [slf4j.manual]: https://www.slf4j.org/manual.html
  [logback]: https://logback.qos.ch/
  [logstash-logback-encoder]: https://github.com/logstash/logstash-logback-encoder
  [logstash-logback-encoder.standard-fields]: https://github.com/logstash/logstash-logback-encoder#standard-fields
  [logstash-logback-encoder.providers-for-loggingevents]: https://github.com/logstash/logstash-logback-encoder#providers-for-loggingevents
  
  [repo]: https://github.com/cassiomolin/log-aggregation-spring-boot-elastic-stack
  [repo.docker-compose.yml]: https://github.com/cassiomolin/log-aggregation-spring-boot-elastic-stack/blob/master/docker-compose.yml
  [repo.logstash.conf]: https://github.com/cassiomolin/log-aggregation-spring-boot-elastic-stack/blob/master/logstash/pipeline/logstash.conf
  [repo.filebeat.docker.yml]: https://github.com/cassiomolin/log-aggregation-spring-boot-elastic-stack/blob/master/filebeat/filebeat.docker.yml

  [elk-stack]: https://www.elastic.co/elk-stack
  [elasticsearch]: https://www.elastic.co/products/elasticsearch
  [logstash]: https://www.elastic.co/products/logstash
  [logstash.input-plugins]: https://www.elastic.co/guide/en/logstash/current/input-plugins.html
  [logstash.filter-plugins]: https://www.elastic.co/guide/en/logstash/current/filter-plugins.html
  [logstash.output-plugins]: https://www.elastic.co/guide/en/logstash/current/output-plugins.html
  [kibana]: https://www.elastic.co/products/kibana
  [beats]: https://www.elastic.co/products/beats
  [filebeat]: https://www.elastic.co/products/beats/filebeat
  [filebeat.autodiscover]: https://www.elastic.co/guide/en/beats/filebeat/current/configuration-autodiscover.html
  [metricbeat]: https://www.elastic.co/products/beats/metricbeat
  [packetbeat]: https://www.elastic.co/products/beats/packetbeat
  [heartbeat]: https://www.elastic.co/products/beats/heartbeat

  [docker]: https://docs.docker.com/
  [docker.json-file-logging-driver]: https://docs.docker.com/config/containers/logging/json-file/
  [docker-compose]: https://docs.docker.com/compose/

  [slf4j.mdc]: https://www.slf4j.org/manual.html#mdc
  
  [lombok]: https://projectlombok.org/
  [lombok.slf4j]: https://projectlombok.org/api/lombok/extern/slf4j/Slf4j.html
  
  [org.slf4j.Logger]: https://www.slf4j.org/api/org/slf4j/Logger.html
  [org.slf4j.LoggerFactory]: https://www.slf4j.org/api/org/slf4j/LoggerFactory.html"
phishman3579/Bitcoin,master,119,54,2015-07-10T17:22:56Z,149,0,An example Bitcoin implementation which can be used to learn about Bitcoin/Blockchain. This implementations is for educational use only!,blockchain java,"# Bitcoin
An example Bitcoin implementation which can be used to learn about Bitcoin/Blockchain. This implementations is for educational use only.

# Overview.

## Wallet

The Wallet is how peers interact with the Bitcoin peer-to-peer network. The Wallet generates a public key and a private key which it uses to sign each Transaction. The pulic key is the send-to address used by the Bitcoin network. Each Wallet has the ability to send coins from your account to another account and it also has the ability to confirm Transactions (except it's own) which it receives from the Bitcoin peer-to-peer network.

```
    Wallet {
      sendCoin(entity, value); // Creates a new Transaction
      handleTransaction(Transaction); // Receives a unconfirmed Transaction
      handleConfirmation(Transaction); // Receives a confirmed Transaction and adds to blockchain
    }
```

## Transaction

Transactions are just a collection of input transactions, output transactions, a value, and a signature. 

```
    Transaction {
        byte[] header;
        Transaction[] inputs;
        Transaction[] outputs;
        long value;
        byte[] signature;
    }
```

See the [Transaction Class](https://github.com/phishman3579/Bitcoin/blob/master/src/com/jwetherell/bitcoin/data_model/Transaction.java) for reference.

#### The Wallet also has a number of Transaction rules:

* Once a Transaction has been used as an input, it cannot be used again. 
* All inputs on a Transaction have to be completely consumed on a transaction.

Note: To send a Bitcoin transaction, you have to already own a Bitcoin. Getting an initial Bitcoin is usually done by trading something for a number of Bitcoins. One caveat of, having to own a Bitcoin to make a transaction, is the first transaction. The first transaction is called the genesis transaction, it is the only transaction which does not need input transactions.

### An example Transaction

If Justin wants to send 6 coins to George:

Ledger:

|  Justin's unused Transactions  |  George's unused Transaction  |
|  ----------------------------- | ----------------------------- | 
| Transaction #1 : 5 Coins       |                               |
| Transaction #2 : 3 Coins       |                               |
| Transaction #3 : 7 Coins       |                               |

```
    Aggregate Transaction #4 {
      byte[]        header      ""6 coins for George and 2 coins to Justin""
      Transaction[] input       { Transaction #1, Transaction #2 }
      Transaction[] output      { Transaction #5, Transaction #6 }
      int           value       0
      byte[]        signature   ""Justin's signature based on the Header""
    }
```
Note: The 'value' on the Aggregate Transaction (#4) is a reward for anyone who confirms the Transaction. The higher the reward, the better chance the Transaction will be processed quicker.

```
    Transaction #5 {
      byte[]        header      ""2 coins to Justin""
      Transaction[] input       { Transaction #1, Transaction #2 }
      Transaction[] output      { }
      int           value       2
      byte[]        signature   ""Justin's signature based on the Header""
    }

    Transaction #6 {
      byte[]        header      ""6 coins for George""
      Transaction[] input       { Transaction #1, Transaction #2 }
      Transaction[] output      { }
      int           value       6
      byte[]        signature   ""Justin's signature based on the Header""
    }
```

The Aggregate Transaction (#4) will remove Transaction #1 and #2 from Justin's unused Transactions. Since the total of all inputs is 8 coins, which is 2 more than what Justin wants to send to George, the output will contain a Transaction which sends 2 coins back to Justin.

The Wallet will use it's private key to sign the Header of the Aggregate Transactions (#4) and it will also sign each of the output Transactions (#5 & #6). It will then send Transaction #4 to the Bitcoin network for confirmation. 

Each peer on the Bitcoin network will receive the Transaction and try to confirm it. 

To confirm a Transaction, a Peer will:
* Check the Signature of Transaction against the public key of the sender. 

If it passes:
* Send the confirmed Transaction to the Bitcoin network.

## Block

The confirmed Transaction (#4) is added to a pool of confirmed Transactions. Peers (also called Miners) will gather confirmed Transactions from the pool and put them into a Block. A Block contains a number of confirmed Transactions, the Miner's signature, and a couple of other fields used for ""Proof of work"" processing.

```
    Block {
      Transaction[]     transactions
      int               nonce
      int               zeros
      byte[]            previousHash
      byte[]            nextHash
      byte[]            signature
    }
```

See the [Block Class](https://github.com/phishman3579/Bitcoin/blob/master/src/com/jwetherell/bitcoin/data_model/Block.java) for reference.

Miners will create a single 'block hash' from all the confirmed Transactions in the Block. They will then go through the process of ""Proof of work"". The goal of the ""Proof of work"" is to create a hash which begins with a random number of zeros (see the 'zeros' field). ""Proof of work"" is designed to be processor intensive which adds randomness to the time it takes to process a Block. A Miner will take the 'block hash' and append a random integer (called a 'nonce') to it. It will then create a new hash from 'block hash + nonce' and see if it satisfies the ""Proof of work"", this process will repeat until it finds a 'nonce' which satisfies the ""Proof of work""

See the [Proof of work](https://github.com/phishman3579/Bitcoin/blob/master/src/com/jwetherell/bitcoin/ProofOfWork.java) for reference.

Once a Miner finds a 'nonce' which satisfies the ""Proof of work"", it will:
* Create another hash (see 'nextHash') using the Blockchain's current hash (see 'previousHash') and the 'block hash' 
* Send the Block to the Bitcoin network.

```
    Block #1 {
      Transaction[]     transactions    { Transaction #4 }
      int               nonce           453;
      int               zeros           3;
      byte[]            previousHash    ""Blockchain hash #1"";
      byte[]            nextHash        ""Blockchain hash #2"";
      byte[]            signature       ""Miner's signature"";
    }
```
Peers on the Bitcoin network will receive the Block and start confirming it. 

To confirm the Block, A Peer will:
* Make sure the 'nonce' satisfies the ""Proof of work""
* Check the Block's signature 
* Check the signature of each Trasaction in the Block.

If everything passes:
* Add the block to it's Blockchain.
* Send the confirmed Block to the Bitcoin network

## Blockchain

The Blockchain is a simple structure which contains a list of confirmed Blocks, a list of Transactions in chronological order, a list of unused Transactions, and the current hash.

Note: all transactions in the same block are said to have happened at the same time.

```
    Blockchain {
        List<Block>         blockchain
        List<Transactions>  transactions
        List<Transaction>   unused
        byte[]              currentHash
    }
```

See the [Blockchain](https://github.com/phishman3579/Bitcoin/blob/master/src/com/jwetherell/bitcoin/BlockChain.java) for reference.


When the Peer adds the Block to the Blockchain, the Blockchain will:
* Check to see if the 'previousHash' from the Block matches it's 'currentHash', 
* Check to see if the input Transactions from all the Transactions in the Block are 'unused'

If everything passes:
* The Block is added to the 'blockChain'
* The Transaction is added to the 'transactions' list
* All 'input' transactions are removed from the 'unused' list
* All the 'output' transactions are added to the 'unused' list
* The 'currentHash' is updated to 'nextHash' from the current Block.

```
    Blockchain {
        List<Block>         blockchain      { Block #0 }
        List<Transactions>  transactions    { Transaction #0 }
        List<Transaction>   unused          { Transaction #1, Transaction #2, Transaction #3 }
        byte[]              currentHash     ""Blockchain hash #1""
    }
```

Updated Blockchain.

```
    Blockchain {
        List<Block>         blockchain      { Block #0, Block #1 };
        List<Transactions>  transactions    { Transaction #0, Transaction #4 }
        List<Transaction>   unused          { Transaction #3, Transaction #5, Transaction #6 }
        byte[]              currentHash     ""Blockchain hash #2""
    }
```

Ledger:

|  Justin's unused Transactions  |  George's unused Transaction  |
|  ----------------------------- | ----------------------------- | 
| Transaction #3 : 7 Coins       | Transaction #6 : 6 Coins      |
| Transaction #5 : 2 Coins       |                               |
|                                |                               |

Based off of [1](http://www.michaelnielsen.org/ddi/how-the-bitcoin-protocol-actually-works/) and [2](http://www.imponderablethings.com/2013/07/how-bitcoin-works-under-hood.html)

Also see the [original paper](https://bitcoin.org/bitcoin.pdf)
"
AndroidExamples/SwipeRefreshLayout-ListViewExample,master,25,7,2014-04-14T21:11:10Z,232,0,Example SwipeRefreshLayout with ListView-EmptyView combination.,,"SwipeRefreshLayout-ListViewExample
==================================

SwipeRefreshLayout example to animate the refreshing of a ListView.

V. 0.1: Support for emptyView
"
jaxio/jpa-query-by-example,master,42,22,2012-11-26T09:55:45Z,264,5,The JPA Query by Example framework is used by projects generated by Celerio.,,"## JPA Query by Example framework

[![Build Status](https://travis-ci.org/jaxio/jpa-query-by-example.svg?branch=master)](https://travis-ci.org/jaxio/jpa-query-by-example)

Query By Example for JPA is originally inspired from [Hibernate Example criterion](https://docs.jboss.org/hibernate/orm/3.6/reference/en-US/html/querycriteria.html#querycriteria-examples
). But since Hibernate's Example is not part of JPA 2, we have created our own API, using JPA 2 only.


## How To Use QBE 

We do not cover here QBE implementation details, instead we explain how to use the Query By Example API.

JPA Query by Example is available on Maven central repository:

```xml
<dependency>
	<groupId>com.jaxio</groupId>
	<artifactId>jpa-querybyexample</artifactId>
	<version>1.0.1</version>
</dependency>
```

#### Resources

* Take a look directly at the [QBE junit tests](https://github.com/jaxio/jpa-query-by-example/blob/master/src/test/java/demo), they are almost self-explanatory.
* Use Celerio to generate an advanced CRUD application that leverages this QBE API. See [Celerio](http://www.jaxio.com/documentation/celerio/installation.html)
* [Watch a demo of an application generated by Celerio](https://www.facebook.com/video/video.php?v=524162864265905&notif_t=video_processed)
 

### Simple Query By Example

In its simplest form, Query By Example allows you to construct a query from a given entity instance.

Let's assume we have an [Account entity](https://github.com/jaxio/jpa-query-by-example/blob/master/src/test/java/demo/Account.java) 
having a `lastName` property and that we want to query all accounts whose last name matches 'Jagger'.

Using QBE, constructing the query is as simple as setting the lastName...:

```java
Account example = new Account();
example.setLastName(""Jagger"");
List<Account> result = accountRepository.find(example);
```

At the SQL level, the resulting query looks like this:

```sql
select
    -- skip other fields for clarity
    account0_.LAST_NAME as LAST9_3_,
from
    Account account0_ 
where
    account0_.LAST_NAME=?
```

The [AccountRepository](https://github.com/jaxio/jpa-query-by-example/blob/master/src/test/java/demo/AccountRepository.java)
extends a [GenericRepository](https://github.com/jaxio/jpa-query-by-example/blob/master/src/main/java/com/jaxio/jpa/querybyexample/GenericRepository.java)

#### Case sensitivity, order by

The first query above involves a String. Let's change it to make it case insensitive.

Our `Account` entity does not carry case sensitivity meta information. For this reason, we require some extra parameters 
for case sensitivity, but also ordering, etc.
The number of parameters can grow quickly, so we have grouped them in the
[SearchParameters](https://github.com/jaxio/jpa-query-by-example/blob/master/src/main/java/com/jaxio/jpa/querybyexample/SearchParameters.java) class 
which can be passed as a parameter to the accountRepository's methods.

Let's make the first query above `case insensitive` and let's add an `ORDER BY`.

```java
Account example = new Account();
example.setLastName(""Jagger""); 
SearchParameters sp = new SearchParameters().caseSensitive().orderBy(OrderByDirection.ASC, Account_.lastName);
List<Account> result = accountRepository.find(example, sp);
```

Note the usage of the 
[Account_](https://github.com/jaxio/jpa-query-by-example/blob/master/src/test/java/demo/Account_.java)* 
static metamodel, which helps you to keep your query related Java code strongly typed.

At the SQL level, the resulting FROM clause now looks like this:

```sql
from
    ACCOUNT account0_ 
where
    lower(account0_.LAST_NAME)=? 
order by
    account0_.LAST_NAME asc
```

#### Pagination

In most web application we need to paginate the query results in order to save resources. In the query below, we retrieve only 
the 3rd page (we assume a page lists 25 rows). The first result is the 50th element and we retrieve at most 25 elements.

```java
Account example = new Account();
example.setLastName(""Jagger"");
SearchParameters sp = new SearchParameters().orderBy(OrderByDirection.ASC, Account_.lastName) //
	.first(50).maxResults(25);
List<Account> result = accountRepository.find(example, sp);
```

At the SQL level, the resulting FROM clause now looks like this (we use H2 database):

```sql
from
    ACCOUNT account0_ 
where
    account0_.LAST_NAME=? 
order by
    account0_.LAST_NAME asc limit ? offset ?
```

#### LIKE and String

For strings, you can globally control whether a `LIKE` should be used and where the `%` wildcard should be placed. For example, adding :

```java
example.setLastName(""Jag"");
SearchParameters sp = new SearchParameters().startingLike();
```

to our example above would result in  

```sql
account0_.LAST_NAME LIKE 'Jag%'
```

#### Multiple criteria

Until now, we have worked only with one property, lastName, but we can set other properties, for example:

```java
Account example = new Account();
example.setLastName(""Jag"");
example.setBirthDate(new Date());
SearchParameters sp = new SearchParameters().orderBy(OrderByDirection.ASC, Account_.lastName).startingLike();
List<Account> result = accountRepository.find(example, sp);
```

By default, the FROM clause uses a `AND` predicate. 

```sql
from
    ACCOUNT account0_ 
where
    account0_.BIRTH_DATE=? 
    and (
        account0_.LAST_NAME like ?
    ) 
order by
    account0_.LAST_NAME asc
```

To use instead `OR`, use the `.orMode()`, as follow:

```java
SearchParameters sp = new SearchParameters().orMode().orderBy(OrderByDirection.ASC, Account_.lastName).startingLike();
```

And this time we get:

```sql
where
    account0_.LAST_NAME like ? 
    or account0_.BIRTH_DATE=? 
order by
    account0_.LAST_NAME asc
```

#### Is that all ?

Not really, we have just scratched the surface. For the moment, we have covered only rather simple queries.
While simplicity is key, it is often not sufficient. What about date or number range queries ?  What about associated entities ? etc.

### Beyond Query By Example

#### Mixing Query by Example and Range Query.

Now, let's imagine that you also want to restrict the query above to all accounts having their date of birth between 1940 and 1945 included.
Of course, the entity does not have the appropriate property (from & to). 
For this reason, we introduce an additional 
[Range](https://github.com/jaxio/jpa-query-by-example/blob/master/src/main/java/com/jaxio/jpa/querybyexample/Range.java) 
parameter.

Here is an example:

```java
Account example = new Account();
example.setLastName(""Jagger"");

Calendar from = Calendar.getInstance();
from.set(1940, 0, 1);

Calendar to = Calendar.getInstance();
to.set(1945, 11, 31);

Range<Account, Date> birthDateRange = Range.newRange(Account_.birthDate);
birthDateRange.from(from.getTime()).to(to.getTime());

SearchParameters sp = new SearchParameters().range(birthDateRange);
List<Account> result = accountRepository.find(example, sp);
```

Note that you can add ranges of any type: Integer, Long, LocalDate (joda time), BigDecimal, etc...

This codes leads in fine to following `FROM` clause:

```sql
from
    ACCOUNT account0_ 
where
    (
        account0_.BIRTH_DATE between ? and ?
    ) 
    and account0_.LAST_NAME=?
```

Here is a variation of the same example (depends on need, taste and color :-): 

```java
DateFormat dateFormat = new SimpleDateFormat(""yyyy-MM-dd"");
Date from = dateFormat.parse(""1920-12-01"");
Date to = dateFormat.parse(""1974-12-01"");

SearchParameters sp = new SearchParameters().range(from, to, Account_.birthDate);
List<Account> accountList = accountRepository.find(sp);
```

#### Query all string properties in a OR clause

To find all entities having at least one of their String property matching a given value, use the `searchPattern` method.

Here is an example: 

```java    
SearchParameters sp = new SearchParameters().searchMode(SearchMode.STARTING_LIKE).searchPattern(""Jag"");
List<Account> result = accountRepository.find(sp);
```

The FROM clause now includes all string columns:

```sql
from
    ACCOUNT account0_ 
where
    or account0_.LAST_NAME like ? 
    or account0_.USERNAME like ? 
```

#### Property Selector

In order to construct a `OR` clause for a given property we use the `PropertySelector` class.

Here is an example:

```java    
PropertySelector<Account, String> lastNameSelector = PropertySelector.newPropertySelector(Account_.lastName);
lastNameSelector.setSelected(Arrays.asList(""Jagger"", ""Richards"", ""Jones"", ""Watts"", ""taylor"", ""Wyman"", ""Wood""));

SearchParameters sp = new SearchParameters().property(lastNameSelector);

List<Account> result = accountRepository.find(sp);
```

Here is the corresponding FROM clause: 

```sql
	from
	    ACCOUNT account0_ 
	where
	    account0_.LAST_NAME='Jagger'
	    or account0_.LAST_NAME='Richards'
	    or account0_.LAST_NAME='Jones'
	    or account0_.LAST_NAME='Watts'
	    or account0_.LAST_NAME='Taylor'
	    or account0_.LAST_NAME='Wyman'
	    or account0_.LAST_NAME='Wood'
```

Note that if you use JSF2 with PrimeFaces, you can directly pass a `PropertySelector` to a multiple autoComplete component's value property.
This way, the autoComplete component fills the PropertySelector. Here is how:

```xml
<p:autoComplete ... multiple=""true"" value=""#{accountSearchForm.lastNameSelector.selected}"" ... />
```

Here is a snapshot:

![property selector](https://github.com/jaxio/jpa-query-by-example/blob/master/src/img/property-selector.png)

PrimeFaces uses the `setSelected(List<Account> selection)` method to fill the lastNameSelector.

#### Mix it all

Remember, you can mix all the example we have seen so far.
You can have in a single query having multiple ranges, multiple property selector, multiple properties set on the example entity, etc.

This gives you great power ;-)

#### Query By Example on association

The `Account` entity has a `@ManyToOne` association with the `Address` entity.

Here is how we can retrieve all accounts pointing to an Address having its `city` property set to ""Paris"":

```java    
Account example = new Account();
example.setHomeAddress(new Address());
example.getHomeAddress().setCity(""Paris"");
List<Account> result = accountRepository.find(example);
Assert.assertThat(result.size(), is(2));
```

The FROM clause uses a JOIN:

```sql
from
    ACCOUNT account0_ cross 
join
    ADDRESS address1_ 
where
    account0_.ADDRESS_ID=address1_.ID 
    and address1_.CITY='Paris'
```

Enjoy!


## License

The JPA Query By Example Framework is released under version 2.0 of the [Apache License][].

[Apache License]: http://www.apache.org/licenses/LICENSE-2.0

"
FISCO-BCOS/spring-boot-starter,master,65,46,2019-02-12T08:31:00Z,466,12,An example to help users use java-sdk(master branch) and web3sdk(master-web3sdk branch) with Spring Boot,,"# spring-boot-starter

本示例项目基于Java SDK + Gradle + SpringBoot方式来调用智能合约。

## 前置条件

搭建FISCO BCOS 单群组区块链（Air版本），具体步骤[参考这里](https://fisco-bcos-doc.readthedocs.io/zh_CN/latest/docs/tutorial/air/build_chain.html) 。

## 下载spring-boot-starter、证书拷贝

```shell
git clone https://github.com/FISCO-BCOS/spring-boot-starter.git
```

进入spring-boot-starter项目

```shell
cd spring-boot-starter
```

请将证书拷贝到src/main/resources/conf目录下。

## 配置连接节点

请修改application.properties，该文件包含如下信息：

```yml
### Java sdk configuration
cryptoMaterial.certPath=conf
network.peers[0]=127.0.0.1:20200
        #network.peers[1]=127.0.0.1:20201

        ### System configuration
system.groupId=group0
system.hexPrivateKey=

        ### Springboot configuration
server.port=8080
```

其中：

- Java SDK configuration配置部分与 [Java SDK](https://fisco-bcos-doc.readthedocs.io/zh_CN/latest/docs/develop/sdk/java_sdk/config.html)一致。就本例而言，用户需要：
  - 请将network.peers更换成实际的链节点监听地址。
  - cryptoMaterial.certPath设为conf

- System configuration配置部分，需要配置：
  - system.hexPrivateKey是16进制的私钥明文，可运行Demos.java中的`keyGeneration`生成（文件路径：src/test/java/org/example/demo/Demos.java）。该配置允许为空，此时系统会随机生成一个私钥。
  - system.groupId设为目标群组，默认为group0

Demos.java 代码如下：（**以项目最新文件为准**）

```java
package org.example.demo;

import java.util.Arrays;
import org.example.demo.constants.ContractConstants;
import org.fisco.bcos.sdk.client.Client;
import org.fisco.bcos.sdk.crypto.keypair.CryptoKeyPair;
import org.fisco.bcos.sdk.crypto.keypair.ECDSAKeyPair;
import org.fisco.bcos.sdk.crypto.keypair.SM2KeyPair;
import org.fisco.bcos.sdk.model.TransactionReceipt;
import org.fisco.bcos.sdk.transaction.manager.AssembleTransactionProcessor;
import org.fisco.bcos.sdk.transaction.manager.TransactionProcessorFactory;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

@SpringBootTest
@RunWith(SpringRunner.class)
public class Demos {

  @Autowired private Client client;

  @Test
  public void keyGeneration() throws Exception {
    // ECDSA key generation
    CryptoKeyPair ecdsaKeyPair = new ECDSAKeyPair().generateKeyPair();
    System.out.println(""ecdsa private key :"" + ecdsaKeyPair.getHexPrivateKey());
    System.out.println(""ecdsa public key :"" + ecdsaKeyPair.getHexPublicKey());
    System.out.println(""ecdsa address :"" + ecdsaKeyPair.getAddress());
    // SM2 key generation
    CryptoKeyPair sm2KeyPair = new SM2KeyPair().generateKeyPair();
    System.out.println(""sm2 private key :"" + sm2KeyPair.getHexPrivateKey());
    System.out.println(""sm2 public key :"" + sm2KeyPair.getHexPublicKey());
    System.out.println(""sm2 address :"" + sm2KeyPair.getAddress());
  }

  @Test
  public void deploy() throws Exception {
    AssembleTransactionProcessor txProcessor =
            TransactionProcessorFactory.createAssembleTransactionProcessor(
                    client, client.getCryptoSuite().getCryptoKeyPair());
    String abi = ContractConstants.HelloWorldAbi;
    String bin = ContractConstants.HelloWorldBinary;
    TransactionReceipt receipt =
            txProcessor.deployAndGetResponse(abi, bin, Arrays.asList()).getTransactionReceipt();
    if (receipt.isStatusOK()) {
      System.out.println(""Contract Address:"" + receipt.getContractAddress());
    } else {
      System.out.println(""Status code:"" + receipt.getStatus() + ""-"" + receipt.getStatusMsg());
    }
  }
}
```

## 编译和运行

您可以在idea内直接运行，也可以编译成可执行jar包后运行。以编译jar包方式为例：

```shell
cd spring-boot-starter
bash gradlew bootJar
cd dist
```

会在dist目录生成spring-boot-starter-exec.jar，可执行此jar包：

```shell
java -jar spring-boot-starter-exec.jar
```

随后，即可访问相关接口。

set示例：

```shell
curl http://127.0.0.1:8080/hello/set?n=hello
```

返回示例（表示交易哈希）：

```shell
0x1c8b283daef12b38632e8a6b8fe4d798e053feb5128d9eaf2be77c324645763b
```

get示例：

```shell
curl http://127.0.0.1:8080/hello/get
```

返回示例：

```json
[""hello""]
```

## 加入我们的社区

**FISCO BCOS开源社区**是国内活跃的开源社区，社区长期为机构和个人开发者提供各类支持与帮助。已有来自各行业的数千名技术爱好者在研究和使用FISCO BCOS。如您对FISCO BCOS开源技术及应用感兴趣，欢迎加入社区获得更多支持与帮助。

![](https://raw.githubusercontent.com/FISCO-BCOS/LargeFiles/master/images/QR_image.png)

## 相关链接

- FISCO BCOS： [FISCO BCOS文档](https://fisco-bcos-doc.readthedocs.io/zh_CN/latest/docs/introduction.html)。
- Java Sdk： [JavaSdk文档](https://fisco-bcos-doc.readthedocs.io/zh_CN/latest/docs/develop/sdk/java_sdk/index.html)。
- SpringBoot文档： [Spring Boot](https://spring.io/guides/gs/spring-boot/)。
- Maven工程示例：[maven示例](https://github.com/FISCO-BCOS/spring-boot-crud)。"
ddd-by-examples/cinema,main,62,10,2020-11-28T15:43:36Z,1136,0,Cinema playground - example repo from reserving seats with different rules,,"# Cinema
Example repo for reserving seats in a cinema for different events with different rules

# Training material
The code is not finished, I use it for refactoring/DDD classes

# Diagram of packages/modules

![arch](/layers.png ""arch"")
"
berndruecker/customer-onboarding-camunda-8-springboot,master,31,29,2020-04-04T08:31:54Z,1455,9,"A simple onboarding process example using BPMN, Camunda Cloud, Java, Spring Boot and REST",,"# Customer Onboarding Process

*Process solution example for customer onboarding as used in the OReilly book [Practical Process Automation](https://processautomationbook.com/).*

![Customer Onboarding](docs/customer-onboarding-simple.png)

This following stack is used:

* Camunda Platform 8
* Java 17
* Spring Boot 3

# Intro

This simple onboarding process is meant to get started with process automation, workflow engines and BPMN.

The process model contains three tasks:

* A service task that executes Java Code to score customers (using the stateless Camunda DMN engine)
* A user task so that humans can approve customer orders (or not)
* A service task that executes glue code to call the REST API of a CRM system

The process solution is a Maven project and contains:

* The onboarding process model as BPMN
* Source code to provide a REST endpoint for clients
* Java code to do the customer scoring
* Glue code to implement the REST call to the CRM system
* Fake for CRM system providing a REST API that can be called (to allow running this example self-contained)


# How To Run

<a href=""http://www.youtube.com/watch?feature=player_embedded&v=QUB0dSBBMPM"" target=""_blank""><img src=""http://img.youtube.com/vi/QUB0dSBBMPM/0.jpg"" alt=""Walkthrough"" width=""240"" height=""180"" border=""10"" /></a>

## Create Camunda Platform 8 Cluster

The easiest way to try out Camunda is to create a cluster in the SaaS environment:

* Login to https://camunda.io/ (you can create an account on the fly)
* Create a new cluster
* Create a new set of API client credentials
* Copy the client credentials into `src/main/resources/application.properties`


## Run Spring Boot Java Application

The application will deploy the process model during startup

`mvn package exec:java`


## Play

You can easily use the application by requesting a new customer onboarding posting a PUT REST request to 

`curl -X PUT http://localhost:8080/customer`

You can now see the process instance in Camunda Operate - linked via the Cloud Console.

You can work on the user task using Camunda Tasklist, also linked via the Cloud Console.



# Extended Process

There is also an extended process model that adds some more tasks in the process: 

![Customer Onboarding](docs/customer-onboarding-extended.png)

You can find that in another repository on GitHub: https://github.com/berndruecker/customer-onboarding-camundacloud-springboot-extended"
bezkoder/spring-boot-login-mongodb,master,35,27,2021-12-17T04:13:01Z,119,0,"Spring Boot & MongoDB Login and Registration example with JWT, Spring Security, Spring Data MongoDB",authentication authorization cookie http-cookies jwt jwt-auth jwt-authentication jwt-token login mongodb mongodb-database registration spring spring-boot spring-security spring-security-jwt token-based-authentication,"# Spring Boot Login and Registration example with MongoDB

Build a Spring Boot Auth with HttpOnly Cookie, JWT, Spring Security and Spring Data MongoDB. You'll know:
- Appropriate Flow for User Login and Registration with JWT
- Spring Boot Rest API Architecture with Spring Security
- How to configure Spring Security to work with JWT
- How to define Data Models and association for User Login and Registration
- Way to get and generate Cookies for Token
- Way to use Spring Data MongoDB to interact with MongoDB Database

## User Registration, Login and Authorization process.

![spring-boot-mongodb-login-example-flow](spring-boot-mongodb-login-example-flow.png)

## Spring Boot Rest API Architecture with Spring Security
You can have an overview of our Spring Boot Server with the diagram below:

![spring-boot-mongodb-login-example-architecture](spring-boot-mongodb-login-example-architecture.png)

For more detail, please visit:
> [Spring Boot Login and Registration example with MongoDB](https://www.bezkoder.com/spring-boot-mongodb-login-example/)

Working with Front-end:
> [Angular 12](https://www.bezkoder.com/angular-12-jwt-auth-httponly-cookie/) / [Angular 13](https://www.bezkoder.com/angular-13-jwt-auth-httponly-cookie/) / [Angular 14](https://www.bezkoder.com/angular-14-jwt-auth/) / [Angular 15](https://www.bezkoder.com/angular-15-jwt-auth/) / [Angular 16](https://www.bezkoder.com/angular-16-jwt-auth/) / [Angular 17](https://www.bezkoder.com/angular-17-jwt-auth/)

> [React](https://www.bezkoder.com/react-login-example-jwt-hooks/) / [React Redux](https://www.bezkoder.com/redux-toolkit-auth/)

More Practice:
> [Spring Boot with MongoDB CRUD example using Spring Data](https://www.bezkoder.com/spring-boot-mongodb-crud/)

> [Spring Boot MongoDB Pagination & Filter example](https://www.bezkoder.com/spring-boot-mongodb-pagination/)

> [Spring Boot + GraphQL + MongoDB example](https://www.bezkoder.com/spring-boot-graphql-mongodb-example-graphql-java/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Rest Controller Unit Test with @WebMvcTest](https://www.bezkoder.com/spring-boot-webmvctest/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Fullstack:
> [Vue.js + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-vue-mongodb/)

> [Angular 8 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-spring-boot-mongodb/)

> [Angular 10 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-10-spring-boot-mongodb/)

> [Angular 11 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-11-spring-boot-mongodb/)

> [Angular 12 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-12-spring-boot-mongodb/)

> [Angular 13 + Spring Boot + MongoDB example](https://www.bezkoder.com/angular-13-spring-boot-mongodb/)

> [Angular 14 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-14-mongodb/)

> [Angular 15 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-15-mongodb/)

> [Angular 16 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-16-mongodb/)

> [Angular 17 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-17-mongodb/)

> [React + Spring Boot + MongoDB example](https://www.bezkoder.com/react-spring-boot-mongodb/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://www.bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React with Spring Boot Rest API](https://www.bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue with Spring Boot Rest API](https://www.bezkoder.com/integrate-vue-spring-boot/)

## Run Spring Boot application
```
mvn spring-boot:run
```
"
mouse0w0/forge-mixin-example,1.12.2-14.23.5.2860,104,17,2019-11-15T06:43:44Z,48340,0,An example for using Mixin in Minecraft Forge 1.12.2 & 1.8.9,minecraft minecraft-forge minecraft-forge-mod minecraft-mod mixin-framework mixins,"# forge-mixin-example
An example for using Mixin in Minecraft Forge
"
aws-samples/aws-quarkus-demo,main,71,24,2020-01-17T23:12:15Z,1619,1,Quarkus example projects for Amazon ECS and Amazon EKS with AWS Fargate and AWS Lambda,amazon-ecs aws-fargate aws-lambda cdk eks quarkus quarkusio sam,"# Quarkus example projects for Amazon ECS with AWS Fargate, Amazon EKS with AWS Fargate, and AWS Lambda

This repository contains different examples how [Quarkus](https://quarkus.io) can be used in combination with different AWS services:

* [Amazon ECS](https://aws.amazon.com/ecs/) with [AWS Fargate](https://aws.amazon.com/fargate/)
* [Amazon EKS](https://aws.amazon.com/eks/) with [AWS Fargate](https://aws.amazon.com/fargate/)
* [AWS Lambda](https://aws.amazon.com/lambda/)

Quarkus is ""`A Kubernetes Native Java stack tailored for OpenJDK HotSpot and GraalVM, crafted from the best of breed Java libraries and standards.`""

In the examples in this repository, two different approaches have been used: a JVM based built (with an Uber-Jar) and a native-image that is created using SubstrateVM. 

For the [containers example](fargate) we use Amazon ECS and Amazon EKS with AWS Fargate as base infrastructure which is created using [AWS CDK](https://github.com/aws/aws-cdk). AWS Fargate is a technology that provides on-demand, right-sized compute capacity for containers; this way you no longer have to provision, configure, or scale groups of virtual machines to run containers.

The [second example](lambda) uses AWS Lambda and [AWS SAM](https://github.com/awslabs/serverless-application-model). SAM is an open-source framework for building serverless applications. It provides shorthand syntax to express functions, APIs, databases, and event source mappings.

## Contributing
Please create a new GitHub issue for any feature requests, bugs, or documentation improvements.

Where possible, please also submit a pull request for the change.
"
fqdeng/algorithm,master,32,4,2020-01-11T14:47:06Z,110,1,leetcode some example code,,"# Java常见面试算法考试大全

## 如何使用本仓库
* 我会在README里面写总结跟一些技巧 大量的细节跟注释都在代码附近，遵从一个知识离代码最近的原则
* 包名包含了问题的名字，所有的类都是Solution 兼容leetcode，通常一个包下 只有一个Solution类
* 建议clone下来配合IDEA跟README食用

## 面试算法的心得体会

* 最近看了很多题解深感国内大厂受硅谷白板编程之风所害，
纷纷搞起了算法面试题，在这里分享一些我做题的经验，
先声明我自己也是一个菜鸡，我个人的算法能力局限于 二分查找 快速排序 图搜索 生成树 skip-list 等简易中等难度的范畴，
仅能应付常规面试题。

## 为应付算法面试而应该达到的目标

* 在面试3-5年的Java开发岗位，算法面试可能大多着重于对基础数据结构 
ArrayList LinkedList Stack Queue Map 的应用跟原理的掌握，这个我不推荐大家去读JDK的源代码，
里面具体的实现 其实涉及到生产实践中大量的改进，细节十分多，例如JDK8的HashMap 在达到8个hash冲突链表后会转成红黑树，
而在理论学习的阶段中，应该了解除 头接链表法解决hash冲突 其它解决hash冲突的方式，
这里我推荐大家阅读 <<算法>> 第四版，里面有对基础的数据结构算法有详细的介绍，
这本书着重于应用跟理解，不像算法导论大篇幅的描述算法的数学证明。
从工程师的角度来讲，工程师在掌握算法的原理以及实现的思想后，能够熟练运用这些工具解决问题即可，
至于在数学的基础上对算法做出正确性的推导，我觉得并不是一个工程师应该所必须掌握的能力。

* leetcode应偏向中等跟简单难度的题目，这些题目出现的概率比较大，应该尽量把这些题目都覆盖掉。

* 待补充

## 基本常识跟一些小的技巧

* 了解基本的算法复杂度分析，了解O(N) O(N^2) O(LogN) 等复杂度

* 递归不好写，容易写错， 必须要掌握写对递归的三要素  1.递归一定要有一个终结条件，例如dfs搜索，必然会有一个节点其子节点为空，此时就是递归调用的出口 2.每一次递归之后，问题的解空间是在不断缩小的 3.父调用的解空间不能与其子调用的问题重叠 （这个很难文字解释清楚，后续可能会做视频）

* 二分搜索有模板，可以背下来，如果不确定，可以把目标值跟 mid low指针上的元素都比较一下

* 一些题目其实是有一固定解题套路的，例如在你掌握一个深度搜索 广度搜索的模板之后，
可以通过这个模板来解决大量图相关的问题，当然可能在这上面可能又涉及到减枝 用HashMap去重等操作。

* 很多算法都是从朴素算法出发演化来的，例如KMP求子字符串，同样时间复杂度的RK求字符串，也都是根据朴素的双重循环比对
字符串是否相等演化而来，在学习任何算法前，可以先了解其相关朴素算法的实现，可以加深对算法数据结构的认识

* 手写代码跟白板代码，一定要着重于可理解性，一个著名的观点是代码是写给人看的，顺便让机器执行一下，在算法面试中，如果
面试官对 空间复杂度 时间复杂度没有特殊要求，应该尽量选最好解释且最容易实现的方式去写，如果你写的代码不能通过简单的test case证明其正确性，
那么面试可能会大打折扣，其实短短几十分钟的时间，很难让你写出一个炫技的实现。

* 无论任何时候先处理dirty-case，就是防御式编程，不相信任何人提交参数的正确性，这种编程思维会让你受益终身。

* 通常应该写一个问题规模比较小的test-case验证思路

* 待补充


## 常见的套路模板

* 算法题的解答，其实要在白板编程时写出正确的代码，最好结合算法的思想去背诵一些模板，

* 二分查找模板
```java
public class BinarySearch { //二分查找模板
    public int search(int[] nums, int target) {
        int left = 0;
        int right = nums.length - 1;
        while (left <= right) {
            int mid = left + ((right - left) >> 1);
            if (nums[mid] == target){ 
                return mid;
            }
            // 如果你面试记不住 可以顺便比较一下 if nums[low] == target
            else if (nums[mid] > target) {
                right = mid - 1;
            } else {
                left = mid + 1;
            }
        }
        return -1;
    }
}
//
//循环条件： left <= right
//中间位置计算： mid = left + ((right -left) >> 1)
//左边界更新：left = mid + 1
//右边界更新： right = mid - 1
//返回值： mid / -1
```

* bfs广度搜索优先模板

```java
    
public class Solution {

    class TreeNode {
        public int val;

        public TreeNode(int val) {
            this.val = val;
        }

        public TreeNode left;

        public TreeNode right;
    }

    //           0               <- 第一次从队列里面取到0  然后把子节点1放回去
    //         /   \
    //        1     null         <- 第二次从队列里面取到1 然后把子节点 3 4 放回去
    //      /  \
    //     3   4                 <- 第三次从队列里面取到3，4 因为其没有子节点 所以队列为空 返回 得到count = 3
    //   null -> layer   
    // 这里其实思路很简单，因为bfs是层序遍历，每次针对队列的循环，都是取得同层级别的节点，除开二叉树 多叉树亦是如此


    //求二叉树的最大层数 算是bfs模板题
    public int calculateBinaryTreeLayer(TreeNode node) {
        if (node == null) {
            return 0;
        }
        //不管怎么样通常bfs是要进队的
        Queue<TreeNode> queue = new LinkedList<>();
        queue.add(node);
        int count = 0;

        while (!queue.isEmpty()) {
            List<TreeNode> polls = new ArrayList<>();
            //这个是取出当前这一层所有的左右节点 实际上针对多叉树 其思想也是一样
            while (!queue.isEmpty()) {
                polls.add(queue.poll());
            }
            
            //把所有节点的子节点再塞回去
            polls.forEach(poll -> {
                if (poll.right != null) {
                    queue.add(poll.right);
                }
                if (poll.left != null) {
                    queue.add(poll.left);
                }
            });
            
            //计数+1
            count++;
        }
        return count;
    }

    /**
     * not full binary tree
     */
    @Test
    public void testCalculateBinaryTreeTestCase2() {
        
        TreeNode top = new TreeNode(0);
        top.left = new TreeNode(1);
        top.right = new TreeNode(2);
        top.left.left = new TreeNode(3);
        top.left.right = new TreeNode(4);
        Assert.assertEquals(3, calculateBinaryTreeLayer(top));
    }

    /**
     * full binary tree
     */
    @Test
    public void testCalculateBinaryTreeTestCase1() {
        //           0
        //         /   \
        //        1     2
        //      /  \   /  \
        //     3   4   5   6
        //   null -> layer

        TreeNode top = new TreeNode(0);
        top.left = new TreeNode(1);
        top.right = new TreeNode(2);
        top.left.left = new TreeNode(3);
        top.left.right = new TreeNode(4);
        top.right.left = new TreeNode(5);
        top.right.right = new TreeNode(6);
        Assert.assertEquals(3, calculateBinaryTreeLayer(top));
    }
}

```

## 待续...


"
inovex/tango-ar-navigation-example,master,40,21,2016-05-02T09:28:09Z,2024,1,Small example implementation of an augmented reality path finding navigation using Project Tango,,"# Project Tango AR Navigation Example

This is a small example implementation of an augmented reality path 
finding navigation using Project Tango. 

* walkable floor plan is tracked inside a [quadtree](https://de.wikipedia.org/wiki/Quadtree)
* navigation through the quadtree using [A*](https://de.wikipedia.org/wiki/A*-Algorithmus) with euclidean heuristic
* the floor plan is shown in a top view and can be rotated and scaled with multitouch gestures


![Screenshot](screenshot.png)

 
### Development

* Missing assets can be installed by `./gradlew installAssets`
* This project still depends on the android gradle plugin `1.5.0` because to the missing sdkmanager plugin release
"
crctraining/customers-accounts-and-money-transfers,master,29,24,2016-10-07T20:59:28Z,248,0,One of the example applications used in Chris Richardson's microservices training class,,"# Microservices application: Customers, accounts and money transfers

This is the source code for a simple banking application.
The application architecture is based on [microservices](http://microservices.io/patterns/microservices.html), [Event Sourcing](http://microservices.io/patterns/data/event-sourcing.html) and [CQRS](http://microservices.io/patterns/data/cqrs.html).
It is built using Spring Cloud, Spring Boot and the [Eventuate platform](http://eventuate.io/).
The application is used in hands-on labs that are part of a [microservices services class](http://www.chrisrichardson.net/training.html) that is taught by [Chris Richardson](http://www.chrisrichardson.net/about.html).
"
DrFair/ExampleMod,master,28,6,2022-06-23T19:34:49Z,129,0,An example mod for Necesse.,,"An example mod for Necesse.

Check out the [modding wiki page](https://necessewiki.com/Modding) for more."
jbossdemocentral/brms-coolstore-demo,master,60,64,2012-12-21T11:06:39Z,146350,3,"Retail online web shopping cart example, the Cool Store demo leverages JBoss BRMS, JBoss Developer Studio, and Vaadin UI framework.",,"JBoss BRMS Suite Cool Store Demo
================================
This is a retail web store demo where you will find rules, decision tables, events, and a ruleflow
that is leveraged by a web application. The web application is a WAR built using the JBoss BRMS
generated project as a dependency, providing an example project showing how developers can focus on the
application code while the business analysts can focus on rules, events, and ruleflows in the
JBoss BRMS product web based dashboard.

This demo is self contained, it uses a custom maven settings to deploy all built JBoss BRMS knowledge artifacts
into an external maven repository (not your local repository), in /tmp/maven-repo.

There are four options available to you for using this demo; local, Docker, Openshift Online and Red Hat CDK OpenShift Enterprise.

Software
--------
The following software is required to run this demo:
- [JBoss EAP 7.0 installer](https://developers.redhat.com/download-manager/file/jboss-eap-7.0.0-installer.jar)
- [JBoss BRMS 6.4.0.GA deployable for EAP 7](https://developers.redhat.com/download-manager/content/origin/files/sha256/14/148eb9be40833d5da00bb6108cbed1852924135d25ceb6c601c62ba43f99f372/jboss-brms-6.4.0.GA-deployable-eap7.x.zip)
- Git client
- Maven 3.2+
- [7-Zip](http://www.7-zip.org/download.html) (Windows only): to overcome the Windows 260 character path length limit, we need 7-Zip to unzip the BRMS deployable.


Option 1 - Install on your machine
----------------------------------
1. [Download and unzip.](https://github.com/jbossdemocentral/brms-coolstore-demo/archive/master.zip)

2. Add products to installs directory.

3. Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges.

4. Start JBoss BRMS Server by running ./target/jboss-eap-7.0/bin/standalone.sh

5. Login to http://localhost:8080/business-central

    ```
    - login for admin and analyst roles (u:brmsAdmin / p:jbossbrms1!)
    ```

6. Build and deploy project. To do this, click on 'Authoring -> Project Authoring', this will open the 'Project Authoring' view. Click on the 'Open Project Editor' button, which opens the project editor. Now, click on the 'Build -> Build & Deploy' button, which can be found on the right-hand side of the project editor window.

7. Open shopping cart and demo away (http://localhost:8080/brms-coolstore-demo)


Option 2 - Install on OpenShift
-------------------------------
Running this demo in a container on any OpenShift Container Platform is [available at Red Hat Demo Central](https://github.com/redhatdemocentral/rhcs-coolstore-demo).


Option 3 - Run in Docker
-----------------------------------------
The following steps can be used to configure and run the demo in a container

1. [Download and unzip.](https://github.com/jbossdemocentral/brms-coolstore-demo/archive/master.zip)

2. Add the EAP installer and BPM Suite deployable to installs directory.

3. Run the 'init-docker.sh' or 'init-docker.ps1' file.

4. Start the container: `docker run -it -p 8080:8080 -p 9990:9990 jbossdemocentral/brms-coolstore-demo`

5. Login to http://&lt;DOCKER_HOST&gt;:8080/business-central

    ```
    - login for admin and analyst roles (u:brmsAdmin / p:jbossbrms1!)
    ```

6. Open shopping cart and demo away (http://&lt;DOCKER_HOST&gt;:8080/brms-coolstore-demo)

Additional information can be found in the jbossdemocentral container [developer repository](https://github.com/jbossdemocentral/docker-developer)



Notes
-----
The web application (shopping cart) is built during demo installation with a provided coolstore project jar version 2.0.0. When you
open the project you will find the version is also set to 2.0.0. You can run the web application as is, but if you build and deploy
a new version of 2.0.0 to your maven repository it will find duplicate rules. To demo you deploy a new version of the coolstore
project by bumping the version number on each build and deploy, noting the KieScanner picking up the new version within 10 seconds
of a new deployment. For example, initially start project, bump the version to 3.0.0, build and deploy, open web application and
watch KieScanner in server logs pick up the 3.0.0 version. Now change a shipping rule value in decision table, save, bump project
version to 4.0.0, build and deploy, watch for KieScanner picking up new 4.0.0 version, now web application on next run will use new
shipping values.


Supporting Articles
-------------------
- [JBoss BRMS Cool Store UI gets Vaadin facelift](http://www.schabell.org/2016/01/jboss-brms-coolstore-ui-vaadin-facelift.html)

- [7 Steps to Your First Rules with JBoss BRMS Starter Kit](http://www.schabell.org/2015/08/7-steps-first-rules-jboss-brms-starter-kit.html)

- [3 shockingly easy ways into JBoss rules, events, planning & BPM](http://www.schabell.org/2015/01/3-shockingly-easy-ways-into-jboss-brms-bpmsuite.html)

- [Jump Start Your Rules, Events, Planning and BPM Today](http://www.schabell.org/2014/12/jump-start-rules-events-planning-bpm-today.html)

- [4 Foolproof Tips Get You Started With JBoss BRMS 6.0.3](http://www.schabell.org/2014/10/4-foolproof-tips-get-started-jboss-brms-603.html)

- [How to Use Rules and Events to Drive JBoss BRMS Cool Store for xPaaS](http://www.schabell.org/2014/08/how-to-use-rules-events-drive-jboss-brms-coolstore-xpaas.html)

- [Red Hat JBoss BRMS - all product demos updated for version 6.0.2.GA release](http://www.schabell.org/2014/07/redhat-jboss-brms-product-demos-6.0.2-updated.html)

- [Red Hat JBoss BRMS 6 - Demo Cool Store Dynamic Rule Updates (video)] (http://www.schabell.org/2014/05/redhat-jboss-brms6-demo-coolstore-dynamic-rule-updates.html)

- [Red Hat JBoss BRMS 6 - The New Cool Store Demo] (http://www.schabell.org/2014/03/redhat-jboss-brms-v6-coolstore-demo.html)

- [JBoss BRMS Cool Store Demo updated with EAP 6.1.1] (http://www.schabell.org/2013/09/jboss-brms-coolstore-demo-updated-eap-611.html)

- [A shopping cart example in the Cool Store Demo] (http://www.schabell.org/2013/04/jboss-brms-coolstore-demo.html)

- [Cool Store installation video part I] (http://www.schabell.org/2013/05/jboss-brms-coolstore-demo-video-partI.html)

- [Cool Store CEP and Rules video part II] (http://www.schabell.org/2013/05/jboss-brms-coolstore-demo-video-partII.html)

- [Cool Store BPM and Decision Tables video part III] (http://www.schabell.org/2013/05/jboss-brms-coolstore-demo-video-partIII.html)


Released versions
-----------------
See the tagged releases for the following versions of the product:

- v3.8 JBoss BRMS 6.4.0.GA on JBoss EAP 7.0.0.GA with cool store installed and RH CDK on OSE Cloud install option.

- v3.7 JBoss BRMS 6.3.0 on JBoss EAP 6.4.7 with cool store installed and RH CDK on OSE Cloud install option.

- v3.6 JBoss BRMS 6.2.0-BZ-1299002 on JBoss EAP 6.4.4 with cool store installed and RH CDK on OSE Cloud install option.

- v3.5 JBoss BRMS 6.2.0-BZ-1299002 on JBoss EAP 6.4.4 with cool store installed.

- v3.4 JBoss BRMS 6.2.0, JBoss EAP 6.4.4 and OSE aligned containerization.

- v3.3 JBoss BRMS 6.2.0, JBoss EAP 6.4.4 and cool store installed, UI updated to Vaadin 7.6.0.

- v3.2 JBoss BRMS 6.2.0, JBoss EAP 6.4.4 and cool store installed, UI updated to Vaadin 7.

- v3.1 JBoss BRMS 6.2.0, JBoss EAP 6.4.4 and cool store installed.

- v3.0 JBoss BRMS 6.1.1 (patch update applied) with cool store installed and Albert Wong updates for JBDS project importing.

- v2.9 JBoss BRMS 6.1.1 (patch update applied) with cool store installed.

- v2.8 JBoss BRMS 6.1 with cool store installed.

- v2.7 JBoss BRMS 6.0.3 installer with cool store configured to scan external maven repository.

- v2.6 JBoss BRMS 6.0.3 installer with cool store updated so that project unit tests running again.

- v2.5 JBoss BRMS 6.0.3 with optional containerized installation.

- v2.4 moved to JBoss Demo Central, with updated windows init.bat support and one click install button.

- v2.3 JBoss BRMS 6.0.3 installer with cool store demo installed.

- v2.2 JBoss BPM Suite 6.0.2, JBoss EAP 6.1.1, cool store demo installed.

- v2.1 JBoss BPM Suite 6.0.1, JBoss EAP 6.1.1, cool store demo installed.

- v2.0 JBoss BPM Suite 6.0.0, JBoss EAP 6.1.1, cool store demo installed.

- v1.4 is BRMS 5.3.1 deployable, running on JBoss EAP 6.1.1, integrated BRMS maven repo into project so no longer need to add to
	personal settings configuration which fully automates project build.

- v1.3 is BRMS 5.3.1 deployable, running on JBoss EAP 6.1.1, and added Forge Laptop Sticker to store.

- v1.2 is BRMS 5.3.1 deployable, running on JBoss EAP 6.1, mavenized using JBoss repo.

- v1.1 new welcome screen and doc fixes.

- v1.0 is BRMS 5.3.1 deployable, running on JBoss EAP 6.

![Announcement Sign](https://github.com/jbossdemocentral/brms-coolstore-demo/blob/master/docs/demo-images/announce-sign.jpg?raw=true)

[![Video bpmPaaS CoolStore](https://github.com/jbossdemocentral/brms-coolstore-demo/blob/master/docs/demo-images/video-brms-coolstore-demo.png?raw=true)](https://vimeo.com/ericschabell/brms-coolstore-demo)

[![Video bpmPaaS CoolStore](https://github.com/jbossdemocentral/brms-coolstore-demo/blob/master/docs/demo-images/video-bpmpaas-coolstore.png?raw=true)](http://vimeo.com/ericschabell/bpmpaas-brms-coolstore-demo)

![Decision Table](https://github.com/jbossdemocentral/brms-coolstore-demo/blob/master/docs/demo-images/coolstore-decision-table.png?raw=true)

![Domain Model](https://github.com/jbossdemocentral/brms-coolstore-demo/blob/master/docs/demo-images/coolstore-model.png?raw=true)
"
kbastani/cloud-native-microservice-strangler-example,master,27,33,2016-08-21T17:09:16Z,5868,3,Spring Cloud example of a cloud native strangler pattern for integrating microservices with legacy applications,,"# Microservices: Cloud Native Legacy Strangler Example

This reference application is a Spring Cloud example of implementing a cloud-native [Strangler Pattern](http://www.martinfowler.com/bliki/StranglerApplication.html) using microservices. The project is intended to demonstrate techniques for integrating a microservice architecture with legacy applications in an existing SOA. This reference architecture implements a hybrid cloud architecture that uses best practices for developing _Netflix-like_ microservices using Spring Cloud.

* Cloud Native Microservices
  * Uses best practices for cloud native applications
  * OAuth2 User Authentication
  * Netflix OSS / Spring Cloud Netflix
  * Configuration Server
  * Service Discovery
  * Circuit Breakers
  * API Gateway / Micro-proxy
* Legacy Edge Gateway
  * Legacy application integration layer
  * Adapter for legacy systems to consume microservices
* Lazy Migration of Legacy Data
  * Microservice facades integrate domain data from legacy applications
  * Database records are siphoned away from legacy databases
  * Datasource routing enables legacy systems to use microservices as the system of record
* Strangler Event Architecture
  * Asset capture strategy uses events to guarantee single system of record for resources
  * Durable mirroring of updates back to legacy system

## Architecture Diagram

![Example Cloud Native Strangler Microservice Architecture](http://i.imgur.com/ZhuwpbZ.png)

## Overview

This reference application is based on both common and novel design patterns for building a cloud-native hybrid architecture with both legacy applications and microservices. The reference project includes the following applications.

* Legacy Applications
  * Customer Service
  * Legacy Edge Service
* Microservices
  * Discovery Service
  * Edge Service
  * Config Service
  * User Service
  * Profile Service
  * Profile Web

## Legacy Database Strangulation

When building microservices, the general approach is to take existing monoliths and to decompose their components into microservices. Instead of migrating all legacy applications at once, we can allow an organic process of decomposition to drive the birth of new cloud-native applications that strangle data away from shared databases used by legacy applications. The _cloud-native strangler pattern_ focuses on the complete replacement of a monolith's database access over a period of time.

In this approach microservices will be transitioned to become the system of record for domain data used by strangled legacy applications. The process of performing an on-demand migration of data out of a shared database will require that only one system of record exists at any one time. To solve this, a _Legacy Edge_ application acts as an API gateway to allow legacy applications to talk to new microservices.
 
## Usage

There are two ways to run the reference application, with either Docker Compose or Cloud Foundry, the latter of which can be installed on a development machine using [PCF Dev](https://docs.pivotal.io/pcf-dev/). Since the distributed application is designed to be cloud-native, there is a lot to be gained from understanding how to deploy the example using Cloud Foundry.

### Docker Compose

To run the example using Docker Compose, a `run.sh` script is provided which will orchestrate the startup of each application. Since the example will run 8 applications and multiple backing services, it's necessary to have at least 9GB of memory allocated to Docker.

WARNING: The `run.sh` script is designed to use Docker Machine, so if you're using Docker for Mac, you'll need to modify the `run.sh` script by setting `DOCKER_IP` to `localhost`.

### Cloud Foundry

To run the example using Cloud Foundry, a `deploy.sh` script is provided which will orchestrate the deployment of each application to a simulated cloud-native environment. If you have enough resources available, you can deploy the example on [Pivotal Web Service](http://run.pivotal.io). If you're new to Cloud Foundry, it's highly recommended that you go with the PCF Dev approach, which you can install by following the directions at https://docs.pivotal.io/pcf-dev/.

When you have a CF environment to deploy the example, go ahead and run the `deploy.sh` script in the parent directory of the project. The bash script is commented enough for most to understand the steps of the deployment. Each Cloud Foundry deployment manifest is located in the directory of the application in example project, named `manifest.yml`. The deployment process will deploy the Spring Cloud backing services first, and afterward, each microservice will be deployed one by one until each application is running.

## License

This project is an open source product licensed under GPLv3.
"
FreedomChuks/NavigationUiExample-,master,27,6,2019-05-07T12:13:17Z,185,0,example with working with navigation Components,,"# NavigationUiExample-
It contains Android navigation component examples which show how to use navigation component in android app with fragments and action as destinations. For details about android navigation component and this project explanation see https://medium.com/@freedom.chuks7/how-to-use-jet-pack-components-bottomnavigationview-with-navigation-ui-19fb120e3fb9


![Web 1920 – 1](https://user-images.githubusercontent.com/31355965/57305146-6ea11800-7095-11e9-9d01-51bfb40ae337.png)


"
dbleicher/recyclerview-grid-quickreturn,master,84,28,2014-11-11T16:58:28Z,231,1,An example of implementing QuickReturn on a RecyclerView using a StaggeredGridLayoutManager to display CardViews inside a SwipeRefreshLayout,,"#recyclerview-grid-quickreturn

An example of implementing QuickReturn on a RecyclerView 
using a StaggeredGridLayoutManager to display CardViews inside a SwipeRefreshLayout.

This is an example project that shows one approach (probably not the best one!) of 
implementing the QuickReturn pattern with a RecyclerView that uses the
StaggeredGridLayoutManager.  For grins, the whole thing also supports Pull-to-Refresh
using a SwipeRefreshLayout. By the way, the cells within the layout are CardViews, and use 
the `card_view:cardUseCompatPadding=""true""` attribute to display properly on Lollipop.

The idea is that the QR view should not cover the top items in the RV.  This is now accomplished with a custom
(but trivial) ItemDecoration.  As a result, the adapter and layoutmanager are plain vanilla.  I'm sure there's
a better way, so if you find it, please explain it to me!  :-)

Here's what it looks like with expandable cells:  https://www.youtube.com/watch?v=ulf4v3Qzn4o

Here's an older animation:

![rsqr](https://cloud.githubusercontent.com/assets/3764409/4998140/88d948ee-69a3-11e4-95ba-076da0a6ad95.gif)

##Changes
1. (2015-1-2) Added TargetedSwipeRefreshLayout (TSRL) to permit multiple views within the SwipeRefreshLayout.
1. (2015-1-2) Removed topview detection from onScrollListener (no longer needed with TSRL).
2. (2014-11-14) Modified the spacing hack to use an ItemDecorator (cleaner approach).

##TODO
1. (2014-11-14) ~~It's been suggested that I look into using ItemDecoration instead of adjusting cell margins during onBind.~~
2. (2015-03-18) Fixed using recyclerview-v7 R22 ~~Need to address issue of inserting items at top of grid.~~


##License

```
Copyright 2014-2015 David Bleicher

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```
"
berndruecker/flowing-retail-old,master,64,18,2016-12-15T18:44:18Z,953,0,REPLACED BY MORE CURRENT VRSION OF THIS EXAMPLE: https://github.com/berndruecker/flowing-retail,,"# Flowing retail sample application

This sample application showcases *concepts and alternatives* to implement

* a simple order application

in the context of

* Domain Driven Design (DDD)
* Event Driven Architecture (EDA)
* Microservices (µS)

Key facts:

* Written in Java
* As simple as possible to show concepts, not build for production usage. Hint: we know some parts in the code skip well known best practices and patterns, but we focussed on making the code easy to understand. For example we prefer to duplicate code, if this means you have to read one class less to understand what a component is doing.

# Links

* Introduction blog post by Bernd Rücker: https://blog.bernd-ruecker.com/flowing-retail-demonstrating-aspects-of-microservices-events-and-their-flow-with-concrete-source-7f3abdd40e53

# Overview and architecture

Flowing retail simulates a very easy order processing system. The business logic is separated into the following microservices:

![Microservices](docs/services.png)

* The core domains communicate via messages with each other.
* Messages might contain *events* or *commands*.

This is the stable nucleus for flowing retail.

## Alternatives

Now there are a couple of options you can choose of when running / inspecting the example. 

### Channel technology

You can choose between:

* [Apache Kafka](http://kafka.apache.org/) as event bus (option ```kafka```, *default*).
* [RabbitMQ](https://www.rabbitmq.com/) as AMQP messaging system (option ```rabbit```).

### Long running processes

In order to support [long running processes](xxx) there are multiple options, which are very interessting to compare:

* Domain entities store state (option ```entity```)
* [Camunda](http://camunda.org/) workflow engine orchestrates using BPMN models (option ```camunda```, *default*)
* [Camunda](http://camunda.org/) workflow engine orchestrates using a technical DSL (option ```camunda-dsl```)

Note that every component does its own parts of the overall order process. As an example this is illustrated using BPMN and showing the Order and Payment Service with their processes:

![Events and Commands](docs/bpmn.png)


# Run the application

* Download or clone the source code
* Run a full maven build

```
mvn install
```

* Start all components by in one Java process
    * Channel (e.g. Kafka which also requires Zookeeper)
    * All microservices

```
mvn -f starter exec:java
```

If you want to select options you can also do so:

```
mvn -f starter exec:java -Dexec.args=""rabbit camunda-dsl""
```

You can also import the projects into your favorite IDE and start the following class yourself:

```
starter/io.flowing.retail.command.SimpleStarter
```

* Now you can place an order via [http://localhost:8085](http://localhost:8085)
* You can inspect all events going on via [http://localhost:8086](http://localhost:8086)

# TODO ZONE

## Using Kafka

* Can be started built in, but you can also install and run yourself
* Port = default = ## 

When installed yourself, create topic *""flowing-retail""*

```
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic flowing-retail
```

You can query all topics by: 

```
kafka-topics.sh --list --zookeeper localhost:2181
```

## Using RabbitMQ

* Must be installed and started yourself
* Port = default = ##

## Using Camunda

You can inspect what's going on using Cockpit:

* Download Camunda Distribution of your choice
* Configure Datasource to connect to: jdbc:h2:tcp://localhost:8092/mem:camunda
    * In Tomcat distribution this is configured in server/apache-tomcat-8.0.24/conf/server.xml
    * In Wildfly distribution this is configred in server/wildfly-10.1.0.Final/standalone/configuration/standalone.xml
* Best: Do not start job executor
* Run it and you can use cockpit normally

If you want to restart microservices and keep cockpit running, you have to make sure your JDBC connection pool destroys stale connections. In Wildfly you can add a valdidation to your datasource, so the config will look like this:

```
<datasource jndi-name=""java:jboss/datasources/ProcessEngine"" pool-name=""ProcessEngine"" ...>
    <connection-url>jdbc:h2:tcp://localhost:8092/mem:camunda</connection-url>
    <driver>h2</driver>
    <transaction-isolation>TRANSACTION_READ_COMMITTED</transaction-isolation>
    <security>
        <user-name>sa</user-name>
        <password>sa</password>
    </security>
    <validation>
        <check-valid-connection-sql>select 1</check-valid-connection-sql>
        <validate-on-match>false</validate-on-match>
    </validation>
</datasource>
```
"
humank/ddd-practitioners-ref,main,312,88,2018-05-05T11:24:53Z,59194,6,"EventStorming workshop, this is a hands-on workshop. Contains such topics: DDD, Event storming, Specification by example. Including the AWS product : Serverless Lambda , DynamoDB, Fargate, CloudWatch.",aws container ddd ecs eventbridge eventstorming fargate lambda microservices serverless,"# Domain-Driven Design Practitioners Reference

## Under Construction - 

**Appreciate having your support on building this workshop, hope this workshop is useful & meaningful for you. In order to well organize all of the contents for DDD practitioners reference, the workshop will be refactored to cover wider topics with a more complex business scenario sample. Plan to release new content before the end of 2021, stay tuned.**

In this ddd-practitioners-reference, you will learn more than classic Domain-Driven Design Strategic design and Tactical design patterns. DDD is good to approach decision makers to align business goals among diversity stakeholders in different BU.

When learning a series of methodology would always bored ourself and lot passion on the unlimited learning journey, so i'll walk you through a bsuiness case to practice the following methodologies/approaches to get familiar in using DDD to design solutions.

So, this guide will cover below topics whaich are what I learned from WW communities (ddd_eu, virtualddd) and awesome ddd-practitioners experience.

Outline:

- A sample business story - Trip Service
- Awaren businesss context by Wardley Maps
- Kowing your key stakeholders - Impcat Mapping
- EventStorming
- Bounded Context Canvas - founded by Nick Tune
- Aggregate Design Canvas (*) - founded by Kacper Gunia
- Aggregate Canvas (*) - founded by Arthur Chang
- Example Mapping
- Specification by Example
- Implement DDD Tactical pattern in Clean Architecture with Spring boot framework - refer to awesome-trip
- Integrate with AWS cloud native offerings
-----

## Table of Contents
- [00 - Event Storming](#eventstorming)
  - [What is Event Storming?](#what-is-event-storming)
  - [Whom is it for?](#whom-is-it-for)
  - [Event Storming Terms](#event-storming-terms)
  - [Event Storming Benefits](#event-storming-benefits)
  - [Event Storming Applications](#event-storming-applications)
- [01 - Hands-on: Events exploring](docs/01-hands-on-events-exploring/README.md)
- [02 - Cafe business scenario](docs/02-coffee-shop-scenario/README.md)
- [03 - Roles, Commands, and Events Mapping](docs/03-roles-commands-events-mapping/README.md)
  - [Key Business events in the coffeeshop](docs/03-roles-commands-events-mapping/README.md#key-business-events-in-the-coffeeshop)
  - [Commands and Events mapping](docs/03-roles-commands-events-mapping/README.md#commands-and-events-mapping)
  - [Roles](docs/03-roles-commands-events-mapping/README.md#roles)
  - [Exceptions or risky events](docs/03-roles-commands-events-mapping/README.md#exceptions-or-risky-events)
  - [Re-think solutions to serve risky events](docs/03-roles-commands-events-mapping/README.md#re-think-solutions-to-serve-risky-events)
  - [Aggregate](docs/03-roles-commands-events-mapping/README.md#aggregate)
  - [Bounded Context forming up](docs/03-roles-commands-events-mapping/README.md#bounded-context-forming-up)
- [04 - Modeling and Development](docs/04-modeling-and-development/README.md)
  - [Specification by Example](docs/04-modeling-and-development/README.md#specification-by-example)
  - [TDD within Unit Test environment](docs/04-modeling-and-development/README.md#tdd-within-unit-test-environment)
  - [Generate unit test code skeleton](docs/04-modeling-and-development/README.md#generate-unit-test-code-skeleton)
  - [Implement Domain Model from code Skeleton](docs/04-modeling-and-development/README.md#implement-domain-model-from-code-skeleton)
  - [Design each Microservices in Port-adapter concept](docs/04-modeling-and-development/README.md#design-each-microservices-in-port-adapter-concept)
- [05 - Deploy Applications by AWS CDK](docs/05-deploy-applications-by-cdk/README.md) 
<!---
- [05 - Domain Driven Design Tactical design pattern guidance](05-ddd-tactical-design-pattern)
- [06 - Actual Implementation](06-actual-implementation)
- [07 - Infrastructure as Code by CDK](07-iaac-cdk)
- [08 - Deploy Serverless application](08-deploy-serverless-app)
- [09 - Deploy Containerized application](09-deploy-containerized-app)
- [10 - Build up CI/CD pipeline](10-build-up-cicd-pipeline)
--->

# Event Storming
![image](docs/img/problemsolving.png)

## What is Event Storming?
Event Storming is a **rapid**, **lightweight**, and often under-appreciated group modeling technique that is **intense**, **fun**, and **useful** to **accelerate** project teams. It is typically offered as an interactive **workshop** and it is a synthesis of facilitated group learning practices from Gamestorming, leveraging on the principles of Domain Driven Design (DDD).

You can apply it practically on any technical or business domain, especially those that are large, complex, or both.

## Whom is it for?
Event Storming isn't limited to just for the software development team. In fact, it is recommend to invite all the stakeholders, such as developers, domain experts, business decision makers etc to join the Event Storming workshop to collect viewpoints from each participants.

## Event Storming Terms

![Event Storming](https://storage.googleapis.com/xebia-blog/1/2018/10/From-EventStorming-to-CoDDDing-New-frame-3.jpg)

> Reference from Kenny Bass - https://storage.googleapis.com/xebia-blog/1/2018/10/From-EventStorming-to-CoDDDing-New-frame-3.jpg

Take a look on this diagram, there are a few colored sticky notes with different intention:

* **Domain Events** (Orange sticky note) - Describes *what happened*. Represent facts that happened in a specific business context, written in past tense
* **Actions** aka Command (Blue sticky note) - Describes an *action* that caused the domain event. It is a request or intention, raised by a role or time or external system
* **Information** (Green sticky note) - Describes the *supporting information* required to help make a decision to raise a command
* **Consistent Business Rules** aka Aggregate (Yellow sticky note)
    * Groups of Events or Actions that represent a specific business capability
    * Has the responsibility to accept or fulfill the intention of command
    * Should be in small scope
    * And communicated by eventual consistency
* **Eventual Consistent Business rules** aka Policy (Lilac sticky note)
    * Represents a process or business rules. Can come from external regulation and restrictions e.g. account login success/fail process logic.

## Event Storming Benefits

Business requirements can be very complex. It is often hard to find a fluent way to help the Product Owner and Development teams to collaborate effectively. Event storming is designed to be **efficient** and **fun**. By bringing key stakeholder into the same room, the process becomes:

- **Efficient:** Everyone coming together in the same room can make decisions and sort out differences quickly. To create a comprehensive business domain model, what used to take many weeks of email, phone call or meeting exchanges can be reduced to a single workshop.

- **Simple:** Event Storming encourages the use of ""Ubiquitous language"" that both the technical and non-technical stakeholders can understand.

- **Fun:** Domain modeling is fun! Stakeholders get hands-on experience to domain modeling which everyone can participate and interact with each other. It also provides more opportunities to exchange ideas and improve mindsharing, from various perspective across multiple roles.

- **Effective:** Stakeholders are encouraged not to think about the data model, but about the business domain. This puts customers first and working backwards from there, achieves an outcome that is more relevant.

- **Insightful:** Event Storming generate conversations. This helps stakeholders to understand the entire business process better and help to have a more holistic view from various perspective.

## Event Storming Applications

There are many useful applications of Event Storming. The most obvious time to use event storming is at a project's inception, so the team can start with a common understanding of the domain model. Some other reasons include:
* Discovering complexity early on, finding missing concepts, understanding the business process;
* Modelling or solving a specific problem in detail;
* Learning how to model and think about modelling.

Event Storming can also help to identify key views for your user interface, which can jump start Site Mapping or Wireframing.

Let's get started with a quick example to demonstrate how to run a simple Event Storming.

[Next: 01 Hands-on Events Exploring >](docs/01-hands-on-events-exploring/README.md)
"
AlexZhukovich/MultipleRowLayoutsRecyclerView,master,29,17,2016-02-25T21:01:42Z,2138,1,This short example shows how to use different row layouts for RecyclerView,,"# MultipleRowLayoutsRecyclerView
This short example shows how to use different row layouts for RecyclerView

<img src=""https://github.com/AlexZhukovich/MultipleRowLayoutsRecyclerView/blob/master/screen/logo.png"" width=""720px"" height=""450px"" />

If you want to use different types of row layouts you must to implement next method in adapter:
```java
@Override
public int getItemViewType(int position) {
    ...
}
```

Article: http://alexzh.com/tutorials/multiple-row-layouts-using-recyclerview/
"
wx-chevalier/Java-Notes,master,32,14,2019-10-02T14:36:54Z,6240,22,:books: Java Notes & Examples. | 语法基础、数据结构、工程实践、设计模式、并发编程、JVM、Scala,clojure java,"[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![license: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey.svg)][license-url]

<!-- PROJECT LOGO -->
<br />
<p align=""center"">
  <a href=""https://github.com/wx-chevalier/Java-Notes"">
    <img src=""https://assets.ng-tech.icu/item/header.svg"" alt=""Logo"" style=""width: 100vw;height: 400px"" />
  </a>

  <p align=""center"">
    <a href=""https://ng-tech.icu/books/Java-Notes""><strong>在线阅读 >> </strong></a>
    <br />
    <br />
    <a href=""https://github.com/wx-chevalier"">代码案例</a>
    ·
       <a href=""https://github.com/wx-chevalier/Awesome-Lists"">参考资料</a>

  </p>
</p>

<!-- ABOUT THE PROJECT -->

# Java Series | Java 开发基础与工程实践

![题图](https://assets.ng-tech.icu/item/20230416205530.png)

Java 是由 Sun Microsystems 公司于 1995 年 5 月推出的高级程序设计语言，Java 当初诞生的时候，正是上世纪 90 年代末互联网兴起的时代，在企业应用开发中存在几个问题，一是以 IBM，SUN 和 HP 的 UNIX 服务器和大型机为主的异构环境，C/C++ 和其它语言编写的应用跨平台支持和移植比较困难，二是基于 CGI 和其它技术的网络应用从开发效率和功能性角度来看都不够理想，三是 C/C++在当时是主流编程语言，门槛高、易出错、对经验要求很高，而 Java 简单易学、安全可靠，并且一次编写到处运行，再加上 Applet、Servlet 和 JSP 技术，解决了这些痛点，满足了当时互联网程序设计和运维的要求，伴随着互联网的发展一下子就脱颖而出并长期占据主流地位。

在 CS 领域中，很少有技术能够与 Java 的影响相比肩；它在 Web 早期的创造帮助塑造了 Internet 的现代形式，包括客户端和服务器端。它的创新功能提高了编程艺术和科学水平，为计算机语言设计树立了新标准。围绕 Java 成长的具有前瞻性的文化确保 Java 可以保持生机盎然，并能适应计算领域中经常快速变化的变化。简而言之：Java 不仅是世界上最重要的计算机语言之一，而且是一种革命性的编程方式，并在此过程中改变了世界。尽管 Java 是一种经常与 Internet 编程相关的语言，但绝不限于此 Java 是一种功能强大的，功能齐全的通用编程语言。因此，如果您不熟悉编程，那么 Java 是一门优秀的学习语言。而且，要成为当今的专业程序员，就意味着可以使用 Java 进行编程，这一点非常重要。

任何一种编程语言如果要获得用户和开发者的认可，一定是要解决一些应用开发和运维的痛点的。Java 能够长盛不衰得益于在标准的统一和开放基础上不断的与时俱进。Java 除了是一种编程语言，也同时是一个运行时，为了能够在最广泛的平台和环境中运行，在诞生伊始就联合各个厂商和组织形成语言和虚拟机统一标准，并通过 TCK 对标准的具体实现进行认证，保障了来自于任何一个厂商的 JDK 的兼容性，使得 Java 没有出现如 UNIX 系统那样的问题。开放性是 Java 生命常青的另一个基石，Java 的演进一直由各个厂商和用户组成的社区来协调和驱动，遵从 JCP 的流程来讨论决定重大特性和问题，这一点保障了 Java 生态的发展壮大和活跃。社区和生态的活跃反过来又促进了 Java 的发展，Java 的一些特性和类库就是直接继承自社区的项目，比如 JDK 5 引入的 JSR 166 until.concurrent，JDK 8 引入的新 Java date 和 time API 等等。正在开发中的很多重要项目，比如 Amber、Valhalla、Loom 等等，也都是社区呼声很高的，并且在迭代中积极吸纳社区的意见和反馈。

![Java Platform Standard Edition](http://static.oschina.net/uploads/space/2015/0917/192918_c6O7_1434710.png)

# About

## Links

- https://crossoverjie.top/JCSprout/#/

## Copyright & More | 延伸阅读

笔者所有文章遵循[知识共享 署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议](https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh)，欢迎转载，尊重版权。您还可以前往 [NGTE Books](https://ng-tech.icu/books-gallery/) 主页浏览包含知识体系、编程语言、软件工程、模式与架构、Web 与大前端、服务端开发实践与工程架构、分布式基础架构、人工智能与深度学习、产品运营与创业等多类目的书籍列表：

[![NGTE Books](https://s2.ax1x.com/2020/01/18/19uXtI.png)](https://ng-tech.icu/books-gallery/)

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

[contributors-shield]: https://img.shields.io/github/contributors/wx-chevalier/Java-Notes.svg?style=flat-square
[contributors-url]: https://github.com/wx-chevalier/Java-Notes/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/wx-chevalier/Java-Notes.svg?style=flat-square
[forks-url]: https://github.com/wx-chevalier/Java-Notes/network/members
[stars-shield]: https://img.shields.io/github/stars/wx-chevalier/Java-Notes.svg?style=flat-square
[stars-url]: https://github.com/wx-chevalier/Java-Notes/stargazers
[issues-shield]: https://img.shields.io/github/issues/wx-chevalier/Java-Notes.svg?style=flat-square
[issues-url]: https://github.com/wx-chevalier/Java-Notes/issues
[license-shield]: https://img.shields.io/github/license/wx-chevalier/Java-Notes.svg?style=flat-square
[license-url]: https://github.com/wx-chevalier/Java-Notes/blob/master/LICENSE.txt
"
UniversalRobots/Universal_Robots_ExternalControl_URCap,master,57,15,2019-10-04T11:24:21Z,279,3,Example implementation of how to use ROS driver on-demand in a URCap.,ros ros-industrial urcaps,"# URCaps External Control
The External Control URCap is the user interface for the Universal Robots [ROS](https://github.com/UniversalRobots/Universal_Robots_ROS_Driver), [ROS2](https://github.com/UniversalRobots/Universal_Robots_ROS2_Driver) and [Isaac SDK](https://github.com/UniversalRobots/Universal_Robots_Isaac_Driver) driver, as well as the [Universal Robots Client Library](https://github.com/UniversalRobots/Universal_Robots_Client_Library) used by the drivers.

It supports the Universal Robots CB3 and e-Series robots.

## Prerequisites
As this URCap is using swing to implement the user interface, the URCap library in version 1.3.0 or
higher is required. Therefore the minimal PolyScope versions are 3.7 and 5.1.

## Usage
* In the _Installation_ tab of Polyscope:
	* Adjust the IP address of your robot in the _Installation_ tab of Polyscope (this step might be unnecessary in simulation). 
* On the remote PC:
	* Launch the suitable _launch_ file for UR3/UR5/UR10 and CB3/e-series.
* In the _Program_ tab of Polyscope:
	* Add this URcap to a program by selecting it from the side menu under the tab _URcap_.
	* Execute the program by pressing the _play_ button in the _Program_ tab of Polyscope.

### Multiple URCap nodes
To use this URCap node multiple times in a ur program, the control script is divided into two
scripts. After receiving the script, it is divided into a header part and a control loop part. The
header part consist of all the function deffinitions. The header is only inserted once in the 
program, while the control loop is inserted for each URCap node in the program tree.

To be able to distinguish between header and control loop, the header part of the script should be
encapsulated in:
```bash
# HEADER_BEGIN
Here goes the header code
# HEADER_END

# NODE_CONTROL_LOOP_BEGINS
Here goes the control loop code
# NODE_CONTROL_LOOP_ENDS
```
If its not possible to find either `# HEADER_BEGIN` or `# HEADER_END`, the script will not be
divided into two scripts and it will not be possible to have multiple URCap nodes in one program.

## Acknowledgment
Developed in collaboration between:

[<img height=""60"" alt=""Universal Robots A/S"" src=""doc/resources/ur_logo.jpg"">](https://www.universal-robots.com/) &nbsp; and &nbsp;
[<img height=""60"" alt=""FZI Research Center for Information Technology"" src=""doc/resources/fzi-logo_transparenz.png"">](https://www.fzi.de).

<!--
    ROSIN acknowledgement from the ROSIN press kit
    @ https://github.com/rosin-project/press_kit
-->

<a href=""http://rosin-project.eu"">
  <img src=""http://rosin-project.eu/wp-content/uploads/rosin_ack_logo_wide.png""
       alt=""rosin_logo"" height=""60"" >
</a>

Supported by ROSIN - ROS-Industrial Quality-Assured Robot Software Components.
More information: <a href=""http://rosin-project.eu"">rosin-project.eu</a>

<img src=""http://rosin-project.eu/wp-content/uploads/rosin_eu_flag.jpg""
     alt=""eu_flag"" height=""45"" align=""left"" >

This project has received funding from the European Union’s Horizon 2020
research and innovation programme under grant agreement no. 732287.
"
mat3e/3pigs-ddd,master,38,12,2020-09-04T21:56:59Z,995,0,DDD & Clean Architecture on the example of The Three Little Pigs,,"# _The Three Little Pigs_ with DDD and clean architecture

[My tech talk](https://github.com/mat3e/talks/tree/master/docs/3pigs), fairy tale
sources: [1](https://www.gillbooks.ie/AcuCustom/Sitename/DAM/101/WWSI_OM_0902.pdf), [2](http://www.hellokids.com/c_14958/reading-learning/stories-for-children/animal-stories-for-kids/the-three-little-pigs), [3](https://sacred-texts.com/neu/eng/eft/eft15.htm), [4](https://americanliterature.com/childrens-stories/the-three-little-pigs).

> Java, Groovy + Spock, Kotlin, Maven, Spring

The main focus should be on _The Three Little Pigs_, but to show an alternative, more pragmatic approach there is also
_Little Red Riding Hood_ module, utilizing package-private access more, close to what's presented
in [this great tech talk by Jakub Nabrdalik](https://www.youtube.com/watch?v=KrLFs6f2bOA).

## Web app

App starts as an ordinary web app for

```properties
spring.main.web-application-type=servlet
```

### _The Three Little Pigs_

Available operations:

1. Build house: `POST` `localhost:8080/houses`
   ```json
    {
        ""owner"": ""VERY_LAZY""
    }
    ```
   Possible values for `owner`:
    * `VERY_LAZY`
    * `LAZY`
    * `NOT_LAZY`
    * `NOT_LAZY_ANYMORE`
2. Verify the house state: `GET` `localhost:8080/houses/{id}`
3. Blow house down: `DELETE` `localhost:8080/houses/{id}`

There is a dedicated [Postman](https://www.postman.com/) collection with all these operations already
defined: `pigs3/adapters/src/main/resources/3Pigs.postman_collection.json`.

### _Little Red Riding Hood_

There is a dedicated [Postman](https://www.postman.com/) collection with all the operations ready to
use: `redhood/src/main/resources/RedHood.postman_collection.json`.

## Console app

When

```properties
spring.main.web-application-type=none
```

app prints the whole _The Three Little Pigs_ story in the console.

---

## EventStorming

An example session with myself, for _The Three Little Pigs_. There was no need to run Process Level ES as we already had
a single BoundedContext, and it was doable to jump straight into Design Level.

For the second module I also run Big Picture ES which helped to realize that the main things are interactions and wolf's
intentions.

### Big Picture

![Big Picture](./es.jpg)

### Design Level - commands, rules & actors

![Design Level rules](./es2.jpg)

### Design Level - naming aggregates

![Design Level aggregates](./es3.jpg)

## Possible improvements

* `House` could have mechanisms for rebuilding
* Story can be extended - currently there is nothing about wolf climbing through the chimney and pigs lighting the fire
    * New `House` method, e.g. `litFire`
    * New `BigBadWolfService` method, e.g. `comeDownTheChimneyOf`
    * Event, e.g. `WolfStartedClimbing` instead of `WolfResignedFromAttacking`, new event from `House`,
      e.g. `WolfEscaped` (when burns in the fireplace)
    * `WolfStartedClimbing` should call both `litFire` and `comeDownTheChimneyOf` in a proper order
    * `WolfEscaped` should result in knowledge sharing
* Full Event Sourcing - `House` can be built just from events, no snapshots in the current form
* Rely fully on `DomainEventPublisher` - although `@DomainEvents` annotation looks
  nice, it relies on `ApplicationEventPublisher` which has known limitations, especially without additional tooling
  like [Spring Modulith](https://spring.io/blog/2022/10/21/introducing-spring-modulith)
* Instead of ""technical"" packages corresponding with Clean Architecture and DDD, there could be more process-oriented
  packages, like `building` (or `construcitng`) and `destroying`, where the domain logic would lay, similar as presented
  in [this great tech talk by Victor Rentea](https://www.youtube.com/watch?v=H7HWOlANX78)
"
noelportugal/GlassBeacon,master,32,11,2014-04-17T02:44:53Z,935,2,A Google Glass GDK example to find iBeacons (using Estimote beacons).,,"GlassBeacon
===========

A Google Glass GDK example to find iBeacons (using Estimote beacons).

![alt tag](http://theappslab.com/wp-content/uploads/2014/04/GlassBeacon.png)
"
nisrulz/FirebaseExample,master,62,17,2016-09-29T12:23:18Z,376,0,:fire: Simplistic example app demonstrating using latest Firebase features. Checkout branches for each feature. ,,
AlmasB/JavaFX11-example,master,34,15,2018-10-10T17:50:05Z,13214,0,An example that shows how to use JavaFX 11 with Java 11,javafx javafx-11,"# JavaFX11-example
An example that shows how to use JavaFX 11 with Java 11
"
SwerveDriveSpecialties/Do-not-use-Example-Swerve-unmaintained,master,31,28,2019-09-01T19:20:21Z,100,4,Example code for a swerve drivetrain using the SDS Mk2 swerve modules with NEO motors,,"# Example Swerve Project

When using Swerve Drive Specialties MK2 modules this template code will provide a quick and simple way to get your robot driving.

## Electrical Hardware Setup

1.	A navX should be plugged into the roboRIO MXP port.
2.	Steering encoders (analog US digital MA3) are connected to the roboRIO analog input ports.	
3.	Spark Max motor controllers for the drive motors are:
    1.	powered using 40 Amp PDP ports and breakers
    2.	controlled with CAN Bus
    3.  set to brushless brake mode (blinking cyan LED status when disabled) 
4.	Spark Max motor controllers for the steering motors are:
    1.	powered with either size PDP port. We recommend connecting them to the small ports with 30 Amp breakers
    2.	controlled with CAN Bus
    3.  set to brushless brake mode (blinking cyan LED status when disabled) 
    
The following port mapping is recommended

1.	Front Left Module
    1.	Drive Motor Controller – CAN ID 1
    2.	Steering Motor Controller – CAN ID 2
    3.	Steering Encoder – Analog input 0
2.	Front Right Module
    1.	Drive Motor Controller – CAN ID 3
    2.	Steering Motor Controller – CAN ID 4
    3.	Steering Encoder – Analog input 1
3.	Back Left Module
    1.	Drive Motor Controller – CAN ID 5
    2.	Steering Motor Controller – CAN ID 6
    3.	Steering Encoder – Analog input 2
4.	Back Right Module
    1.	Drive Motor Controller – CAN ID 7
    2.	Steering Motor Controller – CAN ID 8
    3.	Steering Encoder – Analog input 3

## Default Control Setup

By default the robot is setup to be controlled by a XBox One controller. However any XBox-style controller should work.

The left stick is setup to control the translational movement of the robot using field-oriented control.

The right stick is setup to control the rotational movement of the robot. Right on the stick should make the robot
rotate clockwise while left should make the robot rotate counter-clockwise.

The back button on the controller is setup to re-zero the robot's gyroscope. By default, the direction the robot is
facing when turned on is the forwards direction but this can be changed by re-zeroing the gyroscope.

## Configure For Your Robot

1. Set your team number using the WPILib extension's ""Set Team Number"" action.
2. In the `RobotMap` class:
    1. If needed, change the values to match the ports and CAN IDs on your robot.
3. In the `DrivetrainSubsystem` class:
    1. Set the `TRACKWIDTH` and `WHEELBASE` to your robot's trackwidth and wheelbase.
    2. Set all of the `*_ANGLE_OFFSET` constants to `-Math.toRadians(0.0)`.
4. Deploy the code to your robot.
    > NOTE: The robot isn't drivable quite yet, we still have to setup the module offsets
5. Turn the robot on its side and align all the wheels so they are facing in the forwards direction.
    > NOTE: The wheels will be pointed forwards (not backwards) when modules are turned so the large bevel gears are towards the right side of the robot. When aligning the wheels they must be as straight as possible. It is recommended to use a long strait edge such as a piece of 2x1 in order to make the wheels straight.
6. Record the angles of each module using the angle put onto Shuffleboard. The values are named
    `Front Left Module Angle`, `Front Right Module Angle`, etc.
7. Set the values of the `*_ANGLE_OFFSET` to `-Math.toRadians(<the angle you recorded>)`
    > NOTE: All angles must be in degrees.
8. Re-deploy and try to drive the robot forwards. All the wheels should stay parallel to each other. If not go back to
    step 3.
9. Make sure all the wheels are spinning in the correct direction. If not, add 180 degrees to the offset of each wheel
    that is spinning in the incorrect direction. i.e `-Math.toRadians(<angle> + 180.0)`.

### Optional Steps
#### Changing Controller Setup
To invert the controller sticks or modify the control mapping modify the `DriveCommand` class.

#### Using Different Types of Motors
While the default hardware setup uses NEOs & Spark MAXs to control the module, teams may desire to use different motors
to control their modules. The new `Mk2SwerveModuleBuilder` class supports any combination of NEOs, CIMs, or Mini CIMs
using either CAN or PWM.

##### Example 1
Angle motor: NEO controlled by a Spark MAX over CAN
Drive motor: NEO controlled by a Spark MAX over CAN

```java
SwerveModule module = new Mk2SwerveModuleBuilder(new Vector2(5.0, 5.0))
    .angleEncoder(new AnalogInput(0), -Math.toRadians(254.16))
    .angleMotor(new CANSparkMax(1, CANSparkMaxLowLevel.MotorType.kBrushless),
            Mk2SwerveModuleBuilder.MotorType.NEO)
    .driveMotor(new CANSparkMax(2, CANSparkMaxLowLevel.MotorType.kBrushless),
            Mk2SwerveModuleBuilder.MotorType.NEO)
    .build();
```

##### Example 2
Angle motor: NEO controlled by a Spark MAX over PWM with custom PID constants
Drive motor: NEO controlled by a Spark MAX over CAN


```java
SwerveModule module = new Mk2SwerveModuleBuilder(new Vector2(5.0, 5.0))
    .angleEncoder(new AnalogInput(0), -Math.toRadians(330.148))
    .angleMotor(new Spark(4), new PidConstants(1.0, 0.0, 0.001))
    .driveMotor(new CANSparkMax(4, CANSparkMaxLowLevel.MotorType.kBrushless),
            Mk2SwerveModuleBuilder.MotorType.NEO)
    .build();
```

##### Example 3
Angle motor: Mini CIM controlled by a Talon SRX over CAN
Drive motor: CIM controlled by a Talon SRX over CAN

```java
SwerveModule module = new Mk2SwerveModuleBuilder(new Vector2(5.0, 5.0))
    .angleEncoder(new AnalogInput(0), -Math.toRadians(118.1114))
    .angleMotor(new TalonSRX(4), Mk2SwerveModuleBuilder.MotorType.MINI_CIM)
    .driveMotor(new TalonSRX(5), Mk2SwerveModuleBuilder.MotorType.CIM)
    .build();
```"
sassoftware/enlighten-integration,master,61,51,2015-04-09T20:36:41Z,48788,2,Example code and materials that illustrate techniques for integrating SAS with popular open source analytics technologies like Python and R.,,"# enlighten-integration

Example code and materials that illustrate techniques for integrating SAS with
popular open source analytics technologies like Python and R.

See individual subdirectories for specific examples and instructions. 

Contributors include:
Patrick Hall, Radhikha Myneni, Ruiwen Zhang, and Tim Haley

## Contents

The example materials in this repository use two approaches to call functionality in other languages from a SAS&reg; session.
* The Base SAS&reg; Java Object
* SAS/IML&reg; Integration with R

### The Base SAS Java Object

![alt text](readme_pics/Slide2.png ""The Base SAS Java Object"")

The [Base SAS Java Object](http://support.sas.com/documentation/cdl/en/lrcon/68089/HTML/default/viewer.htm#n0swy2q7eouj2fn11g1o28q57v4u.htm) is a SAS DATA step component that enables Java objects to be instantiated, object methods to be called, and results to be returned from Java to SAS. The [SASJavaExec.java](https://github.com/sassoftware/enlighten-integration/blob/master/SAS_Base_OpenSrcIntegration/src/dev/SASJavaExec.java) class in this repository is designed to call executable files from SAS with command line arguments and reports STDOUT and STDERR back to the SAS log. Example materials in this repository use the SASJavaExec.java class to call R and Python scripts, but the class could be used to call other types of executables as well.

#### Using the Base SAS Java Object to call R or Python

[SAS_Base_OpenSrcIntegration](https://github.com/sassoftware/enlighten-integration/tree/master/SAS_Base_OpenSrcIntegration)

* White Paper on [Open Source Integration using the Base SAS Java Object](https://github.com/sassoftware/enlighten-integration/blob/master/SAS_Base_OpenSrcIntegration/SAS_Base_OpenSrcIntegration.pdf)
* White Paper on [Connecting Java to SAS Data Sets](http://support.sas.com/resources/papers/proceedings12/008-2012.pdf)

#### Using Python inside of SAS&reg; Enterprise Miner&trade;

[SAS_EM_PythonIntegration](https://github.com/sassoftware/enlighten-integration/tree/master/SAS_EM_PythonIntegration)

* SAS Communities Tip: [How to execute a Python script in SAS Enterprise Miner](https://communities.sas.com/t5/SAS-Communities-Library/Tip-How-to-execute-a-Python-script-in-SAS-Enterprise-Miner/tac-p/223765)
* Video on [How to Execute a Python Script in SAS Enterprise Miner](http://www.sas.com/apps/webnet/video-sharing.html?player=brightcove&width=640&height=360&autoStart=true&playerID=1873162645001&playerKey=AQ~~,AAABs_kuvqE~,9q03viSCCi8Qu-ec7KH7e-bapzBTKVDB&videoPlayer=4283224315001&emptyPage=false)

### SAS/IML Integration with R

![alt text](readme_pics/Slide1.png ""SAS/IML Integration with R"")

[SAS/IML Integration with R](https://support.sas.com/documentation/cdl/en/imlug/68150/HTML/default/viewer.htm#imlug_r_toc.htm) enables data to be transferred between SAS and R and it enables calling statements from the R language from within a SAS session. One important consideration with R is its ability, much like SAS', to generate [Predictive Modeling Markup Langauge (PMML)](http://dmg.org/pmml/v4-2-1/GeneralStructure.html) to encapsulate the logic of predictive models in a portable format. The example materials in this repository use R to train models and PMML as a portable deployment mechanism. The Enterprise Miner Open Source Integration node is based on the same technologies.

#### Using SAS/IML to call R and create PMML

[SAS_IML_PmmlIntegration](https://github.com/sassoftware/enlighten-integration/tree/master/SAS_IML_PmmlIntegration)

* Video on the [Enterprise Miner Open Source Integration node](http://www.sas.com/apps/webnet/video-sharing.html?player=brightcove&width=640&height=360&autoStart=true&playerID=1873162645001&playerKey=AQ~~,AAABs_kuvqE~,9q03viSCCi8Qu-ec7KH7e-bapzBTKVDB&videoPlayer=3939327608001&emptyPage=false)
* Video on [Calling R from SAS/IML](https://www.youtube.com/watch?v=rUaTTre24kI)

#### Using R to create PMML and importing PMML into SAS Enterprise Miner

[SAS_EM_PmmlIntegration](https://github.com/sassoftware/enlighten-integration/tree/master/SAS_EM_PmmlIntegration)

## Other Integration Approaches

* [SAS Kernel for Jupyter Notebooks](https://github.com/sassoftware/sas_kernel)
* [Calling SAS from R or Python using SAS&reg; BI Web Services](http://blogs.sas.com/content/subconsciousmusings/2015/10/13/how-analytical-web-services-can-help-scale-your-machine-learning/)
* [The LUA Procedure](http://support.sas.com/documentation/cdl/en/proc/68954/HTML/default/viewer.htm#n1csk38ocks0rgn1rr8d302ofqgs.htm)
* [The GROOVY Procedure](http://support.sas.com/documentation/cdl/en/proc/68954/HTML/default/viewer.htm#p1x8agymll9gten1ocziihptcjzj.htm)
* [The JSON Procedure](http://support.sas.com/documentation/cdl/en/proc/68954/HTML/default/viewer.htm#p06hstivs0b3hsn1cb4zclxukkut.htm)"
saturnism/spring-cloud-gcp-guestbook,master,57,68,2017-12-04T09:07:14Z,178,3,,appengine appengine-java distributed-tracing docker examples gcp gcp-spanner gcp-sql gcp-storage kubernetes microservices-architecture ml mysql spring spring-boot spring-cloud spring-cloud-gcp workshop,"This is not an official Google project.

This repository contains example code for the Spring Cloud GCP lab.

The instructions are in [bit.ly/spring-gcp-lab](http://bit.ly/spring-gcp-lab)

"
subhashlamba/spring-boot-microservice-example,main,73,46,2021-05-08T05:30:04Z,851,5,Spring boot microservice example with Eureka Server + Eureka Client + Spring Cloud API Gateway + OAuth2.0 + Circuit Breaker + Resilience4J + FeignClient + RestTemplate,api-gateway eureka-client eureka-server feign-client oath2 oauth2-client oauth2-server resilience4j resttemplate spring-boot-microservice spring-oauth2 zipkin-server,
nfrankel/jvm-controller,master,31,10,2019-12-13T17:15:12Z,835,0,Example on how to write a kubernetes controller in Java,,
anatawa12/ForgeGradle-example,master,48,10,2019-11-30T13:58:00Z,414,2,example project of fork of ForgeGradle 1.2 made by anatawa12,,"# anatawa12's ForgeGradle 1.2 fork for Gradle 4.4.1+ - example project

This is an example mod using the [fork of ForgeGradle-1.2 made by anatawa12](https://github.com/anatawa12/ForgeGradle-1.2).
This fork supports Gradle 4.4.1 and later. This example project uses Gradle 5.6.4.

## How to use this example project

You can download this example project from [here](https://github.com/anatawa12/ForgeGradle-example/archive/master.zip), or use it as a template on Github.
This project can be used as a replacement for Forge's 1.7.10 MDK.

## How to replace ForgeGradle 1.2. with anatawa12's fork
Although this example project has some differences to Forge's 1.7.10 MDK, anatawa12's fork of ForgeGradle 1.2 can be used by most projects with only minimal changes to their Gradle build script.

Here is a list of changes to Forge's 1.7.10 MDK Gradle build script, to replace the official ForgeGradle 1.2 plugin with the fork. These changes are likely to work with most projects based on Forge's 1.7.10 MDK.

In the repositories block of the buildscript section, add jcenter, and switch the Forge maven to use HTTPS instead of HTTP:
```diff
     repositories {
         mavenCentral()
         maven {
             name = ""forge""
-            url = ""http://files.minecraftforge.net/maven""
+            url = ""https://maven.minecraftforge.net/""
         }
```

Also in the dependencies block of the buildscript section, change the dependency on Forge's official ForgeGradle 1.2 to the fork:
```diff
     dependencies {
-        classpath 'net.minecraftforge.gradle:ForgeGradle:1.2-SNAPSHOT'
+        classpath ('com.anatawa12.forge:ForgeGradle:1.2-1.1.+') {
+            changing = true
+        }
     }
```

The Gradle wrapper should also be changed to use Gradle 4.4.1 or higher. <!--Currently, the plugin [does not support Gradle 6.x](https://github.com/anatawa12/ForgeGradle-1.2/issues/9), although this may change in the future. As such, the latest version of Gradle this plugin supports is Gradle 5.6.4.-->
"
swtestacademy/javafxexample,master,27,22,2016-06-18T21:01:22Z,2576,1,This is the example of this article http://www.swtestacademy.com/database-operations-javafx,,"# javafxexample
This is the example of these articles:

- http://www.swtestacademy.com/database-operations-javafx

- https://www.swtestacademy.com/database-operations-javafx/
"
JohnathanMarkSmith/springmvc-resttemplate-test,master,26,32,2013-06-18T12:35:16Z,121,1,This is a Quick Example of Spring RESTTemplate Doing a POST to Spring MVC RESTful service,,"###  Using Spring RESTTemplate to Post Objects to RESTful web services with Spring's Java Configuration (JavaConfig) style with Maven, JUnit, Log4J


In this example I am going to show you how to post data to a RESTful web service in Java using Spring, Spring Java Configuration and more


### Web Service Code

Let's take a quick look at the Spring MVC Web Service code on the server:

    @Controller
    @RequestMapping(""/api"")
    class JSonController
    {

        private static final Logger logger = LoggerFactory.getLogger(JSonController.class);



        @RequestMapping(value = ""/{id}"", method = RequestMethod.POST)
        @ResponseBody
        public User updateCustomer(@PathVariable(""id"") String id, @RequestBody User user) {

            logger.debug(""I am in the controller and got ID: "" + id.toString());
            logger.debug(""I am in the controller and got user name: "" + user.toString());

            return new User(""NEW123"", ""NEW SMITH"");
        }


As you can see from the code above the web service is goign to what for a ID and user object to be passed in and then its going to create a new User Object and send it back to the client.

### Time For The Client Code

You can see from the client code below is that we are using Spring RESTTemaple and going to post an User Object to a web server and get one back.


    @PropertySource(""classpath:application.properties"")
    public class Main
    {

        /**
         * Setting up logger
         */
        private static final Logger LOGGER = getLogger(Main.class);


        public static void main(String[] args) throws IOException
        {
            LOGGER.debug(""Starting REST Client!!!!"");

            /**
             *
             * This is going to setup the REST server configuration in the applicationContext
             * you can see that I am using the new Spring's Java Configuration style and not some OLD XML file
             *
             */
            ApplicationContext context = new AnnotationConfigApplicationContext(RESTConfiguration.class);

            /**
             *
             * We now get a RESTServer bean from the ApplicationContext which has all the data we need to
             * log into the REST service with.
             *
             */
            RESTServer mRESTServer = context.getBean(RESTServer.class);



            /**
             *
             * Setting up data to be sent to REST service
             *
             */
            Map<String, String> vars = new HashMap<String, String>();
            vars.put(""id"", ""JS01"");




            /**
             *
             * Doing the REST call and then displaying the data/user object
             *
             */


            try
            {

                /*

                    This is code to post and return a user object

                 */

                RestTemplate rt = new RestTemplate();
                rt.getMessageConverters().add(new MappingJacksonHttpMessageConverter());
                rt.getMessageConverters().add(new StringHttpMessageConverter());

                String uri = new String(""http://"" + mRESTServer.getHost() + "":8080/springmvc-resttemplate-test/api/{id}"");

                User u = new User();
                u.setName(""Johnathan M Smith"");
                u.setUser(""JS01"");


                User returns = rt.postForObject(uri, u, User.class, vars);
                LOGGER.debug(""User:  "" + u.toString());

            }
            catch (HttpClientErrorException e)
            {
                /**
                 *
                 * If we get a HTTP Exception display the error message
                 */

                LOGGER.error(""error:  "" + e.getResponseBodyAsString());

                ObjectMapper mapper = new ObjectMapper();
                ErrorHolder eh = mapper.readValue(e.getResponseBodyAsString(), ErrorHolder.class);

                LOGGER.error(""error:  "" + eh.getErrorMessage());

            }
            catch(Exception e)
            {
                LOGGER.error(""error:  "" + e.getMessage());

            }
        }

    }


You can see from the above code how easy it is to use RESTTeample to post data to a web service.



You can see how easy it is to use Spring's Java Configuration (JavaConfig) style and Not XML.. The time of using XML files with Springs is over...

### We Can I Get The Sourcec Code

You can checkout the project from github.

    git clone git@github.com:JohnathanMarkSmith/springmvc-resttemplate-test.git
    cd springmvc-resttemplate-test.git


If you have any questions please email me at john@johnathanmarksmith.com"
robmelfi/21-points-react,master,40,13,2018-10-14T06:46:12Z,943,6,This application refers to the book “The JHipster Mini-Book by Matt Raible”. In this application the examples of the book are made using React instead of Angular.,bootstrap4 health java jhipster maven npm react spring-boot webpack,"# 21-Points Health (React Version)
This application refers to the book [“The JHipster Mini-Book by Matt Raible”](http://www.jhipster-book.com). In this application the examples of the book are made using React instead of Angular.

This is the [Angular Web App](https://www.21-points.com) version.

Demo of dev [master](https://twentyone-points-react-dev.herokuapp.com)

Demo of [21 Points Health v1.0.0 (React)](https://twentyone-points-react.herokuapp.com)

‪Note that it takes +30 seconds to wake up in Heroku free account.

This application was generated using JHipster 5.4.1, you can find documentation and help at [https://www.jhipster.tech/documentation-archive/v5.4.1](https://www.jhipster.tech/documentation-archive/v5.4.1).

## Development

Before you can build this project, you must install and configure the following dependencies on your machine:

1. [Node.js][]: We use Node to run a development web server and build the project.
   Depending on your system, you can install Node either from source or as a pre-packaged bundle.

After installing Node, you should be able to run the following command to install development tools.
You will only need to run this command when dependencies change in [package.json](package.json).

    npm install

We use npm scripts and [Webpack][] as our build system.

Run the following commands in two separate terminals to create a blissful development experience where your browser
auto-refreshes when files change on your hard drive.

    ./mvnw
    npm start

Npm is also used to manage CSS and JavaScript dependencies used in this application. You can upgrade dependencies by
specifying a newer version in [package.json](package.json). You can also run `npm update` and `npm install` to manage dependencies.
Add the `help` flag on any command to see how you can use it. For example, `npm help update`.

The `npm run` command will list all of the scripts available to run for this project.

### Service workers

Service workers are commented by default, to enable them please uncomment the following code.

* The service worker registering script in index.html

```html
<script>
    if ('serviceWorker' in navigator) {
        navigator.serviceWorker
        .register('./service-worker.js')
        .then(function() { console.log('Service Worker Registered'); });
    }
</script>
```

Note: workbox creates the respective service worker and dynamically generate the `service-worker.js`

### Managing dependencies

For example, to add [Leaflet][] library as a runtime dependency of your application, you would run following command:

    npm install --save --save-exact leaflet

To benefit from TypeScript type definitions from [DefinitelyTyped][] repository in development, you would run following command:

    npm install --save-dev --save-exact @types/leaflet

Then you would import the JS and CSS files specified in library's installation instructions so that [Webpack][] knows about them:
Note: there are still few other things remaining to do for Leaflet that we won't detail here.

For further instructions on how to develop with JHipster, have a look at [Using JHipster in development][].



## Building for production

To optimize the TwentyOnePointsReact application for production, run:

    ./mvnw -Pprod clean package

This will concatenate and minify the client CSS and JavaScript files. It will also modify `index.html` so it references these new files.
To ensure everything worked, run:

    java -jar target/*.war

Then navigate to [http://localhost:8080](http://localhost:8080) in your browser.

Refer to [Using JHipster in production][] for more details.

## Testing

To launch your application's tests, run:

    ./mvnw clean test

### Client tests

Unit tests are run by [Jest][] and written with [Jasmine][]. They're located in [src/test/javascript/](src/test/javascript/) and can be run with:

    npm test

UI end-to-end tests are powered by [Protractor][], which is built on top of WebDriverJS. They're located in [src/test/javascript/e2e](src/test/javascript/e2e)
and can be run by starting Spring Boot in one terminal (`./mvnw spring-boot:run`) and running the tests (`npm run e2e`) in a second one.

For more information, refer to the [Running tests page][].

### Code quality

Sonar is used to analyse code quality. You can start a local Sonar server (accessible on http://localhost:9001) with:

```
docker-compose -f src/main/docker/sonar.yml up -d
```

Then, run a Sonar analysis:

```
./mvnw -Pprod clean test sonar:sonar
```

For more information, refer to the [Code quality page][].

## Using Docker to simplify development (optional)

You can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.

For example, to start a mysql database in a docker container, run:

    docker-compose -f src/main/docker/mysql.yml up -d

To stop it and remove the container, run:

    docker-compose -f src/main/docker/mysql.yml down

You can also fully dockerize your application and all the services that it depends on.
To achieve this, first build a docker image of your app by running:

    ./mvnw package -Pprod jib:dockerBuild

Then run:

    docker-compose -f src/main/docker/app.yml up -d

For more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.

## Continuous Integration (optional)

To configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.

[JHipster Homepage and latest documentation]: https://www.jhipster.tech
[JHipster 5.4.1 archive]: https://www.jhipster.tech/documentation-archive/v5.4.1

[Using JHipster in development]: https://www.jhipster.tech/documentation-archive/v5.4.1/development/
[Using Docker and Docker-Compose]: https://www.jhipster.tech/documentation-archive/v5.4.1/docker-compose
[Using JHipster in production]: https://www.jhipster.tech/documentation-archive/v5.4.1/production/
[Running tests page]: https://www.jhipster.tech/documentation-archive/v5.4.1/running-tests/
[Code quality page]: https://www.jhipster.tech/documentation-archive/v5.4.1/code-quality/
[Setting up Continuous Integration]: https://www.jhipster.tech/documentation-archive/v5.4.1/setting-up-ci/


[Node.js]: https://nodejs.org/
[Yarn]: https://yarnpkg.org/
[Webpack]: https://webpack.github.io/
[Angular CLI]: https://cli.angular.io/
[BrowserSync]: http://www.browsersync.io/
[Jest]: https://facebook.github.io/jest/
[Jasmine]: http://jasmine.github.io/2.0/introduction.html
[Protractor]: https://angular.github.io/protractor/
[Leaflet]: http://leafletjs.com/
[DefinitelyTyped]: http://definitelytyped.org/
"
HubertWo/java-stream-kata,master,30,10,2019-03-09T15:39:46Z,117,2,Java Stream Code Kata. ☕️ 🤺 Collection of small tasks with detailed answers in form of unit tests.,by example examples java kata katas learn learning-by-doing stream,
Zhuinden/realm-book-example,master,80,19,2016-08-16T00:21:15Z,166,1,"This is an example rewrite of AndroidHive's messy tutorial, accompanying the following article on Realm.",,"# realm-book-example
This is a rewrite of a [""Realm tutorial"" on Android Hive](http://www.androidhive.info/2016/05/android-working-with-realm-database-replacing-sqlite-core-data). Unfortunately the tutorial is extremely outdated (uses 0.82.1 even though the version 3.5.0 is out!), the code is unstructured (Realm transactions inside a click listener inside a dialog created in a long click listener); and it also misuses Realm quite heavily: 

- using `begin/commitTransaction()` instead of `executeTransaction()`
- calling `refresh()` even though the Realm instance is freshly open
- the transactions are all done on the UI thread
- the Realm instance is never closed

It also uses outdated practices or is just not up-to-date information:

- `refresh()` doesn't even exist anymore, and even when it did, in this use-case it was not needed
- uses a Migration to pre-populate the database, even though `initialData()` exists now
- claims that `null` support for primitives isn't in, even though it was added in 0.83.0
- the code relies on `commitTransaction()` immediately updating the `RealmResults<T>` and calling `adapter.notifyDataSetChanged()` manually, but that's not the case since 0.89.0 which means you need to add a change listener to the `RealmResults<T>` (which `RealmRecyclerViewAdapter` does for you automatically)

------------------------------

So with that in mind, this repository shows how to do these things right:

- uses `executeTransactionAsync()` on the UI thread
- uses `initialData()` to prepopulate the Realm
- uses `RealmManager` class (a bit stub-like because I'll have to make its content not static later) to manage number of open activities
- uses retained fragment to count open activity
- uses retained fragment to store presenter (oh, it actually has a ""presenter"" instead of just throwing everything in `OnClickListener`s)
- does not use `Application` subclass explicitly because of [Firebase Crash Reporting](https://firebase.google.com/docs/crash/android) for example creating multiple Application instances
- uses `RealmRecyclerViewAdapter` with asynchronous query

So yeah, this is the interesting class:

``` java
public class RealmManager {
    static Realm realm;

    static RealmConfiguration realmConfiguration;

    public static void initializeRealmConfig(Context appContext) {
        if(realmConfiguration == null) {
            setRealmConfiguration(new RealmConfiguration.Builder(appContext).initialData(new RealmInitialData())
                    .deleteRealmIfMigrationNeeded()
                    .build());
        }
    }

    public static void setRealmConfiguration(RealmConfiguration realmConfiguration) {
        RealmManager.realmConfiguration = realmConfiguration;
        Realm.setDefaultConfiguration(realmConfiguration);
    }

    private static int activityCount = 0;

    public static Realm getRealm() {
        return realm;
    }

    public static void incrementCount() {
        if(activityCount == 0) {
            if(realm != null) {
                if(!realm.isClosed()) {
                    realm.close();
                    realm = null;
                }
            }
            realm = Realm.getDefaultInstance();
        }
        activityCount++;
    }

    public static void decrementCount() {
        activityCount--;
        if(activityCount <= 0) {
            activityCount = 0;
            realm.close();
            Realm.compactRealm(realmConfiguration);
            realm = null;
        }
    }
}
```

Which has its `RealmConfiguration` initialized in `Activity.onCreate()`, and the Realm instance itself is opened with `RealmManager.incrementCount()` from the retained fragment's constructor.

``` java
public class BooksScopeListener extends Fragment {
    BooksPresenter booksPresenter;

    public BooksScopeListener() {
        setRetainInstance(true);
        RealmManager.incrementCount();
        booksPresenter = new BooksPresenter();
    }

    @Override
    public void onDestroy() {
        RealmManager.decrementCount();
        super.onDestroy();
    }

    public BooksPresenter getPresenter() {
        return booksPresenter;
    }
}
```

Which is created in the Activity.

``` java
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        RealmManager.initializeRealmConfig(getApplicationContext());
        super.onCreate(savedInstanceState);
        BooksScopeListener fragment = (BooksScopeListener) getSupportFragmentManager().findFragmentByTag(""SCOPE_LISTENER"");
        if(fragment == null) {
            fragment = new BooksScopeListener();
            getSupportFragmentManager().beginTransaction().add(fragment, ""SCOPE_LISTENER"").commit();
        }
        realm = RealmManager.getRealm();
        booksPresenter = fragment.getPresenter();
```

The adapter is set up like this

``` java
recycler.setAdapter(new BooksAdapter(this, realm.where(Book.class).findAllAsync(), booksPresenter));
```
        
Where the adapter is a proper `RealmRecyclerViewAdapter`:

``` java
public class BooksAdapter extends RealmRecyclerViewAdapter<Book, BooksAdapter.BookViewHolder> {
```
        
And the writes are from the UI thread to a background thread using `executeTransactionAsync()`, found in the presenter.

``` java
    Realm realm = RealmManager.getRealm();
    realm.executeTransactionAsync(new Realm.Transaction() {
```
"
osgi/osgi.enroute,main,121,85,2014-01-29T08:07:58Z,63501,24,The OSGi enRoute project provides a programming model of OSGi applications. This project contains bundles providing the API for the OSGi enRoute base profile and bundles for the OSGi enRoute project. The base profile establishes a runtime that contains a minimal set of services that can be used as a base for applications. The bundles are simple implementations that can be used to run enRoute for smaller applications and provide an example how to implement it more thoroughly. There are also examples in this repo.,java osgi-applications osgi-enroute,"<h1><img src=""http://enroute.osgi.org/img/enroute-logo-64.png"" witdh=40px style=""float:left;margin: 0 1em 1em 0;width:40px"">
OSGi enRoute</h1>

Interested in developing agile & maintainable Enterprise or highly distributed IoT solutions? In either case, [OSGi enRoute](http://enroute.osgi.org) provides a simple on-ramp for developing such modular distributed applications and exploring the power of OSGi.

Based upon the latest OSGi best practices and R7 Specifications, the enRoute tutorials start with a comprehensive hands-on introduction to Declarative Services, and then progresses to explore OSGi's unique and powerful approaches to Microservices & Reactive Systems.

This repository contains the code for the enRoute tutorials, and also defines useful OSGi repositories for the OSGi R7 reference implementations. You can use these repositories directly in your own OSGi applications, or as a template for creating your own personalised OSGi application runtime.

## Contributing

Want to contribute to osgi.enroute? See [CONTRIBUTING.md](CONTRIBUTING.md) for information on building, testing and contributing changes.

## License

The contents of this repository are made available to the public under the terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0).
Bundles may depend on non Apache Licensed code.
"
tspannhw/nifi-tensorflow-processor,master,39,17,2017-07-11T14:51:39Z,49026,0,Example Tensorflow Processor using Java API for Apache NiFi 1.2 - 1.9.1+,apache-nifi deep-learning inception java nifi nifi-processor tensorflow tensorflow-processor,"# nifi-tensorflow-processor
Example Tensorflow Processor using Java API for Apache NiFi 1.2+

Example using out of box TensorFlow Java example with NiFi

Article detailing creation, building and usage
https://community.hortonworks.com/content/kbentry/116803/building-a-custom-processor-in-apache-nifi-12-for.html

Currently simple classification models are supported. The model directory should have a file graph.pb containing a tensorflow graph, and a label.txt file containing labels by index of the output classes of the graph. The model must also have a variable called input which expects as Image tensor, and a output variable which stores a tensor of label index and probability. 



This is a clean update for TensorFlow 1.6.   This takes a flow file as an image 

JPG, PNG, GIF

Updated TensorFlowProcessor to TF 1.6.   Added more tests.   More cleanup.  Top 5 returned in clean naming.

Install to /usr/hdf/current/nifi/lib/

"
szaza/tensorflow-example-java,master,53,31,2018-03-04T12:24:00Z,507,4,This is a Tensorflow Java example application what uses YOLOv2 model and Gradle for build and dependency management.,example java tensorflow yolo,"# TensorFlow Java example with YOLOv2 built by Gradle
TensorFlow Java API is a new opportunity to use TensorFlow from Java applications. 
On the [official TensorFlow site](https://www.tensorflow.org/install/install_java) you can find a description about the
Java API usage with Maven using an Inception model. This sample shows you how to use TensorFlow from Java programs using Gradle as build and 
dependency management tool. In my sample code I used the YOLO vesion 2 to detect and classify objects.

### How it works?

<table>
  <tr>
    <td><img src=""https://github.com/szaza/tensorflow-java-yolo/blob/master/src/main/resources/image/cow-and-bird.jpg"" title=""tensorflow java api cow and bird"" alt=""tensorflow java example cow and bird"" width=""500""/></td>
    <td><img src=""https://github.com/szaza/tensorflow-java-yolo/blob/master/sample/cow-and-bird.jpg"" title=""tensorflow java example"" alt=""tensorflow java example"" width=""500""/></td>
  </tr>
  <tr>
    <td>Input image</td>
    <td>Bird and cow detected by YOLO using TensorFlow Java API</td>
  </tr>
  <tr>
    <td><img src=""https://github.com/szaza/tensorflow-java-yolo/blob/master/src/main/resources/image/eagle.jpg"" title=""tensorflow yolo java eagle"" alt=""tensorflow yolo java eagle"" width=""500""/></td>
    <td><img src=""https://github.com/szaza/tensorflow-java-yolo/blob/master/sample/eagle.jpg"" title=""tensoflow java yolo sample"" alt=""java tensorflow yolo sample"" width=""500""/></td>
  </tr>
  <tr>
    <td>Input image</td>
    <td>Bird detected by YOLO using TensorFlow Java API</td>
  </tr>  
 </table>

### Compile and run

**Preconditions:**
- Java JDK 1.8 or greater;
- TensorFlow 1.6 or grater;
- Git version control system;

**Strongly recommended to install:**
- nVidia CUDA Toolkit 8.0 or higher version;
- nVidia cuDNN GPU accelerated deep learning framework;

**Download the frozen graphs**

Before compiling the application you have to create/download some graph definition files. To try out the application you
can use my frozen graphs, which are trained to the Pascal VOC dataset with 20 classes. You can download them from my
google drive [here](https://drive.google.com/open?id=1GfS1Yle7Xari1tRUEi2EDYedFteAOaoN). Place these files under the
`src/main/resources/YOLO` directory.

Please make sure that you've set properly the *GRAPH_FILE* and *LABEL_FILE* variables in the [Configuration](https://github.com/szaza/tensorflow-java-yolo/blob/master/src/main/java/edu/ml/tensorflow/Config.java) file.

**Compile the source by using Gradle**

By default it runs on CPU. If you want to run this program with GPU support please add this line to the `build.gradle` file: <br/>
`compile group: 'org.tensorflow', name: 'libtensorflow_jni_gpu', version: '1.6.0'`

Specify the path for the image in the [Main](https://github.com/szaza/tensorflow-java-yolo/blob/master/src/main/java/edu/ml/tensorflow/Main.java) class (for sure it can be modified to read from the command line arguments).<br/>
Compile the code with the following command: `./gradlew clean build`

**Run the application**

Type the `./gradlew run` command in the command line window and hit enter. You are done!
The output is printed out with the LogBack logging framework so, it looks like:

`INFO  edu.ml.tensorflow.ObjectDetector - Object: cow - confidence: 0.8864294` <br/>
`INFO  edu.ml.tensorflow.ObjectDetector - Object: bird - confidence: 0.64604723`

**Note**

If you would like to create a client-server architecture with Spring Framework check this project: [TensorFlow Java tutorial with Spring](https://sites.google.com/view/tensorflow-example-java-api/tensorflow-java-api-with-spring-framework).

**FAQ**

Is it much slower than the TensorFlow Python or TensorFlow C++ API? <br/>
   No, because it communicates through Java Native Interface (JNI)

## News about YoloV3 support

The current solution doesn't support the YoloV3 model and unfortunately, I do not have time to implement it, however I would be very happy if I could help to implement and I could review a PR with this feture. 
For this reason I've started a new branch here: https://github.com/szaza/tensorflow-java-examples-spring/tree/feature/add-yolov3-support; If you are interested in this feature and you would like to be a collabortor, please add a comment for this thread: https://github.com/szaza/tensorflow-java-examples-spring/issues/2;

Many-many thank for any support!
"
IMS94/javacv-cnn-example,master,30,23,2017-01-11T17:31:42Z,82863,1,A example to demonstrate the usage of JavaCV and CNN for gender and age recognition,age age-recognition cnn gender javacv javacv-cnn opencv,"# JavaCV CNN (Convolutional Neural Networks) Example for Age and Gender Recognition

A sample repository to demonstrate the usage of JavaCV and CNN for gender and age recognition. **Please refer [Age and gender recognition with JavaCV and CNN](https://medium.com/@Imesha94/age-and-gender-recognition-with-javacv-and-cnn-fdebb3d436c0) for the step by step guide.**

This repository has made use of CNNs trained by [Gil Levi and Tal Hassner in 2015](http://www.openu.ac.il/home/hassner/projects/cnn_agegender).

This simple program is capable of detecting human faces and predicting the gender and age of the detected face. 

## Building project

In order to build this project, run a `mvn clean install` at the project root.
"
bezkoder/spring-security-refresh-token-jwt,master,72,27,2022-09-16T04:53:39Z,149,2,Spring Security Refresh Token using JWT in Spring Boot example with HttpOnly Cookie - Expire and Renew JWT Token,authentication authorization jwt jwt-auth jwt-authentication jwt-authorization jwt-refresh-token jwt-token jwt-tokens refresh-token refresh-tokens refreshtoken spring spring-boot spring-security spring-security-jwt springboot springsecurity,"# Spring Security Refresh Token with JWT in Spring Boot example

Build JWT Refresh Token with Spring Security in the Spring Boot Application. You can know how to expire the JWT Token, then renew the Access Token with Refresh Token in HttpOnly Cookie.

The instruction can be found at:
[Spring Security Refresh Token with JWT](https://www.bezkoder.com/spring-security-refresh-token/)

## User Registration, User Login and Authorization process.
The diagram shows flow of how we implement User Registration, User Login and Authorization process.

![spring-security-jwt-auth-spring-boot-flow](spring-security-jwt-auth-spring-boot-flow.png)

And this is for Refresh Token:

![spring-security-refresh-token-jwt-spring-boot-flow](spring-security-refresh-token-jwt-spring-boot-flow.png)

## Configure Spring Datasource, JPA, App properties
Open `src/main/resources/application.properties`

```properties
spring.datasource.url= jdbc:mysql://localhost:3306/testdb?useSSL=false
spring.datasource.username= root
spring.datasource.password= 123456

spring.jpa.properties.hibernate.dialect= org.hibernate.dialect.MySQLDialect
spring.jpa.hibernate.ddl-auto= update

# App Properties
bezkoder.app.jwtSecret= bezKoderSecretKey
bezkoder.app.jwtExpirationMs= 3600000
bezkoder.app.jwtRefreshExpirationMs= 86400000
```

## Run Spring Boot application
```
mvn spring-boot:run
```

## Run following SQL insert statements
```
INSERT INTO roles(name) VALUES('ROLE_USER');
INSERT INTO roles(name) VALUES('ROLE_MODERATOR');
INSERT INTO roles(name) VALUES('ROLE_ADMIN');
```

Related Posts:
> [Spring Boot, Spring Security: JWT Authentication & Authorization example](https://www.bezkoder.com/spring-boot-security-login-jwt/)

> [For MySQL/PostgreSQL](https://www.bezkoder.com/spring-boot-login-example-mysql/)

> [For MongoDB](https://www.bezkoder.com/spring-boot-mongodb-login-example/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Rest Controller Unit Test with @WebMvcTest](https://www.bezkoder.com/spring-boot-webmvctest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

> Validation: [Spring Boot Validate Request Body](https://www.bezkoder.com/spring-boot-validate-request-body/)

> Documentation: [Spring Boot and Swagger 3 example](https://www.bezkoder.com/spring-boot-swagger-3/)

> Caching: [Spring Boot Redis Cache example](https://www.bezkoder.com/spring-boot-redis-cache-example/)

Associations:
> [Spring Boot One To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-one-to-many/)

> [Spring Boot Many To Many example with Spring JPA, Hibernate](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA One To One example with Spring Boot](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)

## Fullstack Authentication

> [Spring Boot + Vue.js JWT Authentication](https://bezkoder.com/spring-boot-vue-js-authentication-jwt-spring-security/)

> [Spring Boot + Angular 8 JWT Authentication](https://bezkoder.com/angular-spring-boot-jwt-auth/)

> [Spring Boot + Angular 10 JWT Authentication](https://bezkoder.com/angular-10-spring-boot-jwt-auth/)

> [Spring Boot + Angular 11 JWT Authentication](https://bezkoder.com/angular-11-spring-boot-jwt-auth/)

> [Spring Boot + Angular 12 JWT Authentication](https://www.bezkoder.com/angular-12-spring-boot-jwt-auth/)

> [Spring Boot + Angular 13 JWT Authentication](https://www.bezkoder.com/angular-13-spring-boot-jwt-auth/)

> [Spring Boot + Angular 14 JWT Authentication](https://www.bezkoder.com/angular-14-spring-boot-jwt-auth/)

> [Spring Boot + Angular 15 JWT Authentication](https://www.bezkoder.com/angular-15-spring-boot-jwt-auth/)

> [Spring Boot + Angular 16 JWT Authentication](https://www.bezkoder.com/angular-16-spring-boot-jwt-auth/)

> [Spring Boot + Angular 17 JWT Authentication](https://www.bezkoder.com/angular-17-spring-boot-jwt-auth/)

> [Spring Boot + React JWT Authentication](https://bezkoder.com/spring-boot-react-jwt-auth/)

## Fullstack CRUD App

> [Vue.js + Spring Boot + H2 Embedded database example](https://www.bezkoder.com/spring-boot-vue-js-crud-example/)

> [Vue.js + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-vue-js-mysql/)

> [Vue.js + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-vue-js-postgresql/)

> [Angular 8 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + MySQL example](https://bezkoder.com/angular-spring-boot-crud/)

> [Angular 8 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-spring-boot-postgresql/)

> [Angular 10 + Spring Boot + MySQL example](https://bezkoder.com/angular-10-spring-boot-crud/)

> [Angular 10 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-10-spring-boot-postgresql/)

> [Angular 11 + Spring Boot + MySQL example](https://bezkoder.com/angular-11-spring-boot-crud/)

> [Angular 11 + Spring Boot + PostgreSQL example](https://bezkoder.com/angular-11-spring-boot-postgresql/)

> [Angular 12 + Spring Boot + Embedded database example](https://www.bezkoder.com/angular-12-spring-boot-crud/)

> [Angular 12 + Spring Boot + MySQL example](https://www.bezkoder.com/angular-12-spring-boot-mysql/)

> [Angular 12 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/angular-12-spring-boot-postgresql/)

> [Angular 13 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-13-crud/)

> [Angular 13 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-13-mysql/)

> [Angular 13 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-13-postgresql/)

> [Angular 14 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-14-crud/)

> [Angular 14 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-14-mysql/)

> [Angular 14 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-14-postgresql/)

> [Angular 15 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-15-crud/)

> [Angular 15 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-15-mysql/)

> [Angular 15 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-15-postgresql/)

> [Angular 15 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-15-mongodb/)

> [Angular 16 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-16-crud/)

> [Angular 16 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-16-mysql/)

> [Angular 16 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-16-postgresql/)

> [Angular 16 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-16-mongodb/)

> [Angular 17 + Spring Boot + H2 Embedded Database example](https://www.bezkoder.com/spring-boot-angular-17-crud/)

> [Angular 17 + Spring Boot + MySQL example](https://www.bezkoder.com/spring-boot-angular-17-mysql/)

> [Angular 17 + Spring Boot + PostgreSQL example](https://www.bezkoder.com/spring-boot-angular-17-postgresql/)

> [Angular 17 + Spring Boot + MongoDB example](https://www.bezkoder.com/spring-boot-angular-17-mongodb/)

> [React + Spring Boot + MySQL example](https://bezkoder.com/react-spring-boot-crud/)

> [React + Spring Boot + PostgreSQL example](https://bezkoder.com/spring-boot-react-postgresql/)

> [React + Spring Boot + MongoDB example](https://bezkoder.com/react-spring-boot-mongodb/)

Run both Back-end & Front-end in one place:
> [Integrate Angular with Spring Boot Rest API](https://bezkoder.com/integrate-angular-spring-boot/)

> [Integrate React.js with Spring Boot Rest API](https://bezkoder.com/integrate-reactjs-spring-boot/)

> [Integrate Vue.js with Spring Boot Rest API](https://bezkoder.com/integrate-vue-spring-boot/)

## More Practice:
> [Spring Boot File upload example with Multipart File](https://bezkoder.com/spring-boot-file-upload/)

> [Exception handling: @RestControllerAdvice example in Spring Boot](https://bezkoder.com/spring-boot-restcontrolleradvice/)

> [Spring Boot Repository Unit Test with @DataJpaTest](https://bezkoder.com/spring-boot-unit-test-jpa-repo-datajpatest/)

> [Spring Boot Pagination & Sorting example](https://www.bezkoder.com/spring-boot-pagination-sorting-example/)

Associations:
> [JPA/Hibernate One To Many example](https://www.bezkoder.com/jpa-one-to-many/)

> [JPA/Hibernate Many To Many example](https://www.bezkoder.com/jpa-many-to-many/)

> [JPA/Hibernate One To One example](https://www.bezkoder.com/jpa-one-to-one/)

Deployment:
> [Deploy Spring Boot App on AWS – Elastic Beanstalk](https://www.bezkoder.com/deploy-spring-boot-aws-eb/)

> [Docker Compose Spring Boot and MySQL example](https://www.bezkoder.com/docker-compose-spring-boot-mysql/)
"
daemontus/VuforiaLibGDX,master,30,9,2016-06-12T15:10:29Z,13083,2,Example of Vuforia and LibGDX integration for 3D model rendering,,"## Deprecated

Currently, the repo is deprecated, as it is not working with latest Vuforia SDK and I don't have the time to fix it (I am not doing AR any more). The repo is updated with latest SDK (as of July 2018), but the app sometimes crashes (race condition depending on whether Vuforia or LibGDX initialises first - seems to require some architectural changes compared to previous versions) and the model is not rendered (but the transform matrix seems to be computed correctly).

I'll try to fix it if I find some time in the future, but for now, consider it dead. I'm happy to give maintainer rights to anyone interested in keeping this alive.

If you wish to see the version working with older Vuforia SDK, see [here](https://github.com/daemontus/VuforiaLibGDX/tree/2fecef3c2d4699f8dcc9c2813a232f369e640013).

# VuforiaLibGDX
Example of Vuforia and LibGDX integration for 3D model rendering in augmented reality. 

For a more detailed explenation, see this [article](https://treeset.wordpress.com/2016/06/12/vuforia-and-libgdx-3d-model-renderer/).

Note: The app will freeze for a few seconds after start up while loading the 3D model, do not panic :)

##### If you are interested in older versions of Vuforia/LibGDX, check out [this branch](https://github.com/daemontus/VuforiaLibGDX/tree/old).

![Example screenshot](https://treeset.files.wordpress.com/2016/06/screenshot_2016-06-12-21-13-23.png)
"
mkuthan/example-ddd-cqrs-server,master,40,16,2013-11-08T19:42:16Z,672,0,Example DDD/CQRS based on Implementing Domain Driven Design book written by Vaughn Vernon,cqrs ddd spring,"[![Build Status](https://travis-ci.org/mkuthan/example-ddd-cqrs-server.png)](https://travis-ci.org/mkuthan/example-ddd-cqrs-server)

[Presentation](https://docs.google.com/presentation/d/1PlKF4OW5ARqUbqSUwL4D1syEwxw-PmX4KLJObPeYQyI/pub?start=false&loop=false&delayms=3000)
"
sadra/SOLID,master,33,5,2019-01-11T08:37:34Z,12256,3,S.O.L.I.D Principles Example,java solid solid-principles,"# SOLID
S.O.L.I.D Principles Example
"
kowalcj0/cucumber-testng-parallel-selenium,master,27,39,2014-04-11T15:14:12Z,192,1,An example project that shows how to run Cucumber tests in multiple browsers simultaneously using Selenium and TestNG,,"This example project is based on few other projects:
* [Cucumber-JVM-Parallel](https://github.com/tristanmccarthy/Cucumber-JVM-Parallel)
* [java-parallel](https://github.com/cucumber/cucumber-jvm/tree/java-parallel-example/examples/java-parallel)
* [java-webbit-websockets-selenium](https://github.com/cucumber/cucumber-jvm/tree/java-parallel-example/examples/java-webbit-websockets-selenium)

It allows you to run Cucumber features (tests/scenarios) in multiple browsers simultaneously using Selenium (WebDriver) and TestNG.


## Running features in IDE
Tested in IntelliJ Idea 13.1.1
To run all stories from IDE only in Firefox, simply right click on one of the files:
* cucumber.examples.java.testNG.runners.RunCukesTestInChrome
* cucumber.examples.java.testNG.runners.RunCukesTestInFirefox

And chose ""Run ...""
(Yes, choosing RunCukesTestInChrome will also run tests in FF!)


To run all stories simultaneously in both browsers (Chrome and Firefox) right click on one of the files:
* src/test/resources/TestNGRunTestsLocally.xml
* src/test/resources/TestNGRunTestsRemotely.xml

And chose ""Run ...""

To run just one selected feature, change the feature name in the class below:

    cucumber.examples.java.testNG.runners.RunSingleFeature

And as in previous example, right click on this class and chose ""Run ...""


## Running features from CLI
Run tests using local browsers:

    mvn clean install

Run tests using browsers running on remote nodes:

    mvn clean install -P runTestsRemotely


## Viewing the results
All Cucumber reports [html, json, xml, js] are in: target/cucumber-report


## How to download WebDriver binaries automatically
This project is using Mark Collin's ""selenium-standalone-server-plugin"" which is a Maven plugin that can download
WebDriver binaries automatically.
Once you configure the plugin to your liking, then:

    mvn clean install -P downloadDriverBinaries

The pom.xml is currently configured to download only a Chrome driver binary for 64bit Linux OSes.
If you can't download desired driver binary, then check if its URL and checksum specified in:

    src/main/resources/RepositoryMapForMavenWebDriverBinaryDownloaderPlugin.xml

are correct. If not, then modify this file accordingly.


## Jenkins configuration
I'll add a tutorial later

### tools that need to be installed on the Jenkins Host machine
maven 2/3

### List of useful plugins
AnsiColor
Cucumber json test reporting.
cucumber-perf
cucumber-reports
GIT client plugin
GIT plugin
Hudson Locks and Latches plugin
Maven Integration plugin
SSH Credentials Plugin
TestNG Results Plugin
Xvfb plugin"
abhioncbr/Kafka-Message-Server,master,254,147,2014-03-04T11:59:46Z,2436,1,Example application based on Apache Kafka framework to show it usage as distributed message server. Exploring this sample application help users to understand how good and easy is Apache Kafka usage.,,"Kafka-Message-Server Example Application
========================================

Apache kafka is yet another precious gem from Apache Software Foundation. Kafka was originally developed at Linkedin and later on became a member of Apache project.  Apache Kafka is a distributed publish-subscribe messaging system. Kafka differs from traditional messaging system as it is designed as distributed system, persists messages on disk and supports multiple subscribers. 

Kafka-Message-Server is an sample application for demonstrating kafka usage as message-server. Please follow the below instructions  for productive use of the sample application.

1) Download Apache kafka version 0.8.0 zip file from kafka download page and extract it.

2) There is no need to set hadoop or zookeper in your system. You can use zookeper startup script present in bin folder of Kafka.

3) For the execution of the sample application - copy 'kafka-message-server-example-0.8.0.jar' in to the kafka folder where  'kafka_2.8.0-0.8.0.jar' is present. Sample application is dependent on 'commons-cli-1.1.jar'. Copy 'commons-cli-1.1.jar' in to the 'libs' folder of the Apache Kafka.

4) Copy following scripts from 'Kafka-Message-Server-Example/config' folder in to 'bin' folder of kafka
   a) java-mail-content-producer.sh
   b) java-mail-consumer-demo.sh
   c) java-mail-producer-consumer-demo.sh
   d) java-mail-producer-demo.sh
   
   five execution permission to the scripts using chmod command.
   
5) Copy 'commons-cli-1.1.jar' in to the Kafka 'libs' folder.

6) Start Zookeper server using command - bin/zookeeper-server-start.sh config/zookeeper.properties

7) Start Kafka server using command - bin/kafka-server-start.sh config/server.properties

8) Start mail content creation program using command - bin/java-mail-content-producer.sh -path [directory-path]

9) Start message server mail producer using command - bin/java-mail-producer-demo.sh -path [same directory path given above] -topic [topic name]

10) Start message server mail consumer using command - bin/java-mail-consumer-demo.sh -topic [same topic name given above]
"
suikki/simpleSDL,master,46,6,2017-06-01T23:39:56Z,233,2,A simple crossplatform libSDL cmake build environment example/test.,,"
# simpleSDL

A simple crossplatform libSDL cmake build environment example/test. This is still somewhat
work in progress and is missing support for iOS builds.

Tested to build and run successfully with:
  - Android: gradle + cmake
  - Windows: mingw-w64
  - Windows: Visual Studio 2015
  - Linux (Ubuntu): GCC
  - Mac: (Just building a simple executable, no bundle)
  - Emscripten


Building on Android
-------------------

You need to have NDK and cmake plugins installed on Android SDK
(https://developer.android.com/studio/projects/add-native-code.html)

1. Copy/clone `SDL` to the `contrib/` directory

1. run `gradlew assemble` in `platforms/android`

   or

   Open the project in Android Studio and build using the IDE. NOTE: Make sure
   to open the `platforms/android/` dir. Android studio can also
   open the root dir but it's not recognized as an android project.

The included android gradle cmake project is pretty much what Android Studio
generates when you create a new empty app with native cmake support. Just
pointing to the CmakeLists.txt in the project root.

> NOTE:
>
> Currently the SDL2 Android Java code is included in this project. This is not a very good system
> as it easily leads to the SDL Java and native code being out of sync (i.e. code from different versions of SDL).
> You should replace the Java sources from the version of SDL you are using to make sure they are from the same version.


Todo
----

- Nicer way to include SDL in an android project. [A missing android feature](https://issuetracker.google.com/issues/37134163) is needed to include
prebuilt native library with headers in a .aar package.
- iOS build
- Add instructions how to build on all platforms
"
damienbeaufils/spring-data-jpa-encryption-example,master,52,24,2017-06-29T06:46:06Z,131,0,An example of how to encrypt and decrypt entity fields with JPA converters and Spring Data JPA,,"# spring-data-jpa-encryption-example

[![Build Status](https://travis-ci.org/damienbeaufils/spring-data-jpa-encryption-example.svg?branch=master)](https://travis-ci.org/damienbeaufils/spring-data-jpa-encryption-example)

An example of how to encrypt and decrypt entity fields with JPA converters and Spring Data JPA.
See [blog post](https://damienbeaufils.dev/blog/how-to-properly-encrypt-data-using-jpa-converters-and-spring-data-jpa/).

## Requirements

Java 11


## How is encryption enabled

### Entity

There is a `User` entity which have different fields: `id`, `firstName`, `lastName`, `email`, `birthDate` and `creationDate`.

All fields except `id` are encrypted in database using AES algorithm.

### Repository

There is a simple `UserRepository` which extends Spring Data `JpaRepository`.

### Converters

Encryption is enabled on fields using different JPA converters: `StringCryptoConverter`, `LocalDateCryptoConverter` and `LocalDateTimeCryptoConverter`. 
This is verified with `UserRepositoryTest` integration test.

All converters are unit tested.

### Encryption key

Encryption key is empty by default (see `example.database.encryption.key` configuration key in `application.yml`).
 
You have to provide an encryption key in configuration or specify it in options when running application.


## Run tests

```
./gradlew check
```
"
thoersch/spring-boot-rest-api-seed,master,30,21,2015-02-13T04:30:10Z,109,0,"A seed and example project for a RESTful api using Springboot, Jersey, Hibernate and Jackson",,"## Description

This is a seed and example project for building a RESTful API using the following technologies:

* Java 8
* Spring Boot
* Jersey
* Hibernate
* Jackson
* Spring DI
* Postgresql

## Install Postgresql
The seed project is using PostgreSQL 9.3+ and can be installed quite easily on mac, linux or windows following a [guide](https://www.codefellows.org/blog/three-battle-tested-ways-to-install-postgresql)

## Create the database user

```
CREATE ROLE ""SpringBootUser"" LOGIN
  ENCRYPTED PASSWORD 'md513445691374efba1aaee7b0912e63af3'
  SUPERUSER INHERIT CREATEDB NOCREATEROLE NOREPLICATION;
```

## Create the database

```
CREATE DATABASE ""SpringBootRestApi""
  WITH ENCODING='UTF8'
       OWNER=""SpringBootUser""
       CONNECTION LIMIT=-1;
```

## Build the project

```
mvn clean install
```

## Run the migrations

```
mvn liquibase:update -P local
```

## Running the API

Start the service by running the following command:

```
java -jar target/spring-boot-rest-api-seed-1.0-SNAPSHOT.jar
```

You can now test the service by consuming the api on port 8080. Some routes you can try in your browser (GET requests):


* http://127.0.0.1:8080/users

* http://127.0.0.1:8080/users/1

* http://127.0.0.1:8080/books

* http://127.0.0.1:8080/books/2

* http://127.0.0.1:8080/users/1/books


You can add new content by posting payloads like below:

```
POST 127.0.0.1:8080/users
Content-Type: application/json
{
  ""firstName"": ""you"",
  ""lastName"": ""here"",
  ""emailAddress"": ""you.here@example.com"",
  ""profilePicture"": ""yourface.png""
}
```
## License

Copyright © 2014 Tyler Hoersch

Distributed under the Eclipse Public License either version 1.0 or (at
your option) any later version.
"
gregwhitaker/gradle-monorepo-example,master,26,11,2019-02-10T16:56:57Z,233,1,Example of building projects in a monorepo using Gradle Composite Builds,gradle gradle-build gradle-compositebuild gradle-java monorepo,"# gradle-monorepo-example

An example of building projects in a monorepo using [Gradle Composite Builds](https://docs.gradle.org/current/userguide/composite_builds.html).

## Repository Structure
The repository contains four projects each with their own Gradle configurations.

Projects A, B, and C have dependencies on one another:

    [project-a] -- DEPENDS --> [project-b] -- DEPENDS --> [project-c]
    
Project D has no dependencies on the other projects:
    
    [project-d]

## Running the Example
Follow the steps below to run the example:

### Build Project A
Run the following commands to build [project-a](project-a):

1. Change the working directory to [project-a](project-a):

        cd project-a
        
2. Run the following command to generate classes for the project:

        ./gradlew classes --info
        
    Notice in the command output that [project-b](project-b) and [project-c](project-c) was also configured and built, 
    but [project-d](project-d) was neither configured nor built:

        > Configure project :project-b
        Evaluating project ':project-b' using build file '/Users/greg/workspace/gradle-compositebuild-example/project-b/build.gradle'.
        Registering project ':project-b' in composite build. Will substitute for module 'example.gcb.gregwhitaker:project-b'.
        [composite-build] Configuring build: /Users/greg/workspace/gradle-compositebuild-example/project-c
        
        > Configure project :project-c
        Evaluating project ':project-c' using build file '/Users/greg/workspace/gradle-compositebuild-example/project-c/build.gradle'.
        Registering project ':project-c' in composite build. Will substitute for module 'example.gcb.gregwhitaker:project-c'.
        
        > Configure project :
        Evaluating root project 'project-a' using build file '/Users/greg/workspace/gradle-compositebuild-example/project-a/build.gradle'.
        All projects evaluated.
        Selected primary task 'classes' from project :
        Found project 'project :project-b' as substitute for module 'example.gcb.gregwhitaker:project-b'.
        Selected primary task ':jar' from project :
        Found project 'project :project-c' as substitute for module 'example.gcb.gregwhitaker:project-c'.
        Selected primary task ':jar' from project :
        Executing project-b tasks [:jar]
        Executing project-c tasks [:jar]
        Tasks to be executed: [task ':compileJava', task ':processResources', task ':classes']
        :project-b:processResources (Thread[Task worker for ':project-b',5,main]) started.
        :project-c:compileJava (Thread[Task worker for ':project-c' Thread 3,5,main]) started.
        :processResources (Thread[Task worker for ':' Thread 4,5,main]) started.
        
        > Task :project-b:processResources NO-SOURCE
        Skipping task ':project-b:processResources' as it has no source files and no previous output files.
        :project-b:processResources (Thread[Task worker for ':project-b',5,main]) completed. Took 0.005 secs.
        
        > Task :processResources NO-SOURCE
        Skipping task ':processResources' as it has no source files and no previous output files.
        :processResources (Thread[Task worker for ':' Thread 4,5,main]) completed. Took 0.004 secs.
        
        > Task :project-c:compileJava UP-TO-DATE
        Skipping task ':project-c:compileJava' as it is up-to-date.
        :project-c:compileJava (Thread[Task worker for ':project-c' Thread 3,5,main]) completed. Took 0.007 secs.
        :project-c:processResources (Thread[Task worker for ':project-c' Thread 3,5,main]) started.
        
        > Task :project-c:processResources NO-SOURCE
        Skipping task ':project-c:processResources' as it has no source files and no previous output files.
        :project-c:processResources (Thread[Task worker for ':project-c' Thread 3,5,main]) completed. Took 0.0 secs.
        :project-c:classes (Thread[Task worker for ':project-c' Thread 3,5,main]) started.
        
        > Task :project-c:classes UP-TO-DATE
        Skipping task ':project-c:classes' as it has no actions.
        :project-c:classes (Thread[Task worker for ':project-c' Thread 3,5,main]) completed. Took 0.0 secs.
        :project-c:jar (Thread[Task worker for ':project-c' Thread 3,5,main]) started.
        
        > Task :project-c:jar UP-TO-DATE
        Skipping task ':project-c:jar' as it is up-to-date.
        :project-c:jar (Thread[Task worker for ':project-c' Thread 3,5,main]) completed. Took 0.002 secs.
        :project-b:compileJava (Thread[Task worker for ':project-b' Thread 2,5,main]) started.
        
        > Task :project-b:compileJava UP-TO-DATE
        Skipping task ':project-b:compileJava' as it is up-to-date.
        :project-b:compileJava (Thread[Task worker for ':project-b' Thread 2,5,main]) completed. Took 0.005 secs.
        :project-b:classes (Thread[Task worker for ':project-b' Thread 2,5,main]) started.
        
        > Task :project-b:classes UP-TO-DATE
        Skipping task ':project-b:classes' as it has no actions.
        :project-b:classes (Thread[Task worker for ':project-b' Thread 2,5,main]) completed. Took 0.0 secs.
        :project-b:jar (Thread[Task worker for ':project-b' Thread 2,5,main]) started.
        
        > Task :project-b:jar UP-TO-DATE
        Skipping task ':project-b:jar' as it is up-to-date.
        :project-b:jar (Thread[Task worker for ':project-b' Thread 2,5,main]) completed. Took 0.002 secs.
        :compileJava (Thread[Task worker for ':' Thread 4,5,main]) started.
        
        > Task :compileJava UP-TO-DATE
        Skipping task ':compileJava' as it is up-to-date.
        :compileJava (Thread[Task worker for ':' Thread 4,5,main]) completed. Took 0.004 secs.
        :classes (Thread[Task worker for ':' Thread 4,5,main]) started.
        
        > Task :classes UP-TO-DATE
        Skipping task ':classes' as it has no actions.
        :classes (Thread[Task worker for ':' Thread 4,5,main]) completed. Took 0.0 secs.

        BUILD SUCCESSFUL in 0s

### Build Project D
Run the following commands to build [project-d](project-d):

1. Change the working directory to [project-d](project-d):

        cd project-d
        
2. Run the following command to generate classes for the project:

        ./gradlew classes --info
        
    Notice that only [project-d](project-d) was configured and built:
        
        > Configure project :
        Evaluating root project 'project-d' using build file '/Users/greg/workspace/gradle-compositebuild-example/project-d/build.gradle'.
        All projects evaluated.
        Selected primary task 'classes' from project :
        Tasks to be executed: [task ':compileJava', task ':processResources', task ':classes']
        :compileJava (Thread[Task worker for ':',5,main]) started.
        
        > Task :compileJava UP-TO-DATE
        Skipping task ':compileJava' as it is up-to-date.
        :compileJava (Thread[Task worker for ':',5,main]) completed. Took 0.006 secs.
        :processResources (Thread[Task worker for ':',5,main]) started.
        
        > Task :processResources NO-SOURCE
        Skipping task ':processResources' as it has no source files and no previous output files.
        :processResources (Thread[Task worker for ':',5,main]) completed. Took 0.0 secs.
        :classes (Thread[Task worker for ':',5,main]) started.
        
        > Task :classes UP-TO-DATE
        Skipping task ':classes' as it has no actions.
        :classes (Thread[Task worker for ':',5,main]) completed. Took 0.0 secs.
        
        BUILD SUCCESSFUL in 0s
        
## Working in IntelliJ
IntelliJ supports Gradle Composite Builds and will automatically open any included builds for a project.

To see this in action, open [project-a](project-a) in your IntelliJ IDE. You will notice that IntelliJ automatically
opens [project-b](project-d) because it is a dependency of the current project.

![intellij](intellij_screenshot.png)

## Bugs and Feedback
For bugs, questions, and discussions please use the [Github Issues](https://github.com/gregwhitaker/gradle-monorepo-example/issues).

## License
MIT License

Copyright (c) 2019 Greg Whitaker

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"
mitchtabian/Bound-Services-with-MVVM,master,49,17,2018-12-11T16:03:09Z,131,0,A simple example of how to bind an activity to a service while using MVVM,android-bound-service android-mvvm android-mvvm-architecture android-services,"# Bound-Services-with-MVVM
A simple example of how to bind a service while using MVVM

<a href=""https://codingwithmitch.com/blog/bound-services-on-android/"" target=""_blank"">Read the blog post</a>

Or 

<a href=""https://www.youtube.com/watch?v=_xNkVNaC9AI"" target=""_blank"">Watch the video</a>

##### Note: The structure of this project goes against the recommendation of a Google developer. See <a href=""https://medium.com/androiddevelopers/viewmodels-and-livedata-patterns-antipatterns-21efaef74a54"" target=""_blank"">this post</a> for more information.
"
berndruecker/ticket-booking-camunda-8,master,35,33,2020-07-15T08:30:04Z,438,4,"A ticket booking example using Camunda Cloud, RabbitMQ, REST and two sample apps (Java Spring Boot and NodeJS)",,"# Ticket Booking Example

![Ticket Booking Process](booking-service-java/src/main/resources/ticket-booking.png)

A ticket booking example using 
* Camunda Platform 8, 
* RabbitMQ,
* Java Spring Boot App
* NodeJS App

![Architecture Overview](architecture.png)

# How To Run

<a href=""http://www.youtube.com/watch?feature=player_embedded&v=m3MYuRKLZa8"" target=""_blank""><img src=""http://img.youtube.com/vi/m3MYuRKLZa8/0.jpg"" alt=""Walkthrough"" width=""240"" height=""180"" border=""10"" /></a>


## Run RabbitMQ locally

```
docker run -p 15672:15672 -p 5672:5672 rabbitmq:3-management
```

* http://localhost:15672/#/queues/
* User: guest
* Password: guest


## Create Camunda Platform 8 SaaS Cluster

* Login to https://camunda.io/
* Create a new cluster
* When the new cluster appears in the console, create a new set of API client credentials.
* Copy the client credentials into
  * Java App  `booking-service-java/src/main/resources/application.properties`
  * Node App `fake-services-nodejs/.env`


## Run NodeJs Fake Services

If you want to understand the code, please have a look into this get started tutorial: https://github.com/camunda/camunda-platform-get-started/tree/main/nodejs

```
cd fake-services-nodejs
npm update
ts-node src/app.ts
```

## Run Java Ticket Booking Service

If you want to understand the code, please have a look into this documentation: https://github.com/camunda/camunda-platform-get-started/tree/main/spring

```
mvn package exec:java -f booking-service-java\
```

## Test

```
 curl -i -X PUT http://localhost:8080/ticket
```

Simulate failures by:

```
curl -i -X PUT http://localhost:8080/ticket?simulateBookingFailure=seats
curl -i -X PUT http://localhost:8080/ticket?simulateBookingFailure=ticket
```
"
yrizk/FragmentAnimations,master,28,6,2014-12-22T00:10:53Z,2099,0,Shared Element Animation Transition example adapted for Fragments. ,,"FragmentAnimations
==================

Shared Element Animation Transition example adapted for Fragments. 
DevBytes, hosted by Chet Hasse, included a tutorial about overriding the standard window manager at this link: https://www.youtube.com/watch?v=CPxkoe2MraA. 
yrizk adapted this example to play a shared element animations between two fragments between the same activity using ViewAnimatorProperty API , which is available since API 12+ 

Special thanks to pabloff9 for some updates, definetly was not expecting that. if you feel so inclined, feel free to conribute. 
Let me warn you, the .gitignore is in bad shape (nudge nudge). 
"
rdblue/parquet-avro-protobuf,master,29,10,2015-10-30T18:37:16Z,176,1,Example: Convert Protobuf to Parquet using parquet-avro and avro-protobuf,,"## Converting Protobuf to Parquet via Avro

### Why?

This example shows how to convert a Protobuf file to a Parquet file using
Parquet's Avro object model and Avro's support for protobuf objects. Parquet
has a module to work directly with Protobuf objects, but this isn't always a
good option when writing data for other readers, like Hive.

The reason is that Parquet and Protobuf use the same schema definitions. Both
support required, optional, and repeated data fields and use repeated to encode
arrays.  The mapping from Protobuf to Parquet is always 1-to-1.

Other object models, like Avro, allow arrays to be null or to contain null
elements and have an annotation, [LIST][list-annotation-docs], for encoding
these more complicated structures in Parquet's schema format using extra hidden
layers. More object models use this structure than bare repeated fields, so it
is desirable to use it when converting.

The easiest way to use the complex LIST stucture for protobuf data is to write
using parquet-avro and use Avro's support for Protobuf objects, avro-protobuf.

[list-annotation-docs]: https://github.com/apache/parquet-format/blob/master/LogicalTypes.md

### Code

Conversion is done in the [`writeProtobufToParquetAvro`method][write-proto-method].
The first step is to get a handle to Avro's Protobuf object model using
`ProtobufData.get()`.

```Java
ProtobufData model = ProtobufData.get();
```

The Protobuf object model is used to convert the Protobuf data class,
`ExampleMessage`, into an Avro schema.

```Java
Schema schema = model.getSchema(ExampleMessage.class);
```

Then, the Protobuf object model is passed to the builder when creating a
`ParquetWriter`.

```Java
ParquetWriter<ExampleMessage> parquetWriter = AvroParquetWriter
    .<ExampleMessage>builder(new Path(parquetFile))
    .withDataModel(model) // use the protobuf data model
    .withSchema(schema)   // Avro schema for the protobuf data
    .build();
```

Once the parquet-avro writer is configured to use Avro's protobuf support, it
is able to write protobuf messages to the outgoing Parquet file.

```Java
ExampleMessage m;
while ((m = ExampleMessage.parseDelimitedFrom(protoStream)) != null) {
  parquetWriter.write(m);
}
```

[write-proto-method]: https://github.com/rdblue/parquet-avro-protobuf/blob/master/src/main/java/com/example/ProtobufToParquet.java#L59

### Result

After running the example, you will end up with `example.parquet` in temp.
Using `parquet-tools` to view the schema shows the correct 3-level list
representation.

```
message com.example.Example$.ExampleMessage {
  required int64 id;
  required group strings (LIST) {
    repeated group list {
      required binary element (UTF8);
    }
  }
}
```

The original protobuf schema did not include the LIST annotation or the
additional levels needed for compatibility.

```
message ExampleMessage {
  required int64 id = 1;
  repeated string strings = 2;
}
```

The data looks like this when converted to JSON:

```
{""id"": 0, ""strings"": [""a"", ""b"", ""c""]}
{""id"": 1, ""strings"": [""b"", ""c"", ""d""]}
{""id"": 2, ""strings"": [""c"", ""d"", ""e""]}
{""id"": 3, ""strings"": [""d"", ""e"", ""f""]}
{""id"": 4, ""strings"": [""e"", ""f"", ""g""]}
```
"
RoaringCatGames/libgdx-ashley-box2d-example,master,42,5,2015-12-09T05:17:35Z,3591,0,An example game using Box2d with Ashley ECS,,"#Example libGDX using Box2D and Ashley ECS

This is a starter project available to get up and running with libgdx using Box2D in an Ashley ECS based structure. The code is very basic, and the game does very little at this time. This example will give you a starting point with:

 1. Configured texture-packer module that is wired into the gradle system so textures are re-packed when you run (see core/build.gradle)
 2. Simple Texture, Transform, Animation, State, and Body components.
 3. RenderingSystem that accounts for world units to pixels and Z indexing (based heavily on the ashley-superjumper example)
 4. AnimationSystem that supports animations for different States.
 5. PhysicsSystem that will run the World.step() and update TransformComponents for any physics Entities.
 6. A basic splash screen that will show the splash image and a progress bar based on the AssetManager loading progress.
 7. An Asset utility class to setup your AssetManager loading, and retrieval of assets in one location (you'll want to add code to this file to expose more assets)
 8. A crude Screen dipatching pattern that can allow each screen to signal when it has ended and needs to move to the next. You can implement your own IScreenDispatcher or modify the existing to do more complex screen swapping.
 9. Added the required `gdx.reflect.include` options for Ashley Components and Systems so that the GWT Html build works.
 
#Running

The project was created with the libGDX [setup application](https://libgdx.badlogicgames.com/download.html), and is [gradle](https://docs.gradle.org/current/release-notes) based. You can import it into your IDE of choice as a Gradle project. 

From the command line you can run the project:

    git clone https://github.com/RoaringCatGames/libgdx-ashley-box2d-example.git
    cd libgdx-ashley-box2d-example
    ./gradlew texture-packer:run desktop:run
    
NOTE: You only need to run the ```texture-packer:run``` target once after pulling down the project. If you add/update art assets in the texture-packer project, you'll need to re-run the ```texture-packer:run``` target

"
arhohuttunen/spring-boot-hexagonal-architecture,main,100,19,2023-03-20T09:56:11Z,166,0,This is the repository containing an example application for my blog post about Hexagonal Architecture with Spring Boot.,,"# Hexagonal Architecture With Spring Boot

![Gradle Build](https://github.com/arhohuttunen/spring-boot-hexagonal-architecture/workflows/Gradle%20Build/badge.svg)

This is the repository containing an example application for my blog post about [Hexagonal Architecture With Spring Boot](https://www.arhohuttunen.com/hexagonal-architecture-spring-boot/).
"
adamsp/FragmentStatePagerIssueExample,master,30,11,2014-02-18T08:11:57Z,376,3,Example of an issue around state restoration for fragments in a FragmentStatePagerAdapter,,
SapienLLCdev/Cthulhu,master,27,8,2019-01-30T18:01:28Z,31215,3,Arduino Library and Example code for using the Cthulhu Shield,,"## Cthulhu_Shield_Arduino

![Cthulhu Shield](https://ksr-ugc.imgix.net/assets/023/898/915/445716db19d7a5d34502a584e91812b8_original.gif?ixlib=rb-1.1.0&w=680&fit=max&v=1548532149&auto=format&gif-q=50&q=92&s=bc67d6bd83fecd3067255431a1aef305)

This is a library for using the Cthulhu Shield sensory substitution/augmentation development kit created by [Sapien LLC](http://sapienllc.com/). 

If you like what you see here, you can purchase a Cthulhu Shield [here!](https://sapienllc.com/shop/)

The Cthulhu Shield is an open-source Arduino Uno and Arduino Mega compatible sensory substitution/sensory augmentation device. It uses an 18 electrode grid to tactiley display signals on the tongue. The electrodes on the array can be activated with patterns of electrical pulses to depolarize nerve membranes in the tongue to create different types of touch sensations. You can use these touch sensations to draw shapes or simple images on the tongue, feel different sound frequencies, or receive turn by turn directions with your tongue.

Additionally, the Cthulhu Shield can sense whether or not your tongue is in contact with different electrodes using capacitive sensing. You can use the Cthulhu Shield to send keystrokes to your computer, control the cursor, or even control a mobility device. 

In this repository, we have provided a number of example projects to get you started with your Cthulhu, but we encourage you to experiment and build your own senses!

There are some awesome uses of sensory substitution already out there. For more information on these uses, or sensory substitution or augmentation in general, take a look at the links below. 
* [Brainport](https://www.youtube.com/watch?v=OKd56D2mvN0)
* [Wikipedia](https://en.wikipedia.org/wiki/Sensory_substitution)
* [Hear with your tongue](https://source.colostate.edu/words-mouth-csu-device-lets-hear-tongue/)
* [TedTalk](https://www.ted.com/talks/david_eagleman_can_we_create_new_senses_for_humans?language=en)


# Repository Contents:

* [Bare Minimum](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/BareMinimum)
* [Serial Input](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/SerialInput)
* [Accelerometer Example](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/accelerometer_Cthulhu_example)
* [GPS Directions](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/directions_example)
* [Make Patterns](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/make_patterns)
* [Thermal Camera](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/mega_heat_cam_with_shield)
* [Tactile Button](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/tactile_button_example)
* [Tactile Cursor](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/tactile_cursor)
* [Leonardo Tactile Cursor](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/Leonardo_tactile_cursor)
* [Tactile Keypad](https://github.com/SapienLLCdev/Cthulhu/tree/master/examples/tactile_keypad)
* [Cthulhu Camera Demo](https://github.com/SapienLLCdev/Cthulhu/tree/master/Android%20Examples/CthulhuCameraDemo)

# Cthulhu Shield Schematic:

![Cthulhu Shield Schematic](https://github.com/SapienLLCdev/Cthulhu/blob/master/Cthulhu_Shield_Rev2e.jpg).

# How to Use the Cthulhu Shield:

**Power:**
The Cthulhu Shield is made to be powered by plugging it directly into an Arduino Uno or Mega, and connecting the arduino to a USB cable attached to a properly grounded computer, or a smartphone or external battery pack. Users should not power their Arduino/Cthulhu Shield system with an AC wall adaptor, as a small number of these adaptors are not properly grounded or are otherwise unsafe and can cause injury or death if used with any electronic device.

**Input:**
When used with an Arduino Uno, the Cthulhu Shield can receive information directly from the USB port connected to a computer or smartphone, or via broken out Serial pins (RX, TX) which can used to communicate with other Arduinos/microcontrollers, or embedded devices such as Bluetooth modules or sensors with serial outputs. With an Arduino Mega, the extra IO pins can be leveraged to receive Digital or Analog signals that can be used to change the tactile output of the Cthulhu Shield. 

**Output:**
When used with an Arduino Uno, the Cthulhu Shield can send information directly via USB port connected to a computer or smarptphone, or via broken out Serial pins (RX, TX) which can used to communicate with other Arduinos/microcontrollers, or embedded devices such as Bluetooth modules or sensors with serial outputs. With an Arduino Mega, the extra IO pins can be leveraged to send Digital or Analog signals to external devices. 

**Electrode Control:**
Different types of sensations can be created on different electrodes and tongue locations by changing the pattern of pulses generated on each electrode. This can be done with the Cthulhu.UpdateStimuli() function. A user changes values in six (6), eighteen (18) element arrays. The values in these arrays correspond to whether one of the 18 electrodes is on or off, and what type of pulse, and pattern of pulses, is created on each electrode. Changing these patterns changes the type and quality of the sensation perceived by the user. This library was adapted from [work by Kurt Kaczmarek](https://www.sciencedirect.com/science/article/pii/S1026309811001702) and altered for the needs of our early research at Sapien LLC.

**Tongue Position Sensing:**
During electrotactile stimulation with the Cthulhu Shield, the Arduino can quickly sense the electrical potential on a given electrode, which changes if the tongue is in contact with the electrode or not. Placing your tongue on certain electrodes but not others, or swiping your tongue across different electrodes, can be detected by the Arduino, which can then send serial information (or with minor hacking, keystrokes and HID signals) to a computer or smartphone via the USB port, or external Bluetooth modules. 

Currently, tongue-position-sensing is supported only on ADC enabled Arduino pins (A0-A5 on the Uno and Mega). Position sensing on digital only pins should be possible and may be implemented in the near future. 

# How to Use this Repository:

If you are new to Github, Sparkfun has created an [excellent Github tutorial](https://learn.sparkfun.com/tutorials/using-github/all). If you want to get up and running quickly, just take a look at the [Download ZIP](https://learn.sparkfun.com/tutorials/using-github/all#download-zip) section.

Similarly, if you are new to Arduino, Sparkfun once again has a great [guide to installing Arduino Libraries](https://learn.sparkfun.com/tutorials/installing-an-arduino-library). After downloading the .ZIP file of the library you want from Github, follow the instructions above to integrate it with the Arduino IDE.

Please see the README files in the examples linked above for more information on their specific implementations!
"
bennylut/hello-angular2-universal-j2v8,master,34,10,2016-05-12T18:46:04Z,6370,0,A simple example of using angular-universal with java backend using J2V8,,"# Angular-Universal with Java backend using J2V8
This repository contains a simple (and very initial) example of using angular-universal with java backend using J2V8.

##Features:
- Rendering using angular universal from java using J2V8
- Serving both the application and other rest endpoint from java using sparkjava
- Basic live-reload support for the universal server build 
- Linux x64 only
- Multi-Node (each in its own thread) rendring
- Java level cache for increasing performance (using the cache assumes that the render function is pure)
- The renderer itself (not including the usage example) dependes on J2V8 and Guava

##TODO:
- Fetch J2V8 from maven central
- Support other platforms
- Performance tests 
- Documentation and code-cleanup
- Orginize project structure
- Implement a more complex client side application
- ~~Check if can model the bootstrap configuration object in java in order to remove the need for server.js completely~~ 
- ~~Cleanup and improvement of the JavaEngine (currently almost blindly based on the expressEngine)~~
- ~~Remove the direct gson dependency~~
- ~~Expose the cache through configuration~~
- ~~Make the configuration object api fluid~~

##Requirements
- x64 Linux (tested on ubuntu 16.04)
- Java 8
- Maven
- NPM
 
##Running Instructions
1. Clone the repository
2. Install node dependencies (`npm install`)
3. Build the java server(`mvn clean package`)
4. Build&Watch angular-universal + angular client side code (`npm start`)
5. Execute the java server (`mvn -e exec:java -Dexec.mainClass=""hello.ngu.j2v8.Server""`)
6. Open your browser on `http://localhost:3000/app/`

##Links
- [Angular-Universal](https://github.com/angular/universal)
- [J2V8](https://github.com/eclipsesource/J2V8)
- [Spark-Java](http://sparkjava.com/)
- [Angular 2 Universal starter kit](https://github.com/angular/universal-starter)

###Thanks and credits
- The Angular-Universal-related files are based on Angular 2 Universal starter kit with very small modifications
- Special thanks to @irbull for the great J2V8 library and he's help.
"
twitch4j/twitch4j-chatbot,master,30,9,2017-02-15T22:11:45Z,101,0,Chatbot example using the Twitch4J API [https://github.com/twitch4j/twitch4j],chatbot hacktoberfest twitch4j,"# Twitch4J - Chatbot Template

Support:

[![Discord](https://img.shields.io/badge/Join-Twitch4J-7289DA.svg?style=flat-square)](https://discord.gg/FQ5vgW3)
[<img src=""https://discordapp.com/api/guilds/143001431388061696/widget.png?style=shield"">](https://discord.gg/FQ5vgW3)

--------

## A quick note:
This Chatbot is part of the [Twitch4J API](https://github.com/PhilippHeuer/twitch4j) project.

## Chat Token
You can generate a oauth chat token using the `Twitch Chat OAuth Password Generator`:
http://twitchapps.com/tmi/
"
colintheshots/RxJavaExamples,master,45,1,2014-11-03T22:26:38Z,140,0,Several simple examples demonstrating how to use RxJava along with a few exercises to try.,,"RxJavaExamples
==============

Several simple examples demonstrating how to use RxJava along with a few exercises to try as seen in the comments. All code here are simple Java examples wrapped up so you can try them in Android Studio's console.

         * Use this online documentation:
         *  https://github.com/ReactiveX/RxJava/wiki/Filtering-Observables
         *
         * Try the following Rx tricks:
         *
         *  1. takeLast() the last 2 results.
         *  2. elementAt() to obtain value #567.
         *  3. take() the first 10 results.
         *  4. Do #3 and also filter() only values divisible by two.
         *
         *      Keep in mind that order of operations matters!
         *      Use bigInteger.mod(BigInteger.valueOf(2)).equals(BigInteger.ZERO) to test for even values.
         *
         * Use this online documentation:
         *  https://github.com/ReactiveX/RxJava/wiki/Transforming-Observables
         *
         *  5. Use map() to convert from BigInteger values to Long values and take only the first 50 results.
"
JohT/showcase-quarkus-eventsourcing,master,58,11,2019-09-15T07:15:52Z,11316,7,Shows an example on how to use AxonFramework in conjunction with microprofile on quarkus ,axon axon-framework event-driven event-sourcing eventsourcing jasmine-tests microprofile poc quarkus reactive server-sent-events showcase sse,"# showcase-quarkus-eventsourcing

Shows an example on how to use [AxonFramework][AxonFramework] in conjunction with [MicroProfile][MicroProfile] on [Quarkus][Quarkus].
More informations can be found inside the module
[showcase-quarkus-eventsourcing](./showcase-quarkus-eventsourcing/README.md)

[AxonFramework]: https://github.com/AxonFramework/AxonFramework
[Quarkus]: https://quarkus.io
[MicroProfile]: https://projects.eclipse.org/projects/technology.microprofile
"
aws-samples/amazon-qldb-dmv-sample-java,master,26,24,2019-08-06T00:42:53Z,476,9,A DMV based example application which demonstrates best-practices for using QLDB & the QLDB Driver for Java.,amazon-qldb sample,"# Amazon QLDB Java DMV Sample App
[![license](https://img.shields.io/badge/license-Apache%202.0-blue)](https://github.com/awslabs/amazon-qldb-driver-java/blob/master/LICENSE)
[![AWS Provider](https://img.shields.io/badge/provider-AWS-orange?logo=amazon-aws&color=ff9900)](https://aws.amazon.com/qldb/)

The samples in this project demonstrate several uses of Amazon QLDB.

For our tutorial, see [Java and Amazon QLDB](https://docs.aws.amazon.com/qldb/latest/developerguide/getting-started.java.html).

## Requirements

### Basic Configuration

See [Accessing Amazon QLDB](https://docs.aws.amazon.com/qldb/latest/developerguide/accessing.html) for information on connecting to AWS.

See [Setting Region](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/region-selection.html) page for more information on using the AWS SDK for Java. You will need to set a region before running the sample code.

### Java 8 and Gradle

The examples are written in Java 8 using the Gradle build tool. Java 8 must be installed to build the examples, however 
the Gradle wrapper is bundled in the project and does not need to be installed. Please see the link below for more 
detail to install Java 8 and information on Gradle:

* [Java 8 Installation](https://docs.oracle.com/javase/8/docs/technotes/guides/install/install_overview.html)
* [Gradle](https://gradle.org/)
* [Gradle Wrapper](https://docs.gradle.org/3.3/userguide/gradle_wrapper.html)

## Running the Sample code

The sample code creates a ledger with tables and indexes, and inserts some documents into those tables,
among other things. Each of the examples in this project can be run in the following way:

Windows:

```
gradlew run -Dtutorial=CreateLedger
```

Unix:

```
./gradlew run -Dtutorial=CreateLedger
```

The above example will build the CreateLedger class with the necessary dependencies and create a ledger named:
`vehicle-registration`. You may run other examples after creating a ledger.

### Samples

Below is a list of the sample applications included in this repository with the recommended order of execution.

### Setting up the test ledger

- CreateLedger
- ListLedgers
- DescribeLedger
- ConnectToLedger
- CreateTable
- CreateIndex
- ConnectToLedger: Run it again to see the created tables.
- InsertDocument
- ScanTable

### Transaction management, PartiQL queries examples and History

- AddSecondaryOwner
- DeregisterDriversLicense
- FindVehicles
- RegisterDriversLicense
- RenewDriversLicense
- TransferVehicleOwnership
- DeregisterDriversLicense
- QueryHistory
- InsertIonTypes

### Exporting data

- ExportJournal

- ListJournalExports

- DescribeJournalExport

  **Note:** To execute this test, you need to pass the ExportId that will be in the output of `ListJournalExports`. You can execute the test like this:

  ```bash
  ./gradlew run -Dtutorial=DescribeJournalExport --args=""<Export Id obtained from the output of ListJournalExports>""	
  ```

### Verifying data

- GetRevision
- GetDigest
- GetBlock
- ValidateQldbHashChain

### Other Ledger management operations

- TagResource
- DeletionProtection
- DeleteLedger

### Documentation 

Javadoc is used for documentation. You can generate HTML locally with the following:

```mvn site```

It will generate the Javadoc for public members (defined in <reporting/>) using the given stylesheet (defined in <reporting/>), and with an help page (default value for nohelp is true).

```mvn javadoc:javadoc```

It will generate the Javadoc for private members (defined in <build/>) using the stylesheet (defined in <reporting/>), and with no help page (defined in <build/>).

Please see [Javadoc usage](https://maven.apache.org/plugins/maven-javadoc-plugin/usage.html).

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.


## License

This library is licensed under the Apache 2.0 license.
"
jonashackt/spring-rabbitmq-messaging-microservices,master,34,14,2018-11-05T18:40:22Z,722,9,Example project showing how to build a scalable microservice architecture using Spring Boot & RabbitMQ,,"spring-rabbitmq-messaging-microservices
======================================================================================
[![Build Status](https://github.com/jonashackt/spring-rabbitmq-messaging-microservices/workflows/build/badge.svg)](https://github.com/jonashackt/spring-rabbitmq-messaging-microservices/actions)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)

Example project showing how to build a scalable microservice architecture using Spring Boot &amp; RabbitMQ

![spring-rabbitmq-messaging-diagram](https://yuml.me/diagram/scruffy/class/[weatherservice]->[RabbitMQ],[weatherservice]^-.-[RabbitMQ],[RabbitMQ]->[weatherbackend03],[RabbitMQ]^-.-[weatherbackend03],[RabbitMQ]->[weatherbackend02],[RabbitMQ]^-.-[weatherbackend02],[RabbitMQ]->[weatherbackend01],[RabbitMQ]^-.-[weatherbackend01])

We´re using [RabbitMQ Docker image](https://hub.docker.com/_/rabbitmq/) here. So if you fire it up with `docker-compose up -d`, you can easily login to the management gui at http://localhost:15672 using `guest` & `guest` as credentials.

### Testcontainers only inside weatherbackend

![spring-rabbitmq-messaging-diagram](https://yuml.me/diagram/scruffy/class/[weatherbackend]-&gt;[RabbitMQ],[weatherbackend]^-.-[RabbitMQ])

Although we could also use [docker-compose.yml](docker-compose.yml) right here in the weatherbackend test classes, this could lead to errors - because [testcontainers](https://www.testcontainers.org/) would also try to spin up a `weatherbackend` Docker container, which we don´t have at build time of the weatherbackend itself (cause the Spring Boot jar isn´t ready right then).

But there´s something like the `org.testcontainers.containers.GenericContainer` we can use to spin up a RabbitMQ without a docker-compose.yml. Just have a look into the test class [SendAndReceiveTest](weatherbackend/src/test/java/de/jonashackt/SendAndReceiveTest.java):

```
...
import org.junit.ClassRule;
import org.junit.Rule;
...
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.boot.test.util.TestPropertyValues;
import org.springframework.context.ApplicationContextInitializer;
import org.springframework.context.ConfigurableApplicationContext;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.context.junit4.SpringRunner;
import org.testcontainers.containers.GenericContainer;
import org.testcontainers.containers.wait.strategy.Wait;
...

@RunWith(SpringRunner.class)
@SpringBootTest(classes = WeatherBackendApplication.class)
@ContextConfiguration(initializers = {SendAndReceiveTest.Initializer.class})
public class SendAndReceiveTest {

    static class Initializer implements ApplicationContextInitializer<ConfigurableApplicationContext> {

        @Override
        public void initialize(ConfigurableApplicationContext configurableApplicationContext) {

            TestPropertyValues.of(
                    ""spring.rabbitmq.host="" + rabbitMq.getContainerIpAddress(),
                    ""spring.rabbitmq.port="" + rabbitMq.getMappedPort(5672))
                    .applyTo(configurableApplicationContext.getEnvironment());
        }
    }

    @ClassRule
    public static GenericContainer rabbitMq = new GenericContainer(""rabbitmq:management"")
            .withExposedPorts(5672)
            .waitingFor(Wait.forListeningPort());
```

As Testcontainers doesn´t guarantee that the RabbitMQ container is reachable under the host name `localhost` (see https://github.com/testcontainers/testcontainers-java/issues/669#issuecomment-385873331) and therefore the test execution leads to `ConnectionRefused` Exceptions from the Spring Boot Autoconfiguraiton trying to reach RabbitMQ on this host, we need to go a different path.

But since we need to configure the RabbitMQ host url and port in the early stage of SpringBootTest initialization, we need the help of a `org.springframework.context.ConfigurableApplicationContext` to dynamically set our `spring.rabbitmq.host` property. Togehter with [TestPropertyValues](https://dzone.com/articles/testcontainers-and-spring-boot) this could be done easily as seen in the code.


### Testcontainers, the 'real' docker-compose.yml and the weatherservice

At the weatherservice we´re also using [testcontainers](https://www.testcontainers.org/) to fully instanciate every microservice needed to test the whole interaction with RabbitMQ:

![spring-rabbitmq-messaging-diagram](https://yuml.me/diagram/scruffy/class/[weatherservice]->[RabbitMQ],[weatherservice]^-.-[RabbitMQ],[RabbitMQ]->[weatherbackend],[RabbitMQ]^-.-[weatherbackend])

Therefore the sequence of module build inside our [pom.xml](pom.xml) here is crucial:

```
	<modules>
		<module>weathermodel</module>
		<module>weatherbackend</module>
		<module>weatherservice</module>
	</modules>
```
First the shared domain & event classes are packaged into a .jar file, so that every service is able to use it.

Then the weatherbackend is build and tested - which does everything in the context of one microservice.

The final `weatherservice` build then uses the successful build output of the `weatherbackend` inside the corresponding [Dockerfile](weatherbackend/Dockerfile):

```
...
# Add Spring Boot app.jar to Container
ADD ""target/weatherbackend-0.0.1-SNAPSHOT.jar"" app.jar
...
```

Now the service definition inside the [docker-compose.yml](docker-compose.yml) again uses that Dockerfile to spin up a microservice Docker container containing the `weatherbackend`:

```
version: '3.7'

services:

 rabbitmq:
  image: rabbitmq:management
  ports:
    - ""5672:5672""
    - ""15672:15672""
  tty:
    true

 weatherbackend:
  build: ./weatherbackend
  ports:
    - ""8090""
  environment:
    - ""SPRING.RABBITMQ.HOST=rabbitmq""
  tty:
    true
  restart:
    unless-stopped
```

Note the definition of the environment variable `spring.rabbitmq.host`, since the RabbitMQ containers´ host inside the weatherbackend´s Docker Container isn´t `localhost` but instead Docker DNS style `rabbitmq`!

The Test class [WeatherServiceSendAndReceiveTest](weatherservice/src/test/java/de/jonashackt/WeatherServiceSendAndReceiveTest.java) uses `org.testcontainers.containers.DockerComposeContainer` to leverage to `real` docker-compose.yml:

```
package de.jonashackt;

import com.fasterxml.jackson.core.JsonProcessingException;
import de.jonashackt.messaging.MessageSender;
import org.junit.ClassRule;
import org.junit.Rule;
import org.junit.Test;
import org.junit.contrib.java.lang.system.SystemOutRule;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;
import org.testcontainers.containers.DockerComposeContainer;
import org.testcontainers.containers.wait.strategy.Wait;

import java.io.File;

import static de.jonashackt.common.ModelUtil.exampleEventGetOutlook;
import static de.jonashackt.messaging.Queues.QUEUE_WEATHER_BACKEND;
import static org.hamcrest.Matchers.containsString;
import static org.junit.Assert.assertThat;

@RunWith(SpringRunner.class)
@SpringBootTest(classes = WeatherServiceApplication.class)
public class WeatherServiceSendAndReceiveTest {

    @ClassRule
    public static DockerComposeContainer services =
            new DockerComposeContainer(new File(""../docker-compose.yml""))
                    .withExposedService(""rabbitmq"", 5672, Wait.forListeningPort())
                    .withExposedService(""weatherbackend"", 8090, Wait.forListeningPort());

    @Rule
    public final SystemOutRule systemOutRule = new SystemOutRule().enableLog();

    @Autowired
    private MessageSender messageSender;

    @Test
    public void is_EventGetOutlook_send_and_EventGeneralOutlook_received() throws JsonProcessingException, InterruptedException {

        messageSender.sendMessage(QUEUE_WEATHER_BACKEND, exampleEventGetOutlook());

        Thread.sleep(5000); // We have to wait a bit here, since our Backend needs 3+ seconds to calculate the outlook

        assertThat(systemOutRule.getLog(), containsString(""EventGeneralOutlook received in weatherservice.""));
    }
}
```


### Scale weatherbackend & observe, which retrieves the Events with Elastic stack

To scale the weatherbackend Docker Containers, we can easily facilitate Docker Compose services scaling:

```
docker-compose up -d --scale weatherbackend=3
```

Now we have 3 weatherbackends, as the original architecture diagram suggests:

![spring-rabbitmq-messaging-diagram](https://yuml.me/diagram/scruffy/class/[RabbitMQ]->[weatherbackend03],[RabbitMQ]^-.-[weatherbackend03],[RabbitMQ]->[weatherbackend02],[RabbitMQ]^-.-[weatherbackend02],[RabbitMQ]->[weatherbackend01],[RabbitMQ]^-.-[weatherbackend01])

If we fire up our `weatherservice` now, we can send events that one of the weatherbackends will retrieve. But which is retrieving which event? We need to use log correlation like with the [Elastic stack](https://www.elastic.co/) for that. The easiest way to do so, is to use https://github.com/jonashackt/docker-elk. Just clone this repo and do another `docker-compose up -d`.

To connect our microservices to the Elastic stack, there are multiple possibilties. An easy way is to use the [logstash-logback-encoder](https://github.com/logstash/logstash-logback-encoder) and configure it via a `logback-spring.xml` inside the `resources` directory in each app:

```
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration>
    <include resource=""org/springframework/boot/logging/logback/base.xml""/>
    <logger name=""org.springframework"" level=""WARN""/>
	<logger name=""de.jonashackt"" level=""DEBUG""/>

    <!-- Logstash-Configuration -->
	<!-- For details see https://github.com/logstash/logstash-logback-encoder -->
	<appender name=""logstash"" class=""net.logstash.logback.appender.LogstashTcpSocketAppender"">
		<destination>localhost:5000</destination>
		<!-- encoder is required -->
	   <encoder class=""net.logstash.logback.encoder.LogstashEncoder"">
	   	<includeCallerData>true</includeCallerData>
	   	<customFields>{""service_name"":""weatherservice""}</customFields>
	   	<fieldNames>
	   		<message>log-msg</message>
	   	</fieldNames>
	   </encoder>
	   <keepAliveDuration>5 minutes</keepAliveDuration>
	</appender>
	
	<root level=""INFO"">
	    <appender-ref ref=""logstash"" />
	</root>
	
</configuration>
```

Now with everything in place, fire a request to `weatherservice` with ``.

Open up Kibana after successful startup at http://localhost:5601/app/kibana and first create an index pattern after in __Management/Index Patterns__ called: `logstash-*`. Then click __Next step__ and choose `@timestamp` from the dropdown. Finally click __Create index pattern__. Then head over to __Discover__. Now fire up some events after starting `weatherservice`:

```
curl -v localhost:8095/event
# or 100 events like this
curl -v localhost:8095/events/100
```

Now we should see our services working:

![events-in-kibana](screenshots/kibana-logs.png)


### Scale Containers automatically depending on workload

Initialize local Swarm mode:

```
docker swarm init
```

Now deploy our application as Docker Stack

```
docker stack deploy --compose-file docker-stack.yml {{ application_stack_name }}
```


### Architects heaven: GitHub + Diagram + Markdown-Code

Should be easy right?! I tried: https://yuml.me/diagram/scruffy/class/samples and there´s also a nice editor:

[https://yuml.me/diagram/scruffy/class/edit/](https://yuml.me/diagram/scruffy/class/edit/[weatherservice]->[RabbitMQ],[weatherservice]^-.-[RabbitMQ],[RabbitMQ]->[weatherbackend03],[RabbitMQ]^-.-[weatherbackend03],[RabbitMQ]->[weatherbackend02],[RabbitMQ]^-.-[weatherbackend02],[RabbitMQ]->[weatherbackend01],[RabbitMQ]^-.-[weatherbackend01])"
jonashackt/spring-boot-openapi-kong,main,25,13,2020-11-03T06:58:23Z,2567,7,Example project showing how to integrate Spring Boot microservices with Kong API Gateway,,"# spring-boot-openapi-kong

[![Build Status](https://github.com/jonashackt/spring-boot-openapi-kong/workflows/openapi-to-kong-config-full-setup/badge.svg)](https://github.com/jonashackt/spring-boot-openapi-kong/actions)
[![License](http://img.shields.io/:license-mit-blue.svg)](https://github.com/jonashackt/spring-boot-buildpack/blob/master/LICENSE)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)
[![versionspringboot](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-openapi-kong/main/weatherbackend/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27parent%27%5D%2F%2A%5Blocal-name%28%29%3D%27version%27%5D&label=springboot)](https://github.com/spring-projects/spring-boot)


Example project showing how to integrate Spring Boot microservices with Kong API Gateway

[![asciicast](https://asciinema.org/a/370557.svg)](https://asciinema.org/a/370557)

Bringing together Kong & Spring Boot. But wait, what is https://github.com/Kong/kong ?

> Kong is a cloud-native, fast, scalable, and distributed Microservice Abstraction Layer (also known as an API Gateway or API Middleware). 

This project is also used as sample for this article:
https://blog.codecentric.de/en/2020/11/spring-boot-kong 

## Table of Contents 

* [Idea & Setup](#idea--setup)
* [Step by step...](#step-by-step)
  * [The current problem with springdoc-openapi and WebFlux based Spring Boot apps](#the-current-problem-with-springdoc-openapi-and-webflux-based-spring-boot-apps)
  * [Create a Spring Boot App with REST endpoints](#create-a-spring-boot-app-with-rest-endpoints)
  * [Generate an OpenAPI spec with the springdoc-openapi-maven-plugin](#generate-an-openapi-spec-with-the-springdoc-openapi-maven-plugin)
  * [Tweak the API information in the generated OpenAPI spec](#tweak-the-api-information-in-the-generated-openapi-spec)
* [Import OpenAPI spec into Kong](#import-openapi-spec-into-kong)
  * [Install Insomnia Desinger with Kong Bundle plugin](#install-insomnia-desinger-with-kong-bundle-plugin)
  * [Import Springdoc generated openapi.json into Insomnia Designer](#import-springdoc-generated-openapijson-into-insomnia-designer)
  * [Generate Kong Declarative Config from Openapi](#generate-kong-declarative-config-from-openapi)
* [Docker Compose with Kong DB-less deployment & declarative configuration](#docker-compose-with-kong-db-less-deployment--declarative-configuration)
* [Access the Spring Boot app through Kong](#access-the-spring-boot-app-through-kong)
  * [Configuring the correct upstream in Kong (connect() failed (111: Connection refused) while connecting to upstream)](#configuring-the-correct-upstream-in-kong-connect-failed-111-connection-refused-while-connecting-to-upstream)
* [Automating the OpenAPI-Kong import](#automating-the-openapi-kong-import)
  * [Install Inso CLI](#install-inso-cli)
  * [Inso CLI install problems on Mac](#inso-cli-install-problems-on-mac)
  * [Use Inso CLI to generate Kong declarative config from OpenAPI spec](#use-inso-cli-to-generate-kong-declarative-config-from-openapi-spec)
  * [Run the OpenAPI spec generation and Kong declarative config transformation inside the Maven build](#run-the-openapi-spec-generation-and-kong-declarative-config-transformation-inside-the-maven-build)
  * [Integrate the full Maven build into Cloud CI](#integrate-the-full-maven-build-into-cloud-ci)
  * [Fire up our Kong Docker Compose setup & testdrive the Spring Boot service access](#fire-up-our-kong-docker-compose-setup--testdrive-the-spring-boot-service-access)
* [Links](#links)



### Idea & Setup

Some microservices to access with Kong... I once worked heavily with the Spring Cloud Netflix tooling.

Here's the example project: https://github.com/jonashackt/cxf-spring-cloud-netflix-docker and the blog post I wrote back then https://blog.codecentric.de/en/2017/05/ansible-docker-windows-containers-scaling-spring-cloud-netflix-docker-compose

The goal is to rebuild the project using Kong https://github.com/Kong/kong


agnostical! more pattern like

Setup idea: Spring Boot REST --> [generate OpenAPI spec yamls via springdoc-openapi-maven-plugin](https://www.baeldung.com/spring-rest-openapi-documentation) --> Insomnia: Kong config file with [Kong Bundle plugin](https://insomnia.rest/plugins/insomnia-plugin-kong-bundle/) --> import into Kong and run via decK (normal Kong gateway without EE)

Nothing really there right now:  https://www.google.com/search?q=openapi+spring+boot+kong

* No change in Spring Boot dev workflow required, no custom annotations
* elegant integration of Kong and Spring Boot services

PLUS: CI process to regularly generate OpenAPI specs from Spring code -> and automatically import into Kong, which is an enterprise feature - or it is possible via:




## Step by step...


### The current problem with springdoc-openapi and WebFlux based Spring Boot apps

Why didn't I go with a reactive WebFlux based app? 

WebFlux based Spring Boot Apps need some `springdoc-openapi` specific classes right now in order to fully generate the OpenAPI live documentation in the end. See the demos at

https://github.com/springdoc/springdoc-openapi-demos

And especially the webflux functional demo at: https://github.com/springdoc/springdoc-openapi-demos/blob/master/springdoc-openapi-spring-boot-2-webflux-functional where these imports are used:

```java
import static org.springdoc.core.fn.builders.apiresponse.Builder.responseBuilder;
import static org.springdoc.core.fn.builders.parameter.Builder.parameterBuilder;
import static org.springdoc.webflux.core.fn.SpringdocRouteBuilder.route;
```

I can't fully discourage to go with this approach, but for this project I wanted a 100% ""springdoc-free"" standard Spring Boot app, where the springdoc feature are __ONLY__ used to generate OpenAPI specs - and not rely onto some dependencies from springdoc. Since that would imply that every Spring Boot project that wanted to adopt the solution outlined here would need to integrate springdoc classes in their projects.



### Create a Spring Boot App with REST endpoints

This is the easy part. We all know where to start: Go to start.spring.io and create a Spring REST app skeleton.

As I wanted to rebuild my good old Spring Cloud Netflix / Eureka based apps, I simply took the `weatherbackend` app from https://github.com/jonashackt/cxf-spring-cloud-netflix-docker/tree/master/weatherbackend

Here's the [WeatherBackendAPI.java](weatherbackend/src/main/java/io/jonashackt/weatherbackend/api/WeatherBackendAPI.java) - nothing special here:

```java
package io.jonashackt.weatherbackend.api;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import io.jonashackt.weatherbackend.businesslogic.IncredibleLogic;
import io.jonashackt.weatherbackend.model.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.http.HttpStatus;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping(""/weather"")
public class WeatherBackendAPI {

    private static final Logger LOG = LoggerFactory.getLogger(WeatherBackendController.class);

    @PostMapping(value = ""/general/outlook"", produces = ""application/json"")
    public @ResponseBody GeneralOutlook generateGeneralOutlook(@RequestBody Weather weather) throws JsonProcessingException {
        ...
        return outlook;
    }

    @GetMapping(value = ""/general/outlook"", produces = ""application/json"")
    public @ResponseBody String infoAboutGeneralOutlook() throws JsonProcessingException {
        ...
        return ""Try a POST also against this URL! Just send some body with it like: '"" + weatherJson + ""'"";
    }

    @GetMapping(value = ""/{name}"", produces = ""text/plain"")
    public String whatsTheSenseInThat(@PathVariable(""name"") String name) {
        LOG.info(""Request for /{name} with GET"");
        return ""Hello "" + name + ""! This is a RESTful HttpService written in Spring. :)"";
    }
}
```



### Generate an OpenAPI spec with the springdoc-openapi-maven-plugin

See the docs at https://github.com/springdoc/springdoc-openapi-maven-plugin on how to use the springdoc-openapi-maven-plugin.

> The aim of springdoc-openapi-maven-plugin is to generate json and yaml OpenAPI description during build time. The plugin works during integration-tests phase, and generates the OpenAPI description. The plugin works in conjunction with spring-boot-maven plugin.

But in order to successfully run the springdoc-openapi-maven-plugin, we need to add the [springdoc-openapi-ui](https://github.com/springdoc/springdoc-openapi) plugin (for Tomcat / Spring MVC based apps) or the [springdoc-openapi-webflux-ui](https://github.com/springdoc/springdoc-openapi#spring-webflux-support-with-annotated-controllers) plugin (for Reactive WebFlux / Netty based apps) to our [weatherbackend/pom.xml](hellobackend/pom.xml):

```xml
<dependency>
    <groupId>org.springdoc</groupId>
    <artifactId>springdoc-openapi-ui</artifactId>
    <version>1.4.8</version>
</dependency>
```

Otherwise the `springdoc-openapi-maven-plugin` will run into errors like this (as described [in this so answer](https://stackoverflow.com/a/64677754/4964553)):

```
[INFO] --- springdoc-openapi-maven-plugin:1.1:generate (default) @ hellobackend ---
[ERROR] An error has occured: Response code 404
[INFO]
[INFO] --- spring-boot-maven-plugin:2.3.5.RELEASE:stop (post-integration-test) @ hellobackend ---
[INFO] Stopping application...
2020-11-04 10:18:36.851  INFO 42036 --- [on(4)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
```

As a sidenote: if you fire up your Spring Boot app from here with `mvn spring-boot:run`, you can access the live API documentation already at http://localhost:8080/swagger-ui.html

![openapi-swagger-ui](screenshots/openapi-swagger-ui.png)

Now we can add the `springdoc-openapi-maven-plugin` to our [hellobackend/pom.xml](hellobackend/pom.xml):

```xml
	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<executions>
					<execution>
						<id>pre-integration-test</id>
						<goals>
							<goal>start</goal>
						</goals>
					</execution>
					<execution>
						<id>post-integration-test</id>
						<goals>
							<goal>stop</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.springdoc</groupId>
				<artifactId>springdoc-openapi-maven-plugin</artifactId>
				<version>1.1</version>
				<executions>
					<execution>
						<phase>integration-test</phase>
						<goals>
							<goal>generate</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>
``` 

As you see we also need to tell the `spring-boot-maven-plugin` to start and stop the integration test phases.

In order to generate the Open API spec we need to execute Maven with:

```
mvn verify
```

The output should contain something like that:

```
...
[INFO] --- springdoc-openapi-maven-plugin:1.1:generate (default) @ hellobackend ---
2020-11-04 10:26:09.579  INFO 42143 --- [ctor-http-nio-2] o.springdoc.api.AbstractOpenApiResource  : Init duration for springdoc-openapi is: 29 ms
...
```

This indicates that the OpenAPI spec generation was successful. Therefore we need to have a look into the `weatherbackend/target` directory, where a file called [openapi.json](weatherbackend/target/openapi.json) should be present now (you may need to reformat the code inside you IDE to not look into a one-liner ;) ):

```json
{
  ""openapi"": ""3.0.1"",
  ""info"": {
    ""title"": ""OpenAPI definition"",
    ""version"": ""v0""
  },
  ""servers"": [
    {
      ""url"": ""http://localhost:8080"",
      ""description"": ""Generated server url""
    }
  ],
  ""paths"": {
    ""/weather/general/outlook"": {
      ""get"": {
        ""tags"": [
          ""weather-backend-controller""
        ],
        ""operationId"": ""infoAboutGeneralOutlook"",
        ""responses"": {
          ""200"": {
            ""description"": ""OK"",
            ""content"": {
              ""application/json"": {
                ""schema"": {
                  ""type"": ""string""
                }
              }
            }
          }
        }
      }
}}}
```

### Tweak the API information in the generated OpenAPI spec

I really don't wanted to change much here in the first place. But as I came into more details regarding the Kong integration, I wanted to configure at least some information in the generated `openapi.json`.

Especially the `""title"": ""OpenAPI definition""`, which is then used as the Kong service name, should be optimized :)

Therefore we can [use the @OpenAPIDefinition annotation](https://github.com/springdoc/springdoc-openapi#adding-api-information-and-security-documentation) to configure the service info.

So let's create a class [OpenAPIConfig.java](weatherbackend/src/main/java/io/jonashackt/weatherbackend/api/OpenAPIConfig.java) and specify some info:

```java
package io.jonashackt.weatherbackend.api;

import io.swagger.v3.oas.annotations.OpenAPIDefinition;
import io.swagger.v3.oas.annotations.info.Info;
import io.swagger.v3.oas.annotations.servers.Server;

@OpenAPIDefinition(
        info = @Info(
                title = ""weatherbackend"",
                version = ""v2.0""
        ),
        servers = @Server(url = ""http://weatherbackend:8080"")
)
public class OpenAPIConfig {
}
```

With that we can generate our `openapi.json` again by running `mvn verify -DskipTests=true` and should have the new information propagated:

```json
{
  ""openapi"": ""3.0.1"",
  ""info"": {
    ""title"": ""weatherbackend"",
    ""version"": ""v2.0""
  },
  ""servers"": [
    {
      ""url"": ""http://weatherbackend:8080"",
      ""variables"": {}
    }
  ],
  ""paths"": {
    ""/weather/general/outlook"": {
      ""get"": {
        ""tags"": [
          ""weather-backend-api""
        ],
        ""operationId"": ""infoAboutGeneralOutlook"",
        ""responses"": {
          ""200"": {
            ""description"": ""OK"",
            ""content"": {
              ""application/json"": {
                ""schema"": {
                  ""type"": ""string""
                }
              }
            }
          }
        }
      },
```


### Import OpenAPI spec into Kong

First we start the manual process in order to test drive our solution.

### Install Insomnia Desinger with Kong Bundle plugin

On a Mac simply use brew (or have a look at https://insomnia.rest):

```
brew cask install insomnia-designer
```

Then go to https://insomnia.rest/plugins/insomnia-plugin-kong-bundle and click on `Install in Designer` & open the request in Insomnia Desinger:

![insomnia-designer-kong-bundle-plugin](screenshots/insomnia-designer-kong-bundle-plugin.png)


### Import Springdoc generated openapi.json into Insomnia Designer

Now let's try to import the generated [openapi.json](weatherbackend/target/openapi.json) into our Insomnia Designer by clicking on `Create` and then `Import from / File`:

![insomnia-designer-import-openapi-json](screenshots/insomnia-designer-import-openapi-json.png)

That was easy :) Now you can already interact with your API through Insomnia.



### Generate Kong Declarative Config from Openapi

The next step is to generate the Kong configuration from the OpenAPI specification. Therefore we need to click on the `Generate Config` button:

![insomnia-designer-kong-declarative-config](screenshots/insomnia-designer-kong-declarative-config.png)

And voilà we have our Kong declarative configuration ready:

```yaml
_format_version: ""1.1""
services:
  - name: weatherbackend
    url: http://weatherbackend:8080
    plugins: []
    routes:
      - tags:
          - OAS3_import
        name: weatherbackend-path-get
        methods:
          - GET
        paths:
          - /weather/general/outlook
        strip_path: false
      - tags:
          - OAS3_import
        name: weatherbackend-path_1-post
        methods:
          - POST
        paths:
          - /weather/general/outlook
        strip_path: false
      - tags:
          - OAS3_import
        name: weatherbackend-path_2-get
        methods:
          - GET
        paths:
          - /weather/(?<name>\S+)$
        strip_path: false
    tags:
      - OAS3_import
upstreams:
  - name: weatherbackend
    targets:
      - target: weatherbackend:8080
    tags:
      - OAS3_import
```

For now let's save this yaml inside the [kong/kong.yml](kong/kong.yml) file.




### Docker Compose with Kong DB-less deployment & declarative configuration

I have two goals here: First I want a simple deployment solution. If I could avoid it then I don't want to have multiple services only for the API gateway. I want to start small and you as a reader should be able to easily follow.

As [the official Docker Compose file](https://github.com/Kong/docker-kong/blob/master/compose/docker-compose.yml) has two (!!) database migration services, one database service and one service for Kong I was really overwhelmed at first.

What I learned in my years in the IT industry: Every component you don't have is a good component. So there must be a way to deploy Kong without that much ""hassle"". And I found one:

 
The documentation at https://docs.konghq.com/2.2.x/db-less-and-declarative-config/ & https://docs.konghq.com/install/docker says, that DB-less mode is possible since Kong 1.1 and has a number of benefits:

* reduced number of dependencies: no need to manage a database installation if the entire setup for your use-cases fits in memory
* it is a good fit for automation in CI/CD scenarios: configuration for entities can be kept in a single source of truth managed via a Git repository
* it enables more deployment options for Kong

But be aware that are also some drawbacks. [Not all plugins support this mode]https://docs.konghq.com/2.2.x/db-less-and-declarative-config/#plugin-compatibility) and [there is no central configuration database](https://docs.konghq.com/2.2.x/db-less-and-declarative-config/#no-central-database-coordination) if you want to run multiple Kong nodes. But for our simple setup we should be able to live with that. 


But there's another advantage: we don't need to use [decK](https://github.com/Kong/deck) here as my colleague [already outlined](https://blog.codecentric.de/en/2019/12/kong-api-gateway-declarative-configuration-using-deck-and-visualizations-with-konga/) is used with Kong for declarative config handling.

This is only needed, if you use Kong with a Database deployment! If you choose the DB-less/declarative configuration approach, your declarative file is already everything we need! :)



So let's do it. I'll try to setup the simplest possible `docker-compose.yml` here in order to spin up Kong. I'll derive it [from the official one](https://github.com/Kong/docker-kong/blob/master/compose/docker-compose.yml), the one my colleague Daniel Kocot [used in his blog posts](https://github.com/danielkocot/kong-blogposts/blob/master/docker-compose.yml) and others [like this](https://medium.com/@matias_azucas/db-less-kong-tutorial-8cbf8f70b266). 

```yaml
version: '3.7'

services:
  kong:
    image: kong:2.2.0
    environment:
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: '0.0.0.0:8001'
      KONG_DATABASE: ""off""
      KONG_DECLARATIVE_CONFIG: /usr/local/kong/declarative/kong.yml
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
    volumes:
      - ./kong/:/usr/local/kong/declarative
    networks:
      - kong-net
    ports:
      - ""8000:8000/tcp""
      - ""127.0.0.1:8001:8001/tcp""
      - ""8443:8443/tcp""
      - ""127.0.0.1:8444:8444/tcp""
    healthcheck:
      test: [""CMD"", ""kong"", ""health""]
      interval: 10s
      timeout: 10s
      retries: 10
    restart: on-failure
    deploy:
      restart_policy:
        condition: on-failure

  # no portbinding here - the actual services should be accessible through Kong
  weatherbackend:
    build: ./weatherbackend
    ports:
      - ""8080""
    networks:
      - kong-net
    tty:
      true
    restart:
      unless-stopped

networks:
  kong-net:
    external: false
```

I litterally blew everything out we don't really really need in a DB-less scenario! No `kong-migrations`, `kong-migrations-up`, `kong-db` services - and no extra `Dockerfile` [as shown in this blog post](https://medium.com/@matias_azucas/db-less-kong-tutorial-8cbf8f70b266).

I only wanted to have a single `kong` service for the API gateway - and a `weatherbackend` service that is registered in Kong later.

As stated [in the docs for DB-less deployment](https://docs.konghq.com/install/docker/?_ga=2.266755086.1634614376.1604405282-930789398.1604405282) I used `KONG_DATABASE: ""off""` to switch to DB-less mode and `KONG_DECLARATIVE_CONFIG: /usr/local/kong/declarative/kong.yml` to tell Kong where to get the `kong.yml` we generated with the Insomnia Designer's Kong Bungle plugin.
To have the file present at `/usr/local/kong/declarative/kong.yml`, I used a simple volume mount like this: `./kong/:/usr/local/kong/declarative`. No need to manually create the Volume as described in the docs - or to create another Dockerfile solely to load the config file into the Kong container. Simply nothing needed instead of this sweet volume!

Now this thing starts to make fun to me :)

 
Now let's fire up our Kong setup with `docker-compose up`

```
$ docker-compose up
Starting spring-boot-openapi-kong_kong_1           ... done
Starting spring-boot-openapi-kong_weatherbackend_1 ... done
Attaching to spring-boot-openapi-kong_weatherbackend_1, spring-boot-openapi-kong_kong_1
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: using the ""epoll"" event method
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: openresty/1.17.8.2
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: built by gcc 9.3.0 (Alpine 9.3.0)
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: OS: Linux 5.4.39-linuxkit
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: getrlimit(RLIMIT_NOFILE): 1048576:1048576
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: start worker processes
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: start worker process 22
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: start worker process 23
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: start worker process 24
kong_1            | 2020/11/04 14:21:11 [notice] 1#0: start worker process 25
kong_1            | 2020/11/04 14:21:11 [notice] 23#0: *2 [lua] cache.lua:374: purge(): [DB cache] purging (local) cache, context: init_worker_by_lua*
kong_1            | 2020/11/04 14:21:11 [notice] 23#0: *2 [lua] cache.lua:374: purge(): [DB cache] purging (local) cache, context: init_worker_by_lua*
kong_1            | 2020/11/04 14:21:11 [notice] 23#0: *2 [kong] init.lua:354 declarative config loaded from /usr/local/kong/declarative/kong.yml, context: init_worker_by_lua*
weatherbackend_1  |
weatherbackend_1  |   .   ____          _            __ _ _
weatherbackend_1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
weatherbackend_1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
weatherbackend_1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
weatherbackend_1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
weatherbackend_1  |  =========|_|==============|___/=/_/_/_/
weatherbackend_1  |  :: Spring Boot ::        (v2.3.5.RELEASE)
weatherbackend_1  |
weatherbackend_1  | 2020-11-04 14:21:13.226  INFO 6 --- [           main] io.jonashackt.weatherbackend.WeatherBackendApplication  : Starting WeatherBackendApplication v2.3.5.RELEASE on 209e8a7cbb36 with PID 6 (/app.jar started by root in /)
weatherbackend_1  | 2020-11-04 14:21:13.239  INFO 6 --- [           main] io.jonashackt.weatherbackend.WeatherBackendApplication  : No active profile set, falling back to default profiles: default
weatherbackend_1  | 2020-11-04 14:21:15.920  INFO 6 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
weatherbackend_1  | 2020-11-04 14:21:15.958  INFO 6 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
weatherbackend_1  | 2020-11-04 14:21:15.960  INFO 6 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.39]
weatherbackend_1  | 2020-11-04 14:21:16.159  INFO 6 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
weatherbackend_1  | 2020-11-04 14:21:16.163  INFO 6 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 2714 ms
weatherbackend_1  | 2020-11-04 14:21:16.813  INFO 6 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
weatherbackend_1  | 2020-11-04 14:21:18.534  INFO 6 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
weatherbackend_1  | 2020-11-04 14:21:18.564  INFO 6 --- [           main] io.jonashackt.weatherbackend.WeatherBackendApplication  : Started WeatherBackendApplication in 7.188 seconds (JVM running for 8.611)
kong_1            | 172.19.0.1 - - [04/Nov/2020:14:25:16 +0000] ""GET / HTTP/1.1"" 404 48 ""-"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:82.0) Gecko/20100101 Firefox/82.0""
```

A crucial part here is that Kong successfully loads the declarative configuration file and logs something like `[kong] init.lua:354 declarative config loaded from /usr/local/kong/declarative/kong.yml`


If your log looks somehow like the above you can also have a look at the admin API by opening http://localhost:8001/ in your browser. [As the docs state](https://docs.konghq.com/2.2.x/db-less-and-declarative-config/#setting-up-kong-in-db-less-mode) everything should be ok, if the response says `""database"": ""off""` somewhere like:

![docker-compose-db-less-deploy-database-off](screenshots/docker-compose-db-less-deploy-database-off.png)  

We can also double check http://localhost:8001/status , where we have a good overview of Kong's current availability.



### Access the Spring Boot app through Kong

The next thing we need to look at is how to access our `weatherbackend` through Kong. Specifically we need to have a look into the configured Kong services, if the OpenAPI spec import worked out in the way we'd expected it in the first place.

Without using Kong's declarative configuration [we need to add services and routes manually through the Kong admin API](https://blog.codecentric.de/en/2019/09/api-management-kong-update/). But as we use declarative configuration, which we generated from the OpenAPI spec, everything is taken care for us already.


Therefore let's have a look into the list of all currently registered Kong services at http://localhost:8001/services 

![kong-admin-api-services-overview](screenshots/kong-admin-api-services-overview.png)

You can also access the Kong routes of our Spring Boot-backed service with this URL:

http://localhost:8001/services/weatherbackend/routes



### Configuring the correct upstream in Kong (connect() failed (111: Connection refused) while connecting to upstream)

If you run into problems like this:

```
kong_1            | 2020/11/04 18:56:05 [error] 24#0: *14486 connect() failed (111: Connection refused) while connecting to upstream, client: 172.19.0.1, server: kong, request: ""GET /weather/Jonas HTTP/1.1"", upstream: ""http://127.0.0.1:8080/weather/Jonas"", host: ""localhost:8000""
kong_1            | 2020/11/04 18:56:05 [error] 24#0: *14486 connect() failed (111: Connection refused) while connecting to upstream, client: 172.19.0.1, server: kong, request: ""GET /weather/Jonas HTTP/1.1"", upstream: ""http://127.0.0.1:8080/weather/Jonas"", host: ""localhost:8000""
kong_1            | 172.19.0.1 - - [04/Nov/2020:18:56:05 +0000] ""GET /weather/Jonas HTTP/1.1"" 502 75 ""-"" ""insomnia/2020.4.2""
```

we should have a look at the `upstreams` configuration of our generated Kong declarative config:

```yaml
upstreams:
  - name: weatherbackend
    targets:
      - target: localhost:8080
    tags:
      - OAS3_import
```

As with our setup here Kong needs to access the weatherbackend from within the Docker network. So the `upstreams: target` to `localhost` will not work and lead to the error `connect() failed (111: Connection refused) while connecting to upstream`.

So we need to think about a working `host` configuration. [Daniel did the trick](https://blog.codecentric.de/en/2019/09/api-management-kong-update/) to simply use `host.docker.internal` as host name in his post and I also remember it from my last work with Traefik.

Coming from this solution I thought about my [post about the Spring Cloud microservice setup](https://blog.codecentric.de/en/2017/05/ansible-docker-windows-containers-scaling-spring-cloud-netflix-docker-compose) back in 2017: There I simply used the Docker (Compose) service names, which I aligned with the names of the microservices.

So having a look into our [docker-compose.yml](docker-compose.yml) it would be easy to simply use `weatherbackend` as the host name, since that one should be also available inside the Docker network. And: We can enrich this later by using a DNS resolver and so on...

In order to configure another host name inside Kong, we need to tweak our [OpenAPIConfig.java](weatherbackend/src/main/java/io/jonashackt/weatherbackend/api/OpenAPIConfig.java) with another configuration option called `servers`:

```java
@OpenAPIDefinition(
        info = @Info(
                title = ""weatherbackend"",
                version = ""v2.0""
        ),
        servers = @Server(url = ""http://weatherbackend:8080"")
)
public class OpenAPIConfig {
}
```    

Now doing the OpenAPI spec and Kong declarative config generation again, our setup should come up with a working configuration to access our Spring Boot service through Kong!


Finally we can use Postman, Insomnia Core or the like to access our Spring Boot app with a GET on http://localhost:8000/weather/MaxTheKongUser

![service-access-postman-success](screenshots/service-access-postman-success.png)

Looking into our Docker Compose log we should also see the successful responses from our `weatherbackend` service:

```shell script
weatherbackend_1  | 2020-11-05 07:54:48.381  INFO 7 --- [nio-8080-exec-1] i.j.controller.WeatherBackendController  : Request for /{name} with GET
kong_1            | 172.19.0.1 - - [05/Nov/2020:07:54:48 +0000] ""GET /weather/MaxTheKongUser HTTP/1.1"" 200 133 ""-"" ""PostmanRuntime/7.26.1""
weatherbackend_1  | 2020-11-05 07:54:59.951  INFO 7 --- [nio-8080-exec-2] i.j.controller.WeatherBackendController  : Request for /{name} with GET
kong_1            | 172.19.0.1 - - [05/Nov/2020:07:54:59 +0000] ""GET /weather/MonicaTheKongUser HTTP/1.1"" 200 136 ""-"" ""PostmanRuntime/7.26.1""
weatherbackend_1  | 2020-11-05 07:55:06.573  INFO 7 --- [nio-8080-exec-3] i.j.controller.WeatherBackendController  : Request for /{name} with GET
kong_1            | 172.19.0.1 - - [05/Nov/2020:07:55:06 +0000] ""GET /weather/MartinTheKongUser HTTP/1.1"" 200 136 ""-"" ""PostmanRuntime/7.26.1""
``` 



### Automating the OpenAPI-Kong import

We need to also import the OpenAPI spec everytime the code changes, since otherwise the configuration in Kong will differ with every commit!

Additionally we want to be able to run our process on our CI servers as well, since we're in 2020 and want to be sure everything runs even after code changes.

And there's a way maybe: Inso CLI https://github.com/Kong/insomnia/tree/develop/packages/insomnia-inso

Because there we have a [openapi-2-kong functionality](https://github.com/Kong/insomnia/tree/develop/packages/insomnia-inso#-inso-generate-config-identifier) - see also https://www.npmjs.com/package/openapi-2-kong:

> Similar to the Kong Kubernetes and Declarative config plugins for Designer, this command can generate configuration from an API specification, using openapi-2-kong.


### Install Inso CLI

So let's try Inso CLI! (did I say that this starting to get really cool :D )

Install it with:

```shell script
npm i -g insomnia-inso
```

#### Inso CLI install problems on Mac

I ran into the following error

```
node-pre-gyp WARN Using request for node-pre-gyp https download
  CXX(target) Release/obj.target/node_libcurl/src/node_libcurl.o
clang: error: no such file or directory: '/usr/include'
```

This is a problem, since [MacOS command line tools do not add `/usr/include` folder by default anymore](https://stackoverflow.com/questions/64694248/node-libcurl-installation-fails-on-macos-catalina-clang-error-no-such-file-or/64694249#64694249) (OMG!).

In order to fix that problem, you need to install `node_libcurl` (which has the above problem and is needed by insomnia-inso) first and use the environment variable `npm_config_curl_include_dirs` to show the installation process the new location of `/usr/include` which is `$(xcrun --show-sdk-path)/usr/include`. The command must also include `insomnia-inso`:

```
npm_config_curl_include_dirs=""$(xcrun --show-sdk-path)/usr/include"" npm install -g node-libcurl insomnia-inso
```

### Use Inso CLI to generate Kong declarative config from OpenAPI spec

As we want to go from `openapi.json` to `kong.yml`, we need to [use the `inso generate config` command as described in the docs](https://github.com/Kong/insomnia/tree/develop/packages/insomnia-inso#-inso-generate-config-identifier).

We should also use option `--type declarative`, since the output should result in a Kong declarative configuration file.

Also our OpenAPI spec file at `weatherbackend/target/openapi.json` could be directly passed to Inso CLI. 

The last part is to tell Inso where to output the Kong declarative configuration `--output kong/kong.yml`.

```
inso generate config weatherbackend/target/openapi.json --output kong/kong.yml --type declarative --verbose
```

If you want to see a bit more of an info what the inso CLI is doing, you can add `--verbose` to the command.

If your node/npm installation is broken like mine, you can add the `node_modules/insomnia-inso/bin` directly to your `.bash_profile`, `.zshrc` etc. like that:

```
export PATH=""/usr/local/Cellar/node/15.1.0/lib/node_modules/insomnia-inso/bin:$PATH""
```


### Run the OpenAPI spec generation and Kong declarative config transformation inside the Maven build

Everytime we change our Spring Boot app's code, we should initialize a re-generation of our Kong declarative config in our `kong.yml` file, since the API could have changed!

Playing with different possibilities where to put the generation (Docker, Compose, CI server) I found a really simple solution to bind the step to our standard build process:

I just used the [exec-maven-plugin](https://www.mojohaus.org/exec-maven-plugin/usage.html) to execute the `inso CLI`. Although the XML syntax may look a bit strange at first sight,
it makes totally sense to have the generation of our `kong.yml` also directly coupled to our build process. Therefore let's have a look at our [weatherbackend/pom.xml](weatherbackend/pom.xml):

```xml
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>exec-maven-plugin</artifactId>
				<version>3.0.0</version>
				<executions>
					<execution>
						<id>execute-inso-cli</id>
						<phase>verify</phase>
						<goals>
							<goal>exec</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<executable>inso</executable>
					<arguments>
						<argument>generate</argument>
						<argument>config</argument>
						<argument>target/openapi.json</argument>
						<argument>--output</argument>
						<argument>../kong/kong.yml</argument>
						<argument>--type</argument>
						<argument>declarative</argument>
                        <argument>--verbose</argument>
					</arguments>
				</configuration>
			</plugin>
```

Using `mvn exec:exec` we are now able to execute `inso CLI` through Maven:

```
$ mvn exec:exec
[INFO] Scanning for projects...
[INFO]
[INFO] ------------< io.jonashackt.weatherbackend:weatherbackend >-------------
[INFO] Building weatherbackend 2.3.5.RELEASE
[INFO] --------------------------------[ jar ]---------------------------------
[INFO]
[INFO] --- exec-maven-plugin:3.0.0:exec (default-cli) @ weatherbackend ---
Configuration generated to ""kong/kong.yml"".
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  1.671 s
[INFO] Finished at: 2020-11-05T14:05:04+01:00
[INFO] ------------------------------------------------------------------------
```

As you can see the `inso CLI` logging `Configuration generated to ""kong/kong.yml"".` is part of the output.

And we can push the integration into our build process even further: As [mentioned from Pascal at stackoverflow](https://stackoverflow.com/a/2472767/4964553) we can even bind the execution of the `exec-maven-plugin` to the standard Maven build.

Using the `<phase>` tag we bind the execution to the `verify` phase, where the generation of the OpenAPI spec also takes place already:

```xml
<executions>
    <execution>
        <id>execute-inso-cli</id>
        <phase>verify</phase>
        <goals>
            <goal>exec</goal>
        </goals>
    </execution>
</executions>
```

This is marvelous since with this addition a normal `mvn verify` does every needed step for us to generate a Kong declarative config file at [kong/kong.yml](kong/kong.yml)! 

```shell script
$ mvn verify
...
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.822 s - in io.jonashackt.weatherbackend.api.WeatherBackendAPITests
2020-11-05 14:07:49.261  INFO 66585 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
[INFO]
[INFO] Results:
[INFO]
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO]
[INFO]
[INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ weatherbackend ---
[INFO] Building jar: /Users/jonashecht/dev/spring-boot/spring-boot-openapi-kong/weatherbackend/target/weatherbackend-2.3.5.RELEASE.jar
[INFO]
[INFO] --- spring-boot-maven-plugin:2.3.5.RELEASE:repackage (repackage) @ weatherbackend ---
[INFO] Replacing main artifact with repackaged archive
[INFO]
[INFO] --- spring-boot-maven-plugin:2.3.5.RELEASE:start (pre-integration-test) @ weatherbackend ---
[INFO] Attaching agents: []

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.3.5.RELEASE)

2020-11-05 14:07:50.978  INFO 66597 --- [           main] i.j.w.WeatherBackendApplication          : Starting WeatherBackendApplication on PikeBook.fritz.box with PID 66597 (/Users/jonashecht/dev/spring-boot/spring-boot-openapi-kong/weatherbackend/target/classes started by jonashecht in /Users/jonashecht/dev/spring-boot/spring-boot-openapi-kong/weatherbackend)
2020-11-05 14:07:50.981  INFO 66597 --- [           main] i.j.w.WeatherBackendApplication          : No active profile set, falling back to default profiles: default
2020-11-05 14:07:51.657  INFO 66597 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-11-05 14:07:51.665  INFO 66597 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-11-05 14:07:51.665  INFO 66597 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.39]
2020-11-05 14:07:51.735  INFO 66597 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-11-05 14:07:51.736  INFO 66597 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 715 ms
2020-11-05 14:07:51.889  INFO 66597 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-11-05 14:07:52.292  INFO 66597 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-11-05 14:07:52.300  INFO 66597 --- [           main] i.j.w.WeatherBackendApplication          : Started WeatherBackendApplication in 1.585 seconds (JVM running for 1.978)
[INFO]
[INFO] --- springdoc-openapi-maven-plugin:1.1:generate (default) @ weatherbackend ---
2020-11-05 14:07:52.764  INFO 66597 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-11-05 14:07:52.764  INFO 66597 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-11-05 14:07:52.768  INFO 66597 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 4 ms
2020-11-05 14:07:52.936  INFO 66597 --- [nio-8080-exec-1] o.springdoc.api.AbstractOpenApiResource  : Init duration for springdoc-openapi is: 148 ms
[INFO]
[INFO] --- spring-boot-maven-plugin:2.3.5.RELEASE:stop (post-integration-test) @ weatherbackend ---
[INFO] Stopping application...
2020-11-05 14:07:52.989  INFO 66597 --- [on(4)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-11-05 14:07:53.052  INFO 66597 --- [on(4)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
[INFO]
[INFO] --- exec-maven-plugin:3.0.0:exec (execute-inso-cli) @ weatherbackend ---
Configuration generated to ""../kong/kong.yml"".
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  11.185 s
[INFO] Finished at: 2020-11-05T14:07:54+01:00
[INFO] ------------------------------------------------------------------------
```

With that our Spring Boot app is build & tested, then the `openapi.json` gets generated using the `springdoc-openapi-maven-plugin` and then transformed into `kong.yml` by the `Inso CLI` executed by the `exec-maven-plugin` :))) 


### Integrate the full Maven build into Cloud CI

As we want to make sure everything works as expected every time code changes we need to include the build into a CI system.

Now that we depend on `Inso CLI` installation, which depends on Node.js/NPM and Maven at the same time, we need go with a very flexible CloudCI solution.

As we probably also need Docker Compose on our CI system I decided to go with GitHub Actions since here we have a full-blown virtual machine to do everything we want.

So let's create a [.github/workflows/openapi-to-kong-config-full-setup.yml](.github/workflows/openapi-to-kong-config-full-setup.yml) to execute our Maven build (and don't forget to add `--no-transfer-progress` to the Maven command, since otherwise our build logs get polluted with downloads):

```yaml
name: openapi-to-kong-config-full-setup

on: [push]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Install Node/npm for Inso
        uses: actions/setup-node@v2
        with:
          node-version: '14'

      - name: Install Java & Maven
        uses: actions/setup-java@v1
        with:
          java-version: 15

      - name: Install Inso and run Maven build, that'll generate OpenAPI spec and Kong declarative config later needed for Docker Compose
        run: |
          echo ""Install insomnia-inso (Inso CLI) which is needed by our Maven build process later""
          npm install insomnia-inso

          echo ""Show Inso version""
          node_modules/insomnia-inso/bin/inso --version

          echo ""Build Spring Boot app with Maven""
          echo ""This also generates OpenAPI spec file at weatherbackend/target/openapi.json and the Kong declarative config at kong/kong.yml from the OpenAPI spec with Inso CLI""
          mvn clean verify --file weatherbackend/pom.xml --no-transfer-progress -Dinso.executable.path=node_modules/insomnia-inso/bin/inso
```

I also ran into another problem. GitHub Actions couldn't find the `inso` executable (see this build) and produced the following error:

```
ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:3.0.0:exec (execute-inso-cli) on project weatherbackend: Command execution failed.: Cannot run program ""inso"" (in directory ""/home/travis/build/jonashackt/spring-boot-openapi-kong/weatherbackend""): error=2, No such file or directory -> [Help 1]
```

So I thought about directly defining the full path to the `inso` executable inside our Maven build. But using the `exec-maven-plugin` - and not the command line directly - this isn't that easy anymore.

But maybe we can define a default - and override it on Travis? I looked [at this so q&a](https://stackoverflow.com/questions/34746347/pom-xml-environment-variable-with-default-fallback) and finally [at this answer](https://stackoverflow.com/a/13709976/4964553).

So let's try it! We alter our [weatherbackend/pom.xml](weatherbackend/pom.xml) slightly to use a new property called `${inso.executable.path}`:

```xml
<properties>
    ...
    <inso.executable.path>inso</inso.executable.path>
</properties>
...
<plugin>
    <groupId>org.codehaus.mojo</groupId>
    <artifactId>exec-maven-plugin</artifactId>
    <version>3.0.0</version>
...
    <configuration>
        <executable>${inso.executable.path}</executable>
        <arguments>
...
```

With this change we should be able to run our normal `mvn verify` locally - and a special `mvn verify -DskipTests=true -Dinso.executable.path=inso-special-path` on GitHub Actions like this:

```
mvn clean verify --file weatherbackend/pom.xml --no-transfer-progress -Dinso.executable.path=node_modules/insomnia-inso/bin/inso
```

Now [our build works like a charm](https://travis-ci.com/github/jonashackt/spring-boot-openapi-kong/builds/198466347) :)

At the end we also look into the generated [kong/kong.yml](kong/kong.yml):

```yaml
  echo ""Show kong.yml""
  cat kong/kong.yml
```


### Fire up our Kong Docker Compose setup & testdrive the Spring Boot service access

As we only start Kong through Docker Compose, we should finally ensure, that every `docker-compose up` starts with the latest API definition!

Therefore it would be great to initialize a Maven build every time we fire up our Compose setup.

As we now have a CI server, we can also use it to fire up our Compose setup every time the full chain was build and generated!

All we have to do here is to fire up our setup - and curl Kong with the correct service path. So let's add both to our [.github/workflows/openapi-to-kong-config-full-setup.yml](.github/workflows/openapi-to-kong-config-full-setup.yml):

```yaml
    - name: Fire up Docker Compose setup with Kong & do some checks
      run: |
        docker-compose up -d

        echo ""Let's wait until Kong is available (we need to improve this)""
        sleep 10

        echo ""Also have a look into the Kong & Spring Boot app logs""
        docker ps -a
        docker-compose logs kong
        docker-compose logs weatherbackend

        echo ""Have a look at the /services endpoint of Kong's admin API""
        curl http://localhost:8001/services

        echo ""Verify that we can call our Spring Boot service through Kong""
        curl http://localhost:8000/weather/MaxTheKongUser

        echo ""Again look into Kong logs to see the service call""
        docker-compose logs kong
```

Right after starting `docker-compose up` we need to wait for the containers to spin up. Currently [I use `sleep` here](https://stackoverflow.com/a/47439672/4964553) - it's dead simply, but it works right now :)

We then also have a look into the Kong & Spring Boot app logs with `docker-compose logs kong` & `docker-compose logs weatherbackend`.

After checking the service admin API with `curl http://localhost:8001/services` we finally curl for our service through Kong with `curl http://localhost:8000/weather/MaxTheKongUser`. 



## Links

https://blog.codecentric.de/en/2017/11/api-management-kong/

https://docs.konghq.com/hub/


#### Spring & OpenAPI

https://github.com/springdoc/springdoc-openapi-maven-plugin

https://stackoverflow.com/questions/59616165/what-is-the-function-of-springdoc-openapi-maven-plugin-configuration-apidocsurl

https://www.baeldung.com/spring-rest-openapi-documentation


#### Insomnia (Core) & Insomia Designer

> Insomnia (Core) is a graphical REST client - just like postman

https://blog.codecentric.de/2020/02/testen-und-debuggen-mit-insomnia/

Since 2019 Insomnia (Core) is part of Kong - and is the basis for Kong Studio (Enterprise)

https://github.com/Kong/insomnia


> Insomnia Designer is a OpenAPI / Swagger Desktop App

https://blog.codecentric.de/en/2020/06/introduction-to-insomnia-designer/

> you can preview your specification using Swagger UI

https://medium.com/@rmharrison/an-honest-review-of-insomnia-designer-and-insomnia-core-62e24a447ce


With https://insomnia.rest/plugins/insomnia-plugin-kong-bundle/ you can deploy API definitions into Kong API gateway

To see the integration in action, have a look on https://blog.codecentric.de/en/2020/09/offloading-and-more-from-reedelk-data-integration-services-through-kong-enterprise/ 

https://github.com/codecentric/reedelk-bookingintegrationservice




#### decK

> declarative configuration and drift detection for Kong

https://blog.codecentric.de/en/2019/12/kong-api-gateway-declarative-configuration-using-deck-and-visualizations-with-konga/

https://github.com/Kong/deck



#### Deployment incl. Konga

Official Kong docker-compose template: https://github.com/Kong/docker-kong/blob/master/compose/docker-compose.yml

https://blog.codecentric.de/en/2019/09/api-management-kong-update/

https://github.com/danielkocot/kong-blogposts/blob/master/docker-compose.yml


First question: What is this `kong-migration` Docker container about? [Daniel answers it](https://blog.codecentric.de/en/2019/09/api-management-kong-update/):

> the kong-migration service is used for the initial generation of the objects in the kong-database. Unfortunately, the configuration of the database is not managed by the kong service.



Idea: Database-less deployment possible for showcases?



> Konga: graphical dashboard

https://github.com/pantsel/konga#running-konga

https://blog.codecentric.de/en/2019/12/kong-api-gateway-declarative-configuration-using-deck-and-visualizations-with-konga/

Konga with it's own DB: https://github.com/asyrjasalo/kongpose/blob/master/docker-compose.yml

Konga on the same DB as Kong: https://github.com/abrahamjoc/docker-compose-kong-konga/blob/master/docker-compose.yml

"
EnjoyAndroid/RecyclerviewNestedRecyclerview,master,32,4,2017-07-19T08:45:33Z,5217,1,An example of a recyclerview nested recyclerview,nested recyclerview recyclerview-nested-recyclerview,"# RecyclerviewNestedRecyclerview
An example of a recyclerview nested recyclerview


  最近项目中用到了两个RecyclerView嵌套的布局，即RecyclerView的item也是RecyclerView，其中遇到了两个比较典型的问题：1、当item的方向是垂直方向时，父RecyclerView首次加载会出现位移；2、当item的方向是水平方向时，父RecyclerView上下滑动之后，子RecyclerView位置会还原，本文主要解决以上两个问题。我们先来瞄一眼这两个问题的效果图：

![修复前.gif](http://upload-images.jianshu.io/upload_images/2032177-caf62e812c3c8243.gif?imageMogr2/auto-orient/strip)


来瞄一眼解决问题后的效果图：

![修复后.gif](http://upload-images.jianshu.io/upload_images/2032177-546c6cce03f9b4f4.gif?imageMogr2/auto-orient/strip)

 源码解析：
 http://www.jianshu.com/p/91b6ef2c4c29
"
jonashackt/cxf-spring-cloud-netflix-docker,master,37,20,2017-03-13T14:25:32Z,404,16,"Example project combining Spring Boot apps with Spring Cloud Netflix (Eureka, Zuul, Feign) & cxf-spring-boot-starter",docker eureka eureka-server feign spring-boot spring-cloud-netflix web-services zuul,"cxf-spring-cloud-netflix-docker
======================================================================================
[![Build Status](https://github.com/jonashackt/cxf-spring-cloud-netflix-docker/workflows/cxf-spring-cloud-netflix-docker/badge.svg)](https://github.com/jonashackt/cxf-spring-cloud-netflix-docker/actions)
[![License](http://img.shields.io/:license-mit-blue.svg)](https://github.com/jonashackt/spring-boot-buildpack/blob/master/LICENSE)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)

Spring Boot & Spring Cloud compatibility: https://spring.io/projects/spring-cloud

## Example project combining Spring Boot apps together with Spring Cloud Netflix &amp; Docker

It was created as a showcase for this blog post: [Scaling Spring Boot Apps on Docker Windows Containers with Ansible: A Complete Guide incl Spring Cloud Netflix and Docker Compose](https://blog.codecentric.de/en/2017/05/ansible-docker-windows-containers-scaling-spring-cloud-netflix-docker-compose/) and is used by this Ansible repository: [ansible-windows-docker-springboot](https://github.com/jonashackt/ansible-windows-docker-springboot)

It´s roughly structured like shown in this sketch:

![multiple-apps-spring-boot-cloud-netflix](https://blog.codecentric.de/files/2017/05/multiple-apps-spring-boot-cloud-netflix-768x543.png)

### Usage

As the whole example-application is Dockerized, just do a `docker-compose up -d` and all apps will be started for you. Run a `docker ps` to see what´s going on. Then enter http://localhost:8761/ to see all Services registering in Eureka.

The zuul-edgeservice proxies weatherservice (by retrieving routes dynamically from eureka-serviceregistry) that itself calls weatherbackend

Example: http://localhost:8080/api/weatherservice/soap

There´s a Client application inside this project too, so you can fire requests to the weather-service with that one to - and it should be clear, how to implement a consumer :) For that, just fire up the [weatherclient](https://github.com/jonashackt/cxf-spring-cloud-netflix-docker/tree/master/weatherclient) - it should be right there after a `mvn clean package` ran inside the root directoy.


### Spring Cloud 2.x Upgrade

Renamed starters: https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Edgware-Release-Notes

##### Errors bean overriding

```
***************************
APPLICATION FAILED TO START
***************************

Description:

The bean 'weatherServiceClient', defined in de.jonashackt.WeatherclientTestApplication, could not be registered. A bean with that name has already been defined in class path resource [de/jonashackt/configuration/WeatherclientConfiguration.class] and overriding is disabled.

```

See https://stackoverflow.com/questions/51367566/trouble-when-changing-spring-boot-version-from-2-0-3-release-to-2-1-0-build-snap, 
bean overriding (DI) isn't the default behavior anymore and you have to use:

```
spring.main.allow-bean-definition-overriding: true
```

inside `src/test/resources/application.yml`.

### Links

http://projects.spring.io/spring-cloud/

http://cloud.spring.io/spring-cloud-static/Dalston.RELEASE/

https://github.com/sqshq/PiggyMetrics

https://github.com/kbastani/spring-cloud-microservice-example"
brunoborges/javaee7-jms-websocket-example,master,51,29,2013-05-02T19:22:16Z,192,1,"Example of a Java EE 7 application that integrates JMS 2.0, WebSockets 1.0, CDI events, and EJB 3",,"Java EE 7 Example for JMS and WebSockets integration
=========================

This application demonstrates a full-duplex scenario using WebSockets and JMS, with a fully functional server-side asynchronous push, using CDI events and EJB.

Details and step-by-step were blogged here: https://blogs.oracle.com/brunoborges/entry/integrating_websockets_and_jms_with

# How to run
Download and install JDK 8 and GlassFish 4.1.
Open project on NetBeans or build package with Maven.
Deploy on GlassFish through NB or with admin console.

"
gregwhitaker/springboot-rsocketjwt-example,master,28,6,2019-12-19T15:21:04Z,155,1,Example of using JWT with RSocket and Spring Boot,jwt reactive reactive-programming reactive-streams rsocket rsocket-java spring-boot spring-messaging spring-security,"# springboot-rsocketjwt-example
![Build](https://github.com/gregwhitaker/springboot-rsocketjwt-example/workflows/Build/badge.svg)

An example of using [JWT](https://jwt.io/), for authentication and authorization, with [RSocket](http://rsocket.io) and Spring Boot.

This example consists of an RSocket service, `hello-service`, that returns hello messages based upon the method called and the supplied JWT token from the `hello-client` application.

The example assumes that you have already retrieved valid JWT tokens from your choice of Authorization Server. To mimic this, a `token-generator`
project has been included to get valid tokens for use with this demo.

## Building the Example
Run the following command to build the example:

    ./gradlew clean build
    
## Running the Example
Follow the steps below to run the example:

1. Run the following command to generate the admin and user JWT tokens to use for authenticating with the `hello-service`:

        ./gradlew :token-generator:run
        
    If successful, you will see the tokens displayed in the console:

        > Task :token-generator:run
        
        Generated Tokens
        ================
        Admin:
        eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJhZG1pbiIsImF1ZCI6ImhlbGxvLXNlcnZpY2UiLCJzY29wZSI6IkFETUlOIiwiaXNzIjoiaGVsbG8tc2VydmljZS1kZW1vIiwiZXhwIjoxNTc2ODY4MjE0LCJqdGkiOiIyYjgwOTUwMC0wZWJlLTQ4MDEtOTYwZS1mZjc2MGQ3MjE0ZGUifQ.fzWzcvelcaXooMa5C3w7BI4lJxcruZiA7TwFyPQuH1k
        
        User:
        eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1c2VyIiwiYXVkIjoiaGVsbG8tc2VydmljZSIsInNjb3BlIjoiVVNFUiIsImlzcyI6ImhlbGxvLXNlcnZpY2UtZGVtbyIsImV4cCI6MTU3Njg2ODIxNCwianRpIjoiOGQzZDE2YWUtZTg5MS00Nzc4LWFjNWEtN2NhY2ExOGEwMTYwIn0.Tlg1WxTcrMliLOBmBRSPR33C3xfbc6KUEkEZit928tE
        
2. In a new terminal, run the following command to start the `hello-service`:

        ./gradlew :hello-service:bootRun
        
    If successful, you will see a message stating the service has been started in the console:
    
        2019-12-20 10:33:59.223  INFO 1889 --- [           main] e.service.hello.HelloServiceApplication  : Started HelloServiceApplication in 1.185 seconds (JVM running for 1.546)
        
    Now you are ready to start calling the `hello-service`.
    
3. In a new terminal, run the following command to call the unsecured `hello` endpoint:

        ./gradlew :hello-client:bootRun --args=""hello Bob""
        
   Notice that the request was successful and you received a hello response:
   
        2019-12-20 10:37:24.282  INFO 1919 --- [           main] e.client.hello.HelloClientApplication    : Response: Hello, Bob! - from unsecured method 
        
4. Next, run the following command to call the `hello.secure` method which requires that the user is authenticated:

        ./gradlew :hello-client:bootRun --args=""hello.secure Bob""
        
    You will receive an `io.rsocket.exceptions.ApplicationErrorException: Access Denied` exception because you have not supplied a valid JWT token.
 
5. Now, run the same command again, but this time supply the `User` JWT token you generated earlier:

        ./gradlew :hello-client:bootRun --args=""--token {User Token Here} hello.secure Bob""

    You will now receive a successful hello message because you have authenticated with a valid JWT token:
    
        2019-12-20 10:42:14.371  INFO 1979 --- [           main] e.client.hello.HelloClientApplication    : Response: Hello, Bob! - from secured method
        
6. Next, let's test authorization by calling the `hello.secure.adminonly` endpoint with the `User` token by running the following command:

        ./gradlew :hello-client:bootRun --args=""--token {User Token Here} hello.secure.adminonly Bob""

    You will receive an `io.rsocket.exceptions.ApplicationErrorException: Access Denied` exception because while you are authenticated, you are not authorized to access the method.
    
7. Finally, let's call the `hello.secure.adminonly` endpoint again, but this time use the `Admin` token by running the following command:

        ./gradlew :hello-client:bootRun --args=""--token {Admin Token Here} hello.secure.adminonly Bob""
        
    You will receive a successful hello message because you have supplied a valid JWT token with admin scope:
    
        2019-12-20 10:47:56.047  INFO 2054 --- [           main] e.client.hello.HelloClientApplication    : Response: Hello, Bob! - from secured method [admin only]

## Bugs and Feedback
For bugs, questions, and discussions please use the [Github Issues](https://github.com/gregwhitaker/springboot-rsocketjwt-example/issues).

## License
MIT License

Copyright (c) 2019 Greg Whitaker

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"
idris/spring-example-gae,master,27,6,2009-04-19T17:43:28Z,5988,0,Example of Spring 3.0 on Google App Engine,,
enpassio/Databinding,master,26,14,2018-11-15T13:32:02Z,2726,4,Various examples on databinding which can help not only understand how to get started with it but it also shows how this can be used in complex and real use cases,,"# Android Data Binding Samples

This repository contains three samples for demonstrating the use of Android Data Binding Library. All three samples have both Java and Kotlin versions. The three samples are of various difficulty levels. We tried to avoid unnecessary complexities and minimize the use of external libraries, in case some learners might not be familiar with those libraries. But we also wanted to show something more or less realist. 

The first sample, Data Binding with RecyclerView is intentionally kept very simple so that you can concentrate on learning basics of data binding. It contains a single activity with two fragments: First fragment shows a list of items (hardcoded list of products) within a recyclerview, and the second fragment shows the details of the chosen product. In this sample, we demonstrated how to set up data binding in xml layouts, how to access binding instance from Java/Kotlin code, how to use imports and helper methods, how to implement data binding in recyclerview item layouts and how to set an item click listener with data binding

The second one, Data Binding with News Api, again has two fragments, one showing a list of articles and the second one showing details of the chosen article. However this one makes a network call to fetch articles from News Api and uses some Android Jetpack components, like ViewModel and LiveData. Regarding data binding, besides the similar concepts that were used in the first sample, this sample also demonstrates use of custom binding adapters and integration of viewModel and liveData with data binding. 

And the third one, Two-Way Databinding, demonstrates the use of two-way data binding. It is an inventory app, which uses Room for data persistence. This one again uses ViewModel, LiveData and Repository pattern. It also demonstrates use of ObservableFields and converter methods. 

"
yole/comparisonChainGen,master,54,10,2012-11-29T19:30:43Z,1519,0,"Example plugin created during the Live Coding an IntelliJ IDEA Plugin from Scratch"" webinar.""",,
spektom/realtime-dashboard-example,master,25,12,2016-02-28T08:43:51Z,811,0,This is a real-time dashboard example using Spark Streaming and Node.js,dashboard-application flink kafka meetup rethinkdb spark spark-streaming,"coding-with-af-spark-streaming
===============================

Spark Streaming makes it easy to build scalable fault-tolerant streaming applications. 

At AppsFlyer, we use Spark for many of our offline processing services. Spark Streaming joined our technology stack a few months ago for real-time work flows, reading directly from Kafka to provide value to our clients in near-real-time. 

In this session we will code a real-time dashboard application based on Spark Streaming technology. You will learn how to collect events from Kafka, aggregate them by time window and present aggregated insights in a dashboard. 

## Screenshot

![Screenshot](https://github.com/spektom/coding-with-af-spark-streaming/raw/master/screenshot.gif)

## Architecture

The following scheme presents what we are going to create in this session:


                    Read events
     +------------+              +------------------------+
     |            |              |                        |
     |  Kafka     | -----------> |   Spark Streaming Job  |
     |            |              |                        |
     +------------+              +------------------------+
                                             |
                                             | Update
                                             V                   +---------------+
                                    +--------+------+            |               |
                                    |               |   Push!    |   Real-time   |
                                    |   RethinkDB   | ---------> |   Dashboard   |
                                    |               |            |       _..     |
                                    +---------------+            |   (../   \)   |
                                                                 +---------------+



1. We'll read real-time events from Kafka queue.
2. We'll aggregate events in Spark streaming job by some sliding window.
3. We'll write aggregated events to RethinkDB.
4. RethinkDB will push updates to the real-time dashboard.
5. Real-time dashboard will present current status.


## Prerequisites

1. Laptop with at least 4GB of RAM.
2. Make sure Virtualization is enabled in BIOS.
3. [VirtualBox v5.x](https://www.virtualbox.org/wiki/Downloads) or greater installed.
4. [Vagrant v1.8.1](https://www.vagrantup.com/downloads.html) or greater installed.


## Preparation & Setup

Please do these steps **prior** to coming to the Meetup:

1. Clone or download this repository.
2. Run `vagrant up && vagrant halt` inside the `vagrant/` directory.

Please be patient, this process may take some time...


## Running the Application

1. Go inside `vagrant/` directory.

2. Boot the Vagrant virtual machine:

     `vagrant up`

3. Start the Spark Streaming process:

     `vagrant ssh -c /projects/aggregator/run.sh`

4. Start the Dashboard application in another terminal window:

     `vagrant ssh -c /projects/dashboard/run.sh`


If everything was successful, you should be able to access your Dashboard application here:

[http://192.168.10.16:3000](http://192.168.10.16:3000)


## Cleaning Up

After the meetup, you may want to close running virtual machine. To do so, run inside `vagrant/` directory:

     vagrant suspend

To destroy the virtual machine completely, run:

     vagrant destroy


"
lijingyao/microservice_coffeeshop,master,50,25,2018-07-05T06:11:57Z,106,1,"An example of microservice architecture with SpringBoot,SpringCloud-Eureka,JPA and so on.You can build docker image with gradle.",,"# microservice_coffeeshop     

## 简介    

这是一个微服务架构为基础的，简单的咖啡厅的微服务示例。主要的微服务工程如下：   

1. service_user 维护了来咖啡厅的用户的领域模型。    
2. service_item 维护了咖啡厅的主要商品，包含了咖啡饮品的领域模型。     
3. service_trade 包含订单、子订单的领域模型。 

主要使用的基础技术如下：        

* 微服务的服务发现使用EurekaServer。 EurekaServer的Docker镜像可以从 dockerhub 中download。     
* 微服务的数据组装、转发在API Gateway 工程中,可以去 [API-Gateway](https://github.com/lijingyao/gateway_coffeeshop) 工程中checkout代码。   
* 使用的工程构建工具：Gradle、Gradlew插件    
* 存储服务：MySQL——InnoDB   
* 涉及到的框架有：SpringMVC、SpringBoot、SpringCloud-Netflix、Hibernate、RxJava(Gateway工程中)    
* 服务间通信：Restful API   
* 服务基础涉及原则：DDD(Domain-Driven Design)     

其他：
编码：utf-8

## 部署信息   

### 基础服务部署      

需要启动的本地容器/服务：
注：以下服务可以通过docker镜像，也可以直接本地安装。工程中示例代码连接DB、Eureka、nexus 服务的地址，请替换成您本地配置的账号、密码。 


1. Mysql ：docker 容器可以使用官方镜像：[docker mysql image](https://hub.docker.com/_/mysql/)
2. Eureka :镜像：[netflixoss-eureka image](https://hub.docker.com/r/netflixoss/eureka/)
3. docker registry 镜像仓库： [docker registry image](https://hub.docker.com/_/registry/)
4. nexus 二方库、三方库镜像：[docker nexus image](https://hub.docker.com/r/sonatype/nexus/)     

### 微服务部署  

#### 打包docker镜像

运行gradle命令打包docker镜像，并且上传到本地的 docker 仓库。   
  
```
./gradlew buildDocker -x test 

```
然后运行 **docker images** 命令查看镜像信息。 

#### 运行docker 镜像

可以使用docker run 一键运行。或者使用docker-compose 做简单的容器编排  

```
docker run  -p :8080 -t localhost:5000/item:1.0.0  --name service-item  
```

如果不以docker容器运行，本地环境也可以直接运行每个微服务的Springboot实例。 


## 给读者的作业   

1. 用Java8 的 *Predicate* API  来实现对于入参和业务逻辑的校验。在DDD思想中，有参数的校验，也有领域模型自身逻辑的校验。
本demo 工程没有做这两种校验。先给读者做思考，怎样有更简洁、更高内聚的方式实现最基础的校验？     
2. 本demo中的 *AdditionalTasteVO* 中有一个DDD **值对象**的设计，关于价格计算模型，还有什么更好的方式呢？
目前只计算了 *espresso*的附加价，读者们可以继续做更多的价格模型扩展。    

## 解答

1. 更新代码后，主要看service 包下面多了 *validators*包，用来封装各种业务的校验器。以*UserValidator*类为例，
主要增加了对用户注册入参的校验。过程中产生的中间业务结果，也可以用**Predicate**实现。统一的校验器可以将相似
的逻辑抽象出来，并且减少service代码对于一般参数校验。更方便维护主领域模型的逻辑。 

2. 新增的代码在service_item的 *manager*包中。**PriceSelector**相当于策略模式的situation的选择器,示例中是
通过系统当前时间来判断和选择具体的策略。实际业务中会有更复杂的条件。示例代码中的策略分为两个，Summer,Winter。 
不同的季节不同的咖啡附加料价格不同，通过策略模式，可以很好得解耦不同的计算模型。如果计算流程是可以复用的，那么
还可以在策略中结合**Template**模式。

"
jonashackt/spring-boot-graalvm,master,229,49,2020-03-20T10:02:07Z,1750,8,This example project shows how to compile a Webflux based Spring Boot application into a Native App using GraalVM Native Image locally & on GitHub Actions with & without Docker,docker github-actions graalvm graalvm-native-image heroku heroku-container-registry heroku-docker java native-image native-image-maven-plugin spring-boot spring-graal substratevm travis travis-ci,"# spring-boot-graalvm
[![Build Status](https://github.com/jonashackt/spring-boot-graalvm/workflows/native-image-compile/badge.svg)](https://github.com/jonashackt/spring-boot-graalvm/actions)
[![License](http://img.shields.io/:license-mit-blue.svg)](https://github.com/jonashackt/spring-boot-graalvm/blob/master/LICENSE)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)
[![versionspringboot](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-graalvm/master/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27parent%27%5D%2F%2A%5Blocal-name%28%29%3D%27version%27%5D&label=springboot)](https://github.com/spring-projects/spring-boot)
[![versionspring-graalvm-native](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-graalvm/master/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27properties%27%5D%2F%2A%5Blocal-name%28%29%3D%27spring-native.version%27%5D&label=spring-native)](https://github.com/spring-projects-experimental/spring-graalvm-native)
[![versionjava](https://img.shields.io/badge/graalvm_ce-21.2.0_JDK11-orange.svg?logo=java)](https://www.graalvm.org/)
[![Deployed on Heroku](https://img.shields.io/badge/heroku-deployed-blueviolet.svg?logo=heroku&)](https://spring-boot-graal.herokuapp.com/hello)
[![Pushed to Docker Hub](https://img.shields.io/badge/docker_hub-released-blue.svg?logo=docker)](https://hub.docker.com/r/jonashackt/spring-boot-graalvm)


This example project shows how to compile a Webflux based Spring Boot application into a Native App using GraalVM Native Image

> This project here shows a technical demo of what's possible right now - stable GraalVM Native Image support for Spring Boot could be expected with [Spring Frameworks 5.3 release planned in October 2020](https://spring.io/blog/2019/12/03/spring-framework-maintenance-roadmap-in-2020-including-4-3-eol), on which Spring Boot 2.4 will be based.

[![asciicast](https://asciinema.org/a/313688.svg)](https://asciinema.org/a/313688)

A live deployment is available on Heroku: https://spring-boot-graal.herokuapp.com/hello

This project is used as example in some articles:

* [blog.codecentric.de/en/2020/05/spring-boot-graalvm/](https://blog.codecentric.de/en/2020/05/spring-boot-graalvm/)
* [blog.codecentric.de/en/2020/06/spring-boot-graalvm-docker-heroku/](https://blog.codecentric.de/en/2020/06/spring-boot-graalvm-docker-heroku/)
* [blog.codecentric.de/en/2020/06/spring-boot-graalvm-native-image-maven-plugin/](https://blog.codecentric.de/en/2020/06/spring-boot-graalvm-native-image-maven-plugin/)

[![javamagazin-092020-cover-small](screenshots/javamagazin-092020-cover-small.jpg)](https://public.centerdevice.de/41c5481e-5782-4c0e-bf7b-a62ec68d3854)

## Table of Contents 

* [New to GraalVM with Spring Boot?](#new-to-graalvm-with-spring-boot)
  * [Graal Native Image & SpringBoot](#graal-native-image--springboot)
  * [Dynamic Graal Native Image configuration with @AutomaticFeature](#dynamic-graal-native-image-configuration-with-automaticfeature)
* [Install GraalVM with SDKMAN](#install-graalvm-with-sdkman)
  * [Install GraalVM Native Image](#install-graalvm-native-image)
* [Create a simple WebFlux Reactive REST Spring Boot app](#create-a-simple-webflux-reactive-rest-spring-boot-app)
* [Make Spring Boot app Graal Native Image friendly](#make-spring-boot-app-graal-native-image-friendly)
  * [Relocate Annotation classpath scanning from runtime to build time](#relocate-annotation-classpath-scanning-from-runtime-to-build-time)
  * [Disable usage of CGLIB proxies](#disable-usage-of-cglib-proxies)
  * [Detect Autoconfiguration](#detect-autoconfiguration)
  * [Get Spring Graal @AutomaticFeature](#get-spring-graal-automaticfeature)
  * [Set start-class element in pom.xml](#set-start-class-element-in-pomxml)
  * [Craft a compile.sh script](#craft-a-compilesh-script)
  * [Run the compile.sh script & start your native Spring Boot App](#run-the-compilesh-script--start-your-native-spring-boot-app)
* [Doing all the steps together using the native-image-maven-plugin](#doing-all-the-steps-together-using-the-native-image-maven-plugin)
  * [Tackling the 'No default constructor found Failed to instantiate java.lang.NoSuchMethodException: io.jonashackt.springbootgraal.SpringBootHelloApplication.()' error](#tackling-the-no-default-constructor-found-failed-to-instantiate-javalangnosuchmethodexception-iojonashacktspringbootgraalspringboothelloapplication-error)
* [Comparing Startup time & Memory footprint](#comparing-startup-time--memory-footprint)
* [Build and Run your Native Image compilation on a Cloud-CI provider like TravisCI](#build-and-run-your-native-image-compilation-on-a-cloud-ci-provider-like-travisci)
  * [Prevent the 'java.lang.UnsatisfiedLinkError: no netty_transport_native_epoll_x86_64 in java.library.path: [/usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib]' error](#prevent-the-javalangunsatisfiedlinkerror-no-netty_transport_native_epoll_x86_64-in-javalibrarypath-usrjavapackageslib-usrlib64-lib64-lib-usrlib-error)
  * [Tackling the 'There was an error linking the native image /usr/bin/ld: final link failed: Memory exhausted' error](#tackling-the-there-was-an-error-linking-the-native-image-usrbinld-final-link-failed-memory-exhausted-error)
* [Build and Run your Native Image compilation on GitHub Actions](#build-and-run-your-native-image-compilation-on-github-actions)
* [Use Docker to compile a Spring Boot App with GraalVM](#use-docker-to-compile-a-spring-boot-app-with-graalvm)
  * [Tackling 'Exception java.lang.OutOfMemoryError in thread ""native-image pid watcher""' error](#tackling-exception-javalangoutofmemoryerror-in-thread-native-image-pid-watcher-error)
  * [Run Spring Boot Native Apps in Docker](#run-spring-boot-native-apps-in-docker)
* [Running Spring Boot Graal Native Apps on Heroku](#running-spring-boot-graal-native-apps-on-heroku)
  * [Configure the Spring Boot Native app's port dynamically inside a Docker container](#configure-the-spring-boot-native-apps-port-dynamically-inside-a-docker-container)
  * [Use Docker to run our Spring Boot Native App on Heroku](#use-docker-to-run-our-spring-boot-native-app-on-heroku)
  * [Work around the Heroku 512MB RAM cap: Building our Dockerimage with TravisCI](#work-around-the-heroku-512mb-ram-cap-building-our-dockerimage-with-travisci)
  * [Tackling 'Error: Image build request failed with exit status 137' with the -J-Xmx parameter](#tackling-error-image-build-request-failed-with-exit-status-137-with-the--j-xmx-parameter)
  * [Pushing and Releasing our Dockerized Native Spring Boot App on Heroku Container Infrastructure](#pushing-and-releasing-our-dockerized-native-spring-boot-app-on-heroku-container-infrastructure)
  * [Pushing and Releasing our Dockerized Native Spring Boot App on Heroku Container Infrastructure using GitHub Actions](#pushing-and-releasing-our-dockerized-native-spring-boot-app-on-heroku-container-infrastructure-using-github-actions)
* [Autorelease on Docker Hub with TravisCI](#autorelease-on-docker-hub-with-travisci)
* [Links](#links)


# New to GraalVM with Spring Boot?

Current status of Spring's Graal support: 

* https://github.com/spring-projects/spring-framework/wiki/GraalVM-native-image-support
* https://github.com/spring-projects/spring-framework/issues/22968

> Note: [GraalVM](https://www.graalvm.org/) is an umbrella for many projects - if we want to fasten the startup and reduce the footprint of our Spring Boot projects, we need to focus on [GraalVM Native Image](https://www.graalvm.org/docs/reference-manual/native-image/).  

### Graal Native Image & SpringBoot

There are some good intro resources - like the [Running Spring Boot Applications as GraalVM Native Images talk @ Spring One Platform 2019](https://www.infoq.com/presentations/spring-boot-graalvm/) by [Andy Clement](https://twitter.com/andy_clement).

One could tell Native Image to initialize Java classes 

```
# at build time:
native image --initialize-at-build-time=your.package.YourClass
 
# or at runtime
native image --initialize-at-run-time=your.package.YourClass
``` 

GraalVM Native Image supports:
 
* __static configuration:__ via JSON files
  * either hand-crafted or 
  * [generated by Graal Native Image agent](https://medium.com/graalvm/introducing-the-tracing-agent-simplifying-graalvm-native-image-configuration-c3b56c486271))
* __dynamic configuration:__ with the help of a [Graal Feature interface](https://www.graalvm.org/sdk/javadoc/index.html?org/graalvm/nativeimage/hosted/Feature.html)
  * implementing classes are called back throughout the image build process (see https://github.com/oracle/graal/blob/master/substratevm/REFLECTION.md#manual-configuration)

### Dynamic Graal Native Image configuration with @AutomaticFeature

[Andy Clement](https://twitter.com/andy_clement) also seems to lead a Spring experimental project, that provides a Graal @AutomaticFeature for typical Spring application: https://github.com/spring-projects-experimental/spring-graalvm-native

There are also already some example projects available: https://github.com/spring-projects-experimental/spring-graalvm-native/tree/master/spring-graalvm-native-samples 


# Install GraalVM with SDKMAN

Let's install GraalVM with the help of SDKMAN. Therefore you need to [have SDKMAN itself installed](https://sdkman.io/install):

```
curl -s ""https://get.sdkman.io"" | bash
source ""$HOME/.sdkman/bin/sdkman-init.sh""
```

If SDKMAN has been installed successfully, the following command should work:

```
$ sdk list java

================================================================================
Available Java Versions
================================================================================
 Vendor        | Use | Version      | Dist    | Status     | Identifier
--------------------------------------------------------------------------------
 AdoptOpenJDK  |     | 14.0.0.j9    | adpt    |            | 14.0.0.j9-adpt
               |     | 14.0.0.hs    | adpt    |            | 14.0.0.hs-adpt
               |     | 13.0.2.j9    | adpt    |            | 13.0.2.j9-adpt
... 
 GraalVM       | >>> | 20.2.0.r11   | grl     | installed  | 20.2.0.r11-grl
               |     | 20.2.0.r8    | grl     |            | 20.2.0.r8-grl
               |     | 20.1.0.r11   | grl     |            | 20.1.0.r11-grl
               |     | 20.1.0.r8    | grl     |            | 20.1.0.r8-grl
               |     | 20.0.0.r11   | grl     |            | 20.0.0.r11-grl
               |     | 20.0.0.r8    | grl     |            | 20.0.0.r8-grl
               |     | 19.3.1.r11   | grl     |            | 19.3.1.r11-grl
               |     | 19.3.1.r8    | grl     |            | 19.3.1.r8-grl
...
```

The list itself is much longer and you could see the wonderful simplicity of this approach: Don't ever mess again with JDK installations!

Now to install GraalVM based on JDK11, simply run:

```
sdk install java 20.2.0.r11-grl
``` 

SDKMAN now installs GraalVM for us. To have the correct `PATH` configuration in place, you may need to restart your console. If everything went fine, you should see `java -version` react like this:

```
$ java -version
openjdk version ""11.0.8"" 2020-07-14
OpenJDK Runtime Environment GraalVM CE 20.2.0 (build 11.0.8+10-jvmci-20.2-b03)
OpenJDK 64-Bit Server VM GraalVM CE 20.2.0 (build 11.0.8+10-jvmci-20.2-b03, mixed mode, sharing)
```



### Install GraalVM Native Image

GraalVM brings a special tool `gu` - the GraalVM updater. To list everything thats currently installed, run

```
$ gu list
ComponentId              Version             Component name      Origin
--------------------------------------------------------------------------------
graalvm                  20.2.0              GraalVM Core
```

Now to install GraalVM Native image, simply run:

```
gu install native-image
```

After that, the `native-image` command should work for you:

```
$ native-image --version
GraalVM Version 20.2.0 (Java Version 11.0.8)
```


# Create a simple WebFlux Reactive REST Spring Boot app

As famous [starbuxman](https://twitter.com/starbuxman) suggests, we start at: https://start.spring.io/!

As https://github.com/spring-projects/spring-framework/wiki/GraalVM-native-image-support suggests, the GraalVM Native Image support becomes better every day - so [we should choose the newest Spring Boot `2.3` Milestone release](https://github.com/spring-projects-experimental/spring-graalvm-native) available:

> Spring Boot 2.3.0.M1 (you may be able to get some things working with Boot 2.2.X but not 2.1 or earlier)

![spring.start.io](screenshots/spring.start.io.png)      

Stable Native Image support for Spring Boot could be expected with [Spring Frameworks 5.3 release planned in October 2020](https://spring.io/blog/2019/12/03/spring-framework-maintenance-roadmap-in-2020-including-4-3-eol), on which Spring Boot 2.4 will be based.

Let's create a simple Spring Boot Reactive REST service. First we need a Handler like [HelloHandler](src/main/java/io/jonashackt/springbootgraal/HelloHandler.java):

```java
package io.jonashackt.springbootgraal;

import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.BodyInserters;
import org.springframework.web.reactive.function.server.ServerRequest;
import org.springframework.web.reactive.function.server.ServerResponse;
import reactor.core.publisher.Mono;

@Component
public class HelloHandler {

    protected static String RESPONSE_TEXT= ""Hello Reactive People!"";

    public Mono<ServerResponse> hello(ServerRequest serverRequest) {
        return ServerResponse
                        .ok()
                        .contentType(MediaType.TEXT_PLAIN)
                        .body(BodyInserters.fromValue(RESPONSE_TEXT));
    }
}
```

In the Reactive Spring approach we also need a Router - let's create [HelloRouter](src/main/java/io/jonashackt/springbootgraal/HelloRouter.java):

```java
package io.jonashackt.springbootgraal;

import org.springframework.context.annotation.Bean;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.server.*;

@Component
public class HelloRouter {

    @Bean
    public RouterFunction<ServerResponse> route(HelloHandler helloHandler) {
        return RouterFunctions.route(
                RequestPredicates.GET(""/hello"").and(RequestPredicates.accept(MediaType.TEXT_PLAIN)),
                serverRequest -> helloHandler.hello(serverRequest)
        );
    }
}
```

Now we have everything in place to create a Testcase [HelloRouterTest](src/test/java/io/jonashackt/springbootgraal/HelloRouterTest.java) using the non-blocking [WebClient](https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/web/reactive/function/client/WebClient.html):

```java
package io.jonashackt.springbootgraal;

import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.http.MediaType;
import org.springframework.test.web.reactive.server.WebTestClient;

@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
class HelloRouterTest {

	@Test void
	should_call_reactive_rest_resource(@Autowired WebTestClient webTestClient) {
		webTestClient.get().uri(""/hello"")
			.accept(MediaType.TEXT_PLAIN)
			.exchange()
			.expectBody(String.class).isEqualTo(HelloHandler.RESPONSE_TEXT);
	}
}
``` 

If you want to create another Spring Boot app I can recomment the great [Getting Started Guides](https://spring.io/guides)!



# Make Spring Boot app Graal Native Image friendly

From https://github.com/spring-projects/spring-framework/wiki/GraalVM-native-image-support#experimental-support:

> ""The spring-graalvm-native experimental project, created by Andy Clement, shows how it is possible to run a Spring Boot application out of the box as a GraalVM native image. It could be used as a basis for a potential upcoming official support.""

So let's try this currently available implementation!


### Relocate Annotation classpath scanning from runtime to build time

The `spring-context-indexer` is an Annotation processor, which pushes the scan for Annotations from runtime to build time - see the docs: https://docs.spring.io/spring/docs/5.2.4.RELEASE/spring-framework-reference/core.html#beans-scanning-index:

> While classpath scanning is very fast, it is possible to improve the startup performance of large applications by creating a static list of candidates at compilation time. In this mode, all modules that are target of component scan must use this mechanism.

We could use the spring-context-indexer via importing it with Maven:

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework</groupId>
        <artifactId>spring-context-indexer</artifactId>
        <optional>true</optional>
    </dependency>
</dependencies>
```

This would produce a `META-INF/spring.components` file containing a list of all Spring Compontens, Entities and so on.

__But we don't have to do this manually__, since the [Spring Graal @AutomaticFeature](https://github.com/spring-projects-experimental/spring-graalvm-native) (again, this is in experimental stage right now) does this automatically for us.

The `@AutomaticFeature` will additionally chase down imported annotated classes like `@Import` - it knows, which kinds of annotations lead to reflection needs at runtime, which with GraalVM need to be registered at build time.

And as resource files like `application.properties` also need to be registered at build time, the Feature covers those too. 


### Disable usage of CGLIB proxies

With Spring Boot 2.2 CGLIB proxies are no longer necessary - it introduces the new `proxyBeanMethods` option to avoid CGLIB processing. Let's have a look at our [SpringBootHelloApplication.java](src/main/java/io/jonashackt/springbootgraal/SpringBootHelloApplication.java):

```java
@SpringBootApplication(proxyBeanMethods = false)
public class SpringBootHelloApplication {
    ...
}
```

The usage of [JDK Proxies is supported by GraalVM](https://github.com/oracle/graal/blob/master/substratevm/DYNAMIC_PROXY.md), they just need to be registered at build time. This is also taken care of by the [Spring Graal @AutomaticFeature](https://github.com/spring-projects-experimental/spring-graalvm-native).


### Detect Autoconfiguration

Spring Boot ships with lot's of autoconfiguration projects, which only kick in, when there are specific classes found on the class path. Since this is done at runtime, it wouldn't work with GraalVM.

But the [SpringBootHelloApplication.java](src/main/java/io/jonashackt/springbootgraal/SpringBootHelloApplication.java) also takes care of this. It simply analyses the `META-INF/spring.factories` file, where the autoconfiguration classes are listed. An [example of such a file](https://github.com/codecentric/cxf-spring-boot-starter/blob/master/cxf-spring-boot-starter/src/main/resources/META-INF/spring.factories) could be found in the community-driven Spring Boot Starter [cxf-spring-boot-starter](https://github.com/codecentric/cxf-spring-boot-starter).

The `@AutomaticFeature` again pulls the work from runtime to build time - and eliminates the need for runtime autoconfiguration.


### Get Spring Graal @AutomaticFeature

In order to compile our Spring Boot App as a Native Image, we need to have the latest [Spring Graal @AutomaticFeature](https://github.com/spring-projects-experimental/spring-graalvm-native) in place. As until March 2020 there was no Maven Dependency available, since this project is in a very early stage of development I guess. So I initially crafted a script `get-spring-feature.sh` that cloned and build the project for local usage.

But the Spring guys are moving fast! As there was also [a spring.io post released by starbuxman](https://spring.io/blog/2020/04/16/spring-tips-the-graalvm-native-image-builder-feature) at 16th of April, I think he got [Andy Clement](https://twitter.com/andy_clement) and [Sébastien Deleuze](https://twitter.com/sdeleuze) to get him a Maven dependecy available on https://repo.spring.io/milestone :)

So there we go! Now we don't need to manually download and compile the @AutomaticFeature, we simply add a dependency to our [pom.xml](pom.xml):

```
	<dependencies>
		<dependency>
			<groupId>org.springframework.experimental</groupId>
			<artifactId>spring-graalvm-native</artifactId>
			<version>0.7.1</version>
		</dependency>
    ...

	<repositories>
		<repository>
			<id>spring-milestones</id>
			<name>Spring Milestones</name>
			<url>https://repo.spring.io/milestone</url>
		</repository>
	</repositories>
	<pluginRepositories>
		<pluginRepository>
			<id>spring-milestones</id>
			<name>Spring Milestones</name>
			<url>https://repo.spring.io/milestone</url>
		</pluginRepository>
	</pluginRepositories>

```

Be sure to also have the separate `Spring Milestones` repository definition in place, since the library isn't available on Maven Central right now!


### Set start-class element in pom.xml

For successfully being able to execute the `native-image` compilation process, we need to provide the command with the full name of our Spring Boot main class. 

At first I provided a parameter for my `compile.sh` script we have a look into later on. But as the [native-image-maven-plugin](https://mvnrepository.com/artifact/com.oracle.substratevm/native-image-maven-plugin) also relies on this setting, I found it rather okay to provide this class' name inside the [pom.xml](pom.xml):

```
	<properties>
		...
		<start-class>io.jonashackt.springbootgraal.SpringBootHelloApplication</start-class>
	</properties>
```

Since after setting this class once in our `pom.xml`, we don't need to bother with this parameter again - since we could read it from our pom in the later steps automatically.


### Craft a compile.sh script

I'am pretty sure, that this step described here will not be necessary when Spring will officially release the Graal full support. But right now, we do need to do a little grunt work here.

There are great examples of working compile scripts inside the [spring-graalvm-native-samples](https://github.com/spring-projects-experimental/spring-graalvm-native/tree/master/spring-graalvm-native-samples) project. So let's try to derive our own from that - just have a look into this project's [compile.sh](compile.sh):

```shell script
#!/usr/bin/env bash

echo ""[-->] Detect artifactId from pom.xml""
ARTIFACT=$(mvn -q \
-Dexec.executable=echo \
-Dexec.args='${project.artifactId}' \
--non-recursive \
exec:exec);
echo ""artifactId is '$ARTIFACT'""

echo ""[-->] Detect artifact version from pom.xml""
VERSION=$(mvn -q \
  -Dexec.executable=echo \
  -Dexec.args='${project.version}' \
  --non-recursive \
  exec:exec);
echo ""artifact version is '$VERSION'""

echo ""[-->] Detect Spring Boot Main class ('start-class') from pom.xml""
MAINCLASS=$(mvn -q \
-Dexec.executable=echo \
-Dexec.args='${start-class}' \
--non-recursive \
exec:exec);
echo ""Spring Boot Main class ('start-class') is '$MAINCLASS'""
```

The first part of the script is dedicated to define needed variables for later GraalVM Native Image compilation. The variables `ARTIFACT`, `VERSION` and `MAINCLASS` could be simply derived from our [pom.xml](pom.xml) with [the help of the Maven exec plugin](https://stackoverflow.com/a/26514030/4964553).

In the next section of the [compile.sh](compile.sh) script, we clean (aka remove) the `target` directory and build our Spring Boot App via a well known `mvn package`:

```shell script
echo ""[-->] Cleaning target directory & creating new one""
rm -rf target
mkdir -p target/native-image

echo ""[-->] Build Spring Boot App with mvn package""
mvn -DskipTests package
```


After the build, the Spring Boot fat jar needs to be expanded and the classpath needs to be set to the content of the results.

Also the Spring Graal AutomaticFeature needs to be available on the classpath. This is taken care by using the all the libraries found in `BOOT-INF/lib`, since by using the Maven dependency of `spring-graalvm-native` the automatic feature also resides there. 

```shell script
echo ""[-->] Expanding the Spring Boot fat jar""
JAR=""$ARTIFACT-$VERSION.jar""
cd target/native-image
jar -xvf ../$JAR >/dev/null 2>&1
cp -R META-INF BOOT-INF/classes

echo ""[-->] Set the classpath to the contents of the fat jar (where the libs contain the Spring Graal AutomaticFeature)""
LIBPATH=`find BOOT-INF/lib | tr '\n' ':'`
CP=BOOT-INF/classes:$LIBPATH
``` 

Now finally the GraalVM Native Image compilation is triggered with lot's of appropriate configuration options:

```shell script
GRAALVM_VERSION=`native-image --version`
echo ""[-->] Compiling Spring Boot App '$ARTIFACT' with $GRAALVM_VERSION""
time native-image \
  -H:+TraceClassInitialization \
  -H:Name=$ARTIFACT \
  -H:+ReportExceptionStackTraces \
  -Dspring.graal.remove-unused-autoconfig=true \
  -Dspring.graal.remove-yaml-support=true \
  -cp $CP $MAINCLASS;
```

I altered this section compared to the example scripts also, since I wanted to see the compilation process in my console.


### Run the compile.sh script & start your native Spring Boot App

We can now run the compile script with: 

```shell script
./compile.sh
```

The compile step does take it's time (depending on your hardware!). On my MacBook Pro 2017 this takes around 3 to 4 minutes. I prepared a small asciinema record so that you can have a look at how the compilation process works:

[![asciicast](https://asciinema.org/a/320745.svg)](https://asciinema.org/a/320745)


If your console shows something like the following:

```shell script
[spring-boot-graal:93927]   (typeflow):  74,606.04 ms, 12.76 GB
[spring-boot-graal:93927]    (objects):  58,480.01 ms, 12.76 GB
[spring-boot-graal:93927]   (features):   8,413.90 ms, 12.76 GB
[spring-boot-graal:93927]     analysis: 147,776.93 ms, 12.76 GB
[spring-boot-graal:93927]     (clinit):   1,578.42 ms, 12.76 GB
[spring-boot-graal:93927]     universe:   4,909.40 ms, 12.76 GB
[spring-boot-graal:93927]      (parse):   6,885.61 ms, 12.78 GB
[spring-boot-graal:93927]     (inline):   6,594.06 ms, 12.78 GB
[spring-boot-graal:93927]    (compile):  33,040.00 ms, 12.79 GB
[spring-boot-graal:93927]      compile:  50,001.85 ms, 12.79 GB
[spring-boot-graal:93927]        image:   8,963.82 ms, 12.79 GB
[spring-boot-graal:93927]        write:   2,414.18 ms, 12.79 GB
[spring-boot-graal:93927]      [total]: 232,479.88 ms, 12.79 GB

real	3m54.635s
user	16m16.765s
sys	1m55.756s
```
 
you're now be able to __fire up your first GraalVM Native App!__. How cool is that?!! All you have to do is to run the generated executable `/target/native-image/spring-graal-vm`:

```shell script
$ ./target/native-image/spring-graal-vm

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::

2020-03-26 15:45:32.086  INFO 33864 --- [           main] i.j.s.SpringBootHelloApplication         : Starting SpringBootHelloApplication on PikeBook.fritz.box with PID 33864 (/Users/jonashecht/dev/spring-boot/spring-boot-graalvm/target/spring-boot-graal started by jonashecht in /Users/jonashecht/dev/spring-boot/spring-boot-graalvm/target)
2020-03-26 15:45:32.086  INFO 33864 --- [           main] i.j.s.SpringBootHelloApplication         : No active profile set, falling back to default profiles: default
2020-03-26 15:45:32.133  WARN 33864 --- [           main] io.netty.channel.DefaultChannelId        : Failed to find the current process ID from ''; using a random value: 801435406
2020-03-26 15:45:32.136  INFO 33864 --- [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port(s): 8080
2020-03-26 15:45:32.137  INFO 33864 --- [           main] i.j.s.SpringBootHelloApplication         : Started SpringBootHelloApplication in 0.083 seconds (JVM running for 0.086)
```

I also prepared a small asciicast - but be aware, you'll maybe don't get it since it's damn fast :)

[![asciicast](https://asciinema.org/a/313688.svg)](https://asciinema.org/a/313688)

__Your Spring Boot App started in 0.083!!__ Simply access the App via http://localhost:8080/hello.



# Doing all the steps together using the native-image-maven-plugin

Currently it really makes sense to hand-craft a bash script like our [compile.sh](compile.sh) in order to be able to debug all those `native-image` options!

But the development of GraalVM and the spring-graalvm-native projects really go fast. See [this post about GraalVM 20.1.0 release](https://medium.com/graalvm/graalvm-20-1-7ce7e89f066b) for example. So it makes also sense to have a look at the posibility to do all the needed steps to compile a Spring Boot app with GraalVM native images by only using the [native-image-maven-plugin](https://search.maven.org/search?q=g:org.graalvm.nativeimage%20AND%20a:native-image-maven-plugin).

> For more information about the `native-image-maven-plugin` see this post: https://medium.com/graalvm/simplifying-native-image-generation-with-maven-plugin-and-embeddable-configuration-d5b283b92f57

Therefor let's add a new Maven profile to our [pom.xml](pom.xml) as [described in the spring-graalvm-native docs](https://repo.spring.io/milestone/org/springframework/experimental/spring-graalvm-native-docs/0.7.0/spring-graalvm-native-docs-0.7.0.zip!/reference/index.html#_add_the_maven_plugin):

```xml
	<profiles>
		<profile>
			<id>native</id>
			<build>
				<plugins>
					<plugin>
						<groupId>org.graalvm.nativeimage</groupId>
						<artifactId>native-image-maven-plugin</artifactId>
						<version>20.2.0</version>
						<configuration>
							<buildArgs>-J-Xmx4G -H:+TraceClassInitialization -H:+ReportExceptionStackTraces -Dspring.graal.remove-unused-autoconfig=true -Dspring.graal.remove-yaml-support=true</buildArgs>
							<imageName>${project.artifactId}</imageName>
						</configuration>
						<executions>
							<execution>
								<goals>
									<goal>native-image</goal>
								</goals>
								<phase>package</phase>
							</execution>
						</executions>
					</plugin>
					<plugin>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-maven-plugin</artifactId>
					</plugin>
				</plugins>
			</build>
		</profile>
	</profiles>
```

The `buildArgs` tag is crucial here! We need to configure everything needed to successfully run a `native-image` command for our Spring Boot app as already used inside our [compile.sh](compile.sh).

But we can leave out `-cp $CP $MAINCLASS` parameter since they are already provided by the plugin. Remember now we run the `native-image` compilation from within the Maven pom context where all those is known.

Using the `<imageName>${project.artifactId}</imageName>` is a good idea in order to use our `artifactId` for the resulting executable image name. Otherwise we end up with a fully qualified class name like `io.jonashackt.springbootgraal.springboothelloapplication`.

Just remember to have the `start-class` property in place:

```
<properties>
		<start-class>io.jonashackt.springbootgraal.SpringBootHelloApplication</start-class>
        ...
</properties>
```

That should already suffice! Now we can simply run our Maven profile with:

```
mvn -Pnative clean package
```


### Tackling the 'No default constructor found Failed to instantiate java.lang.NoSuchMethodException: io.jonashackt.springbootgraal.SpringBootHelloApplication.<init>()' error

After executing the build process (which went fine), the resulting native image doesn't start without errors:

```
./spring-boot-graal

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::

Jun 05, 2020 10:46:27 AM org.springframework.boot.StartupInfoLogger logStarting
INFO: Starting application on PikeBook.fritz.box with PID 33047 (started by jonashecht in /Users/jonashecht/dev/spring-boot/spring-boot-graalvm/target)
Jun 05, 2020 10:46:27 AM org.springframework.boot.SpringApplication logStartupProfileInfo
INFO: No active profile set, falling back to default profiles: default
Jun 05, 2020 10:46:27 AM org.springframework.context.support.AbstractApplicationContext refresh
WARNING: Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'springBootHelloApplication': Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.jonashackt.springbootgraal.SpringBootHelloApplication]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.jonashackt.springbootgraal.SpringBootHelloApplication.<init>()
Jun 05, 2020 10:46:27 AM org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener logMessage
INFO:

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
Jun 05, 2020 10:46:27 AM org.springframework.boot.SpringApplication reportFailure
SEVERE: Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'springBootHelloApplication': Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.jonashackt.springbootgraal.SpringBootHelloApplication]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.jonashackt.springbootgraal.SpringBootHelloApplication.<init>()
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1320)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1214)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:895)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550)
	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:62)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226)
	at io.jonashackt.springbootgraal.SpringBootHelloApplication.main(SpringBootHelloApplication.java:10)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.jonashackt.springbootgraal.SpringBootHelloApplication]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.jonashackt.springbootgraal.SpringBootHelloApplication.<init>()
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:83)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1312)
	... 18 more
Caused by: java.lang.NoSuchMethodException: io.jonashackt.springbootgraal.SpringBootHelloApplication.<init>()
	at java.lang.Class.getConstructor0(DynamicHub.java:3349)
	at java.lang.Class.getDeclaredConstructor(DynamicHub.java:2553)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:78)
	... 19 more
```

> But what is the difference between the way our [compile.sh](compile.sh) works compared to the `native-image-maven-plugin` really? The parameters are the same!

I had a hard time figuring that one out! But finally I found a difference - it's all about the Spring Feature computed `spring.components`:

```
$ ./compile.sh
...
Excluding 104 auto-configurations from spring.factories file
Found no META-INF/spring.components -> synthesizing one...
Computed spring.components is
vvv
io.jonashackt.springbootgraal.HelloRouter=org.springframework.stereotype.Component
io.jonashackt.springbootgraal.HelloHandler=org.springframework.stereotype.Component
io.jonashackt.springbootgraal.SpringBootHelloApplication=org.springframework.stereotype.Component
^^^
Registered 3 entries
Configuring initialization time for specific types and packages:
#69 buildtime-init-classes   #21 buildtime-init-packages   #28 runtime-init-classes    #0 runtime-init-packages
```

with our [compile.sh](compile.sh) the Feature finds the 3 classes that are Spring Components and thus are relevant for our Application to work.

```
$ mvn -Pnative clean package
...
Excluding 104 auto-configurations from spring.factories file
Found no META-INF/spring.components -> synthesizing one...
Computed spring.components is
vvv
^^^
Registered 0 entries
Configuring initialization time for specific types and packages:
#69 buildtime-init-classes   #21 buildtime-init-packages   #28 runtime-init-classes    #0 runtime-init-packages
```

Our Maven plugin does not recognize the three needed classes! And thus it also doesn't successfully run our application in the end, since the REST controller doesn't work, if we access it via http://localhost:8080/hello

In a non-native world, our Spring Components would be explored at runtime via component scanning. But with GraalVM native image compilation, all notion of a thing called classpath is lost at runtime! So we need something to do the component scanning at build time.
The one utility that does this is the [spring-context-indexer](https://stackoverflow.com/questions/47254907/how-can-i-create-a-spring-5-component-index/48407939) and is executed by the Spring @AutomaticFeature for us, if we use our `compile.sh`.

But using the `native-image-maven-plugin` this isn't done automatically! So we have to explicitely include the [spring-context-indexer](https://mvnrepository.com/artifact/org.springframework/spring-context-indexer/5.2.6.RELEASE) dependency inside our [pom.xml]:

```xml
		<dependency>
			<groupId>org.springframework</groupId>
			<artifactId>spring-context-indexer</artifactId>
		</dependency>
```

Now running a Maven build, the file `target/classes/META_INF/spring.components` containing our 3 needed classes is created:

```
io.jonashackt.springbootgraal.HelloHandler=org.springframework.stereotype.Component
io.jonashackt.springbootgraal.HelloRouter=org.springframework.stereotype.Component
io.jonashackt.springbootgraal.SpringBootHelloApplication=org.springframework.stereotype.Component
```

And using that dependency, our Maven build finally works as expected:

```
$ mvn -Pnative clean package
...
Excluding 104 auto-configurations from spring.factories file
Processing META-INF/spring.components files...
Registered 3 entries
Configuring initialization time for specific types and packages:
#69 buildtime-init-classes   #21 buildtime-init-packages   #28 runtime-init-classes    #0 runtime-init-packages
...
```

__The question remains why the Spring @AutomaticFeature doesn't do that automatically only while executed via the `native-image-maven-plugin`!__


# Comparing Startup time & Memory footprint 

Ok, the initial goal was to run our beloved Spring Boot Apps at lightning speed. Now we have a ""normal"" Spring Boot App, that we're able to run with:

```
$ java -jar target/spring-boot-graal-0.0.1-SNAPSHOT.jar

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::             (v2.3.0.M4)

2020-04-30 15:40:21.187  INFO 40149 --- [           main] i.j.s.SpringBootHelloApplication         : Starting SpringBootHelloApplication v0.0.1-SNAPSHOT on PikeBook.fritz.box with PID 40149 (/Users/jonashecht/dev/spring-boot/spring-boot-graalvm/target/spring-boot-graal-0.0.1-SNAPSHOT.jar started by jonashecht in /Users/jonashecht/dev/spring-boot/spring-boot-graalvm)
2020-04-30 15:40:21.190  INFO 40149 --- [           main] i.j.s.SpringBootHelloApplication         : No active profile set, falling back to default profiles: default
2020-04-30 15:40:22.280  INFO 40149 --- [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port(s): 8080
2020-04-30 15:40:22.288  INFO 40149 --- [           main] i.j.s.SpringBootHelloApplication         : Started SpringBootHelloApplication in 1.47 seconds (JVM running for 1.924)
```

The standard way takes about `1.47 seconds` to start up and it uses around `491 MB` of RAM:

```
  PID TTY           TIME CMD
Processes: 545 total, 2 running, 1 stuck, 542 sleeping, 2943 threads                                                                                                     16:21:23
Load Avg: 1.35, 1.92, 2.30  CPU usage: 3.96% user, 3.84% sys, 92.19% idle  SharedLibs: 240M resident, 63M data, 19M linkedit.
MemRegions: 224056 total, 3655M resident, 50M private, 6794M shared. PhysMem: 16G used (3579M wired), 93M unused.
VM: 2744G vsize, 1997M framework vsize, 64447396(189) swapins, 66758016(0) swapouts. Networks: packets: 34854978/40G in, 30746488/34G out.
Disks: 28626843/545G read, 11039646/423G written.

PID    COMMAND      %CPU TIME     #TH  #WQ  #POR MEM  PURG CMPR PGRP  PPID STATE    BOOSTS    %CPU_ME %CPU_OTHRS UID  FAULTS  COW  MSGS MSGR SYSBSD SYSM CSW    PAGE IDLE POWE
40862  java         0.1  00:05.46 27   1    112  491M 0B   0B   40862 1592 sleeping *0[1]     0.00000 0.00000    501  136365  1942 5891 2919 52253+ 8577 21848+ 7148 733+ 0.8
```

Now comparing our Natively compiled Spring Boot App, we see a startup time of about `0.078 seconds`:

```
./spring-boot-graal

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::

2020-05-01 10:25:31.200  INFO 42231 --- [           main] i.j.s.SpringBootHelloApplication         : Starting SpringBootHelloApplication on PikeBook.fritz.box with PID 42231 (/Users/jonashecht/dev/spring-boot/spring-boot-graalvm/target/native-image/spring-boot-graal started by jonashecht in /Users/jonashecht/dev/spring-boot/spring-boot-graalvm/target/native-image)
2020-05-01 10:25:31.200  INFO 42231 --- [           main] i.j.s.SpringBootHelloApplication         : No active profile set, falling back to default profiles: default
2020-05-01 10:25:31.241  WARN 42231 --- [           main] io.netty.channel.DefaultChannelId        : Failed to find the current process ID from ''; using a random value: 635087100
2020-05-01 10:25:31.245  INFO 42231 --- [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port(s): 8080
2020-05-01 10:25:31.245  INFO 42231 --- [           main] i.j.s.SpringBootHelloApplication         : Started SpringBootHelloApplication in 0.078 seconds (JVM running for 0.08)
```

and uses only `30MB` of RAM:

```
Processes: 501 total, 2 running, 499 sleeping, 2715 threads                                                                                                              10:26:05
Load Avg: 5.73, 10.11, 6.17  CPU usage: 4.33% user, 3.86% sys, 91.79% idle  SharedLibs: 162M resident, 34M data, 9248K linkedit.
MemRegions: 214693 total, 2846M resident, 72M private, 1677M shared. PhysMem: 11G used (3607M wired), 4987M unused.
VM: 2448G vsize, 1997M framework vsize, 77090986(192) swapins, 80042677(0) swapouts.  Networks: packets: 31169140/37G in, 27833716/33G out.
Disks: 29775686/600G read, 11686485/480G written.

PID    COMMAND      %CPU TIME     #TH  #WQ  #POR MEM  PURG CMPR PGRP  PPID STATE    BOOSTS    %CPU_ME %CPU_OTHRS UID  FAULT COW  MSGS MSGR SYSB SYSM CSW  PAGE IDLE POWE INST CYCL
42231  spring-boot- 0.0  00:00.08 7    1    38   30M  0B   0B   42231 1592 sleeping *0[1]     0.00000 0.00000    501  17416 2360 77   20   2186 186  174  27   2    0.0  0    0
```

So with a default Spring App we have around 500MB memory consumption, a natively compiled Spring App has only 30MB. That means, we could run more than 15 Spring microservices with the same amount of RAM we needed for only one standard Spring microservice! Wohoo! :) 

And not to mention the startup times. Around 1.5 seconds versus only 78 milli seconds. So even our Kubernetes cluster is able to scale our Spring Boot Apps at lightning speed!



# Build and Run your Native Image compilation on a Cloud-CI provider like TravisCI

As we are used to test-driven development and we rely on very new code, which is for sure subject to change in the near future, we should be also able to automatically run our GraalVM Native image complilation on a Cloud CI provider like 

In order to run the compilation process, we need to [install GraalVM and GraalVM Native Image first on TravisCI](https://stackoverflow.com/a/61254927/4964553). Therefore let's have a look into our [.travis.yml](.travis.yml):

```yaml
dist: bionic
language: minimal

install:
  # Install GraalVM with SDKMAN
  - curl -s ""https://get.sdkman.io"" | bash
  - source ""$HOME/.sdkman/bin/sdkman-init.sh""
  - sdk install java 20.2.0.r11-grl

  # Check if GraalVM was installed successfully
  - java -version

  # Install Maven, that uses GraalVM for later builds
  - sdk install maven

  # Show Maven using GraalVM JDK
  - mvn --version

  # Install GraalVM Native Image
  - gu install native-image

  # Check if Native Image was installed properly
  - native-image --version

script:
  # Run GraalVM Native Image compilation of Spring Boot App
  - ./compile.sh
```

There are two main things to notice here: First we simply leverage the power of SDKMAN again to install GraalVM, as we already did on our local machines.

Second: __Don't use a `language: java` or the default linux distros like `dist: bionic`!__, because they ship with pre-installed Maven versions, which is configured to use the pre-installed OpenJDK - and __NOT our GraalVM installation__.

Therefore we simply use the `language: minimal`, which is [a simple way of getting our Travis builds based on a basic Travis build environment without pre-installed JDKs or Maven](https://stackoverflow.com/a/44738181/4964553) together with `distro: bionic` which will tell Travis to use the latest available `minimal` build image (see https://docs.travis-ci.com/user/languages/minimal-and-generic/).

Now our TravisCI builds should run a full native image compilation:

```
Warning: class initialization of class io.netty.handler.ssl.JettyNpnSslEngine failed with exception java.lang.NoClassDefFoundError: org/eclipse/jetty/npn/NextProtoNego$Provider. This class will be initialized at run time because option --allow-incomplete-classpath is used for image building. Use the option --initialize-at-run-time=io.netty.handler.ssl.JettyNpnSslEngine to explicitly request delayed initialization of this class.
[spring-boot-graal:5634]   (typeflow): 238,622.47 ms,  6.23 GB
[spring-boot-graal:5634]    (objects): 122,937.15 ms,  6.23 GB
[spring-boot-graal:5634]   (features):  10,311.79 ms,  6.23 GB
[spring-boot-graal:5634]     analysis: 379,203.23 ms,  6.23 GB
[spring-boot-graal:5634]     (clinit):   2,542.77 ms,  6.23 GB
[spring-boot-graal:5634]     universe:   9,890.85 ms,  6.23 GB
[spring-boot-graal:5634]      (parse):  20,901.16 ms,  6.23 GB
[spring-boot-graal:5634]     (inline):  14,131.55 ms,  6.23 GB
[spring-boot-graal:5634]    (compile):  94,847.99 ms,  6.23 GB
[spring-boot-graal:5634]      compile: 133,862.12 ms,  6.23 GB
[spring-boot-graal:5634]        image:   8,635.21 ms,  6.23 GB
[spring-boot-graal:5634]        write:   1,472.98 ms,  6.23 GB
``` 
 
See this build for example:

![successfull-travis-compile](screenshots/successfull-travis-compile.png)

### Tackling the 'There was an error linking the native image /usr/bin/ld: final link failed: Memory exhausted' error

I now had Travis finally compiling my Spring Boot App - but with a last error (you can [see full log here](https://travis-ci.org/github/jonashackt/spring-boot-graalvm)):

```
[spring-boot-graal:5634]   (typeflow): 238,622.47 ms,  6.23 GB
[spring-boot-graal:5634]    (objects): 122,937.15 ms,  6.23 GB
[spring-boot-graal:5634]   (features):  10,311.79 ms,  6.23 GB
[spring-boot-graal:5634]     analysis: 379,203.23 ms,  6.23 GB
[spring-boot-graal:5634]     (clinit):   2,542.77 ms,  6.23 GB
[spring-boot-graal:5634]     universe:   9,890.85 ms,  6.23 GB
[spring-boot-graal:5634]      (parse):  20,901.16 ms,  6.23 GB
[spring-boot-graal:5634]     (inline):  14,131.55 ms,  6.23 GB
[spring-boot-graal:5634]    (compile):  94,847.99 ms,  6.23 GB
[spring-boot-graal:5634]      compile: 133,862.12 ms,  6.23 GB
[spring-boot-graal:5634]        image:   8,635.21 ms,  6.23 GB
[spring-boot-graal:5634]        write:   1,472.98 ms,  6.23 GB
Fatal error: java.lang.RuntimeException: java.lang.RuntimeException: There was an error linking the native image: Linker command exited with 1

Linker command executed:
cc -v -o /home/travis/build/jonashackt/spring-boot-graalvm/target/native-image/spring-boot-graal -z noexecstack -Wl,--gc-sections -Wl,--dynamic-list -Wl,/tmp/SVM-8253584528623373425/exported_symbols.list -Wl,-x -L/tmp/SVM-8253584528623373425 -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64 /tmp/SVM-8253584528623373425/spring-boot-graal.o /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libjava.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libzip.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnio.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libextnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libffi.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/liblibchelper.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libjvm.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libstrictmath.a -lpthread -ldl -lz -lrt

Linker command ouput:
Using built-in specs.
COLLECT_GCC=cc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.4.0-1ubuntu1~18.04.1' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) 
COMPILER_PATH=/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/
LIBRARY_PATH=/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib/:/lib/x86_64-linux-gnu/:/lib/../lib/:/usr/lib/x86_64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/x86_64-linux-gnu/7/../../../:/lib/:/usr/lib/
COLLECT_GCC_OPTIONS='-v' '-o' '/home/travis/build/jonashackt/spring-boot-graalvm/target/native-image/spring-boot-graal' '-z' 'noexecstack' '-L/tmp/SVM-8253584528623373425' '-L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib' '-L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64' '-mtune=generic' '-march=x86-64'
 /usr/lib/gcc/x86_64-linux-gnu/7/collect2 -plugin /usr/lib/gcc/x86_64-linux-gnu/7/liblto_plugin.so -plugin-opt=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper -plugin-opt=-fresolution=/tmp/ccHdD8kF.res -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s -plugin-opt=-pass-through=-lc -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s --sysroot=/ --build-id --eh-frame-hdr -m elf_x86_64 --hash-style=gnu --as-needed -dynamic-linker /lib64/ld-linux-x86-64.so.2 -pie -z now -z relro -o /home/travis/build/jonashackt/spring-boot-graalvm/target/native-image/spring-boot-graal -z noexecstack /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o -L/tmp/SVM-8253584528623373425 -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64 -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. --gc-sections --dynamic-list /tmp/SVM-8253584528623373425/exported_symbols.list -x /tmp/SVM-8253584528623373425/spring-boot-graal.o /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libjava.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libzip.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnio.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libextnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libffi.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/liblibchelper.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libjvm.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libstrictmath.a -lpthread -ldl -lz -lrt -lgcc --push-state --as-needed -lgcc_s --pop-state -lc -lgcc --push-state --as-needed -lgcc_s --pop-state /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o
/usr/bin/ld: final link failed: Memory exhausted
collect2: error: ld returned 1 exit status

	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at java.base/java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:600)
	at java.base/java.util.concurrent.ForkJoinTask.get(ForkJoinTask.java:1006)
	at com.oracle.svm.hosted.NativeImageGenerator.run(NativeImageGenerator.java:462)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner.buildImage(NativeImageGeneratorRunner.java:357)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner.build(NativeImageGeneratorRunner.java:501)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner.main(NativeImageGeneratorRunner.java:115)
	at com.oracle.svm.hosted.NativeImageGeneratorRunner$JDK9Plus.main(NativeImageGeneratorRunner.java:528)
Caused by: java.lang.RuntimeException: There was an error linking the native image: Linker command exited with 1

Linker command executed:
cc -v -o /home/travis/build/jonashackt/spring-boot-graalvm/target/native-image/spring-boot-graal -z noexecstack -Wl,--gc-sections -Wl,--dynamic-list -Wl,/tmp/SVM-8253584528623373425/exported_symbols.list -Wl,-x -L/tmp/SVM-8253584528623373425 -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64 /tmp/SVM-8253584528623373425/spring-boot-graal.o /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libjava.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libzip.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnio.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libextnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libffi.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/liblibchelper.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libjvm.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libstrictmath.a -lpthread -ldl -lz -lrt

Linker command ouput:
Using built-in specs.
COLLECT_GCC=cc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.4.0-1ubuntu1~18.04.1' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) 
COMPILER_PATH=/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/
LIBRARY_PATH=/usr/lib/gcc/x86_64-linux-gnu/7/:/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib/:/lib/x86_64-linux-gnu/:/lib/../lib/:/usr/lib/x86_64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/x86_64-linux-gnu/7/../../../:/lib/:/usr/lib/
COLLECT_GCC_OPTIONS='-v' '-o' '/home/travis/build/jonashackt/spring-boot-graalvm/target/native-image/spring-boot-graal' '-z' 'noexecstack' '-L/tmp/SVM-8253584528623373425' '-L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib' '-L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64' '-mtune=generic' '-march=x86-64'
 /usr/lib/gcc/x86_64-linux-gnu/7/collect2 -plugin /usr/lib/gcc/x86_64-linux-gnu/7/liblto_plugin.so -plugin-opt=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper -plugin-opt=-fresolution=/tmp/ccHdD8kF.res -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s -plugin-opt=-pass-through=-lc -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s --sysroot=/ --build-id --eh-frame-hdr -m elf_x86_64 --hash-style=gnu --as-needed -dynamic-linker /lib64/ld-linux-x86-64.so.2 -pie -z now -z relro -o /home/travis/build/jonashackt/spring-boot-graalvm/target/native-image/spring-boot-graal -z noexecstack /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o -L/tmp/SVM-8253584528623373425 -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib -L/home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64 -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. --gc-sections --dynamic-list /tmp/SVM-8253584528623373425/exported_symbols.list -x /tmp/SVM-8253584528623373425/spring-boot-graal.o /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libjava.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libzip.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libnio.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/libextnet.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libffi.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/liblibchelper.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libjvm.a /home/travis/.sdkman/candidates/java/20.0.0.r11-grl/lib/svm/clibraries/linux-amd64/libstrictmath.a -lpthread -ldl -lz -lrt -lgcc --push-state --as-needed -lgcc_s --pop-state -lc -lgcc --push-state --as-needed -lgcc_s --pop-state /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o
/usr/bin/ld: final link failed: Memory exhausted
collect2: error: ld returned 1 exit status

	at com.oracle.svm.hosted.image.NativeBootImageViaCC.handleLinkerFailure(NativeBootImageViaCC.java:424)
	at com.oracle.svm.hosted.image.NativeBootImageViaCC.write(NativeBootImageViaCC.java:399)
	at com.oracle.svm.hosted.NativeImageGenerator.doRun(NativeImageGenerator.java:657)
	at com.oracle.svm.hosted.NativeImageGenerator.lambda$run$0(NativeImageGenerator.java:445)
	at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1407)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)
Error: Image build request failed with exit status 1

real	9m11.937s
user	17m46.032s
sys	0m11.720s
```

# Build and Run your Native Image compilation on GitHub Actions

Since Travis laid down their OpenSource support to a massive degree, many maintainers move their repos over to GitHub Actions - see also this post: https://blog.codecentric.de/en/2021/02/github-actions-pipeline/

So let's implement a [.github/workflows/native-image-compile.yml](.github/workflows/native-image-compile.yml):

```yaml
name: native-image-compile

on: [push]

jobs:
  native-image-compile-on-host:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2

    - name: Cache SDKMAN archives & candidates
      uses: actions/cache@v2
      with:
        path: ~/.sdkman
        key: ${{ runner.os }}-sdkman-${{ hashFiles('pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-sdkman-

    - name: Install GraalVM, Maven, Native Image & Run Maven build
      run: |
        echo 'Install GraalVM with SDKMAN'
        curl -s ""https://get.sdkman.io"" | bash
        source ""$HOME/.sdkman/bin/sdkman-init.sh""
        sdk install java 20.2.0.r11-grl

        echo 'Check if GraalVM was installed successfully'
        java -version

        echo 'Install GraalVM Native Image'
        gu install native-image

        echo 'Check if Native Image was installed properly'
        native-image --version

        echo 'Install Maven, that uses GraalVM for later builds'
        source ""$HOME/.sdkman/bin/sdkman-init.sh""
        sdk install maven

        echo 'Show Maven using GraalVM JDK'
        mvn --version

        echo 'Run GraalVM Native Image compilation of Spring Boot App (Maven version instead of ./compile.sh)'
        mvn -B clean package -P native --no-transfer-progress
```

This one does exactly what we did with TravisCI - building the native image using Maven and installing GraalVM beforehand.


# Use Docker to compile a Spring Boot App with GraalVM

There's an [official Docker image from Oracle](https://github.com/orgs/graalvm/packages/container/package/graalvm-ce), but this one sadyl lacks both Maven with it's `mvn` command and the `native-image` plugin also not installed.

But we can help ourselves - we just craft a simple [Dockerfile](Dockerfile) for us. We're already used to leverage SDKMAN to install Maven. Therefore we need to install `unzip` and `zip` first, since SDKMAN needs both to work properly:

```dockerfile
# Simple Dockerfile adding Maven and GraalVM Native Image compiler to the standard
# https://github.com/orgs/graalvm/packages/container/package/graalvm-ce image
FROM ghcr.io/graalvm/graalvm-ce:ol7-java11-20.3.1.2

# For SDKMAN to work we need unzip & zip
RUN yum install -y unzip zip

RUN \
    # Install SDKMAN
    curl -s ""https://get.sdkman.io"" | bash; \
    source ""$HOME/.sdkman/bin/sdkman-init.sh""; \
    sdk install maven; \
    # Install GraalVM Native Image
    gu install native-image;

RUN source ""$HOME/.sdkman/bin/sdkman-init.sh"" && mvn --version

RUN native-image --version

# Always use source sdkman-init.sh before any command, so that we will be able to use 'mvn' command
ENTRYPOINT bash -c ""source $HOME/.sdkman/bin/sdkman-init.sh && $0""
```

In order to enable the `mvn` command for a user of our Docker image, we craft a slightly more interesting `ENTRYPOINT` that always prefixes commands with `""source $HOME/.sdkman/bin/sdkman-init.sh`.

Now let's build our Image with:

```shell script
docker build . --tag=graalvm-ce:20.3.0-java11-mvn-native-image
```

Now we should be able to launch our GraalVM Native Image compilation inside official Oracle GraalVM image with:

```shell script
docker run -it --rm \
    --volume $(pwd):/build \
    --workdir /build \
    --volume ""$HOME""/.m2:/root/.m2 \
    graalvm-ce:20.3.0-java11-mvn-native-image ./compile.sh
```

When I first thought about a Docker usage, I wanted to pack this build into a `Dockerfile` also - but then I realized, that there's [no easy way of using Docker volumes at Docker build time](https://stackoverflow.com/questions/51086724/docker-build-using-volumes-at-build-time). But I really wanted to mount a Docker volume to my local Maven repository like `--volume ""$HOME""/.m2:/root/.m2` to prevent the download of all the Spring Maven dependencies over and over again every time we start our Docker container.

So I went with another way: We simply use a `docker run` command, that will compile our native Spring Boot app into our project's working directory (with `--volume $(pwd):/build`).

The resulting `spring-boot-graal` native App should be ready after some minutes of heavy compilation.

__But!__ We're not able to run it! Hell yeah - because we turned our platform independend Java App into a platform dependend one! That's the price for speed I guess :)


### Tackling 'Exception java.lang.OutOfMemoryError in thread ""native-image pid watcher""' error

Sometimes the `docker run` seems to take ages to complete - and then a `java.lang.OutOfMemoryError` is thrown into the log:

```
14:06:34.609 [ForkJoinPool-2-worker-3] DEBUG io.netty.handler.codec.compression.ZlibCodecFactory - -Dio.netty.noJdkZlibEncoder: false
Exception in thread ""native-image pid watcher""
Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread ""native-image pid watcher""
```

Then it is very likely that your Docker Engine has not enough RAM it is able to use! In my Mac installation the default is only `2.00 GB`:

![docker-mac-memory](screenshots/docker-mac-memory.png)

As [stated in the comments of this so q&a](https://stackoverflow.com/questions/57935533/native-image-building-process-is-frozen-in-quarkus), you have to give Docker much more memory since the GraalVM Native Image compilation process is really RAM intensive. I had a working local compilation in the Docker Container when I gave Docker `12.00 GB` of RAM.


### Run Spring Boot Native Apps in Docker

Now that our Docker build works in general, we should also run our Native Spring Boot App inside a Docker container. Therefore a Docker multi-stage build would come in handy, since we could then do the build & Native Image compilation stuff in the first container - and then only take the resulting Native app and use it in the second container to run it.

Therefore let's refactor our Dockerfile:

```dockerfile
# Simple Dockerfile adding Maven and GraalVM Native Image compiler to the standard
# https://github.com/orgs/graalvm/packages/container/package/graalvm-ce image
FROM ghcr.io/graalvm/graalvm-ce:ol7-java11-20.3.1.2

ADD . /build
WORKDIR /build

# For SDKMAN to work we need unzip & zip
RUN yum install -y unzip zip

RUN \
    # Install SDKMAN
    curl -s ""https://get.sdkman.io"" | bash; \
    source ""$HOME/.sdkman/bin/sdkman-init.sh""; \
    sdk install maven; \
    # Install GraalVM Native Image
    gu install native-image;

RUN source ""$HOME/.sdkman/bin/sdkman-init.sh"" && mvn --version

RUN native-image --version

RUN source ""$HOME/.sdkman/bin/sdkman-init.sh"" && ./compile.sh


# We use a Docker multi-stage build here in order that we only take the compiled native Spring Boot App from the first build container
FROM oraclelinux:7-slim

MAINTAINER Jonas Hecht

# Add Spring Boot Native app spring-boot-graal to Container
COPY --from=0 ""/build/target/native-image/spring-boot-graal"" spring-boot-graal

# Fire up our Spring Boot Native app by default
CMD [ ""sh"", ""-c"", ""./spring-boot-graal"" ]
```

Additionally the second container isn't based on the `ghcr.io/graalvm/graalvm-ce` image containing a GraalVM installation, Maven and the `native-image` command - but instead uses [the base image of this image](https://github.com/oracle/docker-images/blob/master/GraalVM/CE/Dockerfile.java11), which is `oraclelinux:7-slim`.

With that we reduce the resulting Docker image size from around `1.48GB` to only `186MB`!

Let't run our Multi-stage build with the following command:


```shell script
docker build . --tag=spring-boot-graal
```

This again will take a while - you may grab a coffee :)

After the Docker build successfully finished with some output like that:

```
[spring-boot-graal:289]   (typeflow): 114,554.33 ms,  6.58 GB
[spring-boot-graal:289]    (objects):  63,145.07 ms,  6.58 GB
[spring-boot-graal:289]   (features):   6,990.75 ms,  6.58 GB
[spring-boot-graal:289]     analysis: 190,400.92 ms,  6.58 GB
[spring-boot-graal:289]     (clinit):   1,970.98 ms,  6.67 GB
[spring-boot-graal:289]     universe:   6,263.93 ms,  6.67 GB
[spring-boot-graal:289]      (parse):  11,824.83 ms,  6.67 GB
[spring-boot-graal:289]     (inline):   7,216.63 ms,  6.73 GB
[spring-boot-graal:289]    (compile):  63,692.52 ms,  6.77 GB
[spring-boot-graal:289]      compile:  86,836.76 ms,  6.77 GB
[spring-boot-graal:289]        image:  10,050.63 ms,  6.77 GB
[spring-boot-graal:289]        write:   1,319.52 ms,  6.77 GB
[spring-boot-graal:289]      [total]: 313,644.65 ms,  6.77 GB

real	5m16.447s
user	16m32.096s
sys	1m34.441s
Removing intermediate container 151e1413ec2f
 ---> be671d4f237f
Step 10/13 : FROM docker pull ghcr.io/graalvm/graalvm-ce:ol7-java11-20.3.1.2
 ---> 364d0bb387bd
Step 11/13 : MAINTAINER Jonas Hecht
 ---> Using cache
 ---> 445833938b60
Step 12/13 : COPY --from=0 ""/build/target/native-image/spring-boot-graal"" spring-boot-graal
 ---> 2d717a0db703
Step 13/13 : CMD [ ""sh"", ""-c"", ""./spring-boot-graal"" ]
 ---> Running in 7fa931991d7e
Removing intermediate container 7fa931991d7e
 ---> a0afe30b3619
Successfully built a0afe30b3619
Successfully tagged spring-boot-graal:latest
```

We are able to run our Spring Boot Native app with `docker run -p 8080:8080 spring-boot-graal`: 

```
$ docker run -p 8080:8080 spring-boot-graal

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::

2020-04-19 09:22:51.547  INFO 1 --- [           main] i.j.s.SpringBootHelloApplication         : Starting SpringBootHelloApplication on 06274db526b0 with PID 1 (/spring-boot-graal started by root in /)
2020-04-19 09:22:51.547  INFO 1 --- [           main] i.j.s.SpringBootHelloApplication         : No active profile set, falling back to default profiles: default
2020-04-19 09:22:51.591  WARN 1 --- [           main] io.netty.channel.DefaultChannelId        : Failed to find the current process ID from ''; using a random value: -949685832
2020-04-19 09:22:51.593  INFO 1 --- [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port(s): 8080
2020-04-19 09:22:51.594  INFO 1 --- [           main] i.j.s.SpringBootHelloApplication         : Started SpringBootHelloApplication in 0.063 seconds (JVM running for 0.065)
```

Now simply access your App via http://localhost:8080/hello


# Running Spring Boot Graal Native Apps on Heroku

Finally we are where we wanted to be in the first place! We're able to run our natively compiled Spring Boot Apps inside Docker containers. It should be easy to deploy those to [a cloud provider like Heroku](https://heroku.com)!

And it's good to get back on my last year's article on Running [Spring Boot on Heroku with Docker, JDK 11 & Maven 3.5.x](https://blog.codecentric.de/en/2019/08/spring-boot-heroku-docker-jdk11/), since there may be tweaks we need with our Graal-Setup also!

Now as we move forward to a deployment of our Spring Boot Native app on a cloud provider's Docker infrastructure, we need to have our Spring Boot Native app's port configurable in a dynamic fashion! Most cloud providers want to dynamically set this port from the outside - as [we can see in Heroku for example](https://devcenter.heroku.com/articles/setting-the-http-port-for-java-applications).

[As the Heroku docs state]( https://devcenter.heroku.com/articles/container-registry-and-runtime#dockerfile-commands-and-runtime):
                                                                                                                    
> The web process must listen for HTTP traffic on $PORT, which is set by Heroku. EXPOSE in Dockerfile is not respected, but can be used for local testing. Only HTTP requests are supported.


### Configure the Spring Boot Native app's port dynamically inside a Docker container

To achieve that, we need to somehow pass a port variable to our Spring Boot Native app from command line. Since the GraalVM support is just in its early stages, we can't rely on a huge documentation. But as this is a similar problem other frameworks also needed to solve, I thought about [Quarkus.io](https://quarkus.io/) which has been around for some time now - and should have had exactly this problem already.

And [there's the stackoverflow answer](https://stackoverflow.com/a/55043637/4964553) :) With Quarkus, you simply need to pass the port as `-D` parameter like `-Dquarkus.http.port=8081` to the native app.

[Could this be mapped onto Spring Boot too?](https://stackoverflow.com/questions/61302412/how-to-configure-the-port-of-a-spring-boot-app-thats-natively-compiled-by-graal) Luckily yes! Just run your Spring Boot native app with

```shell script
./spring-boot-graal -Dserver.port=8087
```

And your App starts using port `8087` :)

Now we are able to pass the port dynamically from a `docker run` command. Therefore we need to make a small change to our [Dockerfile](Dockerfile):

```dockerfile
...
# Add Spring Boot Native app spring-boot-graal to Container
COPY --from=0 ""/build/target/native-image/spring-boot-graal"" spring-boot-graal

# Fire up our Spring Boot Native app by default
CMD [ ""sh"", ""-c"", ""./spring-boot-graal -Dserver.port=$PORT"" ]
```

With this we are able to run our Dockerized Spring Boot Native App with a dynamic port setting from command line like this:

```
docker run -e ""PORT=8087"" -p 8087:8087 spring-boot-graal
```

Finally try to access your app at http://localhost:8087/hello


### Use Docker to run our Spring Boot Native App on Heroku

First things first: Let's start by creating your Heroku app if you haven't already:

```
heroku create spring-boot-graal
```

Then you simply set the Heroku stack:

```
heroku stack:set container --app spring-boot-graal
```

Sadly we can't use the section __'Configuring Heroku to use Docker'__ of my article on Running [Spring Boot on Heroku with Docker, JDK 11 & Maven 3.5.x](https://blog.codecentric.de/en/2019/08/spring-boot-heroku-docker-jdk11/) in this case here, since we would run into the `Error: Image build request failed with exit status 137`.
                                                                                                                                                                                                                                                           
My first attempts on Heroku lead to the build problems:

```
Error: Image build request failed with exit status 137
real	2m51.946s
user	2m9.594s
sys	0m19.085s
The command '/bin/sh -c source ""$HOME/.sdkman/bin/sdkman-init.sh"" && ./compile.sh' returned a non-zero code: 137
```

This error appears usually [when Docker does not have enough memory](https://codefresh.io/docs/docs/troubleshooting/common-issues/error-code-137/). And since the free Heroku dyno only guarantees us `512MB` of RAM :( ([see Dyno Types](https://devcenter.heroku.com/articles/dyno-types))), we won't get far on this way.

But [as the docs state](https://devcenter.heroku.com/categories/deploying-with-docker) the way of [Building Docker Images with heroku.yml](https://devcenter.heroku.com/articles/build-docker-images-heroku-yml) isn't the only way to run Docker containers on Heroku. There's another way of using the [Container Registry & Runtime (Docker Deploys)](https://devcenter.heroku.com/articles/container-registry-and-runtime)!

With that we could decouple the Docker image build process (which is so much memory hungry!) from simply running the Docker container based on that image.


### Work around the Heroku 512MB RAM cap: Building our Dockerimage with TravisCI

So we need to do the Docker build on another platform - why not simply use Travis?! It already proofed to work directly on the host, why not also [using the Travis Docker service](https://docs.travis-ci.com/user/docker/)?!

Leveraging [Travis jobs feature](https://docs.travis-ci.com/user/build-stages/), we can also do both in parallel - just have a look at the following screenshot:

![travis-parallel-jobs-direct-and-docker](screenshots/travis-parallel-jobs-direct-and-docker.png)


Therefore we implement two separate Travis jobs `""Native Image compile on Travis Host""` and `""Native Image compile in Docker on Travis & Push to Heroku Container Registry""` inside our [.travis.yml](.travis.yml) and include the `docker` services:

```yaml
# use minimal Travis build image so that we could install our own JDK (Graal) and Maven
# use newest available minimal distro - see https://docs.travis-ci.com/user/languages/minimal-and-generic/
dist: bionic
language: minimal

services:
  - docker

jobs:
  include:
    - script:
        # Install GraalVM with SDKMAN
        - curl -s ""https://get.sdkman.io"" | bash
        - source ""$HOME/.sdkman/bin/sdkman-init.sh""
        - sdk install java 20.2.0.r11-grl

        # Check if GraalVM was installed successfully
        - java -version

        # Install Maven, that uses GraalVM for later builds
        - sdk install maven

        # Show Maven using GraalVM JDK
        - mvn --version

        # Install GraalVM Native Image
        - gu install native-image

        # Check if Native Image was installed properly
        - native-image --version

        # Run GraalVM Native Image compilation of Spring Boot App
        - ./compile.sh

      name: ""Native Image compile on Travis Host""

    - script:
        # Compile with Docker
        - docker build . --tag=spring-boot-graal
      name: ""Native Image compile in Docker on Travis & Push to Heroku Container Registry""
```

### Tackling 'Error: Image build request failed with exit status 137' with the -J-Xmx parameter

[As mentioned in the Spring docs](https://repo.spring.io/milestone/org/springframework/experimental/spring-graalvm-native-docs/0.7.0/spring-graalvm-native-docs-0.7.0.zip!/reference/index.html#_options_enabled_by_default), the `spring-graalvm-native` uses the `--no-server` option by default when running Native Image compilations with Spring.

But why is this parameter used? See the official docs: https://www.graalvm.org/docs/reference-manual/native-image/

> Another prerequisite to consider is the maximum heap size. Physical memory for running a JVM-based application may be insufficient to build a native image. For server-based image building we allow to use 80% of the reported physical RAM for all servers together, but never more than 14GB per server (for exact details please consult the native-image source code). If you run with --no-server option, you will get the whole 80% of what is reported as physical RAM as the baseline. This mode respects -Xmx arguments additionally.

We somehow could leave out the `no-server` option in order to reduce the amount of memory our Native Image compilation consumes - but there's an open issue in combination with Spring: https://github.com/oracle/graal/issues/1952 which says, that the images build without `--no-server` is sometimes unreliable.

Luckily there's [a hint in this GitHub issue](https://github.com/oracle/graal/issues/920), that we could configure the amount of memory the `--no-server` option takes in total with the help of a `Xmx` parameter like `-J-Xmx3G`.

Using that option together like this in our `native-image` command:

```shell script
time native-image \
  -J-Xmx4G \
  -H:+TraceClassInitialization \
  -H:Name=$ARTIFACT \
  -H:+ReportExceptionStackTraces \
  -Dspring.graal.remove-unused-autoconfig=true \
  -Dspring.graal.remove-yaml-support=true \
  -cp $CP $MAINCLASS;
```

we could repeatably reduce the amount of memory to 4GBs of RAM, which should be enough for TravisCI - since it provides us with more than 6GB using the Docker service ([see this build for example](https://travis-ci.org/github/jonashackt/spring-boot-graalvm/builds/677157831)). Using the option results in the following output:

```
08:07:23.999 [ForkJoinPool-2-worker-3] DEBUG io.netty.util.internal.PlatformDependent - maxDirectMemory: 4294967296 bytes (maybe)
...
[spring-boot-graal:215]   (typeflow): 158,492.53 ms,  4.00 GB
[spring-boot-graal:215]    (objects):  94,986.72 ms,  4.00 GB
[spring-boot-graal:215]   (features): 104,518.36 ms,  4.00 GB
[spring-boot-graal:215]     analysis: 368,005.35 ms,  4.00 GB
[spring-boot-graal:215]     (clinit):   3,107.18 ms,  4.00 GB
[spring-boot-graal:215]     universe:  12,502.04 ms,  4.00 GB
[spring-boot-graal:215]      (parse):  22,617.13 ms,  4.00 GB
[spring-boot-graal:215]     (inline):  10,093.57 ms,  3.49 GB
[spring-boot-graal:215]    (compile):  82,256.99 ms,  3.59 GB
[spring-boot-graal:215]      compile: 119,502.78 ms,  3.59 GB
[spring-boot-graal:215]        image:  12,087.80 ms,  3.59 GB
[spring-boot-graal:215]        write:   3,573.06 ms,  3.59 GB
[spring-boot-graal:215]      [total]: 558,194.13 ms,  3.59 GB

real	9m22.984s
user	24m41.948s
sys	2m3.179s
```

The one thing to take into account is that Native Image compilation will be a bit slower now. So if you run on your local machine with lot's of memory, feel free to delete the ` -J-Xmx4G` parameter :)


### Work around the Heroku 512MB RAM cap: Building our Dockerimage with GitHub Actions

```yaml
  native-image-compile-in-docker:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Compile Native Image using Docker
        run: docker build . --tag=registry.heroku.com/spring-boot-graal/web
```


### Pushing and Releasing our Dockerized Native Spring Boot App on Heroku Container Infrastructure

Now we should be able to finally [push the build Docker image into Heroku's Container Registry](https://devcenter.heroku.com/articles/container-registry-and-runtime#using-a-ci-cd-platform), from where we're able to run our Spring Boot Native app later on.

Therefore we need to [configure some environment variables in Travis in order to push](https://docs.travis-ci.com/user/docker/#pushing-a-docker-image-to-a-registry) to Heroku's Container Registry inside our TravisCI job's settings: `DOCKER_USERNAME` and `DOCKER_PASSWORD`. The first is your Heroku eMail, the latter is your Heroku API key. Be sure to prevent displaying the values in the build log:

![travis-env-vars-heroku](screenshots/travis-env-vars-heroku.png)

With the following configuration inside our [.travis.yml](.travis.yml), we should be able to successfully log in to Heroku Container Registry:

```yaml
    - script:
        # Login into Heroku Container Registry first, so that we can push our Image later
        - echo ""$DOCKER_PASSWORD"" | docker login -u ""$DOCKER_USERNAME"" --password-stdin registry.heroku.com
```

Now after a successful Docker build, that compiles our Spring Boot App into a native executable, we finally need to push the resulting Docker image into Heroku Container Registry.

Therefore we need to use the correct tag for our Docker image build([see the docs](https://devcenter.heroku.com/articles/container-registry-and-runtime#pushing-an-existing-image):

```shell script
docker build . --tag=registry.heroku.com/<app>/<process-type>
docker push registry.heroku.com/<app>/<process-type>
```

This means we add the following `docker tag` and `docker push` command into our [.travis.yml](.travis.yml):

```yaml
    - docker build . --tag=registry.heroku.com/spring-boot-graal/web
    - docker push registry.heroku.com/spring-boot-graal/web
```


The final step after a successful push is [to release our App on Heroku](https://devcenter.heroku.com/articles/container-registry-and-runtime#releasing-an-image), which is always the last step to deploy our App on Heroku using Docker [since May 2018](https://devcenter.heroku.com/changelog-items/1426) (before a push was all you had to do).

There are [two ways to achieve this](https://devcenter.heroku.com/articles/container-registry-and-runtime#releasing-an-image): either through the CLI via `heroku container:release web` or with the API. The first would require us to install Heroku CLI in Travis, the latter should work out-of-the-box. Therefore let's craft the needed `curl` command:

```shell script
curl -X PATCH https://api.heroku.com/apps/spring-boot-graal/formation \
          -d '{
                ""updates"": [
                {
                  ""type"": ""web"",
                  ""docker_image"": ""'""$(docker inspect registry.heroku.com/spring-boot-graal/web --format={{.Id}})""'""
                }]
              }' \
          -H ""Content-Type: application/json"" \
          -H ""Accept: application/vnd.heroku+json; version=3.docker-releases"" \
          -H ""Authorization: Bearer $DOCKER_PASSWORD""
```

This `curl` command is even better then the documented on in [the official Heroku docs](https://devcenter.heroku.com/articles/container-registry-and-runtime#api), since it already incorporates the `docker inspect registry.heroku.com/spring-boot-graal/web --format={{.Id}})` command to retrieve the needed Docker image id and also omits the need to login to Heroku CLI beforehand (to create the needed `~/.netrc` mentioned in the docs), since we simply use `-H ""Authorization: Bearer $DOCKER_PASSWORD""` here, where `$DOCKER_PASSWORD` is our Heroku API Key again.

The problem with Travis: [It does not understand our nice curl](https://travis-ci.org/github/jonashackt/spring-boot-graalvm/jobs/679008339) command, [since it interprets it totally wrong](https://stackoverflow.com/questions/34687610/how-to-properly-use-curl-in-travis-ci-config-file-yaml), even if we mind [the correct multiline usage](https://travis-ci.community/t/yaml-multiline-strings/3914/4). Well I guess our Java User Group Thüringen speaker Kai Tödter did already know that restriction of some CI systems, and [crafted himself a bash script](https://toedter.com/2018/06/02/heroku-docker-deployment-update/) for exactly that purpose.

At that point I created a script called [heroku-release.sh](heroku-release.sh):

```shell script
#!/usr/bin/env bash

herokuAppName=$1
dockerImageId=$(docker inspect registry.heroku.com/$herokuAppName/web --format={{.Id}})

curl -X PATCH https://api.heroku.com/apps/$herokuAppName/formation \
          -d '{
                ""updates"": [
                {
                  ""type"": ""web"",
                  ""docker_image"": ""'""$dockerImageId""'""
                }]
              }' \
          -H ""Content-Type: application/json"" \
          -H ""Accept: application/vnd.heroku+json; version=3.docker-releases"" \
          -H ""Authorization: Bearer $DOCKER_PASSWORD""
```

Using this script, we finally have our fully working [.travis.yml](.travis.yml):

```yaml
dist: bionic
language: minimal

services:
  - docker

- script:
    # Login into Heroku Container Registry first, so that we can push our Image later
    - echo ""$DOCKER_PASSWORD"" | docker login -u ""$DOCKER_USERNAME"" --password-stdin registry.heroku.com

    # Compile App with Docker
    - docker build . --tag=registry.heroku.com/spring-boot-graal/web

    # Push to Heroku Container Registry
    - docker push registry.heroku.com/spring-boot-graal/web

    # Release Dockerized Native Spring Boot App on Heroku
    - ./heroku-release.sh spring-boot-graal
```

That's it! After a successfull TravisCI build, we should be able to see our running Dockerized Spring Boot Native App on Heroku at https://spring-boot-graal.herokuapp.com/hello

![heroku-running-app](screenshots/heroku-running-app.png)

You can even use `heroku logs` to see what's happening behind the scenes:

```
$ heroku logs -a spring-boot-graal

2020-04-24T12:02:14.562471+00:00 heroku[web.1]: State changed from down to starting
2020-04-24T12:02:41.564599+00:00 heroku[web.1]: State changed from starting to up
2020-04-24T12:02:41.283549+00:00 app[web.1]:
2020-04-24T12:02:41.283574+00:00 app[web.1]: .   ____          _            __ _ _
2020-04-24T12:02:41.283575+00:00 app[web.1]: /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
2020-04-24T12:02:41.283575+00:00 app[web.1]: ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
2020-04-24T12:02:41.283576+00:00 app[web.1]: \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
2020-04-24T12:02:41.283576+00:00 app[web.1]: '  |____| .__|_| |_|_| |_\__, | / / / /
2020-04-24T12:02:41.283578+00:00 app[web.1]: =========|_|==============|___/=/_/_/_/
2020-04-24T12:02:41.286498+00:00 app[web.1]: :: Spring Boot ::
2020-04-24T12:02:41.286499+00:00 app[web.1]:
2020-04-24T12:02:41.287774+00:00 app[web.1]: 2020-04-24 12:02:41.287  INFO 3 --- [           main] i.j.s.SpringBootHelloApplication         : Starting SpringBootHelloApplication on 1c7f1944-1f01-4284-8931-bc1a0a2d1fa5 with PID 3 (/spring-boot-graal started by u11658 in /)
2020-04-24T12:02:41.287859+00:00 app[web.1]: 2020-04-24 12:02:41.287  INFO 3 --- [           main] i.j.s.SpringBootHelloApplication         : No active profile set, falling back to default profiles: default
2020-04-24T12:02:41.425964+00:00 app[web.1]: 2020-04-24 12:02:41.425  WARN 3 --- [           main] io.netty.channel.DefaultChannelId        : Failed to find the current process ID from ''; using a random value: -36892848
2020-04-24T12:02:41.427326+00:00 app[web.1]: 2020-04-24 12:02:41.427  INFO 3 --- [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port(s): 59884
2020-04-24T12:02:41.430874+00:00 app[web.1]: 2020-04-24 12:02:41.430  INFO 3 --- [           main] i.j.s.SpringBootHelloApplication         : Started SpringBootHelloApplication in 0.156 seconds (JVM running for 0.159)
```


### Pushing and Releasing our Dockerized Native Spring Boot App on Heroku Container Infrastructure using GitHub Actions

We should also use GitHub Actions to [push the build Docker image into Heroku's Container Registry](https://devcenter.heroku.com/articles/container-registry-and-runtime#using-a-ci-cd-platform).

Therefore we need to configure encrypted variables in our GitHub repository in order to push to Heroku's Container Registry:
`DOCKER_USERNAME` and `DOCKER_PASSWORD`. The first is your Heroku eMail, the latter is your Heroku API key. Be sure to prevent displaying the values in the build log:

With the following configuration inside our [.github/workflows/native-image-compile.yml](.github/workflows/native-image-compile.yml), we should be able to successfully log in to Heroku Container Registry:

```yaml
        run: |
          echo ' Login into Heroku Container Registry first, so that we can push our Image later'
          echo ""$DOCKER_PASSWORD"" | docker login -u ""$DOCKER_USERNAME"" --password-stdin registry.heroku.com
```

Now after a successful Docker build, that compiles our Spring Boot App into a native executable, we finally need to push the resulting Docker image into Heroku Container Registry.

Therefore we need to use the correct tag for our Docker image build([see the docs](https://devcenter.heroku.com/articles/container-registry-and-runtime#pushing-an-existing-image):

```shell script
docker build . --tag=registry.heroku.com/<app>/<process-type>
docker push registry.heroku.com/<app>/<process-type>
```

This means we add the following `docker tag` and `docker push` command into our [.github/workflows/native-image-compile.yml](.github/workflows/native-image-compile.yml):

```yaml
          echo 'Compile Native Image using Docker'
          docker build . --tag=registry.heroku.com/spring-boot-graal/web

          echo 'Push to Heroku Container Registry'
          docker push registry.heroku.com/spring-boot-graal/web
```

See the paragraph on how to release to Heroku using Containers at [Pushing and Releasing our Dockerized Native Spring Boot App on Heroku Container Infrastructure](#pushing-and-releasing-our-dockerized-native-spring-boot-app-on-heroku-container-infrastructure).)



# Autorelease on Docker Hub with TravisCI & GitHub Actions

We could try to __autorelease to Docker Hub on hub.docker.com:__ 

Therefore head over to the repositories tab in Docker Hub and click `Create Repository`:

![docker-hub-create-repo](screenshots/docker-hub-create-repo.png)

As the docs state, there are some config options to [setup automated builds](https://docs.docker.com/docker-hub/builds/).

__BUT:__ As the automatic builds feature rely on the Docker Hub build infrastructure, there woun't be enough RAM for our builds to succeed! You may try it, but you'll see those errors at the end:

```
13:13:26.080 [ForkJoinPool-2-worker-3] DEBUG io.netty.handler.codec.compression.ZlibCodecFactory - -Dio.netty.noJdkZlibEncoder: false
#
# There is insufficient memory for the Java Runtime Environment to continue.
# Native memory allocation (mmap) failed to map 578920448 bytes for committing reserved memory.
# An error report file with more information is saved as:
# /build/target/native-image/hs_err_pid258.log
[91mOpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x000000078d96d000, 578920448, 0) failed; error='Not enough space' (errno=12)
[0m
[91mError: Image build request failed with exit status 1[0m
```

Since our TravisCI & GitHub Actions builds are now enabled to successfully run our GraalVM Native Image compilation in a Docker build, we could live without the automatic builds feature of Docker Hub - and simply push our build image to Docker Hub also!

Therefore you need to create an Access Token in your Docker Hub account at https://hub.docker.com/settings/security

Then head over to your TravisCI & GitHub Actions project settings and add the environment variables `DOCKER_HUB_TOKEN` and `DOCKER_HUB_USERNAME` as already happended for Heroku Container Registry.

The final step then is to add the correct `docker login` and `docker push` commands to our [.travis.yml](.travis.yml) and [.github/workflows/native-image-compile.yml](.github/workflows/native-image-compile.yml):

```yaml
        # Push to Docker Hub also, since automatic Builds there don't have anough RAM to do a docker build
        - echo ""$DOCKER_HUB_TOKEN"" | docker login -u ""$DOCKER_HUB_USERNAME"" --password-stdin
        - docker tag registry.heroku.com/spring-boot-graal/web jonashackt/spring-boot-graalvm:latest
        - docker push jonashackt/spring-boot-graalvm:latest
```

Be sure to also tag your image correctly according to your created Docker Hub repository.

Finally, we should see our Docker images released on https://hub.docker.com/r/jonashackt/spring-boot-graalvm and could run this app simply by executing:

```
docker run -e ""PORT=8087"" -p 8087:8087 jonashackt/spring-boot-graalvm:latest
```

This pulls the latest `jonashackt/spring-boot-graalvm` image and runs our app locally.






# Upgrade to spring-native (from spring-graalvm-native) & spring-aot-maven-plugin & GraalVM 21.3

Current docs: https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/index.html#overview

https://spring.io/blog/2021/03/11/announcing-spring-native-beta


### spring-graalvm-native -> spring-native

Switch from `spring-graalvm-native` to `spring-native`:

```xml
<spring-graalvm-native.version>0.8.5</spring-graalvm-native.version>
<dependency>
    <groupId>org.springframework.experimental</groupId>
    <artifactId>spring-graalvm-native</artifactId>
    <version>${spring-graalvm-native.version}</version>
</dependency>

to

<spring-native.version>0.10.5</spring-native.version>
<dependency>
    <groupId>org.springframework.experimental</groupId>
    <artifactId>spring-native</artifactId>
    <version>${spring-native.version}</version>
</dependency>
```


### Spring Boot Version <=> spring-native Version <=> GraalVM version <=> Java version

https://github.com/spring-projects-experimental/spring-native/milestones?state=closed

https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/index.html#_validate_spring_boot_version

> Spring Native 0.10.5 only supports Spring Boot 2.5.6, so change the version if necessary.

https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/index.html#_freeze_graalvm_version

Install the matching GraalVM version with SDKMAN:

```shell
sdk install java 21.2.0.r11-grl
```

This will also configure the correct Maven version.


Run 

```shell
$ native-image --version
GraalVM 21.2.0 Java 11 CE (Java Version 11.0.12+6-jvmci-21.2-b08)

$ java -version
openjdk version ""11.0.12"" 2021-07-20
OpenJDK Runtime Environment GraalVM CE 21.2.0 (build 11.0.12+6-jvmci-21.2-b08)
OpenJDK 64-Bit Server VM GraalVM CE 21.2.0 (build 11.0.12+6-jvmci-21.2-b08, mixed mode, sharing)

$ mvn --version
Apache Maven 3.8.3 (ff8e977a158738155dc465c6a97ffaf31982d739)
Maven home: /Users/jonashecht/.sdkman/candidates/maven/current
Java version: 11.0.12, vendor: GraalVM Community, runtime: /Users/jonashecht/.sdkman/candidates/java/21.2.0.r11-grl
Default locale: de_DE, platform encoding: UTF-8
OS name: ""mac os x"", version: ""11.5"", arch: ""x86_64"", family: ""mac""
```

Also use the matching version (see https://github.com/graalvm/container/pkgs/container/graalvm-ce) inside your [Dockerfile](Dockerfile) (if you don't use Buildpacks):

```dockerfile
FROM ghcr.io/graalvm/graalvm-ce:ol7-java11-21.2.0
```

and inside your CI system like GitHub Actions [.github/workflows/native-image-compile.yml](.github/workflows/native-image-compile.yml):

```yaml
    - name: Install GraalVM with SDKMAN
      run: |
        curl -s ""https://get.sdkman.io"" | bash
        source ""$HOME/.sdkman/bin/sdkman-init.sh""
        sdk install java 21.2.0.r11-grl
        java -version
```


### Enable native image support via spring-boot-maven-plugin

https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/index.html#_enable_native_image_support

Enhance `spring-boot-maven-plugin` buildpacks configuration & `${repackage.classifier}`:

```xml
<build>
    <plugins>
        <plugin>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-maven-plugin</artifactId>
        </plugin>
    </plugins>
</build>

to

<plugin>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-maven-plugin</artifactId>
    <configuration>
        <classifier>${repackage.classifier}</classifier>
        <image>
            <builder>paketobuildpacks/builder:tiny</builder>
            <env>
                <BP_NATIVE_IMAGE>true</BP_NATIVE_IMAGE>
            </env>
        </image>
    </configuration>
</plugin>
```


### spring-context-indexer --> spring-aot-maven-plugin

https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/index.html#_add_the_spring_aot_plugin

From `spring-context-indexer` to new Spring ahead-of-time (AOT) Maven build plugin `spring-aot-maven-plugin`:

```xml
		<dependency>
			<groupId>org.springframework</groupId>
			<artifactId>spring-context-indexer</artifactId>
		</dependency>

to

        <plugin>
            <groupId>org.springframework.experimental</groupId>
            <artifactId>spring-aot-maven-plugin</artifactId>
            <version>${spring-native.version}</version>
            <executions>
                <execution>
                    <id>test-generate</id>
                    <goals>
                        <goal>test-generate</goal>
                    </goals>
                </execution>
                <execution>
                    <id>generate</id>
                    <goals>
                        <goal>generate</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```


### native-image-maven-plugin --> native-maven-plugin

Inside the profile `native` move plugin `org.graalvm.nativeimage.native-image-maven-plugin` to new `org.graalvm.buildtools.native-maven-plugin`:

```xml

    <native-image-maven-plugin.version>20.3.2</native-image-maven-plugin.version>
	<profiles>
		<profile>
			<id>native</id>
			<build>
				<plugins>
					<plugin>
						<groupId>org.graalvm.nativeimage</groupId>
						<artifactId>native-image-maven-plugin</artifactId>
						<version>${native-image-maven-plugin.version}</version>
						<configuration>
							<buildArgs>-J-Xmx4G -H:+ReportExceptionStackTraces -Dspring.native.remove-unused-autoconfig=true -Dspring.native.remove-yaml-support=true</buildArgs>
							<imageName>${project.artifactId}</imageName>
						</configuration>
						<executions>
							<execution>
								<goals>
									<goal>native-image</goal>
								</goals>
								<phase>package</phase>
							</execution>
						</executions>
					</plugin>
					<plugin>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-maven-plugin</artifactId>
					</plugin>
				</plugins>
			</build>
		</profile>
	</profiles>

to
    <native-buildtools.version>0.9.4</native-buildtools.version>
    <profiles>
        <profile>
            <id>native</id>
            <properties>
                <repackage.classifier>exec</repackage.classifier>
            </properties>
            <dependencies>
                <dependency>
                    <groupId>org.graalvm.buildtools</groupId>
                    <artifactId>junit-platform-native</artifactId>
                    <version>${native-buildtools.version}</version>
                    <scope>test</scope>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                  <plugin>
                      <groupId>org.graalvm.buildtools</groupId>
                      <artifactId>native-maven-plugin</artifactId>
                      <version>${native-buildtools.version}</version>
                      <executions>
                          <execution>
                              <id>test-native</id>
                              <phase>test</phase>
                              <goals>
                                  <goal>test</goal>
                              </goals>
                          </execution>
                          <execution>
                              <id>build-native</id>
                              <phase>package</phase>
                              <goals>
                                  <goal>build</goal>
                              </goals>
                          </execution>
                      </executions>
                  </plugin>
                </plugins>
            </build>
        </profile>
    </profiles>
```







# Links

### Spring

Current docs: https://repo.spring.io/milestone/org/springframework/experimental/spring-graalvm-native-docs/0.7.0/spring-graalvm-native-docs-0.7.0.zip!/reference/index.html

https://github.com/spring-projects/spring-framework/wiki/GraalVM-native-image-support

https://www.infoq.com/presentations/spring-boot-graalvm/

https://github.com/spring-projects/spring-framework/issues/21529

https://spring.io/blog/2020/04/09/spring-graal-native-0-6-0-released

https://spring.io/blog/2020/04/16/spring-tips-the-graalvm-native-image-builder-feature

https://spring.io/blog/2020/06/10/the-path-towards-spring-boot-native-applications

##### 0.8.3

Spring Boot 2.4.0 Release + Oracle GraalVM 20.3.x compatibility: https://spring.io/blog/2020/11/23/spring-native-for-graalvm-0-8-3-available-now

No `-H:+TraceClassInitialization` as simple boolean anymore: https://github.com/quarkusio/quarkus/issues/12434 & https://github.com/oracle/graal/commit/8c210f7fdbba5045bfbe14b6870f98ebbff6eed7

With GraalVM 20.3.x the official Docker image moved from Docker Hub to GitHub Packages: https://github.com/orgs/graalvm/packages/container/package/graalvm-ce


### Stackoverflow

https://stackoverflow.com/questions/50911552/graalvm-and-spring-applications

https://stackoverflow.com/questions/58465833/graalvm-with-native-image-compilation-in-travis-ci

https://stackoverflow.com/questions/61302412/how-to-configure-the-port-of-a-spring-boot-app-thats-natively-compiled-by-graal


### GraalVM & Oracle

https://blog.softwaremill.com/graalvm-installation-and-setup-on-macos-294dd1d23ca2

https://github.com/orgs/graalvm/packages/container/package/graalvm-ce

https://www.graalvm.org/docs/reference-manual/native-image/

https://medium.com/graalvm/graalvm-20-1-7ce7e89f066b

https://medium.com/graalvm/updates-on-class-initialization-in-graalvm-native-image-generation-c61faca461f7


### Others

https://e.printstacktrace.blog/building-java-and-maven-docker-images-using-parallelized-jenkins-pipeline-and-sdkman/

https://medium.com/analytics-vidhya/maybe-native-executable-in-quarkus-is-not-for-you-but-it-is-awesome-967588e80a4

https://quarkus.io/guides/building-native-image

"
joolu/ddd-sample,master,36,17,2011-08-16T12:08:47Z,649,0,An SVN import of the Domain Driven Design (DDD) example project hosted on http://dddsample.sourceforge.net/,,
lynx-r/tictactoe-microservices-example,master,25,10,2018-11-28T06:28:12Z,629,0,An example of Spring Cloud Microservices application based on books (see Links section),eureka hystrix jwt microservices-application reactive-applications reactive-microservices ribbon spring-boot spring-boot-admin spring-cloud spring-config-server spring-gateway spring-microservices zipkin zuul,"# An example of a simple microservices application

# Run in Postman

[![Run in Postman](https://run.pstmn.io/button.svg)](https://app.getpostman.com/run-collection/3d22b6efe9ada28ae2de#?env%5Btictactoe-local%5D=W3sia2V5IjoiSE9TVCIsInZhbHVlIjoiaHR0cDovL2xvY2FsaG9zdDo1NTU1IiwiZGVzY3JpcHRpb24iOiIiLCJlbmFibGVkIjp0cnVlfSx7ImtleSI6IlRPS0VOIiwidmFsdWUiOiJleUpoYkdjaU9pSklVekkxTmlKOS5leUp6ZFdJaU9pSmhaRzFwYmlJc0ltRjFkR2h6SWpvaVVrOU1SVjlCUkUxSlRpeFNUMHhGWDFWVFJWSWlMQ0pwYzNNaU9pSjBhV04wWVdOMGIyVXVZMjl0SWl3aVpYaHdJam94TlRRME1qUXpOREUzZlEuLXF5cWptYlVQN3lTYkZiMGVsUnBxaU0xSmpsUnVUVWRaLXU5MzlkanNmUSIsImRlc2NyaXB0aW9uIjoiIiwiZW5hYmxlZCI6dHJ1ZX0seyJrZXkiOiJIT1NUX0NPTkZJRyIsInZhbHVlIjoiaHR0cDovL2xvY2FsaG9zdDo4ODg4IiwiZGVzY3JpcHRpb24iOiIiLCJlbmFibGVkIjp0cnVlfV0=)

Or import `tictactoe-postman_collection.json`

Services and Credential (**login/password**):

admin/admin

actuator/actuator

# Involved Spring Cloud and other services

[Service discovery Eureka](http://localhost:8761)
eureka/password

[Cloud Config](http://localhost:8888/webapi/default)
configuser/123

[Spring Boot Admin](http://localhost:9999/#/applications)
admin/adminpassword

[Zipkin](http://localhost:9411/zipkin/)
zipkin/zipkin

# Run and scripts

Run `docker-compose` via `gradle plugin`:

    Before running `docker-compose` copy `tictactoe-shared.env` in `${HOME}/Docker/tictactoe-shared.env`.

```
./docker-compose-up.sh
```

Create images via `gradle plugin`:

```
./spring-create-images.sh
./tictactoe-create-images.sh
```

Push images via `gradle plugin`:

```
./spring-push-images.sh
./tictactoe-push-images.sh
```

# Spring Cloud Config

I use [this](https://github.com/lynx-r/tictactoe-config-repo) git repository to config application

# Links

* [Spring Microservices in Action](https://www.manning.com/books/spring-microservices-in-action)
* [Hands-On Spring 5 Security for Reactive Applications](https://www.packtpub.com/application-development/hands-spring-security-5-reactive-applications)
* [The code for the book Spring Microservices in Action](https://github.com/carnellj?tab=repositories)
* [The code for the book Hands-On Spring 5 Security for Reactive Applications](https://github.com/lynx-r/Hands-On-Spring-Security-5-for-Reactive-Applications)
"
Nepxion/DiscoveryGuide,6.x.x-simple,1197,278,2019-05-25T07:40:53Z,2340,3,☀️ Nepxion Discovery Guide is a guide example for Nepxion Discovery 蓝绿灰度发布、路由、限流、熔断、降级、隔离、追踪、流量染色、故障转移、多活的指南示例,apollo blue-green-deployment gray-release nacos opentelemetry sentinel skywalking spring-cloud,"![](http://nepxion.gitee.io/discovery/docs/discovery-doc/Banner.png)

# Discovery【探索】云原生微服务解决方案
![Total visits](https://visitor-badge.laobi.icu/badge?page_id=Nepxion&title=total%20visits)  [![Total lines](https://tokei.rs/b1/github/Nepxion/Discovery?category=lines)](https://tokei.rs/b1/github/Nepxion/Discovery?category=lines)  [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg?label=license)](https://github.com/Nepxion/Discovery/blob/6.x.x/LICENSE)  [![Maven Central](https://img.shields.io/maven-central/v/com.nepxion/discovery.svg?label=maven)](https://search.maven.org/artifact/com.nepxion/discovery)  [![Javadocs](http://www.javadoc.io/badge/com.nepxion/discovery-plugin-framework-starter.svg)](http://www.javadoc.io/doc/com.nepxion/discovery-plugin-framework-starter)  [![Build Status](https://github.com/Nepxion/Discovery/workflows/build/badge.svg)](https://github.com/Nepxion/Discovery/actions)  [![Codacy Badge](https://app.codacy.com/project/badge/Grade/5c42eb719ef64def9cad773abd877e8b)](https://www.codacy.com/gh/Nepxion/Discovery/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=Nepxion/Discovery&amp;utm_campaign=Badge_Grade)  [![Stars](https://img.shields.io/github/stars/Nepxion/Discovery.svg?label=Stars&style=flat&logo=GitHub)](https://github.com/Nepxion/Discovery/stargazers)  [![Stars](https://gitee.com/Nepxion/Discovery/badge/star.svg?theme=gvp)](https://gitee.com/Nepxion/Discovery/stargazers)

[![Wiki](https://badgen.net/badge/icon/wiki?icon=wiki&label=GitHub)](https://github.com/Nepxion/Discovery/wiki)  [![Wiki](https://badgen.net/badge/icon/wiki?icon=wiki&label=Gitee)](https://gitee.com/nepxion/Discovery/wikis/pages?sort_id=3993615&doc_id=1124387)  [![Discovery PPT](https://img.shields.io/badge/Discovery%20-ppt-brightgreen?logo=Microsoft%20PowerPoint)](http://nepxion.gitee.io/discovery/docs/link-doc/discovery-ppt.html)  [![Discovery Page](https://img.shields.io/badge/Discovery%20-page-brightgreen?logo=Microsoft%20Edge)](http://nepxion.gitee.io/discovery/)  [![Discovery Platform Page](https://img.shields.io/badge/Discovery%20Platform%20-page-brightgreen?logo=Microsoft%20Edge)](http://nepxion.gitee.io/discoveryplatform)  [![Polaris Page](https://img.shields.io/badge/Polaris%20-page-brightgreen?logo=Microsoft%20Edge)](http://polaris-paas.gitee.io/polaris-sdk)

<a href=""https://github.com/Nepxion"" tppabs=""#"" target=""_blank""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/github.png""></a>&nbsp;  <a href=""https://gitee.com/Nepxion"" tppabs=""#"" target=""_blank""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/gitee.png""></a>&nbsp;  <a href=""https://search.maven.org/search?q=g:com.nepxion"" tppabs=""#"" target=""_blank""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/maven.png""></a>&nbsp;  <a href=""http://nepxion.gitee.io/discovery/docs/contact-doc/wechat.jpg"" tppabs=""#"" target=""_blank""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/wechat.png""></a>&nbsp;  <a href=""http://nepxion.gitee.io/discovery/docs/contact-doc/dingding.jpg"" tppabs=""#"" target=""_blank""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/dingding.png""></a>&nbsp;  <a href=""http://nepxion.gitee.io/discovery/docs/contact-doc/gongzhonghao.jpg"" tppabs=""#"" target=""_blank""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/gongzhonghao.png""></a>&nbsp;  <a href=""mailto:1394997@qq.com"" tppabs=""#""><img width=""25"" height=""25"" src=""http://nepxion.gitee.io/discovery/docs/icon-doc/email.png""></a>

如果您觉得本框架具有一定的参考价值和借鉴意义，请帮忙在页面右上角 [**Star**]

## 简介

### 作者简介
- Nepxion开源社区创始人
- 2020年阿里巴巴中国云原生峰会出品人
- 2020年被Nacos和Spring Cloud Alibaba纳入相关开源项目
- 2021年阿里巴巴技术峰会上海站演讲嘉宾
- 2021年荣获陆奇博士主持的奇绩资本，进行风险投资的关注和调研
- 2021年入选Gitee最有价值开源项目
- 阿里巴巴官方书籍《Nacos架构与原理》作者之一
- Spring Cloud Alibaba Steering Committer、Nacos Group Member
- Spring Cloud Alibaba、Nacos、Sentinel、OpenTracing Committer & Contributor

<img src=""http://nepxion.gitee.io/discovery/docs/discovery-doc/CertificateGVP.jpg"" width=""43%""><img src=""http://nepxion.gitee.io/discovery/docs/discovery-doc/AwardNacos1.jpg"" width=""28%""><img src=""http://nepxion.gitee.io/discovery/docs/discovery-doc/AwardSCA1.jpg"" width=""28%"">

### 商业合作
① Discovery系列

| 框架名称 | 框架版本 | 支持Spring Cloud版本 | 使用许可 |
| --- | --- | --- | --- |
| Discovery | 1.x.x ~ 6.x.x | Camden ~ Hoxton | 开源，永久免费 |
| DiscoveryX | 7.x.x ~ 10.x.x | 2020 ~ 2023 | 闭源，商业许可 |

② Polaris系列

Polaris为Discovery高级定制版，特色功能

- 基于Nepxion Discovery集成定制
- 多云、多活、多机房流量调配
- 跨云动态域名、跨环境适配
- DCN、DSU、SET单元化部署
- 组件灵活装配、配置对外屏蔽
- 极简低代码PaaS平台

| 框架名称 | 框架版本 | 支持Discovery版本 | 支持Spring Cloud版本 | 使用许可 |
| --- | --- | --- | --- | --- |
| Polaris | 1.x.x | 6.x.x | Finchley ~ Hoxton | 闭源，商业许可 |
| Polaris | 2.x.x | 7.x.x ~ 10.x.x | 2020 ~ 2023 | 闭源，商业许可 |

有商业版需求的企业和用户，请添加微信1394997，联系作者，洽谈合作事宜

### 入门资料
![](http://nepxion.gitee.io/discovery/docs/discovery-doc/Logo64.png) Discovery【探索】企业级云原生微服务开源解决方案

① 快速入门
- [快速入门Github版](https://github.com/Nepxion/Discovery/wiki)
- [快速入门Gitee版](https://gitee.com/Nepxion/Discovery/wikis/pages)

② 解决方案
- [解决方案WIKI版](http://nepxion.com/discovery)
- [解决方案PPT版](http://nepxion.gitee.io/discovery/docs/link-doc/discovery-ppt.html)

③ 最佳实践
- [最佳实践PPT版](http://nepxion.gitee.io/discovery/docs/link-doc/discovery-ppt-1.html)

④ 平台界面
- [平台界面WIKI版](http://nepxion.com/discovery-platform)

⑤ 框架源码
- [框架源码Github版](https://github.com/Nepxion/Discovery)
- [框架源码Gitee版](https://gitee.com/Nepxion/Discovery)

⑥ 指南示例源码
- [指南示例源码Github版](https://github.com/Nepxion/DiscoveryGuide)
- [指南示例源码Gitee版](https://gitee.com/Nepxion/DiscoveryGuide)

⑦ 指南示例说明
- Spring Cloud Finchley ~ Hoxton版本
    - [极简版指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/6.x.x-simple)，分支为6.x.x-simple
    - [极简版域网关部署指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/6.x.x-simple-domain-gateway)，分支为6.x.x-simple-domain-gateway
    - [极简版非域网关部署指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/6.x.x-simple-non-domain-gateway)，分支为6.x.x-simple-non-domain-gateway
    - [集成版指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/6.x.x)，分支为6.x.x
    - [高级版指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/6.x.x-complex)，分支为6.x.x-complex
- Spring Cloud 202x版本
    - [极简版指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/master-simple)，分支为master-simple
    - [极简版本地化指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/master-simple-native)，分支为master-simple-native
    - [集成版指南示例](https://github.com/Nepxion/DiscoveryGuide/tree/master)，分支为master

![](http://nepxion.gitee.io/discovery/docs/polaris-doc/Logo64.png) Polaris【北极星】企业级云原生微服务商业解决方案

① 解决方案
- [解决方案WIKI版](http://nepxion.com/polaris)

② 框架源码
- [框架源码Github版](https://github.com/polaris-paas/polaris-sdk)
- [框架源码Gitee版](https://gitee.com/polaris-paas/polaris-sdk)

③ 指南示例源码
- [指南示例源码Github版](https://github.com/polaris-paas/polaris-guide)
- [指南示例源码Gitee版](https://gitee.com/polaris-paas/polaris-guide)

④ 指南示例说明
- Spring Cloud Finchley ~ Hoxton版本
    - [指南示例](https://github.com/polaris-paas/polaris-guide/tree/1.x.x)，分支为1.x.x
- Spring Cloud 202x版本
    - [指南示例](https://github.com/polaris-paas/polaris-guide/tree/master)，分支为master

## 请联系我
微信、钉钉、公众号和文档

![](http://nepxion.gitee.io/discovery/docs/contact-doc/wechat-1.jpg)![](http://nepxion.gitee.io/discovery/docs/contact-doc/dingding-1.jpg)![](http://nepxion.gitee.io/discovery/docs/contact-doc/gongzhonghao-1.jpg)![](http://nepxion.gitee.io/discovery/docs/contact-doc/document-1.jpg)

## Star走势图
[![Stargazers over time](https://starchart.cc/Nepxion/Discovery.svg)](https://starchart.cc/Nepxion/Discovery)"
pereferrera/trident-lambda-splout,master,76,22,2013-01-23T17:02:18Z,1027,3,"A toy example of a Lambda architecture"" using Storm's Trident as real-time layer and Splout SQL as batch layer.""",,"trident-lambda-splout
=====================

A toy example of a [""Lambda architecture""](http://www.dzone.com/links/r/big_data_lambda_architecture.html) using Storm's [Trident](https://github.com/nathanmarz/storm/wiki/Trident-tutorial) 
as real-time layer and [Splout SQL](http://sploutsql.com) as batch layer.

The problem
===========

We want to implement counting the number of appearances of hashtags in tweets, grouped by date, and serve the data as a remote service,
 for example to be able to populate timelines in a website / mobile app (e.g. give me the evolution of mentions for hashtag ""california"" for
 the past 10 days).

The requirements for the solution are:
- It must scale (we want to process billions of tweets. Think as if we had access to the Firehouse!).
- It must be able to serve low-latency requests to potentially a lot of concurrent users asking for timelines.

Using Hadoop to store the tweets and a simple Hive query for grouping by hashtag and date seems good enough for calculating the counts.
However, we also want to add real-time to the system: we want to have the actual number of appearances for hashtags updated 
for today in seconds time. And we need to put the Hadoop counts in some really fast datastore for being able to query them. 

The solution
============

The solution proposed is to use a ""lambda architecture"" and implement a real-time layer using [Trident](https://github.com/nathanmarz/storm/wiki/Trident-tutorial), which is an API on top of Storm that eases
building real-time topologies and saving persistent state derived from them. 

For serving the batch layer we will use [Splout SQL](http://sploutsql.com) which is a high-performant SQL read-only data store that can pull and serve datasets
 from Hadoop very efficiently. Splout is fast like [ElephantDB](https://github.com/nathanmarz/elephantdb) but it also allows us to execute SQL queries. Using SQL for serving the batch
 layer is convenient as we might want to break-down the counts by hour, day, week, or any arbitrary date period.  
 
We will also use [Trident](https://github.com/nathanmarz/storm/wiki/Trident-tutorial) to implement the remote service using its DRPC capabilities. [Trident](https://github.com/nathanmarz/storm/wiki/Trident-tutorial) iself will query both the batch layer and the
real-time layer and merge the results.

This is how, conceptually, the overall architecture looks like:

![alt text](https://raw.github.com/pereferrera/trident-lambda-splout/master/TridentSploutArch-medium.png ""Trident-Lambda-Splout Hashtag Counts Architecture"")

How to try it
=============

1) Hadoop

Hadoop is a key component of this ""lambda architecture"" example so you must have it installed and its services
must be running. $HADOOP_HOME needs to be defined for Splout SQL.

2) Batch layer

For trying out this example you must first download Splout SQL an execute a one-node cluster locally.
You can download a distribution (.tar.gz file) from Maven Central: http://search.maven.org/#browse%7C-1223220252
After uncompressing it:

	bin/splout-service.sh qnode start
	bin/splout-service.sh dnode start

Should bring you a one-node local cluster up at: http://localhost:4412

When that is finished you can load a toy dataset of hourly hashtag counts. 
You can use the data in this ""trident-lambda-splout"" repo under ""sample-hashtags"" folder.

Let's call $TRIDENT_LAMBDA_SPLOUT_HOME the path where you have cloned this repo, then, 
from $SPLOUT_HOME (the path where you uncompressed Splout) you just execute:

	hadoop fs -put $TRIDENT_LAMBDA_SPLOUT_HOME/sample-hashtags sample-hashtags
	hadoop jar splout-hadoop-*-hadoop.jar simple-generate -i sample-hashtags -o out-hashtags -pby hashtag -p 2 -s ""label:string,date:string,count:int,hashtag:string"" --index ""hashtag,date"" -t hashtags -tb hashtags
	hadoop jar splout-hadoop-*-hadoop.jar deploy -q http://localhost:4412 -root out-hashtags -ts hashtags
	
After these three statements you will have the data indexed, partitioned and loaded into [Splout SQL](http://sploutsql.com). 
You can check it by looking for Tablespace ""hashtags"" at the management webapp: http://localhost:4412

2) Real-time layer

Execute the class in this repo called ""LambdaHashTagsTopology"" from your favorite IDE. This class will:
- Start a dummy cyclic input Spout that emits always the same two tweets.   
- Start a Trident topology that counts hashtags by date in real-time.
- Start a DRPC server that accepts a hashtag as argument and queries both Splout (batch-layer) and Trident (real-time layer) and merges the
results.

If you want to execute it from command line you can use maven as follows:

	mvn clean install
	mvn dependency:copy-dependencies
	mvn exec:exec -Dexec.executable=""java"" -Dexec.args=""-cp target/classes:target/dependency/* com.datasalt.trident.LambdaHashTagsTopology""

You should see something like this:

	...
	Result for hashtag 'california' -> [[{""20091022"":115,""20091023"":115,""20091024"":158,""20091025"":19}]]
	Result for hashtag 'california' -> [[{""20091022"":115,""20091023"":115,""20091024"":158,""20091025"":19,""20130123"":76}]]
	Result for hashtag 'california' -> [[{""20091022"":115,""20091023"":115,""20091024"":158,""20091025"":19,""20130123"":136}]]
	Result for hashtag 'california' -> [[{""20091022"":115,""20091023"":115,""20091024"":158,""20091025"":19,""20130123"":192}]]
	Result for hashtag 'california' -> [[{""20091022"":115,""20091023"":115,""20091024"":158,""20091025"":19,""20130123"":232}]]
	Result for hashtag 'california' -> [[{""20091022"":115,""20091023"":115,""20091024"":158,""20091025"":19,""20130123"":286}]]
	...
	
The first four dates come from the batch layer Splout SQL whereas the last date (whose count is being incremented in real-time) comes from the real-time layer.
The merging has been done with Trident at the DRPC service.

Conclusions
===========

We have shown a simple toy example of a ""lambda architecture"" that provides timelines for mentions of hashtags in tweets.
If you see the code, you will notice it is actually quite easy and straight-forward to implement the real-time part of this system
using [Trident](https://github.com/nathanmarz/storm/wiki/Trident-tutorial), mainly because of its high-level constructs (a-la-Cascading, each(), groupBy(), etc) and its wrappers around memory
state. There is quite an interesting amount of information on how to handle state properly with Trident here: https://github.com/nathanmarz/storm/wiki/Trident-state .
 
We have also seen [Splout SQL](http://sploutsql.com), a database that integrates tightly with Hadoop and provides real low-latency lookups over its data,
being the perfect solution for serving a batch layer in a highly concurrent website or mobile application.

For this example to be complete we have to clarify some things:

- We didn't implement actually crawling the Tweets, parsing them and feeding them into Storm. 
You would usually do that through a messaging / queue system such as Kestrel (see https://github.com/nathanmarz/storm-kestrel). 
Creating a scalable fetcher for Twitter that also outputs the Tweets to Hadoop's HDFS is too complex and out of scope for this example.

- We used a dataset of hourly counts that was already calculated by Hadoop but we didn't show how to do that. 
This part is quite straight-foward and you will find plenty of examples in the web on how to perform simple aggregation tasks 
using Hadoop, Pig, Hive, Cascading or even a lower-level API such as [Pangool](http://pangool.net/).

- We didn't talk about a ""master coordinator"" which is a quite important part of the architecture. This coordinator would be in charge
of triggering the Hadoop aggregation task, and triggering the Splout generation and deploy tasks of [Splout SQL](http://sploutsql.com) we saw above.
One important thing to keep in mind is that batch always overrides real-time in this example so the coordinator and the fetcher must
make sure that Hadoop only processes complete-hour data. Uncomplete hours should only be handled by the real-time layer.

- The real-time layer should expire old data from time to time in order to be efficient (e.g. keep only a rolling view of one week).
Keeping a rolling one-week view would mean that the batch layer could potentially be executed only once per week. 

For another toy example on Storm (even though it is a bit old: http://www.datasalt.com/2012/01/real-time-feed-processing-with-storm/)
"
aspear/izpack5-example-installer,master,33,16,2011-10-20T19:02:53Z,797,3,This is a complete example of an izpack 5.x based installer that uses Maven to build.,,
ThomasVitale/spring-cloud-gateway-resilience-security-observability,main,69,30,2022-10-11T18:57:09Z,313,3,"Example with Spring Boot 3 focused on resilience, security and observability. It uses Spring Cloud Gateway, Spring Security and Spring Cloud Circuit Breaker.",grafana grafana-loki grafana-tempo keycloak microservices opentelemetry prometheus redis spring-boot spring-cloud spring-cloud-gateway spring-security,"# Spring Cloud Gateway - Resilience, Security, and Observability

Do you want to use a microservices architecture? Are you looking for a solution to manage access to single services
from clients? How can you ensure resilience and security for your entire system? Spring Cloud Gateway is a project
based on Reactor, Spring WebFlux, and Spring Boot which provides an effective way to route traffic to your APIs and
address cross-cutting concerns.

In this session, I'll show you how to configure an API gateway to route traffic to your microservices architecture and
implement solutions to improve the resilience of your system with patterns like circuit breakers, retries, fallbacks,
and rate limiters using Spring Cloud Circuit Breaker and Resilience4J. Since the gateway is the entry point of your
system, it’s also an excellent candidate to implement security concerns like user authentication. I'll show you how
to do that with Spring Security, OAuth2, and OpenID Connect, relying on Spring Redis Reactive to manage sessions.
Finally, I'll show you how to improve the observability of your system using Spring Boot Actuator
and Spring Cloud Sleuth and relying on the Grafana stack.

## Stack

* Java 17
* Spring Boot 3
* Grafana OSS

## Usage

You can use Docker Compose to set up the entire system, including applications, data services, and the Grafana observability stack.

First, package both the Edge Service and Book Service application as container images leveraging the Cloud Native Buildpacks integration
provided by Spring Boot. For each application, run the following task:

```bash
./gradlew bootBuildImage
```

Then, from the project root folder, run Docker Compose.

```bash
docker-compose up -d
```

The Edge Service application is exposed on port 9000 while Book Service on port 9001. The applications require authentication through
OAuth2/OpenID Connect. You can log in as Isabelle (isabelle/password) or Bjorn (bjorn/password).

## Observability Stack

Both Spring Boot applications are observable, as any cloud native application should. Prometheus metrics are backed by Spring Boot Actuator and Micrometer Metrics. Distributed tracing is backed by OpenTelemetry and Micrometer Tracing.

**Grafana** lets you query and visualize logs, metrics, and traces from your applications. After running the Docker Compose
configuration as explained in the previous section, you can access Grafana on port 3000. It provides already dashboards
to visualize metrics from Spring Boot, Spring Cloud Gateway, and Spring Cloud Circuit Breaker. In the ""Explore"" panel,
you can query logs from Loki, metrics from Prometheus, and traces from Tempo.

**Loki** is a log aggregation system part of the Grafana observability stack. ""It's like Prometheus, but for logs.""
Logs are available for inspecting from Grafana.

**Tempo** is a distributed tracing backend part of the Grafana observability stack. Spring Boot applications sends traces to Tempo,
which made them available for inspecting from Grafana. The traces follows the OpenTelemetry format and protocol.

**Prometheus** is a monitoring system part of the Grafana observability stack. It parses the metrics endpoints exposed by Spring Boot
applications (`/actuator/prometheus`). Metrics are available for inspecting and dashboarding from Grafana.
"
isilher/red-vs-blue,master,38,3,2020-07-16T19:01:26Z,1831,0,Example React Native white label by config,,"# RED vs BLUE

_React Native white label by config_

## Context

This demo React Native application showcases a simple white label implementation by environment configuration. This means:

- One codebase.
- Centralised config for Android, iOS and JS variables.
- No flavors, no extra schemes, no extra targets.
- No hassle. Just run:

``` shell
yarn ios:red
yarn ios:blue
```

To get:

![screenshot](screenshot_ios.png)

``` shell
yarn android:red
yarn android:blue
```

To get:

![screenshot](screenshot_android.png)

## Approach

The demo setup was achieved using the following steps.

1. React native init.
1. Add and configure [react-native-ultimate-config](https://github.com/maxkomarychev/react-native-ultimate-config). (Their comprehensive documentation is amazing 🤩)
1. Set up `.env` files for each white label. I chose RED (`.env.red`) and BLUE (`.env.blue`).
1. Set the environment variables for the app name and unique identifier and icon names.
1. (optional) Set up asset folders for each white label and add [a hook script](.rnucrc.js) to copy the content into the `res` and `xcimages` folders when switching env files.
1. (optional) Add yarn scripts to switch env file and run the correct build.

For a more detailed explanation you can check the commits of this project. They follow the above steps, starting with a common asset pool and then extracting them into separate folders as suggested in step 5.

## When to choose this approach

- When you need to run out a few white label versions of your RN app.
- When you want to keep the codebase as consistent as possible between those white label versions.

## When NOT to choose this approach

When you want the white label versions to have differences beyond theme variables and feature flags. For example when different white labels will have different dependencies, you may be better off splitting into XCode targets/schemes and Android flavors. This is outside the scope of my research. There is [experimental support](https://github.com/maxkomarychev/react-native-ultimate-config/blob/master/docs/cookbook.md) for flavors and schemes in react-native-ultimate-config, but since these functionalities are intertwined within the build process it will probably never be completely supported.

In my personal opinion you would probably be better off splitting your project into separate apps that use common functionality through shared libraries in those cases.

## Gotcha's

- When setting a dynamic android `applicationId` you must supply it to `react-native run-android` or it can not auto-launch the app after building. I chose to add this into the yarn scripts for convenience.
"
java-crypto/cross_platform_crypto,main,59,17,2020-10-28T08:50:27Z,2659,2,"Example codes for cryptographic exchange between several platforms (Java, PHP, C#, Javascript, NodeJs, node-forge, Python, Go and Dart)",aes crypto-js cryptography csharp dart go java javascript keyexchange node-js php python rsa,
oldratlee/io-api,main,56,19,2013-02-16T13:18:29Z,1167,0,"📐 generic API design example by I/O, the demo implementation of https://dzone.com/articles/generic-inputoutput-api-java",api api-design demo design generic io io-api java,"# 📐 `Java`的通用`IO API`设计

<p align=""center"">
<a href=""https://github.com/oldratlee/io-api/actions/workflows/ci.yaml""><img src=""https://img.shields.io/github/actions/workflow/status/oldratlee/io-api/ci.yaml?branch=main&logo=github&logoColor=white"" alt=""Github Workflow Build Status""></a>
<a href=""https://app.codecov.io/gh/oldratlee/io-api/tree/main""><img src=""https://img.shields.io/codecov/c/github/oldratlee/io-api/main?logo=codecov&logoColor=white"" alt=""Codecov""></a>
<a href=""https://openjdk.java.net/""><img src=""https://img.shields.io/badge/Java-8+-339933?logo=openjdk&logoColor=white"" alt=""Java support""></a>
<a href=""https://www.apache.org/licenses/LICENSE-2.0.html""><img src=""https://img.shields.io/github/license/oldratlee/io-api?color=4D7A97&logo=apache"" alt=""License""></a>
<a href=""https://github.com/oldratlee/io-api/stargazers""><img src=""https://img.shields.io/github/stars/oldratlee/io-api?style=flat"" alt=""GitHub Stars""></a>
<a href=""https://github.com/oldratlee/io-api/fork""><img src=""https://img.shields.io/github/forks/oldratlee/io-api?style=flat"" alt=""GitHub Forks""></a>
<a href=""https://github.com/oldratlee/io-api/issues""><img src=""https://img.shields.io/github/issues/oldratlee/io-api"" alt=""GitHub Issues""></a>
<a href=""https://github.com/oldratlee/io-api""><img src=""https://img.shields.io/github/repo-size/oldratlee/io-api"" alt=""GitHub repo size""></a>
<a href=""https://gitpod.io/#https://github.com/oldratlee/io-api""><img src=""https://img.shields.io/badge/Gitpod-ready to code-339933?label=gitpod&logo=gitpod&logoColor=white"" alt=""gitpod: Ready to Code""></a>
</p>

[:book: English Documentation](README-EN.md) | :book: 中文文档

<a href=""#dummy""><img src=""https://user-images.githubusercontent.com/1063891/234197656-c664c069-01db-4883-9031-9800644ec9ac.jpg"" width=""50%"" align=""right"" /></a>

------------------------------

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


- [包的功能](#%E5%8C%85%E7%9A%84%E5%8A%9F%E8%83%BD)
- [更多信息](#%E6%9B%B4%E5%A4%9A%E4%BF%A1%E6%81%AF)
- [API设计的进一步学习资料](#api%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99)
    - [简单资料](#%E7%AE%80%E5%8D%95%E8%B5%84%E6%96%99)
    - [系统书籍](#%E7%B3%BB%E7%BB%9F%E4%B9%A6%E7%B1%8D)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

------------------------------

[Java的通用I/O API](https://github.com/oldratlee/translations/blob/master/generic-io-api-in-java-and-api-design/README.md)（by _Rickard Öberg_）中给出了一个通用`Java` `IO API`设计，并且有`API`的`Demo`代码。更重要的是给出了这个`API`设计本身的步骤和过程，这让`API`设计有些条理。文中示范了从 普通简单实现 整理成 正交分解、可复用、可扩展、高性能、无错误的`API`设计 的过程，这个过程是很值得理解和学习！

设计偏向是艺术，一个赏心悦目的设计，尤其是`API`设计，旁人看来多是妙手偶得的感觉，如果能有些章可循真是一件美事。

在艺术工作中，真的艺术性工作量也只是一部分，而给出 _**方法**_ 以 _**减少艺术工作之中艺术性工作量**_ 的人是 **大师**。 ❤️

原文中只给出设计的

- 发展思路
- 关键接口
- 典型的使用方式

没有给出可运行的实现及其连接的细节，看起来可能比较费力，因为设计细致分解后抽象度高而不容易理解。

为了大家和自己更深入有效地学习，需要：  

1. 给出这个通用`IO API`的可运行的`Demo`实现。  
    这个工程即是本人的可运行的`Demo`实现。  
    当然个人力荐你先自己实现练习一下，这样比直接看我的实现，在学习上会有效得多！
1. 写了一篇分析总结。  
    本人的分析总结：[用Java I/O API设计练习的分析和总结](docs/java-api-design-exercise.md)。这个你可以直接看，以更高效方便地理解这个`API`的设计。

> PS：
>
> 上面2件事其实是份自学的家庭作业哦～ :laughing:  
> 在阿里中间件团队的时候（2011年），[@_ShawnQianx_ 大大](http://weibo.com/shawnqianx)看到这篇文章时，给组员布置的家庭作业～ :bowtie:
>
> @_ShawnQianx_ 对这篇文章及作者的评论：
>
> 设计时，一要分解好系统，二是多个组件拼回来还是系统预期的样子，二步都做好是难度所在。这个人分析和把控的功力很好！

## 包的功能

- 包`com.oldratlee.io.core`  
    核心接口
- 包`com.oldratlee.io.core.filter`  
    实现的`Filter`功能的类
- 包`com.oldratlee.io.utils`  
    工具类
- 包`com.oldratlee.io.demo`  
    Demo示例的`Main`类

## 更多信息

- 个人在组内分享时的PPT：[API设计实例分析](docs/ApiDesignSampleStudy.pptx)
- 本人对这篇博文的译文：[【译】Java的通用I/O API](https://github.com/oldratlee/translations/tree/master/generic-io-api-in-java-and-api-design/README.md)
- 问题交流： https://github.com/oldratlee/io-api/issues

## API设计的进一步学习资料

### 简单资料

- How to Design a Good API and Why it Matters(by Joshua Bloch) 【[本地下载](docs/How-to-Design-a-Good-API-and-Why-it-Matters-by-Joshua-Bloch.pdf)】  
    <http://lcsd05.cs.tamu.edu/slides/keynote.pdf>
- Google Search  
    <http://www.google.com.hk/search?&q=api+design>

### 系统书籍

- The Little Manual of API Design 【[本地下载](docs/The-Little-Manual-of-API-Design.pdf)】  
    <http://chaos.troll.no/~shausman/api-design/api-design.pdf>
- [《软件框架设计的艺术》](http://book.douban.com/subject/6003832/) | 英文原版[Practical API Design: Confessions of a Java Framework Architect](http://www.amazon.com/Practical-API-Design-Confessions-Framework/dp/1430243171)  
- [Contributing to Eclipse中文版](https://book.douban.com/subject/1219945/) | 英文原版[Contributing to Eclipse : Principles, Patterns, and Plug-Ins](https://book.douban.com/subject/1610318/)
- [.NET设计规范 : NET约定、惯用法与模式](http://book.douban.com/subject/4805165/) | 英文原版[Framework Design Guidelines: Conventions, Idioms, and Patterns for Reusable .NET Libraries (2nd Edition)](http://www.amazon.com/Framework-Design-Guidelines-Conventions-Libraries/dp/0321545613)  
"
minimaldevelop/libgdx-scene2d-demo-game,master,39,31,2012-12-04T15:46:33Z,14109,0,"Example game using libgdx with scene2d, actors, box2d and other cool stuff. In this game you are falling man that avoid platforms.",,
eiceblue/Spire.Office-for-Java,master,34,9,2019-07-31T07:24:15Z,17194,0,"A collection of examples that shows you how to use Spire.Office for Java to create, convert and manipulate Word, PowerPoint & PDF documents, and generate and scan 1D & 2D barcodes.",barcode-generator barcode-scanner java-library processing-office-document processing-pdf-document,"# Spire.Office-for-Java-Java Libraries for Processing MS Office Documents and PDF 

[![Foo](https://i.imgur.com/yRDvquw.png)](https://www.e-iceblue.com/Introduce/office-for-java.html)

[Product Page](https://www.e-iceblue.com/Introduce/office-for-java.html) | [Tutorials](https://www.e-iceblue.com/Tutorials.html) | [Examples](https://github.com/eiceblue) | [Forum](https://www.e-iceblue.com/forum/) | [Customized Demo](https://www.e-iceblue.com/freedemo.html) | [Temporary License](https://www.e-iceblue.com/TemLicense.html)

[Spire.Office for Java](https://www.e-iceblue.com/Introduce/office-for-java.html) is a **combination of Enterprise-Level Office Java APIs** offered by E-iceblue. It includes the most recent versions of Spire.Doc, Spire.XLS, Spire.Presentation, Spire.PDF, and Spire.Barcode. 

Using Spire.Office for Java, developers can **open**, **create**, **modify**, **convert**, **print**, and **view** **MS Word**, **Excel**, and **PowerPoint** documents, **PDF** documents and many other format files. 

### Spire.Doc for Java

A professional [Word Java library](https://www.e-iceblue.com/Introduce/doc-for-java.html) designed to [create](https://www.e-iceblue.com/Tutorials/Java/Spire.Doc-for-Java/Program-Guide/Document-Operation/Create-Word-Document-in-Java.html), read, [write](https://www.e-iceblue.com/Tutorials/Java/Spire.Doc-for-Java/Program-Guide/Document-Operation/Create-Word-Document-in-Java.html), [convert](https://www.e-iceblue.com/Tutorials/Java/Spire.Doc-for-Java/Program-Guide/Conversion/Convert-Word-to-PDF-in-Java.html) and [print Word](https://www.e-iceblue.com/Tutorials/Java/Spire.Doc-for-Java/Program-Guide/Print/Print-Word-Document-in-Java.html) document files in any Java applications with fast and high-quality performance.

### Spire.XLS for Java

A professional [Excel Java library](https://www.e-iceblue.com/Introduce/xls-for-java.html) that can be used to [create](https://www.e-iceblue.com/Tutorials/Java/Spire.XLS-for-Java/Program-Guide/Document-Operation/Create-Excel-File-in-Java.html), read, [write](https://www.e-iceblue.com/Tutorials/Java/Spire.XLS-for-Java/Program-Guide/Document-Operation/Create-Excel-File-in-Java.html), [convert](https://www.e-iceblue.com/Tutorials/Java/Spire.XLS-for-Java/Program-Guide/Conversion/Java-convert-Excel-to-PDF.html) and [print Excel](https://www.e-iceblue.com/Tutorials/Java/Spire.XLS-for-Java/Program-Guide/Print/Print-Excel-Documents-in-Java.html) files in any type of Java applications.

### Spire.Presentation for Java

A professional [PowerPoint® compatible library](https://www.e-iceblue.com/Introduce/presentation-for-java.html) that enables developers to [create](https://www.e-iceblue.com/Tutorials/Java/Spire.Presentation-for-Java/Program-Guide/Document-Operation/Operate-the-presentation-slide-on-Java-applications.html), read, [modify](https://www.e-iceblue.com/Tutorials/Java/Spire.Presentation-for-Java/Program-Guide/Document-Operation/Operate-the-presentation-slide-on-Java-applications.html), [convert](https://www.e-iceblue.com/Tutorials/Java/Spire.Presentation-for-Java/Program-Guide/Conversion/Convert-PowerPoint-to-PDF-in-Java.html) and [print PowerPoint](https://www.e-iceblue.com/Tutorials/Java/Spire.Presentation-for-Java/Program-Guide/Print/Java-print-a-PowerPoint-document.html) documents in any Java application.

### Spire.PDF for Java

A professional [PDF Java library](https://www.e-iceblue.com/Introduce/pdf-for-java.html) that enables developers to [create](https://www.e-iceblue.com/Tutorials/Spire.PDF-for-JAVA/Spire.PDF-Program-Guide-JAVA/Document-Operation/Create-a-PDF-Document-in-Java.html), edit, [convert](https://www.e-iceblue.com/Tutorials/Java/Spire.PDF-for-Java/Program-Guide/Conversion/Convert-PDF-to-Word-in-Java.html) and [print PDF](https://www.e-iceblue.com/Tutorials/Java/Spire.PDF-for-Java/Program-Guide/Print/How-to-print-PDF-document-in-Java.html) files in a Java application without any external dependencies.

### Spire.Barcode for Java

A professional [barcode library](https://www.e-iceblue.com/Introduce/barcode-for-java.html) designed for Java developers to [generate](https://www.e-iceblue.com/Tutorials/Spire.Barcode-for-JAVA/Getting-Started/How-to-Create-Barcode-Using-Spire.Barcode-for-Java.html), [read and scan 1D & 2D barcodes](https://www.e-iceblue.com/Tutorials/Spire.Barcode-for-JAVA/Scan-Barcode-in-Java.html) in Java applications.

[Product Page](https://www.e-iceblue.com/Introduce/office-for-java.html) | [Tutorials](https://www.e-iceblue.com/Tutorials.html) | [Examples](https://github.com/eiceblue) | [Forum](https://www.e-iceblue.com/forum/) | [Customized Demo](https://www.e-iceblue.com/freedemo.html) | [Temporary License](https://www.e-iceblue.com/TemLicense.html)

"
IvanWooll/FloatingLabelValidator,master,59,11,2015-03-31T17:14:08Z,217,1,A small library including an example app which uses the 'floating label' pattern to show form validation,,"# FloatingLabelValidator
A small library including an example app demonstrating a concept of combining the 'floating label' pattern with form validation.
[Youtube video demo](https://youtu.be/9O6cJpybySg)
---
This is more a proof of concept than a full blown library but if you want to use it all the files you need are in the lib folder.

<LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:tools=""http://schemas.android.com/tools""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    tools:context="".MainActivity""
    android:orientation=""vertical"">

    <com.ivanwooll.floatinglabelvalidator.lib.FloatingLabelTextView
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        app:hint=""alpha""
        app:allowEmpty=""false""
        app:validatorType=""alpha"" />

    <com.ivanwooll.floatinglabelvalidator.lib.FloatingLabelTextView
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        app:hint=""numeric""
        app:allowEmpty=""false""
        app:validatorType=""numeric"" />

    <com.ivanwooll.floatinglabelvalidator.lib.FloatingLabelTextView
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        app:hint=""alpha numeric""
        app:allowEmpty=""false""
        app:validatorType=""alphaNumeric"" />

    <com.ivanwooll.floatinglabelvalidator.lib.FloatingLabelTextView
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        app:hint=""email""
        app:allowEmpty=""false""
        app:validatorType=""email"" />

    <com.ivanwooll.floatinglabelvalidator.lib.FloatingLabelTextView
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        app:hint=""phone number""
        app:allowEmpty=""false""
        app:validatorType=""phone"" />

</LinearLayout>
"
android10/DynamicProxy_Java_Sample,master,34,22,2014-07-23T21:58:56Z,148,0,This is an example written in Java that demonstrates how to implement a simple dynamic proxy for intercepting method calls.,,"Dynamic Proxy Java Sample
==================

This is an example written in Java that demonstrates how to implement a simple dynamic proxy for intercepting method calls.


Proxy Pattern (from Wikipedia)
-----------------

In computer programming, the proxy pattern is a software design pattern.

A proxy, in its most general form, is a class functioning as an interface to something else. The proxy could interface to anything: a network connection, a large object in memory, a file, or some other resource that is expensive or impossible to duplicate.

A well-known example of the proxy pattern is a reference counting pointer object.

In situations where multiple copies of a complex object must exist, the proxy pattern can be adapted to incorporate the flyweight pattern in order to reduce the application's memory footprint. Typically, one instance of the complex object and multiple proxy objects are created, all of which contain a reference to the single original complex object. Any operations performed on the proxies are forwarded to the original object. Once all instances of the proxy are out of scope, the complex object's memory may be deallocated.


License
--------

    Copyright 2014 Fernando Cejas

    Licensed under the Apache License, Version 2.0 (the ""License"");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an ""AS IS"" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
"
jreznot/intellij-selenide-example,main,26,8,2020-12-12T12:17:07Z,372,0,Example of the project created by Selenium UI Testing plugin for IntelliJ IDEA,allure-report intellij-idea selenide selenium ui-testing ui-tests,"# intellij-selenide-example

Example of a project created by Selenium UI Testing plugin for IntelliJ IDEA.

Includes:

- Gradle with JUnit 5
- Selenide tests
- Allure listener setup
- Browsers.json file for Selenoid

[Read more about Selenium plugin for IntelliJ IDEA](https://blog.jetbrains.com/idea/2020/03/intellij-idea-2020-1-selenium-support/)

<a href=""https://blog.jetbrains.com/idea/2020/03/intellij-idea-2020-1-selenium-support/""><img src=""https://raw.githubusercontent.com/jreznot/intellij-selenide-example/main/img/idea-install.png"" alt=""Install""/></a>
"
traex/SlidingMenuExample,master,52,17,2014-09-24T02:45:54Z,254,0,Example for one of my tutorials at http://blog.robinchutaux.com/blog/how-to-create-a-menu-like-hello-sms/,,"SlidingMenuExample
==================

![SlidingMenuExample](https://github.com/traex/SlidingMenuExample/blob/master/header.png)

This is an example of [How to create a menu like Hello SMS](http://blog.robinchutaux.com/blog/how-to-create-a-menu-like-hello-sms/)

[HelloSMS](https://hellotext.com) is an awesome app with a design concept that I like very much ! So I wanted to know how to create the same menu and after some digging I found a way to do it. It was a little bit difficult so I explained [here](http://blog.robinchutaux.com/blog/how-to-create-a-menu-like-hello-sms/) how to achieve the same menu with interaction."
gauravgyal/MVVM-LIveData-ViewModel,master,45,15,2017-12-27T15:36:10Z,137,0,This is a basic example which gives an idea of MVVM Architecture along with LiveData and ViewModel Architecture components. ,,"A sample project which illustrate uses of MVVM Architecture and LiveData,ViewModel Architecture components.
It displays list of news in a Recycler view and on click of any news, news will be opened in a WebView.
https://android.jlelse.eu/android-architecture-pattern-components-mvvm-livedata-viewmodel-lifecycle-544e84e85177?source=friends_link&sk=a009475da1cf62720891f4526eb8ec05


![whatsapp image 2017-12-30 at 12 32 22 pm](https://user-images.githubusercontent.com/14937553/34452211-6d54872a-ed60-11e7-9dcb-1ce503fcedcb.jpeg)
![whatsapp image 2017-12-30 at 12 32 22 pm 1](https://user-images.githubusercontent.com/14937553/34452214-797701c2-ed60-11e7-8471-8254f6ec97a7.jpeg)
![whatsapp image 2017-12-30 at 12 32 22 pm 2](https://user-images.githubusercontent.com/14937553/34452215-7b3dc216-ed60-11e7-82c6-48a0c05f2df8.jpeg)
"
Azure-Samples/hdinsight-kafka-java-get-started,main,30,38,2016-11-09T17:25:28Z,13434,7,Basic example of using Java to create a producer and consumer that work with Kafka on HDInsight. Also a demonstration of the streaming api.,,"---
page_type: sample
languages:
- java
products:
  - azure
  - azure-hdinsight
description: ""The examples in this repository demonstrate how to use the Kafka Consumer, Producer, and Streaming APIs with a Kafka on HDInsight cluster.""
urlFragment: hdinsight-kafka-java-get-started
---

# Java-based example of using the Kafka Consumer, Producer, and Streaming APIs

The examples in this repository demonstrate how to use the Kafka Consumer, Producer, and Streaming APIs with a Kafka on HDInsight cluster.

There are two projects included in this repository:

* Producer-Consumer: This contains a producer and consumer that use a Kafka topic named `test`.

* Streaming: This contains an application that uses the Kafka streaming API (in Kafka 0.10.0 or higher) that reads data from the `test` topic, splits the data into words, and writes a count of words into the `wordcounts` topic.

NOTE: This both projects assume Kafka 0.10.0, which is available with Kafka on HDInsight cluster version 3.6.

## Producer and Consumer

To run the consumer and producer example, use the following steps:

1. Fork/Clone the repository to your development environment.

2. Install Java JDK 8 or higher. This was tested with Oracle Java 8, but should work under things like OpenJDK as well.

3. Install [Maven](http://maven.apache.org/).

4. Assuming Java and Maven are both in the path, and everything is configured fine for JAVA_HOME, use the following commands to build the consumer and producer example:

        cd Producer-Consumer
        mvn clean package
    
    A file named `kafka-producer-consumer-1.0-SNAPSHOT.jar` is now available in the `target` directory.

5. Use SCP to upload the file to the Kafka cluster:

        scp ./target/kafka-producer-consumer-1.0-SNAPSHOT.jar SSHUSER@CLUSTERNAME-ssh.azurehdinsight.net:kafka-producer-consumer.jar
   
    Replace **SSHUSER** with the SSH user for your cluster, and replace **CLUSTERNAME** with the name of your cluster. When prompted enter the password for the SSH user.

6. Use SSH to connect to the cluster:

        ssh USERNAME@CLUSTERNAME

7. Use the following commands in the SSH session to get the Zookeeper hosts and Kafka brokers for the cluster. You need this information when working with Kafka. Note that JQ is also installed, as it makes it easier to parse the JSON returned from Ambari. Replace __PASSWORD__ with the login (admin) password for the cluster. Replace __KAFKANAME__ with the name of the Kafka on HDInsight cluster.

        sudo apt -y install jq
        export KAFKAZKHOSTS=`curl -sS -u admin:$PASSWORD -G https://$CLUSTERNAME.azurehdinsight.net/api/v1/clusters/$CLUSTERNAME/services/ZOOKEEPER/components/ZOOKEEPER_SERVER | jq -r '[""\(.host_components[].HostRoles.host_name):2181""] | join("","")' | cut -d',' -f1,2`

        export KAFKABROKERS=`curl -sS -u admin:$PASSWORD -G https://$CLUSTERNAME.azurehdinsight.net/api/v1/clusters/$CLUSTERNAME/services/KAFKA/components/KAFKA_BROKER | jq -r '[""\(.host_components[].HostRoles.host_name):9092""] | join("","")' | cut -d',' -f1,2`

8. Use the following to verify that the environment variables have been correctly populated:

        echo '$KAFKAZKHOSTS='$KAFKAZKHOSTS
        echo '$KAFKABROKERS='$KAFKABROKERS

    The following is an example of the contents of `$KAFKAZKHOSTS`:
   
        zk0-kafka.eahjefxxp1netdbyklgqj5y1ud.ex.internal.cloudapp.net:2181,zk2-kafka.eahjefxxp1netdbyklgqj5y1ud.ex.internal.cloudapp.net:2181
   
    The following is an example of the contents of `$KAFKABROKERS`:
   
        wn1-kafka.eahjefxxp1netdbyklgqj5y1ud.cx.internal.cloudapp.net:9092,wn0-kafka.eahjefxxp1netdbyklgqj5y1ud.cx.internal.cloudapp.net:9092

    NOTE: This information may change as you perform scaling operations on the cluster, as this adds and removes worker nodes. You should always retrieve the Zookeeper and Broker information before working with Kafka.
    
    IMPORTANT: You don't have to provide all broker or Zookeeper nodes. A connection to one broker or Zookeeper node can be used to learn about the others. In this example, the list of hosts is trimmed to two entries.

9. This example uses a topic named `test`. Use the following to create this topic:

        /usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --replication-factor 2 --partitions 8 --topic test --zookeeper $KAFKAZKHOSTS

10. Use the producer-consumer example to write records to the topic:
   
        java -jar kafka-producer-consumer.jar producer test $KAFKABROKERS
    
    A counter displays how many records have been written.

11. Use the producer-consumer to read the records that were just written:

        java -jar kafka-producer-consumer.jar consumer test $KAFKABROKERS
    
    This returns a list of the random sentences, along with a count of how many are read.

## Streaming

NOTE: The streaming example expects that you have already setup the `test` topic from the previous section.

1. On your development environment, change to the `Streaming` directory and use the following to create a jar for this project:

        mvn clean package
    
2. Use SCP to copy the `kafka-streaming-1.0-SNAPSHOT.jar` file to your HDInsight cluster:
   
        scp ./target/kafka-streaming-1.0-SNAPSHOT.jar SSHUSER@CLUSTERNAME-ssh.azurehdinsight.net:kafka-streaming.jar
   
    Replace **SSHUSER** with the SSH user for your cluster, and replace **CLUSTERNAME** with the name of your cluster. When prompted enter the password for the SSH user.

3. Once the file has been uploaded, return to the SSH connection to your HDInsight cluster and use the following commands to create the `wordcounts` and `wordcount-example-Counts-changelog` topics:

        /usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --replication-factor 2 --partitions 8 --topic wordcounts --zookeeper $KAFKAZKHOSTS
        /usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --replication-factor 2 --partitions 8 --topic wordcount-example-Counts-changelog --zookeeper $KAFKAZKHOSTS

4. Use the following command to start the streaming process in the background:

        java -jar kafka-streaming.jar $KAFKABROKERS 2>/dev/null &

4. While it is running, use the producer to send messages to the `test` topic:

        java -jar kafka-producer-consumer.jar producer test $KAFKABROKERS &>/dev/null &

6. Use the following to view the output that is written to the `wordcounts` topic:
   
        /usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --bootstrap-server $KAFKABROKERS --topic wordcounts --from-beginning --formatter kafka.tools.DefaultMessageFormatter --property print.key=true --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer
   
    NOTE: You have to tell the consumer to print the key (which contains the word value) and the deserializer to use for the key and value in order to view the data.
   
    The output is similar to the following:
   
        dwarfs  13635
        ago     13664
        snow    13636
        dwarfs  13636
        ago     13665
        a       13803
        ago     13666
        a       13804
        ago     13667
        ago     13668
        jumped  13640
        jumped  13641
        a       13805
        snow    13637

7. Use __Ctrl + C__ to exit the consumer, then use the `fg` command to bring the streaming background task to the foreground. Use __Ctrl + C__ to exit it also.
"
nicksieger/refactoring-to-rails,large,51,3,2011-04-09T08:37:11Z,649,7,Example of refactoring a Spring/Hibernate application to Rails,,
ilya40umov/spring-batch-quartz-example,master,57,43,2013-02-18T12:33:04Z,293,0,An example which is meant to show how Spring Batch and Quartz can address the key issues of batch processing and job scheduling in a clustered environment.,,"spring-batch-quartz-example
===========================

## Summary ##

An example which is meant to show how Spring Batch and Quartz can address the key issues of batch processing and job scheduling in a clustered
environment.

## Used Technologies ##

Spring Framework(IoC, JDBC, Transactions, etc.), Quartz Scheduler, Spring Batch, MySQL.

## Project details ##

### How to run ###

The application contains two ""main"" classes:

1) org.sbq.batch.mains.ActivityEmulator does exactly what it's supposed to, it emulates some activity from users. This part is only needed to
keep adding some new data to DB. You should run only one instance of this class(meaning that this part does not deal with clustering).

2) org.sbq.batch.mains.SchedulerRunner is meant to be run in multiple instances concurrently in order to simulate a bunch of nodes in a cluster.

### Simulated environment ###

The example is meant to test the following environment: several servers(at least 2 nodes) running in a cluster against RDBMS(hopefully clustered)
which have to perform certain batch tasks periodically and have fail-over, work distribution etc.

### Implemented Jobs ###

<b>CalculateEventMetricsScheduledJob:</b> calculates a number of occurrences for each type of event since last job run and updates the site
statistic entry(which hold metrics of site since its start); Triggered each 5 minutes; saves where it finished(time for which it processed);
 misfire policy 'FireOnceAndProceed', meaning that only one call to the job is needed for any number of misfires;

<b>CalculateOnlineMetricsScheduledJob:</b> calculates total number of users online, number of users jogging, chatting,
dancing and idle for a certain point of time; Triggered each 15 seconds;
uses ScheduledFireTime from Quartz to identify for which point it should calculate the metrics; misfire policy 'IgnoreMisfire',
meaning that all missed executions will be fired as soon as Quartz identifies them(so that the job can catch up);
this job randomly (in ~ 1/3 of cases) throws an exception(TransientException) in order to emulate network issues;

## Addressed Scenarios ##

### Scheduler: No single point of failure ###

<b>Use case:</b> Make sure that if one node goes down, the scheduled tasks are still being executed by the rest of the nodes.

<b>How supported/implemented:</b> Quartz should be running on each machine in a cluster.
Each Quartz should be configured to work with DB-backed JobStore and clustering should be enabled in Quartz properties.
When at least 1 node with Quartz is up, the scheduled tasks will keep being executed(guaranteed by Quartz architecture).

<b>Steps to verify:</b> Run init.sql. Start one instance of ActivityEmulator(optional). Start several instances of SchedulerRunner.
Watch them executing jobs. Kill some of them. See how load is spread between the nodes which are left running.

### Scheduler: Work distribution ###

<b>Use case:</b> Make sure that the tasks are getting distributed among nodes in the cluster.
(This is important because after a certain point one node won't be able to handle all tasks).

<b>How supported/implemented:</b> Quartz with DB JobStore performs work distribution automatically.

<b>Steps to verify:</b> Run init.sql. Start one instance of ActivityEmulator(optional). Start several instances of SchedulerRunner.
Looking at the log file on each instance of SchedulerRunner verify that the tasks are executed on each node(The distribution is not guaranteed to
be even).

### Scheduler: Misfire Support ###

<b>Use case:</b> Make sure that if all nodes go down and then after while at least one is back online,
all of missed job executions(for particular jobs which are sensitive to misfires) are invoked.

<b>How supported/implemented:</b> Quartz with DB JobStore performs detection of misfired jobs automatically upon startup of the first node from
cluster.

<b>Steps to verify:</b> Run init.sql. Start one instance of ActivityEmulator(optional).
Start several instances of SchedulerRunner. Stop all instances of SchedulerRunner. Wait for some time.
Start at least one instance of SchedulerRunner. See how misfired executions are detected and executed.

### Scheduler: Task Recovery ###

<b>Use case:</b> Make sure that if a node executing a certain job goes down, the job is automatically repeated/re-started.

<b>How supported/implemented:</b> This use case is tricky because a server crash is likely to leave the job in unknown state(especially if it
writes data into non-transactional storage like Mongo). For now I assume the simplest use-case where the job just have to be restarted and we can
ignore the fact of possible data collisions. Using requestRecovery feature from Quartz and SYNCHRONOUS executor(which uses Quartz thread for
performing batch processing) we can rely on Quartz in terms of identifying crashed jobs and re-invoking them on a different node(or on the same one
 if it's up and the first one to identify the problem).

<b>NOTE:</b> I think that a more smooth transition for job recovery can be made by storing job state in ExecutionContext which will be picked up by
 Spring Batch when you create a new execution for the same job instance.

<b>Steps to verify:</b> Run init.sql. Start one instance of ActivityEmulator(optional). Start several instances of SchedulerRunner.
Look at the logs and find out which SchedulerRunner is running LongRunningBatchScheduledJob, kill it. See how after a while another job logs the
message that it's picked up the job(it can also be verified in DB by looking at executions table).

### Spring Batch: Retries Support ###

<b>Use case:</b> Retry a job if it fails due to a transient problem(such as a network connectivity issue, or DB being down for a couple of minutes).

<b>How supported/implemented:</b> Spring Batch provides RetryTemplate and RetryOperationsInterceptor for this purpose,
which allow to specify number of retries, back-off policy and types of exceptions which considered retry-able.

<b>Steps to verify:</b> Run init.sql. Start one instance of ActivityEmulator(optional). Start several instances of SchedulerRunner.
In logs you should see ""calculateOnlineMetrics() - TRANSIENT EXCEPTION..."" which indicates that exception has been thrown but a method of Service
class was retried by RetryOperationsInterceptor.

### General: Monitoring ###

<b>Use case:</b> There should be an easy way to get the following info at any point in time:
list of all jobs which are being executed at the moment, history of all job executions(with parameters and execution results success/failure),
list of all scheduled jobs(e.g. next time a particular job runs etc.).

<b>How supported/implemented:</b> In fact all this information can be obtained from Quartz and Spring Batch abstractions in java code. For some
cases you can look into DB and find out the status of running jobs, history etc. There is also Spring Batch Admin web-app which can be used for
this purpose.

<b>Steps to verify:</b> see 'How supported/implemented' section.

## Un-Addressed Scenarios ##

### General: Execution Management ###

<b>Q:</b> How do I manually re-execute a particular job(with given parameters) if it fails completely(i.e. no luck after N auto-retries)?

<b>A:</b> Not implemented at the moment. In fact we should consider using JMS in order to deliver a command to a cluster of batch processing nodes.
 Then a JMS listener will trigger a specified Spring Batch job.

### General: Graceful Halt ###

<b>Q:</b> How can I signal to all nodes to stop, so that I can deploy a new version of software, do maintenance etc.?

<b>A:</b> I think this is also should be done via JMS message(send to a topic!). Upon receiving of a message each node should: a) stop Quartz b)
wait for all nodes which don't support re-start c) stop all nodes which support re-start (the jobs which can save the point where they left and
resume from that point). Also see http://numberformat.wordpress.com/tag/batch/ for some info on graceful stop."
aws-samples/designing-cloud-native-microservices-on-aws,main,284,76,2019-12-13T18:15:07Z,46975,2,"Introduce a fluent way to design cloud native microservices via EventStorming workshop, this is a hands-on workshop. Contains such topics: DDD, Event storming, Specification by example. Including the AWS product : Serverless Lambda , DynamoDB, Fargate, CloudWatch.",aws cloudnative ddd dynamodb ecr ecs eventbridge eventstorming fargate lambda microservices serverless,"# Designing Cloud Native Microservices on AWS  (via DDD/EventStormingWorkshop)

![](docs/img/coffee.jpg)
_Picture license-free from [Pexels](https://www.pexels.com/photo/background-beverage-breakfast-brown-414645/)_

Building software is hard. Understanding the business needs of the software is even harder. In almost every software development project, there will always be some form of gap between the requirements of the business users and the actual implementation.

As a developer, knowing how to narrow this gap can help you go a long way to building applications that are relevant for the users. Using a Domain Driven Design approach, delivered via Event Storming, it can help to reduce the time it takes for everyone in the project team to understand a business domain model.



> Theory and Practice: Learning in the Real world cases

**Go through all of the learning journey, develop-->build-->deploy artifacts on AWS**

![](docs/img/Coffeeshop-architecture.png)





## Table of Contents
- [00 - Event Storming](#eventstorming)
  - [What is Event Storming?](#what-is-event-storming)
  - [Whom is it for?](#whom-is-it-for)
  - [Event Storming Terms](#event-storming-terms)
  - [Event Storming Benefits](#event-storming-benefits)
  - [Event Storming Applications](#event-storming-applications)
- [01 - Hands-on: Events exploring](docs/01-hands-on-events-exploring/README.md)
- [02 - Cafe business scenario](docs/02-coffee-shop-scenario/README.md)
- [03 - Roles, Commands, and Events Mapping](docs/03-roles-commands-events-mapping/README.md)
  - [Key Business events in the coffeeshop](docs/03-roles-commands-events-mapping/README.md#key-business-events-in-the-coffeeshop)
  - [Commands and Events mapping](docs/03-roles-commands-events-mapping/README.md#commands-and-events-mapping)
  - [Roles](docs/03-roles-commands-events-mapping/README.md#roles)
  - [Exceptions or risky events](docs/03-roles-commands-events-mapping/README.md#exceptions-or-risky-events)
  - [Re-think solutions to serve risky events](docs/03-roles-commands-events-mapping/README.md#re-think-solutions-to-serve-risky-events)
  - [Aggregate](docs/03-roles-commands-events-mapping/README.md#aggregate)
  - [Bounded Context forming up](docs/03-roles-commands-events-mapping/README.md#bounded-context-forming-up)
- [04 - Modeling and Development](docs/04-modeling-and-development/README.md)
  - [Specification by Example](docs/04-modeling-and-development/README.md#specification-by-example)
  - [TDD within Unit Test environment](docs/04-modeling-and-development/README.md#tdd-within-unit-test-environment)
  - [Generate unit test code skeleton](docs/04-modeling-and-development/README.md#generate-unit-test-code-skeleton)
  - [Implement Domain Model from code Skeleton](docs/04-modeling-and-development/README.md#implement-domain-model-from-code-skeleton)
  - [Design each Microservices in Port-adapter concept](docs/04-modeling-and-development/README.md#design-each-microservices-in-port-adapter-concept)
- [05 - Deploy Applications by AWS CDK](docs/05-deploy-applications-by-cdk/README.md) 
<!---
- [05 - Domain Driven Design Tactical design pattern guidance](05-ddd-tactical-design-pattern)
- [06 - Actual Implementation](06-actual-implementation)
- [07 - Infrastructure as Code by CDK](07-iaac-cdk)
- [08 - Deploy Serverless application](08-deploy-serverless-app)
- [09 - Deploy Containerized application](09-deploy-containerized-app)
- [10 - Build up CI/CD pipeline](10-build-up-cicd-pipeline)
--->

# Event Storming
![image](docs/img/problemsolving.png)

## What is Event Storming?
Event Storming is a **rapid**, **lightweight**, and often under-appreciated group modeling technique invented by Alberto Brandolini, that is **intense**, **fun**, and **useful** to **accelerate** project teams. It is typically offered as an interactive **workshop** and it is a synthesis of facilitated group learning practices from Gamestorming, leveraging on the principles of Domain Driven Design (DDD).

You can apply it practically on any technical or business domain, especially those that are large, complex, or both.

## Whom is it for?
Event Storming isn't limited to just for the software development team. In fact, it is recommend to invite all the stakeholders, such as developers, domain experts, business decision makers etc to join the Event Storming workshop to collect viewpoints from each participants.

## Event Storming Terms

![Event Storming](https://storage.googleapis.com/xebia-blog/1/2018/10/From-EventStorming-to-CoDDDing-New-frame-3.jpg)

> Reference from Kenny Bass - https://storage.googleapis.com/xebia-blog/1/2018/10/From-EventStorming-to-CoDDDing-New-frame-3.jpg

Take a look on this diagram, there are a few colored sticky notes with different intention:

* **Domain Events** (Orange sticky note) - Describes *what happened*. Represent facts that happened in a specific business context, written in past tense
* **Actions** aka Command (Blue sticky note) - Describes an *action* that caused the domain event. It is a request or intention, raised by a role or time or external system
* **Information** (Green sticky note) - Describes the *supporting information* required to help make a decision to raise a command
* **Consistent Business Rules** aka Aggregate (Yellow sticky note)
    * Groups of Events or Actions that represent a specific business capability
    * Has the responsibility to accept or fulfill the intention of command
    * Should be in small scope
    * And communicated by eventual consistency
* **Eventual Consistent Business rules** aka Policy (Lilac sticky note)
    * Represents a process or business rules. Can come from external regulation and restrictions e.g. account login success/fail process logic.

## Event Storming Benefits

Business requirements can be very complex. It is often hard to find a fluent way to help the Product Owner and Development teams to collaborate effectively. Event storming is designed to be **efficient** and **fun**. By bringing key stakeholder into the same room, the process becomes:

- **Efficient:** Everyone coming together in the same room can make decisions and sort out differences quickly. To create a comprehensive business domain model, what used to take many weeks of email, phone call or meeting exchanges can be reduced to a single workshop.

- **Simple:** Event Storming encourages the use of ""Ubiquitous language"" that both the technical and non-technical stakeholders can understand.

- **Fun:** Domain modeling is fun! Stakeholders get hands-on experience to domain modeling which everyone can participate and interact with each other. It also provides more opportunities to exchange ideas and improve mindsharing, from various perspective across multiple roles.

- **Effective:** Stakeholders are encouraged not to think about the data model, but about the business domain. This puts customers first and working backwards from there, achieves an outcome that is more relevant.

- **Insightful:** Event Storming generate conversations. This helps stakeholders to understand the entire business process better and help to have a more holistic view from various perspective.

## Event Storming Applications

There are many useful applications of Event Storming. The most obvious time to use event storming is at a project's inception, so the team can start with a common understanding of the domain model. Some other reasons include:
* Discovering complexity early on, finding missing concepts, understanding the business process;
* Modelling or solving a specific problem in detail;
* Learning how to model and think about modelling.

Event Storming can also help to identify key views for your user interface, which can jump start Site Mapping or Wireframing.

Let's get started with a quick example to demonstrate how to run a simple Event Storming.

[Next: 01 Hands-on Events Exploring >](docs/01-hands-on-events-exploring/README.md)


## License

This library is licensed under the MIT-0 License. See the LICENSE file.
"
naftulikay/commons-daemon-example,master,38,8,2012-08-31T20:49:26Z,147,0,An example project using the Apache Commons Daemon library to run a Java system service.,,"commons-daemon-example
======================

	Version: ${project.version}
	
A fairly simple project to demonstrate the awesomeness of the Apache Commons
Daemon project. This project demonstrates a complete application which 
can be run in the foreground, or (more importantly) as a background daemon
service using `jsvc`.
"
andbed/clean-architecture,master,50,7,2014-07-03T17:30:21Z,312,0,An example of the application built around clean architecture principles as defined by Uncle Bob.,,"Clean-architecture
==================

An example of applying ""The Clean Architecture"" principles as defined by Uncle Bob:
http://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html

This is only to illustrate key concepts. 

Version 1.1

Next TODOs:
* Add HSQLDB
* Finish configuring app as a working REST service (Spring based)
* Add security
* Add validation
* Add another delivery mechanism
* Implement some real functionality for a couple of use cases

Changelog:
* version 1.0 - prepared for Confitura 2014, contained only basic project structure
* version 1.1 - added stand-alone controller tests and Spring DI support
 
"
sureshg/java-rust-ffi,master,42,4,2015-05-04T11:33:14Z,892,0,🍋 FFI example for accessing Rust lang dynamic libraries from java ,java jvm rust rust-ffi,"# Java-Rust-FFI
FFI example for accessing rust dynamic libraries from java 
"
digitalgust/java2llvm,master,44,10,2019-10-24T06:49:29Z,788,1,"An Example shown convert java class bytecode to llvm ir , then compile llvm ir to standalong executable file .",,"
# java2llvm

An Example Project Show Convert Java Byte Code to LLVM IR assembler , then compile to standalone executable file   

This project is referenced on [class2ir](https://github.com/MParygin/class2ir), that based on an old llvm version.   
So I've changed instruction syntax, reimplemention to stack mode to fix branch problem, and repaired some bugs.   

There is a similar project that [tinyj2c](https://github.com/digitalgust/tinyj2c), it convert java bytecode to c source , it impmentated more function for java    

### Currently:
Generated CentOS_x64 and MacOS executable file, and say ""Hello world"".    
There are 2 implemention in the project, branch ""emu stack ver"" and ""register ver"", ""register_ver"" is fastest, but maybe problem that  branch static analysis, the ""emu_stack_ver"" is more slow, no branch problem.

### Make:
1. Enter directory java2llvm/   
2. Run ***mac_build.sh*** or ***centos_build.sh*** , then you will get a.out here.   

### Requirements:
 java 1.8    
* Centos:    
  CentOS 7.0 x86_64    
  llvm-as / llc / clang  5.0    
  make    
* MacOS    
  MacOS 10.15       
  XCode with cli tools 11.0     


### Known issue:
* No GC.   
* Maybe some of java instruction can't work   
* some of java instruction behavior simplify , eg. invokevirtual      
* Object memory allocation , like NO inheirt parent class field.     

### change log:
* Add base class java.lang.*, java.io.PrintStream   
* Add String to handle text output, StringBuilder to handle string concat   
* Trace instruction flow , to fix register var scope bug.   




==============
## class2ir readme

This project is the compiler from class files (Java byte code) to LL files (LLVM IR assembler).
Result files can be compiled by llvm-as to standalone binary ELF files.

Features:

* No JDK, no JVM
* Linux x86_64 target arch
* Extreme small size (~10-20 kB ordinary program)
* Use glibc
* Use clang for system object

At this moment project in active development, many things does not work.
"
levinotik/ReusableAsyncTask,master,27,5,2011-10-05T15:48:51Z,158,0,An example of using the Observer pattern to implement a reusable AsyncTask,,
krugloid/todo-jedux,master,47,7,2016-04-08T09:17:49Z,826,0,A simple Todo app example using Jedux for building app architecture and Anvil for reactive views,,"# todo-jedux

A simple Todo app example using [Jedux](https://github.com/trikita/jedux) for building app architecture and [Anvil](https://github.com/zserge/anvil) for reactive views

![screencap](https://github.com/krugloid/todo-jedux/blob/master/screencap.gif)
"
danramirez/wearable-listview-example,master,31,4,2015-07-13T14:29:56Z,1369,0,"Simple wearable listview example, with custom rows and center position animations",,"# Wearable Listview Example

Simple example showing how to use WearableListview for Android Wear.
Implements OnCenterProximityListener interface to change view style when focus on some list items 

![androidwear-capture](images/listview.gif)

# Icons by Norbert Kucsera
You can download his icons collection from The Noun Project website [https://thenounproject.com/idiotbox/collection/sports/](https://thenounproject.com/idiotbox/collection/sports/)
"
jonashackt/spring-boot-buildpack,main,32,9,2020-10-27T10:41:08Z,2444,7,Example project showing how to use Buildpacks.io together with Spring Boot & it's layered jar feature,,"# spring-boot-buildpack

[![Build Status](https://github.com/jonashackt/spring-boot-buildpack/workflows/build/badge.svg)](https://github.com/jonashackt/spring-boot-buildpack/actions)
[![License](http://img.shields.io/:license-mit-blue.svg)](https://github.com/jonashackt/spring-boot-buildpack/blob/master/LICENSE)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)
[![versionspringboot](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-buildpack/main/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27parent%27%5D%2F%2A%5Blocal-name%28%29%3D%27version%27%5D&label=springboot)](https://github.com/spring-projects/spring-boot)
[![Pushed to Docker Hub](https://img.shields.io/badge/docker_hub-released-blue.svg?logo=docker)](https://hub.docker.com/r/jonashackt/spring-boot-buildpack)

Example project showing how to use Buildpacks.io together with Spring Boot &amp; it's layered jar feature

[![asciicast](https://asciinema.org/a/368329.svg)](https://asciinema.org/a/368329)

I was really inspired to get to know the concept of buildpacks after attending this year's Spring One 2020 - and especially the talk by https://twitter.com/nebhale : https://www.youtube.com/watch?v=44n_MtsggnI

## Table of Contents 

* [Spring Boot & Cloud Native Build Packs?](#spring-boot--cloud-native-build-packs)
* [Step by step...](#step-by-step)
* [""dive"" into the Containers](#dive-into-the-containers)
* [Paketo pack CLI](#paketo-pack-cli)
  * [Why are the Spring Boot & Paketo images 40 years old?](#why-are-the-spring-boot--paketo-images-40-years-old)
* [Layered jars](#layered-jars)
* [Using Layered jars inside Dockerfiles](#using-layered-jars-inside-dockerfiles)
* [Buildpacks with layered jars](#buildpacks-with-layered-jars)
* [Doing a Buildpack build on TravisCI](#doing-a-buildpack-build-on-travisci)



### Spring Boot & Cloud Native Build Packs?

__Buildpacks?__

* Heroku invented (2011)

> Buildpacks were first conceived by Heroku in 2011. Since then, they have been adopted by Cloud Foundry (Pivotal) and other PaaS such as Google App Engine, Gitlab, Knative, Deis, Dokku, and Drie.

__Cloud Native Buildpacks & Paketo__

* today: [CNCF Incubation project](https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/) 

> Specification for turning applications into Docker images: [buildpacks.io](https://buildpacks.io/)

Paketo.io is an implementation for major languages (Java, Go, .Net, node.js, Ruby, PHP...)
--> [paketo.io](https://paketo.io/)

Similar to tools like: Jib https://github.com/GoogleContainerTools/jib, ko https://github.com/google/ko, Bazel (https://bazel.build/)

__Maven/Gradle Plugin to use Paketo Buildpacks__

The build-image plugin takes care of doing the Paketo build. From Spring Boot 2.3.x on simply run it with:

```shell script
mvn spring-boot:build-image
```



### Step by step...

Always start at [start.spring.io](start.spring.io) :)

![start-spring-io](screenshots/start-spring-io.png)

Implement your App (e.g. building a reactive Web app using Spring Webflux).

Then run the build with:

```shell script
mvn spring-boot:build-image
```

This will do a ""normal"" Maven build of your Spring Boot app, but also be 

```shell script
$ mvn spring-boot:build-image
...
[INFO] --- spring-boot-maven-plugin:2.4.0-M4:build-image (default-cli) @ spring-boot-buildpack ---
[INFO] Building image 'docker.io/library/spring-boot-buildpack:0.0.1-SNAPSHOT'
[INFO]
[INFO]  > Pulling builder image 'docker.io/paketobuildpacks/builder:base' 100%
[INFO]  > Pulled builder image 'paketobuildpacks/builder@sha256:00a9c25f8f994c1a044fa772f7e9314fe5d90d329b40f51426e1dafadbfa5ac8'
[INFO]  > Pulling run image 'docker.io/paketobuildpacks/run:base-cnb' 100%
[INFO]  > Pulled run image 'paketobuildpacks/run@sha256:21c1fb65033ae5a765a1fb44bfefdea37024ceac86ac6098202b891d27b8671f'
[INFO]  > Executing lifecycle version v0.9.2
[INFO]  > Using build cache volume 'pack-cache-604f3372716a.build'
[INFO]
[INFO]  > Running creator
[INFO]     [creator]     ===> DETECTING
[INFO]     [creator]     5 of 17 buildpacks participating
[INFO]     [creator]     paketo-buildpacks/bellsoft-liberica 4.0.0
[INFO]     [creator]     paketo-buildpacks/executable-jar    3.1.1
[INFO]     [creator]     paketo-buildpacks/apache-tomcat     2.3.0
[INFO]     [creator]     paketo-buildpacks/dist-zip          2.2.0
[INFO]     [creator]     paketo-buildpacks/spring-boot       3.2.1
[INFO]     [creator]     ===> ANALYZING
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:jre"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:jvmkill"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:helper"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:java-security-properties"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/executable-jar:class-path"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/spring-boot:spring-cloud-bindings"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/spring-boot:web-application-type"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/spring-boot:helper"" from app image
[INFO]     [creator]     ===> RESTORING
[INFO]     [creator]     ===> BUILDING
[INFO]     [creator]
[INFO]     [creator]     Paketo BellSoft Liberica Buildpack 4.0.0
[INFO]     [creator]       https://github.com/paketo-buildpacks/bellsoft-liberica
[INFO]     [creator]       Build Configuration:
[INFO]     [creator]         $BP_JVM_VERSION              11.*            the Java version
[INFO]     [creator]       Launch Configuration:
[INFO]     [creator]         $BPL_JVM_HEAD_ROOM           0               the headroom in memory calculation
[INFO]     [creator]         $BPL_JVM_LOADED_CLASS_COUNT  35% of classes  the number of loaded classes in memory calculation
[INFO]     [creator]         $BPL_JVM_THREAD_COUNT        250             the number of threads in memory calculation
[INFO]     [creator]         $JAVA_TOOL_OPTIONS                           the JVM launch flags
[INFO]     [creator]       BellSoft Liberica JRE 11.0.8: Reusing cached layer
[INFO]     [creator]       Launch Helper: Reusing cached layer
[INFO]     [creator]       JVMKill Agent 1.16.0: Reusing cached layer
[INFO]     [creator]       Java Security Properties: Reusing cached layer
[INFO]     [creator]
[INFO]     [creator]     Paketo Executable JAR Buildpack 3.1.1
[INFO]     [creator]       https://github.com/paketo-buildpacks/executable-jar
[INFO]     [creator]       Process types:
[INFO]     [creator]         executable-jar: java org.springframework.boot.loader.JarLauncher
[INFO]     [creator]         task:           java org.springframework.boot.loader.JarLauncher
[INFO]     [creator]         web:            java org.springframework.boot.loader.JarLauncher
[INFO]     [creator]
[INFO]     [creator]     Paketo Spring Boot Buildpack 3.2.1
[INFO]     [creator]       https://github.com/paketo-buildpacks/spring-boot
[INFO]     [creator]       Creating slices from layers index
[INFO]     [creator]         dependencies
[INFO]     [creator]         spring-boot-loader
[INFO]     [creator]         snapshot-dependencies
[INFO]     [creator]         application
[INFO]     [creator]       Launch Helper: Reusing cached layer
[INFO]     [creator]       Web Application Type: Reusing cached layer
[INFO]     [creator]       Spring Cloud Bindings 1.6.0: Reusing cached layer
[INFO]     [creator]       4 application slices
[INFO]     [creator]       Image labels:
[INFO]     [creator]         org.opencontainers.image.title
[INFO]     [creator]         org.opencontainers.image.version
[INFO]     [creator]         org.springframework.boot.spring-configuration-metadata.json
[INFO]     [creator]         org.springframework.boot.version
[INFO]     [creator]     ===> EXPORTING
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/bellsoft-liberica:helper'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/bellsoft-liberica:java-security-properties'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/bellsoft-liberica:jre'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/bellsoft-liberica:jvmkill'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/executable-jar:class-path'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/spring-boot:helper'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/spring-boot:spring-cloud-bindings'
[INFO]     [creator]     Reusing layer 'paketo-buildpacks/spring-boot:web-application-type'
[INFO]     [creator]     Reusing 5/5 app layer(s)
[INFO]     [creator]     Reusing layer 'launcher'
[INFO]     [creator]     Reusing layer 'config'
[INFO]     [creator]     Adding label 'io.buildpacks.lifecycle.metadata'
[INFO]     [creator]     Adding label 'io.buildpacks.build.metadata'
[INFO]     [creator]     Adding label 'io.buildpacks.project.metadata'
[INFO]     [creator]     Adding label 'org.opencontainers.image.title'
[INFO]     [creator]     Adding label 'org.opencontainers.image.version'
[INFO]     [creator]     Adding label 'org.springframework.boot.spring-configuration-metadata.json'
[INFO]     [creator]     Adding label 'org.springframework.boot.version'
[INFO]     [creator]     *** Images (408f3d59f38e):
[INFO]     [creator]           docker.io/library/spring-boot-buildpack:0.0.1-SNAPSHOT
[INFO]
[INFO] Successfully built image 'docker.io/library/spring-boot-buildpack:0.0.1-SNAPSHOT'
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  20.009 s
[INFO] Finished at: 2020-10-27T14:29:46+01:00
[INFO] ------------------------------------------------------------------------
``` 

As you can see in the first phases `DETECTING` and `ANALYZING`, the build process analyses the given application and identifies multiple build packs that are needed to successfully package the application into a Docker image:

```
[INFO]     [creator]     ===> ANALYZING
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:jre"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:jvmkill"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:helper"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/bellsoft-liberica:java-security-properties"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/executable-jar:class-path"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/spring-boot:spring-cloud-bindings"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/spring-boot:web-application-type"" from app image
[INFO]     [creator]     Restoring metadata for ""paketo-buildpacks/spring-boot:helper"" from app image
```

For example there's `paketo-buildpacks/bellsoft-liberica:jre` to bring in a JRE, since we have a Java app here. And there's also `paketo-buildpacks/executable-jar` since the resulting application is an executable jar.

Also there are a few `paketo-buildpacks/spring-boot-x` build packs because we have a Spring Boot application.
 

Now simply run your Dockerized app via

```
docker run -p 8080:8080 spring-boot-buildpack
```


### ""dive"" into the Containers

Let's use the great Container introspection tool [dive](https://github.com/wagoodman/dive) to gain an insight of the build Docker image

Install it with `brew install dive` on a Mac (or see https://github.com/wagoodman/dive#installation)
 
Using dive we see a whole lot of Docker image layers containing all the different paketo layers:

![dive-container-layers-without-layered-jars-feature](screenshots/dive-container-layers-without-layered-jars-feature.png)

If you want to have dive always start with the default to hide file attributes & unmodified files of each layer for an easier overview whats going on inside the layers, you can have a look at
https://github.com/wagoodman/dive#ui-configuration or simply create a `.dive.yaml` inside your home directory. Here's my `.dive.yaml` for convenience:

```yaml
diff:
  # You can change the default files shown in the filetree (right pane). All diff types are shown by default.
  hide:
    - unmodified

filetree:
  # Show the file attributes next to the filetree
  show-attributes: false
```

Btw. it's also the dive configuration https://twitter.com/nebhale uses in his SpringOne 2020 talk - and it took me a while to get that one right :) 



### Paketo pack CLI

Use Paketo without the Maven/Gradle build plugin directly through the CLI.

You need to [install pack CLI](https://buildpacks.io/docs/tools/pack/#pack-cli) first. On a Mac simply use brew:

```
brew install buildpacks/tap/pack
```

Choose one Paketo builder then

```
$ pack suggest-builders

Suggested builders:
	Google:                gcr.io/buildpacks/builder:v1      Ubuntu 18 base image with buildpacks for .NET, Go, Java, Node.js, and Python
	Heroku:                heroku/buildpacks:18              heroku-18 base image with buildpacks for Ruby, Java, Node.js, Python, Golang, & PHP
	Paketo Buildpacks:     paketobuildpacks/builder:base     Ubuntu bionic base image with buildpacks for Java, NodeJS and Golang
	Paketo Buildpacks:     paketobuildpacks/builder:full     Ubuntu bionic base image with buildpacks for Java, .NET, NodeJS, Golang, PHP, HTTPD and NGINX
	Paketo Buildpacks:     paketobuildpacks/builder:tiny     Tiny base image (bionic build image, distroless run image) with buildpacks for Golang

Tip: Learn more about a specific builder with:
	pack inspect-builder <builder-image>
```


Directly use Paketo with the pack CLI

```
pack build spring-boot-buildpack --path . --builder paketobuildpacks/builder:base
```

This will do exactly the same build which was run via the Spring Boot Maven build-image plugin behind the scenes (but maybe in more beautiful color):

[![asciicast](https://asciinema.org/a/368331.svg)](https://asciinema.org/a/368331)

Now simply use Docker to run the resulting image:

```
docker run -p 8080:8080 spring-boot-buildpack
```

and access your app on http://localhost:8080/hello


##### Why are the Spring Boot & Paketo images 40 years old?

As you may noticed the resulting images have a really old timestamp:

```shell script
gcr.io/paketo-buildpacks/builder          base-platform-api-0.3   914aba170326        40 years ago        654MB
paketobuildpacks/builder                  <none>                  914aba170326        40 years ago        654MB
spring-boot-buildpack-gcr-builder         latest                  6c7a74899b13        40 years ago        462MB
pack.local/builder/axczkudrjk             latest                  69aeed7ad644        40 years ago        654MB
spring-boot-buildpack                     latest                  b529a37599a6        40 years ago        259MB
jonashackt/spring-boot-buildpack          latest                  a9ccbb57fffd        40 years ago        259MB
paketobuildpacks/builder                  base                    1435430a71b7        40 years ago        558MB
```

Why is that? Because of providing reproducible builds (see this https://reproducible-builds.org/ for more info).

There's great post about the why available here: https://medium.com/buildpacks/time-travel-with-pack-e0efd8bf05db (Thanks coldfinger [to clarify this one on stackoverflow](https://stackoverflow.com/a/62866908/4964553)!)

Long story short: Without the fixed timestamp the hashes of the Docker images would differ every time you would issue a build (although maybe only seconds) - and then it wouldn't be clear, if anything changed.



### Layered jars

From Spring Boot 2.3 on there's also [a build in feature called layered jars](https://spring.io/blog/2020/08/14/creating-efficient-docker-images-with-spring-boot-2-3).

Before looking into the layered jars featuer, we should bring a standard Spring Boot jar layout to our minds. Simply unzip `spring-boot-buildpack-0.0.1-SNAPSHOT.jar` to see what's inside:

![jar-layout](screenshots/jar-layout.png)

You can see `BOOT-INF`, `META-INF` and `org` directories - where `BOOT-INF/classes` contains our application classes and `BOOT-INF/lib` inherits all application dependencies. The directory `org/springframework/boot/loader` contains all Spring Boot magic classes that are needed to create the executable Boot app. So nothing new here for the moment.

[While using Spring Boot 2.3.x we need activate this feature](https://docs.spring.io/spring-boot/docs/2.3.1.RELEASE/maven-plugin/reference/html/#repackage-layers) with simply configuring our `spring-boot-maven-plugin`:

```
	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<layers>
						<enabled>true</enabled>
					</layers>
				</configuration>
			</plugin>
		</plugins>
	</build>
```

[From Spring Boot 2.4.x Milestones (and GA) on, you don't even need to configure it since the default behavior then](https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/maven-plugin/reference/html/#repackage-layers):

> The repackaged jar includes the layers.idx file by default.


Now run a fresh 

```
mvn clean package
```

Now our jar file's `BOOT-INF` directory contains a new `layers.idx` file:

```
- ""dependencies"":
  - ""BOOT-INF/lib/""
- ""spring-boot-loader"":
  - ""org/""
- ""snapshot-dependencies"":
- ""application"":
  - ""BOOT-INF/classes/""
  - ""BOOT-INF/classpath.idx""
  - ""BOOT-INF/layers.idx""
  - ""META-INF/""
```

As you can see the main thing about this is to assign our directories to layers and implement an order for them! Our dependencies define the first layer since they are likely to not change that often.

The second layer inherits all Spring Boot loader classes and also shouldn't change all too much. Our SNAPSHOT dependencies then make for a more variable part and create the 3rd layer.

Finally our application's class files and so on are likely to change a lot! So they reside in the last layer.

In order to view the layers, there's a new command line option (or system property) `-Djarmode=layertools` for us. Simply `cd` into the `target` directory and run:

```
$ java -Djarmode=layertools -jar spring-boot-buildpack-0.0.1-SNAPSHOT.jar list

dependencies
spring-boot-loader
snapshot-dependencies
application
```

To extract each layer, we can also use the command line option with the `extract` option:

```
$ java -Djarmode=layertools -jar spring-boot-buildpack-0.0.1-SNAPSHOT.jar extract
```

Now inside the `target` directory you should find 4 more folders, which represent the separate layers:

![extracted-jar-layers](screenshots/extracted-jar-layers.png)


### Using Layered jars inside Dockerfiles

All those directories could be used to create a separate layer inside a Docker image e.g. by using the `COPY` command. Phil Webb [outlined this in his spring.io post](https://spring.io/blog/2020/01/27/creating-docker-images-with-spring-boot-2-3-0-m1) already, where he crafts a `Dockerfile` that runs the `java -Djarmode=layertools -jar` command in the first build container and then uses the extracted directories to create seperate Docker layers from them: 

```dockerfile
FROM adoptopenjdk:11-jre-hotspot as builder
WORKDIR application
ARG JAR_FILE=target/*.jar
COPY ${JAR_FILE} application.jar
RUN java -Djarmode=layertools -jar application.jar extract

FROM adoptopenjdk:11-jre-hotspot
WORKDIR application
COPY --from=builder application/dependencies/ ./
COPY --from=builder application/spring-boot-loader/ ./
COPY --from=builder application/snapshot-dependencies/ ./
COPY --from=builder application/application/ ./
ENTRYPOINT [""java"", ""org.springframework.boot.loader.JarLauncher""]
```

You can run the Docker build if you want using the [DockerfileThatsNotNeededUsingBuildpacks](DockerfileThatsNotNeededUsingBuildpacks) via:

```
docker build . --tag spring-boot-layered --file DockerfileThatsNotNeededUsingBuildpack
```

And inside the output you'll see the separate layers beeing created:

```
...
Step 8/12 : COPY --from=builder application/dependencies/ ./
 ---> 88bb8adaaca6
Step 9/12 : COPY --from=builder application/spring-boot-loader/ ./
 ---> 3922891db128
Step 10/12 : COPY --from=builder application/snapshot-dependencies/ ./
 ---> f139bcf5babb
Step 11/12 : COPY --from=builder application/application/ ./
 ---> 5d02393d4fe2
...
```

We can even further examine the created Docker image with `dive`:

```
dive spring-boot-layered
```

It was really cool for me to see that one in action!

![dive-docker-image-with-layeres](screenshots/dive-docker-image-with-layeres.png)


### Buildpacks with layered jars

Now running our build pack powered Maven build again should show a new part `Creating slices from layers index` inside the `Paketo Spring Boot Buildpack` output:

```
$ mvn spring-boot:build-image
...
[INFO]     [creator]     Paketo Spring Boot Buildpack 3.2.1
[INFO]     [creator]       https://github.com/paketo-buildpacks/spring-boot
[INFO]     [creator]       Creating slices from layers index
[INFO]     [creator]         dependencies
[INFO]     [creator]         spring-boot-loader
[INFO]     [creator]         snapshot-dependencies
[INFO]     [creator]         application
[INFO]     [creator]       Launch Helper: Reusing cached layer
...
```

> Oh, I found a bug https://github.com/paketo-buildpacks/spring-boot/issues/1 , which comes from a change in the buildpacks/lifecycle umbrella project: https://github.com/buildpacks/lifecycle/issues/455

Bug was fixed already :) So we could move on! After doing our build pack powered build, at the end of the log you should find the latest image id like `*** Images (4c26dc7b3fa3)`:

```
...
*** Images (4c26dc7b3fa3):
      spring-boot-buildpack
Reusing cache layer 'paketo-buildpacks/bellsoft-liberica:jdk'
Adding cache layer 'paketo-buildpacks/maven:application'
Adding cache layer 'paketo-buildpacks/maven:cache'
Reusing cache layer 'paketo-buildpacks/maven:maven'
Successfully built image spring-boot-buildpack
```

Now let's dive into the build image and watch our for our layers inside it:

![dive-container-layers-paketo-using-layered-jars-feature](screenshots/dive-container-layers-paketo-using-layered-jars-feature.png)



### Doing a Buildpack build on TravisCI

Let's have a look into this project's [.travis.yml](.travis.yml):

```yaml
language: java

jdk:
  - openjdk11

cache:
  directories:
    - $HOME/.m2

services:
  - docker

jobs:
  include:
    - script:
        - mvn clean spring-boot:build-image

      name: ""Build Spring Boot app with build-image Maven plugin""

    - script:
        # Install pack CLI via homebrew. See https://buildpacks.io/docs/tools/pack/#pack-cli
        - (curl -sSL ""https://github.com/buildpacks/pack/releases/download/v0.14.2/pack-v0.14.2-linux.tgz"" | sudo tar -C /usr/local/bin/ --no-same-owner -xzv pack)

        # Build app with pack CLI
        - pack build spring-boot-buildpack --path . --builder paketobuildpacks/builder:base

        # Push to Docker Hub also
        - echo ""$DOCKER_HUB_TOKEN"" | docker login -u ""$DOCKER_HUB_USERNAME"" --password-stdin
        - docker tag spring-boot-buildpack jonashackt/spring-boot-buildpack:latest
        - docker push jonashackt/spring-boot-buildpack:latest

      name: ""Build Spring Boot app with Paketo.io pack CLI""
```

I wanted to have both possible build options covered - the first uses the Maven plugin with `mvn clean spring-boot:build-image`.

The second installs `pack CLI` and build the application using it. Also the resulting image is pushed to DockerHub at https://hub.docker.com/r/jonashackt/spring-boot-buildpack


### Building GraalVM Native Images from Spring Boot Apps using Buildpacks

There's a new Maven goal in town to use Buildpacks to create Native Images (see https://github.com/jonashackt/spring-boot-graalvm)

```shell script
mvn springboot:native
```


### Links

Spring One 2020 talk by https://twitter.com/nebhale : https://www.youtube.com/watch?v=44n_MtsggnI

https://spring.io/blog/2020/01/27/creating-docker-images-with-spring-boot-2-3-0-m1

https://spring.io/blog/2020/08/14/creating-efficient-docker-images-with-spring-boot-2-3

https://docs.spring.io/spring-boot/docs/2.3.0.RELEASE/maven-plugin/reference/html/#repackage-layers

https://www.baeldung.com/spring-boot-docker-images

https://github.com/paketo-buildpacks/spring-boot

PackCLI needs Docker container runtime locally, not `docker build`! Build is done by lifecycle, see https://github.com/buildpacks/pack/issues/564#issuecomment-610172880

https://www.redhat.com/en/blog/why-red-hat-investing-cri-o-and-podman


## Advanced Topics

#### Passing Runtime Environment Variables JAVA_TOOL_OPTS

https://stackoverflow.com/questions/64964709/how-to-pass-flags-to-java-process-in-docker-contatiner-built-by-cloud-native-bui/65142031#65142031


#### Bindings

Configure JDK uri of the bellsoft-liberica buildpack:

https://stackoverflow.com/questions/65212231/cloud-native-buildpacks-paketo-with-java-spring-boot-how-to-configure-different

Configure uri of spring-cloud-bindings jar:

https://stackoverflow.com/questions/65118519/spring-boot-gradle-bootbuildimage-task-with-private-repo

Bindings with spring-boot-maven-plugin

https://stackoverflow.com/questions/65078636/how-to-configure-buildpack-bindings-with-the-spring-boot-maven-plugin/65195715#65195715


#### Change 


#### K8s

Skaffold: https://skaffold.dev/docs/pipeline-stages/builders/buildpacks/

https://stackoverflow.com/questions/64843991/how-do-i-use-spring-boot-maven-plugin-build-image-with-skaffold-and-dekorate


#### Buildpacks with Spring Boot < 2.3

https://stackoverflow.com/questions/64061096/using-cloud-native-buildpacks-with-spring-boot-2-3/65142343#65142343



#### Azure

https://docs.microsoft.com/en-us/azure/container-registry/container-registry-tasks-pack-build


#### Google Cloud

https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks


"
sameershukla/JavaFPLearning,main,26,3,2023-02-15T03:56:01Z,804,0,"The Repository is a compendium of Java-based Functional Programming examples aimed at enhancing your comprehension of the concepts and facilitating your eventual implementation of them. The examples in the repo doesn't contains the examples of how to use obvious map, filter, reduce, instead it focuses on writing efficient functional code in Java",,"# Functional Programming In Java

<img src=""https://axisapplications.com/wp-content/uploads/2019/02/functionalprogramming_icon-300x300.png"" width=""300"">

# Overview

The Repository is a compendium of Java-based Functional Programming examples aimed at enhancing your comprehension of the concepts and facilitating your eventual implementation of them.
The examples in this repo doesn't contains the examples of how to use obvious map, filter, reduce, instead it focuses on writing efficient functional code. 
Throughout this course, you will gain a solid understanding of Functional programming concepts, starting from the fundamentals and progressing to more advanced topics. You will learn how to write Higher Order Functions in Java and how to leverage Function Chaining to produce elegant and efficient code. 
Additionally, you will explore Function Currying, Partial Functions, and Monads. One noteworthy aspect of this course is that it includes a variety of practical examples, which will be incredibly beneficial for your learning experience.

# What you'll learn and how the code is structured. 

The repository contains examples that demonstrate the principles of writing elegant functional code. The repo so far has 2 packages ""basic"" and ""problems"". One should start exploring from the ""basic"" package that 
has several sub-packages covering each FP concept one should start learning in this order 

###  basics
  - Composition
        - basic
        - advance 
  - hof
  - currying
  - types
  - utils

### problems

This package contains Pipeline examples, which should be looked into once basics are in place, this WIP (Work In Progress, more and more examples will be added going forward)

###  The ""composition.basic"" and ""composition.advance"" packages in Java for Function Chaining

The ""composition.basic"" package provides a comprehensive guide for chaining regular functions, covering examples for String manipulation, file reading, and handling functions with multiple parameters. Here is the suggested order for learning these examples:

**StringFunctionPipeline**: Creating a pipeline of functions to manipulate strings.

**BiFunctionPipeline**: Chaining BiFunctions and returning Tuples, utilizing the Tuple class.

**TriFunctionPipeline**: Handling functions with three parameters using TriFunction.

**UserManagementService**: Demonstrating function chaining in a Spring Boot application.

### The ""composition.advance"" package is dedicated to showcasing how to chain objects of the java.util.function.Function interface. 

Here is the suggested order for learning these examples:

**FunctionExample**: Demonstrating Function as First-class citizens in Java.

**StringFunctionPipeline**: Creating a pipeline of Functions to manipulate strings.

**FunctionCompositionExample**: Understanding the difference between 'compose' and 'andThen' functions.

### The ""basics.hof"" package contains Higher Order Function examples, which are functions that either take other functions as arguments or return functions as results.
Here is the suggested order for learning these examples:

**StringComparatorHof**: Example demonstrates passing Comparator Function to a Function and Compares Strings.
**ConsoleFormatterHof**: Example demonstrates a function that takes 2 functions as params. 

### The ""currying"" package is dedicated to showcasing Function Currying and Partial Applied Functions (PAF)

The ""functional.currying"" package provides examples of Currying, which is a technique for transforming a function that takes multiple arguments into a sequence of functions that each take a single argument.
Here is the suggested order:

**CurriedCreateUser**: Showcases simple example of Function Currying

**CurriedEmailComposer**: Showcases Composing EmailId using Currying

**TriFunctionCurrying**: Slightly advance example of Currying.

**PartialApplicationEndpoint**: Demonstrates example of Partial Applied Function (PAF)

**PartialFunctionApplicationExample**: MOST IMPORTANT EXAMPLE OF CURRYING AND PAF.

### The ""types"" package contains types. 

There are 2 Types covered Tuple and Unit. 

**Tuple**: In functional programming, a tuple is an ordered collection of elements of different types.

**Unit**: Unit is a class that represents the absence of a value. It is used to indicate that a function returns no useful value, similar to the void type.

### The utils package is work in progress that is a collection of some user-defined utils method. Very USEFUL by the way. 

# What are Functions 

In computer programming, a function is a self-contained block of code that performs a specific task. 
Functions take input, called arguments or parameters, and can return output values, allowing them to be used as building blocks for larger programs.

![img.png](images/function1.png)

# Understanding Functions in Functional Programming 

   Functions are a key concept in functional programming, and are used to express computations and transformations on data. In functional programming, functions are treated as first-class citizens, meaning that they can be passed around as values, stored in variables or data structures, and returned as results from other functions.
   Functions in functional programming are typically pure functions, which means that they don't have any side effects, and their output is solely determined by their input. This makes them very predictable and easy to reason about, since their behavior doesn't depend on any external state or context.

   One way to perceive java.util.function.Function is as follows: 

   ![img.png](images/function.png)
   
   BiFunction can be perceive as

   ![img.png](images/bifunc.png)

# Lambda Expression

  In Java, a lambda expression is a type of anonymous function that can be used to represent a block of code that can be passed as an argument to a method or stored in a variable. When a Java compiler encounters a lambda expression in the source code, it performs several steps to detect and process it:
   
   ##### **_Parsing_**: The Java compiler parses the lambda expression to determine its syntax and identify the variables that are used in the expression.
   
   ##### **_Type_ _Inference_**: The compiler infers the types of the lambda parameters based on the context in which the lambda expression is used.
   
   ##### **Creation of a Functional Interface**:_ A lambda expression is only valid if it can be assigned to a functional interface. A functional interface is an interface with a single abstract method. If the lambda expression matches the signature of the functional interface, the compiler creates an instance of that interface and assigns the lambda expression to it.
    
   ##### **Compilation**_: Finally, the compiler compiles the lambda expression and generates bytecode that can be executed by the Java Virtual Machine (JVM).

   During compilation, the lambda expression is translated into a class file that implements the functional interface. The class file contains a method that implements the lambda expression, as well as any captured variables and their values. When the lambda expression is executed, the JVM creates an instance of this class and invokes the method on that instance.

# How Lambda Expressions handled by JVM  

When a lambda expression is encountered in Java code, the JVM uses the invokedynamic instruction to create an instance of a functional interface that represents the lambda.

Here's how the process works in more detail:

1. The Java compiler generates an instance of a functional interface that corresponds to the lambda expression. For example, if the lambda expression is of the form x -> x * 2, the compiler generates an instance of the java.util.function.IntUnaryOperator interface.

2. The invokedynamic instruction is used to create a CallSite object, which is responsible for the dynamic invocation of the lambda expression. The CallSite object is associated with the lambda expression and the functional interface instance generated in step 1.

3. When the lambda expression is invoked, the JVM uses the CallSite object to dynamically bind the lambda expression to the appropriate method in the functional interface.

4. The JVM then invokes the method on the functional interface instance using the appropriate arguments, and returns the result to the calling code.

Overall, the use of invokedynamic and functional interfaces enables efficient implementation of lambda expressions in Java, allowing for concise and expressive code. The dynamic binding of the lambda expression to the appropriate method in the functional interface allows for greater flexibility in code composition and enables more powerful abstractions in Java programming.

# Function Chaining

In order to create a chain of functions, it is essential to first instantiate a Function or BiFunction object.
This marks the beginning of the pipeline. For example, you could create a Function<String, String> object named ""pipeline"" using the
""createReader"" method of the ""FileOps"" class. Once you have created the ""pipeline"" object, you can use the ""andThen"" method to chain subsequent functions together.
Each function in the chain will take the output of the preceding function as input. Eventually, the final function in the chain should return a String value.

Function<String, String> pipeline = FileOps :: createReader;

pipeline.andThen(""Output of Create Reader is input here"") and so on, but eventually it should return String.

more details can be found here: https://www.c-sharpcorner.com/article/creating-function-pipelines-in-java/

# Function Chaining Use Cases

**Data processing**: Function chaining can be used to perform a series of data transformations on a collection or stream of data, such as filtering, mapping, sorting, and reducing. By chaining these operations together, you can create a data processing pipeline that is both efficient and easy to read and maintain.

**Input validation**: Function chaining can be used to validate user input by applying a series of validation rules to the input data. Each function in the chain can check a specific aspect of the input, such as its length, format, or range, and return an error message if the input fails the validation.

**Logging and debugging**: Function chaining can be used to create a chain of logging or debugging statements that track the execution of a program or a specific code path. Each function in the chain can output a specific piece of information, such as the input or output data, the execution time, or the error message, and pass the output to the next function in the chain.

**Configuration and setup**: Function chaining can be used to configure and set up a complex system or application. Each function in the chain can perform a specific configuration task, such as initializing a database connection, setting up a network connection, or loading a configuration file, and pass the configuration data to the next function in the chain.

In general, function chaining can be used in any situation where you need to compose a series of related functions to perform a specific task or data transformation. By chaining the functions together, you can create a powerful and flexible pipeline that is both easy to use and easy to maintain.

# Function Chaining Methods and Interfaces

**apply Function**: The 'apply()' method takes an input and returns a result. It is used to apply a function to an argument and compute a result

   ```
   Function<Integer, Integer> doubleFunction = x -> x * 2;
   Integer result = doubleFunction.apply(5); // result is 10
   ```
In this example, we have created a function that doubles its input and applied it to the integer 5. The apply() method takes the integer 5 as an argument and returns the result 10.
Remember: apply returns a result

**andThen Function:** The Function interface's ""andThen"" method takes a sequence of two functions and applies them in succession, using the output of the first function as the input to the second function. This chaining of the functions results in a new function that combines the behavior of both functions in a single transformation. Here's an example:

![img.png](images/andThen.png)

    ```
      Function<Integer, Integer> addOne = x -> x + 1;
      Function<Integer, Integer> doubleIt = x -> x * 2;
      Function<Integer, Integer> addOneAndDoubleIt = addOne.andThen(doubleIt);
   
      System.out.println(addOneAndDoubleIt.apply(5)); // Output: 12
   
    ```


**compose Function:** In contrast to the ""andThen"" method, the ""compose"" method applies the first function to the output of the second function. This means that the second function is applied to the input, and then the first function is applied to the output of the second function. This results in a chain of functions where the output of the second function becomes the input of the first function.. Here's an example:

![img.png](images/compose.png)

       ```
         Function<Integer, Integer> addOne = x -> x + 1;
         Function<Integer, Integer> doubleIt = x -> x * 2;
         Function<Integer, Integer> addOneAfterDoubleIt = addOne.compose(doubleIt);
      
         System.out.println(addOneAfterDoubleIt.apply(5)); // Output: 11
      
       ```

**BiFunction Interface:** BiFunction can be represented as Function<A, Function<A, B>>

      ```
      /**
      * Input is Function<String, Function<String,String>>
      *     Input to Function is String and output is a second function
      *       Input to second function is String and output is a String, hence on apply.apply a String is returned
      *        Input to first function (s1) output is a function (s2) -> s1 + s2
      *          Input to second function is (s2) output is s1 + s2
      *
      */
      (s1) -> (s2) -> s1 + s2
      private static String function(Function<String, Function<String, String>> f){
         return f.apply(""Hello"").apply(""World"");
      }
      
      (s1, s2) -> s1 + s2 
      private static String biFunc(BiFunction<String, String, String> b){
        return b.apply(""Hello"", ""World"");
     }
      ```

**TriFunction:** If we require more than two parameters to be passed to a function, such as three parameters, we may encounter a problem as there is no TriFunction interface available in Java. However, there are two potential solutions to this issue.
The first is to create our own TriFunction interface, which would resemble something like:,

      ```
      @FunctionalInterface
      public interface TriFunction<A, B, C, R> {
           R apply(A a, B b, C c);

           default <R> TriFunction<A, B, C, R> andThen(TriFunction<A, B, C, R> after) {
              return (A a, B b, C c) -> after.apply(a,b,c);
            }
      }
     ```
If we need to pass more than three parameters to a function, it can become a difficult problem to solve. In such cases, using currying can be the most effective approach.
By breaking down the function into a series of nested functions, each taking one argument, we can create a more flexible and reusable solution.

# Higher Order Function 

  A higher-order function is a function that can take one or more functions as arguments, and/or return a function as its result. 
  This allows for more flexible and reusable code, as functions can be passed around like any other value. 
  We are familiar with 'map()', 'filter()' methods both of them take Function and Predicate as arguments 

![img.png](images/hof.png)

  They are an important and powerful concept in functional programming, providing several benefits, including:
   
  **Code reuse**: Higher-order functions allow you to abstract away common patterns of code, such as iterating over a collection, filtering elements, or mapping values. Once you have written a higher-order function for a particular pattern, you can reuse it with different functions to achieve different behaviors.
   
  **Code clarity**: Higher-order functions can make code more concise and easier to read by removing unnecessary boilerplate code. By passing a function as an argument to another function, you can define behavior in a clear and declarative way.
   
  **Flexibility**: Higher-order functions allow you to write more flexible code that can adapt to different situations. By allowing functions to be passed as arguments or returned as results, higher-order functions can be used to create generic and reusable code that can be adapted to different contexts.
   
  **Separation of concerns**: Higher-order functions can help to separate concerns by allowing you to define specific behavior in separate functions, which can then be combined and reused as necessary. This can make code more modular and easier to test.
   
  **Function composition and Chaining**: Higher-order functions can be used to compose more complex functions by combining simpler functions in a logical and reusable way. This can make code more expressive and easier to reason about. 
    
####   Example of HOF that takes Function as an argument 
  
   ```
    public static void applyMultiplyFunction(Integer[] numbers, Function<Integer, Integer> f){
        for(int i=0; i < numbers.length; i++){
            numbers[i] = f.apply(numbers[i]);
        }
    }

    public static void main(String[] args) {
        Integer[] numbers = {1,2,3,4,5};
        Function<Integer, Integer> multiply = x -> x * 2;
        applyMultiplyFunction(numbers, multiply);
        System.out.println(Arrays.toString(numbers));
    }
  ```
  In the above example, we have created a Higher Order Function ""applyMultiplyFunction"" that takes an array of integers and a function as arguments, and applies the function to each element of the array.
  This example demonstrates how higher-order functions can be used to make our code more modular and reusable, by abstracting away the details of how a function is applied to an array or collection.

####   Example of HOF that returns Function as it's result

    ```
       private static Function<String, String> prefix = str -> str;
   
       private static Function<String, String> suffix(String str){
           return suffix -> str + "" "" + suffix;
       }
   
       public static void main(String[] args) {
           Function<String, Function<String, String>> namePipeline = name -> prefix.andThen(suffix(name));
           System.out.println(namePipeline.apply(""John"").apply(""Doe""));
       }
    ```
The example above includes the creation of two functions, ""prefix"" and ""suffix"", both of which return a function that takes a string input and produces a string output. These two functions are then combined together using a pipeline, allowing their outputs to be concatenated.



# Currying and Partial Functions

   https://www.c-sharpcorner.com/article/exploring-the-benefits-of-function-currying-in-java-understanding-the-concept/ 

   Function currying is a technique that involves breaking down a function that takes multiple arguments into a series of functions that each take a single argument.
   In other words, it transforms a function that takes multiple arguments into a chain of functions that each take a single argument and return a new function until all the original arguments are consumed.
   Java's Function interface supports currying through the use of the ""andThen"" and ""compose"" methods. These methods enable the creation of a sequence of functions where the output of one function is used as the input of another function. By chaining functions together in this way, it is possible to create a pipeline of transformations that can be applied to data in a flexible and modular way.
   Currying has several benefits, including making it easier to reuse and compose functions, and enabling functions to be partially applied with some of their arguments fixed at runtime. This can lead to more modular, maintainable code and can simplify the development process. However, it's important to use currying judiciously and to avoid creating overly complex function chains that are difficult to reason about.

   Although Java doesn't have built-in support for function currying, it is still possible to implement curried functions using functional interfaces and lambda expressions. 
   However, the syntax for defining a curried function in Java can be verbose and difficult to read. 
   For example, declaring a function that takes two integer parameters and returns an integer in curried form would look like this: Function<Integer, Function<Integer, Integer>>, which can be challenging to interpret at first glance.
 
   Below code show-case how currying looks like, 

   ```
      //Curried function, it's returning other function, currying with 2 params
      Function<Integer, Function<Integer, Integer>> add = (param1) -> (param2) -> param1 + param2; 
   
      //Curried function, it's returning other function, Currying with 3 params
      Function<String, Function<String, Function<String, String>>> curry = (f) -> (s) -> (t) -> f + "" ""+ s + "" "" + t;
      System.out.println(curry.apply(""Java"").apply(""Programming"").apply(""Language"")); # Java Programming Language
   
   ```


   Several Java 8 functions, such as map in Optional or Stream, expect a Function as their argument. 
   If we have a BiFunction, we can curry it and pass it directly to these functions without the need for a wrapper function or lambda expression.

   Partial functions, on the other hand, are functions that are defined only for certain input values, and undefined for all other values. 
   A partial function can be thought of as a function that takes a subset of the arguments of another function

   Partial functions have several advantages:

**Increased expressiveness:** Partial functions allow for more expressive code by allowing you to express functions that are not defined for all possible inputs. This can make your code more concise and easier to read.

**Improved error handling:** When a function is defined for all possible inputs, it can be difficult to detect errors. With a partial function, you can explicitly specify when an input is not valid, which can make error handling more robust.

**Better separation of concerns:** Partial functions can help you separate your code into smaller, more manageable pieces by allowing you to define functions that only operate on certain subsets of the input domain. This can make your code more modular and easier to maintain.

**More efficient algorithms:** In some cases, a partial function can be computed more efficiently than a total function. For example, if you only need to compute a function for a subset of the input domain, you can avoid computing unnecessary values.

**Improved type safety:** By using partial functions, you can make your code more type safe by explicitly defining the input and output types for each subset of the input domain. This can help prevent type errors and make your code more reliable.

# Currying Use Cases

**Configuring database access:** When connecting to a database, it's often necessary to provide credentials and other configuration parameters. Using a curried function to handle the configuration allows for greater flexibility and reuse of code. For example, we can create a function that takes the database URL as input and returns another function that takes the username and password as input and returns a database connection.

**Filtering and sorting data:** When working with large datasets, it can be useful to create functions that filter and sort the data according to specific criteria. Using function currying to create reusable filters and sorters allows for greater flexibility and efficiency in data processing. For example, we can create a function that takes a list of strings as input and returns another function that filters the list to include only strings that contain a specific substring.

**Event-driven programming:** In event-driven programming, it's common to register listeners or callbacks that are triggered when specific events occur. Using function currying to register listeners and callbacks can make the code more flexible and easier to maintain. For example, we can create a function that takes an event type as input and returns another function that takes a listener function as input and registers the listener for that event type.

**Service composition:** In a service-oriented architecture, it's common to compose services by chaining together functions that handle different aspects of the service. Using function currying to chain together functions allows for greater flexibility and adaptability in service composition. For example, we can create a function that takes a URL as input and returns another function that fetches data from that URL, then another function that processes the data, and so on.



# Monads 

A monad is a type that encapsulates a value and provides a way to chain operations on that value in a composable way. 
Monads allow developers to abstract away common patterns of code and provide a consistent interface for working with different types of data.
There are several popular monads in Java, including Optional, Stream, and CompletableFuture. The Optional monad is used to represent a value that may or may not be present, and provides methods for safely accessing and manipulating the value. The Stream monad is used to represent a sequence of values that can be transformed and filtered in a composable way. The CompletableFuture monad is used to represent a future result that can be processed in a non-blocking way, and provides methods for combining and transforming the results of multiple futures.
In addition to these built-in monads, it's also possible to create custom monads in Java using libraries such as the Functional Java library or the Vavr library. These libraries provide abstractions for working with monads and other functional programming concepts in a more idiomatic and expressive way.
Overall, monads provide a powerful tool for writing composable and modular code in Java, and can help developers to write cleaner, more concise, and more maintainable code.

While the most commonly used monads in functional programming languages such as Haskell, Scala, and F# usually have the map, filter, and flatMap operations, it's not necessarily the case that all monads must have these operations. In fact, there are many different types of monads with different sets of operations.
The essential feature of a monad is that it provides a way to chain computations in a composable way. The specific operations that a monad provides depend on the specific use case and the types of data that the monad is designed to work with.
For example, the Maybe monad in Haskell provides map and flatMap operations, but does not have a filter operation. The State monad in Haskell provides get and put operations for working with stateful computations, but does not have map, filter, or flatMap operations in the traditional sense.
In general, a monad can have any number of operations that are tailored to its specific use case. The key is that the operations must satisfy the three monad laws: the identity law, the associativity law, and the compatibility law. As long as these laws are satisfied, the operations can be used to chain computations in a composable way, regardless of whether they are map, filter, flatMap, or some other set of operations.

# How to create our own Monad 

Writing your own monad can be a bit involved, but it's definitely possible. The steps involved in creating a monad are:

Define the type that the monad will encapsulate. This can be any type of data, such as a list, a tree, a stream, or a result.

Define the operations that the monad will provide. The most common operations are map, flatMap, and unit (or return). map applies a function to the value inside the monad and returns a new monad with the transformed value. flatMap applies a function that returns another monad to the value inside the monad and returns a flattened monad. unit (or return) creates a new monad with a given value.

Implement the monad operations using the underlying data structure. The operations must satisfy the three monad laws: the identity law, the associativity law, and the compatibility law. These laws ensure that the operations can be used to chain computations in a composable way.

# The 3 Monad law in detail

**Identity law:** The unit operation must be an identity function for the flatMap operation. That is, m.flatMap(unit) is equivalent to m for any monad m.

This means that when you apply the flatMap operation to a monad and pass in the unit operation, you should get the same monad back. In other words, the unit operation should not change the value of the monad.

**Associativity law:** The flatMap operation must be associative. That is, m.flatMap(f).flatMap(g) is equivalent to m.flatMap(x -> f.apply(x).flatMap(g)) for any monad m and functions f and g.

This means that when you apply the flatMap operation to a monad twice, with two different functions, the order in which you apply the functions should not matter. The result should be the same, regardless of whether you apply the first function first or the second function first.

**Compatibility law:** The map operation must be compatible with the flatMap operation. That is, m.map(f) is equivalent to m.flatMap(x -> unit(f.apply(x))) for any monad m and function f.

This means that when you apply the map operation to a monad, the result should be the same as if you apply the flatMap operation with a function that returns a new monad with the result of applying the function to the value inside the original monad.

@author: Sameer Shukla

   
   
   
   
   "
tideworks/arvo2parquet,master,37,13,2018-05-19T19:03:31Z,137,6,"Example program that writes Parquet formatted data to plain files (i.e., not Hadoop hdfs); Parquet is a columnar storage format.",,"# avro2parquet - write Parquet to plain files (i.e., not Hadoop hdfs)

Based on example code snippet `ParquetReaderWriterWithAvro.java` located on github at:
 
&nbsp;&nbsp;&nbsp;&nbsp;[**MaxNevermind/Hadoop-snippets**](https://github.com/MaxNevermind/Hadoop-snippets/blob/master/src/main/java/org/maxkons/hadoop_snippets/parquet/ParquetReaderWriterWithAvro.java)
 
Original example code author: **Max Konstantinov** [MaxNevermind](https://github.com/MaxNevermind)

Extensively refactored by: **Roger Voss** [roger-dv](https://github.com/roger-dv), Tideworks Technology, May 2018

## IMPLEMENTATION NOTES:

- Original example wrote 2 Avro dummy test data items to a Parquet file.

- The refactored implementation uses an iteration loop to write a default of 10
Avro dummy test day items and will accept a count as passed as a command line
argument.

- The test data strings are now generated by RandomString class to a size of 64
characters.

- Still uses the original avroToParquet.avsc schema by which to describe the Avro
dummy test data.

- The most significant enhancements is where the code now calls these two methods:
    * `nioPathToOutputFile()`
    * `nioPathToInputFile()`

  + `nioPathToOutputFile()` accepts a Java nio `Path` to a standard file system file path
and returns an `org.apache.parquet.io.OutputFile` (which is accepted by the
`AvroParquetWriter` builder).

  + `nioPathToInputFile()` accepts a Java nio Path to a standard file system file path
and returns an `org.apache.parquet.io.InputFile` (which is accepted by the
`AvroParquetReader` builder).  
<br>
These methods provide implementations of these two `OutputFile` and `InputFile` adaptors
that make it possible to write Avro data to Parquet formatted file residing in the
conventional file system (i.e., a plain file system instead of the Hadoop hdfs file system)
and then read it back. The usecase would be for working in a big data solution stack that
is not predicated on Hadoop and hdfs.  
<br>

- It is an easy matter to adapt this approach to work with JSON input data - just
synthesize an appropriate Avro schema to describe the JSON data, put the JSON data
into an Avro `GenericData.Record` and write it out.

## NOTES ON BUILDING AND RUNNING PROGRAM:

- Build: `mvn install`

- **`HADOOP_HOME`** environment variable should be defined to prevent an exception from being
thrown - code will continue to execute properly but defining this squelches it. This is
down in the bowels of Hadoop/Parquet library implementation - not behavior from the
application code.

- **`HOME`** environment variable may defined. The program will look for logback.xml there
and will write the Parquet file it generates to there. Otherwise the program will
use the current working directory.

- In `logback.xml`, the filters on the `ConsoleAppender` and `RollingFileAppender` should be
adjusted to modify verbosity level of logging. The defaults are set to `INFO` level. The
intent is to allow, say, setting file appender to `DEBUG` while console is set to `INFO`.

- The only command line argument accepted is the specification of how many iterations
of writing Avro records; the default is 10.

- Can use the shell script `run.sh` to invoke the program from the Maven `target/` directory.

- Logging will go into a `logs/` directory as the file `avro2parquet.log`.
"
lwluc/camunda-ddd-and-clean-architecture,main,31,6,2022-05-01T16:37:28Z,49247,2,An example to show how you could use clean architecture and DDD elements with Camunda.,,"# Camunda DDD and Clean Architecture

An example to show how you could use clean architecture and DDD and their advantages with Camunda.

I also wrote a blog post to show how clean architecture could help you to update to Camunda Platform 8 without 
touching your domain centered code: [How Clean Architecture helps you migrating Camunda Platform 7 to 8](https://www.novatec-gmbh.de/en/blog/how-clean-architecture-helps-you-migrating-camunda-platform-7-to-8/).

## 🚀Features

The [BPMN process](assets/processes/loan_agreement.png) which start a [second process](assets/processes/cross_selling_recommendation.png) via message correlation should represent a tiny business process just to demonstrate the architecture.

### 🛫Start the process

With the following POST request, you could start the process:

```sh
curl --request POST \
  --url http://localhost:8080/loan/agreement/1 \
  --header 'Content-Type: application/json' \
  --data '{
    ""customerNumber"": ""A-11"",
    ""name"": ""Tester"",
    ""mailAddress"": ""tester@web.io"",
    ""amount"": 1100
  }'
```

Using the admin user (`username: admin` and `password: pw`) you could log in to the Camunda Cockpit.

### ↔️Migration to Camunda Platform 8

All necessary change to upgrade from Camunda Platform 7 to 8 are shown in [this pull request](https://github.com/lwluc/camunda-ddd-and-clean-architecture/pull/1).
The only changed files are all placed in the adapter layer. So the domain does not need to be touched to change a framework.

## 🏗Architecture

The following sections contain some small aspects explaining the advantages of Domain-driven Design (DDD) and clean architecture.

Flexibility around your domain (e.g., switching from Camunda 7 to Camunda 8) is the main focus I want to show you in this little example.

### Clean Architecture

A software architecture that integrates changeability in their package and class structure makes it easy to switch or migrate a framework. 
So the migration of Camunda Platform 7 to 8 is much less painful with a good architecture.

![DDD-Clean-Architecture](assets/architecture/camunda-ddd-and-clean-architecture-rings.png)
*The layers of clean architecture (based on Clean Architecture by Robert C. Martin)*

Robert C. Martin describes architectural guidelines in his book ""[Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)"", 
which should allow independence of frameworks, databases, user interface (UI) and other technologies. 
In his opinion, clean architecture ensures the testability of business rules by its design. 
The image above displays layers as concentric circles wrapping each other. 
Each layer represents different parts of software. 
The center of the circle represents ""policies"" and thus your business rules and domain knowledge. 
The outer circles are ""mechanisms"" supporting our domain center. 
Beside the layers, the arrows show the dependency rule – only inward point dependencies! 
To reach the goals of clean architecture, the domain code must not have any dependencies pointing outwards. 
Instead, all dependencies point towards the domain code.
The essential aspect of your business domain is placed in the core of the architecture: 
the entities. They are only accessed by the surrounding layer: the use cases. 
Services in a classic layered architecture represent use cases in a clean architecture, 
but these services should be more fine-grained so that they have only one responsibility. 
You do not want one big service implementing all your business use cases. 
Supporting components are placed around the core (your entities and use cases), such as persistence or user interfaces.

#### Building Block View

The [building block view](https://docs.arc42.org/section-5/) image below shows a stereotypical static decomposition of a system using Clean Architecture into building blocks as well as their dependencies. 

![Clean-Architecture-Building-Block-View](assets/architecture/clean_architecture_building_blocks.svg)
*Building Block View of clean architecture*

#### Runtime View

The [runtime view](https://docs.arc42.org/section-6/) image below describes concrete behavior and interactions of the stereotypical building blocks of a system using Clean Architecture.

![Clean-Architecture-Runtime-Block-View](assets/architecture/clean_architecture_runtime_view.svg)
*Building Block View of clean architecture*

#### Dependency Inversion Principle

When the dependency rule is applied, the domain has no knowledge about how you persist your 
data or how you display them in any client. 
The domain should not contain any framework code (arguably Dependency Injection). 
As I already mentioned, you could use the Dependency Inversion Principle (DIP) to apply the 
dependency rule of clean architecture. The DIP tells you to reverse the direction of a dependency. 
You may be thinking of the Inversion of Control (IoC) design pattern, which is not the same as DIP, 
although they fit well together. If you want to know the exact differences 
I recommend reading Martin Fowlers article ""[DIP in the Wild](https://martinfowler.com/articles/dipInTheWild.html#YouMeanDependencyInversionRight)"" (in short: ""[...] IoC is about direction, 
and DIP is about shape.""). The following figure shows an example of how the DIP works.

![With and without Dependency Inversion Principle](assets/architecture/dependency-inversion-principle.png)
*The Dependency Inversion Principle (DIP)*

Imagine having a service (DomainService in the image) which starts a Camunda Process. 
To isolate your service (your business logic) from the framework, you could create another service using the 
Camunda Java API to start a process instance. The left frame of the image shows this scenario without applying the DIP. 
The domain service calls the ProcessEngineService directly. So what's the problem? Starting a process 
is a core aspect of our domain, so we want to pull it into our domain. By doing so, we break the rule of keeping 
our domain framework-agnostic. We can fix this, by placing an interface in our domain core instead of the 
concrete implementation and place the actual implementation outside of our domain layer, et voilà we apply the DIP.

Combining the DIP with the [Ports and Adapters](http://alistair.cockburn.us/Hexagonal+architecture) architecture (the clean architecture emerged of), 
we get the picture shown below.

![DIP, Ports and Adapter, Clean Architecture](assets/architecture/dependency-inversion-principle-rings-in-out.png)
*Clean architecture DIP and ports and adapters*

Separating our ports / use cases and adapters that drive our application (input-ports) or are driven by our 
application (output-ports) helps us to structure our code even more and to keep the boundaries more clear.

#### Mapping between layers

The following image shows how the layers interact with the domain object with and without mapping. 
Without mapping, you miss the biggest advantage of clean architecture: 
decoupling your domain core with the outer (infrastructure) layers. 
If you do not map between your inner and outer layers, you are not isolated. 
If a third-party system changes its data model, your domain model needs to change as well. 
To prevent dependence on external influencing factors and to promote independence and decoupling, 
it is necessary to map between the layers. 
Using the input and output ports (use case layer) as gatekeepers into your domain core, 
they define how to communicate and interact with your application. 
They provide a clear API and by mapping into your domain you keep it independent of any framework 
or technology model changes.

![With and without mapping between layers](assets/architecture/mapping-between-layers.png)
*With and without mapping between layers*

The frame explaining the mapping approach is just one possible way of mapping. 
If you want to know more about different stages of mapping, take a look a 
Tom Hombergs book ""[Get Your Hands Dirty on Clean Architecture](https://leanpub.com/get-your-hands-dirty-on-clean-architecture)"", he explains them pretty well.
In conclusion, mapping can be used to achieve greater decoupling. On the other hand, 
mapping between each layer could produce a lot of boilerplate code, which might be overkill 
depending on your use case and the goals you are working towards.

### Domain-driven Design

Using clean architecture as architecture style combines perfectly with Domain-driven Design because we completely focus on our domain core (entities and use cases).
In my opinion, Domain-driven Design (DDD) perfectly combines with clean architecture due to the fact that DDD is focused on your business domain. 
Focusing on your domain is supported by the goal of clean architecture, keeping the domain free of any framework or technologies. 
E.g. your domain does not focus on how to persist something, it just tells the outgoing port to save it. 
The implementation of the port (placed on the adapter layer) decides to use, e.g., relational or non-relational databases.

Beside the matching goal of DDD and clean architecture, DDD tries to help you build complex designs around your domain,
by e.g., building immutable objects that know all about their invariants, which helps you even more to structure your code.

DDD Elements like Aggregate Entities and ValueObject can be found in our [domain-primitives](https://github.com/domain-primitives/domain-primitives-java) library.

Structuring your code functional and brining more context to your object with, e.g. Value Object does not only help you to keep your code expressive, it also helps keeping it close to your business as your BPMN model.

## 🙏🏼Credits

Thanks to [Matthias Eschhold](https://github.com/MatthiasEschhold) for the passionate discussion around DDD and clean architecture. 
Matthias published a nice blog series: [Clean Architecture and flexibility patterns](https://github.com/MatthiasEschhold/clean-architecture-and-flexibility-patterns)

## 📨Contact

If you have any questions or ideas, feel free to contact me or create an [issue](https://github.com/lwluc/camunda-ddd-and-clean-architecture/issues)."
rpereira-dev/CubeEngine,master,40,6,2015-07-20T10:51:46Z,23309,0,"A Desktop Voxel rendering engine (window, 3D Voxels, GUI's, audio lib) + a game implementation example",,"# VoxelEngine

-----------------------------------------------------------------------

A Game engine for Voxel games, using OpenGL, GLFW, OpenAL, Netty

**ABANDONNED**

-----------------------------------------------------------------------

## DEMO VIDEOS
https://www.youtube.com/playlist?list=PLTsKtD9K5K8nkeK2MzVr3JFv4ofuJTugb

## HOW TO USE ##
        - >> git clone https://github.com/toss-dev/VoxelEngine.git

        - >> cd VoxelEngine

        - >> ./gradlew eclipse

Then in Eclipse, import the project
(You can also import the gradle project directly if you are using the Eclipse plugin)

You now have 3 projects:

- VoxelEngine is the core engine
- POT is a game implementation
- Mod sample : a mod example, which will be imported by POT on launch


## DEMO VIDEOS
https://www.youtube.com/playlist?list=PLTsKtD9K5K8nkeK2MzVr3JFv4ofuJTugb










## TECHNICAL PART:
Down bellow are all the explanations about how things are implemented (more or less) deeply. It gives a great overview of the engine, and it may allow one to find a wrong implementation, or something that should have been thought differently 

# Face system

Front: x-       ;    Back: x+

Left: z-        ;    Right: z+

Bot(tom): y-    ;    Top: y+


# Terrains

Terrains are chunks of the world. They are 16x16x16 blocks. They contains 2 16x16x16 arrays (unidimensional for optimisation), one for each block light value (1 byte per block), and 1 for block ids (2 bytes per blocks). If the light value array is null, it means no block are emetting lights nearly. If the block id array is empty, it means the terrain is full of air. (This null values are key point in memory management)

Moreover, each terrains has a list of 'BlockInstance', which contains... blocks instances (see bellow)

# Terrains meshes

They are basically 1 gl vao and one gl vbo. Various meshing algorithm should be implemented.

Currently, I'm using the 'greedy' meshing algorithm (see https://0fps.net/2012/06/30/meshing-in-a-minecraft-game/)

When building a mesh, the Mesher iterates through all terrain's block, and get it 'BlockRenderer'.

A 'BlockRenderer' is an interface which is supposed to push a specific block vertices to the vertex stack, when the mesher meshes it.

# Block

A block has a unique instance which is created on engine initialisation. This instance stores all the block data. But then, only it id is stored into the terrain as we said before

# BlockInstance
If a block need it own instance, (parameters), you can override the function 'Block.createBlockInstance()' , which when returning a non-null 'BlockInstance', the new BlockInstance will be updated on every terrain's update

i.e, liquid blocks need some parameters (liquid level, color...), and so has a BlockInstance

# Water

As explained upside, every water block has it own instance. Each instance has an amount of liquid, between MIN_LIQUID_AMOUNT and MAX_LIQUID_AMOUNT. The block rendering is done as simple block, but by translating vertices upper, or lower, depending on the amount of liquid for an instance. (this is done pretty fastly in the meshing algorythm)

The flowing update algorythm (for eacg liquid block instance): the most it is called, the faster / smoother the water will flow, and so the flowing effect will look realistic, but this is a quite costly call as it require to rebuild a terrain mesh. So for now it is call like each 4 frames)

Algorithm:

        var amount
        if amount < MIN_LIQUID_AMOUNT:
                disperseWater() (remove block)
        else if the block under this instance is air:
        			make the instance 'fall', reducing this block height by 1
        else
        			if the block under is liquid:
                        transfer as much liquid from the current instance, to the instance under
                if the current instance still has an amount of water:
                			transfer as much liquid possible to neighbor liquid block (x+1, z), (x, z+1), (x-1, z), (x, z-1)


# Light

The light system is based on SOA implementations (https://www.seedofandromeda.com/blogs/29-fast-flood-fill-lighting-in-a-blocky-voxel-game-pt-1)

It is a flood filling algorithms, applied on byte arrays. The distinction between sunlight (ambiant lighting), and blocklights (lights) is made.

# Particles

I implemented two type of particles, which are both behaving like points particles cpu-side. They have a health value which decrease on update, and the particle is deleted when this value reach 0. Each particles has a scale, position, velocity, and color value. They are being updated once in the rendering thread, before each frames

# Billboarded particles.
They are billboarded rectangles, which always face the camera, gpu. I use geometry shader and a single call for each particle draws. (So I can render them depending on the distance from the camera). Each BillboardedParticle has a TextureAtlas reference. This object is basically a GLTexture, where the image is a texture atlas. On particle updates and rendering, I use a single integer to know which texture of the atlas should be use, and I interpolate it with the next texture of the atlas, so it create this nice smooth effect when updating the texture

# Cube particles.
These particles are rendered as cubes, using a single draw call (via glDrawArraysInstanced()). A vbo is fill up with 21 floats per cubes: it transformation matrix (16 floats), it color (4 floats), it health (1 float).


# Sky, environment
The sky is currently using an untextured skydome, colored using a 3D noise. I'm looking for a nicer solution (sky plane + volumetric clouds should be better)
Supporting fog (density, opacity, color)
Supporting day/night cycles
Climatic effects can be simulated using particles (dust, pollen, rain...)

# Models
3D models implementation is based on Skeleton system.
The mesh vertex format is:

(x, y, z, ux, uy, vx, vy, nx, ny, nz, b1, b2, b3, w1, w2, w3)
('position', 'texture coordinates', 'normal', 'bones', 'weights')

Each bones 'bn' correspond to the ID of a bone on the skeleton, and the corresponding weight 'wn' is a factor on how much does the bone transformation affect this vertex. (so when animating, the mesh stays static, the bones are transformed, and then we apply the same transformation to vertices but using these weights)


- A 'Model' contains all the data of a model, which is basically a 'ModelSkeleton', a 'ModelMesh', 'List<ModelAnimation>', 'List<ModelSkin>'
- 'ModelMesh' : contains the mesh (VAO/VBO) of the whole model
- 'ModelSkin' simply has a name, and a texture.
- 'ModelSkeletonAnimation' represents a single animation for a skeleton (i.e dance, run, ...). It has a name and a list of Key frames for transformed bones at given times.

The ModelRenderer is only able to render 'ModelInstance', which are instances of a Model. This 'instance' system allows to get hundred of instances of the same model without performance loss.

You should consider binding your model to a specific Entity, using the ModelManager and EntityManager on program initialization. (so when this Entity spawns, a new 'ModelInstance' is automatically bound to it), and so whole rendering process does the job independantly

However, you can also dynamically bind an Entity and a Model, by creating a new 'ModelInstance', and add it to the ModelManager. (you should really not be doing this)

# Entities
An entity is an (moving) object of the world.
It has a unique world id (set when added to a world), vec3 position, rotation, vec3 velocities, vec3 accelerations
It follows the physics rules we apply on it (gravity, frictions...)
It may have AI
It may have a model, and then it has it own ModelInstance


# World

A world is basically a set of Terrains. Each terrains are stored into a Hashmap (where the key is 3 integers representing terrain index, the hash function is optimized for this. (see 'Vector3i.hashCode()')

Every terrains which need to be updated are also in another list. (they are the 'loaded terrains')

Entities are stored within multiples data storage to make their rendering and updates faster. See 'EntityStorage.java'

# Events

See EventManager.java. A simple event system. One can register an event or an event callback via the EventManager

# Mod loader

It loads every jar file in the folder './mods', './mod', './plugins', './plugin', and if they have a class which inherit from 'Mod.class', and has a valid 'ModInfo' annotation, then it load it to the engine. Pretty easy, isn't it?

# Rendering pipeline

The game is rendering in two times: the world, and the GUI's

• The World:

The WorldRenderer contains some 'Renderer', which are object which render parts of the world.
They are allocated when they are needed, and deallocated when they arent anymore properly
For example, there is the ModelRenderer (which render every entity's model), the SkyRenderer, which render the sky, the TerrainRenderer...
Any modder can register new world renderer if needed.
The world is rendered to it own FBO and texture. It can be displayed using a 'GuiTexture' for example.

• Gui Renderer

# GUI System

The engine implements it own GUI system, and a preset of GUI objects.
The system is based on parent/child hierarchy. (coordinates are always relative to the parent)
Each objects have a weight, which determines it layer when rendering.
Events are handled properly.
New font can easily be added to the game (one line of code), by using the hiero jar file (font generator), in the 'com.grillecube.renderer.gui.font' package

# Sounds

A custom set of object and functions are implemented for 3D sounds (using OpenAL, thanks to LWJGL bindings)

# Assets management :
Each mod / project should have it own assets, stored into a zip file. 
This file has to be registered on program initialisation
Then, it will be unzipped, and missing/modified files will be unzipped (so we ensure data is always present and not corrupted)
"
PavelMal/selenide-example,main,142,0,2023-09-11T23:12:25Z,277,0,Example of using Selenide for UI Autotests,,"
This is an example of using the Selenide framework and showcasing tests using the Page Object pattern. The project includes basic tests for search/clearing the search/ displaying pop-up suggestions, as well as attempting to log in with incorrect data.

You can run tests in parallel by adding param `-Psuite=""Parallel""`also you can configure thread amount by adding param `-Pthreads=""2""` into 'arguments'.

In case of no additional params tests will start with default configuration (`single` thread with a `single` suite).
Also, you can add a param `-PbaseUrl` to change a start URL for example:

- `-PbaseUrl=""google.com""`

To see a test report after passing tests, you need following the instruction:

- Run tests (when tests finish you will see a new folder 'build' inside a project, inside 'build' folder you will see 'allure-results' folder)

- Change your directory into 'build' and run a command `allure serve` in command line (report will be formed automatically)

Screenshots will be automatically added to failed steps

![img.png](src/test/resources/screenshot/failed.png)"
mzubal/spring-boot-monolith,master,31,5,2018-03-03T15:59:14Z,458,0,Simple example of monolithic spring-boot app with components isolated using Java visibility modifiers.,,"# Simple Spring-boot Monolith
This repository represents a very simple proof of concept of creating a *monolithic* *spring-boot* project with *separation* of internal components via Java APIs (hiding their internals from others). This is intentionally the most simple way of doing this using Java visibility modifiers (and verifying this works well with Spring and other libraries), but there might be better choices for bigger projects (like maven/gradle modules or microservices).

The APIs are very loosely coupled and it would be quite easy to change e.g. the persistence for each ""service"" or transform this to use modules (you can check how that looks e.g. in [spring-gradle-kotlin-multimodule](https://github.com/mzubal/spring-gradle-kotlin-multimodule)) or microservice.

The project uses *spring-data* as a persistence layer for all the ""services"". It also takes advantage of *ObjectMapper* and *Lombok* to reduce the boilerplate needed.

The package structure of the project is following, with each ""service"" residing in it's package:
![packages](doc/packages.png)
"
camunda-community-hub/Make-Rest-Calls-From-Camunda-7-Example,main,27,21,2021-04-08T09:35:10Z,686,3,This is an example application which demonstrates the main ways in which a rest call can ben made by from a Camunda BPMN process. ,,"# Make REST calls from Camunda Platform 7 Example

This document outlines an example project, and four ways to make REST calls from Camunda Platform 7 to external systems. Each method offers a series of pros and cons, but this document aims to provide a better understanding as to which method may be the best option for a given requirement and user.  

![Video Tutorial Badge](https://img.shields.io/badge/Tutorial%20Reference%20Project-Tutorials%20for%20getting%20started%20with%20Camunda-%2338A3E1)
<img src=""https://img.shields.io/badge/Camunda%20DevRel%20Project-Created%20by%20the%20Camunda%20Developer%20Relations%20team-0Ba7B9"">


 This document outlines implementation of the following:

* [Java Delegates](https://docs.camunda.org/manual/latest/user-guide/process-engine/delegation-code/)
  * Where the call is made within a local Java Class, called by the engine.
* [External Task](https://docs.camunda.org/manual/latest/user-guide/process-engine/external-tasks/)
  * Where the call is made by an external piece of software, running independently from the engine.
* [Connectors](https://docs.camunda.org/manual/latest/user-guide/process-engine/connectors/)
  * Where the call is made by the engine, using properties added directly to the XML of the process model. 
* [Script](https://docs.camunda.org/manual/latest/user-guide/process-engine/scripting/)
  * Where the call is made by the engine, executing a script. The script can be added directly to the XML or be maintained as an external ressource.

Within a process, the three first implementation methods can implement a BPMN [Service Task](https://docs.camunda.org/manual/latest/reference/bpmn20/tasks/service-task/). The best practice guide provides a good [overview of the different options for the implementation of service taks](https://camunda.com/best-practices/invoking-services-from-the-process/). Script can be implemented within a [Script Task](https://docs.camunda.org/manual/latest/reference/bpmn20/tasks/script-task/).

Additionally, [Task Listeners](https://docs.camunda.org/manual/latest/user-guide/process-engine/delegation-code/#execution-listener) and [Execution Listeners](https://docs.camunda.org/manual/latest/user-guide/process-engine/delegation-code/#execution-listener) can implement Java Delegates and Script.

This project uses three Service Tasks and one Script Task to outline the different implementation methods. The following image outlines the process:

![Process](./img/process.png)

:exclamation: **Important:**  
If a REST call returns a `2xx` status code, this indicates a successful call. However, it should not be assumed other codes such as `5xx` or `4xx` will automatically lead to an error within the process. Instead, this can be implemented and handled depending on the requirements for each project. For more information, read the [explanation of the implementations](#explanation-of-the-implementations) section below.

## Run the project

The project contains a **Camunda Spring Boot** application and a [JavaScript External Task Worker](https://github.com/camunda/camunda-external-task-client-js). To run the project and start a process instance in Tasklist, follow the steps below:

1. Download the project and open the **Camunda Spring Boot** application in your IDE using Java 11.
2. Start the application.
3. Start a process instance of the process in Tasklist using the predefined start form, or start the instance via REST.
4. If you [start the instance via REST](https://docs.camunda.org/manual/latest/reference/rest/process-definition/post-start-process-instance/) make sure the necessary variables are included.

Example for the Request body:

```Json
{
  ""variables"": {
    ""repoName"" : {
        ""value"" : ""Name of Repo"",
        ""type"": ""String""
    },
    ""repoOwner"" : {
      ""value"" : ""Name of Repo Owner"",
      ""type"": ""String""
    }
  },
 ""businessKey"" : ""myBusinessKey""
}

```

5. Navigate to the folder of the **Javascript External Task** client. Make sure you have npm installed and install the needed packages with an:

```
npm update
```

6. Run the worker.

```
node service.js
```

## Explanation of the implementations

This section provides more information on each implementation. This section also shows how the response code and the information from the response body can be used differently. 

In this project, a response code that is anything except `200` will create an incident. The information of the response body is either used to complete the task, or used to throw a BPMN error.

No matter how you implement the call, there three main options as to how a Service Task can behave:

* Complete the task successfully (use the information from the REST call to route the further process.)
* Throw a [BPMN error](https://docs.camunda.org/manual/latest/reference/bpmn20/events/error-events/) (information gained from the REST call leads to an error that should be handled within the logic of the process.)
* Create an [incident](https://docs.camunda.org/manual/latest/user-guide/process-engine/incidents/) (information from the REST call leads to a fail and creates an incident in the workflow engine. This will require an administrator to resolve.)

### Java Delegate

A **Java Delegate** is called during the execution, and must implement the **JavaDelegate** interface. In this example, the Java Class is deployed to the Camunda Engine.

:file_folder: **Note:**  
The explanation divides the code into different pieces to outline the different concepts. The full class can be found within [this project](Make-Rest-Calls-From-Camunda-Example/CamundaApllication/src/main/java/com/example/workflow/FindGitHubRepo.java).

The first part of the class gets the process variables `repoOwner` and `repoName`. These variables are used to perform the REST call within the Java code:

```java
@Named
public class FindGitHubRepo implements JavaDelegate {

    @Override
    public void execute(DelegateExecution execution) throws Exception {

        String repoOwner = (String) execution.getVariable(""repoOwner"");
        String repoName = (String) execution.getVariable(""repoName"");


        HttpResponse<String> response = get(""https://api.github.com/repos/"" + repoOwner + ""/"" + repoName);

```

The `get` method being called in the above snippet simply implements the rest call using the Java9 HTTP client

```Java
    public HttpResponse<String> get(String uri) throws Exception {
        HttpClient client = HttpClient.newHttpClient();
        HttpRequest request = HttpRequest.newBuilder()
                .uri(URI.create(uri))
                .build();

        HttpResponse<String> response =
                client.send(request, HttpResponse.BodyHandlers.ofString());

        System.out.println(response.body());

        return response;
    }

```

#### Create an incident

The code example then checks the status code. If the response code is not `200`, an exception will be thrown. Within the code, this exception is not handled. Therefore, this will lead to an incident within the Camunda Platform Engine.

```java
 if (response.statusCode() != 200) {

            // create incidence if Status code is not 200
            throw new Exception(""Error from REST call, Response code: "" + response.statusCode());

        } 

```

:exclamation: **Important:**   
Ensure you understand [transactions](https://docs.camunda.org/manual/latest/user-guide/process-engine/transactions-in-processes/) within the Camunda workflow engine. Depending on where your last transaction in the process is, the state of the process will roll back to the last transaction. Note that this may not be the service task where the error occurred. You can set transactions manually by using the **async before and after** flag in the modeler.

![Process](./img/async.png)

#### Throw a BPMN error

If the response code is `200`, the example code receives the response body and parses for the entry of `downloads`. If the value of downloads is `false`, the code throws a BPMN error. This error can then be handled by the logic of the process:

```java
 } else {

            //getStatusText
            String body = response.body();
            JSONObject obj = new JSONObject(body);
            //parse for downloads
            Boolean downloads = obj.getBoolean(""has_downloads"");

            if (!downloads) {

                // Throw BPMN error
                throw new BpmnError(""NO_DOWNLOAD_OPTION"", ""Repo can't be downloaded"");

            }

```

#### Complete the task

If the two prior checks do not trigger the exception or the BPMN error, the example code parses the response body for the number of forks. This will set the variable to the process and the task complete.

```java
} else {
  //parse for forks
                String forks = obj.getString(""forks"");
                int forksAsNumber = Integer.parseInt(forks);
                //Set variables to the process
                execution.setVariable(""forks"", forksAsNumber);

            }
```

### External Task

An external task is written into a list. Next, an external task worker fetches and locks it using Camunda's REST API, and the external task workers deploy independently and are therefore language independent. There is a [list with available clients in different languages](https://github.com/camunda/awesome-camunda-external-clients) you may refer to. This project uses the JavaScript external task client.

:file_folder: **Note:**  
 The explanation divides the code into different pieces to outline the different concepts. The full code example can be found within [this project](Make-Rest-Calls-From-Camunda-Example/SearchContributorService/service.js).

With the External Task client, it is possible to get variables from the process. These variables are then used to make a REST call in Javascript code:

```javascript
client.subscribe(""searchContributors"", async function({ task, taskService }) {

    const repoName = task.variables.get(""repoName"");
    const repoOwner = task.variables.get(""repoOwner"");
 
const url = ""https://api.github.com/repos/""+ repoOwner +""/"" + repoName + ""/contributors""
console.log(url)

try{
const contributors = await fetch(url)
```

#### Create an incident

Again, we check the JavaScript code for the response code. If the code does not equal `200`, we throw an error. Later in our JavaScript code, we handle the error and use the External Task client to send back a failure to the workflow engine. This failure will then create an incident. If the response code equals `200`, the response body is returned:

```javascript
.then(function(response) {    
    if (!response.ok) {
       // throw Exception;
       var e = new Error(""HTTP status "" + response.status); // e.name is 'Error'
       e.name = 'RestError';
       throw e;
    }
    return response.json();
})

...

// Handle Exception and create an incidence in Workflow Engine
}catch (e){
    await taskService.handleFailure(task, {
        errorMessage: e.name,
        errorDetails: e.message,
        retries: 0,
        retryTimeout: 1000
      });

}

```

#### Throw a BPMN error

Next, the information of the response body is used. The example uses the information of the number of contributors. If the number is smaller or equals **one**, the external task worker sends back a BPMN Error:

```javascript
var numberContributors = Object.keys(contributors).length;

if(numberContributors <= 1){
    const processVariables = new Variables();
    processVariables.set(""errorMessage"", ""Sorry the repo has just one or none contributor, look for another one"");
    await taskService.handleBpmnError(task, ""NO_CONTRIBUTORS"", ""The repo has no contributors"", processVariables);
}

```

#### Complete the task

If there is more than one contributor, the External Task worker uses the client method to complete the task and send back variables to the process:

```javascript
//Complete Task
const processVariables = new Variables();
processVariables.set(""contributors"", numberContributors);
await taskService.complete(task, processVariables)
```

### Connectors

The two previous examples implemented the REST call within their code. Beneficially, everything is together in one place and the user can easily handle the different outcomes.

**Connectors** within Camunda provide an API for simple HTTP and SOAP connections; there is no need to implement the REST call with code. However, handling the different outcomes is more complicated and requires Script.

:exclamation: **Important:**  
Be aware of the other two options. Depending on how complicated the REST call and the proceeding of the response becomes, the other options above may be more suitable.

To use **Connectors** and the http client, the connect dependency and the http client must be added to the POM file:

```xml
    <dependency>
      <groupId>org.camunda.bpm</groupId>
      <artifactId>camunda-engine-plugin-connect</artifactId>
    </dependency>

    <dependency>
      <groupId>org.camunda.connect</groupId>
      <artifactId>camunda-connect-http-client</artifactId>
    </dependency>
```

To parse the response body, it may be helpful to include the [Spin Plugin](https://docs.camunda.org/manual/latest/reference/spin/) as well. To add Spin and JSON, add the dependencies to the POM file.

```xml
    <dependency>
      <groupId>org.camunda.bpm</groupId>
      <artifactId>camunda-engine-plugin-spin</artifactId>
    </dependency>

    <dependency>
      <groupId>org.camunda.spin</groupId>
      <artifactId>camunda-spin-dataformat-json-jackson</artifactId>
    </dependency>
```

This [project](https://github.com/rob2universe/camunda-http-connector-example) shows a simple use case for **Connectors**.

To configure the **Connector**, the **Input Parameters** must be set.

To configure a **GET** call, the method, the url, and the headers must be set:

![Output](./img/input.png)

The configuration of the **Connector** allows setting output variables:

![Output](./img/output.png)

The response code can be accessed easily with the Expression:

```
${statusCode}
```

To parse the body, we use an Expression in combination with Spin:

```
${S(response).prop(""health_percentage"")}
```

#### Create an incident

Similar to the examples above, the **Connector** should create an incident if the response code is not `200`.

:exclamation: **Important:**  
Ensure you understand [transactions](https://docs.camunda.org/manual/latest/user-guide/process-engine/transactions-in-processes/) within the Camunda workflow engine. Depending on where your last transaction in the process is, the state of the process will roll back to the last transaction, which might not be the service task where the error occurred. You can set transactions manually by using the **sync before and after** flag in the modeler.

![Async](./img/async.png)

To observe the incident at the right place in this project, the **async before** flag is set. This will also ensure the transaction isn't rolled back too far. 

The response code is defined as an output variable. To check the value of the variable, the project uses [Script](https://docs.camunda.org/manual/latest/user-guide/process-engine/scripting/). Script can be used at various places. For example, Script can be used directly by defining the output variable of a **Connector**. This example uses Script as an [Execution Listener](https://docs.camunda.org/manual/latest/user-guide/process-engine/scripting/#use-scripts-as-execution-listeners) at the end of the **Connector**.

![ExecutionListenerForResponseCode](./img/ExecutionListener1.png)

If the response code does not equal `200`, the Script throws an error. As the error is not handled, this leads to an incident within the workflow engine.

:bangbang: **cases to consider:**  
In this project, the incident will be created before. If the response is not `200`, the response body will look different. Therefore, the Expression we use to store the health percentage ```${S(response).prop(""health_percentage"")}``` fails. The accompanying incident message won't give details about the failed REST call. Rather, it shares that the evaluation of the expression has failed. This outlines one of the challenges working with **Connectors**. If the evaluation of the response code and the different variables is handled within the same code, it is easier to maintain the outcome and the logic.


#### Throw a BPMN error

The example uses the gained information about the health percentage. An **Execution Listener** at the end of the connector is used to evaluate the value of the variable.

```javascript
health = execution.getVariable(""healthPercentage"");

if(health < 70){

execution.setVariable(""healthPercentage"", health);
throw new org.camunda.bpm.engine.delegate.BpmnError(""error-not-healthy"");

}else{
execution.setVariable(""healthPercentage"",health);
}
```

#### Complete the task

With a **Connector**, the task completes after calling the REST endpoint.

#### Logging Connectors

To get more output about the traffic with the called service, you can use these logging configuration in the `application.yaml` file:

```yaml
logging:
  level:
    '[org.camunda.bpm.connect]': DEBUG
    '[org.apache.http.headers]': DEBUG
    '[org.apache.http.wire]': DEBUG
    '[connectjar.org.apache.http.headers]': DEBUG
    '[connectjar.org.apache.http.wire]': DEBUG 
```

The levels are preconfigured to `INFO` in the `application.yaml` of this project.


### Script Task

Scripting can be used in a variety of places within the process, including dedicated script tasks. In some distributions of Camunda the groovy engine is already included. For spring boot it needs to be added as a dependency.

```XML
    <dependency>
      <groupId>org.codehaus.groovy</groupId>
      <artifactId>groovy-all</artifactId>
      <version>3.0.8</version>
      <type>pom</type>
    </dependency>
```

JavaScript is part of the Java Runtime (SRE) until version 15. The Nashorn JavaScript Engine is removed in Java 15. 

To use another scripting language that is compatible with JSR-223 the respective jar file has to be added to the classpath. 

:exclamation: **Important:**  
Normally Script is not that common to make a REST call within Camunda

This example uses Groovy to make the REST call. With the Script, it is possible to get variables from the process. These variables are then used to make a REST call in the Groovy script:

```java
def repoOwner = execution.getVariable(""repoOwner"")
def repoName = execution.getVariable(""repoName"")

RESTClient client = new RESTClient(""https://api.github.com/"")
def path = ""/repos/""+ repoOwner +""/""+ repoName +""/languages""
def response

```
The script uses then the information from the response to set the variables true, if the response body contains a certain language: 
```java

    if(response.contentAsString.contains(""Java"")){
        java = true;
        programingLanguages = programingLanguages + "" Java ""
    }

```

#### Create an incident

Within the script an uncaught exception will create an incident in the engine. In this example we catch any exception from the RESTClient, print the exception to the console and then throw a new exception, which is not be caught and create the incident.

```java
catch (RESTClientException e) {
    println(e)
    throw new Exception(e)
}    
```


#### Throw a BPMN error

BPMN errors can be thrown based on the response from the REST call. The example script throws a BPMN error as soon as Scala is included in the response body:

```java
    if(response.contentAsString.contains(""Scala"")){
        scala = true;
        programingLanguages = programingLanguages + "" Scala ""

        throw new org.camunda.bpm.engine.delegate.BpmnError(""error-scala-detected"");
    }  
```

#### Complete the task

If the try block runs successfully without the execution of the if statement for scala the task will complete and the variables are set back to the process instance.

```java
   //return variables
    execution.setVariable(""programingLanguages"", programingLanguages)
    execution.setVariable(""java"", java)
    execution.setVariable(""javaScript"", javaScript)
    execution.setVariable(""python"", python)
    execution.setVariable(""ruby"", ruby)
    execution.setVariable(""closure"", closure
```
"
tringuyenhoaiphuong/DrawerOnTopActionBar,master,31,15,2014-10-04T08:28:45Z,876,2,This example demonstrates how to make NavigationDrawer on top of Actionbar.  Remember to add appcompat_v7 project to its libraries before compiling.,,"DrawerOnToActionBar
===================

This example demonstrates how to make NavigationDrawer on top of Actionbar.

Remember to add appcompat_v7 project to its libraries before compiling."
yrojha4ever/JavaStud,master,306,119,2015-09-03T04:50:23Z,1657,1,"Official, Main: This is Core/Advance java example series project. It help to learn java step by step using pdf tutorial provided here and corresponding demo project for the eclipse. Tag: Java Student, Java Stud, Stud Java, StudJava, Java Teachers, Studs Quick Start Guide, Studs Java, Object Oriented Programming, Core Java, Java SE, Java EE, Java Enterprise Edition, Java Blog, Java Articles, Java Web, JSP, Servlet, Maven, Spring, Hibernate, Spring-boot, Spring MVC Web, Angular JS, Angular 2, Java Security, Java CRUD, Java Login Example, File Handling, Multi threading, exception handling, Collection classes, Swing, Database, Date Time, Joda Time, JPA. ",angular angularjs corejava hibernate java java-enterprise-edition java-guru java-students java-tutorial java-tutorials jsp maven object-oriented-programming servlet spring spring-boot stud-java stud-projects student swing,"# JavaStud
This is java tutorial example series. Visit http://yro-tech.blogspot.com/ blog for more resources.

[1.Introduction:](https://drive.google.com/open?id=0B3_WIs_SGCRzbDdKbTVoZHZUMGs)<br/>
[2.OOP:](https://drive.google.com/open?id=0B3_WIs_SGCRzZHk2MmNsVkxqa1U)<br/>
[3.Exception Handling,Inner Class, Date Time, Joda time, Reflection:](https://drive.google.com/open?id=0B3_WIs_SGCRzdkk1WGpGSGxMdU0)<br/>
[4.Multithreading, IO, Serialization:](https://drive.google.com/open?id=0B3_WIs_SGCRzTl9GbFZSdmZabE0)<br/>
[5.Collections, Java Generics:](https://drive.google.com/open?id=0B3_WIs_SGCRzVDg0MV9qQmVjajQ)<br/>
[6. JDBC ](https://drive.google.com/open?id=0B3_WIs_SGCRzU1Z2NUhaSkdXUE0)<br/>
[7. Swing ](https://drive.google.com/open?id=0B3_WIs_SGCRzRFVEdzV3ekNNMWM)    &nbsp;&nbsp;&nbsp;[(Project here..)](https://github.com/yrojha4ever/StudManagProj)<br/>
[8. Java EE/Servlet](https://drive.google.com/open?id=0B3_WIs_SGCRzcG1rQVRabTJSVG8) &nbsp;&nbsp;/&nbsp; [JSP](https://drive.google.com/open?id=0B3_WIs_SGCRzRnIySktZZTlsT2M) &nbsp;&nbsp;:wavy_dash:[Web Project(Jsp/Servlet)](https://github.com/yrojha4ever/JavaStudWeb)<br/>
[10. Maven ](https://drive.google.com/open?id=0B3_WIs_SGCRzaHpnR0VvdkNlVWc)<br/>
[11. Hibernate ](https://drive.google.com/open?id=0B3_WIs_SGCRzRnlsYkhLTW1QTlk) &nbsp;&nbsp;&nbsp;[(Hibernate Project Here...)](https://github.com/yrojha4ever/JavaStudHibernate)<br/>
[11. Spring AOP `Dependency Injection` Project..](https://github.com/yrojha4ever/JavaStudSpringDI)<br/>
[12. Spring Web:](https://drive.google.com/open?id=0B3_WIs_SGCRzMExNRlFJN24yT3c) &nbsp;&nbsp;&nbsp;[(Spring Web Mvc/Hibernate Project...)](https://github.com/yrojha4ever/JavaStudSpringMVCWeb) &nbsp;&nbsp;&nbsp;Spring boot version: [springmvcweb-boot](https://github.com/yrojha4ever/springmvcweb-boot)<br/>

### Some Extra course along with Spring MVC WEB!  
12.1 [Angular JS APP](https://github.com/yrojha4ever/angularapp)<br/>
12.2 [Design Pattern]
```
Factory Pattern
Singleton Pattern
MVC Pattern
Builder Pattern
Decorator Pattern
```

12.3 [Java - 8]
```
Lambda Expressions
Default methods
Functional interfaces
Streams
Filters
Date-Time Package
```

12.4 [JUnit]
```
Assertions
assertThat
Execution order
@Test
@BeforeClass
@AfterClass
@Before
@After
```

## :coffee: NEXT :fast_forward: [Industrial Java Development With Advance Web(Training)](IndustrialJava.MD) :coffee:

## If this repository helps you in anyway, show your love :heart: by putting a :star: on this project :v:
```
---------------------------------------------
Assignment 1: http://www.ctae.ac.in/images/editorFiles/file/Lab%20Solutions%20of%20CSE_IT/java.pdf
1. Write a program to find sum and average of N number using command line argument.
2. Write a program to find sum and average of N number input by User(using Scanner class).
3. Write a program to Demonstrate type casting of all type of data type in java.
4. Write a program to Demonstrate boxing/un-boxing of all types of data type in java.
5. Write a program to test prime number.
6. Write a program to calculate Simple Interest input by user. Simple Intrest = P*T*R/100
7. Write a program to display following string in the console:

<!DOCTYPE html>
<html lang=""en-US"">
<script src=""http://ajax.googleapis.com/ajax/libs/angularjs/1.3.14/angular.min.js""></script>
<body>

<div ng-app="""">
 	<p>Name : <input type=""text"" ng-model=""name""></p>
 	<h1>Hello '{{name}}'</h1>
</div>

</body>
</html>
---------------------------------------------
```

```
Assignment 2: Src: http://www.scribd.com/doc/68627280/Java-Lab-Test-Final-Questions#scribd
1.Write a program with different methods to convert Fahrenheit to Celsius andCelsius to Fahrenheit.
2.Write a program to take input from the user and calculate sales-tax.
3.Write a program to take input from the user and calculate interest rate (10%) for giving loan.
4.Write a program that reads in the radius and length of a cylinder and computesvolume.
5.Write a program that converts pounds into kg. The program prompts the user toenter a number of pounds, converts it to kg and displays the result [ 1 pound is0.454 kg].
6.Write a program that reads an integer 0 to 1000 and adds all the digits in integer.[For example: 911 (input) -> 11 (result)].
7.Write a program that converts lowercase letter to uppercase letter. [hint: int offset= ‘a’ – ‘A’; char uppercase = (char) (lowercase-offse) ]
8.Write a program that receives an ASCII code (int between 0 – 128) and display itscharacter [example : 97 (input) -> A(output)].
9.Write a program that reads following information -> Employee’s name, number of hours worked in week, hourly pay rate, tax (20%) with-holding from user and prints a payroll statement with employee’s details.
10.Write a program that reads in investment amount, annual interest rate and number of years. Display the future investment value of the person.
11.Write a program that calculates the energy needed to heat water from an initialtemperature to final temperature. Your program should prompt the user to enter the amount of water in kg and initial and final temperature of water.
12.Write a program that displays the following table (5 IN ROW):

a b pow(a,b)     a b pow(a,b)
---------------------------------------------------------------
1 2 1            6 7   ______ 
2 3 8            7 8   ______
3 4 81           8 9   ______ 
4 5              9 10  ______
5 6              10 11 ______

13.Write a program to calculate leap year.
14.Write a program that reads an integer and checks whether it is even, odd or primenumber, print the same as output.
15.Write a program which sorts given numbers, which is provided by user.
16.Write a program to display multiplication table for the given number by user.
17.Write a program to calculate GCD and LCM of the given input from user indifferent methods. 
18.Write a program that prompts the user to enter the number of students and eachstudent’s name and score. Finally display the student with highest score.
19.Write a program that displays all number from 100 to 1000, ten per line that aredivisible by 5 and 6.
20.Use a while loop to find the smallest integer ‘n’ such that n square (n2) is greater than 12000.
21.Write a program that display all leap years, ten per line, in the twenty first centure(2001 to 2100).
22.Write a program that prompts the user to enter a decimal integer and display itscorresponding binary value. Use built-in class and without built-in class.
23.Write a program to display an integer in reverse order [ example : 1345 (input) ->5431 (output)].
24.Write a program that prompts the user to enter a decimal integer and display itscorresponding hexadecimal value.
25.Write a program to find if the given input is palindrome or not. Also includedifferent method to see if number is prime or not.
26.Write a program which reads the score, then finds best score and finally assignsgrades to the students and prints the students details in order. (use array)
27. Write a program to count number letters in given array, with built-in function andwithout built-in functions.
28.Write a program which prompts for set of elements and search given key element.
29.Write a program to sort given array elements using insertion sort.
30.Write a program that reads eleven number from user, computes their average, andfinds out how many numbers are below average and displays duplicate numbers.
31.Write two overloaded methods that return the average of an array with followingheaders: public static int averate(int[] array); and public static doubleaverage(double[] array).
32.Write a program which reads two matrices (2 D) and adds two matrices anddisplays the output on screen.
33.Write a program with different methods to do these array operations -> sort anarray and search an element inside it, determine the upper bound of 2D array.
34.Write a program with different methods to do these array operations -> sort anarray and insert an element inside it, determine the upper bound of 2D array.
35.Write a program with different methods to do these array operations -> reverse anarray, search mini and the maxi element in an array.
36.Write a program with different methods to do these array operations -> comparetwo arrays and display if it is equal or not.
37.Write a program to use methods for calculating Fibonacci series using recursion.
38.Write a program to use recursion for calculating factorial of a number.
39.Write a program to demonstrate various arithmetic and assignment operations,right shift and left shift.
40.Write a program to accept string in command line and print the same, also counthow many characters are in the given string.
41.Write a program to demonstrate various relational and logical operations.
42.Write a program using different methods to demonstrate conditional operator anddo type conversions from -> double to float, short to int, double to int, chat to int,int to short.
43.Write a program using different methods with different control flow controls (for,switch, while) to check whether an alphabet is a vowel or not.
44. Write an exception which catches if the value is very small(eg:<.01)
45. WAP which catches different exceptions 1.divide by 0, 2.Array boundindex error 3.Wrong datatype.
46. WAP to catch wrong input frm command line argument.
47. A simple applet to display a msg:HELLO WORLD on applet window.
48. Do d above pgm by passing parameters and align d msg.
49. Your own exception -> if number is two small, (declare variables as float, do anyarithmetic operationsif the output is less than 0.01 then call and exception).
50. Write a java program which catches exception for divide by zero and array indexerror and wrong data type.
51. Write a java program to catch wrong input from command line, ( declare int variable but input of different type).
52. Display ""Hello World "" on applet window53. Pass parameters and display string on applet screen.
54.Align the output ""Helloworld"" to rightmost corner, below, middle, leftmost corner,anywhere on the applet screen.
55. Write a program to calculate the value of X= sin x+cosx+tanx using multiple threads.
56. Define a thread using thread class to generate the factorials of first 20 naturalnumbers. create an instance for this thread and then activate it.
57. Write a program to generate the square roots of the first 30 natural numbers usingRunnable Interface.
58. Define a thread to display the odd numbered element in an array of size 50.define another thread to display even numbered element in another array of size 50.Create instances of the above threads and run them.
59. Write a program that executes three threads. first thread displays Good morning everyone second.second thread displays hello every two seconds and the third thread displays welcome inevery three seconds.create the three threads by extending the thread class.
```

### Java soft installation

```
32 bit/64 bit:
1. Install JDK 1.8
2. Install 7zip software
3. spring-tool-suite:
	>create C:\java-ws folder
	> copy zip file ""spring-tool-suite-3.8.1"" into C:\java-ws folder
	> extract it there using 7zip
	
	To run spring-tool-suite:
	> go to sts-bundle>sts-3.8.1.RELEASE>STS.exe
	> it will promt select workspace dialog?
	  #give path of your workspace: C:\java-ws
	  #tick checkbox (default)
	  #OK	
 ```
 
 ### Install Maven in Mac/Linux: 
`/usr/bin/ruby -e ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)""`

Alternatively, I recommend installing Homebrew for these kinds of utilities.

Then you just install Maven using:
`brew install maven` <br/>
PS: If you got a 404 error, try doing a brew update just before

*Install Maven in Linux Ubuntu:*
`sudo apt-get install maven`
 
 ### How to install lombok in mac:
 
 ```
 Rename the file ""STS.EXE"" to ""sts.exe"" under ../sts-bundle/sts.app/Contents/MacOS/. 
And then run java -jar lomobok.jar and select the STS.ini file under ../sts-bundle/sts.app/Contents/Eclipse
```

[Assignments: ] (https://github.com/yrojha4ever/JavaStud/blob/master/Assignments.MD) <br/>
Some good Links: <br/>
[Designing Patterens for Human] (https://github.com/kamranahmedse/design-patterns-for-humans)
[Java Exercism] (http://exercism.io/languages/java/about)
[How to Conduct Good Programming Interview] (http://www.lihaoyi.com/post/HowtoconductagoodProgrammingInterview.html)
"
MinecraftU/copper-mod,master,30,2,2014-08-21T15:17:24Z,29062,0,Minecraft mod intended as an example for teaching,,
kevinthecity/DialerAnimation,master,44,1,2015-04-10T13:19:28Z,183,0,Two different examples of how one could architect the Lollipop Dialer Animation,,"# DialerAnimation
Two different examples of how one could architect the Lollipop Dialer Animation

Deep link to the java source - https://github.com/kevinthecity/DialerAnimation/tree/master/app/src/main/java/com/tumblr/myapplication
"
gabrieldim/Resource-Description-Framework,main,28,1,2021-11-02T22:17:58Z,114,0,Resource Description Framework aka RDF examples written in Java,java pretty-rdf-xml rdf turtle xml,"# Resource Description Framework also known as RDF
Used syntaxes for developing this repository:
- RDF/XML
- N-TRIPLES
- TURTLE
- pretty RDF/XML
"
tunjos/RxJava2-RxMarbles-Samples,master,29,3,2017-07-12T20:00:19Z,3306,0,RxJava 2 RxMarbles Samples,example examples java learning-rxjava rxjava rxjava2 sample samples tutorial tutorials,"RxJava 2 RxMarbles Samples
==============

This repository contains RxJava 2 implementations of the sample operators found in the [RxMarbles Android Application](https://play.google.com/store/apps/details?id=com.moonfleet.rxmarbles). Please download the app for a more interactive tutorial.

### Running

Simply import the project using intelliJ IDEA and run the corresponding run configurations.

### Awesome Links
[RxMarbles Android Application](https://play.google.com/store/apps/details?id=com.moonfleet.rxmarbles)  
[ReactiveX](http://reactivex.io/)  
[ReactiveX Operators](http://reactivex.io/documentation/operators.html)  
[RxMarbles](http://rxmarbles.com/)  
[RxJava Wiki](https://github.com/ReactiveX/RxJava/wiki)  

### Dependencies
[RxJava2](https://github.com/ReactiveX/RxJava)  
[RxJava2Extensions](https://github.com/akarnokd/RxJava2Extensions)

## [Transforming](https://github.com/tunjos/RxJava2-RxMarbles-Samples/blob/master/Transforming/src/Main.java)

<img src=""Transforming/operators/map.png"" width=""250""> <img src=""Transforming/operators/flatMap.png"" width=""250""> <img src=""Transforming/operators/buffer.png"" width=""250""> <img src=""Transforming/operators/groupBy.png"" width=""250""> <img src=""Transforming/operators/scan.png"" width=""250"">

## [Filtering](https://github.com/tunjos/RxJava2-RxMarbles-Samples/blob/master/Filtering/src/Main.java)

<img src=""Filtering/operators/debounce.png"" width=""250""> <img src=""Filtering/operators/distinct.png"" width=""250""> <img src=""Filtering/operators/distinctUntilChanged.png"" width=""250""> <img src=""Filtering/operators/elementAt.png"" width=""250""> <img src=""Filtering/operators/filter.png"" width=""250""> <img src=""Filtering/operators/first.png"" width=""250""> <img src=""Filtering/operators/last.png"" width=""250""> <img src=""Filtering/operators/skip.png"" width=""250""> <img src=""Filtering/operators/skipLast.png"" width=""250""> <img src=""Filtering/operators/take.png"" width=""250""> <img src=""Filtering/operators/takeLast.png"" width=""250""> <img src=""Filtering/operators/ignoreElements.png"" width=""250"">

## [Combining](https://github.com/tunjos/RxJava2-RxMarbles-Samples/blob/master/Combining/src/Main.java)

<img src=""Combining/operators/startWith.png"" width=""250""> <img src=""Combining/operators/amb.png"" width=""250""> <img src=""Combining/operators/combineLatest.png"" width=""250""> <img src=""Combining/operators/concat.png"" width=""250""> <img src=""Combining/operators/merge.png"" width=""250""> <img src=""Combining/operators/sequenceEqual.png"" width=""250""> <img src=""Combining/operators/zip.png"" width=""250"">

## [Error Handling](https://github.com/tunjos/RxJava2-RxMarbles-Samples/blob/master/ErrorHandling/src/Main.java)

<img src=""ErrorHandling/operators/onErrorReturn.png"" width=""250""> <img src=""ErrorHandling/operators/onErrorResumeNext.png"" width=""250"">

## [Conditional](https://github.com/tunjos/RxJava2-RxMarbles-Samples/blob/master/Conditional/src/Main.java)

<img src=""Conditional/operators/all.png"" width=""250""> <img src=""Conditional/operators/contains.png"" width=""250""> <img src=""Conditional/operators/skipWhile.png"" width=""250""> <img src=""Conditional/operators/skipUntil.png"" width=""250""> <img src=""Conditional/operators/takeWhile.png"" width=""250""> <img src=""Conditional/operators/takeUntil.png"" width=""250"">

## [Math](https://github.com/tunjos/RxJava2-RxMarbles-Samples/blob/master/Math/src/Main.java)

<img src=""Math/operators/average.png"" width=""250""> <img src=""Math/operators/sum.png"" width=""250""> <img src=""Math/operators/reduce.png"" width=""250""> <img src=""Math/operators/count.png"" width=""250"">

NB
--------

All screenshots taken directly from the [RxMarbles Android Application](https://play.google.com/store/apps/details?id=com.moonfleet.rxmarbles).

License
--------

  Copyright 2017 Tunji Olu-Taiwo

  Licensed under the Apache License, Version 2.0 (the ""License"");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an ""AS IS"" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
"
UrsZeidler/shr5rcp,development,49,9,2014-01-17T14:47:08Z,183460,30,The shadowrun 5 rich client platfrom is a model driven project for managing shadowrun resources. A shadowrun 5 character generator for example ...,character-generator emf java rcp shadowrun,"shr5rcp
=====================
![logo](de.urszeidler.shr5.product/icons/shrImage_6_128.png)

1. Overview

 This is a program to manage resources and characters for the rolegame shadowrun 5.0.
 It is dedicated to create and manage characters, providing game master aid and reporting.

Refer to [releases](https://github.com/UrsZeidler/shr5rcp/releases) to download the software.

For now it contains :
* several character generators
  * [shadowrun 5 character generator aka priority system](https://github.com/UrsZeidler/shr5rcp/wiki/shr5-core-rule-generator) after the core rule book
  * [karma based- aka buy points](https://github.com/UrsZeidler/shr5rcp/wiki/karma-generator) character generator
  * [sum to ten]()
  * [life module system](https://github.com/UrsZeidler/shr5rcp/wiki/lifemodule-generator) 
  * [freestyle](https://github.com/UrsZeidler/shr5rcp/wiki/freestyle)
* [a runtime](https://github.com/UrsZeidler/shr5rcp/wiki/script-runtime) a script and combat view let you use all stuff, making tests, manages combat turns etc. the players can now collaborate by impersonating their character instances, check out the [web-app](https://github.com/UrsZeidler/shr5rcp/wiki/script-webapp).
* [editors](https://github.com/UrsZeidler/shr5rcp/wiki/editing) for the resources objects and [wizards](https://github.com/UrsZeidler/shr5rcp/wiki/createItemWizard) to create new ones
* a simple character sheet
* [grunt editor](https://github.com/UrsZeidler/shr5rcp/wiki/generators#grunts) and sheet
* various [sheets](https://github.com/UrsZeidler/shr5rcp/wiki/m2t) for player and game master

A small german instruction : [kurz übersicht](https://github.com/UrsZeidler/shr5rcp/wiki/kurz-%C3%BCbersicht)

see the upcoming and past changes : [changelog](https://github.com/UrsZeidler/shr5rcp/wiki/release-notes)

|using the application | player |  runtime and game master|
| --- | --- | ---|
|<ul><li>[starting](https://github.com/UrsZeidler/shr5rcp/wiki/Installation-and-starting)</li><li>[Using the application](https://github.com/UrsZeidler/shr5rcp/wiki/Using%20the%20application)</li><li>[editors](https://github.com/UrsZeidler/shr5rcp/wiki/editing)</li><li>[generator wizard](https://github.com/UrsZeidler/shr5rcp/wiki/characterbuilding-perspective#character-generator-wizard)</li><li>[importing exporting.](https://github.com/UrsZeidler/shr5rcp/wiki/importing-exporting) </li><li>[source book view](https://github.com/UrsZeidler/shr5rcp/wiki/sourceBookView) </li><li>[update-site](https://github.com/UrsZeidler/shr5rcp/wiki/update-site) </li></ul>	  |    <ul><li>[character generators](https://github.com/UrsZeidler/shr5rcp/wiki/generators)</li><li>[character building](https://github.com/UrsZeidler/shr5rcp/wiki/characterbuilding-perspective)</li><li> [character diary](https://github.com/UrsZeidler/shr5rcp/wiki/character-diary)</li><li> [manage money](https://github.com/UrsZeidler/shr5rcp/wiki/CredstickTransactions)</li><li> [web app player](https://github.com/UrsZeidler/shr5rcp/wiki/script-webapp-player)</li></ul>	  |     <ul><li>[script editing](https://github.com/UrsZeidler/shr5rcp/wiki/script-editing)</li><li>[runtime](https://github.com/UrsZeidler/shr5rcp/wiki/script-runtime)</li><li>[web app](https://github.com/UrsZeidler/shr5rcp/wiki/script-webapp)</li><li>[quick combat](https://github.com/UrsZeidler/shr5rcp/wiki/script-quick-combat)</li></ul>  |
or the [FAQ](https://github.com/UrsZeidler/shr5rcp/wiki/faq)
 
 [![Build Status](https://buildhive.cloudbees.com/job/UrsZeidler/job/shr5rcp/badge/icon)](https://buildhive.cloudbees.com/job/UrsZeidler/job/shr5rcp/)
 
[![simple instruction](http://img.youtube.com/vi/wQCnu3sj0RA/0.jpg)](http://www.youtube.com/watch?v=wQCnu3sj0RA)
 
[![create a grunt group instruction](http://img.youtube.com/vi/Q0AX250K9CE/0.jpg)](http://www.youtube.com/watch?v=Q0AX250K9CE)

 
2. Motivation
  
 As I used to play shadowrun for a very long time, I started with an editor in Delphi for shadowrun 2.0, 
 many year later I started a technology study with emf for the 3.01 version, as my group has now moved
 to 5.0 and the chummer project don't work well on linux I have moved some of the model to 5.0. This is
 a kind of technology study, working with an model driven approach.
 
 Find out more in the [wiki](https://github.com/UrsZeidler/shr5rcp/wiki).
 
 and checkout the [constribute](https://github.com/UrsZeidler/shr5rcp/wiki/Building%20and%20development#contributing)
 section
 
 If you are not part of the github community you could use other channels to contact:
 
 * diaspora: [shr5rcp@pod.geraspora.de](https://pod.geraspora.de/people/94e9fef074180132e8774860008dbc6c), a Community-run, Distributed [Social-network](https://joindiaspora.com/)
 * email: shr5rcp@urszeidler.de 
 * twitter: [@shr5rcp](https://twitter.com/shr5rcp)
 
another way to support is via bitcoin:
 
 * **12Fgh416ogMiJsYnXyeYqaEGyEQHcVFSsJ** for main support like webspace and service
 * **1B9nJ2eXZJz1UKaVQTeMHriD1LBQsd4CvS** for arts and graphics
 * **18BbgDaurToEu6sou5dmBzNUNWAhTH25Tg** for localization and spell checking
 * **1JcJK1nLkAZkr4jid6N44L2bYQ7rxPSVYZ** tip the coder
  
as we could use the bitcoin to pay some people to make the tedious spell checking jobs, pay webspace or services or pay for some artwork. 
 
3. Installation

 As the software is an eclipse product so you need to unpack the software and start the exe, you will need java installed.
 
 * [Installation and starting](https://github.com/UrsZeidler/shr5rcp/wiki/Installation-and-starting)
 * [faq](https://github.com/UrsZeidler/shr5rcp/wiki/faq)
 
 
4. Technical stuff

 This project is based on the EMF modeling framework the EMF Client Platform and EMF Forms.
 
 [development](https://github.com/UrsZeidler/shr5rcp/wiki/Building-and-development)
 
 
 License
-------

The code is published under the terms of the [Eclipse Public License, version 1.0](http://www.eclipse.org/legal/epl-v10.html).
 
 
<a href=""http://with-eclipse.github.io/"" target=""_blank"">
<img alt=""with-Eclipse logo"" src=""http://with-eclipse.github.io/with-eclipse-0.jpg"" /></a>
"
jwboardman/whirlpool,master,34,12,2016-05-23T03:34:33Z,1995,0,Example Microservices using Kafka 3.3.1 and WebSockets with Netty 5.0.0-alpha2 with both React/Typescript and HTML/JavaScript UIs,,"# TL;DR
- clone repo
- `./maclocal_run.sh` or `./linuxlocal_run.sh` or `wsllocal_run.sh`
- when that finishes
- `cd src/main/ui`
- `yarn start`

# Recommended Development Setup
- Mac OSX, Ubuntu 20.04, or Windows WSL Ubuntu
- JDK 8
- Maven 3

## Notes
- I'm using Java 8, Maven 3.8.6, Kafka 3.3.1, and Netty 5.0.0-alpha2. The script will auto-install (and remove!) Zk/Kafka version 3.0.0, so if you have an existing installation, save it or don't use the script!
- localhost is used to bypass Kafka 3.3.1's desire to look up your external hostname
- No database or security has been included because this is an example.
- Use any username you like, and the password doesn't matter. Note that logging in multiple times with the same username is not allowed due to the simplistic ""session"" support with no true users or security present.
It would not take a lot of work to add true sessions and allow multiple logins using the same username, with updates for a user sent to all the websockets that the user currently has open.
Logging in with unique usernames on multiple browsers or tabs is not only allowed, it is coded for (users each have their own subscriptions) and encouraged.

## Prerequisites
- MacOS make sure you have JAVA_HOME set
- Linux use set-alternatives to make Java 8 the default
- make sure your default Java is version 8. There was only so much time I had, so updating the code to a more recent Java version just wasn't going to happen

## Help installing Maven for Linux
- `sudo apt install maven`. Note that this will also install OpenJDK 11.

## Help installing Java for Linux
- `sudo apt install openjdk-8-jdk`
- `sudo update-alternatives --config java`. This works nicely on WSL. For my Ubuntu VM I had to use
- `sudo apt-get install galternatives`

## Install/Build/Start Zookeeper, Kafka, Services, and Server
- For this script, do NOT click out of your terminal window until the WhirlpoolServer tab starts. Otherwise the script will act like it worked, but will actually fail.
- Run `./maclocal_run.sh` (or `sudo ./linuxlocal_run.sh` or `sudo ./wsllocal_run.sh`)
- `NOTE`: This will `REMOVE ANY EXISTING KAFKA INSTALLATION` located at /Applications/kafka and /Applications/kafka_2.13-3.0.0 (or /opt/kafka and /opt/kafka_2.13-3.0.0 for linux)
along with `ALL` data in /tmp/zookeeper and /tmp/kafka-logs!
- This will download (if it isn't already) version 3.0.0 of Kafka (with Scala 2.13) that includes Zookeeper, install them, and configure them, and starts them. It will then kick off the maven build that compiles
and builds runnable deployed targets. Finally, it starts the services, and finally the server.

## Stop
- This script shuts down everything and closes all except the left most tab.
- Run `./maclocal_kill.sh` (or `sudo ./linuxlocal_kill.sh` or `sudo ./wsllocal_kill.sh`)
- This will kill the services and server, then shut down Kafka, then shutdown Zookeeper. `NOTE`: It will also `REMOVE` the Kafka logs and Zookeeper data in /tmp/zookeeper and /tmp/kafka-logs!!!

## About the React UI
Here's a screenshot:
![Whirlpool Screen Shot](https://github.com/jwboardman/whirlpool/blob/master/whirlpool_react_ui.png?raw=true ""Whirlpool"")

To get the React site running:
- from the root whirlpool directory, `cd src/main/ui`
- if you don't have Node installed, use nvm to easily control Node versions
  - Mac
    - install Homebrew `ruby -e ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)""`
    - install nvm `brew install nvm`
  - Linux
    - `curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash`
    - expect to see some errors, but they don't keep it from working
    - restart terminal

- install Node `nvm install 16.17.0`
- install yarn `npm install --global yarn`
- install node modules `yarn install`
- start dev server `yarn start`

## React UI usage
- To add a stock symbol, click anywhere on the ""Stocks +"" header, enter the ticker symbol (i.e. ""GOOG"") and click the Add button. The reason you can click on the text or the + is for accessibility - the + by itself is really too small of a target. To remove it, click the trash can icon next to the stock.
- To add a website to test whether it is up or down, click anywhere on the ""Up Down +"" header, type in the fully-qualified URL (i.e. http://facebook.com) and click the Add button. To remove it, click the trash can icon next to the URL.
- To add a weather check, click anywhere on the ""Weather +"" header, type the zip code (i.e. ""10001"") and click the Add button. To remove it, click the trash can icon next to the weather.

## NOTE
- Be patient after adding a new subscription. I set the timers at 30 seconds so I'm not hitting any sites too often. If you're really impatient, you can refresh the page after adding a subscription, which will end the WebSocket, use the cookie to re-login, then cause an out-of-band refresh command to be sent, which should get the data fairly quickly.

- Subscriptions survive page refresh (with the same userid) because they are stored with each service in memory. A ""real"" system would of course use a database. Logging out cleans up all subscriptions for a user. A cookie is set upon login so reloading the page automatically logs you back in. The cookie is expired upon logout.

## About the old Vanilla JS UI
The previous UI still works. Here's a screenshot:
![Whirlpool Screen Shot](https://github.com/jwboardman/whirlpool/blob/master/whirlpool.png?raw=true ""Whirlpool"")

- To add a stock symbol, type it in (i.e. ""GOOG"") and click the A button under ""Stock"". To remove it, click the X.
- To add a website to test whether it is up or down, type in the fully-qualified URL (i.e. http://facebook.com) and click the A button under ""UpDown"". To remove it, click the X.
- To add a weather check, type the city,state in (i.e. ""chicago,il"") and click the A button under ""City,State"". To remove it, click the X.

## Ports/Logs
- http://localhost:3000/ - the React app
- http://localhost:8080/ - the old vanilla JS UI
"
vitrivr/cineast,main,55,50,2016-01-29T17:03:10Z,20127,21,"Cineast is a multi-feature content-based mulitmedia retrieval engine. It is capable of retrieving images, audio- and video sequences as well as 3d models based on edge or color sketches, textual descriptions and example objects.",3d audio images java oas retrieval video,"[![vitrivr - cineast](https://img.shields.io/static/v1?label=vitrivr&message=cineast&color=blue&logo=github)](https://github.com/vitrivr/cineast)
[![GitHub release](https://img.shields.io/github/release/vitrivr/cineast?include_prereleases=&sort=semver&color=2ea44f)](https://github.com/vitrivr/cineast/releases/)
[![License](https://img.shields.io/badge/License-MIT-blueviolet)](LICENSE)
[![swagger-editor](https://img.shields.io/badge/open--API-in--editor-green.svg?style=flat&label=Open-Api%20(Release))](https://editor.swagger.io/?url=https://raw.githubusercontent.com/vitrivr/cineast/master/docs/openapi.json)
[![swagger-editor](https://img.shields.io/badge/open--API-in--editor-green.svg?style=flat&label=Open-Api%20(Dev))](https://editor.swagger.io/?url=https://raw.githubusercontent.com/vitrivr/cineast/dev/docs/openapi.json)
[![Java CI with Gradle](https://github.com/vitrivr/cineast/workflows/Java%20CI%20with%20Gradle/badge.svg)](https://github.com/vitrivr/cineast/actions?query=workflow:""Java+CI+with+Gradle"")

# Cineast
Cineast is a multi-feature content-based multimedia retrieval engine. It is capable of retrieving images, audio- and video sequences as well as 3d models based on edge or color sketches, sketch-based motion queries and example objects.
Cineast is written in Java and uses [CottontailDB](https://github.com/vitrivr/cottontaildb) as a storage backend.

## Building Cineast
Cineast can be built using [Gradle](https://gradle.org/). It needs Java 17+. Building and running it is as easy as
```
git clone https://github.com/vitrivr/cineast.git
cd cineast
./gradlew getExternalFiles cineast-runtime:shadowJar
java -jar cineast-runtime/build/libs/cineast-runtime-x.x-all.jar cineast.json
 ```

For more setup information, consult our [Wiki](https://github.com/vitrivr/cineast/wiki)

## Docker image

There is a Docker image available [on Docker
Hub](https://hub.docker.com/r/vitrivr/cineast).

You can run the CLI with:
```
docker run vitrivr/cineast cli cineast.json help
```

To change the configuration you can use a bind mount, e.g. to run the API
server with custom configuration file cineast.json in the current directory:
```
docker run -v ""$PWD""/cineast.json:/opt/cineast/cineast.json:ro,Z vitrivr/cineast api cineast.json
```

## Generate OpenApi Specification

If you need to rebuild the OpenApi Specification (OAS), there is a gradle task for this purpose:

```
./gradlew -PcineastConfig=<path/to/your/config> generateOpenApiSpecs
```

You can omit `-PcineastConfig`, then the default config (`cineast.json`) is used.
The generated OAS is stored at `docs/openapi.json`


## Prerequisites
### System dependencies
* git
* JDK 17 or higher

### 3D rendering
For 3D rendering (required in order to support 3D models) you either need a video card or Mesa 3D. The JOGL library supports both. Rendering on Headless devices has been successfully tested with Xvfb. The following steps are required to enable
3D rendering support on a headless device without video card (Ubuntu 16.04.1 LTS)

1. Install Mesa 3D (should come pre-installed on Ubuntu). Check with `dpkg -l | grep mesa`
2. Install Xvfb:

 ```
 $> sudo apt-get install xvfb
 ```
 
3. Start a new screen:

 ```
 $> sudo Xvfb :1 -ac -screen 0 1024x768x24 &
 ```
 
4. Using the new screen, start Cineast:

 ```
 $> DISPLAY=:1 java -jar cineast.jar -3d
 ```
 
The -3d option will perform a 3D test. If it succeeds, cineast should generate a PNG image depicting two coloured
triangles on a black background.

### Versioning

Cineast uses [semantic versioning](https://semver.org). See [the releases page](https://github.com/vitrivr/cineast/releases).

### Code Style

Cineast primarily uses the [Google Java Styleguide](https://google.github.io/styleguide/javaguide.html).
Please use the file supplied in the `docs/` folder

To automatically apply the styleguide in [IntelliJ IDEA](https://www.jetbrains.com/idea/) go to_File_ -> _Settings_ -> _Editor_ -> _Code Style_ -> _Java_ and import the supplied file via the gear icon.

You can also use [Eclipse](https://www.eclipse.org/) for development and use Google's [styleguide for eclipse](https://github.com/google/styleguide/blob/gh-pages/eclipse-java-google-style.xml).
"
ahmontero/wifi-direct-demo,master,124,114,2012-08-02T14:58:12Z,334,6,"This project is based on the original demo from Google. The original example show us how to send an image file from the client to the group owner. With this version, I try to show how to send data between two devices (be group owner or not).",,
MrPand-21/HRMS_Backend,master,35,5,2021-05-12T11:40:03Z,177,0,This project is an example of human resources management system (HRMS) and can be used as backend,hrms human-resources-management-system java mernis postgres postgresql postgresql-database spring-boot springboot,"<div align=""center"">
  <a href=""https://github.com/MrPand-21/HRMS_Backend/graphs/contributors""><img src=""https://img.shields.io/github/contributors/MrPand-21/HRMS_Backend.svg?style=for-the-badge""></a>
  <a href=""https://github.com/MrPand-21/HRMS_Backend/network/members""><img src=""https://img.shields.io/github/forks/MrPand-21/HRMS_Backend.svg?style=for-the-badge""></a>
  <a href=""https://github.com/MrPand-21/HRMS_Backend/stargazers""><img src=""https://img.shields.io/github/stars/MrPand-21/HRMS_Backend.svg?style=for-the-badge""></a>
  <br/>
  <br/>
  <a href=""https://github.com/MrPand-21/HRMS_Backend"">
    <img src=""https://github.com/MrPand-21/MrPand-21/blob/main/HRMS.png"" height=""160"" alt=""HRMS"">
  </a>
  <h3>HRMS_Backend</h3>

  <p align=""center"">
    <a href=""#about-the-project"">About</a> •
    <a href=""#usage"">How To Use</a> •
    <a href=""#installation"">Installation</a> •
    <a href=""#credits"">Credits</a> •
    <a href=""#reference-documentation"">Related</a> •
    <a href=""https://github.com/MrPand-21/HRMS_Backend/issues"">Report Bug</a> •
    <a href=""https://github.com/MrPand-21/HRMS_Backend/issues"">Request Feature</a>
  </p>
  <h4 align=""center"">N-Layer Architecture human resource management system project builted by 
    <a href=""https://www.java.com/"" target=""_blank"">Java</a>.
  </h4>
</div>

# About the Project

[![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=java&logoColor=white)](https://www.java.com/)
[![Spring](https://img.shields.io/badge/Spring-6DB33F?style=for-the-badge&logo=spring&logoColor=white)](https://spring.io/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![forthebadge](http://forthebadge.com/images/badges/built-with-love.svg)](http://forthebadge.com)

N-Layer Architecture human resource management system project. Using this project, you can create `admins`, `job seekers`, `jobs` and `employers`.
Along with these, you can find the <a href="""">frontend</a> of this project built with react in my profile or you can use this as an api and use the `swagger-ui` interface.
## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

The things you need before installing the software.

* You should download <a href=""https://www.postgresql.org/download/""> `PostgreSQL`</a> on your device.
* You should download <a href=""https://www.oracle.com/java/technologies/sdk-downloads.html"">`Java Sdk`</a> on your device.
* Lastly, don't forget to download an ide and plugins which you can write codes.

### Installation

A step by step guide that will tell you how to get the development environment up and running:

1. Clone the repository
```bash
# Clone this repository
$ git clone https://github.com/MrPand-21/HRMS_Backend.git
# Go into the repository
$ cd HRMS_Backend
```
Open this in terminal or you can use your ide!

2. Create PostgreSQL connectinon (If don't use Postgre, execute script in yours)
```bash
# open the Postgre SQL script
$ nano `PostgreDatabaseSQL`
```
Here,  copy the SQL script from here or open it from github and copy.

Then open the Postgre's `pgAdmin4`, under Databases (Servers/Your Server/Databases/) create a database and give its name to it (Default = HRMS). Then find the CREATE Script option (double click to database). It will open a `Query Editor` to you and here, paste the SQL script we copied from `PostgreDatabaseSQL` file and execute the script. Don't forget to refresh database to see the tables.

3. Configure the Connection
   you can open the application.properties in terminal:
```bash
#open in terminal
$ nano src/main/resources/application.properties
```
or you can directly open in your code editor. Then, configure your cridentials in the application.properties file.

4. Create Mernis Connection (Optional)

**This project created in Turkey, that's why it uses Mernis System to check if the person is Turkey citizen or not. If you don't want to use it, you can delete the `mernisService` folder and delete `mernisServiceAdapter.java` and related files.**

To use the mernis service, you can use the <a href=""https://easywsdl.com/WsdlGenerator"">WSDL Generator</a>.
If you use IntellijIdea, you can follow the following instructions:

1. In the IntellijIdea interface open Plugins > Marketplace and type EasyWSDL and install the plugin (here, you may need to restart Ide).
2. Open the project again
3. Double click `mernisService` folder and press `EasyWSDL - Update web service` option and it will regenerate all files.
4. Close `mernisService`folder and go `MernisServiceAdapter.java` file in core/utilities/adapters/adapters/concretes and change imports, replace old imports with new file imports and there you are!

If you use Eclipse, you can follow the following instructions:

1. Double click `mernisService` folder and press Add > Connected Service. As url paste https://tckimlik.nvi.gov.tr/service/kpspublic.asmx and press finish button.
2. Close `mernisService`folder and go `MernisServiceAdapter.java` file in core/utilities/adapters/adapters/concretes and change imports, replace old imports with new file imports and there you are!

## Usage - Deployment - Server

Now, you can start the project in HRMSApplication.java. Since we use springboot, you may want to go to the springboot interface.

* Live: http://localhost:8080/swagger-ui.html

Once you open this link after run the application, you can use it. That's it!

# Controllers

In the swagger-ui panel, there are 10 different controllers which you can use. They are :

1. Activation Panel Controller
2. Basic Error Controller
3. City Controller
4. Employer Controller
5. Images Controller
6. Job Controller
7. Job Position Controller
8. Job Seekers Controller
9. Work Places Controller
10. Work Times Controller

Please Refer to API Documentation

[![API Documentation](https://img.shields.io/badge/Swagger-85EA2D?style=for-the-badge&logo=swagger&logoColor=black)](https://github.com/ahmet-cetinkaya/hrms-project-backend/blob/master/APIDocumentation.md)

## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**. Right now there is only one branch which is master.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


### Reference Documentation
For further reference, please consider the following sections:

* [Official Apache Maven documentation](https://maven.apache.org/guides/index.html)
* [Spring Boot Maven Plugin Reference Guide](https://docs.spring.io/spring-boot/docs/2.4.5/maven-plugin/reference/html/)
* [Create an OCI image](https://docs.spring.io/spring-boot/docs/2.4.5/maven-plugin/reference/html/#build-image)
* [Spring Boot DevTools](https://docs.spring.io/spring-boot/docs/2.4.5/reference/htmlsingle/#using-boot-devtools)
* [Spring Web](https://docs.spring.io/spring-boot/docs/2.4.5/reference/htmlsingle/#boot-features-developing-web-applications)
* [Spring Data JPA](https://docs.spring.io/spring-boot/docs/2.4.5/reference/htmlsingle/#boot-features-jpa-and-spring-data)
* [Spring Native Reference Guide](https://docs.spring.io/spring-native/docs/current/reference/htmlsingle/)
* [Spring Configuration Processor](https://docs.spring.io/spring-boot/docs/2.4.5/reference/htmlsingle/#configuration-metadata-annotation-processor)

### Guides
The following guides illustrate how to use some features concretely:

* [Building a RESTful Web Service](https://spring.io/guides/gs/rest-service/)
* [Serving Web Content with Spring MVC](https://spring.io/guides/gs/serving-web-content/)
* [Building REST services with Spring](https://spring.io/guides/tutorials/bookmarks/)
* [Accessing Data with JPA](https://spring.io/guides/gs/accessing-data-jpa/)
* [Installing and Using EasyWSDL in IntellijIdea from stratch](https://github.com/torukobyte/JavaCampHomework/tree/master/MernisServiceEkleme)

### Additional Links
These additional references should also help you:

* [Configure the Spring AOT Plugin](https://docs.spring.io/spring-native/docs/0.9.2/reference/htmlsingle/#spring-aot-maven)

### Credits

Carabelli - Engin Demiroğ
"
opensourceBIM/IfcValidator,master,25,8,2013-04-08T11:01:22Z,581,4,"Checking IFC models on the quality of the data. Implemented parts of the Dutch Rijksgebouwendienst BIM norm"" as an example.""",,"IfcValidator
==========

This is a BIMserver plugin that checks Ifc2x3tc1 models for common requirements.

> Note: This plugin needs BIMserver 1.5

The plugin generates [Extended Data](https://github.com/opensourceBIM/BIMserver/wiki/Extended-Data) according to the following [Validation Report](https://github.com/opensourceBIM/BIMserver-Repository/wiki/Validation-Report) format.

For now, this plugin only implements checks that can be done with only the IFC file, so it will not read external files for cross-checking data.

## TODO
- Implement for IFC4 as well

## Checks

A list of checks that have been identified by asking people from the building industry and reading Dutch ""norm"" documents that seem computer checkable.

| Check | Implemented | Part of |
| ------------- | ------------- | ----- | ------ | 
| Exactly 1 IfcProject | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| IfcProject has at least one representation where the TrueNorth attribute has been set | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| IfcProject has a length unit set | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Length unit is either in Meters or Millimeters | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| IfcProject has an area unit | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Area unit is in m2 | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| IfcProject has a volume unit | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Volume unit is in m3 | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Exactly 1 IfcSite | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm1.1 |
| [Dutch]Kadastrale aanduidingen | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 2.2.7.2 |
| IfcSite has lattitude | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| IfcSite has longitude | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| IfcSite has elevation | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Has at least one IfcBuilding | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Has at least one IfcBuildingStorey | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 2.2.7.4 |
| Building storeys naming according to RVB_BIM_Norm | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| [link]Building storeys with increasing numbers have increased center | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| All objects must be hierarchically structured to be in a building storey | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/accept.png) | RVB_BIM_Norm 1.1 |
| Use a special ""cube"" to identify the origin of the model | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/exclamation.png) | |
| [Check whether the right Ifc entitities have been used based on geometric ratios](#geometric-ratios) | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/exclamation.png) | |
| No use of IfcProxy | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/exclamation.png) | 
| Every object should have some kind of identification | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/exclamation.png) |
| No 2 objects can be modelled the same, be at the same place or represent the same thing | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/exclamation.png) |
| Clash detection | ![](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/exclamation.png) |

## Further explanations

### Geometric ratios

This check uses the geometry of an object to check whether the right IFC type has been used. For example, IfcSlab objects are usually flat surfaces that ware much wider then they are high. Columns are usually slender compared to their length etc...

To be able to do these kind of comparisons it would be very useful to have oriented bounding boxes available (those are not available in BImserver at the moment).

## Eample

Screenshot from a validationreport generated by this plugins, shown in BIMvie.ws

![alt text](https://github.com/opensourceBIM/IfcValidator/blob/master/docs/img/screenshot.png ""screenshot"")
"
